# arXiv q-fin 今日论文 (2025-11-24)

共找到 11 篇论文

## 1. U.S. Economy and Global Stock Markets: Insights from a Distributional Approach

**作者**: Ping Wu, Dan Zhu

**PDF链接**: [https://arxiv.org/pdf/2511.17140.pdf](https://arxiv.org/pdf/2511.17140.pdf)

**摘要**: Financial markets are interconnected, with micro-currents propagating across global markets and shaping economic trends. This paper moves beyond traditional stock market indices to examine cross-sectional return distributions-15 in our empirical application, each representing a distinct global market. To facilitate this analysis, we develop a matrix functional VAR method with interpretable factors extracted from cross-sectional return distributions. Our approach extends the existing framework from modeling a single function to multiple functions, allowing for a richer representation of cross-sectional dependencies. By jointly modeling these distributions with U.S. macroeconomic indicators, we uncover the predictive power of financial market in forecasting macro-economic dynamics. Our findings reveal that U.S. contractionary monetary policy not only lowers global stock returns, as traditionally understood, but also dampens cross-sectional return kurtosis, highlighting an overlooked policy transmission. This framework enables conditional forecasting, equipping policymakers with a flexible tool to assess macro-financial linkages under different economic scenarios.

---

## 2. Law-Strength Frontiers and a No-Free-Lunch Result for Law-Seeking Reinforcement Learning on Volatility Law Manifolds

**作者**: Jian'an Zhang

**PDF链接**: [https://arxiv.org/pdf/2511.17304.pdf](https://arxiv.org/pdf/2511.17304.pdf)

**摘要**: We study reinforcement learning (RL) on volatility surfaces through the lens of Scientific AI. We ask whether axiomatic no-arbitrage laws, imposed as soft penalties on a learned world model, can reliably align high-capacity RL agents, or mainly create Goodhart-style incentives to exploit model errors. From classical static no-arbitrage conditions we build a finite-dimensional convex volatility law manifold of admissible total-variance surfaces, together with a metric law-penalty functional and a Graceful Failure Index (GFI) that normalizes law degradation under shocks. A synthetic generator produces law-consistent trajectories, while a recurrent neural world model trained without law regularization exhibits structured off-manifold errors. On this testbed we define a Goodhart decomposition \(r = r^{\mathcal{M}} + r^\perp\), where \(r^\perp\) is ghost arbitrage from off-manifold prediction error. We prove a ghost-arbitrage incentive theorem for PPO-type agents, a law-strength trade-off theorem showing that stronger penalties eventually worsen P\&L, and a no-free-lunch theorem: under a law-consistent world model and law-aligned strategy class, unconstrained law-seeking RL cannot Pareto-dominate structural baselines on P\&L, penalties, and GFI. In experiments on an SPX/VIX-like world model, simple structural strategies form the empirical law-strength frontier, while all law-seeking RL variants underperform and move into high-penalty, high-GFI regions. Volatility thus provides a concrete case where reward shaping with verifiable penalties is insufficient for robust law alignment.

---

## 3. Scaling Conditional Autoencoders for Portfolio Optimization via Uncertainty-Aware Factor Selection

**作者**: Ryan Engel, Yu Chen, Pawel Polak, Ioana Boier

**PDF链接**: [https://arxiv.org/pdf/2511.17462.pdf](https://arxiv.org/pdf/2511.17462.pdf)

**摘要**: Conditional Autoencoders (CAEs) offer a flexible, interpretable approach for estimating latent asset-pricing factors from firm characteristics. However, existing studies usually limit the latent factor dimension to around K=5 due to concerns that larger K can degrade performance. To overcome this challenge, we propose a scalable framework that couples a high-dimensional CAE with an uncertainty-aware factor selection procedure. We employ three models for quantile prediction: zero-shot Chronos, a pretrained time-series foundation model (ZS-Chronos), gradient-boosted quantile regression trees using XGBoost and RAPIDS (Q-Boost), and an I.I.D bootstrap-based sample mean model (IID-BS). For each model, we rank factors by forecast uncertainty and retain the top-k most predictable factors for portfolio construction, where k denotes the selected subset of factors. This pruning strategy delivers substantial gains in risk-adjusted performance across all forecasting models. Furthermore, due to each model's uncorrelated predictions, a performance-weighted ensemble consistently outperforms individual models with higher Sharpe, Sortino, and Omega ratios.

---

## 4. Emergence of Randomness in Temporally Aggregated Financial Tick Sequences

**作者**: Silvia Onofri, Andrey Shternshis, Stefano Marmi

**PDF链接**: [https://arxiv.org/pdf/2511.17479.pdf](https://arxiv.org/pdf/2511.17479.pdf)

**摘要**: Markets efficiency implies that the stock returns are intrinsically unpredictable, a property that makes markets comparable to random number generators. We present a novel methodology to investigate ultra-high frequency financial data and to evaluate the extent to which tick by tick returns resemble random sequences. We extend the analysis of ultra high-frequency stock market data by applying comprehensive sets of randomness tests, beyond the usual reliance on serial correlation or entropy measures. Our purpose is to extensively analyze the randomness of these data using statistical tests from standard batteries that evaluate different aspects of randomness.
We illustrate the effect of time aggregation in transforming highly correlated high-frequency trade data to random streams. More specifically, we use many of the tests in the NIST Statistical Test Suite and in the TestU01 battery (in particular the Rabbit and Alphabit sub-batteries), to prove that the degree of randomness of financial tick data increases together with the increase of the aggregation level in transaction time. Additionally, the comprehensive nature of our tests also uncovers novel patterns, such as non-monotonic behaviors in predictability for certain assets. This study demonstrates a model-free approach for both assessing randomness in financial time series and generating pseudo-random sequences from them, with potential relevance in several applications.

---

## 5. Relative Arbitrage Opportunities in an Extended Mean Field System

**作者**: Nicole Tianjiao Yang, Tomoyuki Ichiba

**PDF链接**: [https://arxiv.org/pdf/2311.02690.pdf](https://arxiv.org/pdf/2311.02690.pdf)

**摘要**: This paper studies relative arbitrage opportunities in a market with competitive investors through stochastic differential games in the limit as the number of players tends to infinity. With common noises introduced by the stock capitalization processes, we establish a conditional McKean-Vlasov system to study the market dynamics coupled to the expected trading volume of investors. We show that optimal arbitrage can be characterized as a solution of a Cauchy PDE constructed by the volatility terms in the market model. The structure of the market dynamics can be relaxed, and we provide a theoretical framework to study a general mean-field system, where the interaction is characterized by a joint distribution of wealth and strategies. In this setting, the optimal relative arbitrage constitutes the strong equilibrium of an extended mean-field game. We provide conditions for the existence and uniqueness of the mean-field equilibrium. We further prove the propagation of chaos result for the finite-player game counterpart, and demonstrate that the Nash equilibrium converges to the mean field equilibrium when the population grows to infinity.

---

## 6. Joint Pricing in SPX and VIX Derivative Markets with Composite Change of Time Models

**作者**: Liexin Cheng, Xue Cheng, Xianhua Peng

**PDF链接**: [https://arxiv.org/pdf/2404.16295.pdf](https://arxiv.org/pdf/2404.16295.pdf)

**摘要**: The Chicago Board Options Exchange Volatility Index (VIX) is calculated from SPX options and derivatives of VIX are also traded in market, which leads to the so-called ``consistent modeling" problem. This paper proposes a time-changed Lévy model for log price with a composite change of time structure to capture both features of the implied SPX volatility and the implied volatility of volatility. Consistent modeling is achieved naturally via flexible choices of jumps and leverage effects, as well as the composition of time changes. Many celebrated models are covered as special cases. From this model, we derive an explicit form of the characteristic function for the asset price (SPX) and the pricing formula for European options as well as VIX options. The empirical results indicate great competence of the proposed model in the problem of joint calibration of the SPX/VIX Markets.

---

## 7. Optimal risk mitigation by deep reinsurance

**作者**: Aleksandar Arandjelović, Julia Eisenberg

**PDF链接**: [https://arxiv.org/pdf/2408.06168.pdf](https://arxiv.org/pdf/2408.06168.pdf)

**摘要**: We consider an insurance company which faces financial risk in the form of insurance claims and market-dependent surplus fluctuations. The company aims to simultaneously control its terminal wealth (e.g. at the end of an accounting period) and the ruin probability in a finite time interval by purchasing reinsurance. The target functional is given by the expected utility of terminal wealth perturbed by a modified Gerber-Shiu penalty function. We solve the problem of finding the optimal reinsurance strategy and the corresponding maximal target functional via neural networks. The procedure is illustrated by a numerical example, where the surplus process is given by a Cramér-Lundberg model perturbed by a mean-reverting Ornstein-Uhlenbeck process.

---

## 8. Analyzing distortion riskmetrics and weighted entropy for unimodal and symmetric distributions under partial information constraints

**作者**: Baishuai Zuo, Chuancun Yin

**PDF链接**: [https://arxiv.org/pdf/2504.19725.pdf](https://arxiv.org/pdf/2504.19725.pdf)

**摘要**: In this paper, we develop the lower and upper bounds of worst-case distortion riskmetrics and weighted entropy for unimodal, and symmetric unimodal distributions when mean and variance information are available. We also consider the sharp upper bounds of distortion riskmetrics and weighted entropy for symmetric distribution under known mean and variance. These results are applied to (weighted) entropies, shortfalls and other risk measures. Specifically, entropies include cumulative Tsallis past entropy, cumulative residual Tsallis entropy of order {\alpha}, extended Gini coefficient, fractional generalized cumulative residual entropy, and fractional generalized cumulative entropy. Shortfalls include extended Gini shortfall, Gini shortfall, shortfall of cumulative residual entropy, and shortfall of cumulative residual Tsallis entropy. Other risk measures include nth-order expected shortfall, dual power principle and proportional hazard principle.

---

## 9. Can Nash inform capital requirements? Allocating systemic risk measures

**作者**: Çağın Ararat, Zachary Feinstein

**PDF链接**: [https://arxiv.org/pdf/2504.20413.pdf](https://arxiv.org/pdf/2504.20413.pdf)

**摘要**: Systemic risk measures aggregate the risks from multiple financial institutions to find system-wide capital requirements. Though much attention has been given to assessing the level of systemic risk, less has been given to allocating that risk to the constituent institutions. Within this work, we propose a Nash allocation rule that is inspired by game theory. Intuitively, to construct these capital allocations, the banks compete in a game to reduce their own capital requirements while, simultaneously, maintaining system-level acceptability. We provide sufficient conditions for the existence and uniqueness of Nash allocation rules, and apply our results to the prominent structures used for systemic risk measures in the literature. We demonstrate the efficacy of Nash allocations with numerical case studies using the Eisenberg-Noe aggregation mechanism.

---

## 10. Deciphering the global production network from cross-border firm transactions

**作者**: Neave O'Clery, Ben Radcliffe-Brown, Thomas Spencer, Daniel Tarling-Hunter

**PDF链接**: [https://arxiv.org/pdf/2508.12315.pdf](https://arxiv.org/pdf/2508.12315.pdf)

**摘要**: Critical for policy-making and business operations, the study of global supply chains has been severely hampered by a lack of detailed data. Here we harness international firm-level transaction data covering 20m global firms, and 1 billion cross-border transactions, to infer key inputs for over 1200 products. Transforming this data to a directed network, we find that products are clustered into three large groups including textiles, chemicals and food, and machinery and metals. European industrial nations and China dominate critical intermediate products such as metals, common components and tools, while industrial complexity is highly correlated with embeddedness in densely connected supply chains. We find structural similarities with AIPNET, a product network generated via LLM queries, and strong linkages between products identified in manually-mapped electric vehicle battery and semiconductor supply chains. Finally, both forward and backward linkages are predictive of country-product diversification patterns, with stronger overall evidence for backward (upstream) linkages.

---

## 11. Dynamic Risk Assessment of Wildland-Urban Interface Fires

**作者**: Yusheng Hu, Huaiyi Pan, Shaobo Zhong, Liying Zhang

**PDF链接**: [https://arxiv.org/pdf/2511.16302.pdf](https://arxiv.org/pdf/2511.16302.pdf)

**摘要**: Wildland-Urban Interface (WUI) fires represent a compound disaster resulting from the interactions between natural ecosystems and human settlements, characterized by significantly dynamic evolving risks. However, most current risk assessment studies are based on static frameworks, which struggle to effectively capture the dynamic changes in risk over time. To address this issue, this paper proposes an innovative method that integrates a dynamic evaluation matrix, grey incidence analysis, and an optimization model for the dynamic risk assessment of WUI fires. This method incorporates time-series data by constructing a dynamic evaluation matrix, subsequently calculates the weighted standardized matrix for each evaluated area and its local volume matrices relative to the positive and negative ideal matrices. The dynamic differences between the evaluated areas and the ideal state are quantified by calculating the grey incidence degree, and an optimization model is established to solve for the superiority degree used for risk ranking. Research demonstrates that this method not only simplifies the computational process but also effectively captures the dynamic evolution patterns of fire risk across different areas, enabling refined risk classification. Compared to existing static methods, this framework overcomes their limitation in adequately representing risk dynamics, providing a more scientific basis for decision-making in the dynamic management and proactive prevention and control of WUI fires.

---

