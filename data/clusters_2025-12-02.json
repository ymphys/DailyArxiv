{
  "metadata": {
    "date": "2025-12-02",
    "model": "text-embedding-3-large",
    "summarizer_model": "gpt-4o-mini",
    "paper_count_input": 2315,
    "paper_count_filtered": 2288,
    "paper_count_clustered": 2288,
    "cluster_count": 10,
    "noise_pre_filtered": 27,
    "noise_hdbscan": 20,
    "noise_rescued": 0,
    "embedding_backend": "openai",
    "cache_path": ".cache/embeddings.db"
  },
  "clusters": [
    {
      "cluster_id": 0,
      "size": 18,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2408.00316",
          "title": "The Dynamics of Reheating in Loop Quantum Cosmology",
          "abstract": "In loop quantum cosmology (LQC), the initial singularity is replaced by a quantum bounce, leading to a universal post-bounce evolution characterized by three distinct epochs: bouncing, transition, and slow-roll inflation, before the hot big-bang universe starts. While the generic nature of inflation in LQC is well-established, the subsequent reheating phase-the process that thermalizes the universe and marks the beginning of the hot big bang has remained unexplored in this quantum gravitational framework. This paper presents the first comprehensive integration of the (generalized) reheating mechanism into the LQC paradigm. Using the Power Law Plateau potential and comparing predictions with the latest Planck 2018 and ACT 2025 data, we demonstrate that the inclusion of a reheating phase with a generic equation of state is fully consistent with the cosmological constraints. In addition, using the observational data for the amplitude and spectral index of the scalar perturbations and the tensor-to-scalar ratio, we also constrain the total number of e-folds from the bounce to the present day and find a lower bound, which is less constrained than that obtained previously from the fitting of the high-$l$ CMB temperature power spectrum (TT), the polarization data (TT, TE, EE) and the low-$l$ polarization data (lowP).",
          "primary_category": "gr-qc",
          "authors": [
            "Yogesh",
            "Bao-Fei Li",
            "Mayukh R. Gangopadhyay",
            "Anzhong Wang"
          ]
        },
        {
          "id": "arXiv:2512.02969",
          "title": "Singular $α$-attractors",
          "abstract": "$\\alpha$-attractor models naturally appear in supergravity with hyperbolic geometry. The simplest versions of $\\alpha$-attractors, T- and E-models, originate from theories with non-singular potentials. In canonical variables, these potentials have a plateau that is approached exponentially fast at large values of the inflaton field $\\varphi$. In a closely related class of polynomial $\\alpha$-attractors, or P-models, the potential is not singular, but its derivative is singular at the boundary. The resulting inflaton potential also has a plateau, but it is approached polynomially. In this paper, we will consider a more general class of potentials, which can be singular at the boundary of the moduli space, S-models. These potentials may have a short plateau, after which the potential may grow polynomially or exponentially at large values of the inflaton field. We will show that this class of models may provide a simple solution to the initial conditions problem for $\\alpha$-attractors and may account for a very broad range of possible values of $n_{s}$ matching the recent ACT, SPT, and DESI data.",
          "primary_category": "hep-th",
          "authors": [
            "Renata Kallosh",
            "Andrei Linde"
          ]
        },
        {
          "id": "arXiv:2512.02969",
          "title": "Singular $α$-attractors",
          "abstract": "$\\alpha$-attractor models naturally appear in supergravity with hyperbolic geometry. The simplest versions of $\\alpha$-attractors, T- and E-models, originate from theories with non-singular potentials. In canonical variables, these potentials have a plateau that is approached exponentially fast at large values of the inflaton field $\\varphi$. In a closely related class of polynomial $\\alpha$-attractors, or P-models, the potential is not singular, but its derivative is singular at the boundary. The resulting inflaton potential also has a plateau, but it is approached polynomially. In this paper, we will consider a more general class of potentials, which can be singular at the boundary of the moduli space, S-models. These potentials may have a short plateau, after which the potential may grow polynomially or exponentially at large values of the inflaton field. We will show that this class of models may provide a simple solution to the initial conditions problem for $\\alpha$-attractors and may account for a very broad range of possible values of $n_{s}$ matching the recent ACT, SPT, and DESI data.",
          "primary_category": "hep-th",
          "authors": [
            "Renata Kallosh",
            "Andrei Linde"
          ]
        },
        {
          "id": "arXiv:2512.02847",
          "title": "Inflationary assessment of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan models",
          "abstract": "In the framework of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.",
          "primary_category": "gr-qc",
          "authors": [
            "Theodoros Katsoulas",
            "Kyriakos Tamvakis"
          ]
        },
        {
          "id": "arXiv:2512.02847",
          "title": "Inflationary assessment of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan models",
          "abstract": "In the framework of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.",
          "primary_category": "gr-qc",
          "authors": [
            "Theodoros Katsoulas",
            "Kyriakos Tamvakis"
          ]
        },
        {
          "id": "arXiv:2512.02847",
          "title": "Inflationary assessment of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan models",
          "abstract": "In the framework of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.",
          "primary_category": "gr-qc",
          "authors": [
            "Theodoros Katsoulas",
            "Kyriakos Tamvakis"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2408.00316",
          "title": "The Dynamics of Reheating in Loop Quantum Cosmology",
          "abstract": "In loop quantum cosmology (LQC), the initial singularity is replaced by a quantum bounce, leading to a universal post-bounce evolution characterized by three distinct epochs: bouncing, transition, and slow-roll inflation, before the hot big-bang universe starts. While the generic nature of inflation in LQC is well-established, the subsequent reheating phase-the process that thermalizes the universe and marks the beginning of the hot big bang has remained unexplored in this quantum gravitational framework. This paper presents the first comprehensive integration of the (generalized) reheating mechanism into the LQC paradigm. Using the Power Law Plateau potential and comparing predictions with the latest Planck 2018 and ACT 2025 data, we demonstrate that the inclusion of a reheating phase with a generic equation of state is fully consistent with the cosmological constraints. In addition, using the observational data for the amplitude and spectral index of the scalar perturbations and the tensor-to-scalar ratio, we also constrain the total number of e-folds from the bounce to the present day and find a lower bound, which is less constrained than that obtained previously from the fitting of the high-$l$ CMB temperature power spectrum (TT), the polarization data (TT, TE, EE) and the low-$l$ polarization data (lowP).",
          "authors": [
            "Yogesh",
            "Bao-Fei Li",
            "Mayukh R. Gangopadhyay",
            "Anzhong Wang"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.00316",
          "title": "The Dynamics of Reheating in Loop Quantum Cosmology",
          "abstract": "In loop quantum cosmology (LQC), the initial singularity is replaced by a quantum bounce, leading to a universal post-bounce evolution characterized by three distinct epochs: bouncing, transition, and slow-roll inflation, before the hot big-bang universe starts. While the generic nature of inflation in LQC is well-established, the subsequent reheating phase-the process that thermalizes the universe and marks the beginning of the hot big bang has remained unexplored in this quantum gravitational framework. This paper presents the first comprehensive integration of the (generalized) reheating mechanism into the LQC paradigm. Using the Power Law Plateau potential and comparing predictions with the latest Planck 2018 and ACT 2025 data, we demonstrate that the inclusion of a reheating phase with a generic equation of state is fully consistent with the cosmological constraints. In addition, using the observational data for the amplitude and spectral index of the scalar perturbations and the tensor-to-scalar ratio, we also constrain the total number of e-folds from the bounce to the present day and find a lower bound, which is less constrained than that obtained previously from the fitting of the high-$l$ CMB temperature power spectrum (TT), the polarization data (TT, TE, EE) and the low-$l$ polarization data (lowP).",
          "authors": [
            "Yogesh",
            "Bao-Fei Li",
            "Mayukh R. Gangopadhyay",
            "Anzhong Wang"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.10081",
          "title": "Precision predictions of Starobinsky inflation with self-consistent Weyl-squared corrections",
          "abstract": "Starobinsky's $R+\\alpha R^2$ inflation provides a compelling one-parameter inflationary model that is supported by current cosmological observations. However, at the same order in spacetime derivatives as the $R^2$ term, an effective theory of spacetime geometry must also include the Weyl-squared curvature invariant $W^2$. In this paper, we study the inflationary predictions of the gravitational theory with action of the form $R+\\alpha R^2 - \\beta W^2$, where the coupling constant $\\alpha$ sets the scale of inflation, and corrections due to the $W^2$ term are treated self-consistently via reduction of order in an expansion in the coupling constant $\\beta$, at the linear order in $\\beta/\\alpha$. Cosmological perturbations are found to be described by an effective action with a nontrivial speed of sound $c_{\\textrm{s}}$ for scalar and $c_{\\textrm{t}}$ for tensor modes, satisfying the relation $c_{\\textrm{t}}/c_{\\textrm{s}} \\simeq 1+ \\frac{\\beta}{6\\, \\alpha}$ during the inflationary phase. Within this self-consistent framework, we compute several primordial observables up to the next-to-next-to-next-to leading order (N3LO). We find the tensor-to-scalar ratio $r \\simeq 3(1-\\frac{\\beta}{6\\alpha})(n_\\textrm{s}-1)^2$, the tensor tilt $n_{\\textrm{t}}\\simeq-\\frac{r}{8}$ and the running of the scalar tilt $\\mathfrak{a}_{\\textrm{s}}\\simeq-\\frac{1}{2} (n_{\\textrm{s}} - 1)^2$, all expressed in terms of the observed scalar tilt $n_{\\textrm{s}}$. We also provide the corresponding corrections up to N3LO, $\\mathcal{O}((n_{\\textrm{s}} - 1)^3)$.",
          "authors": [
            "Eugenio Bianchi",
            "Mauricio Gamonal"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.10081",
          "title": "Precision predictions of Starobinsky inflation with self-consistent Weyl-squared corrections",
          "abstract": "Starobinsky's $R+\\alpha R^2$ inflation provides a compelling one-parameter inflationary model that is supported by current cosmological observations. However, at the same order in spacetime derivatives as the $R^2$ term, an effective theory of spacetime geometry must also include the Weyl-squared curvature invariant $W^2$. In this paper, we study the inflationary predictions of the gravitational theory with action of the form $R+\\alpha R^2 - \\beta W^2$, where the coupling constant $\\alpha$ sets the scale of inflation, and corrections due to the $W^2$ term are treated self-consistently via reduction of order in an expansion in the coupling constant $\\beta$, at the linear order in $\\beta/\\alpha$. Cosmological perturbations are found to be described by an effective action with a nontrivial speed of sound $c_{\\textrm{s}}$ for scalar and $c_{\\textrm{t}}$ for tensor modes, satisfying the relation $c_{\\textrm{t}}/c_{\\textrm{s}} \\simeq 1+ \\frac{\\beta}{6\\, \\alpha}$ during the inflationary phase. Within this self-consistent framework, we compute several primordial observables up to the next-to-next-to-next-to leading order (N3LO). We find the tensor-to-scalar ratio $r \\simeq 3(1-\\frac{\\beta}{6\\alpha})(n_\\textrm{s}-1)^2$, the tensor tilt $n_{\\textrm{t}}\\simeq-\\frac{r}{8}$ and the running of the scalar tilt $\\mathfrak{a}_{\\textrm{s}}\\simeq-\\frac{1}{2} (n_{\\textrm{s}} - 1)^2$, all expressed in terms of the observed scalar tilt $n_{\\textrm{s}}$. We also provide the corresponding corrections up to N3LO, $\\mathcal{O}((n_{\\textrm{s}} - 1)^3)$.",
          "authors": [
            "Eugenio Bianchi",
            "Mauricio Gamonal"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.10081",
          "title": "Precision predictions of Starobinsky inflation with self-consistent Weyl-squared corrections",
          "abstract": "Starobinsky's $R+\\alpha R^2$ inflation provides a compelling one-parameter inflationary model that is supported by current cosmological observations. However, at the same order in spacetime derivatives as the $R^2$ term, an effective theory of spacetime geometry must also include the Weyl-squared curvature invariant $W^2$. In this paper, we study the inflationary predictions of the gravitational theory with action of the form $R+\\alpha R^2 - \\beta W^2$, where the coupling constant $\\alpha$ sets the scale of inflation, and corrections due to the $W^2$ term are treated self-consistently via reduction of order in an expansion in the coupling constant $\\beta$, at the linear order in $\\beta/\\alpha$. Cosmological perturbations are found to be described by an effective action with a nontrivial speed of sound $c_{\\textrm{s}}$ for scalar and $c_{\\textrm{t}}$ for tensor modes, satisfying the relation $c_{\\textrm{t}}/c_{\\textrm{s}} \\simeq 1+ \\frac{\\beta}{6\\, \\alpha}$ during the inflationary phase. Within this self-consistent framework, we compute several primordial observables up to the next-to-next-to-next-to leading order (N3LO). We find the tensor-to-scalar ratio $r \\simeq 3(1-\\frac{\\beta}{6\\alpha})(n_\\textrm{s}-1)^2$, the tensor tilt $n_{\\textrm{t}}\\simeq-\\frac{r}{8}$ and the running of the scalar tilt $\\mathfrak{a}_{\\textrm{s}}\\simeq-\\frac{1}{2} (n_{\\textrm{s}} - 1)^2$, all expressed in terms of the observed scalar tilt $n_{\\textrm{s}}$. We also provide the corresponding corrections up to N3LO, $\\mathcal{O}((n_{\\textrm{s}} - 1)^3)$.",
          "authors": [
            "Eugenio Bianchi",
            "Mauricio Gamonal"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.09759",
          "title": "Bianchi-I cosmology with scale dependent $G$ and $Λ$ in asymptotically safe gravity",
          "abstract": "We study anisotropic Bianchi-I cosmology, incorporating quantum gravitational corrections into the Einstein equation through the scale-dependent Newton coupling and cosmological term, as determined by the flow equation of the effective action for gravity. For the classical cosmological constant $\\Lambda_0=0$, we derive the quantum mechanically corrected, or quantum-improved power-series solution for a general equation-of-state parameter $w$ in the range $-1<w\\leq 1$ in the form of expansions in both inverse cosmic time and the anisotropy parameter. We give a general criterion, valid for any $\\Lambda_0$, if the solution becomes isotropic in the late time, which indicates that the universe becomes isotropic for most cases of $-1<w<1$ except $w=1$. By numerical analysis, we show that quantum corrections lead to earlier isotropization compared to the classical case starting from an initially highly anisotropic state. In contrast, for $\\Lambda_0 >0$, we obtain the inverse power-series solution in the exponential of the cosmic time. We find that the universe always becomes isotropic in the late time, in accordance with the cosmic no hair theorem, and the quantum corrections make the isotropization faster. We also briefly summarize the Kasner solution and its generalization with quantum corrections.",
          "authors": [
            "Chiang-Mei Chen",
            "Akihiro Ishibashi",
            "Rituparna Mandal",
            "Nobuyoshi Ohta"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.09759",
          "title": "Bianchi-I cosmology with scale dependent $G$ and $Λ$ in asymptotically safe gravity",
          "abstract": "We study anisotropic Bianchi-I cosmology, incorporating quantum gravitational corrections into the Einstein equation through the scale-dependent Newton coupling and cosmological term, as determined by the flow equation of the effective action for gravity. For the classical cosmological constant $\\Lambda_0=0$, we derive the quantum mechanically corrected, or quantum-improved power-series solution for a general equation-of-state parameter $w$ in the range $-1<w\\leq 1$ in the form of expansions in both inverse cosmic time and the anisotropy parameter. We give a general criterion, valid for any $\\Lambda_0$, if the solution becomes isotropic in the late time, which indicates that the universe becomes isotropic for most cases of $-1<w<1$ except $w=1$. By numerical analysis, we show that quantum corrections lead to earlier isotropization compared to the classical case starting from an initially highly anisotropic state. In contrast, for $\\Lambda_0 >0$, we obtain the inverse power-series solution in the exponential of the cosmic time. We find that the universe always becomes isotropic in the late time, in accordance with the cosmic no hair theorem, and the quantum corrections make the isotropization faster. We also briefly summarize the Kasner solution and its generalization with quantum corrections.",
          "authors": [
            "Chiang-Mei Chen",
            "Akihiro Ishibashi",
            "Rituparna Mandal",
            "Nobuyoshi Ohta"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05799",
          "title": "Chaotic Inflation RIDES Again",
          "abstract": "Following the recent Atacama Cosmology Telescope (ACT) results, we revisit chaotic inflation based on a single complex scalar field with mass term $M^2 |\\Phi|^2$, which usually predicts a spectra index $n_s\\approx 0.96$ but a too-large tensor to scalar ratio $r\\approx 0.16$. With radiative corrections, the potential $M^2 |\\Phi|^2 \\ln \\left( |\\Phi|^2/\\Lambda^2 \\right)$ induces spontaneous symmetry breaking near the scale $\\Lambda$, yielding a Pseudo Nambu-Goldstone boson which can play the role of a quintessence field, hence radiative inflation and dark energy (RIDE). Including a non-minimal coupling to gravity $\\xi |\\Phi|^2 R^2$ reduces $r$, allowing a good fit of the RIDE model to Planck data. Allowing a small additional quartic coupling correction $\\lambda |\\Phi|^4$ increases both $n_s$ and $r$, with a good fit to ACT data sets achieved for $\\xi \\approx 1$.",
          "authors": [
            "Venus Keus",
            "Stephen F. King"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05799",
          "title": "Chaotic Inflation RIDES Again",
          "abstract": "Following the recent Atacama Cosmology Telescope (ACT) results, we revisit chaotic inflation based on a single complex scalar field with mass term $M^2 |\\Phi|^2$, which usually predicts a spectra index $n_s\\approx 0.96$ but a too-large tensor to scalar ratio $r\\approx 0.16$. With radiative corrections, the potential $M^2 |\\Phi|^2 \\ln \\left( |\\Phi|^2/\\Lambda^2 \\right)$ induces spontaneous symmetry breaking near the scale $\\Lambda$, yielding a Pseudo Nambu-Goldstone boson which can play the role of a quintessence field, hence radiative inflation and dark energy (RIDE). Including a non-minimal coupling to gravity $\\xi |\\Phi|^2 R^2$ reduces $r$, allowing a good fit of the RIDE model to Planck data. Allowing a small additional quartic coupling correction $\\lambda |\\Phi|^4$ increases both $n_s$ and $r$, with a good fit to ACT data sets achieved for $\\xi \\approx 1$.",
          "authors": [
            "Venus Keus",
            "Stephen F. King"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05799",
          "title": "Chaotic Inflation RIDES Again",
          "abstract": "Following the recent Atacama Cosmology Telescope (ACT) results, we revisit chaotic inflation based on a single complex scalar field with mass term $M^2 |\\Phi|^2$, which usually predicts a spectra index $n_s\\approx 0.96$ but a too-large tensor to scalar ratio $r\\approx 0.16$. With radiative corrections, the potential $M^2 |\\Phi|^2 \\ln \\left( |\\Phi|^2/\\Lambda^2 \\right)$ induces spontaneous symmetry breaking near the scale $\\Lambda$, yielding a Pseudo Nambu-Goldstone boson which can play the role of a quintessence field, hence radiative inflation and dark energy (RIDE). Including a non-minimal coupling to gravity $\\xi |\\Phi|^2 R^2$ reduces $r$, allowing a good fit of the RIDE model to Planck data. Allowing a small additional quartic coupling correction $\\lambda |\\Phi|^4$ increases both $n_s$ and $r$, with a good fit to ACT data sets achieved for $\\xi \\approx 1$.",
          "authors": [
            "Venus Keus",
            "Stephen F. King"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05799",
          "title": "Chaotic Inflation RIDES Again",
          "abstract": "Following the recent Atacama Cosmology Telescope (ACT) results, we revisit chaotic inflation based on a single complex scalar field with mass term $M^2 |\\Phi|^2$, which usually predicts a spectra index $n_s\\approx 0.96$ but a too-large tensor to scalar ratio $r\\approx 0.16$. With radiative corrections, the potential $M^2 |\\Phi|^2 \\ln \\left( |\\Phi|^2/\\Lambda^2 \\right)$ induces spontaneous symmetry breaking near the scale $\\Lambda$, yielding a Pseudo Nambu-Goldstone boson which can play the role of a quintessence field, hence radiative inflation and dark energy (RIDE). Including a non-minimal coupling to gravity $\\xi |\\Phi|^2 R^2$ reduces $r$, allowing a good fit of the RIDE model to Planck data. Allowing a small additional quartic coupling correction $\\lambda |\\Phi|^4$ increases both $n_s$ and $r$, with a good fit to ACT data sets achieved for $\\xi \\approx 1$.",
          "authors": [
            "Venus Keus",
            "Stephen F. King"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02847",
          "title": "Inflationary assessment of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan models",
          "abstract": "In the framework of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.",
          "authors": [
            "Theodoros Katsoulas",
            "Kyriakos Tamvakis"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02847",
          "title": "Inflationary assessment of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan models",
          "abstract": "In the framework of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.",
          "authors": [
            "Theodoros Katsoulas",
            "Kyriakos Tamvakis"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02847",
          "title": "Inflationary assessment of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan models",
          "abstract": "In the framework of $F(\\mathcal{R},\\tilde{\\mathcal{R}})$ Einstein-Cartan gravity with an action depending both of the Ricci scalar and the so-called Holst-invariant curvature we consider models that include cubic terms of the latter in the action and study their inflationary behavior. These terms can have a considerable effect either positive or negative in relation to the agreement with present observational data, depending on parameters. In parameter regions where the quadratic models fail to produce results consistent with observational data, the presence of these additional cubic terms can lead to compatible predictions.",
          "authors": [
            "Theodoros Katsoulas",
            "Kyriakos Tamvakis"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02969",
          "title": "Singular $α$-attractors",
          "abstract": "$\\alpha$-attractor models naturally appear in supergravity with hyperbolic geometry. The simplest versions of $\\alpha$-attractors, T- and E-models, originate from theories with non-singular potentials. In canonical variables, these potentials have a plateau that is approached exponentially fast at large values of the inflaton field $\\varphi$. In a closely related class of polynomial $\\alpha$-attractors, or P-models, the potential is not singular, but its derivative is singular at the boundary. The resulting inflaton potential also has a plateau, but it is approached polynomially. In this paper, we will consider a more general class of potentials, which can be singular at the boundary of the moduli space, S-models. These potentials may have a short plateau, after which the potential may grow polynomially or exponentially at large values of the inflaton field. We will show that this class of models may provide a simple solution to the initial conditions problem for $\\alpha$-attractors and may account for a very broad range of possible values of $n_{s}$ matching the recent ACT, SPT, and DESI data.",
          "authors": [
            "Renata Kallosh",
            "Andrei Linde"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02969",
          "title": "Singular $α$-attractors",
          "abstract": "$\\alpha$-attractor models naturally appear in supergravity with hyperbolic geometry. The simplest versions of $\\alpha$-attractors, T- and E-models, originate from theories with non-singular potentials. In canonical variables, these potentials have a plateau that is approached exponentially fast at large values of the inflaton field $\\varphi$. In a closely related class of polynomial $\\alpha$-attractors, or P-models, the potential is not singular, but its derivative is singular at the boundary. The resulting inflaton potential also has a plateau, but it is approached polynomially. In this paper, we will consider a more general class of potentials, which can be singular at the boundary of the moduli space, S-models. These potentials may have a short plateau, after which the potential may grow polynomially or exponentially at large values of the inflaton field. We will show that this class of models may provide a simple solution to the initial conditions problem for $\\alpha$-attractors and may account for a very broad range of possible values of $n_{s}$ matching the recent ACT, SPT, and DESI data.",
          "authors": [
            "Renata Kallosh",
            "Andrei Linde"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02969",
          "title": "Singular $α$-attractors",
          "abstract": "$\\alpha$-attractor models naturally appear in supergravity with hyperbolic geometry. The simplest versions of $\\alpha$-attractors, T- and E-models, originate from theories with non-singular potentials. In canonical variables, these potentials have a plateau that is approached exponentially fast at large values of the inflaton field $\\varphi$. In a closely related class of polynomial $\\alpha$-attractors, or P-models, the potential is not singular, but its derivative is singular at the boundary. The resulting inflaton potential also has a plateau, but it is approached polynomially. In this paper, we will consider a more general class of potentials, which can be singular at the boundary of the moduli space, S-models. These potentials may have a short plateau, after which the potential may grow polynomially or exponentially at large values of the inflaton field. We will show that this class of models may provide a simple solution to the initial conditions problem for $\\alpha$-attractors and may account for a very broad range of possible values of $n_{s}$ matching the recent ACT, SPT, and DESI data.",
          "authors": [
            "Renata Kallosh",
            "Andrei Linde"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02969",
          "title": "Singular $α$-attractors",
          "abstract": "$\\alpha$-attractor models naturally appear in supergravity with hyperbolic geometry. The simplest versions of $\\alpha$-attractors, T- and E-models, originate from theories with non-singular potentials. In canonical variables, these potentials have a plateau that is approached exponentially fast at large values of the inflaton field $\\varphi$. In a closely related class of polynomial $\\alpha$-attractors, or P-models, the potential is not singular, but its derivative is singular at the boundary. The resulting inflaton potential also has a plateau, but it is approached polynomially. In this paper, we will consider a more general class of potentials, which can be singular at the boundary of the moduli space, S-models. These potentials may have a short plateau, after which the potential may grow polynomially or exponentially at large values of the inflaton field. We will show that this class of models may provide a simple solution to the initial conditions problem for $\\alpha$-attractors and may account for a very broad range of possible values of $n_{s}$ matching the recent ACT, SPT, and DESI data.",
          "authors": [
            "Renata Kallosh",
            "Andrei Linde"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 1,
      "size": 294,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:1808.09350",
          "title": "Relativistic and Gravitational transformations in Electrochemistry and NMR spectroscopy",
          "abstract": "A relativistic transformation of the electrode potential has been derived to account for time dilation effects in electrode processes. This newly formulated Lorentz transformation is interpreted through the generation of spin-2 boson gravitons, originating from the fusion of spin-1 boson virtual photons, which subsequently escape into higher dimensions. Gravitational transformations of the electrode potential have also been derived, explaining the observed decrease in cell potential under stronger gravitational fields. The reduction in electrode potential near a gravitational source is attributed to a greater flux of gravitons escaping into higher dimensions in stronger gravitational fields compared to weaker ones. Similarly, the potential energy associated with the spin of magnetically active nuclei in an applied magnetic field, as observed in NMR spectroscopy, is shown to be Lorentz variant. This provides a mathematical demonstration that the Hamiltonian describing the energy of such nuclei is also Lorentz variant. The relativistic and gravitational transformations of both the electrode potential and the spin-related potential energy in magnetic fields are shown to be analogous.",
          "primary_category": "physics.gen-ph",
          "authors": [
            "Mirza Wasif Baig"
          ]
        },
        {
          "id": "arXiv:2512.02296",
          "title": "Observing binary neutron star subpopulations with the Einstein Telescope",
          "abstract": "The formation channels of binary neutron stars (BNSs) remain uncertain. The detection of GW190425 by LIGO/Virgo/KAGRA (LVK) suggests a subpopulation of massive BNSs, possibly formed through unstable \"case BB\" mass transfer with short merger delays. We investigate whether next-generation detectors such as the Einstein Telescope (ET) can identify and characterise such subpopulations. Using the latest LVK constraints on the BNS merger rate, we generate mock ET catalogues containing a mixture of light and heavy subpopulations. The redshift distribution of each subpopulation is modeled as the convolution of the cosmic star formation rate with a time-delay distribution: heavy BNSs have fixed short delays, while light BNSs follow power-law delays with indices -0.5,-1,-1.5. Hierarchical Bayesian analyses are then performed on catalogues of 100-5,000 events. With hundreds of detections from ET, we will be able to establish that the total mass distribution is bimodal. A few thousand events are sufficient to disentangle the redshift distributions of the two subpopulations for moderate time-delay indices (-0.5 or -1). For steeper indices (-1.5), the differences are more subtle, requiring larger catalogues, beyond what we could explore given our computational resources. Next-generation detectors should enable the detection of multiple BNS subpopulations and their redshift evolution, providing valuable insight into their formation pathways.",
          "primary_category": "astro-ph.HE",
          "authors": [
            "Alexandre Toubiana",
            "Irina Dvorkin"
          ]
        },
        {
          "id": "arXiv:2512.02295",
          "title": "Driving mechanisms of solar active region geysers: The role of interacting magnetic flux",
          "abstract": "Active region recurrent jets are manifestations of episodic magnetic energy release processes driven by complex interactions in the lower solar atmosphere. While magnetic flux emergence and cancellation are widely recognized as key contributors to jet formation, the mechanisms behind repeated magnetic reconnection remain poorly understood. In this letter, we report a sequence of nine recurrent jets originating from active region AR 12715 during its decay phase, where the jet activity was associated with a complex distribution of fragmented magnetic flux. Non-linear force-free field (NLFFF) extrapolations reveal the presence of low-lying, current-carrying loops beneath overarching open magnetic fields near the jet footpoints. These magnetic structures were perturbed by (i) emerging flux elements and (ii) interactions between oppositely polarized moving magnetic features (MMFs). To interpret these observations, we compare them with 3D radiative MHD simulation from the Bifrost model, which reproduce jet formation driven by interacting bipolar MMFs, leading to subsequent flux cancellation in the photosphere. Our results emphasize the critical role of MMF-driven flux interactions in initiating and sustaining recurrent jet activity in active regions.",
          "primary_category": "astro-ph.SR",
          "authors": [
            "Aabha Monga",
            "Satoshi Inoue",
            "Jeongwoo Lee",
            "Haimin Wang",
            "Viggo Hansteen"
          ]
        },
        {
          "id": "arXiv:2512.02292",
          "title": "Solitary Alfvén Waves",
          "abstract": "We present a three-dimensional numerical model of a solitary spherically polarized Alfvén wave packet -- an Alfvénon, characterized by open field-line topology and magnetic field reversals, resembling the switchbacks observed by Parker Solar Probe to be a nearly ubiquitous feature of turbulence in the inner heliosphere. Direct magnetohydrodynamic simulations of the constructed Alfvénon demonstrates remarkable stability, confirming its nature as an exact, nonlinear solution of the ideal MHD equations.",
          "primary_category": "astro-ph.SR",
          "authors": [
            "Zesen Huang",
            "Marco Velli",
            "Chen Shi",
            "Yuliang Ding"
          ]
        },
        {
          "id": "arXiv:2512.02292",
          "title": "Solitary Alfvén Waves",
          "abstract": "We present a three-dimensional numerical model of a solitary spherically polarized Alfvén wave packet -- an Alfvénon, characterized by open field-line topology and magnetic field reversals, resembling the switchbacks observed by Parker Solar Probe to be a nearly ubiquitous feature of turbulence in the inner heliosphere. Direct magnetohydrodynamic simulations of the constructed Alfvénon demonstrates remarkable stability, confirming its nature as an exact, nonlinear solution of the ideal MHD equations.",
          "primary_category": "astro-ph.SR",
          "authors": [
            "Zesen Huang",
            "Marco Velli",
            "Chen Shi",
            "Yuliang Ding"
          ]
        },
        {
          "id": "arXiv:2512.02277",
          "title": "Measuring $^{19,20}$O(p,n)$^{20,21}$F reactions using an active target detector",
          "abstract": "Proton capture on $^{19,20}$O nuclei is measured in inverse kinematics with the active target detector MuSIC@Indiana using CH$_4$ as the target gas. Rejection of unreacted and inelastically scattered beam, along with transfer and fusion on the $^{12}$C allows extraction of the (p,n) cross section. As the cross-section for direct (p,n) processes at these energies is small, the measurement provides access to the proton fusion cross-section. An analysis approach that allows extraction of the proton fusion cross-section is detailed.",
          "primary_category": "nucl-ex",
          "authors": [
            "Rohit Kumar",
            "H. Desilets",
            "R.T. deSouza"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:1808.09350",
          "title": "Relativistic and Gravitational transformations in Electrochemistry and NMR spectroscopy",
          "abstract": "A relativistic transformation of the electrode potential has been derived to account for time dilation effects in electrode processes. This newly formulated Lorentz transformation is interpreted through the generation of spin-2 boson gravitons, originating from the fusion of spin-1 boson virtual photons, which subsequently escape into higher dimensions. Gravitational transformations of the electrode potential have also been derived, explaining the observed decrease in cell potential under stronger gravitational fields. The reduction in electrode potential near a gravitational source is attributed to a greater flux of gravitons escaping into higher dimensions in stronger gravitational fields compared to weaker ones. Similarly, the potential energy associated with the spin of magnetically active nuclei in an applied magnetic field, as observed in NMR spectroscopy, is shown to be Lorentz variant. This provides a mathematical demonstration that the Hamiltonian describing the energy of such nuclei is also Lorentz variant. The relativistic and gravitational transformations of both the electrode potential and the spin-related potential energy in magnetic fields are shown to be analogous.",
          "authors": [
            "Mirza Wasif Baig"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2301.08492",
          "title": "WASP-39b: exo-Saturn with patchy cloud composition, moderate metallicity, and underdepleted S/O",
          "abstract": "WASP-39b is one of the first extrasolar giant gas planets that has been observed within the JWST ERS program. Fundamental properties that may enable the link to exoplanet formation differ amongst retrieval methods, for example metallicity and mineral ratios. In this work, the formation of clouds in the atmosphere of WASP-39b is explored to investigate how inhomogeneous cloud properties (particle sizes, material composition, opacity) may be for this intermediately warm gaseous exoplanet. WASP-39b's atmosphere has a comparable day-night temperature median with sufficiently low temperatures that clouds may form globally. The presence of clouds on WASP-39b can explain observations without resorting to a high (> 100x solar) metallicity atmosphere for a reduced vertical mixing efficiency. The assessment of mineral ratios shows an under-depletion of S/O due to condensation compared to C/O, Mg/O, Si/O, Fe/O ratios. Vertical patchiness due to heterogeneous cloud composition challenges simple cloud models. An equal mixture of silicates and metal oxides is expected to characterise the cloud top. Further, optical properties of Fe and Mg silicates in the mid-infrared differ significantly which will impact the interpretation of JWST observations. We conclude that WASP-39b's atmosphere contains clouds and the underdepletion of S/O by atmospheric condensation processes suggest the use of sulphur gas species as a possible link to primordial element abundances. Over-simplified cloud models do not capture the complex nature of mixed-condensate clouds in exoplanet atmospheres. The clouds in the observable upper atmosphere of WASP-39b are a mixture of different silicates and metal oxides. The use of constant particles sizes and/or one-material cloud particles alone to interpret spectra may not be sufficient to capture the full complexity available through JWST observations.",
          "authors": [
            "Ludmila Carone",
            "David A. Lewis",
            "Dominic Samra",
            "Aaron D. Schneider",
            "Christiane Helling"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2311.05704",
          "title": "The Case for Hot-Mode Accretion in Abell 2029",
          "abstract": "Radiative cooling and AGN heating are thought to form a feedback loop that regulates the evolution of low redshift cool-core galaxy clusters. Numerical simulations suggest that formation of multiphase gas in the cluster core imposes a floor on the ratio of cooling time ($t_{\\rm cool}$) to free-fall time ($t_{\\rm ff}$) at $\\min ( t_{\\rm cool} / t_{\\rm ff} ) \\approx 10$. Observations of galaxy clusters show evidence for such a floor, and usually the cluster cores with $\\min ( t_{\\rm cool} / t_{\\rm ff} ) \\lesssim 30$ contain abundant multiphase gas. However, there are important outliers. One of them is Abell 2029, a massive galaxy cluster ($M_{200} \\gtrsim 10^{15}$ M$_\\odot$) with $\\min( t_{\\rm cool}/t_{\\rm ff}) \\sim 20$, but little apparent multiphase gas. In this paper, we present high resolution 3D hydrodynamic AMR simulations of a cluster similar to A2029 and study how it evolves over a period of 1-2 Gyr. Those simulations suggest that Abell 2029 self-regulates without producing multiphase gas because the mass of its central black hole ($\\sim 5\\times 10^{10} \\, M_\\odot$) is great enough for Bondi accretion of hot ambient gas to produce enough feedback energy to compensate for radiative cooling.",
          "authors": [
            "Deovrat Prasad",
            "G. Mark Voit",
            "Brian W. O'Shea"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.05267",
          "title": "Holographic complexity and the Hubble tension: a quantum gravity portrayal for the large scale structure of the cosmos",
          "abstract": "In this letter, we propose a relationship between the so-called Hubble-Lemaître constant $H_{0}$ and holographic complexity related to the emergence of spacetime in quantum gravity. Such a result can represent an important step to understanding the Hubble tension by introducing a quantum gravity perspective for cosmological observations: regarding the degree of quantum complexity we measure around us.",
          "authors": [
            "Carlos Silva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.05267",
          "title": "Holographic complexity and the Hubble tension: a quantum gravity portrayal for the large scale structure of the cosmos",
          "abstract": "In this letter, we propose a relationship between the so-called Hubble-Lemaître constant $H_{0}$ and holographic complexity related to the emergence of spacetime in quantum gravity. Such a result can represent an important step to understanding the Hubble tension by introducing a quantum gravity perspective for cosmological observations: regarding the degree of quantum complexity we measure around us.",
          "authors": [
            "Carlos Silva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.05267",
          "title": "Holographic complexity and the Hubble tension: a quantum gravity portrayal for the large scale structure of the cosmos",
          "abstract": "In this letter, we propose a relationship between the so-called Hubble-Lemaître constant $H_{0}$ and holographic complexity related to the emergence of spacetime in quantum gravity. Such a result can represent an important step to understanding the Hubble tension by introducing a quantum gravity perspective for cosmological observations: regarding the degree of quantum complexity we measure around us.",
          "authors": [
            "Carlos Silva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.05267",
          "title": "Holographic complexity and the Hubble tension: a quantum gravity portrayal for the large scale structure of the cosmos",
          "abstract": "In this letter, we propose a relationship between the so-called Hubble-Lemaître constant $H_{0}$ and holographic complexity related to the emergence of spacetime in quantum gravity. Such a result can represent an important step to understanding the Hubble tension by introducing a quantum gravity perspective for cosmological observations: regarding the degree of quantum complexity we measure around us.",
          "authors": [
            "Carlos Silva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.03331",
          "title": "Minimal U(1) two-Higgs-doublet models for quark and lepton flavour",
          "abstract": "In the context of the 2HDM, and assuming that neutrinos acquire masses via the Weinberg operator, we perform a systematic analysis to determine the minimal quark and lepton flavour patterns, compatible with masses, mixing and CP violation data, realisable by Abelian symmetries. We determine four minimal models for quarks, where the number of independent parameters matches the number of observables. For the lepton sector, three minimal predictive models are identified. Namely, we find scenarios with a preference for the upper/lower octant of the $\\theta_{23}$ atmospheric mixing angle, that exhibit lower bounds on the lightest neutrino masses currently probed by cosmology and testable at future neutrinoless double beta decay experiments, even for a normally-ordered neutrino masses. We investigate the phenomenology of each model taking into account all relevant theoretical, electroweak precision observables, scalar sector constraints, as well as stringent quark flavour processes such as $\\overline{B} \\rightarrow X_s \\gamma$, $B_s \\rightarrow \\mu^- \\mu^+$ and meson oscillations, and the charged lepton flavour-violating decays $e_\\alpha^{-} \\rightarrow e_\\beta^{-} e_\\gamma^{+} e_\\delta^{-}$ and $e_\\alpha \\rightarrow e_\\beta \\gamma$. We show that, in some cases, Abelian flavour symmetries provide a natural framework to suppress flavour-changing neutral couplings and lead to scenarios featuring heavy neutral/charged scalar masses below the TeV scale within the reach of current experiments.",
          "authors": [
            "J. R. Rocha",
            "H. B. Câmara",
            "R. G. Felipe",
            "F. R. Joaquim"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.00247",
          "title": "Inferring three-nucleon couplings from multi-messenger neutron-star observations",
          "abstract": "Understanding the interactions between nucleons in dense matter is an important challenge in theoretical physics. Effective field theories have emerged as the dominant approach to address this problem at low energies, with many successful applications to the structure of nuclei and the properties of dense nucleonic matter. However, how far into the interior of neutron stars these interactions can describe dense matter is an open question. Here, we develop a framework that enables the inference of three-nucleon couplings in dense matter directly from astrophysical neutron star observations. We apply this formalism to the LIGO/Virgo gravitational-wave event GW170817 and the X-ray measurements from NASA's Neutron Star Interior Composition Explorer and establish direct constraints for the couplings that govern three-nucleon interactions in chiral effective field theory. Furthermore, we demonstrate how next-generation observations of a population of neutron star mergers can offer stringent constraints on three-nucleon couplings, potentially at a level comparable to those from laboratory data. Our work directly connects the microscopic couplings in quantum field theories to macroscopic observations of neutron stars, providing a way to test the consistency between low-energy couplings inferred from terrestrial and astrophysical data.",
          "authors": [
            "Rahul Somasundaram",
            "Isak Svensson",
            "Soumi De",
            "Andrew E. Deneris",
            "Yannick Dietz",
            "Philippe Landry",
            "Achim Schwenk",
            "Ingo Tews"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.13497",
          "title": "Global analysis of $μ\\to e$ interactions in the SMEFT",
          "abstract": "We study current experimental bounds on charged lepton flavor violating (CLFV) $\\mu$-$e$ interactions in the model-independent framework of the Standard Model Effective Field Theory (SMEFT). Assuming a generic flavor structure in the quark sector, we consider the contributions of CLFV operators to low-energy observables, including $\\mu\\to e\\gamma$ and $\\mu\\to e$ conversion for quark-flavor conserving operators and CLFV meson decays for quark-flavor violating operators. At high energy, we consider limits on CLFV decays of the Higgs and Z bosons and of the top quark, and obtain bounds on operators with light quarks by recasting searches for production of $e\\mu$ pairs in $pp$ collisions at the Large Hadron Collider (LHC). We connect observables at low- and high-energy by taking into account renormalization group running and matching between CLFV operators. We also discuss the sensitivity of the future Electron-Ion Collider, where the prospective bounds are derived by imposing simple cuts on final state particles. We find that, in a single operator scenario, bounds on purely leptonic operators are dominated by $\\mu \\rightarrow e \\gamma$ and $\\mu \\rightarrow e$ conversion. Semileptonic operators with down-type quarks are also dominantly constrained by low-energy observables, while LHC searches lead the bounds on up-type quark-flavor violating operators. Taking simplified multiple-coupling scenarios, we show that it is easy to evade the strongest low-energy bounds from spin-independent $\\mu \\rightarrow e$ conversion, and that collider searches are competitive and complementary to constraints from spin-dependent $\\mu \\rightarrow e$ conversion and other low-energy probes.",
          "authors": [
            "Filippo Delzanno",
            "Kaori Fuyuto",
            "Sergi Gonzàlez-Solís",
            "Emanuele Mereghetti"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.13497",
          "title": "Global analysis of $μ\\to e$ interactions in the SMEFT",
          "abstract": "We study current experimental bounds on charged lepton flavor violating (CLFV) $\\mu$-$e$ interactions in the model-independent framework of the Standard Model Effective Field Theory (SMEFT). Assuming a generic flavor structure in the quark sector, we consider the contributions of CLFV operators to low-energy observables, including $\\mu\\to e\\gamma$ and $\\mu\\to e$ conversion for quark-flavor conserving operators and CLFV meson decays for quark-flavor violating operators. At high energy, we consider limits on CLFV decays of the Higgs and Z bosons and of the top quark, and obtain bounds on operators with light quarks by recasting searches for production of $e\\mu$ pairs in $pp$ collisions at the Large Hadron Collider (LHC). We connect observables at low- and high-energy by taking into account renormalization group running and matching between CLFV operators. We also discuss the sensitivity of the future Electron-Ion Collider, where the prospective bounds are derived by imposing simple cuts on final state particles. We find that, in a single operator scenario, bounds on purely leptonic operators are dominated by $\\mu \\rightarrow e \\gamma$ and $\\mu \\rightarrow e$ conversion. Semileptonic operators with down-type quarks are also dominantly constrained by low-energy observables, while LHC searches lead the bounds on up-type quark-flavor violating operators. Taking simplified multiple-coupling scenarios, we show that it is easy to evade the strongest low-energy bounds from spin-independent $\\mu \\rightarrow e$ conversion, and that collider searches are competitive and complementary to constraints from spin-dependent $\\mu \\rightarrow e$ conversion and other low-energy probes.",
          "authors": [
            "Filippo Delzanno",
            "Kaori Fuyuto",
            "Sergi Gonzàlez-Solís",
            "Emanuele Mereghetti"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.13497",
          "title": "Global analysis of $μ\\to e$ interactions in the SMEFT",
          "abstract": "We study current experimental bounds on charged lepton flavor violating (CLFV) $\\mu$-$e$ interactions in the model-independent framework of the Standard Model Effective Field Theory (SMEFT). Assuming a generic flavor structure in the quark sector, we consider the contributions of CLFV operators to low-energy observables, including $\\mu\\to e\\gamma$ and $\\mu\\to e$ conversion for quark-flavor conserving operators and CLFV meson decays for quark-flavor violating operators. At high energy, we consider limits on CLFV decays of the Higgs and Z bosons and of the top quark, and obtain bounds on operators with light quarks by recasting searches for production of $e\\mu$ pairs in $pp$ collisions at the Large Hadron Collider (LHC). We connect observables at low- and high-energy by taking into account renormalization group running and matching between CLFV operators. We also discuss the sensitivity of the future Electron-Ion Collider, where the prospective bounds are derived by imposing simple cuts on final state particles. We find that, in a single operator scenario, bounds on purely leptonic operators are dominated by $\\mu \\rightarrow e \\gamma$ and $\\mu \\rightarrow e$ conversion. Semileptonic operators with down-type quarks are also dominantly constrained by low-energy observables, while LHC searches lead the bounds on up-type quark-flavor violating operators. Taking simplified multiple-coupling scenarios, we show that it is easy to evade the strongest low-energy bounds from spin-independent $\\mu \\rightarrow e$ conversion, and that collider searches are competitive and complementary to constraints from spin-dependent $\\mu \\rightarrow e$ conversion and other low-energy probes.",
          "authors": [
            "Filippo Delzanno",
            "Kaori Fuyuto",
            "Sergi Gonzàlez-Solís",
            "Emanuele Mereghetti"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.09377",
          "title": "Quasinormal modes of rotating black holes in shift-symmetric Einstein-scalar-Gauss-Bonnet theory",
          "abstract": "We employ a recently developed spectral method to obtain the spectrum of quasinormal modes of rapidly rotating black holes in alternative theories of gravity and apply it to the black holes of shift-symmetric Einstein-scalar-Gauss-Bonnet theory. In this theory the quasinormal modes were recently obtained by employing perturbation theory in quadratic order in the Gauss-Bonnet coupling constant. Here we present the full non-perturbative results for the spectrum within the domain of existence of rotating black holes and compare with the perturbative results. We also compare with the quasinormal mode spectrum of rapidly rotating Einstein-dilaton-Gauss-Bonnet black holes.",
          "authors": [
            "Fech Scen Khoo",
            "Jose Luis Blázquez-Salcedo",
            "Burkhard Kleihaus",
            "Jutta Kunz"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.09377",
          "title": "Quasinormal modes of rotating black holes in shift-symmetric Einstein-scalar-Gauss-Bonnet theory",
          "abstract": "We employ a recently developed spectral method to obtain the spectrum of quasinormal modes of rapidly rotating black holes in alternative theories of gravity and apply it to the black holes of shift-symmetric Einstein-scalar-Gauss-Bonnet theory. In this theory the quasinormal modes were recently obtained by employing perturbation theory in quadratic order in the Gauss-Bonnet coupling constant. Here we present the full non-perturbative results for the spectrum within the domain of existence of rotating black holes and compare with the perturbative results. We also compare with the quasinormal mode spectrum of rapidly rotating Einstein-dilaton-Gauss-Bonnet black holes.",
          "authors": [
            "Fech Scen Khoo",
            "Jose Luis Blázquez-Salcedo",
            "Burkhard Kleihaus",
            "Jutta Kunz"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.18152",
          "title": "Extremely luminous optical afterglow of an energetic gamma-ray burst GRB 230204B",
          "abstract": "Robotic telescope networks play an important role in capturing early and bright optical afterglows, providing critical insights into the energetics and emission mechanisms of GRBs. In this study, we analyze GRB 230204B, an exceptionally energetic and multi-pulsed long GRB, detected by the Fermi GBM and MAXI detectors, with an isotropic equivalent gamma-ray energy exceeding 10$^{54}$ erg. Time-resolved spectral analysis reveals a transition in the prompt emission from hard (sub-photospheric dominated) spectra during early pulses to softer (synchrotron radiation dominated) spectra in later pulses, indicative of a hybrid jet composition. We report the discovery and characterization of the optical afterglow using the MASTER and BOOTES robotic telescope networks, which enabled rapid follow-up observations starting at $\\sim$1.3 ks post-burst. The optical luminosity at this time was exceptionally high, surpassing that of many other optically bright GRBs, such as GRB 990123, GRB 080319B, etc. This places the burst among the most luminous optical GRBs observed to date. Long-term radio observations extending to 335 days post-burst were conducted with the ATCA. Multi-wavelength modeling was conducted using an external ISM forward-shock top-hat jet model with \\sw{afterglowpy}. The results reveal a narrow and highly collimated jet with a circumburst density of $n_{0} \\sim$ 28.12 cm$^{-3}$, kinetic energy $E_{\\rm K} \\sim$ 4.18 $\\times 10^{55}$ erg, and a relatively low value of $\\epsilon_{B}$ = 2.14 $\\times 10^{-6}$, indicating shock-compression of magnetic field in the surrounding interstellar medium. We constrained a low radiative efficiency of $\\sim$ 4.3 \\%. This study highlights the indispensable contribution of robotic networks to early afterglow observations and advances our understanding of GRB 230204B unique characteristics and underlying jet physics.",
          "authors": [
            "Rahul Gupta",
            "Judith Racusin",
            "Vladimir Lipunov",
            "Y.-D. Hu",
            "Ashna Gulati",
            "Alberto J. Castro-Tirado",
            "Tara Murphy",
            "Motoko Serino",
            "Kirill Zhirkov",
            "S. Shilling",
            "Samantha R. Oates",
            "James K. Leung",
            "T. Parsotan",
            "Amit K. Ror",
            "Shashi B. Pandey",
            "S. Iyyani",
            "V. Sharma",
            "A. Aryan",
            "Jin-Ming Bai",
            "Pavel Balanutsa",
            "David Buckley",
            "María D. Caballero-García",
            "I. M. Carrasco-García",
            "A. Castellón",
            "Sebastián Castillo",
            "Chen-Zhou Cui",
            "Yu-Feng Fan",
            "Emilio Fernández-García",
            "Guillermo García-Segura",
            "Maria Gritsevich",
            "Sergiy Guziy",
            "David Hiriart",
            "William H. Lee",
            "Soomin Jeong",
            "Carlos Jesus Pérez del Pulgar",
            "Ignacio Olivares",
            "I.H. Park",
            "Ignacio Pérez-García",
            "S. Razzaque",
            "Rubén Sánchez-Ramírez",
            "Nataly Tyurina",
            "Vladislav Topolev",
            "Chuan-Jun Wang",
            "Si-Yu Wu",
            "Yu-Xin Xin",
            "Ding-Rong Xiong",
            "Xiao-Hong Zhao",
            "Jirong Mao",
            "Bao-Li Lun",
            "Ye Kai"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.02329",
          "title": "Concept integral field unit spectrometer instrument for the next-generation mm-wave cosmological surveys",
          "abstract": "Past millimeter-wave galaxy surveys have primarily probed the brightest starburst galaxies only and suffered heavily from confusion. The interpretation of existing surveys has also been hindered by the lack of reliable redshift indicators for measuring distances for entire samples. Thanks to recent advances in mm-wave detector technologies we can now overcome these limitations, and conduct the first truly volumetric surveys of star-forming galaxies at mm-wavelengths approaching the L* luminosities of typical galaxies, with ~1000 redshift slices spanning most of the Cosmic star-forming volume (z ~ 1--12) with nearly uniform mass and luminosity selection. We describe an instrument concept capable of delivering such surveys with the technologies available today, which can be built and operated on a ground-based mm-wave facility in the near future. Such integral field unit spectrometers can resolve and identify redshifts for up to to 25,000 star-forming galaxies per year even when operated on a 10-m class telescope. On a larger aperture it can do the same faster or probe even deeper. We propose a collaboration open-source initiative to design, build, and operate one or several such cameras through the shared contributions of leading experts and telescopes from around the globe.",
          "authors": [
            "Attila Kovács",
            "Garrett K. Keating",
            "Thomas R. Greve",
            "Timothy Norton"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.02682",
          "title": "Species scale associated with Weinberg operator and bound on Majorana neutrino mass",
          "abstract": "When states in a tower like the Kaluza-Klein or the string tower couple to another state through the irrelevant operators of the same type, their contributions to the loop corrections of the relevant or the marginal operators are not negligible, threatening the perturbativity. This can be avoided provided the cutoff scale is lower than the species scale associated with the irrelevant operator. We apply this to towers of states associated with the neutrino which couple to the Higgs through the Weinberg operator, the dimension-5 irrelevant operator generating the Majorana neutrino mass. Requiring the `Majorana species scale', the species scale associated with the Weinberg operator, to be below the gravitational species scale, one finds the lower bound on the Majorana neutrino mass determined by the species number. The Festina-Lente bound also gives the lower bound on the Majorana neutrino mass, but it is not so stringent. Meanwhile, even if the neutrino mass is of the Dirac type at the renormalizable level, the Majorana mass term still can be written in the effective field theory action so far as the Weinberg operator is not forbidden. Even if the Majorana neutrino mass is larger than the Dirac one, so far as there are sufficient degrees of freedom with mass smaller than the scale of the cosmological constant, the observation of the Majorana nature of the neutrino may not contradict to quantum gravity constraints which rules out the neutrino mass purely given by the Majorana type.",
          "authors": [
            "Min-Seok Seo"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.02682",
          "title": "Species scale associated with Weinberg operator and bound on Majorana neutrino mass",
          "abstract": "When states in a tower like the Kaluza-Klein or the string tower couple to another state through the irrelevant operators of the same type, their contributions to the loop corrections of the relevant or the marginal operators are not negligible, threatening the perturbativity. This can be avoided provided the cutoff scale is lower than the species scale associated with the irrelevant operator. We apply this to towers of states associated with the neutrino which couple to the Higgs through the Weinberg operator, the dimension-5 irrelevant operator generating the Majorana neutrino mass. Requiring the `Majorana species scale', the species scale associated with the Weinberg operator, to be below the gravitational species scale, one finds the lower bound on the Majorana neutrino mass determined by the species number. The Festina-Lente bound also gives the lower bound on the Majorana neutrino mass, but it is not so stringent. Meanwhile, even if the neutrino mass is of the Dirac type at the renormalizable level, the Majorana mass term still can be written in the effective field theory action so far as the Weinberg operator is not forbidden. Even if the Majorana neutrino mass is larger than the Dirac one, so far as there are sufficient degrees of freedom with mass smaller than the scale of the cosmological constant, the observation of the Majorana nature of the neutrino may not contradict to quantum gravity constraints which rules out the neutrino mass purely given by the Majorana type.",
          "authors": [
            "Min-Seok Seo"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.10508",
          "title": "REBELS-IFU: Dust Build-up in Massive Galaxies at Redshift 7",
          "abstract": "In recent years, observations with the JWST have started to map out the rapid metal enrichment of the early Universe, while (sub)millimeter observations have simultaneously begun to reveal the ubiquity of dust beyond $z\\gtrsim6$. However, the pathways that led to the assembly of early dust reservoirs remain poorly quantified, and require pushing our understanding of key scaling relations between dust, gas and metals into the early Universe. We investigate the dust build-up in twelve $6.5 \\lesssim z \\lesssim 7.7$ galaxies drawn from the REBELS survey that benefit from (i) JWST/NIRSpec strong-line metallicity measurements, (ii) ALMA [CII]-based redshifts and gas masses, and (iii) dust masses from single- or multi-band ALMA continuum observations. Combining these measurements, we investigate the dust-to-gas (DtG), dust-to-metal (DtM), and dust-to-stellar mass (DtS) ratios of our sample as a function of metallicity. While our analysis is limited by systematic uncertainties related to the [CII]-to-H$_2$ conversion factor and dust temperature, we explore a wide range of possible values, and carefully assess their impact on our results. Under a fiducial set of assumptions, we find an average $\\log(\\mathrm{DtG}) = -3.02 \\pm 0.23$, only slightly below that of local metal-rich galaxies. On the other hand, at fixed metallicity our average $\\log(\\mathrm{DtS}) = -2.15 \\pm 0.42$ is significantly larger than that of low-redshift galaxies. Finally, through a comparison to various theoretical models of high-redshift dust production, we find that assembling the dust reservoirs in massive galaxies at $z\\approx7$ likely requires the combination of rapid supernova enrichment and efficient ISM dust growth.",
          "authors": [
            "Hiddo Algera",
            "Lucie Rowland",
            "Mauro Stefanon",
            "Marco Palla",
            "Laura Sommovigo",
            "Hanae Inami",
            "Rychard Bouwens",
            "Manuel Aravena",
            "Rebecca Bowler",
            "Pratika Dayal",
            "Ilse De Looze",
            "Andrea Ferrara",
            "Rebecca Fisher",
            "Luca Graziani",
            "Cindy Gulis",
            "Kasper Heintz",
            "Jacqueline Hodge",
            "Andrés Laza-Ramos",
            "Ivana van Leeuwen",
            "Andrea Pallottini",
            "Siân Phillips",
            "Sander Schouws",
            "Renske Smit",
            "Daniel Stark",
            "Paul van der Werf"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.17145",
          "title": "Feedback and dynamical masses in high-$z$ galaxies: the advent of high-resolution NIRSpec spectroscopy",
          "abstract": "Stellar feedback is an essential step in the baryon cycle of galaxies, but it remains unconstrained beyond Cosmic Noon. We study the ionized gas kinematics, dynamical mass and gas-flow properties of a sample of 16 sub-$L^{\\star}$ star-forming galaxies at $4\\leq z\\leq7.6$, using high-resolution JWST/NIRSpec observations. The emission lines are resolved, with velocity dispersions ($\\sigma_{\\rm gas}{\\rm~(km~s^{-1})}\\simeq38-96$) comparable to more massive galaxies at Cosmic Noon. From $\\sigma_{\\rm gas}$ and the galaxy size ($r_e=400-960~$pc), we estimate the dynamical mass to be $\\log M_{\\rm dyn}/M_{\\odot}=9.25-10.25$. Stellar-to-dynamical mass ratios are low ($\\log M_{\\star}/M_{\\rm dyn}\\in[-0.5,-2]$) and decrease with increasing SFR surface density ($\\Sigma_{\\rm SFR}$). We estimate the gas surface densities assuming a star-formation law, but the gas masses do not balance the baryon-to-dynamical mass ratios, which would require a decrease in the star-formation efficiency. We find evidence of ionized outflows in five out of the sixteen galaxies, based on the need of broad components to reproduce the emission-line wings. We only observe outflows from galaxies undergoing recent bursts of star formation ${\\rm SFR_{10}/SFR_{100}\\geq1}$, with elevated $\\Sigma_{\\rm SFR}$ and low $M_{\\star}/M_{\\rm dyn}$. This links high gas surface densities to increased outflow incidence and lower $M_{\\star}/M_{\\rm dyn}$. With moderate outflow velocities ($v_{\\rm flow}{\\rm~(km~s^{-1})}=150-250$) and mass outflow rates ($\\dot{M}_{\\rm flow}/{\\rm M_{\\odot} yr^{-1}}=0.2-5$), these high-redshift galaxies appear more efficient at removing baryons than low-redshift galaxies with similar $M_{\\star}$, showing mass loading-factors of $\\dot{M}_{\\rm flow}/{\\rm SFR}=0.04-0.4$. For their given dynamical mass, the outflow velocities exceed the escape velocities, meaning that they may eventually enrich the Circumgalactic Medium.",
          "authors": [
            "A. Saldana-Lopez",
            "J. Chisholm",
            "S. Gazagnes",
            "R. Endsley",
            "M. J. Hayes",
            "D. A. Berg",
            "S. L. Finkelstein",
            "S. R. Flury",
            "N. G. Guseva",
            "A. Henry",
            "Y. I. Izotov",
            "E. Lambrides",
            "R. Marques-Chaves",
            "C. T. Richardson"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.03561",
          "title": "Scaling relations, dynamical heating and tidal disruption in spin $s$ ultralight dark matter models",
          "abstract": "We explore the impact of spin 0, spin 1 and spin 2 ultralight dark Matter (ULDM) on small scales by numerically solving the Schrödinger-Poisson system using the time-split method. We perform simulations of ULDM for each spin, starting with different numbers of identical initial solitons and analyse the properties of the resulting haloes after they merge. Our findings reveal that higher spin lead to broader, less dense haloes with more prominent Navarro-Frenk-White (NFW) tails, a characteristic that persists regardless of the number of solitons involved. Additionally, we study the process of dynamical heating for these haloes, and find that the heating time-scale for higher spin increases order an of magnitude compared to the spin 0 case. Then, we identify scaling relations that describe the density profile, core-NFW of spin~$s$ ULDM haloes as a function of the number of initial solitons $N_{\\text{sol}}$. These relations allow us to construct equivalent haloes based on average density or total mass, for arbitrarily large $N_{\\text{sol}}$, without having to simulate those systems. We simulate the orbit of an ULDM satellite in a constructed halo treated as an external potential, and find that for host haloes having the same average density, the disruption time of the satellite is as predicted for a uniform sphere regardless of the spin. However, satellites orbiting haloes having the same mass for each spin, result in faster disruption in the case of spin 0, whereas for haloes having the same core size result in faster disruption in the case of spin 2.",
          "authors": [
            "Jessica N. López-Sánchez",
            "Erick Munive-Villa",
            "Constantinos Skordis",
            "Federico R. Urban"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.12407",
          "title": "Quantum-mechanical numerical model of interaction between dark atom and nucleus of substance",
          "abstract": "The hypothesis of composite $XHe$ dark atoms may provide solution to the long-standing problem of direct searches for dark matter particles. The main problem of the $XHe$ dark atom is its ability to strongly interact with the nucleus of substance, arising from the unshielded nuclear attraction between the helium nucleus and the nucleus of matter. It is assumed that in order to prevent the destruction of the bound structure of dark atom, the effective potential of interaction between $XHe$ and the nucleus of substance must have dipole Coulomb barrier that prevents the fusion of dark matter atom particles with the nucleus of substance. The problem in describing the interaction between dark atom and substance nucleus is the three-body problem, for which an exact analytical solution is not available. Consequently, to assess the physical meaning of the proposed scenario, it is essential to develop a numerical approach. Our approach involves consistently developing an accurate quantum mechanical description of this three-body system, comprising bound dark atom and the external nucleus of substance. We incorporate the necessary effects and interactions to enhance the precision of the results, which helps to elucidate the most significant aspects of the proposed dark atom scenario.",
          "authors": [
            "T. E. Bikbaev",
            "M. Yu. Khlopov",
            "A. G. Mayorov"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.12407",
          "title": "Quantum-mechanical numerical model of interaction between dark atom and nucleus of substance",
          "abstract": "The hypothesis of composite $XHe$ dark atoms may provide solution to the long-standing problem of direct searches for dark matter particles. The main problem of the $XHe$ dark atom is its ability to strongly interact with the nucleus of substance, arising from the unshielded nuclear attraction between the helium nucleus and the nucleus of matter. It is assumed that in order to prevent the destruction of the bound structure of dark atom, the effective potential of interaction between $XHe$ and the nucleus of substance must have dipole Coulomb barrier that prevents the fusion of dark matter atom particles with the nucleus of substance. The problem in describing the interaction between dark atom and substance nucleus is the three-body problem, for which an exact analytical solution is not available. Consequently, to assess the physical meaning of the proposed scenario, it is essential to develop a numerical approach. Our approach involves consistently developing an accurate quantum mechanical description of this three-body system, comprising bound dark atom and the external nucleus of substance. We incorporate the necessary effects and interactions to enhance the precision of the results, which helps to elucidate the most significant aspects of the proposed dark atom scenario.",
          "authors": [
            "T. E. Bikbaev",
            "M. Yu. Khlopov",
            "A. G. Mayorov"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.20088",
          "title": "Planar Property and Long-range Azimuthal Correlation in $e^+e^-$ Annihilation",
          "abstract": "The $e^+e^-$ annihilation of unpolarized beams is free from initial hadron states or initial anisotropy around the azimuthal angle, hence ideal for studying the correlations of dynamical origin via final state jets. We investigate the planar properties of the multi-jet events employing the relevant event-shape observables at next-to-next-to-leading order ($\\mathcal{O}$($\\alpha_{s}^{3}$)) in perturbative QCD; particularly, the azimuthal angle correlations on the long pseudo-rapidity (polar angle) range (Ridge correlation) between the inclusive jet momenta are calculated. We illustrate the significant planar properties and the strong correlations which are natural results of the energy-momentum conservation of the perturbative QCD radiation dynamics. Our study provides benchmarks of hard strong interaction background for the investigations on the collective and/or thermal effects via the Ridge-like correlation observables for complex scattering processes.",
          "authors": [
            "Xuan Chen",
            "Yuesheng Dai",
            "Shi-Yuan Li",
            "Zong-Guo Si",
            "Huiting Sun"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09890",
          "title": "Interplay of non-standard interactions and Earth's composition in atmospheric neutrino oscillations",
          "abstract": "Many geophysical and geochemical phenomena in the Earth's interior are related to physical and chemical processes in the outer core and the core-mantle boundary, which are directly linked to the isotopic composition. Determining the composition using standard geophysical methods has been challenging. Atmospheric neutrino oscillations, influenced by their weak interactions with terrestrial matter, offer a new way to gather valuable information about the Earth's internal structure and, in particular, to constrain the composition of the core. If neutrinos had as yet unknown non-standard interactions (NSI), this could affect their propagation in matter and consequently impact studies of Earth's composition using neutrino oscillation tomography. This study focuses on scalar-mediated NSI and their potential impact on atmospheric neutrino oscillations, which could obscure information about the hydrogen content in the outer core. In turn, compositional uncertainties could affect the characterization of NSI parameters. The analysis is based on a Monte-Carlo simulation of the energy distribution and azimuthal angles of neutrino-generated $\\mu$ events. Using a model of the Earth consisting of 55 concentric shells with constant densities determined from the PREM, we evaluate the effect on the number of events due to changes in the outer core composition (Z/A)$_{oc}$ and the NSI strength parameter $\\epsilon$. To examine the detection capability to observe such variations, we consider regions in the plane of (Z/A)$_{oc}$ and $\\epsilon$ where the statistical significance of the discrepancies between the modified Earth model and the reference model is less than $1\\sigma$.",
          "authors": [
            "Juan Carlos D'Olivo",
            "José Arnulfo Herrera Lara",
            "Ismael Romero",
            "Matias Reynoso",
            "Oscar A. Sampayo"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09890",
          "title": "Interplay of non-standard interactions and Earth's composition in atmospheric neutrino oscillations",
          "abstract": "Many geophysical and geochemical phenomena in the Earth's interior are related to physical and chemical processes in the outer core and the core-mantle boundary, which are directly linked to the isotopic composition. Determining the composition using standard geophysical methods has been challenging. Atmospheric neutrino oscillations, influenced by their weak interactions with terrestrial matter, offer a new way to gather valuable information about the Earth's internal structure and, in particular, to constrain the composition of the core. If neutrinos had as yet unknown non-standard interactions (NSI), this could affect their propagation in matter and consequently impact studies of Earth's composition using neutrino oscillation tomography. This study focuses on scalar-mediated NSI and their potential impact on atmospheric neutrino oscillations, which could obscure information about the hydrogen content in the outer core. In turn, compositional uncertainties could affect the characterization of NSI parameters. The analysis is based on a Monte-Carlo simulation of the energy distribution and azimuthal angles of neutrino-generated $\\mu$ events. Using a model of the Earth consisting of 55 concentric shells with constant densities determined from the PREM, we evaluate the effect on the number of events due to changes in the outer core composition (Z/A)$_{oc}$ and the NSI strength parameter $\\epsilon$. To examine the detection capability to observe such variations, we consider regions in the plane of (Z/A)$_{oc}$ and $\\epsilon$ where the statistical significance of the discrepancies between the modified Earth model and the reference model is less than $1\\sigma$.",
          "authors": [
            "Juan Carlos D'Olivo",
            "José Arnulfo Herrera Lara",
            "Ismael Romero",
            "Matias Reynoso",
            "Oscar A. Sampayo"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.18747",
          "title": "Gravitational form factor of the kaon in holographic QCD",
          "abstract": "The gravitational form factor (GFF) of the kaon is investigated in a bottom-up holographic QCD model, in which the strange quark mass breaks the SU(3) flavor symmetry. The probe energy ($Q^2$) dependence of the kaon GFF is explicitly shown and compared to that of the pion. It is presented that our result shows the $1/Q^2$ behavior in the high energy region, which is consistent with the perturbative QCD prediction. The gravitational radius of the kaon is also calculated, and it is found that the result is quite close to that of the pion but slightly smaller.",
          "authors": [
            "Zhibo Liu",
            "Akira Watanabe"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.18747",
          "title": "Gravitational form factor of the kaon in holographic QCD",
          "abstract": "The gravitational form factor (GFF) of the kaon is investigated in a bottom-up holographic QCD model, in which the strange quark mass breaks the SU(3) flavor symmetry. The probe energy ($Q^2$) dependence of the kaon GFF is explicitly shown and compared to that of the pion. It is presented that our result shows the $1/Q^2$ behavior in the high energy region, which is consistent with the perturbative QCD prediction. The gravitational radius of the kaon is also calculated, and it is found that the result is quite close to that of the pion but slightly smaller.",
          "authors": [
            "Zhibo Liu",
            "Akira Watanabe"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.00088",
          "title": "Flavored Peccei-Quinn symmetries in the minimal $ν$DFSZ model",
          "abstract": "We consider a Dine-Fischler-Srednicki-Zhitnitsky (DFSZ) axion model extended with two right-handed neutrino fields to realize the minimal type-I seesaw. In this $\\nu$DFSZ scheme we systematically determine the simplest quark and lepton flavor patterns compatible with masses, mixing and charge-parity violation data, realized by flavored U(1) Peccei-Quinn (PQ) symmetries. We discuss axion dark matter production in pre and post-inflationary cosmology in this context, and predictions for the axion couplings to photons and fermions. In particular, helioscopes and haloscopes are able to probe our models via their distinct axion-to-photon couplings, while in the quark sector the most stringent constraints on axion-fermion couplings are set by $K^+ \\rightarrow \\pi^+ + a$. Flavor-violating constraints in the lepton sector are not as relevant as those stemming from star cooling that restrict the diagonal $ee$ and $\\mu\\mu$ axion couplings to charged leptons. We also obtain axion mass bounds for the most interesting models and discuss how minimal flavored PQ symmetries provide a natural framework to suppress flavor-violating couplings.",
          "authors": [
            "J. R. Rocha",
            "H. B. Câmara",
            "F. R. Joaquim"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.01750",
          "title": "Probing the Distance Duality Relation with Machine Learning and Recent Data",
          "abstract": "The distance duality relation (DDR) relates two independent ways of measuring cosmological distances, namely the angular diameter distance and the luminosity distance. These can be measured with baryon acoustic oscillations (BAO) and Type Ia supernovae (SNe Ia), respectively. Here, we use recent DESI DR1, Pantheon+, SH0ES and DES-SN5YR data to test this fundamental relation. We employ a parametrised approach and also use model-independent Generic Algorithms (GA), which are a machine learning method where functions evolve loosely based on biological evolution. When we use DESI and Pantheon+ data without Cepheid calibration or big bang nucleosynthesis (BBN), there is a $2\\sigma$ violation of the DDR in the parametrised approach. Then, we add high-redshift BBN data and the low-redshift SH0ES Cepheid calibration. This reflects the Hubble tension since both data sets are in tension in the standard cosmological model $\\Lambda$CDM. In this case, we find a significant violation of the DDR in the parametrised case at $6\\sigma$. Replacing the Pantheon+ SNe Ia data by DES-SN5YR, we find similar results. For the model-independent approach, we find no deviation in the uncalibrated case and a small deviation with BBN and Cepheids which remains at 1$\\sigma$. This shows the importance of considering model-independent approaches for the DDR.",
          "authors": [
            "Felicitas Keil",
            "Savvas Nesseris",
            "Isaac Tutusaus",
            "Alain Blanchard"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.05038",
          "title": "Time-resolved spectro-polarimetric analysis of extremely bright GRB 230307A: Possible Evidence of evolution from photospheric to synchrotron dominated emission",
          "abstract": "The radiation mechanisms powering Gamma-ray bursts (GRBs) and their physical processes remain one of the unresolved questions in high-energy astrophysics. Spectro-polarimetric observations of exceptionally bright GRBs provide a powerful diagnostic tool to address these challenges. GRB 230307A, the second-brightest long-duration GRB ever detected, exhibits a rare association with a Kilonova, offering a unique and rare probe into the emission processes of GRBs originating from compact object mergers. We present a comprehensive time-averaged and time-resolved spectro-polarimetric analysis of GRB 230307A using joint observations from the $AstroSat$ Cadmium Zinc Telluride Imager (CZTI), the $Fermi$ Gamma-ray Burst Monitor (GBM) and $Konus$-Wind. Spectral analysis reveals a temporal evolution in the low-energy photon index, $\\alpha$, transitioning from a hard to a softer state over the burst duration. Time-averaged polarimetric measurements yield a low polarization fraction ($<$ 12.7 %), whereas time-resolved polarization analysis unveils a marked increase in polarization fractions ($>$ 49 %) in the later stages of the emission episode. This spectro-polarimetric evolution suggests a transition in the dominant radiative mechanism: the initial phase, possibly characterized by thermal-dominated photospheric emission (unpolarized or weakly polarized), gives way to a regime dominated by non-thermal synchrotron emission (highly polarized). This transition provides possible evidence for the evolving influence of magnetic fields in shaping the GRB emission process and jet dynamics.",
          "authors": [
            "Soumya Gupta",
            "Rahul Gupta",
            "Tanmoy Chattopadhayay",
            "Sunder Sahayanathan",
            "D. Frederiks",
            "D. Svinkin",
            "Dipankar Bhattacharya",
            "Judith Racusin",
            "Santosh Vadawale",
            "Varun Bhalerao",
            "A. Lysenko",
            "A. Ridnaia",
            "A. Tsvetkova",
            "M. Ulanov"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.05856",
          "title": "Analyzing type Ia supernovae near-infrared light curves with Principal Component Analysis",
          "abstract": "Type Ia supernovae (SNeIa), the thermonuclear explosions of C/O white dwarf stars in binary systems, are phenomena that remain poorly understood. The complexity of their progenitor systems, explosion physics and intrinsic diversity poses not only challenges for their understanding as astrophysical objects, but also for their standardization and use as cosmological probes. Near-infrared (NIR) observations offer a promising avenue for studying the physics of SNeIa and for reducing systematic uncertainties in distance estimations, as they exhibit lower dust extinction and smaller dispersion in peak luminosity than optical bands. Here, Principal Component Analysis (PCA) is applied to a sample of SNeIa with well-sampled NIR (YJH-band) light curves to identify the dominant components of their variability and constrain physical underlying properties. The theoretical models of Kasen2006 are used for the physical interpretation of the PCA components, where we found the 56Ni mass to describe the dominant variability. Other factors, such as mixing and metallicity, were found to contribute significantly as well. However, some differences are found between the components of the NIR bands which may be attributed to differences in the explosion aspects they each trace. Additionally, the PCA components are compared to various light-curve parameters, identifying strong correlations between some components and peak brightness in both the NIR and optical bands, particularly in the Y band. When applying PCA to NIR color curves, we found interesting correlations with the host-galaxy mass, where SNeIa with redder NIR colors are predominantly found in less massive galaxies. We also investigate the potential for improved standardization in the Y band by incorporating PCA coefficients as correction parameters, leading to a reduction in the scatter of the intrinsic luminosity of SNeIa.",
          "authors": [
            "T. E. Müller-Bravo",
            "L.Galbany",
            "M. D. Stritzinger",
            "C. Ashall",
            "E. Baron",
            "C. R. Burns",
            "P. Höflich",
            "N. Morrell",
            "M. Phillips",
            "N. B. Suntzeff",
            "S. A. Uddin"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.07449",
          "title": "Polarization Angle Orthogonal Jumps in Fast Radio Bursts",
          "abstract": "Recently, polarization angle (PA) orthogonal jumps over millisecond timescales were discovered from three bursts of a repeating fast radio burst source FRB 20201124A by the FAST telescope. In general, PA jumps can arise from the coherent or incoherent superposition of two electromagnetic waves, with total polarization fraction remains constant in the former and not in the latter. The observations seem to be more consistent with incoherent superposition. The amplitudes of the two orthogonal modes are required to be comparable when jumps occur. We provide general constraints on FRB emission and propagation mechanisms based on the data. Physically, it is difficult to produce PA jumps through switching the dominance of the two orthogonal modes within millisecond timescales, and a geometric effect due to the source rotation is more plausible. This requires that the emission region be within the magnetosphere of a spinning central engine, likely a magnetar. The two orthogonal modes in different directions can arise when the source rotation brings two independent emission regions with different dominant modes successively into the line-of-sight, either due to intrinsic radiation mechanisms or the O-mode undergoing a delayed transparency because of the Alfvén-O-mode conversion. Splitting of emission directions for the two modes due to plasma birefringence is not easy to achieve when the plasma is moving relativistically. For intrinsic radiation mechanisms, curvature radiation always predicts $|E_{\\rm X}/E_{\\rm O}|\\gtrsim1$, and is difficult to produce jumps; whereas inverse Compton scattering can achieve the conversion amplitude ratio $|E_{\\rm X}/E_{\\rm O}|=1$ to allow jumps to occur under special geometric configurations.",
          "authors": [
            "Yuanhong Qu",
            "Bing Zhang",
            "Pawan Kumar"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.11424",
          "title": "MINDS. Anatomy of a water-rich, inclined, brown dwarf disk: lack of abundant hydrocarbons",
          "abstract": "2MASS J04381486+2611399 (or J0438) is one of the few young brown dwarfs (BD) with a highly inclined ($i\\!\\sim\\!70^\\circ$) disk. Here we report results from JWST-MIRI MRS, HST-ACS and ALMA Band 7 observations. Despite its late spectral type (M7.25), the spectrum of J0438 resembles those of inner disks around earlier-type stars (K1-M5, T Tauri stars), with a volatile reservoir lacking hydrocarbons (except for acetylene, C$_2$H$_2$) and dominated by water. Other identified species are H$_2$, CO$_2$, HCN, [Ar$^{+}$], and [Ne$^{+}$]. The dominance of water over hydrocarbons is driven by multiple factors such as disk dynamics, young disk age, low accretion rate and possible inner disk clearing. J0438 appears highly dynamic, showing a seesaw-like variability and extended emission in H$_2 \\,\\,\\, S$(1), $S$(3), $S$(5), [Ne$^{+}$] and CO ($J=3-2$). Interestingly, the CO emission reaches up to 400 au from the brown dwarf, suggesting ongoing infalling/outflowing activity impacting the disk chemistry. These observations underscore the combined power of MIRI, HST and ALMA in characterizing the chemical diversity and dynamics of brown dwarf disks.",
          "authors": [
            "Giulia Perotti",
            "Nicolás T. Kurtovic",
            "Thomas Henning",
            "Göran Olofsson",
            "Aditya M. Arabhavi",
            "Kamber Schwarz",
            "Jayatee Kanwar",
            "Roy van Boekel",
            "Inga Kamp",
            "Ilaria Pascucci",
            "Ewine F. van Dishoeck",
            "Manuel Güdel",
            "Pierre-Olivier Lagage",
            "David Barrado",
            "Alessio Caratti o Garatti",
            "Adrian M. Glauser",
            "F. Lahuis",
            "Valentin Christiaens",
            "Riccardo Franceschi",
            "Danny Gasman",
            "Sierra L. Grant",
            "Hyerin Jang",
            "Till Kaeufer",
            "Maria Morales-Calderón",
            "Milou Temmink",
            "Marissa Vlasblom"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.14592",
          "title": "The fate of the progenitors of luminous red novae: Infrared detection of LRNe years after the outburst",
          "abstract": "We present late-time optical and infrared (IR) observations of a sample of nine extragalactic luminous red novae (LRNe) discovered in the past three decades. In all of these cases, the LRN survivors fade below the pre-outburst luminosity of the progenitors in the optical region. However, they remain visible in the near-IR (NIR) and bright in the mid-IR (MIR) domains for years. We recover AT 1997bs in Spitzer images from 2004, and a residual source is visible in HST and JWST NIR images 27 years after the outburst. The spectral energy distribution (SED) of AT 1997bs is consistent with that of an orange giant star with a photospheric temperature of 3750-4250 K and a radius of 120-150 $R_{\\odot}$, without a significant circumstellar dust attenuation. Similarly, the SED of AT 2019zhd after three years is compatible with a red supergiant star with $T_{ph}=3100\\pm100$ K and $R=350\\pm50$ $R_{\\odot}$. Another LRN, AT 2011kp, is detected by JWST 12.5 years after the outburst. Its SED, with two excesses at 1.8 and 7.7 $\\mu$m, can be explained by a cold ($T\\sim450$ K) dusty shell composed of amorphous carbon surrounding a cold expanded source, plus emission from the Pa$\\alpha$ line. We constructed the [3.6]-[4.5] colour curves extending up to more than 7 years for six LRNe, which show a similar evolution: The MIR colour is $\\sim-0.5$ mag before the optical maximum light, it becomes bluer after around one year, and then it gradually turns to redder colours before reaching $\\sim+1.0$ mag after 7 years. We also estimated the masses and the temperatures of newly formed dust years after the LRN onset. We find that LRNe produce dust masses of the order of (1-5)x$10^{-4}$ (and up to 2x$10^{-3}$) $M_{\\odot}$ between 7 and 13 years after the outbursts. Finally, we find that the remnants of LRNe detected years or decades after the merger are expanded and cool objects, similar to red supergiant stars.",
          "authors": [
            "A. Reguitti",
            "A. Pastorello",
            "G. Valerin"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.15272",
          "title": "Superheavy dark matter from the natural inflation in light of the highest-energy astroparticle events",
          "abstract": "Superheavy dark matter has been attractive as a candidate of particle dark matter. We propose a ``natural\" particle model, in which the dark matter serves as the inflaton in natural inflation, while decaying to high-energy particles at energies of $10^{9}-10^{13} \\, \\text{GeV}$ from the prediction of the inflation. A scalar field responsible for diluting the dark matter abundance revives the natural inflation either with or without the recent data from the Atacama Cosmology Telescope (ACT) and baryon acoustic oscillation results from Dark Energy Spectroscopic Instrument. Since the dark matter must be a spin-zero scalar, we carefully study the galactic dark matter 3-body decay into fermions and two body decays into a gluon pair, and point out relevant multi-messenger bounds that constrain these decay modes. Interestingly, the predicted energy scale may coincide with the AMATERASU event and/or the KM3NeT neutrino event, KM3-230213A. We also point out particle models with dark baryon to further alleviate $\\gamma$-ray bounds. This scenario yields several testable predictions for the UHECR observations, including the highest-energy neutrons that are unaffected by magnetic fields, the tensor-to-scalar ratio, the running of spectral indices, $\\alpha_s\\gtrsim\\mathcal{O}(0.001)$, and the existence of light new colored particles that could be accessible at future collider experiments. Further measurements of high-energy cosmic rays, including their components and detailed directions, may provide insight into not only the origin of the cosmic rays but also inflation.",
          "authors": [
            "Kohta Murase",
            "Yuma Narita",
            "Wen Yin"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.15272",
          "title": "Superheavy dark matter from the natural inflation in light of the highest-energy astroparticle events",
          "abstract": "Superheavy dark matter has been attractive as a candidate of particle dark matter. We propose a ``natural\" particle model, in which the dark matter serves as the inflaton in natural inflation, while decaying to high-energy particles at energies of $10^{9}-10^{13} \\, \\text{GeV}$ from the prediction of the inflation. A scalar field responsible for diluting the dark matter abundance revives the natural inflation either with or without the recent data from the Atacama Cosmology Telescope (ACT) and baryon acoustic oscillation results from Dark Energy Spectroscopic Instrument. Since the dark matter must be a spin-zero scalar, we carefully study the galactic dark matter 3-body decay into fermions and two body decays into a gluon pair, and point out relevant multi-messenger bounds that constrain these decay modes. Interestingly, the predicted energy scale may coincide with the AMATERASU event and/or the KM3NeT neutrino event, KM3-230213A. We also point out particle models with dark baryon to further alleviate $\\gamma$-ray bounds. This scenario yields several testable predictions for the UHECR observations, including the highest-energy neutrons that are unaffected by magnetic fields, the tensor-to-scalar ratio, the running of spectral indices, $\\alpha_s\\gtrsim\\mathcal{O}(0.001)$, and the existence of light new colored particles that could be accessible at future collider experiments. Further measurements of high-energy cosmic rays, including their components and detailed directions, may provide insight into not only the origin of the cosmic rays but also inflation.",
          "authors": [
            "Kohta Murase",
            "Yuma Narita",
            "Wen Yin"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.18259",
          "title": "Equation of state and Fermi liquid properties of dense matter based on chiral effective field theory interactions",
          "abstract": "We present results for the equation of state of symmetric nuclear matter and pure neutron matter obtained in many-body-perturbation theory (MBPT) up to third order, based on various chiral two- and three-nucleon interactions used in ab initio calculations of nuclei. We extract equation of state properties, such as the incompressibility and the symmetry energy, and discuss estimates of the theoretical uncertainties due to neglected higher-order contributions in the MBPT expansion as well as the chiral effective field theory expansion. In addition, we discuss the Fermi liquid approach to nuclear matter. We calculate all two- and three-nucleon contributions to the quasiparticle interaction up to second order in MBPT and present results for the Landau parameters, effective mass, and speed of sound for pure neutron matter.",
          "authors": [
            "Faruk Alp",
            "Yannick Dietz",
            "Kai Hebeler",
            "Achim Schwenk"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.18259",
          "title": "Equation of state and Fermi liquid properties of dense matter based on chiral effective field theory interactions",
          "abstract": "We present results for the equation of state of symmetric nuclear matter and pure neutron matter obtained in many-body-perturbation theory (MBPT) up to third order, based on various chiral two- and three-nucleon interactions used in ab initio calculations of nuclei. We extract equation of state properties, such as the incompressibility and the symmetry energy, and discuss estimates of the theoretical uncertainties due to neglected higher-order contributions in the MBPT expansion as well as the chiral effective field theory expansion. In addition, we discuss the Fermi liquid approach to nuclear matter. We calculate all two- and three-nucleon contributions to the quasiparticle interaction up to second order in MBPT and present results for the Landau parameters, effective mass, and speed of sound for pure neutron matter.",
          "authors": [
            "Faruk Alp",
            "Yannick Dietz",
            "Kai Hebeler",
            "Achim Schwenk"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.18259",
          "title": "Equation of state and Fermi liquid properties of dense matter based on chiral effective field theory interactions",
          "abstract": "We present results for the equation of state of symmetric nuclear matter and pure neutron matter obtained in many-body-perturbation theory (MBPT) up to third order, based on various chiral two- and three-nucleon interactions used in ab initio calculations of nuclei. We extract equation of state properties, such as the incompressibility and the symmetry energy, and discuss estimates of the theoretical uncertainties due to neglected higher-order contributions in the MBPT expansion as well as the chiral effective field theory expansion. In addition, we discuss the Fermi liquid approach to nuclear matter. We calculate all two- and three-nucleon contributions to the quasiparticle interaction up to second order in MBPT and present results for the Landau parameters, effective mass, and speed of sound for pure neutron matter.",
          "authors": [
            "Faruk Alp",
            "Yannick Dietz",
            "Kai Hebeler",
            "Achim Schwenk"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.00761",
          "title": "What is a photon in de Sitter spacetime?",
          "abstract": "The states of a single photon in four-dimensional de Sitter (dS) spacetime form a Unitary Irreducible Representation (UIR) of SO(1,4), which we call the photon UIR. While in flat spacetime photons are intimately tied to gauge symmetry, we demonstrate that in de Sitter, photon states emerge generically in any quantum field theory, even without an underlying U(1) gauge field. We derive a Källén-Lehmann representation for antisymmetric tensor two-point functions and show that numerous composite operators constructed from massive free fields can create states in the photon UIR. Remarkably, we find that some of these operators exhibit two-point functions with slower late-time and large-distance decay than the electromagnetic field strength itself, challenging the conventional notion that photons dominate the infrared regime. Using our spectral representation, we establish non-perturbative bounds on the late-time behavior of electric and magnetic fields in de Sitter, with potential implications for primordial magnetogenesis. Through one-loop calculations, we demonstrate that both the creation of photon states and the enhanced late-time large-distance behavior persist in weakly interacting theories.",
          "authors": [
            "Manuel Loparco",
            "Joao Penedones",
            "Yannis Ulrich"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.00761",
          "title": "What is a photon in de Sitter spacetime?",
          "abstract": "The states of a single photon in four-dimensional de Sitter (dS) spacetime form a Unitary Irreducible Representation (UIR) of SO(1,4), which we call the photon UIR. While in flat spacetime photons are intimately tied to gauge symmetry, we demonstrate that in de Sitter, photon states emerge generically in any quantum field theory, even without an underlying U(1) gauge field. We derive a Källén-Lehmann representation for antisymmetric tensor two-point functions and show that numerous composite operators constructed from massive free fields can create states in the photon UIR. Remarkably, we find that some of these operators exhibit two-point functions with slower late-time and large-distance decay than the electromagnetic field strength itself, challenging the conventional notion that photons dominate the infrared regime. Using our spectral representation, we establish non-perturbative bounds on the late-time behavior of electric and magnetic fields in de Sitter, with potential implications for primordial magnetogenesis. Through one-loop calculations, we demonstrate that both the creation of photon states and the enhanced late-time large-distance behavior persist in weakly interacting theories.",
          "authors": [
            "Manuel Loparco",
            "Joao Penedones",
            "Yannis Ulrich"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.00916",
          "title": "Photoproduction and detection of $ρ'\\rightarrowπ^+π^-π^+π^-$ decays in ultra-peripheral collisions and at an electron-ion collider",
          "abstract": "Vector meson photoproduction is an important probe of nuclear structure. Light vector mesons are most sensitive to low$-x$ structure, as long as they are not too light for perturbative QCD calculations. The $\\rho'$ is of interest as an intermediate mass state (between the $\\rho$ and $J/\\psi$) that is easier to detect than the $\\phi$. Using HERA data on proton targets, we make projections for lead/gold targets in UPCs at the Large Hadron Collider and RHIC, and for $ep$ and $eA$ collisions at a future Electron-Ion Collider (EIC). We compare the UPC projections with ALICE data, and constrain the branching ratio divided by the square of the photon-$\\rho'$ coupling. The data prefer large couplings and small branching ratio, probably less than 25\\%. The photon-meson coupling predicted by generalized vector meson dominance does not fit the data. The HERA $ep$ and ALICE UPC $e$Pb data exhibit very similar $4\\pi$ mass spectra, indicating that, if the system is composed of two resonances, the products of their photon couplings with their four-pion branching ratios are similar. The predicted rates are high for both UPCs and the EIC. The $\\rho'\\rightarrow\\pi^+\\pi^-\\pi^+\\pi^-$ decay can be observed at the EIC with high efficiency. In $ep$ collisions at the highest energy, the forward B0 detector is needed to observe this channel down to the lowest achievable Bjorken$-x$ values.",
          "authors": [
            "Neha Devi",
            "Minjung Kim",
            "Spencer R. Klein",
            "Janet Seger"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.00916",
          "title": "Photoproduction and detection of $ρ'\\rightarrowπ^+π^-π^+π^-$ decays in ultra-peripheral collisions and at an electron-ion collider",
          "abstract": "Vector meson photoproduction is an important probe of nuclear structure. Light vector mesons are most sensitive to low$-x$ structure, as long as they are not too light for perturbative QCD calculations. The $\\rho'$ is of interest as an intermediate mass state (between the $\\rho$ and $J/\\psi$) that is easier to detect than the $\\phi$. Using HERA data on proton targets, we make projections for lead/gold targets in UPCs at the Large Hadron Collider and RHIC, and for $ep$ and $eA$ collisions at a future Electron-Ion Collider (EIC). We compare the UPC projections with ALICE data, and constrain the branching ratio divided by the square of the photon-$\\rho'$ coupling. The data prefer large couplings and small branching ratio, probably less than 25\\%. The photon-meson coupling predicted by generalized vector meson dominance does not fit the data. The HERA $ep$ and ALICE UPC $e$Pb data exhibit very similar $4\\pi$ mass spectra, indicating that, if the system is composed of two resonances, the products of their photon couplings with their four-pion branching ratios are similar. The predicted rates are high for both UPCs and the EIC. The $\\rho'\\rightarrow\\pi^+\\pi^-\\pi^+\\pi^-$ decay can be observed at the EIC with high efficiency. In $ep$ collisions at the highest energy, the forward B0 detector is needed to observe this channel down to the lowest achievable Bjorken$-x$ values.",
          "authors": [
            "Neha Devi",
            "Minjung Kim",
            "Spencer R. Klein",
            "Janet Seger"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.01208",
          "title": "Impact of magnetic field gradients on the development of the MRI: Applications to binary neutron star mergers and proto-planetary disks",
          "abstract": "The magneto-rotational instability (MRI) is widely believed to play a central role in generating large-scale, poloidal magnetic fields during binary neutron star mergers. However, the few simulations that begin with a weak seed magnetic field and capture its growth until saturation predominantly show the effects of small-scale turbulence and winding, but lack convincing evidence of MRI activity. In this work, we investigate how the MRI is affected by the complex magnetic field topologies characteristic of the post-merger phase, aiming to assess the actual feasibility of MRI in such environments. We first derive the MRI instability criterion, as well as expressions for the characteristic wavelength and growth timescale of the fastest-growing modes, under conditions that include significant magnetic field gradients. Our analysis reveals that strong radial magnetic field gradients can impact significantly on the MRI, slowing its growth or suppressing it entirely if large enough. We then apply this extended framework to both idealized analytical disk models and data from a numerical relativity simulation of a long-lived neutron star merger remnant. We find that conditions favourable to MRI growth on astrophysically relevant timescales may occur only in limited regions of the post-merger disk, and only at late times $t\\gtrsim 100$ ms after the merger. These results suggest that the MRI plays a limited role in amplifying poloidal magnetic fields in post-merger environments during the first $\\mathcal{O}(100)$ms.",
          "authors": [
            "T. Celora",
            "C. Palenzuela",
            "D. Viganò",
            "R. Aguilera-Miret"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.01208",
          "title": "Impact of magnetic field gradients on the development of the MRI: Applications to binary neutron star mergers and proto-planetary disks",
          "abstract": "The magneto-rotational instability (MRI) is widely believed to play a central role in generating large-scale, poloidal magnetic fields during binary neutron star mergers. However, the few simulations that begin with a weak seed magnetic field and capture its growth until saturation predominantly show the effects of small-scale turbulence and winding, but lack convincing evidence of MRI activity. In this work, we investigate how the MRI is affected by the complex magnetic field topologies characteristic of the post-merger phase, aiming to assess the actual feasibility of MRI in such environments. We first derive the MRI instability criterion, as well as expressions for the characteristic wavelength and growth timescale of the fastest-growing modes, under conditions that include significant magnetic field gradients. Our analysis reveals that strong radial magnetic field gradients can impact significantly on the MRI, slowing its growth or suppressing it entirely if large enough. We then apply this extended framework to both idealized analytical disk models and data from a numerical relativity simulation of a long-lived neutron star merger remnant. We find that conditions favourable to MRI growth on astrophysically relevant timescales may occur only in limited regions of the post-merger disk, and only at late times $t\\gtrsim 100$ ms after the merger. These results suggest that the MRI plays a limited role in amplifying poloidal magnetic fields in post-merger environments during the first $\\mathcal{O}(100)$ms.",
          "authors": [
            "T. Celora",
            "C. Palenzuela",
            "D. Viganò",
            "R. Aguilera-Miret"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.01208",
          "title": "Impact of magnetic field gradients on the development of the MRI: Applications to binary neutron star mergers and proto-planetary disks",
          "abstract": "The magneto-rotational instability (MRI) is widely believed to play a central role in generating large-scale, poloidal magnetic fields during binary neutron star mergers. However, the few simulations that begin with a weak seed magnetic field and capture its growth until saturation predominantly show the effects of small-scale turbulence and winding, but lack convincing evidence of MRI activity. In this work, we investigate how the MRI is affected by the complex magnetic field topologies characteristic of the post-merger phase, aiming to assess the actual feasibility of MRI in such environments. We first derive the MRI instability criterion, as well as expressions for the characteristic wavelength and growth timescale of the fastest-growing modes, under conditions that include significant magnetic field gradients. Our analysis reveals that strong radial magnetic field gradients can impact significantly on the MRI, slowing its growth or suppressing it entirely if large enough. We then apply this extended framework to both idealized analytical disk models and data from a numerical relativity simulation of a long-lived neutron star merger remnant. We find that conditions favourable to MRI growth on astrophysically relevant timescales may occur only in limited regions of the post-merger disk, and only at late times $t\\gtrsim 100$ ms after the merger. These results suggest that the MRI plays a limited role in amplifying poloidal magnetic fields in post-merger environments during the first $\\mathcal{O}(100)$ms.",
          "authors": [
            "T. Celora",
            "C. Palenzuela",
            "D. Viganò",
            "R. Aguilera-Miret"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.03702",
          "title": "Gravitational Collapse: Generalizing Oppenheimer-Snyder and a Conjecture on Horizon Formation Time",
          "abstract": "We generalize the Oppenheimer-Snyder model of gravitational collapse by considering a broader class of static, spherically symmetric exterior spacetimes, with an interior geometry described by a Friedmann-Lemaitre-Robertson-Walker (FLRW) geometry. Using Painleve-Gullstrand (PG) coordinates for the spatially flat interior geometry (k=0) and a Novikov-like coordinate system for the spatially closed geometry (k=1), we ensured a smooth transition between the interior and exterior of the collapsing star. By providing general formulas, we analyzed how apparent and event horizons form during the collapse and checked whether the matter satisfies standard energy conditions. For both k=0 and k=1 cases, we studied explicit examples such as Schwarzschild, Schwarzschild-AdS/dS, and Reissner-Nordstrom (RN) black holes, taking into account the effects of the cosmological constant and electric charge. These factors significantly influence the collapse process and can impose constraints on the physical parameters. Our analysis leads to two important results: First, to form a black hole, there is a minimum or critical initial radius for the star to begin collapsing. Second, we propose a conjecture of an inequality regarding the event horizon formation time, starting from the critical radius, namely Delta T_eh <= 19M/6. The upper bound is saturated by the Schwarzschild black hole.",
          "authors": [
            "H. Khodabakhshi",
            "H. Lu",
            "F. Shojai"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.11204",
          "title": "Gravitational scattering of two neutron stars",
          "abstract": "We present the first numerical relativity simulations of the gravitational scattering of two neutron stars. Constraint-satisfying initial data for two equal-mass nonspinning sequences are constructed at fixed energy and various initial angular momenta (impact parameter) and evolved with Einstein equations through the scattering process. The strong-field scattering dynamics are explored up to scattering angles of $220^\\circ$ and the threshold of dynamical captures. The transition to bound orbits is aided by significant mass ejecta up to baryon mass ${\\sim}0.1M_\\odot$. A quantitative comparison with predictions of the scattering angle from state-of-the-art effective-one-body and post-Minkowskian calculations indicates quantitative agreement for large initial angular momenta although significant discrepancies in the tidal contribution emerge toward the capture threshold. Gravitational waveforms and radiated energy are in qualitative agreement with the analogous black hole problem and state-of-the-art effective-one-body predictions. Toward the capture threshold waveforms from scattering dynamics carry a strong imprint of matter effects, including the stars' $f$-mode excitations during the close encounter. Overall, our simulations open a new avenue to study tidal interactions in the relativistic two-body problem.",
          "authors": [
            "Joan Fontbuté",
            "Sebastiano Bernuzzi",
            "Piero Rettegno",
            "Simone Albanesi",
            "Wolfgang Tichy"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.11204",
          "title": "Gravitational scattering of two neutron stars",
          "abstract": "We present the first numerical relativity simulations of the gravitational scattering of two neutron stars. Constraint-satisfying initial data for two equal-mass nonspinning sequences are constructed at fixed energy and various initial angular momenta (impact parameter) and evolved with Einstein equations through the scattering process. The strong-field scattering dynamics are explored up to scattering angles of $220^\\circ$ and the threshold of dynamical captures. The transition to bound orbits is aided by significant mass ejecta up to baryon mass ${\\sim}0.1M_\\odot$. A quantitative comparison with predictions of the scattering angle from state-of-the-art effective-one-body and post-Minkowskian calculations indicates quantitative agreement for large initial angular momenta although significant discrepancies in the tidal contribution emerge toward the capture threshold. Gravitational waveforms and radiated energy are in qualitative agreement with the analogous black hole problem and state-of-the-art effective-one-body predictions. Toward the capture threshold waveforms from scattering dynamics carry a strong imprint of matter effects, including the stars' $f$-mode excitations during the close encounter. Overall, our simulations open a new avenue to study tidal interactions in the relativistic two-body problem.",
          "authors": [
            "Joan Fontbuté",
            "Sebastiano Bernuzzi",
            "Piero Rettegno",
            "Simone Albanesi",
            "Wolfgang Tichy"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12870",
          "title": "Gravitational wave propagation in generalized hybrid metric-Palatini gravity",
          "abstract": "In this work we analyze the propagation properties of gravitational waves in the hybrid metric-Palatini gravity theory. We introduce the scalar-tensor representation of the theory to make explicit the scalar degrees of freedom of the theory and obtain their equations of motion in a form decoupled from the metric tensor. Then, we introduce linear perturbations for the metric tensor and for the two scalar fields and obtain the propagation equations for these three quantities. We analyzed the theory both at non-linear and at linear level through the Newman-Penrose formalism so to find the polarization states. We show that the tensor modes propagate at the speed of light and feature the usual +- and x-polarization modes also present in General Relativity (GR), plus two additional polarization modes: a longitudinal mode and a breathing mode, described by the same additional degree of freedom. On the other hand, the theory features two additional scalar modes not present in GR. These modes are massive and, thus, propagate with a speed smaller than the speed of light in general. The masses of the scalar modes depend solely on the interaction potential between the two scalar fields in the theory, which suggests that one can always fine-tune the potential to make the scalar modes massless and reduce their propagation speed to the speed of light. Given the possibility of fine-tuning the theory to match the observational predictions of GR and in the absence of any measured deviations, these features potentially render the hybrid metric-Palatini theory unfalsifiable in the context of gravitational wave propagation.",
          "authors": [
            "Cláudio Gomes",
            "João Luís Rosa",
            "Miguel A. S. Pinto"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.14137",
          "title": "Structure and Magnetic Field of the Bright-rimmed Cloud IC 1396E/SFO 38",
          "abstract": "We carried out polarimetric observations of the bright-rimmed cloud IC 1396E/SFO 38 with SCUBA-2/POL-2 to study the effect of ultraviolet (UV) light on its structure and magnetic field. This bright-rimmed cloud appears optically to be one single cloud illuminated by the UV light from the excited star of IC 1396, however our Stokes I image and 13CO(J=3-2) archival data suggest that this cloud is not a simple, single structure, but appears to be composed of two parts on first glance; a head part with wings and a tail, and a north-west extension this http URL molecular clouds are generally filamentary and it seems likely that the initial structures of bright-rimmed clouds are expected to be also generally elongated, we examined the possibility that the structure was created from a single elongated cloud by the UV impact. We compared the cloud structure with a simulation study that investigated the evolution of prolate clouds exposed to the UV radiation from various directions and found that this apparent two-part structure could be reproduced in a situation where a single filamentary cloud is obliquely illuminated by UV light. The magnetic field directions of the cloud are different from the ambient field direction, demonstrating the field reconfiguration. The distortion or pinch of the magnetic field is seen toward the cloud head, where an intermediate-mass star cluster is located, suggesting gravitational contraction. We roughly estimated the magnetic strength and stability in three parts of the cloud and found that the cloud head is most likely to be supercritical.",
          "authors": [
            "Koji Sugitani",
            "Jan G. A. Wouterloot",
            "Harriet Parsons",
            "Sarah Graves",
            "Takayoshi Kusune",
            "Archana Soam"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.20709",
          "title": "Dark Classification Matters: Searching for Primordial Black Holes with LSST",
          "abstract": "We present projected constraints on the abundance of primordial black holes (PBHs) as a constituent of dark matter, based on microlensing observations from the upcoming Legacy Survey of Space and Time (LSST) at the Vera C. Rubin Observatory. We use a catalogue of microlensing light curves simulated with Rubin Observatory's OpSims to demonstrate that competitive constraints crucially rely on minimising the false positive rate (FPR) of the classification algorithm. We propose the Bayesian information criterion and a Boosted Decision Tree as effective discriminators and compare their derived efficiency and FPR to a more standard $\\chi^2$-test.",
          "authors": [
            "Miguel Crispim Romao",
            "Djuna Croon",
            "Benedict Crossey",
            "Daniel Godines"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.20709",
          "title": "Dark Classification Matters: Searching for Primordial Black Holes with LSST",
          "abstract": "We present projected constraints on the abundance of primordial black holes (PBHs) as a constituent of dark matter, based on microlensing observations from the upcoming Legacy Survey of Space and Time (LSST) at the Vera C. Rubin Observatory. We use a catalogue of microlensing light curves simulated with Rubin Observatory's OpSims to demonstrate that competitive constraints crucially rely on minimising the false positive rate (FPR) of the classification algorithm. We propose the Bayesian information criterion and a Boosted Decision Tree as effective discriminators and compare their derived efficiency and FPR to a more standard $\\chi^2$-test.",
          "authors": [
            "Miguel Crispim Romao",
            "Djuna Croon",
            "Benedict Crossey",
            "Daniel Godines"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.20709",
          "title": "Dark Classification Matters: Searching for Primordial Black Holes with LSST",
          "abstract": "We present projected constraints on the abundance of primordial black holes (PBHs) as a constituent of dark matter, based on microlensing observations from the upcoming Legacy Survey of Space and Time (LSST) at the Vera C. Rubin Observatory. We use a catalogue of microlensing light curves simulated with Rubin Observatory's OpSims to demonstrate that competitive constraints crucially rely on minimising the false positive rate (FPR) of the classification algorithm. We propose the Bayesian information criterion and a Boosted Decision Tree as effective discriminators and compare their derived efficiency and FPR to a more standard $\\chi^2$-test.",
          "authors": [
            "Miguel Crispim Romao",
            "Djuna Croon",
            "Benedict Crossey",
            "Daniel Godines"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.20824",
          "title": "Planck Constraints on Axion-Like Particles through Isotropic Cosmic Birefringence",
          "abstract": "We present constraints on isotropic cosmic birefringence induced by axion-like particles (ALPs), derived from the analysis of cosmic microwave background (CMB) polarization measurements obtained with the high-frequency channels of Planck. Recent measurements report a hint of isotropic cosmic birefringence, though its origin remains uncertain. The detailed dynamics of ALPs can leave characteristic imprints on the shape of the $EB$ angular power spectrum, which can be exploited to constrain specific models of cosmic birefringence. We first construct a multi-frequency likelihood that incorporates an intrinsic nonzero $EB$ power spectrum. We also show that the likelihood used in previous studies can be further simplified without loss of generality. Using this framework, we simultaneously constrain the ALP model parameters, the instrumental miscalibration angle, and the amplitudes of the $EB$ power spectrum of a Galactic dust foreground model. We find that, if ALPs are responsible for the observed cosmic birefringence, ALP masses at $\\log_{10}m_{\\phi}[{\\rm eV}]\\simeq-27.8$, $-27.5$, $-27.3$, $-27.2$, $-27.1$, as well as $\\log_{10}m_{\\phi}[{\\rm eV}]\\in[-27.0,-26.5]$, are excluded at more than $2\\,\\sigma$ statistical significance.",
          "authors": [
            "Toshiya Namikawa",
            "Kai Murai",
            "Fumihiro Naokawa"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.21442",
          "title": "Low-metallicity massive single stars with rotation. III. Source of ionization and C-IV emission in I Zw 18",
          "abstract": "Chemically homogeneously evolving stars have been proposed to account for several exotic phenomena, including gravitational-wave emissions and gamma-ray bursts. Here we study whether these stars can explain the metal-poor dwarf galaxy I Zwicky 18. We apply our synthetic spectral models from Paper II to (i) establish a classification sequence for these hot stars, (ii) predict the photonionizing flux and the strength of emission lines from a IZw18-like stellar population, and (iii) compare our predictions to available observations of this galaxy. Adding two new models computed with PoWR, we report (i) these stars to follow a unique sequence of classes: O->WN->WO (i.e. without ever being WC). From our population synthesis with standard assumptions, we predict that (ii) the source of the UV C-IV and other emission bumps is a couple dozen WO-type Wolf-Rayet stars (not WC as previously assumed) which are the result of chem. hom. evolution, while these, combined with the rest of the O-star population, account for the He-II ionizing flux and spectral hardness. Contrasting our results against published optical and UV data and accounting for different aperture sizes and spatial regions probed by the observations, we find that (iii) our models are highly consistent with them. Since our \"massive Pop II stars\" might just as well exist in early star-forming regions, our findings have implications for upcoming JWST surveys; and given that our results apply for binary populations too as long as the same fraction (10%) of the systems evolves chem. homogeneously, we conclude that the stellar progenitors of gravitational waves may very well exist today in IZw18.",
          "authors": [
            "Dorottya Szécsi",
            "Frank Tramper",
            "Brankica Kubátová",
            "Carolina Kehrig",
            "Jiří Kubát",
            "Jiří Krtička",
            "Andreas A.C. Sander",
            "Miriam Garcia"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.22248",
          "title": "Phase transitions and gravitational waves in a non-abelian vector dark matter scenario",
          "abstract": "We study a scenario where the Standard Model is extended by a SU(2) gauge group in the dark sector. The three associated dark gauge bosons are stabilised via a custodial symmetry triggered by an additional dark SU(2) scalar doublet, thus making them viable dark-matter candidates. After considering the most recent constraints for this model, we analyse the phase transition dynamics and compute the power spectrum of resulting stochastic gravitational-wave background. Finally, we find regions of the parameter space yielding the observed dark-matter relic density while also leading to strong enough phase transition with an associated gravitational-wave signal reaching the sensitivity of future space-based gravitational-wave detector, such as LISA, DECIGO, BBO, TianQin or Taiji.",
          "authors": [
            "Nico Benincasa",
            "Luigi Delle Rose",
            "Luca Panizzi",
            "Maimoona Razzaq",
            "Savio Urzetta"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.22540",
          "title": "A systematic search for dormant galaxies at z~5-7 from the JWST NIRSpec archive",
          "abstract": "JWST has revealed a population of ``dormant'' galaxies at $z>5$ that have recently halted their star formation and are characterized by weak emission lines and significant Balmer breaks. Until now, only four such galaxies have been reported at $z>5$, three with low stellar masses, $M_*<10^9M_\\odot$ (so-called mini-quenched galaxies), and one massive quiescent galaxy with $M_*=10^{10.2}M_\\odot$; no such galaxy had been reported at intermediate masses. Here, we present a systematic search for dormant galaxies at $5<z<7.4$ that halted star formation at least 10 Myr before the time of observation. To do this, we made use of all the publicly available NIRSpec prism data in the DAWN JWST Archive (DJA) and selected galaxies with low H$\\alpha$ equivalent widths ($EW_{0}<50$Å) and strong Balmer breaks ($F_{\\nu,4200}/F_{\\nu,3500}>1.4$). We find 14 dormant galaxies with stellar masses ranging from $10^{7.6}-10^{10.5}$, revealing an intermediate-mass population. By construction, these 14 sources are located about 1 dex below the star-forming main sequence. Their star formation histories suggest that they halted star formation between 10 and 25 Myr before the time of observation which, according to models, is comparable with the timescales of internally regulated bursts driving a ``breathing'' mode of star formation. Our results show that $\\sim1\\%$ of the galaxies in the DJA are in a dormant phase of their star formation histories, and they span a wide stellar mass range. These galaxies can be empirically selected using only their spectral features in NIRSpec prism data.",
          "authors": [
            "Alba Covelo-Paz",
            "Corentin Meuwly",
            "Pascal A. Oesch",
            "Callum Witten",
            "Andrea Weibel",
            "Cristian Carvajal-Bohorquez",
            "Laure Ciesla",
            "Emma Giovinazzo",
            "Gabriel Brammer"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.03118",
          "title": "Testing Photometric Techniques for Measuring the Rest-Frame UV Spectral Slope Against JWST PRISM Spectroscopy",
          "abstract": "We present a sample of 53 galaxy spectra at z_spec ~ 5-12 from the JWST CEERS and RUBIES surveys, combining NIRSpec PRISM spectroscopy with NIRCam photometry. We aim to use these data to establish best practices for measuring the UV spectral slope ($\\beta$) in the era of JWST. We adopt power-law fits to the rest-frame UV continuum from the spectroscopic data as our fiducial, or `true', $\\beta$ values, and compare them to photometric estimates derived through four methods: (1) photometric power-law fitting, (2) power-law fitting to an SED model fitted to the photometry, (3) single-color fitting near the Lyman break, and (4) single-color fitting at fixed rest-frame wavelengths. We find that photometric power-law fitting most closely recovers the spectroscopic slopes, with minimal bias and scatter. SED fitting performs moderately well, and can be preferable in cases of low signal-to-noise where photometric power-law fitting may become unreliable. Single-color estimates, while commonly used in past studies, show the most significant deviations and are not recommended when more than a single color is available. Our results highlight the limitations and strengths of each approach and provide practical guidance for measuring $\\beta$ from photometry when spectra are unavailable or are of insufficient quality.",
          "authors": [
            "Alexa M. Morales",
            "Steven L. Finkelstein",
            "Pablo Arrabal Haro",
            "Micaela B. Bagley",
            "Antonello Calabrò",
            "Óscar A. Chávez Ortiz",
            "Kelcey Davis",
            "Mark Dickinson",
            "Eric Gawiser",
            "Mauro Giavalisco",
            "Nimish P. Hathi",
            "Michaela Hirschmann",
            "Jeyhan S. Kartaltepe",
            "Anton M. Koekemoer",
            "Arianna S. Long",
            "Ray A. Lucas",
            "Fabio Pacucci",
            "Casey Papovich",
            "Borja Pautasso",
            "Nor Pirzkal",
            "Anthony J. Taylor",
            "Alexander de la Vega",
            "Stephen M. Wilkins",
            "L. Y. Aaron Yung"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06299",
          "title": "Deep Learning Improves Photometric Redshifts in All Regions of Color Space",
          "abstract": "Photometric redshifts (photo-$z$'s) are crucial for the cosmology, galaxy evolution, and transient science drivers of next-generation imaging facilities like the Euclid Mission, the Rubin Observatory, and the Nancy Grace Roman Space Telescope. Previous work has shown that image-based deep learning photo-$z$ methods produce smaller scatter than photometry-based classical machine learning (ML) methods on the Sloan Digital Sky Survey (SDSS) Main Galaxy Sample, a testbed photo-$z$ dataset. However, global assessments can obscure local trends. To explore this possibility, we used a self-organizing map (SOM) to cluster SDSS galaxies based on their $ugriz$ colors. Deep learning methods achieve lower photo-$z$ scatter than classical ML methods for all SOM cells. The fractional reduction in scatter is roughly constant across most of color space with the exception of the most bulge-dominated and reddest cells where it is smaller in magnitude. Interestingly, classical ML photo-$z$'s suffer from a significant color-dependent attenuation bias, where photo-$z$'s for galaxies within a SOM cell are systematically biased towards the cell's mean spectroscopic redshift and away from extreme values, which is not readily apparent when all objects are considered. In contrast, deep learning photo-$z$'s suffer from very little color-dependent attenuation bias. The increased attenuation bias for classical ML photo-$z$ methods is the primary reason why they exhibit larger scatter than deep learning methods. This difference can be explained by the deep learning methods weighting redshift information from the individual pixels of a galaxy image more optimally than integrated photometry.",
          "authors": [
            "Emma R. Moran",
            "Brett H. Andrews",
            "Jeffrey A. Newman",
            "Biprateep Dey"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.10631",
          "title": "Large scale structure constraints and matter power spectrum in $f (Q,\\mathcal{L}_{m})$ gravity",
          "abstract": "In the present work, we take into account the dynamical system analysis to investigate the matter power spectrum within the framework of the $f(Q,\\mathcal{L}_{m})$ gravitational theory. After obtaining autonomous dynamical system variables for two different particular pedagogical choices of $f(Q,\\mathcal{L}_{m})$ models (A and B), we derive the full system of perturbation equations using the $1+3$ covariant formalism to study the matter fluctuations. We present and solve the energy density perturbation equations to obtain the energy density contrast, which decays with redshift for both models for a particular choice of model parameters. After obtaining the numerical results of the density contrast, we computed the matter spectra for each model and conducted a comparative analysis with the $\\Lambda$CDM. Furthermore, by employing the Markov Chain Monte Carlo (MCMC) analysis,the model parameters were constrained using a combination of different observational data sets to improve the robustness and accuracy of the parameter estimation. Our results indicate that only model A can be compatible with the considered observational data sets.",
          "authors": [
            "Praveen Kumar Dhankar",
            "Albert Munyeshyaka",
            "Saddam Hussain",
            "Tom Mutabazi"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.11451",
          "title": "Nuclear modification factor within a dynamical approach to the complex entropic index",
          "abstract": "This work introduces a novel approach to the nuclear deformation factor $R_{\\text{AA}}$, grounded in the dynamical effects of the Quark-Gluon Plasma on parton momentum. The approach uses the Blast-Wave method combined with Tsallis Statistics, within the Cooper-Frye freeze-out framework and, by profiting from appropriate simplifications, it gives analytical expressions that describe the observed $R_{\\text{AA}}$ for two sets of independent measurements at $\\sqrt{s}=2.76$ TeV and $\\sqrt{s}=5.02$ TeV. A nonlinear dynamical equation describes the dynamics and leads to log-periodic oscillations. With the analytical solutions for that equation, it is possible to link the dynamical approach with the complex-$q$ formalism, which was proposed to describe the log-oscillations observed in experimental data.",
          "authors": [
            "R. Baptista",
            "L. Q. Rocha",
            "J. M. C. Pareja",
            "T. Bhattacharyya",
            "A. Deppman",
            "E. Megias",
            "M. Rybczynski",
            "G. Wilk",
            "Z. Wlodarczyk"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.11451",
          "title": "Nuclear modification factor within a dynamical approach to the complex entropic index",
          "abstract": "This work introduces a novel approach to the nuclear deformation factor $R_{\\text{AA}}$, grounded in the dynamical effects of the Quark-Gluon Plasma on parton momentum. The approach uses the Blast-Wave method combined with Tsallis Statistics, within the Cooper-Frye freeze-out framework and, by profiting from appropriate simplifications, it gives analytical expressions that describe the observed $R_{\\text{AA}}$ for two sets of independent measurements at $\\sqrt{s}=2.76$ TeV and $\\sqrt{s}=5.02$ TeV. A nonlinear dynamical equation describes the dynamics and leads to log-periodic oscillations. With the analytical solutions for that equation, it is possible to link the dynamical approach with the complex-$q$ formalism, which was proposed to describe the log-oscillations observed in experimental data.",
          "authors": [
            "R. Baptista",
            "L. Q. Rocha",
            "J. M. C. Pareja",
            "T. Bhattacharyya",
            "A. Deppman",
            "E. Megias",
            "M. Rybczynski",
            "G. Wilk",
            "Z. Wlodarczyk"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.19450",
          "title": "Dark energy constraints in light of theoretical priors",
          "abstract": "In order to derive model-independent observational bounds on dark energy/modified gravity theories, a typical approach is to constrain parametrised models intended to capture the space of dark energy theories. Here we investigate in detail the effect that the nature of these parametrisations can have, finding significant effects on the resulting cosmological dark energy constraints. In order to observationally distinguish well-motivated and physical parametrisations from unphysical ones, it is crucial to understand the theoretical priors that physical parametrisations place on the phenomenology of dark energy. To this end we discuss a range of theoretical priors that can be imposed on general dark energy parametrisations, and their effect on the constraints on the phenomenology of dynamical dark energy. More specifically, we investigate both the phenomenological $\\{\\mu,\\Sigma\\}$ parametrisation as well as effective field theory (EFT) inspired approaches to model dark energy interactions. We compare the constraints obtained in both approaches for different phenomenological and theory-informed time-dependences for the underlying functional degrees of freedom, discuss the effects of priors derived from gravitational wave physics, and investigate the interplay between constraints on parameters constraining only the background evolution vs. parameters controlling linear perturbations.",
          "authors": [
            "Neel Shah",
            "Kazuya Koyama",
            "Johannes Noller"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.19450",
          "title": "Dark energy constraints in light of theoretical priors",
          "abstract": "In order to derive model-independent observational bounds on dark energy/modified gravity theories, a typical approach is to constrain parametrised models intended to capture the space of dark energy theories. Here we investigate in detail the effect that the nature of these parametrisations can have, finding significant effects on the resulting cosmological dark energy constraints. In order to observationally distinguish well-motivated and physical parametrisations from unphysical ones, it is crucial to understand the theoretical priors that physical parametrisations place on the phenomenology of dark energy. To this end we discuss a range of theoretical priors that can be imposed on general dark energy parametrisations, and their effect on the constraints on the phenomenology of dynamical dark energy. More specifically, we investigate both the phenomenological $\\{\\mu,\\Sigma\\}$ parametrisation as well as effective field theory (EFT) inspired approaches to model dark energy interactions. We compare the constraints obtained in both approaches for different phenomenological and theory-informed time-dependences for the underlying functional degrees of freedom, discuss the effects of priors derived from gravitational wave physics, and investigate the interplay between constraints on parameters constraining only the background evolution vs. parameters controlling linear perturbations.",
          "authors": [
            "Neel Shah",
            "Kazuya Koyama",
            "Johannes Noller"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.19450",
          "title": "Dark energy constraints in light of theoretical priors",
          "abstract": "In order to derive model-independent observational bounds on dark energy/modified gravity theories, a typical approach is to constrain parametrised models intended to capture the space of dark energy theories. Here we investigate in detail the effect that the nature of these parametrisations can have, finding significant effects on the resulting cosmological dark energy constraints. In order to observationally distinguish well-motivated and physical parametrisations from unphysical ones, it is crucial to understand the theoretical priors that physical parametrisations place on the phenomenology of dark energy. To this end we discuss a range of theoretical priors that can be imposed on general dark energy parametrisations, and their effect on the constraints on the phenomenology of dynamical dark energy. More specifically, we investigate both the phenomenological $\\{\\mu,\\Sigma\\}$ parametrisation as well as effective field theory (EFT) inspired approaches to model dark energy interactions. We compare the constraints obtained in both approaches for different phenomenological and theory-informed time-dependences for the underlying functional degrees of freedom, discuss the effects of priors derived from gravitational wave physics, and investigate the interplay between constraints on parameters constraining only the background evolution vs. parameters controlling linear perturbations.",
          "authors": [
            "Neel Shah",
            "Kazuya Koyama",
            "Johannes Noller"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.23187",
          "title": "The Fate of Transonic Shocks around Black Holes and their Future Astrophysical Implications",
          "abstract": "Theoretical models have long predicted the existence of shocks in multi-transonic accretion flows onto a black hole, yet their fate under realistic general relativistic simulations has not been fully tested. In this study, we present results from high-resolution two-dimensional general relativistic hydrodynamic (GRHD) and general relativistic magnetohydrodynamic (GRMHD) simulations of low-angular-momentum accretion flows onto Kerr black holes, focusing on the formation of shocks in transonic accretion flow. We demonstrate that for specific combinations of energy and angular momentum, global shock solutions naturally emerge between multiple sonic points. These shocks are sustained in both corotating and counter-rotating cases, and their locations depend on specific energy, angular momentum, and the spin of the black hole which is in good agreement with analytical solutions. In magnetized flows, weak magnetic fields preserve the shock structure, whereas strong fields suppress it, enhancing turbulence and driving powerful, magnetically dominated jets/outflows. The strength and structure of the outflow also depend on a black hole spin and magnetization, with higher black hole spin parameters leading to faster jets. Shock solutions are found only in super-Alfvénic regions, where kinetic forces dominate. Our findings provide important insights into the physics of hot corona formation and jet launching in low-angular-momentum accretion systems such as Sgr~A$^*$ (weak jet/outflow) and X-ray binaries.",
          "authors": [
            "Indu K. Dihingia",
            "Akhil Uniyal",
            "Yosuke Mizuno"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.04589",
          "title": "Perturbations of Black Holes in Einstein-Maxwell-Dilaton-Axion (EMDA) Theories",
          "abstract": "We extend our earlier work on the linearised perturbations of static black holes in Einstein-Maxwell-Dilaton (EMD) theories to the case where the black holes are solutions in an enlarged theory including also an axion. We study the perturbations in a 3-parameter family of such EMDA theories. The systems of equations describing the linearised perturbations can always be separated, but they can only be decoupled when the three parameters are restricted to a 1-parameter family of EMDA theories, characterised by a parameter $b$ that determines the coupling of the axion to the $\\epsilon^{\\mu\\nu\\rho\\sigma}\\, F_{\\mu\\nu}\\, F_{\\rho\\sigma}$ term. In the specific case when $b=1$, the theory is related to an ${\\cal N}=2$ supergravity. In this one case we find that the perturbations in the axial and the polar sectors are related by a remarkable transformation, which generalises one found by Chandrasekhar for the perturbations of Reissner-Nordström in Einstein-Maxwell theory. This transformation is of a form found in supersymmetric quantum mechanical models. The existence of such mappings between the axial and polar perturbations appears to correlate with those cases where there is an underlying supergravity supporting the solution, even though the black hole backgrounds are non-extremal and therefore not supersymmetric. We prove the mode stability of the static black hole solutions in the supersymmetric EMDA theory. For other values of the parameter $b$ in the EMDA theories that allow decoupling of the modes, we find that one of the radial potentials can be negative outside the horizon if $b$ is sufficiently large, raising the possibility of there being perturbative mode instabilities in such a case.",
          "authors": [
            "C.N. Pope",
            "D.O. Rohrer",
            "B.F. Whiting"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.04589",
          "title": "Perturbations of Black Holes in Einstein-Maxwell-Dilaton-Axion (EMDA) Theories",
          "abstract": "We extend our earlier work on the linearised perturbations of static black holes in Einstein-Maxwell-Dilaton (EMD) theories to the case where the black holes are solutions in an enlarged theory including also an axion. We study the perturbations in a 3-parameter family of such EMDA theories. The systems of equations describing the linearised perturbations can always be separated, but they can only be decoupled when the three parameters are restricted to a 1-parameter family of EMDA theories, characterised by a parameter $b$ that determines the coupling of the axion to the $\\epsilon^{\\mu\\nu\\rho\\sigma}\\, F_{\\mu\\nu}\\, F_{\\rho\\sigma}$ term. In the specific case when $b=1$, the theory is related to an ${\\cal N}=2$ supergravity. In this one case we find that the perturbations in the axial and the polar sectors are related by a remarkable transformation, which generalises one found by Chandrasekhar for the perturbations of Reissner-Nordström in Einstein-Maxwell theory. This transformation is of a form found in supersymmetric quantum mechanical models. The existence of such mappings between the axial and polar perturbations appears to correlate with those cases where there is an underlying supergravity supporting the solution, even though the black hole backgrounds are non-extremal and therefore not supersymmetric. We prove the mode stability of the static black hole solutions in the supersymmetric EMDA theory. For other values of the parameter $b$ in the EMDA theories that allow decoupling of the modes, we find that one of the radial potentials can be negative outside the horizon if $b$ is sufficiently large, raising the possibility of there being perturbative mode instabilities in such a case.",
          "authors": [
            "C.N. Pope",
            "D.O. Rohrer",
            "B.F. Whiting"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.05335",
          "title": "Spatially resolved gas-phase metallicity at z~2-3 with JWST/NIRISS",
          "abstract": "Spatially resolved gas-phase metallicity maps are a crucial element in understanding the chemical evolution of galaxies. We present spatially resolved metallicity maps obtained from NIRISS/WFSS observations. This is the first such work presenting multiple individual galaxies. We investigate the source of ionisation, metallicity and its relation to star-formation in a spatially-resolved sense for a sample of eight galaxies -- four from JWST-PASSAGE and four from GLASS-JWST ERS. All but one galaxy are in the redshift range $1.9 \\leq z \\leq 2$, the outlier being at $z = 3.1$. Our sample covers a range of $8.0 <$ \\logM $< 9.5$ in stellar mass, $0.2 <$ $\\log{\\rm{(SFR}}$/\\Msunpyr) $< 1.1$ in star-formation rate (SFR) and $7.8 <$ \\logOH $< 9.0$ in global metallicity. As a solution to the challenge of SF-AGN demarcation in absence of resolved \\halpha, we present a new SF-demarcation line in the \\textit{OHNO} parameter space based on MAPPINGS v5.1 publicly available \\hii region model grids. We present the mass-metallicity gradient relation for our sample, which showed no clear trend with stellar mass, perhaps hinting at the fact that the high-$z$ galaxies have not yet started their accretion dominated phase. By interpreting the correlation between spatially resolved metallicity and SFR maps as a proxy for effective timescales of metal-transport in galaxies, we find a weak trend such that this timescale increases with stellar mass, implying a more effective feedback in lower mass galaxies.",
          "authors": [
            "Ayan Acharyya",
            "Peter J. Watson",
            "Benedetta Vulcani",
            "Tommaso Treu",
            "Kalina V. Nedkova",
            "Andrew J. Bunker",
            "Vihang Mehta",
            "Hakim Atek",
            "Andrew J. Battisti",
            "Farhanul Hasan",
            "Matthew J. Hayes",
            "Mason Huberty",
            "Tucker Jones",
            "Nicha Leethochawalit",
            "Yu-Heng Lin",
            "Matthew A. Malkan",
            "Benjamin Metha",
            "Themiya Nanayakkara",
            "Marc Rafelski",
            "Zahra Sattari",
            "Claudia Scarlata",
            "Xin Wang",
            "Caitlin M. Casey",
            "Andrea Grazian",
            "Anton M. Koekemoer",
            "Mario Radovich",
            "Giulia Rodighiero"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09578",
          "title": "The virtual contributions from $K^*$ in the $B \\to K^*πh$ and $B \\to Kρh$ decays",
          "abstract": "Inspired by the significant virtual contributions of the subprocesses $D^{*}/B^{*}\\to D\\pi$ and $ \\rho\\to\\omega \\pi/K\\bar{K}$ in the three-body hadronic $B$ meson decays, we study the off-shell effects of the resonance $K^*$ decaying into the $K^*\\pi$ or $K\\rho$ system in the decays $B \\to K^*\\pi h$ and $B \\to K\\rho h$ (with $h=\\pi, K$) within the perturbative QCD approach. The strong coupling constants $g_{K^*K^*\\pi}$ and $g_{K^*K\\rho}$ involved in this work are derived from the coupling constant $g_{\\rho\\omega\\pi}$ under the flavor SU$(3)$ symmetry. The $CP$ averaged branching fractions for the quasi-two-body decays $B\\to K^*[\\to K^*\\pi] h$ and $B\\to K^*[\\to K\\rho] h$ are predicted to be on the order of $10^{-9}$ to $10^{-7}$ in this study. And the branching fractions for the decays $B\\to K^*[\\to K\\rho] h$ are found to be around half of the corresponding results for the $B\\to K^*[\\to K^*\\pi] h$ channels, mainly due to the phase space difference between the $K\\rho$ and $K^*\\pi$ pairs originating from the intermediate state $K^*$. Experimental data for the $K^*$ decaying into the final states $K^*\\pi$ and $K\\rho$ in the $B$ meson decays is expected to be obtained by the LHCb and Belle-II experiments in the near future.",
          "authors": [
            "Ai-Jun Ma",
            "Wen-Fei Wang"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.14850",
          "title": "Eccentricity evolution consistency test to distinguish eccentric gravitational-wave signals from eccentricity mimickers",
          "abstract": "Eccentric compact binary coalescences (CBCs) are expected to be observed in current and future gravitational-wave (GW) detector networks. However, it has been recently pointed out that a number of other physical and beyond-GR effects, could imitate, or be mimicked by, eccentric CBCs. In this work, we propose a conceptually simple but powerful method to directly confirm or reject the eccentric hypothesis, without needing to compare the hypothesis with the plethora of other possible hypotheses. The key idea is that while spurious non-zero values of eccentricity, at some reference frequency, could be acquired when a non-eccentric CBC with additional physical/beyond-GR effects is recovered with an eccentric CBC waveform model, the {\\itshape evolution} of eccentricity with frequency will in general not be mimicked. We accordingly formulate an eccentricity evolution consistency test (EECT). The method compares the eccentricity recovered at some low frequency value (e.g, $10$ Hz), evolved to higher frequencies assuming GR, with eccentricities recovered at those same higher frequencies. Discrepancy between the two eccentricities at any reference frequency would violate EECT and indicate the presence of a mimicker. As a proof of concept, assuming a few eccentric CBC systems, quasi-circular CBCs with additional physics mimicking eccentricity, and an O4-like three-detector-network configuration, we demonstrate that our proposed method is indeed able to reject mimickers at $\\geq 68\\%$ confidence, while ensuring that truly eccentric CBCs satisfy EECT.",
          "authors": [
            "Sajad A. Bhat",
            "Avinash Tiwari",
            "Md Arif Shaikh",
            "Shasvath J. Kapadia"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.14850",
          "title": "Eccentricity evolution consistency test to distinguish eccentric gravitational-wave signals from eccentricity mimickers",
          "abstract": "Eccentric compact binary coalescences (CBCs) are expected to be observed in current and future gravitational-wave (GW) detector networks. However, it has been recently pointed out that a number of other physical and beyond-GR effects, could imitate, or be mimicked by, eccentric CBCs. In this work, we propose a conceptually simple but powerful method to directly confirm or reject the eccentric hypothesis, without needing to compare the hypothesis with the plethora of other possible hypotheses. The key idea is that while spurious non-zero values of eccentricity, at some reference frequency, could be acquired when a non-eccentric CBC with additional physical/beyond-GR effects is recovered with an eccentric CBC waveform model, the {\\itshape evolution} of eccentricity with frequency will in general not be mimicked. We accordingly formulate an eccentricity evolution consistency test (EECT). The method compares the eccentricity recovered at some low frequency value (e.g, $10$ Hz), evolved to higher frequencies assuming GR, with eccentricities recovered at those same higher frequencies. Discrepancy between the two eccentricities at any reference frequency would violate EECT and indicate the presence of a mimicker. As a proof of concept, assuming a few eccentric CBC systems, quasi-circular CBCs with additional physics mimicking eccentricity, and an O4-like three-detector-network configuration, we demonstrate that our proposed method is indeed able to reject mimickers at $\\geq 68\\%$ confidence, while ensuring that truly eccentric CBCs satisfy EECT.",
          "authors": [
            "Sajad A. Bhat",
            "Avinash Tiwari",
            "Md Arif Shaikh",
            "Shasvath J. Kapadia"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.17508",
          "title": "XMAGNET : Kinetic, Thermal and Magnetic AGN Feedback in Massive Galaxies at Halo Masses $\\sim 10^{13.5}$ M$_\\odot$",
          "abstract": "The interplay between radiative cooling of the circumgalactic medium (CGM) and feedback heating governs the evolution of the universe's most massive galaxies. This paper presents simulations of feedback processes in massive galaxies showing how kinetic, thermal, and magnetic active galactic nuclei (AGN) feedback interacts with the CGM under different environmental conditions. We find that in massive galaxies with shallower central gravitational potential and higher CGM pressure (multiphase galaxy; MPG) pure kinetic AGN feedback is most efficient in preventing CGM cooling from becoming catastrophic while maintaining the CGM entropy within the observed range. For the same galaxy, partitioning AGN energy injection into kinetic ($75\\%$) and thermal ($25\\%$) energy results in an entropy bump within $r\\lesssim15$ kpc while also having a larger amount of cold gas extending out to $r\\sim80$ kpc. A magnetohydrodynamic MPG run with seed magnetic field in the CGM (1~$\\mu$G) and partial magnetised AGN feedback ($1\\%$ of total AGN power) also shows a higher entropy (within $r<15$ kpc) and cold gas mass, albeit the cold gas remains constrained within $r\\lesssim30$ kpc. For a similarly massive galaxy with deeper potential well and low CGM pressure (single phase galaxy; SPG) our simulations show that for both hydro and MHD runs with partial thermal AGN energy, the feedback mechanism remains tightly self-regulating with centrally concentrated cooling (within $r<1$ kpc). Our simulations of a similar mass galaxy with a deeper potential well and higher CGM pressure (SPG-Cool) show that our AGN feedback mechanism cannot get rid of the high CGM density and pressure and its long term evolution is similar to the multiphase galaxy.",
          "authors": [
            "Deovrat Prasad",
            "Philipp Grete",
            "Brian O'Shea",
            "Forrest Glines",
            "Mark Voit",
            "Freeke van de Voort",
            "Martin Fournier",
            "Benjamin Wibking"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.19860",
          "title": "HD 44892: The youngest (or oldest?) gas-harbouring debris disc around an intermediate mass star",
          "abstract": "We present the first detections of gas around a 2.1 Myr old debris disc-bearing intermediate-mass star, HD 44892. Gas is detected both in $^{12}$CO (2-1) emission through ALMA Band 6 observations and in absorption in Ca II K and H, seen with high-resolution UVES spectroscopy. $^{13}$CO and C$^{18}$O (2-1) are not detected. The star exhibits a 12 $\\mu$m fractional excess of $7.86^{+0.11}_{-2.27}$, placing it in the transition stage between protoplanetary and debris discs. Our detection of 1.3 mm emission yields the dust mass of 0.019$\\pm$0.009 $M_{\\oplus}$ assuming 115 K temperature. The $^{13}$CO non-detection places an upper limit on CO gas mass of $\\sim$10$^{-2}$ $M_{\\oplus}$. The $^{12}$CO detection yields a CO gas mass of (7.86$\\pm$2.05)$\\times$10$^{-5}$ $M_{\\oplus}$ or (1.62$\\pm$0.17)$\\times$10$^{-4}$ $M_{\\oplus}$ assuming a gas temperature of 20 K or 50 K, respectively. These should be considered as lower limits since $^{12}$CO emission may be optically thick. With UVES, we find variability in Ca II K and H lines, which can be interpreted by transiting circumstellar gas, ruling out interstellar absorption as their origin. Both the dust mass, which is within an order of magnitude of HD 141569, and the gas mass derived here indicate a late gas dispersal stage of the protoplanetary disc. Through our analysis we deem the alternative age of 800 Myr unlikely.",
          "authors": [
            "Karolina M. Szewczyk",
            "Olja Panić",
            "Daniela P. Iglesias",
            "Tim D. Pearce",
            "James M. Miley"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.05057",
          "title": "Radiation damage to the Hubble Space Telescope during two Solar cycles, and correction of Charge Transfer Inefficiency using ArCTIc",
          "abstract": "From 2002 to 2025, the Hubble Space Telescope's Advanced Camera for Surveys has suffered in the harsh radiation environment above the protection of the Earth's atmosphere. We track the degradation of its image quality, as Solar protons and galactic cosmic rays have damaged its photosensitive charge-coupled device (CCD) imaging sensors. The rate of damage in low Earth orbit is modulated by $18.5^{+4.5}_{-0.5}$ per cent during an 11 year Solar cycle, peaking $430^{+11}_{-5}$ days after Solar minimum as recorded in the number of sunspots. The type of damage is consistent with defects in the silicon lattice that have all stabilised into one of three configurations. We also present the open-source Algorithm for Charge Transfer Inefficiency correction (ArCTIc) v7. This models the (instantaneous or gradual) capture of photoelectrons into lattice defects, and their release after (a discrete set or continuum of) characteristic time delays, which creates spurious trailing in an image. Calibrated using the trailing of hot pixels, and applied during post-processing of astronomical images, ArCTIc can correct 99.5% of Charge Transfer Inefficiency trailing averaged over the camera's lifetime, and 99.9% of trailing in the worst-affected recent data.",
          "authors": [
            "Richard Massey",
            "Jacob A. Kegerreis",
            "Juan Paolo Lorenzo Gerardo Barrios",
            "James W. Nightingale",
            "Richard G. Hayes",
            "David Lagattuta",
            "Zane D. Lentz",
            "Gavin Leroy",
            "Jesper Skottfelt",
            "Felix Vecchi",
            "Maximilian von Wietersheim-Kramsta"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.05416",
          "title": "Macromodel-free flux-ratio prediction in quadruply imaged quasars with local constraints from lensed arcs",
          "abstract": "Strong gravitational lensing is a powerful cosmological probe, providing a direct tool to unveil the properties of dark matter (DM) on sub-galactic scales. In particular, flux-ratio anomalies in quadruply imaged quasars (\"quads\") can reveal the presence of dark substructure, such that population-level statistics can be used to constrain the particle nature of DM. Current methods, however, rely on globally parametrized models (\"macromodels\") of the lens mass distribution, which impose rigid physical assumptions on the deflection field. Given the high stakes, it is important to develop complementary methods that do not require the assumption of a macromodel. One promising avenue consists of modeling the resolved emission from the quasar host galaxy (lensed arcs) using a local lensing formalism like the Curved Arc Basis (CAB) description. In this paper, we test the ability of CAB models to predict flux ratios from mock imaging data. We find that CAB model-predicted flux ratios accurately reproduce the expected values, with a typical precision of $\\sim 3-5\\%$. While a macromodel-based approach yields smaller uncertainties, as expected, the CAB method permits a more flexible, local description of the deflection field, thus being more robust to angular structure in the main deflector mass profile, in particular avoiding false-positive detections of flux-ratio anomalies that can arise with overly simplistic parametrizations. On the other hand, by injecting individual DM halos near quasar images, we demonstrate that CAB models do not absorb the local lensing perturbations from DM substructure, and can therefore distinguish flux-ratio anomalies caused by DM substructure from other sources of small-scale perturbation. We conclude that CAB models can be used to infer DM properties from flux-ratio anomaly statistics with minimal assumptions, complementing the traditional macromodel based approach.",
          "authors": [
            "Hadrien Paugnat",
            "Tommaso Treu",
            "Daniel Gilman"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.07060",
          "title": "LIMFAST. IV. Learning High-Redshift Galaxy Formation from Multiline Intensity Mapping with Implicit Likelihood Inference",
          "abstract": "By opening up new avenues to statistically constrain astrophysics and cosmology with large-scale structure observations, the line intensity mapping (LIM) technique calls for novel tools for efficient forward modeling and inference. Implicit likelihood inference (ILI) from semi-numerical simulations provides a powerful setup for investigating a large model parameter space in a data-driven manner, therefore gaining significant recent attention. Using simulations of high-redshift 158$\\mu$m [CII] and 88$\\mu$m [OIII] LIM signals created by the LIMFAST code, we develop an ILI framework in a case study of learning the physics of early galaxy formation from the auto-power spectra of these lines or their cross-correlation with galaxy surveys. We leverage neural density estimation with normalizing flows to learn the mapping between the simulated power spectra and parameters that characterize the physics governing the star formation efficiency and the $\\dot{\\Sigma}_{\\star}$-$\\Sigma_\\mathrm{g}$ relation of high-redshift galaxies. Our results show that their partially degenerate effects can be unambiguously constrained when combining [CII] with [OIII] measurements to be made by new-generation mm/sub-mm LIM experiments.",
          "authors": [
            "Guochao Sun",
            "Tri Nguyen",
            "Claude-André Faucher-Giguère",
            "Adam Lidz",
            "Tjitske Starkenburg",
            "Bryan R. Scott",
            "Tzu-Ching Chang",
            "Steven R. Furlanetto"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.07235",
          "title": "Critical masses and numerical computation of massive scalar quasinormal modes in Schwarzschild black holes",
          "abstract": "We present a comprehensive analysis of the quasinormal modes (QNMs) of a massive scalar field in Schwarzschild spacetime using two complementary numerical techniques: the Hill-determinant method and Leaver continued-fraction method. Our study systematically compares the performance, convergence, and consistency of the two approaches across a wide range of field masses and angular momenta. We identify three critical mass thresholds, $m_{\\rm lim}$, $m_{\\rm max}$, and $m_{zd}$, which govern qualitative changes in the QNM spectrum. In particular, long-lived modes emerge at $m_{zd}$, where the imaginary part of the frequency vanishes and the mode becomes essentially non-decaying. This phenomenon is robust across multipoles and may have important implications for the phenomenology of massive fields around black holes. Our results provide a detailed numerical characterization of massive scalar QNMs and highlight the complementary strengths of the Hill-determinant and continued-fraction methods, paving the way for future studies of rotating or charged black holes and quasi-bound states.",
          "authors": [
            "Matheus F. S. Alves",
            "Bruno P. Pônquio",
            "L.G. Medeiros"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.07698",
          "title": "Electromagnetic Leptogenesis -- an EFT-Consistent Analysis via Wilson Coefficients. Part I. Low-Scale, Non-Resonant Regime",
          "abstract": "We analyse electromagnetic leptogenesis within the framework of an effective field theory, where the dynamics is governed by the gauge-invariant dipole operator $O_{NB}$. The Wilson coefficient $C_{NB}$ is matched at one loop and renormalisation-group (RG) evolved to the electroweak scale. After electroweak symmetry breaking we compute flavour-dependent two-body decay widths and CP asymmetries for $N\\to\\nu+\\gamma/Z$, and solve the fully flavoured Boltzmann equations. In the $N_1$-dominated regime the freeze-out baryon asymmetry is $Y_B^{\\rm FO}\\lesssim 10^{-17}$, far below the observed value $Y_B^{\\rm obs}\\simeq 8.7\\times 10^{-11}$. The suppression is structural: gauge invariance forces a Higgs insertion; therefore dipole couplings $\\mu\\propto v/M_{\\Psi}^2$ while the matched coefficient $C_{NB}$ is loop-generated and further reduced by RG running. We note that in the quasi-degenerate limit the self-energy resonance can be operative and suggest a plausible path to $Y_B^{\\rm obs}$.",
          "authors": [
            "Rin Takada"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.12315",
          "title": "WIYN Open Cluster Study. XCVII. An Extended Radial-Velocity Survey and Spectroscopic Binary Orbits in the Open Cluster NGC 188",
          "abstract": "We present 35 new spectroscopic-binary orbits from our extended radial-velocity (RV) survey of the old ($6.4 \\pm 0.2$ Gyr) open cluster NGC 188. Using data from the WIYN Open Cluster Study (WOCS) and APOGEE-2, this work nearly doubles the temporal baseline of the previous RV study of NGC 188. We obtain orbital solutions within a stellar sample that spans a magnitude range of {$10.8 \\leq \\mathrm{G} \\leq 16.5 \\; (0.9\\mbox{-}1.2 \\; {M_\\odot})$}. With revised membership determinations using Gaia DR3 proper-motions and parallaxes, we reassess the cluster binary frequency and period-eccentricity distribution. The incompleteness-corrected binary frequency is $33.1 \\% \\pm 3.8\\%$ for periods less than $10^4$ days, and the tidal-circularization period is $14.4^{+0.14}_{-0.11}$ days. We find evidence that giants are deficient in short-period orbits, and suggest that the missing giants may have undergone mass transfer and in part formed the population of blue straggler stars (BSSs) and blue lurkers. Among the binaries of note, we highlight WOCS 3953 as a blue lurker candidate, WOCS 5020 and WOCS 4945 as very long-period eccentric BSSs, and WOCS 4230, a BSS with a very close WD companion.",
          "authors": [
            "Ritvik Sai Narayan",
            "Evan Linck",
            "Robert D. Mathieu",
            "Aaron M. Geller"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18245",
          "title": "The Great Impersonation: $\\mathcal{W}$-Solitons as Prototypical Black Hole Microstates",
          "abstract": "We analyze a new class of static, smooth geometries in five-dimensional supergravity, dubbed $\\mathcal{W}$-solitons. They carry the same mass and charges as four-dimensional Reissner-Nordström-like black holes but replace the horizon with a Kaluza-Klein bubble supported by electromagnetic flux. These solutions provide analytically tractable prototypes of black hole microstates in supergravity, including a new, relevant neutral configuration involving a massless axion field. Focusing on photon scattering and scalar perturbations, we compute their key observables, aiming to identify mesoscopic observables. We find that $\\mathcal{W}$-solitons feature a single photon sphere, qualitatively similar to that of the black hole but with quantitative differences. They have only short-lived quasinormal modes~(QNMs), as black holes, while long-lived echo modes seen in other ultracompact horizonless objects are absent. As a result, the ringdown closely resembles that of a black hole while still showing sizable deviations. The latter are at the ${\\mathcal{O}}(10\\%)$ level, compatible with the recent measurement of GW250114 and potentially falsifiable in the near future. Finally, we show that $\\mathcal{W}$-solitons are stable under scalar perturbations. Our results underscore the qualitative similarities between $\\mathcal{W}$-solitons and black holes, reinforcing their relevance as smooth black hole microstate prototypes.",
          "authors": [
            "Alexandru Dima",
            "Pierre Heidmann",
            "Marco Melis",
            "Paolo Pani",
            "Gela Patashuri"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18245",
          "title": "The Great Impersonation: $\\mathcal{W}$-Solitons as Prototypical Black Hole Microstates",
          "abstract": "We analyze a new class of static, smooth geometries in five-dimensional supergravity, dubbed $\\mathcal{W}$-solitons. They carry the same mass and charges as four-dimensional Reissner-Nordström-like black holes but replace the horizon with a Kaluza-Klein bubble supported by electromagnetic flux. These solutions provide analytically tractable prototypes of black hole microstates in supergravity, including a new, relevant neutral configuration involving a massless axion field. Focusing on photon scattering and scalar perturbations, we compute their key observables, aiming to identify mesoscopic observables. We find that $\\mathcal{W}$-solitons feature a single photon sphere, qualitatively similar to that of the black hole but with quantitative differences. They have only short-lived quasinormal modes~(QNMs), as black holes, while long-lived echo modes seen in other ultracompact horizonless objects are absent. As a result, the ringdown closely resembles that of a black hole while still showing sizable deviations. The latter are at the ${\\mathcal{O}}(10\\%)$ level, compatible with the recent measurement of GW250114 and potentially falsifiable in the near future. Finally, we show that $\\mathcal{W}$-solitons are stable under scalar perturbations. Our results underscore the qualitative similarities between $\\mathcal{W}$-solitons and black holes, reinforcing their relevance as smooth black hole microstate prototypes.",
          "authors": [
            "Alexandru Dima",
            "Pierre Heidmann",
            "Marco Melis",
            "Paolo Pani",
            "Gela Patashuri"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18245",
          "title": "The Great Impersonation: $\\mathcal{W}$-Solitons as Prototypical Black Hole Microstates",
          "abstract": "We analyze a new class of static, smooth geometries in five-dimensional supergravity, dubbed $\\mathcal{W}$-solitons. They carry the same mass and charges as four-dimensional Reissner-Nordström-like black holes but replace the horizon with a Kaluza-Klein bubble supported by electromagnetic flux. These solutions provide analytically tractable prototypes of black hole microstates in supergravity, including a new, relevant neutral configuration involving a massless axion field. Focusing on photon scattering and scalar perturbations, we compute their key observables, aiming to identify mesoscopic observables. We find that $\\mathcal{W}$-solitons feature a single photon sphere, qualitatively similar to that of the black hole but with quantitative differences. They have only short-lived quasinormal modes~(QNMs), as black holes, while long-lived echo modes seen in other ultracompact horizonless objects are absent. As a result, the ringdown closely resembles that of a black hole while still showing sizable deviations. The latter are at the ${\\mathcal{O}}(10\\%)$ level, compatible with the recent measurement of GW250114 and potentially falsifiable in the near future. Finally, we show that $\\mathcal{W}$-solitons are stable under scalar perturbations. Our results underscore the qualitative similarities between $\\mathcal{W}$-solitons and black holes, reinforcing their relevance as smooth black hole microstate prototypes.",
          "authors": [
            "Alexandru Dima",
            "Pierre Heidmann",
            "Marco Melis",
            "Paolo Pani",
            "Gela Patashuri"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.22526",
          "title": "Event Generator Tuning as a Robustness Test",
          "abstract": "Neutrino oscillation experiments use Monte Carlo event generators to predict neutrino-nucleus interactions. Cross section uncertainties are typically implemented by varying the parameters of the model(s) used in the generator. We study the performance of two commonly-used model configurations of the GENIE generator (G18_10a_02_11a and AR23_0i_00_000) and their uncertainties by tuning parameters to cross section data, and then comparing the resulting tuned prediction to a suite of other measurements from T2K, MicroBooNE, and MINERvA. This reveals whether the model can simultaneously describe several datasets, as well as whether the uncertainties are adequately robust. We find that G18 and especially AR23 are reasonable in predicting lower-energy measurements from T2K and MicroBooNE, but unable to describe MINERvA data, and discuss the implications for short-baseline oscillation searches. We attempt to replicate a tuning procedure developed by MicroBooNE using several different measurements, and find substantially different results depending on which measurement is used, and that the MicroBooNE tune does not agree with other measurements. We conclude that the SBN experiment should not tune its generator to external data.",
          "authors": [
            "Jean Wolfs",
            "Chris M. Marshall"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.22526",
          "title": "Event Generator Tuning as a Robustness Test",
          "abstract": "Neutrino oscillation experiments use Monte Carlo event generators to predict neutrino-nucleus interactions. Cross section uncertainties are typically implemented by varying the parameters of the model(s) used in the generator. We study the performance of two commonly-used model configurations of the GENIE generator (G18_10a_02_11a and AR23_0i_00_000) and their uncertainties by tuning parameters to cross section data, and then comparing the resulting tuned prediction to a suite of other measurements from T2K, MicroBooNE, and MINERvA. This reveals whether the model can simultaneously describe several datasets, as well as whether the uncertainties are adequately robust. We find that G18 and especially AR23 are reasonable in predicting lower-energy measurements from T2K and MicroBooNE, but unable to describe MINERvA data, and discuss the implications for short-baseline oscillation searches. We attempt to replicate a tuning procedure developed by MicroBooNE using several different measurements, and find substantially different results depending on which measurement is used, and that the MicroBooNE tune does not agree with other measurements. We conclude that the SBN experiment should not tune its generator to external data.",
          "authors": [
            "Jean Wolfs",
            "Chris M. Marshall"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.25695",
          "title": "Radiative hydrodynamic simulations of FIP fractionation in solar flares",
          "abstract": "Elemental abundances in solar flares are observed to vary both spatially and temporally, but the underlying mechanisms remain poorly understood. There is an interplay between advection and the preferential acceleration of low first ionization potential (FIP) elements that likely shapes the observed abundance distributions. Models of the FIP effect predict enhancements near loop footpoints that diffuse upward over time. We simulate strong evaporation events that advect this low-FIP enhancement into the corona. When the enhancement is sharply peaked, the corona does not become fractionated, exhibiting only a localized abundance peak near the loop apex that facilitates coronal rain formation. In contrast, a broad enhancement with relatively weak heating yields a uniformly fractionated corona, which is not sufficient for coronal rain formation. As the heating rate increases, the low-FIP enhanced plasma is increasingly compressed toward the loop apex, and rain is able to form. These results suggest a potential observational correlation between the presence and amount of coronal rain, the strength of flare heating, and the fractionation process itself.",
          "authors": [
            "Jeffrey W. Reep",
            "Luke Fushimi Benavitz",
            "Andy S.H. To",
            "David H. Brooks",
            "J. Martin Laming",
            "Patrick Antolin",
            "David M. Long",
            "Deborah Baker"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.00135",
          "title": "SN 2025coe: A Multiple-Peaked Calcium-Strong Transient from A White-Dwarf Progenitor",
          "abstract": "SN 2025coe is a calcium-strong transient located at an extremely large projected offset $\\sim$39.3 kpc from the center of its host, the nearby early-type galaxy NGC 3277 at a distance of $\\sim$25.5 Mpc. In this paper, we present multi-band photometric and spectroscopic observations spanning $\\sim$100 days post-discovery. Its multi-band light curves display {multiple} distinct peaks: (1) an initial peak at $t \\approx 1.6$ days attributed to shock cooling emission, (2) a secondary peak of $M_{R, \\, peak} \\approx$ $-$15.8 mag at $t \\approx 10.2$ days powered by radioactive decay, and (3) a {possible} late-time bump at $t \\approx 42.8$ days likely caused by ejecta-circumstellar material/clump interaction. Spectral evolution of SN 2025coe reveals a fast transition to the nebular phase within 2 months, where it exhibits an exceptionally high [Ca II]/[O I] ratio larger than 6. Modeling of the bolometric light curve suggests an ejecta mass of $M_{\\rm ej} = 0.29^{+0.14}_{-0.15} \\, M_{\\odot}$, a $^{56}$Ni mass of $M_{\\rm ^{56}Ni} = 2.4^{+0.06}_{-0.05} \\times 10^{-2} M_{\\odot}$, and a progenitor envelope with mass $M_e = 1.4^{+6.9}_{-1.2} \\times 10^{-3} \\, M_{\\odot}$ and radius $R_e = 13.5^{+64.1}_{-11.1} \\, R_{\\odot}$. The tidal disruption of a hybrid HeCO white dwarf (WD) by a low-mass CO WD provides a natural explanation for the low ejecta mass, the small fraction of $^{56}$Ni, and the presence of an extended, low-mass envelope.",
          "authors": [
            "Chun Chen",
            "Ning-Chen Sun",
            "Qiang Xi",
            "Samaporn Tinyanont",
            "David Aguado",
            "Ismael Pérez-Fournon",
            "Frédérick Poidevin",
            "Justyn R. Maund",
            "Amit Kumar",
            "Junjie Jin",
            "Yiming Mao",
            "Beichuan Wang",
            "Yu Zhang",
            "Zhen Guo",
            "Wenxiong Li",
            "César Rojas-Bravo",
            "Rong-Feng Shen",
            "Lingzhi Wang",
            "Ziyang Wang",
            "Guoying Zhao",
            "Jie Zheng",
            "Yinan Zhu",
            "David López Fernández-Nespral",
            "Alicia López-Oramas",
            "Zexi Niu",
            "Yanan Wang",
            "Klaas Wiersema",
            "Jifeng Liu"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.00135",
          "title": "SN 2025coe: A Multiple-Peaked Calcium-Strong Transient from A White-Dwarf Progenitor",
          "abstract": "SN 2025coe is a calcium-strong transient located at an extremely large projected offset $\\sim$39.3 kpc from the center of its host, the nearby early-type galaxy NGC 3277 at a distance of $\\sim$25.5 Mpc. In this paper, we present multi-band photometric and spectroscopic observations spanning $\\sim$100 days post-discovery. Its multi-band light curves display {multiple} distinct peaks: (1) an initial peak at $t \\approx 1.6$ days attributed to shock cooling emission, (2) a secondary peak of $M_{R, \\, peak} \\approx$ $-$15.8 mag at $t \\approx 10.2$ days powered by radioactive decay, and (3) a {possible} late-time bump at $t \\approx 42.8$ days likely caused by ejecta-circumstellar material/clump interaction. Spectral evolution of SN 2025coe reveals a fast transition to the nebular phase within 2 months, where it exhibits an exceptionally high [Ca II]/[O I] ratio larger than 6. Modeling of the bolometric light curve suggests an ejecta mass of $M_{\\rm ej} = 0.29^{+0.14}_{-0.15} \\, M_{\\odot}$, a $^{56}$Ni mass of $M_{\\rm ^{56}Ni} = 2.4^{+0.06}_{-0.05} \\times 10^{-2} M_{\\odot}$, and a progenitor envelope with mass $M_e = 1.4^{+6.9}_{-1.2} \\times 10^{-3} \\, M_{\\odot}$ and radius $R_e = 13.5^{+64.1}_{-11.1} \\, R_{\\odot}$. The tidal disruption of a hybrid HeCO white dwarf (WD) by a low-mass CO WD provides a natural explanation for the low ejecta mass, the small fraction of $^{56}$Ni, and the presence of an extended, low-mass envelope.",
          "authors": [
            "Chun Chen",
            "Ning-Chen Sun",
            "Qiang Xi",
            "Samaporn Tinyanont",
            "David Aguado",
            "Ismael Pérez-Fournon",
            "Frédérick Poidevin",
            "Justyn R. Maund",
            "Amit Kumar",
            "Junjie Jin",
            "Yiming Mao",
            "Beichuan Wang",
            "Yu Zhang",
            "Zhen Guo",
            "Wenxiong Li",
            "César Rojas-Bravo",
            "Rong-Feng Shen",
            "Lingzhi Wang",
            "Ziyang Wang",
            "Guoying Zhao",
            "Jie Zheng",
            "Yinan Zhu",
            "David López Fernández-Nespral",
            "Alicia López-Oramas",
            "Zexi Niu",
            "Yanan Wang",
            "Klaas Wiersema",
            "Jifeng Liu"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.01326",
          "title": "Light deflection in axially symmetric stationary spacetimes filled with a moving medium",
          "abstract": "The deflection of light rays near gravitating objects can be influenced not only by gravity itself but also by the surrounding medium. Analytical studies of such effects are possible within the geometrical optics approximation, where the medium introduces additional light bending due to refraction. These studies typically assume a cold non-magnetized plasma, for which light propagation is independent of the medium's velocity. In this paper, we extend the analysis to the general case of dispersive refractive media in motion and study its influence on light deflection. We consider an axially symmetric stationary spacetime filled with a moving medium, motivated by the interplay between rotational effects originating from the spacetime and those induced by the medium's motion. We begin by analyzing light deflection in the equatorial plane of a rotating object in the presence of a radially moving and rotating medium. Assuming a specific form of the refractive index enables a fully analytic treatment. In the particular cases of either pure radial or pure rotational motion, we obtain explicit expressions for the deflection angle. Next, we analyze the case of a slowly moving medium and identify two particularly interesting results. First, we show that, to the first order in the medium's velocity, the radial motion does not affect the light deflection. Second, assuming slow rotation of the gravitating object, we demonstrate that the black hole rotation and the medium motion can produce equivalent observational signatures. We find the quantitative condition under which these effects compensate each other. This relation becomes particularly clear for a Kerr black hole, discussed as an example.",
          "authors": [
            "Christian Pfeifer",
            "Barbora Bezděková",
            "Oleg Yu. Tsupko"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.02431",
          "title": "No Observational Evidence for Dark Matter Nor a Large Metallicity Spread in the Extreme Milky Way Satellite Ursa Major III / UNIONS 1",
          "abstract": "The extremely-low-luminosity, compact Milky Way satellite Ursa Major III / UNIONS 1 (UMaIII/U1; $L_V = 11 \\ L_{\\odot}$; $a_{1/2} = 3$ pc) was found to have a substantial velocity dispersion at the time of its discovery ($\\sigma_v = 3.7^{+1.4}_{-1.0} \\rm \\ km \\ s^{-1}$), suggesting that it might be an exceptional, highly dark-matter-dominated dwarf galaxy with very few stars. However, significant questions remained about the system's dark matter content and nature as a dwarf galaxy due to the small member sample ($N=11$), possible spectroscopic binaries, and the lack of any metallicity information. Here, we present new spectroscopic observations covering $N=16$ members that both dynamically and chemically test UMaIII/U1's true nature. From higher-precision Keck/DEIMOS spectra, we find a 95% confidence level velocity dispersion limit of $\\sigma_v< 2.3 \\rm \\ km \\ s^{-1}$, with a $\\sim$120:1 likelihood ratio now favoring the expected stellar-only dispersion of $\\sigma_* \\approx 0.1 \\rm \\ km \\ s^{-1}$ over the original $3.7 \\rm \\ km \\ s^{-1}$ dispersion. There is now no observational evidence for dark matter in the system. From Keck/LRIS spectra targeting the Calcium II K line, we also measure the first metallicities for 12 member stars, finding a mean metallicity of $\\rm [Fe/H] = -2.65 \\; \\pm \\, 0.1$ (stat.) $\\pm \\,0.3$ (zeropoint) with a metallicity dispersion limit of $\\sigma_{\\rm [Fe/H]} < 0.35$ dex (at the 95% credible level). Together, these properties are more consistent with UMaIII/U1 being a star cluster, though the dwarf galaxy scenario is not fully ruled out. Under this interpretation, UMaIII/U1 ranks among the faintest and most metal-poor star clusters yet discovered.",
          "authors": [
            "William Cerny",
            "Daisy Bissonette",
            "Alexander P. Ji",
            "Marla Geha",
            "Anirudh Chiti",
            "Simon E.T. Smith",
            "Joshua D. Simon",
            "Andrew B. Pace",
            "Evan N. Kirby",
            "Kim A. Venn",
            "Ting S. Li",
            "Alice M. Luna"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12620",
          "title": "Formation of protostars and the launching of stellar core outflows with moving-mesh radiation non-ideal magnetohydrodynamics",
          "abstract": "We present an implementation of radiative transfer with flux-limited diffusion (FLD) for the moving-mesh code {\\small AREPO} and use the method in a physical model for the formation of protostars with non-ideal radiation-magnetohydrodynamics (RMHD). We follow previous work in splitting the additional terms to the hydrodynamical equations arising from the inclusion of radiation into terms to be integrated explicitly and implicitly, as the diffusion and coupling terms would impose very restrictive timestep criteria. We validate the scheme with standard test problems for radiation diffusion, matter-gas coupling, and radiative shocks from the literature. Our implementation is compatible with local timestepping, which often presents problems for implicit schemes, and we found very good agreement with results obtained with global timesteps. We present an example application of the new implementation to the collapse of a $1\\,{\\rm M}_\\odot$ molecular cloud core to a second Larson core modelled with radiation non-ideal magnetohydrodynamics. A high-velocity jet with v$_{\\rm rad}> 10\\, {\\rm km\\,s^{-1}}$ is self-consistently launched from the second core, nested within the first core, which produces a lower-velocity magnetorotational outflow. We observe magnetic field amplification up to more than $\\vert \\mathbf{B}\\vert_{\\rm max}>10^5$ G in the second core, which is surrounded by a small (<0.5 au) disk. This application demonstrates the robustness of our scheme in multi-scale and high-resolution simulations on arbitrary meshes and, as such, the model can be readily used for further simulations of protostar formation at high resolution.",
          "authors": [
            "Alexander C. Mayer",
            "Rüdiger Pakmor",
            "Thorsten Naab",
            "Oliver Zier",
            "Alexei V. Ivlev",
            "Tommaso Grassi",
            "Paola Caselli",
            "Volker Springel"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.22804",
          "title": "Overlapping of photon rings in black hole imaging",
          "abstract": "In this paper, we investigate the overlapping of photon rings - higher-order images of a black hole's luminous environment, concentrated near the shadow boundary and expected to be resolved in future observations. We consider a broad class of static spherically symmetric spacetimes and geometrically thin equatorial accretion disk with a prescribed inner radius and infinite outer extent, viewed by a polar observer. Depending on the inner radius of the disk, the thickness of each photon ring varies, and the rings may or may not overlap. To characterize the overlapping, we introduce the radius of merging - the value of the disk's inner radius at which two photon rings of given orders begin to overlap. Since each radius of merging is labeled by two indices corresponding to the image orders, it becomes possible to arrange these radii in the form of an infinite-dimensional matrix where only the upper right-hand corner is filled. This matrix, which we call the \"matrix of merging\", is a signature of spacetime only, and, once known, it provides a qualitative understanding of the overlapping pattern for any chosen value of the inner radius of the disk. Remarkably, the matrix of merging exhibits several universal properties that hold for all spherically symmetric metrics and can be established even without explicit calculation of light trajectories. Based on these properties, we demonstrate that certain overlapping patterns are universally forbidden across all such spacetimes and for any inner radius of the disk. Examples for the Schwarzschild and Reissner-Nordström black holes are provided. The main application of our study is constraining the spacetime metric and the accretion model using observed photon ring overlaps.",
          "authors": [
            "Oleg Yu. Tsupko",
            "Fabio Aratore",
            "Volker Perlick"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23808",
          "title": "Towards theory constraints on ultralight dark matter from quantum gravity",
          "abstract": "Ultralight scalar dark matter may couple to the Standard Model through dimension-five operators that contain the field-strength tensors of the gauge interactions. Recent progress in nuclear clocks is projected to increase the sensitivity to such couplings by several orders of magnitude. Future experimental constraints may even have Planck-scale sensitivity, calling for a study of such couplings in a framework that includes quantum gravity. We take a first step towards providing the theoretical constraints on such couplings that arise in asymptotically safe gravity. We find evidence that such couplings vanish in asymptotically safe gravity and are also not generated in a perturbative quantum-gravity regime that describes quantum gravity as an effective field theory.",
          "authors": [
            "Gabriel Assant",
            "Astrid Eichhorn",
            "Benjamin Knorr"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23808",
          "title": "Towards theory constraints on ultralight dark matter from quantum gravity",
          "abstract": "Ultralight scalar dark matter may couple to the Standard Model through dimension-five operators that contain the field-strength tensors of the gauge interactions. Recent progress in nuclear clocks is projected to increase the sensitivity to such couplings by several orders of magnitude. Future experimental constraints may even have Planck-scale sensitivity, calling for a study of such couplings in a framework that includes quantum gravity. We take a first step towards providing the theoretical constraints on such couplings that arise in asymptotically safe gravity. We find evidence that such couplings vanish in asymptotically safe gravity and are also not generated in a perturbative quantum-gravity regime that describes quantum gravity as an effective field theory.",
          "authors": [
            "Gabriel Assant",
            "Astrid Eichhorn",
            "Benjamin Knorr"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23808",
          "title": "Towards theory constraints on ultralight dark matter from quantum gravity",
          "abstract": "Ultralight scalar dark matter may couple to the Standard Model through dimension-five operators that contain the field-strength tensors of the gauge interactions. Recent progress in nuclear clocks is projected to increase the sensitivity to such couplings by several orders of magnitude. Future experimental constraints may even have Planck-scale sensitivity, calling for a study of such couplings in a framework that includes quantum gravity. We take a first step towards providing the theoretical constraints on such couplings that arise in asymptotically safe gravity. We find evidence that such couplings vanish in asymptotically safe gravity and are also not generated in a perturbative quantum-gravity regime that describes quantum gravity as an effective field theory.",
          "authors": [
            "Gabriel Assant",
            "Astrid Eichhorn",
            "Benjamin Knorr"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.24340",
          "title": "On the Dusty Proximate Damped Lyman-α System toward Q2310-3358 at z = 2.40",
          "abstract": "Quasar absorption systems not only affect the way quasars are selected, but also serve as key probes of galaxies, providing insight into their chemical evolution and interstellar medium (ISM). Recently, a method based on Gaia astrometric measurements has aided the selection of quasars reddened by dust hitherto overlooked. We conducted a spectroscopic study using VLT/X-Shooter on one such dust-reddened quasar, Q2310-3358. This quasar, at $z = 2.3909\\pm0.0022$, is associated with a damped Lyman-$\\alpha$ absorber (DLA) at nearly the same redshift $2.4007\\pm0.0003$, with a neutral hydrogen column density of $\\log N(HI)=21.214\\pm0.003$. The DLA is very metal-rich (close to solar metallicity after correction for depletion on dust grains). Its properties align with the metal-to-dust ratio and the mass-metallicity relation established in previous large samples of DLAs. Surprisingly, given its proximity to the quasar in redshift, the absorber has strong cold gas characteristics, including CI and H$_2$. Based on the derived kinetic temperature of $71^{+28}_{-15}$~K, we infer the presence of a strong UV radiation field, which in turn suggests that the quasar and the DLA are in close proximity, i.e., part of the same galaxy and not just different objects in the same overdensity of galaxies. We used the line ratios of the fine-structure lines to constrain the density of the cold gas, yielding $n_{\\rm H} \\sim 10^{3}~\\mathrm{cm}^{-3}$. Our analysis extends the understanding of $z_{abs} \\approx z_{em}$ absorption line systems and provides valuable constraints on the interplay between dust, metals, and neutral gas in the ISM of early galaxies.",
          "authors": [
            "S. Han",
            "J.-K. Krogager",
            "C. Ledoux",
            "G. Ma",
            "K. E. Heintz",
            "S. J. Geier",
            "L. Christensen",
            "P. Møller",
            "J. P. U. Fynbo"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.24662",
          "title": "Particle-level transformers for 95 GeV Higgs boson searches at future $e^+e^-$ Higgs factories",
          "abstract": "Motivated by several mild excesses around 95 GeV, we investigate the prospects for a light scalar $S$ produced via Higgsstrahlung, $e^+e^- \\to Z(\\mu^+\\mu^-)S$, at future $e^+e^-$ Higgs factories. We take the CEPC as a benchmark, with a center-of-mass energy of $\\sqrt{s}=240$ GeV and an integrated luminosity of $L=20~\\mathrm{ab}^{-1}$. We focus on the decay modes $S\\to\\tau^+\\tau^-$ and $S\\to b\\bar b$. To maximize sensitivity, we employ the particle-level transformer networks Particle Transformer (ParT) and its more-interactive variant MIParT, which exploit the features of all reconstructed objects and their correlations. For a representative signal benchmark, this approach improves the expected statistical precision on the signal strength by factors of 2.4 in the $\\tau^+\\tau^-$ channel and 1.4 in the $b\\bar b$ channel compared to a cut-based analysis. Within the flipped Next-to-Two-Higgs-Doublet Model (N2HDM-F), the CEPC can measure the signal strength with a statistical precision down to 1.0% in the $\\tau^+\\tau^-$ channel and 0.68% in the $b\\bar b$ channel using MIParT. It can achieve a $5\\sigma$ discovery for $\\mu_{\\tau\\tau}^{ZS}>1.6\\times10^{-2}$ or $\\mu_{bb}^{ZS}>4.9\\times10^{-3}$, and reach 1% precision for $\\mu_{\\tau\\tau}^{ZS}>0.96$ or $\\mu_{bb}^{ZS}>0.14$. These gains are expected to qualitatively carry over to other future lepton colliders such as FCC-ee and the ILC. Our results demonstrate the potential of particle-level machine-learning techniques to strengthen light Higgs searches at future $e^+e^-$ Higgs factories.",
          "authors": [
            "Yabo Dong",
            "Manqi Ruan",
            "Kun Wang",
            "Haijun Yang",
            "Jingya Zhu"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.00397",
          "title": "Properties of Carbon-rich AGB Stars in the LMC and the Milky Way",
          "abstract": "We present a comparative study of carbon-rich asymptotic giant branch (CAGB) stars in the Large Magellanic Cloud (LMC; 7347 stars) and the Milky Way (7163 stars) using infrared color-magnitude diagrams (CMDs), spectral energy distributions (SEDs), two-color diagrams (2CDs), and variability data. Observed SEDs are compared with theoretical models to characterize the central stars and their circumstellar dust envelopes and to estimate distances. For the LMC, a set of best-fitting CAGB models is derived by fitting observed SEDs with radiative transfer models, utilizing the galaxy's well-established distance. For Galactic CAGB stars, where Gaia DR3 parallaxes are uncertain, we estimate distances by fitting observed SEDs with the CAGB models validated against LMC stars, and for Mira variables, from the period-magnitude relation calibrated with LMC Miras. A comparison of these approaches demonstrates that the SED-based distances are both reliable and practical for a large sample of Galactic CAGB stars. We find that CAGB stars in both galaxies show broadly similar infrared properties, although the LMC sample lacks stars with extremely thick dust envelopes.",
          "authors": [
            "Kyung-Won Suh"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.02768",
          "title": "Nested Apparent Horizons and Quantized Separation from Intense Hawking Backreaction",
          "abstract": "When Hawking radiation from a rotating or non-rotating black hole becomes sufficiently intense, its own stress energy can no longer be treated as a perturbation on a fixed background. In this regime the outgoing flux may generate an additional, transient trapping surf ace exterior to the original event horizon. Using a simple spherically symmetric semi classical model we demonstrate that strong outgoing null energy can create nested apparent horizons, a feature reminiscent of the Penrose process but mediated by quantum back reaction. The effect is illustrated using a smooth Vaidya type mass profile, and conditions for bifurcation and merger of horizons are derived. We further propose that the separation between nested horizons may obey a discrete quantization rule analogous to the Bohr Sommerfeld condition,suggesting a geometric route toward quantum-gravity discreteness.",
          "authors": [
            "Steven J. Silverman"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06017",
          "title": "A Universal Framework for Horizon-Scale Tests of Gravity with Black Hole Shadows",
          "abstract": "In this Letter, we have developed a numerically efficient framework for evaluating parameters in metric theories of gravity, and applied it to constrain the horizon-scale magnetic field in the Kerr-Bertotti-Robinson (Kerr-BR) spacetime using the latest EHT observations. The method's adaptive ray-tracing strategy achieves near-linear computational efficiency without loss of numerical accuracy. Owing to this efficiency, the framework enables high precision shadow modeling at minimal computational cost and, for the first time, supports statistically robust inference of black hole parameters from horizon-scale observations for arbitrary stationary black holes. The above framework is applied to the recently obtained Kerr-BR black hole, an exact magnetized and rotating solution to the Einstein field equations. We have evaluated the horizon-scale magnetic fields of M87* and Sgr A*, with the latter showing a field strength of $93.3^{+14.7}_{-23.8}G$, consistent with the equipartition estimate of $71G$ from polarized ALMA observations, thereby supporting Einstein's gravity.",
          "authors": [
            "Wentao Liu",
            "Yang Liu",
            "Di Wu",
            "Yu-Xiao Liu"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.08685",
          "title": "Kinematic scaling relations of disc galaxies from ionised gas at $z\\sim1$ and their connection with dark matter haloes",
          "abstract": "We derive the Tully-Fisher (TFR, $M_\\ast-V_{\\rm circ,f}$) and Fall (FR, $j_\\ast-M_\\ast$) relations at redshift $z = 0.9$ using a sample of 43 main-sequence disc galaxies with H$\\alpha$ IFU data and JWST/HST imaging. The strength of our analysis lies in the use of state-of-the-art 3D kinematic models to infer galaxy rotation curves, the inclusion and morphological modelling of NIR bands, and the use of SED modelling applied to our photometry measurements to estimate stellar masses. After correcting the inferred H$\\alpha$ velocities for asymmetric drift, we find a TFR of the form $\\log(M_\\ast / M_\\odot) = a \\log(V_{\\rm circ,f} / 150~\\mathrm{km\\,s^{-1}}) + b$, with $a=3.82^{+0.55}_{-0.40}$ and $b=10.27^{+0.06}_{-0.07}$, as well as a FR of the form $\\log(j_\\ast / \\mathrm{kpc\\,km\\,s^{-1}}) = a \\log(M_\\ast / 10^{10.5} M_\\odot) + b$, with $a=0.44^{+0.06}_{-0.06}$ and $b=2.86^{+0.02}_{-0.02}$. Compared with their $z=0$ counterparts, we find moderate evolution in the TFR and strong evolution in the FR over the past 8 Gyr. We interpret our findings in the context of the galaxy-to-halo scaling parameters $f_{\\rm M}=M_\\ast/M_{\\rm vir}$ and $f_{\\rm j}=j_\\ast/j_{\\rm vir}$. We infer that $f_{\\rm j}$ shows little redshift evolution and depends very weakly on $M_\\ast$, with typical values around $f_{\\rm j}\\sim0.8$. As for $f_{\\rm M}$, we find it to be higher and less dependent on $M_\\ast$ at $z=0.9$ than at $z=0$. Interpreting our observed $f_{\\rm M}-M_\\ast$ relations within the Cold Dark Matter framework implies necessarily that the galaxy populations at $z=0.9$ and $z=0$ are not the progenitor/descendant of one another. The alternative scenario is that the $z=0.9$ relations are incorrect due to strong selection effects, unidentified systematics, or the possibility that H$\\alpha$ kinematics may not be a reliable dynamical tracer. Such problems would also affect previous studies on the same subject.",
          "authors": [
            "Pavel E. Mancera Piña",
            "Enrico M. Di Teodoro",
            "S. Michael Fall",
            "Antonino Marasco",
            "Mariska Kriek",
            "Marco Martorano"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.09040",
          "title": "Time-Dependent Radiation Quality Factor <Q> of Galactic Cosmic Rays in Deep Space and Shielding Environments: Modeling and Measurements",
          "abstract": "Understanding the long-term variation of the galactic cosmic ray (GCR) radiation environment is critical for assessing radiation risks in space exploration missions. In this study, we systematically model the linear energy transfer (LET) spectra of GCRs and the corresponding radiation quality factor, <Q>, in deep space and shielding environments. The Badhwar-O'Neill 2020 (BON20) model is used to represent GCR fluxes under different solar modulation potentials (phi), which characterize the level of solar activity. GCR interactions with spherical shielding of different thicknesses are simulated to obtain the LET spectra, absorbed dose, dose equivalent, and <Q>. We present a comprehensive dataset of these quantities for a range of phi values and shielding thicknesses. The results show that <Q> depends strongly on the shielding thickness but only weakly on solar activity. Furthermore, model predictions are validated against long-term measurements from the Cosmic Ray Telescope for the Effects of Radiation (CRaTER) orbiting the Moon, and the Liulin-MO detector on board the ExoMars Trace Gas Orbiter (TGO) orbiting Mars. In this comparison, we consider factors for anomalous cosmic ray (ACR) contributions and radial gradients of both GCRs and ACRs, applying scaling factors of 6.3% at 1 AU and 11.0% at 1.5 AU to the calculated absorbed dose rate. With these corrections, the modeled absorbed dose rate and <Q> exhibit consistent temporal variations with the observations under both thin and thick shielding conditions. Moreover, we investigate the distinct temporal evolution of <Q> for light and heavy GCR nuclei, revealing how solar modulation influences the elemental radiation quality factor across GCR species. These results offer new insights into the temporal and environmental dependence of the space radiation quality factor, with implications for radiation dose estimate and crewed mission design.",
          "authors": [
            "Weihao Liu",
            "Mikhail Dobynde",
            "Jingnan Guo",
            "Jordanka Semkova",
            "Krasimir Krastev"
          ],
          "primary_category": "physics.space-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11136",
          "title": "Near-Horizon Symmetries in Einstein-Maxwell theory",
          "abstract": "This manuscript aims to provide a comprehensive derivation of the Einstein-Maxwell charges and fluxes in the near-horizon region of a four-dimensional non-extremal black hole, with vanishing cosmological constant. Specifically, we present a detailed derivation of the Noether charges within both the metric and first-order formulations, elucidating the relationship between the Carrollian internal boost charge and the Lorentz boost charge. It is well-established in the literature that Carrollian fluids exhibit an internal local boost symmetry; we demonstrate that this symmetry precisely corresponds to a Lorentz internal transformation. Finally, we prove that the near-horizon Einstein equations can be obtained from the flux-balance law by employing the generalized Barnich-Troessaert bracket.",
          "authors": [
            "Gianfranco De Simone"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.13856",
          "title": "Low-energy Radio Bursts from Magnetar XTE J1810$-$197: Implications for Fast Radio Bursts",
          "abstract": "Magnetars are the leading candidate sources of fast radio bursts (FRBs). However, the observational probes of the connections between magnetars and FRBs are severely limited by the paucity of detection of highly energetic radio events from magnetars -- to date, only one radio burst as energetic as FRBs has been detected from a Galactic magnetar. Here, we present a detailed analysis of a large sample of low-energy bursts detected from the magnetar XTE J1810$-$197, and probe their implications for FRB emission from magnetars. We report detection of over 97000 bright radio pulses from 242 observations of the magnetar XTE J1810$-$197 over 4.5 years and two decades in frequency (300 MHz to 6.15 GHz), using the Giant Meterwave Radio Telescope and the Green Bank Telescope, after its recent outburst onset in December 2018. We present detailed analysis of the burst fluence distributions and their trends with time as well as frequency, and the waiting time distribution. We show that XTE J1810$-$197 rapidly switches between pulsar-like and giant-pulse-like emission states, and magnetars like XTE J1810$-$197 remain viable and likely emitters of FRBs, in the form of giant-pulses with energies comparable to FRBs. We also demonstrate that the lack of the detection of an underlying periodicity in the bursts from repeating FRBs might be caused by emission across a wide range of spin phases.",
          "authors": [
            "Banshi Lal",
            "Yogesh Maan",
            "Moaz Abdelmaguid",
            "Visweshwar Ram Marthi",
            "Joseph D. Gelfand",
            "Samayra Straal"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18479",
          "title": "Kinematic Mapping of Giant Arcs: A New Method to Locate Lensing Critical Curves",
          "abstract": "Proximity of lensing critical curves features highly magnified portions of lensed galaxies. Accurate knowledge of the location and shape of the critical curve will be useful for understanding the nature of highly magnified stellar sources near critical curves and for revealing sub-galactic dark matter structures within the lens. In galaxy-cluster lenses, however, prediction of critical curves can be uncertain due to complexity in global mass modeling. We explore and validate a kinematics-based method for locating the critical curve. This method leverages the continuous line-of-sight velocity profile of the lensed galaxy mapped through integral field spectroscopy of emission lines, and combines an agnostic local lens model and a disk rotation model. Applying our method to a highly magnified region of the Dragon Arc in the Abell 370 cluster lensing field using archival VLT/MUSE IFU mapping of the H$\\beta$ line, we constrain the critical curve to an uncertainty band with a half-width of 0.23\" ($1\\sigma$). This result reveals locations of recently detected extremely magnified stars biased toward the negative-parity side of the critical curve, as predicted for intracluster microlensing. With future JWST/NIRSpec IFU mapping of the H$\\alpha$ line at SNR $\\simeq$ 10 (20), uncertainty could improve to 0.12\" (0.08\"). A measurement of this type with sufficiently small uncertainty may reveal small-scale wiggles in the shape of the critical curve, which can arise from the lensing perturbation of sub-galactic dark matter substructure. Our approach is generally applicable to caustic-crossing giant arcs and can be incorporated into global lens modeling.",
          "authors": [
            "Ruwen Zhou",
            "Liang Dai",
            "Lingyuan Ji",
            "Massimo Pascale",
            "Jose M. Diego",
            "Fengwu Sun",
            "Yoshinobu Fudamoto"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18939",
          "title": "On the planetary forcing of the Solar dynamo: Evidence from a Lagrangian framework",
          "abstract": "Whether planetary motions influence the solar magnetic cycle has remained an open question due to the lack of a rigorous physical mechanism. Here we develop a Lagrangian framework based on the Virial theorem to show that planetary orbital angular momentum modulates the Sun's rotation through barycentric dynamics, consistent with angular momentum conservation. Using Singular Spectrum Analysis (SSA) applied to sunspot number (SSN) and terrestrial length-of-day (LOD) records spanning the past 250 years, we identify two non-linear trends plus 11 common pseudo-cycles whose periods match those of planetary resonances (LR$^{*}$). We then demonstrate that a reduced nonlinear $\\alpha-\\Omega$ dynamo model, forced solely by the summed planetary right ascension RA(t), reproduces both the Schwabe cycle and its multi-decadal envelope, including the Dalton Minimum and the Modern Maximum. These results provide strong evidence, based on a physically-grounded model, that the solar dynamo is weakly forced by planetary motion, suggesting that the solar dynamo, classically viewed as autonomous, may in fact behave as a synchronized system.",
          "authors": [
            "Jean-Louis Le Mouël",
            "Vincent Courtillot",
            "Vladimir Kossobokov",
            "Dominique Gibert",
            "Fernando Lopes",
            "Jean-Baptiste Boulé",
            "Pierpaolo Zuddas"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18939",
          "title": "On the planetary forcing of the Solar dynamo: Evidence from a Lagrangian framework",
          "abstract": "Whether planetary motions influence the solar magnetic cycle has remained an open question due to the lack of a rigorous physical mechanism. Here we develop a Lagrangian framework based on the Virial theorem to show that planetary orbital angular momentum modulates the Sun's rotation through barycentric dynamics, consistent with angular momentum conservation. Using Singular Spectrum Analysis (SSA) applied to sunspot number (SSN) and terrestrial length-of-day (LOD) records spanning the past 250 years, we identify two non-linear trends plus 11 common pseudo-cycles whose periods match those of planetary resonances (LR$^{*}$). We then demonstrate that a reduced nonlinear $\\alpha-\\Omega$ dynamo model, forced solely by the summed planetary right ascension RA(t), reproduces both the Schwabe cycle and its multi-decadal envelope, including the Dalton Minimum and the Modern Maximum. These results provide strong evidence, based on a physically-grounded model, that the solar dynamo is weakly forced by planetary motion, suggesting that the solar dynamo, classically viewed as autonomous, may in fact behave as a synchronized system.",
          "authors": [
            "Jean-Louis Le Mouël",
            "Vincent Courtillot",
            "Vladimir Kossobokov",
            "Dominique Gibert",
            "Fernando Lopes",
            "Jean-Baptiste Boulé",
            "Pierpaolo Zuddas"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20148",
          "title": "Is the large uncertainty of $δ_{CP}$ fundamentally encoded in the neutrino quantum state?",
          "abstract": "The precise measurement of the leptonic CP-violating phase $\\delta_{CP}$ remains one of the major open challenges in neutrino physics, as current experiments achieve only very limited accuracy. We address this issue through the lens of quantum estimation theory. A distinctive feature of neutrino oscillation experiments is that they cannot freely optimize the probe or measurement, since both are constrained by the production and detection of flavor eigenstates. We therefore examine whether the large uncertainty in $\\delta_{CP}$ originates from intrinsic reasons, either of the neutrino quantum state or of flavor measurements, or if it instead stems from experimental limitations. By comparing quantum and classical Fisher information, we demonstrate that the limited sensitivity to $\\delta_{CP}$ originates primarily from the information content of flavor measurements. Furthermore, we show that targeting the second oscillation maximum, as in the ESS$\\nu$SB proposal, substantially enhances $\\delta_{CP}$ information compared to experiments centered on the first maximum.",
          "authors": [
            "Michela Ignoti",
            "Claudia Frugiuele",
            "Matteo G. A. Paris",
            "Marco G. Genoni"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20760",
          "title": "The Intrinsic Dimension of Collider Events and Model-Independent Searches in 100 Dimensions",
          "abstract": "The phase space of hadron collider events spans hundreds of dimensions, generating an intricate geometry that we are just starting to explore. The number of possible new physics signals is exponential in the number of dimensions and detecting all of them is currently impossible for any human or artificial intelligence. In this work we introduce a method to search for new physics model-independently in this high-dimensional space. It is based on the measurement of the most basic property of the manifold of collider events, its dimensionality. Our proposed technique does not suffer from a look-elsewhere effect that grows exponentially with the number of dimensions of the dataset, and by construction is insensitive to energy scale uncertainties. We illustrate its potential by finding new physics in simulated events with hundreds of phase space dimensions, taking as input single particles rather than jets. This study sets the stage for new model-independent search strategies based on global properties of collider data manifolds.",
          "authors": [
            "Raffaele Tito D'Agnolo",
            "Alfredo Glioti",
            "Gabriele Rigo",
            "Alessandro Valenti"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20760",
          "title": "The Intrinsic Dimension of Collider Events and Model-Independent Searches in 100 Dimensions",
          "abstract": "The phase space of hadron collider events spans hundreds of dimensions, generating an intricate geometry that we are just starting to explore. The number of possible new physics signals is exponential in the number of dimensions and detecting all of them is currently impossible for any human or artificial intelligence. In this work we introduce a method to search for new physics model-independently in this high-dimensional space. It is based on the measurement of the most basic property of the manifold of collider events, its dimensionality. Our proposed technique does not suffer from a look-elsewhere effect that grows exponentially with the number of dimensions of the dataset, and by construction is insensitive to energy scale uncertainties. We illustrate its potential by finding new physics in simulated events with hundreds of phase space dimensions, taking as input single particles rather than jets. This study sets the stage for new model-independent search strategies based on global properties of collider data manifolds.",
          "authors": [
            "Raffaele Tito D'Agnolo",
            "Alfredo Glioti",
            "Gabriele Rigo",
            "Alessandro Valenti"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20760",
          "title": "The Intrinsic Dimension of Collider Events and Model-Independent Searches in 100 Dimensions",
          "abstract": "The phase space of hadron collider events spans hundreds of dimensions, generating an intricate geometry that we are just starting to explore. The number of possible new physics signals is exponential in the number of dimensions and detecting all of them is currently impossible for any human or artificial intelligence. In this work we introduce a method to search for new physics model-independently in this high-dimensional space. It is based on the measurement of the most basic property of the manifold of collider events, its dimensionality. Our proposed technique does not suffer from a look-elsewhere effect that grows exponentially with the number of dimensions of the dataset, and by construction is insensitive to energy scale uncertainties. We illustrate its potential by finding new physics in simulated events with hundreds of phase space dimensions, taking as input single particles rather than jets. This study sets the stage for new model-independent search strategies based on global properties of collider data manifolds.",
          "authors": [
            "Raffaele Tito D'Agnolo",
            "Alfredo Glioti",
            "Gabriele Rigo",
            "Alessandro Valenti"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22763",
          "title": "Saturation effects in exclusive vector meson production in DIS",
          "abstract": "We investigate saturation effects in exclusive vector meson production in deep inelastic scattering (DIS), where we model fluctuations within the target protons as localized color-charge hotspots. Based on the Color Glass Condensate (CGC) framework and the dipole picture for vector meson production, we examine the dependencies of coherent and incoherent scattering cross sections on the momentum transfer. We draw conclusions on the effectiveness of our hot spot model and the strength of the suppression of the scattering cross sections caused by saturation effects. We find that saturation has mild effects in the given energy and charge-density ranges, but can also show that suppression becomes more prominent as the color-charge density inside the proton increases.",
          "authors": [
            "Oscar Garcia-Montero",
            "Yannik Hoffmann",
            "Sören Schlichting"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22763",
          "title": "Saturation effects in exclusive vector meson production in DIS",
          "abstract": "We investigate saturation effects in exclusive vector meson production in deep inelastic scattering (DIS), where we model fluctuations within the target protons as localized color-charge hotspots. Based on the Color Glass Condensate (CGC) framework and the dipole picture for vector meson production, we examine the dependencies of coherent and incoherent scattering cross sections on the momentum transfer. We draw conclusions on the effectiveness of our hot spot model and the strength of the suppression of the scattering cross sections caused by saturation effects. We find that saturation has mild effects in the given energy and charge-density ranges, but can also show that suppression becomes more prominent as the color-charge density inside the proton increases.",
          "authors": [
            "Oscar Garcia-Montero",
            "Yannik Hoffmann",
            "Sören Schlichting"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23003",
          "title": "Holographic description of the kaon gravitational form factor",
          "abstract": "We compute the kaon gravitational form factor (GFF) using a bottom-up holographic QCD approach that incorporates SU(3) flavor symmetry breaking through the strange quark mass. We present the resulting Q^2 dependence of the kaon GFF and compare it with that of the pion. In the high-energy limit, the kaon GFF exhibits a 1/Q^2 falloff, in agreement with perturbative QCD. Furthermore, we extract the gravitational radius of the kaon and find it to be almost the same as that of the pion, with a slightly smaller value.",
          "authors": [
            "Zhibo Liu",
            "Akira Watanabe"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00943",
          "title": "Computing nonlinearity ratios using second order black hole perturbation theory",
          "abstract": "We revisit an analytical approximation scheme for computing nonlinearity ratios involving quadratic quasinormal modes (QQNMs). We compute these ratios for the general case when the QQNM is not one of the linear QNMs, for the $(l,m)$ channel $(2,2) \\times (2,2) \\to (4,4)$. We find an excellent match with numerical simulations. We also discuss where and why the method can fail, for example, for the channel $(2,0) \\times (2,0) \\to (2,0)$ where we can only get crude estimates for the nonlinearity ratio. Motivated by recent studies on nonlinear ringdown at the horizon, we also compute the nonlinearity ratios at the horizon. We find that the ratio both at the horizon and infinity is insensitive to different choices of regularization of the source term in the second order perturbations. We also discuss amplitudes of QQNMs sourced by linear overtones. Finally, we discuss the issues that must be resolved within this method to do precision analysis of nonlinear ringdown.",
          "authors": [
            "Jasveer Singh",
            "Vardarajan Suneeta"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01288",
          "title": "Revisiting wideband pulsar timing measurements",
          "abstract": "In the wideband paradigm of pulsar timing, the time of arrival of a pulsar pulse is measured simultaneously with the corresponding dispersion measure from a frequency-resolved integrated pulse profile. We present a new method for performing wideband measurements that rigorously accounts for measurement noise. We demonstrate this method using observations of PSR J2124$-$3358 made as part of the Indian Pulsar Timing Array experiment using the upgraded Giant Metre-wave Radio Telescope, and show that our method produces more realistic measurement uncertainty estimates compared to the existing wideband measurement method.",
          "authors": [
            "Abhimanyu Susobhanan",
            "Avinash Kumar Paladi",
            "Réka Desmecht",
            "Amarnath",
            "Manjari Bagchi",
            "Manoneeta Chakraborty",
            "Shaswata Chowdhury",
            "Suruj Jyoti Das",
            "Debabrata Deb",
            "Shantanu Desai",
            "Churchil Dwivedi",
            "Himanshu Grover",
            "Jibin Jose",
            "Bhal Chandra Joshi",
            "Shubham Kala",
            "Fazal Kareem",
            "Kuldeep Meena",
            "Sushovan Mondal",
            "K Nobleson",
            "Arul Pandian B",
            "Kaustubh Rai",
            "Adya Shukla",
            "Manpreet Singh",
            "Aman Srivastava",
            "Mayuresh Surnis",
            "Hemanga Tahbildar",
            "Keitaro Takahashi",
            "Pratik Tarafdar",
            "Kunjal Vara",
            "Vaishnavi Vyasraj",
            "Zenia Zuraiq"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01350",
          "title": "The Milky Way stellar halo is twisted and doubly broken: insights from DESI DR2 Milky Way Survey observation",
          "abstract": "Using K giants from the second data release (DR2) of the Dark Energy Spectroscopic Instrument (DESI) Milky Way (MW) Survey, we measure the shape, orientation, radial profile, and density anisotropies of the MW stellar halo over 8 kpc$<r_\\mathrm{GC}<200$ kpc. We identify a triaxial stellar halo (axes ratio $10:8:7$), 43 degrees tilted from the disk, showing two break radii at $\\sim16$ kpc and $\\sim76$ kpc, likely associated with Gaia-Sausage/Enceladus (GSE) and Large Magellanic Cloud (LMC), respectively. The inner stellar halo ($<30$ kpc) is oblate and aligned with the disk, whereas the outer stellar halo becomes prolate and perpendicular to the disk, consistent with the Vast Polar Structure of MW satellites. The twisted halo may arise from the disk-halo angular momentum shift triggered by the infall of a massive satellite. The anisotropic density distribution of the stellar halo is also measured, with successful re-identification of the Hercules-Aquila Cloud South/North (HAC-N/-S) and Virgo overdensities (VOD). Break radii are found at 15/30 kpc for VOD/HAC-N(-S). We identify the LMC transient density wake with a break radius at 60 kpc in the Pisces overdensity region. We also find new observational evidence of the LMC collective density wake, by showing a break radius at $\\sim$100 kpc in the northern Galactic cap with a clear density peak at 90 kpc. In the end, we found that more metal-poor halo stars are more radially extended. Our results provide important clues to the assembly and evolution of the MW stellar halo under the standard cosmic structure formation framework.",
          "authors": [
            "Songting Li",
            "Wenting Wang",
            "Sergey E. Koposov",
            "Joao A. S. Amarante",
            "Alis J. Deason",
            "Nathan R. Sandford",
            "Ting S. Li",
            "Gustavo E. Medina",
            "Jaxin Han",
            "Monica Valluri",
            "Oleg Y. Gnedin",
            "Namitha Kizhuprakkat",
            "Andrew P. Cooper",
            "Leandro Beraldo e Silva",
            "Carlos Frenk",
            "Raymond G. Carlberg",
            "Mika Lambert",
            "Tian Qiu",
            "Jessica Nicole Aguilar",
            "Steven Ahlen",
            "Davide Bianchi",
            "David Brooks",
            "Todd Claybaugh",
            "Axel de la Macorra",
            "Peter Doel",
            "Jaime E. Forero-Romero",
            "Enrique Gaztanaga",
            "Satya Gontcho A Gontcho",
            "Gaston Gutierrez",
            "Dick Joyce",
            "Robert Kehoe",
            "Anthony Kremin",
            "Claire Lamman",
            "Martin Landriau",
            "Laurent Le Guillou",
            "Ramon Miquel",
            "Will Percival",
            "Francisco Prada",
            "Ignasi Perez-Rafols",
            "Graziano Rossi",
            "Eusebio Sanchez",
            "David Schlegel",
            "Ray Sharples",
            "Joseph Harry Silber",
            "David Sprayberry",
            "Gregory Tarle",
            "Benjamin Alan Weaver",
            "Hu Zou"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01501",
          "title": "A Unified Framework for N-Dimensional Visualization and Simulation: Implementation and Evaluation including 4D Boolean",
          "abstract": "This study proposes a unified framework for simulation and visualization of intuitive exploration of phenomena in N-dimensional space. While specialized libraries offer powerful geometric algorithms, they typically lack integrated environments for interactive trial and error, creating a barrier for researchers. The contribution of this research is the integration of Quickhull-based mesh generation, visualization via hyperplane slicing, and computationally expensive Boolean operations into a single, extensible platform, while maintaining interactivity. To validate its effectiveness, this paper presents a 4-dimensional implementation and introduces a new interaction design, termed `High-Dimensional FPS,' to enable intuitive high-dimensional exploration. Furthermore, as a case study to demonstrate the framework's high extensibility, I also integrated a non-rigid body physics simulation based on Extended Position Based Dynamics (XPBD). Experimental results confirmed the effectiveness of the proposed method, achieving real-time rendering (80 fps) of complex 4D objects and completing Boolean operations within seconds in a standard PC environment. By providing an accessible and interactive platform, this work lowers the entry barrier for high-dimensional simulation research and enhances its potential for applications in education and entertainment.",
          "authors": [
            "Hirohito Arai"
          ],
          "primary_category": "cs.CG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02050",
          "title": "Massive Spin-2: Field-equations, Propagators, Massless-limit, and Perihelion Precessions",
          "abstract": "This paper presents the quantization of massive and massless spin-2 particles, using the auxiliary field method. The issue, the so-called vDVZ-discontinuity, whether the perihelion precessions for a massive graviton are in agreement with the data, is studied in the context of this spin-2 theory in tree-approximation. In the context of this setting, it is found, that a massive gravitation model with an imaginary scalar ghost, for a small graviton mass is compatible with the perihelion-precession of Mercury, etc..",
          "authors": [
            "Th.A. Rijken",
            "J.W. Wagenaar"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02054",
          "title": "CP-violating non-linear electrodynamics and corrections to blackbody radiation thermal laws",
          "abstract": "Motivated by ideas from effective field theories, we conduct a twofold investigation in CP-violating non-linear electrodynamics models. On the one hand, features related to field equations and wave propagation in the presence of a magnetic background field are evaluated. Interestingly, we show that the CP-violating term in our framework induces a bi-anisotropic behavior of the vacuum. On the other hand, blackbody radiation thermal laws in this situation are studied. Here, we provide a general formalism for photons at low temperature, namely, with $k_{B}T\\ll{m_{e}c^{2}}$. The deviations from standard values of the thermodynamic quantities, such as energy, pressure, entropy, and specific heat, are discussed. In addition, we investigate the modifications in the Planck distribution and the Stefan-Boltzmann law induced by a non-trivial CP-violating parameter.",
          "authors": [
            "L.P.R. Ospedal",
            "R. Turcati",
            "S.B. Duarte"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02067",
          "title": "How Dark is Dark Energy? A Lightcones Comparison Approach",
          "abstract": "We present a geometrical approach that provides a non-perturbative technique, allowing the standard FLRW observer to evaluate a measurable, scale-dependent distance functional between her idealized FLRW past light cone and the actual physical past light cone. From the point of view of the FLRW observer, gathering data from sources at cosmological redshift $\\widehat{z}$, this functional generates a geometry--structure--growth contribution ${\\Omega_\\Lambda(\\widehat{z})}$ to the FLRW cosmological constant ${\\widehat\\Omega_\\Lambda}$. This redshift--dependent contribution erodes the interpretation of ${\\widehat\\Omega_\\Lambda}$ as representing constant dark energy. In particular, ${\\Omega_\\Lambda(\\widehat{z})}$ becomes significantly large at very low $\\widehat{z}$, where structures dominate the cosmological landscape. At the pivotal galaxy cluster scale, where cosmological expansion decouples from the local gravitation dynamics, we get ${\\Omega_\\Lambda(\\widehat{z})/\\widehat\\Omega_\\Lambda}\\,=\\,\\mathscr{O}(1)$, showing that late--epoch structures provide an effective field contribution to the FLRW cosmological constant that is of the same order of magnitude as its assumed value. We prove that ${\\Omega_\\Lambda(\\widehat{z})}$ is generated by a scale-dependent effective field governed by structure formation and related to the comparison between the idealized FLRW past light cone and the actual physical past light cone. These results are naturally framed in the mainstream FLRW cosmology; they do not require exotic fields and provide a natural setting for analyzing the coincidence problem, leading to an interpretative shift in the current understanding of constant dark energy.",
          "authors": [
            "Mauro Carfora",
            "Francesca Familiari"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02067",
          "title": "How Dark is Dark Energy? A Lightcones Comparison Approach",
          "abstract": "We present a geometrical approach that provides a non-perturbative technique, allowing the standard FLRW observer to evaluate a measurable, scale-dependent distance functional between her idealized FLRW past light cone and the actual physical past light cone. From the point of view of the FLRW observer, gathering data from sources at cosmological redshift $\\widehat{z}$, this functional generates a geometry--structure--growth contribution ${\\Omega_\\Lambda(\\widehat{z})}$ to the FLRW cosmological constant ${\\widehat\\Omega_\\Lambda}$. This redshift--dependent contribution erodes the interpretation of ${\\widehat\\Omega_\\Lambda}$ as representing constant dark energy. In particular, ${\\Omega_\\Lambda(\\widehat{z})}$ becomes significantly large at very low $\\widehat{z}$, where structures dominate the cosmological landscape. At the pivotal galaxy cluster scale, where cosmological expansion decouples from the local gravitation dynamics, we get ${\\Omega_\\Lambda(\\widehat{z})/\\widehat\\Omega_\\Lambda}\\,=\\,\\mathscr{O}(1)$, showing that late--epoch structures provide an effective field contribution to the FLRW cosmological constant that is of the same order of magnitude as its assumed value. We prove that ${\\Omega_\\Lambda(\\widehat{z})}$ is generated by a scale-dependent effective field governed by structure formation and related to the comparison between the idealized FLRW past light cone and the actual physical past light cone. These results are naturally framed in the mainstream FLRW cosmology; they do not require exotic fields and provide a natural setting for analyzing the coincidence problem, leading to an interpretative shift in the current understanding of constant dark energy.",
          "authors": [
            "Mauro Carfora",
            "Francesca Familiari"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02067",
          "title": "How Dark is Dark Energy? A Lightcones Comparison Approach",
          "abstract": "We present a geometrical approach that provides a non-perturbative technique, allowing the standard FLRW observer to evaluate a measurable, scale-dependent distance functional between her idealized FLRW past light cone and the actual physical past light cone. From the point of view of the FLRW observer, gathering data from sources at cosmological redshift $\\widehat{z}$, this functional generates a geometry--structure--growth contribution ${\\Omega_\\Lambda(\\widehat{z})}$ to the FLRW cosmological constant ${\\widehat\\Omega_\\Lambda}$. This redshift--dependent contribution erodes the interpretation of ${\\widehat\\Omega_\\Lambda}$ as representing constant dark energy. In particular, ${\\Omega_\\Lambda(\\widehat{z})}$ becomes significantly large at very low $\\widehat{z}$, where structures dominate the cosmological landscape. At the pivotal galaxy cluster scale, where cosmological expansion decouples from the local gravitation dynamics, we get ${\\Omega_\\Lambda(\\widehat{z})/\\widehat\\Omega_\\Lambda}\\,=\\,\\mathscr{O}(1)$, showing that late--epoch structures provide an effective field contribution to the FLRW cosmological constant that is of the same order of magnitude as its assumed value. We prove that ${\\Omega_\\Lambda(\\widehat{z})}$ is generated by a scale-dependent effective field governed by structure formation and related to the comparison between the idealized FLRW past light cone and the actual physical past light cone. These results are naturally framed in the mainstream FLRW cosmology; they do not require exotic fields and provide a natural setting for analyzing the coincidence problem, leading to an interpretative shift in the current understanding of constant dark energy.",
          "authors": [
            "Mauro Carfora",
            "Francesca Familiari"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02067",
          "title": "How Dark is Dark Energy? A Lightcones Comparison Approach",
          "abstract": "We present a geometrical approach that provides a non-perturbative technique, allowing the standard FLRW observer to evaluate a measurable, scale-dependent distance functional between her idealized FLRW past light cone and the actual physical past light cone. From the point of view of the FLRW observer, gathering data from sources at cosmological redshift $\\widehat{z}$, this functional generates a geometry--structure--growth contribution ${\\Omega_\\Lambda(\\widehat{z})}$ to the FLRW cosmological constant ${\\widehat\\Omega_\\Lambda}$. This redshift--dependent contribution erodes the interpretation of ${\\widehat\\Omega_\\Lambda}$ as representing constant dark energy. In particular, ${\\Omega_\\Lambda(\\widehat{z})}$ becomes significantly large at very low $\\widehat{z}$, where structures dominate the cosmological landscape. At the pivotal galaxy cluster scale, where cosmological expansion decouples from the local gravitation dynamics, we get ${\\Omega_\\Lambda(\\widehat{z})/\\widehat\\Omega_\\Lambda}\\,=\\,\\mathscr{O}(1)$, showing that late--epoch structures provide an effective field contribution to the FLRW cosmological constant that is of the same order of magnitude as its assumed value. We prove that ${\\Omega_\\Lambda(\\widehat{z})}$ is generated by a scale-dependent effective field governed by structure formation and related to the comparison between the idealized FLRW past light cone and the actual physical past light cone. These results are naturally framed in the mainstream FLRW cosmology; they do not require exotic fields and provide a natural setting for analyzing the coincidence problem, leading to an interpretative shift in the current understanding of constant dark energy.",
          "authors": [
            "Mauro Carfora",
            "Francesca Familiari"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02068",
          "title": "Modified Entanglement Patterns in Two-Flavor Neutrinos from Quantum-Gravity Interactions",
          "abstract": "In this work, we investigate the influence of quantum gravity induced corrections on the entanglement entropy associated with two flavor neutrino oscillations in vacuum. Using the Von Neumann entropy as a measure of quantum correlations, we analyze how Planck scale suppressed modification implemented through quantum gravity motivated changes in the neutrino dispersion relation affect the evolution of entanglement during successive oscillation cycles. By performing a statistical study over a range of oscillation lengths and neutrino energies, we identify characteristic deviations in the entropy profile arising from quantum gravity effects. Our results suggest that entanglement entropy provides a sensitive probe of small quantum gravity induced departures from standard neutrino oscillation dynamics, highlighting its potential role in testing Planck scale physics within neutrino phenomenology.",
          "authors": [
            "Bipin Singh Koranga",
            "Parnav Kumar",
            "Baktiar Wasir Farooq"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02077",
          "title": "Gravity and the Superposition Principle",
          "abstract": "The relation between gravity and quantum mechanics is investigated in this work. The link is given by the wave packet expansion process, rooted from the Uncertainty Principle. The basic idea is to express the de Broglie wavelength used by Schrodinger for a massive particle in terms of the associated Compton wavelength which is replaced by the Michell-Laplace radius $Gm/c^{2}$ of the spherical object of mass $m\\geq m_{P}$, where $m_{P}$ is the Planck mass. The wave packet spreading is studying in spherical coordinates, having the width $\\sigma(t)$, expressed in terms of $G$ and $c$ instead of $\\hbar$. Therefore, for masses larger than the Planck mass, a faster dispersion rate of $\\sigma(t)$ is obtained, compared to the standard case. The dispersion of the wave packet is observed only by a free falling observer and the process breaks down once the observer hits the surface of the object. Different freely falling observers notice different rates of expansion of the wave packet and the source of gravity is in a quantum superposition. We further confront the Mita formula for the mean energy of the wave packet with the de Broglie-Bohm quantum potential energy when the Schrodinger equation is expressed in the Madelung form.",
          "authors": [
            "Hristu Culetu"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02093",
          "title": "COSMOS-3D: Two obscured X-ray AGNs with hot dust and He I$λ$10830 absorption at z~3",
          "abstract": "We report the discovery of two broad-line X-ray AGNs cid_414 and cid_947 at z~3 that exhibit prominent He I$\\lambda$10830+ Pa$\\gamma$ emission and absorption, identified from the JWST Cycle 3 large GO treasury program COSMOS-3D using NIRCam F444W grism spectroscopy. Additional UV/optical line measurements (e.g., Ly$\\alpha$, Si IV, C IV) come from complementary COSMOS-field spectroscopy. Both sources are robustly detected in the mid-infrared, with detections in MIRI F1000W for both AGNs and an additional detection in MIRI F2100W for cid_414, indicating the presence of hot dust emission. The source cid_947 shows a higher He I$\\lambda$10830 absorption column density and X-ray-inferred $N_{\\rm H}$, and displays strong outflow signatures in He I, Si IV, and C IV with velocity offsets exceeding 5000 km/s. The source cid_414 shows a narrow Ly$\\alpha$ emission line with luminosity $\\log L_{\\rm Ly\\alpha}=42.49\\pm0.01~\\mathrm{erg~s^{-1}}$ and a higher intrinsic 2-10 keV X-ray luminosity. Host-galaxy decomposition and multi-component SED fitting indicate that cid_947 hosts a more massive black hole but lower star formation rate than cid_414. From simplified photoionization modeling, we infer that the dense absorbing gas has a characteristic size comparable to the nuclear broad-line region and is likely kinematically coupled to the obscuration associated with the dust torus. He I$\\lambda$1083 absorption has also been identified in several compact little red dots at similar redshifts. Together with the two AGNs reported here, these findings suggest that dense circumnuclear gas are plausibly prevalent at high redshift and plays an important role in regulating AGN obscuration and black hole--host co-evolution.",
          "authors": [
            "Zi-Jian Li",
            "Siwei Zou",
            "Jianwei Lyu",
            "Jaclyn B. Champagne",
            "Jia-Sheng Huang",
            "Cheng Cheng",
            "Shuqi Fu",
            "Zijian Zhang",
            "Danyang Jiang",
            "Khee-Gan Lee",
            "Feige Wang",
            "Xiaohui Fan",
            "Jinyi Yang",
            "Ruancun Li",
            "Hollis B. Akins",
            "Fuyan Bian",
            "Andreas L. Faisst",
            "Luis C. Ho",
            "Kohei Inayoshi",
            "Linhua Jiang",
            "Xiangyu Jin",
            "Koki Kakiichi",
            "Jeyhan S. Kartaltepe",
            "Zihao Li",
            "Weizhe Liu",
            "Jan-Torge Schindler",
            "Wei Leong Tee"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02094",
          "title": "Photon (Non)Conservation in the Reduced Speed of Light Approximation and How to (Almost) Fix It",
          "abstract": "The \"Reduced Speed of Light\" (RSL) approximation is commonly used to speed up radiative transfer calculations in cosmological simulations. However, it has been shown previously that the RSL approximation leads to photon non-conservation in some regimes. I show that these missing photons can be counted exactly for some numerical schemes. Adding them back into a simulation, however, is a much harder task. I show one example of such a scheme, which achieves sub-percent accuracy on simple tests. Unfortunately, the scheme performs much worse on semi-realistic simulations of cosmic reionization, leading to a faster overlap and significant errors in the point-to-point comparison of the RSL radiation field with the reference simulation that maintains the full speed of light for the radiative transfer.",
          "authors": [
            "Nickolay Y. Gnedin"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02095",
          "title": "The DREAMS Project: Disentangling the Impact of Halo-to-Halo Variance and Baryonic Feedback on Milky Way Satellite Galaxies",
          "abstract": "We analyze the properties of satellite galaxies around 1,024 Milky Way-mass hosts from the DREAMS Project, simulated within a $\\Lambda$CDM cosmology. Utilizing the TNG galaxy-formation model, the DREAMS simulations incorporate both baryonic physics and cosmological uncertainties for a large sample of galaxies with diverse environments and formation histories. We investigate the relative impact of the physical uncertainty from the galaxy-formation model on predicted satellite properties using four metrics: the satellite stellar mass function, radial distribution, inner slope of dark matter density profile, and stellar half-light radius. We compare these predictions to observations from the SAGA Survey and the DREAMS N-body simulations and find that uncertainties from baryonic physics modeling are subdominant to the scatter arising from halo-to-halo variance. Where baryonic modeling does affect satellites, the supernova wind energy has the largest effect on the satellite properties that we investigate. Specifically, increased supernova wind energy suppresses the stellar mass of satellites and results in more extended stellar half-light radii. The adopted wind speed has only a minor impact, and other astrophysical and cosmological parameters show no measurable effect. Our findings highlight the robustness of satellite properties against uncertainties in baryonic physics modeling.",
          "authors": [
            "Jonah C. Rose",
            "Mariangela Lisanti",
            "Paul Torrey",
            "Francisco Villaescusa-Navarro",
            "Alex M. Garcia",
            "Arya Farahi",
            "Carrie Filion",
            "Alyson M. Brooks",
            "Nitya Kallivayalil",
            "Kassidy E. Kollmann",
            "Ethan Lilie",
            "Jiaxuan Li",
            "Olivia Mostow",
            "Akaxia Cruz",
            "Tri Nguyen",
            "Sandip Roy",
            "Andrew B. Pace",
            "Niusha Ahvazi",
            "Stephanie O'Neil",
            "Xuejian Shen",
            "Francis-Yan Cyr-Racine",
            "Adrian M. Price-Whelan",
            "Marla Geha",
            "Lina Necib",
            "Mark Vogelsberger",
            "Julian B. Muñoz",
            "Julianne J. Dalcanton"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02096",
          "title": "Discovery of two little red dots transitioning into quasars",
          "abstract": "James Webb Space Telescope (JWST) has uncovered a new population of compact objects that show a unique V-shaped spectral energy distribution (SED) in the UV and optical wavelength range. These so-called \"little red dots\" (LRDs) often exhibit broad Balmer emission lines, indicative of the presence of active galactic nuclei (AGNs). They generally lack detection of X-ray, radio, and mid-IR radiation, which is fundamentally different from typical AGNs. Various models, including super-Eddington-accreting black holes enshrouded in dense and dust-poor gas, have been proposed to explain these features. However, the nature of LRDs remains debated, and their evolutionary fate is unclear. Here we report two unusual LRDs at redshift z = 2.868 and 2.925 that are in a transitional phase towards typical AGNs. Their V-shaped SEDs, compact optical morphology, and broad emission lines satisfy the defining criteria of LRDs. On the other hand, they exhibit intense X-ray, radio, and mid-IR radiation that is much stronger than previously known LRDs. These hybrid properties suggest that the dense gas envelope around their central black holes is dispersing, allowing high-energy photons and radio emission to escape. Meanwhile, a dust torus is forming. This finding provides a direct insight into the nature of LRDs and indicates that at least some LRDs will evolve into AGNs or quasars at later times.",
          "authors": [
            "Shuqi Fu",
            "Zijian Zhang",
            "Danyang Jiang",
            "Jie Chen",
            "Linhua Jiang",
            "Luis C. Ho",
            "Kohei Inayoshi",
            "Kaiyuan Chen",
            "Jianwei Lyu",
            "Fengwu Sun",
            "Feige Wang",
            "Jinyi Yang"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02097",
          "title": "Unitarizing non-relativistic scattering",
          "abstract": "Unitarity imposes coupled constraints on elastic and inelastic amplitudes. Satisfying them requires resummation of the self-energy contributions from both elastic and inelastic channels. Inelastic channels generate anti-Hermitian contributions that can be consistently deduced from the unitarity relation underlying the optical theorem, leading to non-local separable potentials and a compact unitarization scheme in the non-relativistic regime. We present two alternative derivations of the anti-Hermitian kernel, from the continuity equation and by integrating out inelastic channels. We further extend this framework to treat non-analytic and non-convergent behavior of inelastic amplitudes in the complex momentum plane and to incorporate bound states. For non-convergent amplitudes, we demonstrate a simple renormalization procedure in which anti-Hermitian separable potentials necessarily induce Hermitian separable counterterms, yielding finite cross sections consistent with unitarity. These results provide a general tool for non-relativistic scattering problems, with clear applications to dark-matter phenomenology.",
          "authors": [
            "Marcos M. Flores",
            "Kalliopi Petraki"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02097",
          "title": "Unitarizing non-relativistic scattering",
          "abstract": "Unitarity imposes coupled constraints on elastic and inelastic amplitudes. Satisfying them requires resummation of the self-energy contributions from both elastic and inelastic channels. Inelastic channels generate anti-Hermitian contributions that can be consistently deduced from the unitarity relation underlying the optical theorem, leading to non-local separable potentials and a compact unitarization scheme in the non-relativistic regime. We present two alternative derivations of the anti-Hermitian kernel, from the continuity equation and by integrating out inelastic channels. We further extend this framework to treat non-analytic and non-convergent behavior of inelastic amplitudes in the complex momentum plane and to incorporate bound states. For non-convergent amplitudes, we demonstrate a simple renormalization procedure in which anti-Hermitian separable potentials necessarily induce Hermitian separable counterterms, yielding finite cross sections consistent with unitarity. These results provide a general tool for non-relativistic scattering problems, with clear applications to dark-matter phenomenology.",
          "authors": [
            "Marcos M. Flores",
            "Kalliopi Petraki"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02099",
          "title": "Possible $ν$ Source Class: 3-sigma Detection of High-Energy Neutrinos from Supermassive Black Hole Binary Candidates",
          "abstract": "Identifying the sources of high-energy (TeV-PeV) astrophysical neutrinos is crucial for studies in both astrophysics and particle physics. Despite extensive searches for more than a decade, which revealed several individual potential sources and only one potential source class, the origins of these neutrinos remain largely unresolved; thus, more source classes should be investigated. In this work, we conduct the first search for high-energy neutrino emission from a new source class, supermassive black hole binaries (SMBHBs), which are also theoretically motivated. We perform an unbinned maximum-likelihood-ratio analysis on our constructed catalog of 693 SMBHB candidates and 10 years of IceCube public data. Our results show positive correlations, with higher significance in more physically motivated scenarios and the highest significance at 3.0$\\sigma$. In addition, we also study potential connections between SMBHBs' high-energy neutrino and nano-Hz gravitational-wave emissions, the latter being the main target of pulsar timing arrays. Our results provide the first evidence of SMBHBs being high-energy neutrino emitters.",
          "authors": [
            "Pugazhendhi A D",
            "Subhadip Bouri",
            "Bei Zhou",
            "Rachana",
            "Ranjan Laha"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02101",
          "title": "Do neutrinos dream in 5D? Towards a comprehensive extra-dimensional neutrino phenomenology",
          "abstract": "This paper provides a comprehensive overview of neutrino masses and mixing in Large Extra Dimension scenarios, focusing on the phenomenological impact of a five-dimensional (5D) bulk fermion. In a flat extra dimension compactified on an $S^1/\\mathbb{Z}_2$ orbifold, this fermion manifests as a Kaluza-Klein tower of right-handed neutrinos in the 4D effective theory. We systematically investigate four distinct scenarios for mass generation, considering both Dirac and Majorana mass terms originating from either the bulk or the 3-brane. For each case, we analyse the consequences for neutrino oscillations in a vacuum and in matter, deriving the resulting mass spectra and mixing patterns. By comparing these theoretical predictions with experimental data, we explore the constraints on the large extra dimensions' parameters.",
          "authors": [
            "Arturo de Giorgi",
            "Dhruv Pasari",
            "Jessica Turner"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02104",
          "title": "Momentum entanglement at colliders: the $H \\to WW,ZZ$ case",
          "abstract": "We address momentum entanglement in Higgs decays to weak boson pairs, $H \\to WW,ZZ$, by discretising momentum space. The momenta of the two weak bosons are entangled, as well as the degrees of freedom in momentum and spin spaces. For $H \\to ZZ$ in the four-lepton final state, we also estimate the statistical sensitivity of entanglement measures at the Large Hadron Collider and future upgrades. The discretisation method introduced here is broadly applicable, offering a framework for studies of momentum entanglement at the energy frontier.",
          "authors": [
            "J. A. Aguilar-Saavedra"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02104",
          "title": "Momentum entanglement at colliders: the $H \\to WW,ZZ$ case",
          "abstract": "We address momentum entanglement in Higgs decays to weak boson pairs, $H \\to WW,ZZ$, by discretising momentum space. The momenta of the two weak bosons are entangled, as well as the degrees of freedom in momentum and spin spaces. For $H \\to ZZ$ in the four-lepton final state, we also estimate the statistical sensitivity of entanglement measures at the Large Hadron Collider and future upgrades. The discretisation method introduced here is broadly applicable, offering a framework for studies of momentum entanglement at the energy frontier.",
          "authors": [
            "J. A. Aguilar-Saavedra"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02104",
          "title": "Momentum entanglement at colliders: the $H \\to WW,ZZ$ case",
          "abstract": "We address momentum entanglement in Higgs decays to weak boson pairs, $H \\to WW,ZZ$, by discretising momentum space. The momenta of the two weak bosons are entangled, as well as the degrees of freedom in momentum and spin spaces. For $H \\to ZZ$ in the four-lepton final state, we also estimate the statistical sensitivity of entanglement measures at the Large Hadron Collider and future upgrades. The discretisation method introduced here is broadly applicable, offering a framework for studies of momentum entanglement at the energy frontier.",
          "authors": [
            "J. A. Aguilar-Saavedra"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02106",
          "title": "JCMT Constraints on the Early-Time HCN and CO Emission and HCN Temporal Evolution of 3I/ATLAS",
          "abstract": "Interstellar objects (ISOs), particularly those with cometary activity, provide unique insight into the primordial physical and chemical conditions present during the formation of the planetary system in which they originated. Observations in the sub-mm regime allow for direct measurements of several parent molecules released from the comet nucleus into the coma. Here we present observations of the third ISO, 3I/ATLAS, with the `Ū`ū heterodyne receiver on the James Clerk Maxwell Telescope (JCMT), which targeted emission from HCN($J = 3 - 2$) and CO($J = 2 - 1$). Our observations, taken between 16 July 2025 and 21 July 2025 (UT), when 3I/ATLAS was at a heliocentric distance between 4.01 and 3.84 au, provide the earliest sub-mm constraints on its activity. We do not detect HCN or CO in these epochs, with 3$\\sigma$ upper-limits on the production rates of $Q(HCN) < 1.7 \\times 10^{24}$ s$^{-1}$ at $r_h = 4.01 - 3.97$ au and $Q(CO) < 1.1 \\times 10^{27}$ s$^{-1}$ at $r_h = 3.94 - 3.84$ au, respectively. We combine this HCN limit with later JCMT observations of HCN to constrain its temporal evolution. Fitting the HCN detections with a $Q(HCN) \\propto r_h^{-n}$ model and accounting for the upper-limits yields $n = 12.7^{+6.9}_{-2.5}$. This slope is steeper than those of typical Solar System comets, but consistent with the production rate slopes measured for other species in the coma of 3I/ATLAS.",
          "authors": [
            "Jason T. Hinkle",
            "Bin Yang",
            "Karen J. Meech",
            "Andrew Hoffman",
            "Benjamin J. Shappee",
            "W. B. Hoogendam",
            "James J. Wray"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02108",
          "title": "The Dependence of Earth Milankovitch Cycles on Martian Mass",
          "abstract": "The Milankovitch cycles of Earth result from gravitational interactions with other bodies in the Solar System. These interactions lead to slow changes in the orbit and angular momentum vector of Earth, and correspondingly influence Earth's climate evolution. Several studies have shown that Mars may play a significant role in these Milankovitch cycles, such as the 2.4 Myr eccentricity cycle related to perihelion precession dynamics. Here we provide the results of a detailed dynamical analysis that explores the Earth Milankovitch cycles as a function of the Martian mass to quantify the extent that Mars influences variations in Earth's orbital eccentricity, the longitude of perihelion, the longitude of the ascending node, and obliquity (axial tilt). Our results show that, although the 405 kyr long-eccentricity metronome driven by $g_2$ (Venus) and $g_5$ (Jupiter) persists at all Mars masses, the $\\sim$100 kyr short-eccentricity bands driven by $g_4$ (Mars) lengthen and gain power as Mars becomes more massive, consistent with enhanced coupling among inner-planet $g$-modes. The 2.4 Myr grand cycle is absent when Mars approaches zero mass, reflecting the movement of $g_4$ with the Martian mass. Meanwhile, Earth's obliquity cycles driven by $s_3$ (Earth) and $s_4$ (Mars) lengthen from the canonical $\\sim$41 kyr with increasing Mars mass, relocating to a dominant 45--55 kyr band when the mass of Mars is an order of magnitude larger than its present value. These results establish how Mars' mass controls the architecture of Earth's climate-forcing spectrum and that the Milankovitch spectrum of an Earth-like planet is a sensitive, interpretable probe of its planetary neighborhood.",
          "authors": [
            "Stephen R. Kane",
            "Pam Vervoort",
            "Jonathan Horner"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02109",
          "title": "Cosmic chronometers with galaxy clusters: a new avenue for multi-probe cosmology",
          "abstract": "We provide a new measurement of the expansion history of the Universe at $z=0.54$ with the cosmic chronometers (CC) method, exploiting the high-quality spectroscopic VLT/MUSE data for three galaxy clusters in close-by redshift bins: SDSS J2222+2745 ($z=0.49$), MACS J1149.5+2223 ($z=0.54$), and SDSS J1029+2623 ($z=0.59$). The central one, MACS J1149.5+2223, hosts the well-known supernova 'Refsdal', which allowed for $H_0$ measurements via time delay cosmography (TDC). This represents the first step for a self-consistent probe combination, where different methods are applied to the same data sample. After selecting the most passive and massive cluster members (38 CCs), we derive their age and physical parameters via full spectrum fitting. We use the code Bagpipes, specifically modified to remove the cosmological prior on ages. On average, the CC sample shows super-solar metallicities $Z/Z_{\\odot} = 1.3 \\pm 0.7$, low dust extinction $A_{\\rm{V}} = 0.3 \\pm 0.3$ mag and to have formed in short bursts $\\tau = 0.6 \\pm 0.2$ Gyr. We also observe both an ageing trend in redshift and a mass-downsizing pattern. From the age-redshift trend, implementing the CC method through a bootstrap approach, we derive a new $H(z)$ measurement: $H$($z$=0.542) = $66_{-29}^{+81}$ (stat) $\\pm$13 (syst) km/s/Mpc. We also simulate the impact of increased statistics and extended redshift coverage, finding that $H$($z$) uncertainties can be reduced by up to a factor of 4 with $\\sim$100 CCs and a slightly broader redshift range (d$z\\sim$0.2).",
          "authors": [
            "E. Tomasetti",
            "M. Moresco",
            "G. Granata",
            "M. D'Addona",
            "P. Bergamini",
            "C. Grillo",
            "A. Mercurio",
            "P. Rosati",
            "A. Cimatti",
            "L. Tortorelli",
            "S. Schuldt",
            "M. Meneghetti"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02110",
          "title": "Exceptional Points and Resonance in Black Hole Ringdown",
          "abstract": "We propose an exceptional-point (EP) framework for black-hole ringdown beyond the standard quasinormal-mode (QNM) paradigm. It provides a first-principles characterization of the resonance associated with avoided crossings near EPs, an effect that conventional QNM analysis cannot fully capture. Employing a phenomenological environmental black-hole model with the hyperboloidal framework, we identify near-coalescence of both QNM eigenvalues and eigenfunctions, and directly demonstrate that the resonance produces enhanced mode contributions in the time domain, resulting in characteristic departures from exponentially damped oscillations. Our formulation further reveals that the EP frequency, given by the averaged value of the resonant modes, emerges as the physically relevant observable in the near-EP regime, and offers a robust foundation for modeling and extracting resonant ringdown signals.",
          "authors": [
            "Rodrigo Panosso Macedo",
            "Takuya Katagiri",
            "Kei-ichiro Kubota",
            "Hayato Motohashi"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02111",
          "title": "Assessing uncertainties in the determination of the trilinear Higgs self-coupling from single-Higgs observables",
          "abstract": "Circular $e^{+}e^{-}$ colliders operating at energies below the di-Higgs production threshold can provide information on the trilinear Higgs self-coupling $\\lambda_{hhh}$ via its loop contributions to single Higgs production processes and electroweak precision observables. We investigate how well a non-SM value of $\\lambda_{hhh}$ can be determined indirectly via its loop contributions within a global EFT fit. Using an inert doublet extension of the SM Higgs sector as an example for a scenario of physics beyond the SM that could be realised in nature, we find that theoretical uncertainties related to the treatment of loop contributions and the truncation of the EFT expansion, which are usually neglected, play an important role in determining the sensitivity to $\\lambda_{hhh}$ in a global fit. The results obtained from such an indirect determination of $\\lambda_{hhh}$ without taking these additional uncertainties into account would be too optimistic, leading to an artificially high resulting precision for $\\lambda_{hhh}$. They could therefore be misleading in the quest to precisely identify the underlying physics of electroweak symmetry breaking.",
          "authors": [
            "Henning Bahl",
            "Philip Bechtle",
            "Johannes Braathen",
            "Sven Heinemeyer",
            "Jenny List",
            "Murillo Vellasco",
            "Georg Weiglein"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02113",
          "title": "Slow-Light Effect in the Jet-Launching Region of M87",
          "abstract": "We explore the impact of \"slow-light\" radiative transfer - i.e., general relativistic radiative transfer (GRRT) calculations in which the simulated fluid evolves while light rays are propagating through it - in general relativistic magnetohydrodynamic (GRMHD) models of the M87 jet. Because the plasma in the jet-launching region is accelerated to relativistic velocities, and because the jet in M87 is nearly aligned with the line of sight (offset by ~17 degrees), a slow-light treatment is important for accurately modeling the observable structure. While fast-light images exhibit prominent helical or loop-shaped features in the jet - which we associate with narrow bundles of magnetic field lines - these features become stretched and smoothed-out in slow-light images. Our slow-light images instead exhibit a double-edged, cone-like morphology that is more consistent with observations of M87 than corresponding fast-light images. We find that the radius at which the plasma transitions from sub-relativistic to relativistic velocities is imprinted on slow-light images via a transition from loop-dominated at small distances from the black hole to edge-dominated at a larger distance, with the loop-edge transition occurring at larger distances for lower black hole spins. The jet image dynamics also vary with black hole spin, with low-spin models producing jets that exhibit substantial \"wobbling\", while high-spin models produce jets that are straighter and more stable in time. The spin-dependent jet morphology and variability are revealed by slow-light imaging because slow-light effects become more enhanced as the plasma velocity becomes more relativistic, and because the plasma acceleration is itself a strong function of the spin.",
          "authors": [
            "Yuh Tsunetoe",
            "Dominic W. Pesce",
            "Ramesh Narayan"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02114",
          "title": "Image simulations of highly magnified clumpy galaxies",
          "abstract": "We present ClumPyLen, a Python-based simulator designed to produce realistic mock observations of strongly lensed, high-redshift, clumpy star-forming galaxies. The tool models galaxy components such as disks, bulges, and spiral arms using Sérsic profiles, and it populates them with stellar clumps whose properties are sampled from physically motivated distributions. ClumPyLen includes the effects of gravitational lensing through user-provided deflection angle maps and simulates realistic observational conditions by accounting for instrumental effects, Point-Spread-Function convolution, sky background, and photon noise. The simulator can support a wide range of filters and instruments; here we focus on HST/ACS, HST/WFC3-IR, and JWST/NIRCam. We demonstrate the capabilities of the code through two examples, including a detailed simulation of the z = 6.145 source Cosmic Archipelago lensed by MACS J0416.1-2403. The simulated images closely match the morphology and limiting magnitudes of real observations. ClumPyLen is designed to explore the detectability of stellar clumps in terms of mass and size, especially in the low-mass regime, and it allows the study of clump blending effects. Thanks to its modular design, the code is highly adaptable to a wide range of scientific goals, including lensing studies, galaxy evolution, and the generation of synthetic datasets for machine learning or forward modeling applications.",
          "authors": [
            "Irene Mini",
            "Massimo Meneghetti",
            "Matteo Messa",
            "Lauro Moscardini",
            "Eros Vanzella",
            "Pietro Bergamini",
            "Piero Rosati",
            "Anita Zanella"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02115",
          "title": "Determining the Milky Way gravitational potential without selection functions",
          "abstract": "Selection effects, such as interstellar extinction and varying survey depth, complicate efforts to determine the gravitational potential - and thus the distribution of baryonic and dark matter - throughout the Milky Way galaxy using stellar kinematics. We present a new variant of the \"Deep Potential\" method of determining the gravitational potential from a snapshot of stellar positions and velocities that does not require any modeling of spatial selection functions. Instead of modeling the full six-dimensional phase-space distribution function $f\\left(\\vec{x},\\vec{v}\\right)$ of observed kinematic tracers, we model the conditional velocity distribution $p\\left(\\vec{v}\\mid\\vec{x}\\right)$, which is unaffected by a purely spatial selection function. We simultaneously learn the gravitational potential $\\Phi\\left(\\vec{x}\\right)$ and the underlying spatial density of the entire tracer population $n\\left(\\vec{x}\\right)$ - including unobserved stars - using the collisionless Boltzmann equation under the stationarity assumption. The advantage of this method is that unlike the spatial selection function, all of the quantities we model, $p\\left(\\vec{v}\\mid\\vec{x}\\right)$, $\\Phi\\left(\\vec{x}\\right)$, and $n\\left(\\vec{x}\\right)$, typically vary smoothly in both position and velocity. We demonstrate that this \"conditional\" Deep Potential method is able to accurately recover the gravitational potential in a mock dataset with a complex three-dimensional dust distribution that imprints fine angular structure on the selection function. Because we do not need to model the spatial selection function, our new method can effectively scale to large, complex datasets while using relatively few parameters, and is thus well suited to Gaia data.",
          "authors": [
            "Taavet Kalda",
            "Gregory Green"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02116",
          "title": "Hidden in Plain Sight II: Characterizing the luminous companion to Kappa Velorum with VLTI/GRAVITY",
          "abstract": "Kappa Velorum (Markeb, HD 81188) is one of the brightest stars in the Southern sky and has long been known to be a single-lined spectroscopic binary. The binary mass function is large, $f(M)=1.15\\ M_\\odot$, suggesting that the bright (V=2.5) B2IV star may host a dark, compact object companion. We use VLTI GRAVITY observations to definitively test this possibility by directly resolving the binary. We detect a main sequence B star companion and rule out the compact object scenario. By combining the relative astrometric orbit and archival radial velocities, we report an updated precise characterization of the orbit (period $P=116.795\\pm0.002$ d, eccentricity $e=0.1764\\pm0.0004$, inclination $i=74.04\\pm0.01^{\\circ}$) and estimate the masses of the B stars. Using the original Hipparcos parallax measurement $\\varpi = 6.05\\pm0.48$ mas, we find $M_1 = 10^{+4}_{-2}\\ M_\\odot$ and $M_2 = 6.9\\pm1.0\\ M_\\odot$. The uncertainties on the masses are primarily driven by the uncertain parallax, which we find is likely biased by the orbital motion. We use an archival UVES spectrum and MIST evolutionary tracks to refine our mass estimates. Finally, we discuss how interferometry and high-contrast imaging may be used to characterize other candidate star+compact object binaries, including those that will be discovered with Gaia DR4, as part of a larger effort to uncover the hidden population of black holes in the Milky Way.",
          "authors": [
            "D. M. Rowan",
            "S. Kraus",
            "Todd A. Thompson"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02117",
          "title": "VENUS: When Red meets Blue -- A multiply imaged Little Red Dot with an apparent blue companion behind the galaxy cluster Abell 383",
          "abstract": "We report the discovery of a doubly-imaged Little Red Dot (LRD) candidate behind the galaxy cluster Abell 383, which we dub A383-LRD1. Initially classified as a dropout galaxy in HST imaging with several ground-based emission line detections placing it at $z_{\\mathrm{spec}}=6.027$, new JWST/NIRCam observations taken as part of the cycle 4 VENUS survey now reveal that the source consists of two underlying components: A red point-source with a V-shaped SED consistent with LRD selection criteria, and a nearby ($\\sim 380$ pc) compact blue companion which was the main contributor to the previous rest-frame UV detections. Based on lensing symmetry and its SED, the LRD appears to lie at a similar redshift as well. The magnification of the two images of A383-LRD1 is $\\mu_{\\mathrm{A}}=16.2\\pm1.2$ and $\\mu_\\mathrm{B}=9.0\\pm0.6$, respectively, and the predicted time delay between them is $\\Delta t_{\\mathrm{grav}}=5.20\\pm0.14$ yr ($\\sim0.7$ yr in the rest-frame). After correcting for the lensing magnification, we derive an absolute magnitude of $M_{\\mathrm{UV,LRD}}=-16.8\\pm 0.3$ for the LRD, and $M_{\\mathrm{UV,BC}}=-18.2\\pm 0.2$ for the blue companion. We perform SED fits to both components, revealing the LRD to be best fitted with a black hole star (BH*) model and a substantial host galaxy, and the blue companion with an extremely young, emission-line dominated star-forming nebula. A383-LRD1 represents the second known multiply-imaged LRD detected to date, following A2744-QSO1, and to our knowledge, the first LRD system with a confirmed detection of [C $_{II}$]$\\lambda158 \\ \\mu$m emission from ALMA observations. Thanks to lensing magnification, this system opens a unique door to study the relation between a LRD, its host galaxy, and its environment, and represents a prime candidate for deep JWST spectroscopy and high-resolution ALMA follow-up observations.",
          "authors": [
            "Miriam Golubchik",
            "Lukas J. Furtak",
            "Joseph F. V. Allingham",
            "Adi Zitrin",
            "Hollis B. Akins",
            "Vasily Kokorev",
            "Seiji Fujimoto",
            "Abdurro'uf",
            "Ricardo O. Amorín",
            "Franz E. Bauer",
            "Rachel Bezanson",
            "Marusa Bradač",
            "Larry D. Bradley",
            "Gabriel B. Brammer",
            "John Chisholm",
            "Dan Coe",
            "Christopher J. Conselice",
            "Pratika Dayal",
            "Miroslava Dessauges-Zavadsky",
            "Jose M. Diego",
            "Andreas L. Faisst",
            "Qinyue Fei",
            "Henry C. Ferguson",
            "Steven L. Finkelstein",
            "Brenda L. Frye",
            "Mauro González-Otero",
            "Jenny E. Greene",
            "Yuichi Harikane",
            "Tiger Yu-Yang Hsiao",
            "Kohei Inayoshi",
            "Yolanda Jiménez-Teja",
            "Kirsten Knudsen",
            "Anton M. Koekemoer",
            "Ivo Labbé",
            "Ray A. Lucas",
            "Georgios E. Magdis",
            "Jorryt Matthee",
            "Matteo Messa",
            "Rohan P. Naidu",
            "Minami Nakane",
            "Gaël Noirot",
            "Richard Pan",
            "Casey Papovich",
            "Johan Richard",
            "Massimo Ricotti",
            "Luke Robbins",
            "Daniel P. Stark",
            "Fengwu Sun",
            "Tommaso Treu",
            "Roberta Tripodi",
            "Eros Vanzella",
            "Chris Willott",
            "Rogier A. Windhorst"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02118",
          "title": "SEAMLESS Survey: Four Faint Dwarf Galaxies Tracing Low-Mass Galaxy Evolution Across Environments",
          "abstract": "We report on four Local Volume dwarf galaxies identified through our ongoing SEmi-Automated Machine LEarning Search for Semi-resolved galaxies (SEAMLESS): Hydrus A, LEDA 486718, Cetus B, and Sculptor 26, with the discovery of Hydrus A reported here for the first time. These four galaxies span a wide range of environments and evolutionary states. Hydrus A (MV = -9.39+/-0.20, D = 3.38-0.30+0.32 Mpc) and LEDA 486718 (MV = -11.62+/-0.08, D = 4.80+/-0.17 Mpc) are among the most isolated dwarfs known within 5 Mpc, while Cetus B (MV = -8.26+/-0.17, D = 3.32-0.23+0.25 Mpc) and Sculptor 26 (MV = -11.25+/-0.10, D =3.21+/-0.13 Mpc) lie < 2 Rvir of NGC 253. Hydrus A shows properties consistent with quenching driven by cosmic reionization, cosmic-web interactions, or internal feedback. LEDA 486718 is an isolated star forming dwarf. Cetus B appears quenched and morphologically disturbed, making it a low-mass satellite or backsplash candidate, while Sculptor 26 is red and seemingly gas-poor but displays signs of recent activity, consistent with a transitional evolutionary state. Together, these systems demonstrate the power of SEAMLESS for building a census of faint galaxies beyond the Local Group.",
          "authors": [
            "Catherine E. Fielder",
            "Michael G. Jones",
            "David J. Sand",
            "Denija Crnojevic",
            "Burcin Mutlu-Pakdil",
            "Paul Bennet",
            "Amandine Doliva-Dolinsky",
            "Richard Donnerstein",
            "Laura Congreve Hunter",
            "Ananthan Karunakaran",
            "Donghyeon J. Khim",
            "Deepthi S. Prabhu",
            "Kristine Spekkens",
            "Dennis Zaritsky"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02122",
          "title": "Untangling the Sources of Abundance Dispersion in Low-metallicity Stars II: Neutron Capture Elements",
          "abstract": "We present the abundances of 23 elements, including 11 heavy elements (Cu, Zn, Sr, Y, Zr, Ba, La, Ce, Nd, Sm, Eu) for up to 86 metal-poor (-2 < [Fe/H] < -1) subgiants. We use KORG, a state of the art spectral synthesis package, to derive 1D-LTE abundances from high-SNR and high-resolution spectra taken by the Large Binocular Telescope with the Potsdam Echelle Polarimetric and Spectroscopic Instrument. These precise spectra and abundance measurements minimize the impact of photon-noise (<0.06 dex), allowing us to robustly measure the intrinsic abundance scatter in [X/Fe]. After removing two stars with exceptional s-process enhancement, we find that the intrinsic scatter among the s- and r-process elements tends to be larger than for the lighter elements, with heavy element scatter ranging from 0.11 (Zn) to 0.27 (Eu) dex. Intrinsic abundance scatter could have multiple origins, including star-to-star variations in the ratios of nucleosynthetic sources as well as stochastic sampling of the progenitor supernovae properties, such as mass, rotation, and magnetic field strength. We explore the expected abundance scatter signature caused by stochastic sampling, finding that a fraction of both rapidly rotating CCSN and magnetorotationally driven SN are needed to reach the observed abundances and intrinsic scatter. This analysis is limited by the restrictive parameter spaces spanned by existing yield sets. A diverse, finely sampled grid of supernovae yields is needed to robustly model stochastic abundance scatter.",
          "authors": [
            "Emily J. Griffith",
            "Marissa Blum",
            "David H. Weinberg",
            "Jennifer A. Johnson",
            "Tawny Sit",
            "Ilya Ilyin",
            "Klaus G. Strassmeier"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02124",
          "title": "Kinematics of young stellar objects in NGC 2024 based on infrared proper motions",
          "abstract": "The most recently formed young stellar objects (YSOs) in active star forming regions are excellent tracers of their parent cloud motion. Their positions and dynamics provide insight into cluster formation and constrain kinematic decoupling timescales between stars and gas. However, because of their strong extinction and young age, embedded YSOs are mainly visible at infrared wavelengths and thus absent from astrometric surveys such as Gaia. We measured the proper motions of 6,769 sources toward the NGC 2024 cluster in the Flame Nebula using multi-epoch near-infrared observations from three ESO public surveys: VISIONS, VHS, and the VISTA/VIRCAM science verification program. Cross-validation of our results with Gaia using optically visible stars shows excellent agreement, with uncertainties on the same order of magnitude. For 362 YSO candidates identified from the literature, we derived proper motions on the order of <5 mas/yr with mean measurement uncertainties of ~0.22 mas/yr. This is the first homogeneous proper motion measurement of this quality for more than half of these stars. For Class I and flat-spectrum sources, our results provide a >13-fold increase in available proper motion measurements. We analyzed the positional and kinematic differences between YSO classes and confirmed a previously reported inside-out age segregation from younger to older stars, likely driven by an outward movement of older stars. No evidence of prolonged hierarchical assembly was found. Instead, the results support a rapid (<1 Myr) cluster collapse. This scenario also accounts for the observed slightly higher 1D velocity dispersion of Class I sources relative to Class flat objects. YSO radial velocities generally align with the gas velocities measured from 12CO(3-2), HNC(1-0), HCN(1-0), and show a weaker correlation with N_2H+(1-0). Some Class II and III objects appear to be already decoupling.",
          "authors": [
            "Alena Rottensteiner",
            "Monika G. Petr-Gotzens",
            "Stefan Meingast",
            "João Alves",
            "Emmanuel Bertin",
            "Hervé Bouy",
            "Martin Piecka",
            "Sebastian Ratzenböck",
            "Andrea Socci"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02125",
          "title": "A value-added catalogue of neural network-based europium abundances for GALAH DR4",
          "abstract": "The rapid neutron-capture ($r$-process) element europium (Eu) is a valuable tracer of neutron star mergers and other rare nucleosynthetic events. The stellar spectroscopic survey GALAH's unique wavelength range and setup include the Eu absorption feature at $\\sim6645$ Å for almost a million stars in the most recent Data Release 4 (DR4). However, DR4 also saw a decreased precision in reported Eu measurements compared to previous data releases. In this work, we use a convolutional neural network (CNN) to perform label transfer, wherein we use the GALAH DR4 spectra and stellar parameters to infer DR3 [Eu/H] abundances. This CNN is then applied to DR4 spectra without corresponding DR3 Eu abundances to develop a new, publicly available catalogue of [Eu/H] values for high signal-to-noise targets. We include [Eu/H] predictions for $118\\,946$ stars, out of which $54\\,068$ giants constitute our \"golden sample\" of high-confidence predictions, which pass stricter quality cuts and have a reported precision $\\lesssim0.1$. To overcome the scarcity of training data in the low metallicity regime, we provide an additional catalogue of [Eu/H] abundances for metal poor ($\\mathrm{[Fe/H]}<-1$) stars derived from synthesis of the Eu feature. Our \"golden sample\" can be combined with [Eu/H] values from GALAH DR3 to create a catalogue of over $100\\,000$ vetted, high-quality abundances on a homogeneous scale. Moreover, we are able to reproduce known science results, including the elevated Eu abundances of accreted stars and previously observed Galactic chemical evolution trends. This catalogue represents one of the largest available samples of [Eu/H] abundances for high signal-to-noise targets.",
          "authors": [
            "Sarah G. Kane",
            "Zofia Kaczmarek",
            "Andrew Garner",
            "Sven Buder",
            "Stephanie Monty",
            "Elana Kane"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02126",
          "title": "OASIS Survey Direct Imaging and Astrometric Discovery of HIP 71618 B: A Substellar Companion Suitable for the Roman Coronagraph Technology Demonstration",
          "abstract": "We present the OASIS survey program discovery of a substellar companion orbiting the young A1V star HIP 71618, detected using precision astrometry from \\textit{Gaia and Hipparcos} and high-contrast imaging with SCExAO/CHARIS and Keck/NIRC2. Atmospheric modeling favors a spectral type of M5--M8 and a temperature of $\\sim$2700 $\\pm$ 100 $K$. Dynamical modeling constrains HIP 71618 B's mass to be ${60}_{-21}^{+27}$ $M_{\\rm Jup}$ or ${65}_{-29}^{+54}$ $M_{\\rm Jup}$, depending on the adopted companion mass prior. It has a nearly edge-on, 11 au-orbit with a high eccentricity. HIP 71618 B will be located within Roman Coronagraph's dark hole region during the instrument's technological demonstration phase. A high signal-to-noise ratio detection of HIP 71618 B at 575 nm would demonstrate a 5-$\\sigma$ contrast of 10$^{-7}$ or better. The system is also located within or very close to Roman's Continuous Viewing Zone -- near multiple candidate reference stars for dark-hole digging -- and its primary is bright ($V$ $\\approx$ 5). The suitability of HIP 71618 as one potential Roman Coronagraph target for demonstrating the instrument's core requirement (TTR5) should motivate the timely, deep vetting of candidate reference stars.",
          "authors": [
            "Mona El Morsy",
            "Thayne Currie",
            "Brianna Lacy",
            "Taylor L. Tobin",
            "Qier An",
            "Yiting Li",
            "Ziying Gu",
            "Masayuki Kuzuhara",
            "Danielle Bovie",
            "Dillon Peng",
            "Jeffrey Chilcote",
            "Olivier Guyon",
            "Timothy D. Brandt",
            "Robert J. De Rosa",
            "Vincent Deo",
            "Tyler D. Groff",
            "Markus Janson",
            "N. Jeremy Kasdin",
            "Julien Lozi",
            "Christian Marois",
            "Bertrand Mennesson",
            "Naoshi Murakami",
            "Eric Nielsen",
            "Sabina Sagynbayeva",
            "Nour Skaf",
            "William Thompson",
            "Motohide Tamura",
            "Taichi Uyama",
            "Sébastien Vievard",
            "Alice Zurlo"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02127",
          "title": "Ripples in the baryon to dark matter ratio in $Λ$CDM: implications for galaxy formation",
          "abstract": "We use the FLAMINGO galaxy formation model to quantify the impact of baryon-CDM isocurvature perturbations on galaxy formation in $\\Lambda$CDM. In linear theory, these perturbations represent local, compensated variations in the ratio between the baryon and CDM densities; they freeze in amplitude at late times, with an RMS amplitude of $1.5\\%$ on the Lagrangian scale of a $10^{11}\\,\\rm M_\\odot$ halo ($0.85\\, \\rm{Mpc}$). Although such perturbations arise naturally within $\\Lambda$CDM, most cosmological simulations and semi-analytic models to date omit them. These perturbations are strongly anti-correlated with the matter overdensity field such that halos form with baryon fractions below the cosmic mean, with earlier-collapsing halos exhibiting stronger baryonic suppression. To isolate the galaxy response, we analyse three hydrodynamical simulations with identical initial matter overdensity fields that: i) include isocurvature modes, ii) omit them, or iii) invert their amplitude. At $z=8$, isocurvature perturbations reduce the mean baryon fraction and star formation rates of resolved halos by $ 5\\%$ and $ 12\\%$, respectively, relative to the null-isocurvature case. These effects are almost independent of halo mass and diminish steadily with time, reaching $ 0.1\\%$ and $ 1\\%$ by $z=0$. We develop a model based on spherical collapse that accurately reproduces the mean baryon fraction suppression. As high-redshift observations become increasingly routine, incorporating isocurvature perturbations into simulations and semi-analytic models will be important for robust predictions of early galaxy and black hole formation in the JWST era.",
          "authors": [
            "Owen Jessop",
            "Adrian Jenkins",
            "Andrew Pontzen",
            "Joop Schaye",
            "Matthieu Schaller",
            "John C. Helly"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02128",
          "title": "Vacuum Structure of the BNT Model of Neutrino Mass Generation",
          "abstract": "We analyze the vacuum structure of the Babu--Nandi--Tavartkiladze (BNT) model of neutrino mass generation, in which the Standard Model is extended by an $SU(2)_L$ scalar quadruplet with hypercharge $Y=3/2$ and a vector-like $SU(2)_L$ triplet fermion with $Y=1$, generating neutrino masses via an effective dimension-seven operator. We delineate the theoretical constraints on the model, requiring the scalar potential to be bounded from below in all field directions, ensuring perturbative unitarity of scattering amplitudes, and demanding that the electroweak vacuum corresponds to the global minimum of the potential. We find that the electroweak vacuum is not generically guaranteed to be the global minimum: several charge-breaking stationary points may coexist with -- and potentially lie below -- it in potential depth. For the electroweak-like vacuum with vanishing quadruplet expectation value, the condition of global stability reduces to two simple mass inequalities involving the doubly- and triply-charged scalars. In contrast, for the general electroweak vacuum with nonzero doublet and quadruplet expectation values -- compatible with neutrino-mass generation -- no comparably simple analytic condition emerges, and the stability must be assessed for each specific choice of scalar couplings. Nonetheless, by combining the analytic condition governing the relative depth of the two electroweak stationary points with the mass inequalities ensuring the stability of the electroweak-like configuration against charge breaking, we obtain a practical criterion for determining when the general electroweak vacuum is globally stable.",
          "authors": [
            "Saiyad Ashanujjaman",
            "Siddharth P. Maharathy"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02129",
          "title": "Dynamo and Jet interconnections in GRMHD simulations of black hole accretion disks",
          "abstract": "We present global 3D GRMHD simulations of black hole (BH) accretion disks designed to investigate how MRI-driven dynamo action regulates jet formation and evolution. Unlike standard SANE/MAD setups that impose a coherent large-scale poloidal loop, our \"sub-SANE\" initial conditions use multiple same-polarity small-scale magnetic loops. Rapid reconnection erases magnetic memory and enables large-scale dynamo to emerge early from MRI turbulence. We perform two such sub-SANE simulations at different BH spins ($a = 0.5, 0.9375$) and compare them with conventional SANE runs. The sub-SANE disks show regular large-scale dynamo cycles with periods of about ten orbits. Decomposition of the induction equation shows that the turbulent dynamo term is stronger in 3D compared to 2.5D and balances advection in the saturated state, confirming sustained large-scale field generation. These dynamo-generated fields are advected inward with minimal time lag, producing correlated peaks in both poloidal and toroidal field strengths from $r_{\\rm max}$ to the horizon. Early in the evolution, these peaks imprint directly onto the jet's electromagnetic energy flux, indicating that the jet mirrors the dynamo wave. Though jets form at early times, the sub-SANE runs eventually undergo jet shutdown. We show that this occurs when the magnetic field at the horizon loses coherence, as quantified by a decline in the signed-to-unsigned flux ratio $\\mathcal{C}_{\\rm BH}$ below $\\approx 0.6$. In contrast, the SANE reference case with similar accretion rate and horizon magnetic flux maintains high magnetic coherence because its initial large-scale field persists, allowing its jet to survive. Our results show that both dynamo-driven field evolution and horizon magnetic-field coherence critically regulate jet longevity, establishing a direct dynamo-jet connection in GRMHD disks.",
          "authors": [
            "P. S. Santhiya",
            "Pallavi Bhat",
            "Prayush Kumar",
            "Tushar Mondal",
            "Indu K. Dihingia"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02129",
          "title": "Dynamo and Jet interconnections in GRMHD simulations of black hole accretion disks",
          "abstract": "We present global 3D GRMHD simulations of black hole (BH) accretion disks designed to investigate how MRI-driven dynamo action regulates jet formation and evolution. Unlike standard SANE/MAD setups that impose a coherent large-scale poloidal loop, our \"sub-SANE\" initial conditions use multiple same-polarity small-scale magnetic loops. Rapid reconnection erases magnetic memory and enables large-scale dynamo to emerge early from MRI turbulence. We perform two such sub-SANE simulations at different BH spins ($a = 0.5, 0.9375$) and compare them with conventional SANE runs. The sub-SANE disks show regular large-scale dynamo cycles with periods of about ten orbits. Decomposition of the induction equation shows that the turbulent dynamo term is stronger in 3D compared to 2.5D and balances advection in the saturated state, confirming sustained large-scale field generation. These dynamo-generated fields are advected inward with minimal time lag, producing correlated peaks in both poloidal and toroidal field strengths from $r_{\\rm max}$ to the horizon. Early in the evolution, these peaks imprint directly onto the jet's electromagnetic energy flux, indicating that the jet mirrors the dynamo wave. Though jets form at early times, the sub-SANE runs eventually undergo jet shutdown. We show that this occurs when the magnetic field at the horizon loses coherence, as quantified by a decline in the signed-to-unsigned flux ratio $\\mathcal{C}_{\\rm BH}$ below $\\approx 0.6$. In contrast, the SANE reference case with similar accretion rate and horizon magnetic flux maintains high magnetic coherence because its initial large-scale field persists, allowing its jet to survive. Our results show that both dynamo-driven field evolution and horizon magnetic-field coherence critically regulate jet longevity, establishing a direct dynamo-jet connection in GRMHD disks.",
          "authors": [
            "P. S. Santhiya",
            "Pallavi Bhat",
            "Prayush Kumar",
            "Tushar Mondal",
            "Indu K. Dihingia"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02135",
          "title": "Constraining the Occurrence of ZLK-Induced White Dwarf Pollution with Dissipative Precession",
          "abstract": "Von Zeipel-Lidov-Kozai (ZLK) oscillations, induced by bound, perturbative companions to white dwarfs, have been suggested as a dynamical mechanism that may contribute to white dwarf pollution. To trigger ZLK oscillations, however, a 3-body system must reach a sufficiently large mutual inclination between orbits. The occurrence of these high-mutual-inclination configurations can be curtailed by dissipative precession at the protoplanetary disk stage, which pushes exoplanet-hosting close binary systems toward preferential orbit-orbit alignment. In this work, we constrain the fraction of white dwarfs with binary companions that can undergo ZLK-driven pollution given the effects of dissipative precession. To accrete pollution via ZLK oscillations, a white dwarf binary system must be sufficiently inclined and the characteristic timescale of the oscillations must be sufficiently short to perturb material within the white dwarf's cooling age. Considering a sample of 4400 known white dwarf/main sequence binaries, we find that $50-70\\%$ have favorable parameters for ZLK pollution, depending on the orbital separation of the polluting body. While the conditions for oscillations are favorable, the tendency for ZLK to result in massive but more infrequent polluters likely restricts the rates of ZLK-induced pollution among the observed population. In general, dissipative precession is a limiting factor in pollution rates for more closely separated binaries (initial separations $<500-800$~au), while ZLK timescale constraints are most limiting for wider binaries.",
          "authors": [
            "Isabella Trierweiler",
            "Konstantin Gerbig",
            "Malena Rice"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02136",
          "title": "AT2022zod: An Unusual Tidal Disruption Event in an Elliptical Galaxy at Redshift 0.11",
          "abstract": "Tidal Disruption Events (TDEs) have long been hypothesized as valuable indicators of black holes, offering insight into their demographics and behaviour out to high redshift. TDEs have also enabled the discovery of a few Massive Black Holes (MBHs) with inferred masses of $10^4$--$10^6\\,M_\\odot$, often associated with the nuclei of dwarf galaxies or ultra-compact dwarf galaxies (UCDs). Here we present AT2022zod, an extreme and short-lived optical flare in an elliptical galaxy at z=0.11, residing within 3kpc of the galaxy's centre. Its luminosity and ~30-day duration make it unlikely to have originated from the host galaxy's central supermassive black hole (SMBH), which estimate to have a mass around $10^8\\,M_\\odot$. Assuming that the emission mechanism is consistent with known observed TDEs, we find that such a rapidly evolving transient could either be produced by a MBH in the intermediate-mass range or, alternatively, result from the tidal disruption of a star on a non-parabolic orbit around the central SMBH. We suggest that the most plausible origin for AT2022zod is the tidal disruption of a star by a MBH embedded in a UCD. As the Vera C. Rubin Observatory's Legacy Survey of Space and Time comes online, we propose that AT2022zod serves as an important event for refining search strategies and characterization techniques for intermediate-mass black holes.",
          "authors": [
            "Kristen C. Dage",
            "Phelipe Darc",
            "Thallis Pessi",
            "Rupesh Durgesh",
            "Shravya Shenoy",
            "Lilianne Nakazono",
            "Celine Boehm",
            "Ana L. Chies-Santos",
            "Rafael S. de Souza",
            "Zsofia V. Kovacs-Stermeczky",
            "Arash Bahramian",
            "Bahar Bidaran",
            "Emille E. O. Ishida",
            "Alberto Krone-Martins",
            "Aarya A. Patil",
            "Reinaldo R. Rosa",
            "Andressa Wille",
            "Richard M. Plotkin",
            "Behzad Tahmazebzadeh"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02137",
          "title": "Linearly Polarized Gravitational Waves from Bubble Collisions",
          "abstract": "Physics beyond the Standard Model may give rise to first-order phase transitions proceeding via the nucleation of vacuum bubbles, whose subsequent collisions generate gravitational waves (GWs). Their detection would open the possibility of investigating the universe in its first instants. If the transition is slow enough, such that it completes with the nucleation and collision of only two bubbles, the resulting GW signal is linearly polarized. We show that in this case triangular interferometers such as LISA and the Einstein Telescope could be able to not only measure the magnitude of the GW but also establish its linear polarization. This would give a strong hint about the origin of the signal.",
          "authors": [
            "Katarina Trailović"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02137",
          "title": "Linearly Polarized Gravitational Waves from Bubble Collisions",
          "abstract": "Physics beyond the Standard Model may give rise to first-order phase transitions proceeding via the nucleation of vacuum bubbles, whose subsequent collisions generate gravitational waves (GWs). Their detection would open the possibility of investigating the universe in its first instants. If the transition is slow enough, such that it completes with the nucleation and collision of only two bubbles, the resulting GW signal is linearly polarized. We show that in this case triangular interferometers such as LISA and the Einstein Telescope could be able to not only measure the magnitude of the GW but also establish its linear polarization. This would give a strong hint about the origin of the signal.",
          "authors": [
            "Katarina Trailović"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02147",
          "title": "Inefficient Circularization, Delayed Stream-Disk Interaction and Reprocessing: A Five-Stage Model for the Intermediate-Mass Black Hole Tidal Disruption Event EP240222a",
          "abstract": "EP240222a is the first intermediate-mass black hole (IMBH) tidal disruption event (TDE) captured in real-time with multi-wavelength observations and spectroscopic confirmation. However, its light curves deviate substantially from previous theoretical expectations. Motivated by these unique features, we have developed a novel model that successfully reproduces its peculiar evolution. Our model delineates five stages: (1) Initial Stage of inefficient circularization; (2) Slow-Rising Stage with a faint X-ray precursor disk fed by successive self-crossings; (3) Fast-Rising Stage, where delayed stream-disk interaction at momentum flux matching drives a sharp luminosity rise; (4) Plateau Stage with super-Eddington accretion, outflow, reprocessing, and a clear polar line-of-sight; and (5) Decline Stage of sub-Eddington accretion and ongoing reprocessing. Our fit indicates the disruption of a $M_* \\approx 0.4~M_\\odot$ main-sequence (MS) star with a penetration factor $\\beta \\approx 1.0$. Our model, which incorporates key TDE processes, establishes EP240222a-like light curves as typical IMBH-TDE signatures. The distinctive identifier is a slow rise in X-rays and a corresponding slow rise/quasi-plateau in the UV/optical, followed by a brighter, super-Eddington plateau in both bands, though other forms exist, such as the rapid rise from white dwarf (WD) disruptions over minutes to days.",
          "authors": [
            "Wenkai Li",
            "Ning Jiang",
            "Tinggui Wang",
            "Rongfeng Shen",
            "Erlin Qiao",
            "Lixin Dai",
            "Di Luo",
            "Dongyue Li",
            "Chichuan Jin",
            "Jiazheng Zhu"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02148",
          "title": "Gravitational waves from flavoured SU(2) early-universe phase transitions",
          "abstract": "Flavourful extensions of the Standard Model aimed at explaining its fermionic mass structure typically rely on symmetries, broken at high-energy scales far beyond the reach of foreseeable direct collider searches. We illustrate, using a $SU(2)$ flavour gauge group, that the breaking of these symmetries up to scales as high as $10^7$ GeV could generate a gravitational-wave signal potentially observable by future observatories. We use dimensional reduction techniques to obtain the finite-temperature effective potential and study the possible first-order phase transitions. We match these transitions to steady-state hydrodynamical solutions in order to determine the corresponding gravitational-wave spectra. We observe that order-one gauge couplings are always required for a first-order phase transition to occur. On the other hand, adding leptoquarks (as an example of particles that are typically present in a complete flavour theory) significantly extends the testable parameter space. We find excellent prospects at the Einstein Telescope for future gravitational-wave detection of flavoured $SU(2)$ early-universe phase transitions.",
          "authors": [
            "Anna Chrysostomou",
            "Alan S. Cornell",
            "Luc Darmé",
            "Aldo Deandrea",
            "Thibault Demartini"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02148",
          "title": "Gravitational waves from flavoured SU(2) early-universe phase transitions",
          "abstract": "Flavourful extensions of the Standard Model aimed at explaining its fermionic mass structure typically rely on symmetries, broken at high-energy scales far beyond the reach of foreseeable direct collider searches. We illustrate, using a $SU(2)$ flavour gauge group, that the breaking of these symmetries up to scales as high as $10^7$ GeV could generate a gravitational-wave signal potentially observable by future observatories. We use dimensional reduction techniques to obtain the finite-temperature effective potential and study the possible first-order phase transitions. We match these transitions to steady-state hydrodynamical solutions in order to determine the corresponding gravitational-wave spectra. We observe that order-one gauge couplings are always required for a first-order phase transition to occur. On the other hand, adding leptoquarks (as an example of particles that are typically present in a complete flavour theory) significantly extends the testable parameter space. We find excellent prospects at the Einstein Telescope for future gravitational-wave detection of flavoured $SU(2)$ early-universe phase transitions.",
          "authors": [
            "Anna Chrysostomou",
            "Alan S. Cornell",
            "Luc Darmé",
            "Aldo Deandrea",
            "Thibault Demartini"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02155",
          "title": "SE+BSF4DM - A micrOMEGAs package for Sommerfeld Effect and Bound State Formation in colored Dark Sectors",
          "abstract": "We present SE+BSF4DM, a novel add-on package for micrOMEGAs that includes the Sommerfeld effect and bound state formation in the numerical evaluation of the dark matter relic density for QCD colored dark sectors. Including these non-perturbative effects in the relic density calculation is crucial for achieving accurate predictions in a broad class of models and SE+BSF4DM seamlessly integrates them into the standard micrOMEGAs workflow, requiring minimal user modification. The package is applicable to any model mappable onto a simplified t-channel framework, making it a versatile tool. This paper details the implementation, assets, and scope of SE+BSF4DM, serving as both a comprehensive introduction and a practical user guide.",
          "authors": [
            "Mathias Becker",
            "Emanuele Copello",
            "Martin Napetschnig"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02156",
          "title": "Testing ER = EPR with Hydrogen",
          "abstract": "According to the ER = EPR conjecture, entangled particles are connected by quantum wormholes. Under the assumption that some of the electric field surrounding an entangled charged particle leaks into the wormhole, we show that this effect will modify the hyperfine structure of the hydrogen atom. In addition, if the quantum wormholes are non-traversable, this will also lead to a non-zero total effective charge for the hydrogen atom. These effects provide strong constraints on the amplitude of this potential ER = EPR effect, given high-precision measurements of the hydrogen atom's hyperfine structure and total charge.",
          "authors": [
            "Irfan Javed",
            "Edward Wilson-Ewing"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02159",
          "title": "SCExAO/CHARIS and Gaia Direct Imaging and Astrometric Discovery of a Superjovian Planet 3--4 lambda/D from the Accelerating Star HIP 54515",
          "abstract": "We present the discovery of a superjovian planet around the young A5 star HIP 54515, detected using precision astrometry from the \\textit{Hipparcos Gaia Catalogue of Accelerations} and high-contrast imaging with SCExAO/CHARIS from the recently-commenced \\surveyname\\ program. SCExAO/CHARIS detects HIP 54515 b in five epochs 0\\farcs{}145--0\\farcs{}192 from the star ($\\sim$3--4 $\\lambda$/D at 1.65 $\\mu m$), exhibiting clockwise orbital motion. HIP 54515 b lies near the M/L transition with a luminosity of log(L/L$_{\\rm \\odot}$) $\\sim$ -3.52 $\\pm$ 0.03. Dynamical modeling constrains its mass and mass ratio to be ${17.7}_{-4.9}^{+7.6}$ $M_{\\rm Jup}$ and ${0.0090}_{-0.0024}^{+0.0036}$ and favors a $\\sim$25 au semimajor axis. HIP 54515 b adds to a growing list of superjovian planets with moderate eccentricities (e $\\approx$ 0.4). Now the third planet discovered from surveys combining high-contrast extreme adaptive optics imaging with precision astrometry, HIP 54515 b should help improve empirical constraints on the luminosity evolution and eccentricity distribution of the most massive planets. It may also provide a key technical test of the Roman Space Telescope Coronagraph Instrument's performance in the low stellar flux, small angular separation limit and a demonstration of its ability to yield constrainable planet spectral properties.",
          "authors": [
            "Thayne Currie",
            "Yiting Li",
            "Mona El Morsy",
            "Brianna Lacy",
            "Maria Vincent",
            "Taylor L. Tobin",
            "Masayuki Kuzuhara",
            "Jeffrey Chilcote",
            "Olivier Guyon",
            "Ziying Gu",
            "Danielle Bovie",
            "Dillon Peng",
            "Qier An",
            "Timothy D. Brandt",
            "Robert J. De Rosa",
            "Vincent Deo",
            "Tyler D. Groff",
            "Markus Janson",
            "N. Jeremy Kasdin",
            "Julien Lozi",
            "Christian Marois",
            "Bertrand Mennesson",
            "Naoshi Murakami",
            "Eric Nielsen",
            "Sabina Sagynbayeva",
            "Nour Skaf",
            "William Thompson",
            "Motohide Tamura",
            "Taichi Uyama",
            "Sébastien Vievard",
            "Alice Zurlo"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02165",
          "title": "Non-perturbaitve effects in Higgs boson decays to electroweak vector bosons and photons",
          "abstract": "We estimate the magnitude of the leading non-perturbative QCD corrections to the decays of the Higgs boson to the $\\gamma Z$ and $\\gamma \\gamma$ final states. These corrections originate from the light-quark contributions to such decays. We show that the non-perturbative effects are suppressed by the small Yukawa couplings of light quarks, but that there is no further quark-mass suppression. This is at variance with what is found in the standard perturbative calculations of the light-quark contributions. We demonstrate that the non-perturbative corrections modify the $H \\to \\gamma Z$ and $H \\to \\gamma \\gamma$ decay rates by $O(10^{-5})$, well below the expected precision with which such decays can be studied both at the high-luminosity LHC and at future colliders.",
          "authors": [
            "Alexander Khodjamirian",
            "Kirill Melnikov",
            "Arkady Vainshtein"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02167",
          "title": "Impact of Nuclear Reaction Rate Uncertainties on Type I X-ray Burst Nucleosynthesis: A Monte Carlo Study",
          "abstract": "To investigate the impact of nuclear reaction rate uncertainties on type I X-ray burst nucleosynthesis, comprehensive Monte Carlo simulations are performed with temperature-independent and -dependent variations in reaction rates using the REACLIB and STARLIB libraries, respectively. A total of 1,711 $(p, \\gamma)$, $(p, \\alpha)$, $(\\alpha, p)$, and $(\\alpha, \\gamma)$ reactions are varied simultaneously, along with their inverse reactions, via detailed balance. For the first time, it is found that Monte Carlo sampling with larger perturbations to these reaction rates may lead to multi-peaked abundance distributions for some isotopes. These multi-peak structures arise not only from coupled reactions but also, in some cases, from single reactions. Our study also confirmed previously identified key reactions and provides more robust lists. These reactions deserve priority consideration in future study.",
          "authors": [
            "Qing Wang",
            "Ertao Li",
            "Zhihong Li",
            "Youbao Wang",
            "Bing Guo",
            "Yunju Li",
            "Jun Su",
            "Shipeng Hu",
            "Yinwen Guan",
            "Dong Xiang",
            "Yu Liu",
            "Lei Yang",
            "Weiping Liu"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02171",
          "title": "High-Energy Extractions from Horizonless Compact Objects",
          "abstract": "High-energy astrophysical sources such as active galactic nuclei, quasars, X-ray binaries, and gamma-ray bursts are powered by mechanisms that convert gravitational or rotational energy into radiation, jets, and relativistic outflows. Understanding the physics of these processes remains a major challenge. Black holes have traditionally served as the central engines behind such phenomena, with well established energy extraction mechanisms including the Penrose process, the Blandford-Znajek process, and the Banados-Silk-West mechanism. However, studies in general relativity indicate that, under certain conditions, gravitational collapse may lead to the formation of naked singularities or other horizonless compact objects, which could in principle allow more efficient energy extraction than classical black holes. This brief review summarizes recent progress on energy extraction mechanisms in naked singularity spacetimes. We examine the roles of rotation, electromagnetic fields, and particle interactions in shaping extraction efficiency and dynamics. Particular attention is given to negative energy orbits and ergoregion physics, which enable Penrose type and magnetic Penrose mechanisms without an event horizon. We also discuss collisional Penrose processes and particle acceleration near the singularity, emphasizing their potential astrophysical implications. By comparing extraction efficiencies and physical conditions in black holes and naked singularities, we highlight how the absence of a horizon fundamentally alters the dynamics of energy release. These results suggest that naked singularities may serve as natural laboratories for strong field gravity and as alternative engines for high-energy astrophysical phenomena in the era of multi-messenger observations.",
          "authors": [
            "Parth Bambhaniya",
            "Elisabete M. de Gouveia Dal Pino"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02171",
          "title": "High-Energy Extractions from Horizonless Compact Objects",
          "abstract": "High-energy astrophysical sources such as active galactic nuclei, quasars, X-ray binaries, and gamma-ray bursts are powered by mechanisms that convert gravitational or rotational energy into radiation, jets, and relativistic outflows. Understanding the physics of these processes remains a major challenge. Black holes have traditionally served as the central engines behind such phenomena, with well established energy extraction mechanisms including the Penrose process, the Blandford-Znajek process, and the Banados-Silk-West mechanism. However, studies in general relativity indicate that, under certain conditions, gravitational collapse may lead to the formation of naked singularities or other horizonless compact objects, which could in principle allow more efficient energy extraction than classical black holes. This brief review summarizes recent progress on energy extraction mechanisms in naked singularity spacetimes. We examine the roles of rotation, electromagnetic fields, and particle interactions in shaping extraction efficiency and dynamics. Particular attention is given to negative energy orbits and ergoregion physics, which enable Penrose type and magnetic Penrose mechanisms without an event horizon. We also discuss collisional Penrose processes and particle acceleration near the singularity, emphasizing their potential astrophysical implications. By comparing extraction efficiencies and physical conditions in black holes and naked singularities, we highlight how the absence of a horizon fundamentally alters the dynamics of energy release. These results suggest that naked singularities may serve as natural laboratories for strong field gravity and as alternative engines for high-energy astrophysical phenomena in the era of multi-messenger observations.",
          "authors": [
            "Parth Bambhaniya",
            "Elisabete M. de Gouveia Dal Pino"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02173",
          "title": "Dynamics of Streamers and Pseudostreamers and Implications for the Solar Wind",
          "abstract": "The origin of the Sun's slow wind and its inherent variability remain unknown, but there is increasing evidence that interaction between closed and open magnetic flux in the corona plays a role. This paper studies the dynamic evolution of streamers and pseudostreamers with a particular focus on the release of plasma from the closed to the open field region. We employ a global magnetohydrodynamic model that extends from the solar chromosphere to 30 solar radii, and that extends previous interchange magnetic reconnection modelling by including self-consistent thermodynamics. We find that at both the helmet streamer and pseudostreamer there is a continual dynamic interaction between closed and open flux. At the helmet streamer, this takes the form of a ''breathing'' cycle in which the closed flux contracts and expands, and plasmoids are released along the heliospheric current sheet. The pseudostreamer exhibits a back-and-forth motion, driving interchange reconnection alternately on its opposite flanks. The resulting release of hot, dense plasma leads to density fluctuations in the open field that are significantly larger above the helmet streamer due to the persistence of the plasmoids there. Our model demonstrates that plasma is continually being released into the heliosphere from both streamers and pseudostreamers.",
          "authors": [
            "Sahel Dey",
            "David I. Pontin",
            "Spiro K. Antiochos"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02177",
          "title": "$S^5$: Tidal Disruption in Crater 2 and Formation of Diffuse Dwarf Galaxies in the Local Group",
          "abstract": "We present results of a spectroscopic campaign around the diffuse dwarf galaxy Crater 2 (Cra2) and its tidal tails as part of the Southern Stellar Stream Spectroscopic Survey ($S^5$). Cra2 is a Milky Way dwarf spheroidal satellite with extremely cold kinematics, but a huge size similar to the Small Magellanic Cloud, which may be difficult to explain within collisionless cold dark matter. We identify 143 Cra2 members, of which 114 belong to the galaxy's main body and 29 are deemed part of its stellar stream. We confirm that Cra2 is dynamically cold (central velocity dispersion $2.51^{+0.33}_{-0.30}\\,{\\rm km\\,s^{-1}}$) and also discover a $\\approx$7$\\sigma$ velocity gradient consistent with its tidal debris track. We separately estimate the stream velocity dispersion to be $5.74^{+0.98}_{-0.83}\\,{\\rm km\\,s^{-1}}$. We develop a suite of $N$-body simulations with both cuspy and cored density profiles on a realistic Cra2 orbit to compare with $S^5$ observations. We find that the velocity dispersion ratio between Cra2 stream and galaxy ($2.30^{+0.41}_{-0.35}$) is difficult to reconcile with a cuspy halo with fiducial concentration and an initial mass predicted by standard stellar mass$-$halo mass relationships. Instead, either a cored halo with relatively small core radius or a low-concentration cuspy model can reproduce this ratio. Despite tidal mass loss, Cra2 is metal-poor ($\\langle \\rm[Fe/H]\\rangle=-2.16\\pm0.04$) compared to the stellar mass$-$metallicity relation for its luminosity. Other diffuse dwarf galaxies similar to Cra2 in the Local Group (Antlia 2 and Andromeda 19) also challenge galaxy formation models. Finally, we discuss possible formation scenarios for Cra2, including ram-pressure stripping of a gas-rich progenitor combined with tides.",
          "authors": [
            "Guilherme Limberg",
            "Alexander P. Ji",
            "Ting S. Li",
            "Denis Erkal",
            "Sergey E. Koposov",
            "Andrew B. Pace",
            "Andrew P. Li",
            "Petra Awad",
            "Alexandra Senkevich",
            "Joss Bland-Hawthorn",
            "Lara Cullinane",
            "Gary Da Costa",
            "Alex Drlica-Wagner",
            "Raphaël Errani",
            "Peter S. Ferguson",
            "Kyler Kuehn",
            "Geraint F. Lewis",
            "Sarah L. Martell",
            "Jorge Peñarrubia",
            "Nora Shipp",
            "Yong Yang",
            "Daniel B. Zucker"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02207",
          "title": "Uncertainty Principle and Angular Momentum Generation in Microscopic Fission Models",
          "abstract": "The generation of angular momentum (intrinsic spin) in fission fragments has recently attracted renewed attention. While several microscopic approaches reproduce the spin distribution qualitatively using projection techniques, the physical origin of the fragments' angular momentum in density functional theory remains unclear. In this work, we investigate the mechanisms responsible for the spin distribution of fission fragments within a microscopic TDDFT framework. We compare spin distributions obtained from projection operators with those predicted by a simple expression derived from the uncertainty relation between angle and angular momentum, where angular fluctuations are estimated using a Monte Carlo sampling of nucleon positions. We find that a large portion of the spin distribution obtained from projection methods can be explained by the uncertainty principle. Our results thus show that, within microscopic approaches, the spin of fission fragments originates primarily from quantum uncertainty associated with their orientation angle with respect to the fission axis, mainly due to quadrupole deformation and, to a lesser extent, octupole deformation.",
          "authors": [
            "G. Scamps",
            "A. Guilleux",
            "D. Regnier",
            "A. Bernard"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02207",
          "title": "Uncertainty Principle and Angular Momentum Generation in Microscopic Fission Models",
          "abstract": "The generation of angular momentum (intrinsic spin) in fission fragments has recently attracted renewed attention. While several microscopic approaches reproduce the spin distribution qualitatively using projection techniques, the physical origin of the fragments' angular momentum in density functional theory remains unclear. In this work, we investigate the mechanisms responsible for the spin distribution of fission fragments within a microscopic TDDFT framework. We compare spin distributions obtained from projection operators with those predicted by a simple expression derived from the uncertainty relation between angle and angular momentum, where angular fluctuations are estimated using a Monte Carlo sampling of nucleon positions. We find that a large portion of the spin distribution obtained from projection methods can be explained by the uncertainty principle. Our results thus show that, within microscopic approaches, the spin of fission fragments originates primarily from quantum uncertainty associated with their orientation angle with respect to the fission axis, mainly due to quadrupole deformation and, to a lesser extent, octupole deformation.",
          "authors": [
            "G. Scamps",
            "A. Guilleux",
            "D. Regnier",
            "A. Bernard"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02207",
          "title": "Uncertainty Principle and Angular Momentum Generation in Microscopic Fission Models",
          "abstract": "The generation of angular momentum (intrinsic spin) in fission fragments has recently attracted renewed attention. While several microscopic approaches reproduce the spin distribution qualitatively using projection techniques, the physical origin of the fragments' angular momentum in density functional theory remains unclear. In this work, we investigate the mechanisms responsible for the spin distribution of fission fragments within a microscopic TDDFT framework. We compare spin distributions obtained from projection operators with those predicted by a simple expression derived from the uncertainty relation between angle and angular momentum, where angular fluctuations are estimated using a Monte Carlo sampling of nucleon positions. We find that a large portion of the spin distribution obtained from projection methods can be explained by the uncertainty principle. Our results thus show that, within microscopic approaches, the spin of fission fragments originates primarily from quantum uncertainty associated with their orientation angle with respect to the fission axis, mainly due to quadrupole deformation and, to a lesser extent, octupole deformation.",
          "authors": [
            "G. Scamps",
            "A. Guilleux",
            "D. Regnier",
            "A. Bernard"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02209",
          "title": "Muon magnetic anomaly: experimental status and prospects",
          "abstract": "The past five years have brought significant new results on the muon magnetic anomaly, $a_\\mu = (g_\\mu - 2)/2$, and on the hadronic vacuum polarization (HVP) contribution dominating the uncertainty $\\Delta a_\\mu$. Serious tension has emerged between the experimental and standard model(SM) values for $a_\\mu$, as well as between the SM and the first precise lattice QCD values. We review the current experimental and theoretical status of $a_\\mu$, along with the prospects for new results,focusing on MUonE,a new experiment at CERN, aiming to evaluate the leading order contribution to a(HVP) in a direct measurement of muonic Bhabha scattering.",
          "authors": [
            "Dinko Pocanic"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02209",
          "title": "Muon magnetic anomaly: experimental status and prospects",
          "abstract": "The past five years have brought significant new results on the muon magnetic anomaly, $a_\\mu = (g_\\mu - 2)/2$, and on the hadronic vacuum polarization (HVP) contribution dominating the uncertainty $\\Delta a_\\mu$. Serious tension has emerged between the experimental and standard model(SM) values for $a_\\mu$, as well as between the SM and the first precise lattice QCD values. We review the current experimental and theoretical status of $a_\\mu$, along with the prospects for new results,focusing on MUonE,a new experiment at CERN, aiming to evaluate the leading order contribution to a(HVP) in a direct measurement of muonic Bhabha scattering.",
          "authors": [
            "Dinko Pocanic"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02209",
          "title": "Muon magnetic anomaly: experimental status and prospects",
          "abstract": "The past five years have brought significant new results on the muon magnetic anomaly, $a_\\mu = (g_\\mu - 2)/2$, and on the hadronic vacuum polarization (HVP) contribution dominating the uncertainty $\\Delta a_\\mu$. Serious tension has emerged between the experimental and standard model(SM) values for $a_\\mu$, as well as between the SM and the first precise lattice QCD values. We review the current experimental and theoretical status of $a_\\mu$, along with the prospects for new results,focusing on MUonE,a new experiment at CERN, aiming to evaluate the leading order contribution to a(HVP) in a direct measurement of muonic Bhabha scattering.",
          "authors": [
            "Dinko Pocanic"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02219",
          "title": "Convective Heat Transport Asymptotic Law in an $α^2$ dynamo model",
          "abstract": "Stellar activity and planetary magnetospheres are powered by an underlying dynamo mechanism generated by magnetoconvection coupled with rotation. In astrophysical contexts, magnetoconvection typically occurs in parameter regimes that are currently inaccessible to direct numerical simulations (DNS). We investigate convective heat transfer in a magneto-convection and dynamo model under extreme parameter conditions, specifically high Rayleigh and Prandtl numbers, in a plasma flow with maximum kinetic helicity compatible with fast-rotating objects. Our approach to studying magneto-convection and dynamo mechanisms employs a simplified thermally driven shell model. Magnetic polarity reversals are obtained by including a pitchfork bifurcation term in the large-scale magnetic field equation, while nonlinear dynamics are described by a shell model formulation. The low computational cost of the model allows us to explore the asymptotic behavior of convective heat transfer in regimes beyond those reached by current DNS. Our results reveal that the Nusselt number $Nu$ -- a dimensionless measure of convective heat transport-- generally increases with turbulence, following a power-law scaling and showing a strong correlation with Ra and Pr. This relationship appears to be more pronounced than that observed in non-magnetized fluids, suggesting that magnetic fields may significantly enhance convective heat transfer. Despite the assumption to neglect spatial information such as density stratification -- an assumption that is necessary in the shell model approach -- our model captures the gross dynamical features of turbulent magnetoconvection in asymptotic regimes. It allows for a broad exploration of parameter space, indicating that magnetic fields may play a central role in modulating heat transport in stellar and planetary interiors.",
          "authors": [
            "Giuseppina Nigro"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02233",
          "title": "On the Fourier transform of the hyperbola and its role in hyperbolic photonics",
          "abstract": "Motivated by recent breakthrough studies of wave hyperbolicity in extremely anisotropic natural materials and artificial composites, we investigate the radiation pattern of a localized emitter in a hyperbolic medium. Since the emission of a point source is associated with the Fourier transform of the iso-frequency contours of a medium, we derive and analyze the properties of the Fourier transform of hyperbolic dispersion, which sheds light into the emission properties in the presence of hyperbolic bands. Our analysis leads to a generalized form of Huygens' principle for hyperbolic waves, connecting to the emergence of negative refraction and focusing with hyperbolic media. We also highlight the occurrence of aliasing artifacts in polariton imaging. More broadly, our findings provide analytical tools to model polariton propagation in materials with extreme anisotropy, and may be applied to several other physical platforms featuring hyperbolic responses, from astrophysics to seismology.",
          "authors": [
            "Emroz Khan",
            "Andrea Alù"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02233",
          "title": "On the Fourier transform of the hyperbola and its role in hyperbolic photonics",
          "abstract": "Motivated by recent breakthrough studies of wave hyperbolicity in extremely anisotropic natural materials and artificial composites, we investigate the radiation pattern of a localized emitter in a hyperbolic medium. Since the emission of a point source is associated with the Fourier transform of the iso-frequency contours of a medium, we derive and analyze the properties of the Fourier transform of hyperbolic dispersion, which sheds light into the emission properties in the presence of hyperbolic bands. Our analysis leads to a generalized form of Huygens' principle for hyperbolic waves, connecting to the emergence of negative refraction and focusing with hyperbolic media. We also highlight the occurrence of aliasing artifacts in polariton imaging. More broadly, our findings provide analytical tools to model polariton propagation in materials with extreme anisotropy, and may be applied to several other physical platforms featuring hyperbolic responses, from astrophysics to seismology.",
          "authors": [
            "Emroz Khan",
            "Andrea Alù"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02233",
          "title": "On the Fourier transform of the hyperbola and its role in hyperbolic photonics",
          "abstract": "Motivated by recent breakthrough studies of wave hyperbolicity in extremely anisotropic natural materials and artificial composites, we investigate the radiation pattern of a localized emitter in a hyperbolic medium. Since the emission of a point source is associated with the Fourier transform of the iso-frequency contours of a medium, we derive and analyze the properties of the Fourier transform of hyperbolic dispersion, which sheds light into the emission properties in the presence of hyperbolic bands. Our analysis leads to a generalized form of Huygens' principle for hyperbolic waves, connecting to the emergence of negative refraction and focusing with hyperbolic media. We also highlight the occurrence of aliasing artifacts in polariton imaging. More broadly, our findings provide analytical tools to model polariton propagation in materials with extreme anisotropy, and may be applied to several other physical platforms featuring hyperbolic responses, from astrophysics to seismology.",
          "authors": [
            "Emroz Khan",
            "Andrea Alù"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02233",
          "title": "On the Fourier transform of the hyperbola and its role in hyperbolic photonics",
          "abstract": "Motivated by recent breakthrough studies of wave hyperbolicity in extremely anisotropic natural materials and artificial composites, we investigate the radiation pattern of a localized emitter in a hyperbolic medium. Since the emission of a point source is associated with the Fourier transform of the iso-frequency contours of a medium, we derive and analyze the properties of the Fourier transform of hyperbolic dispersion, which sheds light into the emission properties in the presence of hyperbolic bands. Our analysis leads to a generalized form of Huygens' principle for hyperbolic waves, connecting to the emergence of negative refraction and focusing with hyperbolic media. We also highlight the occurrence of aliasing artifacts in polariton imaging. More broadly, our findings provide analytical tools to model polariton propagation in materials with extreme anisotropy, and may be applied to several other physical platforms featuring hyperbolic responses, from astrophysics to seismology.",
          "authors": [
            "Emroz Khan",
            "Andrea Alù"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02237",
          "title": "Evolution of the Accretion Rate of Young Intermediate Mass Stars: Implications for Disk Evolution and Planet Formation",
          "abstract": "This work presents a study of the evolution of the stellar accretion rates of pre-main-sequence intermediate-mass stars. We compare the accretion rate of the younger intermediate-mass T Tauri stars (IMTTSs) with the older Herbig stars into which they evolve. We find that the median accretion rate of IMTTSs (1.2$\\times$10$^{-8}$ M$_{\\odot}$ yr$^{-1}$) is significantly lower than that of Herbig stars (1.9$\\times$10$^{-7}$ M$_{\\odot}$ yr$^{-1}$). This increase stands in stark contrast with canonical models of disk evolution that predict that the stellar accretion rate declines with age. We put forward a physically plausible scenario that accounts for the systematic increase of stellar accretion based on the increase of the effective temperature of the stars as they evolve towards the zero-age main sequence. For example, the temperature of a 2M$_{\\odot}$ star will increase from 4900~K in the IMTTS phase to 9100~K during the Herbig phase. Thus, the luminosity of the far ultraviolet (FUV) radiation will increase by orders of magnitude. We propose that this increase drives a higher stellar accretion rate. The scenario we propose to account for the increase in the stellar accretion rate solves the lifetime problem for Herbig disks because the increasing stellar accretion rates require lower initial disk masses to account for present-day disk masses. This work highlights the importance of the role FUV radiation has in driving the accretion rate, predicts a large population of pre-main-sequence non-accreting A stars, and has implications for interpreting disk morphologies that may serve as signposts of embedded gas giant planets in Herbig disks.",
          "authors": [
            "Sean D. Brittain",
            "Joshua W. Kern",
            "Gwendolyn Meeus",
            "Rene D. Oudmaijer"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02238",
          "title": "Revisiting the gravitational \"arrow of time\"",
          "abstract": "We address a long-standing misperception on the gravitational ``arrow of time'', a proposal by Penrose (also known as the ``Weyl-curvature hypothesis\") that associates structure formation along timelike directions in which Weyl-curvature scalars become dominant over Ricci scalars. A counterexample of this hypothesis was found by Bonnor on a class of exact solutions describing heat conducting spheres collapsing in a Vaidya background. We show that this result does not hold in the same class of solutions considered as physically viable near FLRW cosmological models, with the heat conduction vector interpreted as a peculiar velocity field. We also discuss the similarities and differences between the gravitational ``arrow of time'' and the gravitational entropy formalism of Clifton, Ellis and Tavakol.",
          "authors": [
            "Roberto A. Sussman",
            "Sebastián Nájera",
            "Fernando A. Pizaña",
            "Juan Carlos Hidalgo"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02248",
          "title": "Evaluating the Prospects of Cyclic Deconvolution across 312 Pulsars",
          "abstract": "We use the cyclic figure of merit to determine the likelihood of achieving cyclic deconvolution for 312 pulsars with sub-40 ms spin periods across 14 different telescope-observing frequency combinations. We find that the optimal frequency range for achieving cyclic deconvolution for most pulsars is between $\\sim$80$-$300 MHz, making low frequency observatories like uGMRT, LOFAR, and MWA the best-suited instruments for the technique. Moreover, we find that, as quantified by the total number sources with sufficient cyclic merits that are observed within the full deconvolution regime, uGMRT is likely the best current instrument for cyclic spectroscopy among the nine telescopes we considered, with LOFAR being the second best, and future telescopes like SKA-Low serving as the most likely eventual successors. The relatively high cyclic merit of the Crab Pulsar in the frequency ranges considered for GBT, MWA, LOFAR, and uGMRT suggests that some faster-spinning canonical pulsars may be able to achieve cyclic deconvolution, and we discuss potential follow-up analyses on other non-recycled pulsars. We conclude by advocating for near real-time cyclic spectroscopy backends to be considered for current and upcoming low frequency telescopes to increase the accessibility of this technique.",
          "authors": [
            "Jacob E. Turner"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02256",
          "title": "Impact of Higgs-boson measurements on SMEFT fits",
          "abstract": "We present current bounds on SMEFT operators that are mainly constrained by Higgs-boson observables, under different assumptions for the flavour structure of the UV theory. We investigate how the accuracy reached through a dedicated Higgs-boson precision physics program is starting to have a major impact in setting a lower bound on the scale of new physics, and we discuss the relevance of considering the scale evolution of the SMEFT coefficients in this context. We compare our results with the literature, pointing out the consistency of the results in spite of the different assumptions adopted in each analysis, and we discuss future steps aimed at improving the accuracy of the fit.",
          "authors": [
            "J. de Blas",
            "A. Goncalves",
            "V. Miralles",
            "L. Reina",
            "L. Silvestrini",
            "M. Valli"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02256",
          "title": "Impact of Higgs-boson measurements on SMEFT fits",
          "abstract": "We present current bounds on SMEFT operators that are mainly constrained by Higgs-boson observables, under different assumptions for the flavour structure of the UV theory. We investigate how the accuracy reached through a dedicated Higgs-boson precision physics program is starting to have a major impact in setting a lower bound on the scale of new physics, and we discuss the relevance of considering the scale evolution of the SMEFT coefficients in this context. We compare our results with the literature, pointing out the consistency of the results in spite of the different assumptions adopted in each analysis, and we discuss future steps aimed at improving the accuracy of the fit.",
          "authors": [
            "J. de Blas",
            "A. Goncalves",
            "V. Miralles",
            "L. Reina",
            "L. Silvestrini",
            "M. Valli"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02269",
          "title": "The SPHINX M dwarf Spectral Grid. II. New Model Atmospheres and Spectra to Derive Fundamental Properties of mid-to-late type M-dwarfs",
          "abstract": "M-dwarfs are the most dominant stars in the Galaxy. Their interiors and atmospheres exhibit complex processes including dust condensation, convective feedback, and magnetic activity-driven heterogeneity. Standard stellar characterization methods often struggle to capture these coupled effects. Part I of this series introduced SPHINX I, a validated grid of self-consistent radiative-convective model atmospheres and spectra for M-dwarfs with up-to-date molecular opacities suitable for early-to-mid M-dwarfs. Here, we present SPHINX II, which extends the model grid to cover mid-to-late type M-dwarfs, including both gray and physically motivated condensate cloud treatments and shorter convective mixing lengths. We validate SPHINX II using 39 benchmark FGK+M binary systems observed with SpeX IRTF (Mann et al. 2014) and apply it to 32 mid-to-late-type M-dwarfs from the SpeX Prism Library. SPHINX II yields improved fits that are statistically consistent with empirical benchmarks, achieving precisions of 0.078 dex in metallicity and 0.13 dex in C/O. Across the model grid, condensate cloud mass peaks between 2100-2400 K, decreasing sharply toward both cooler and hotter temperatures. We find the onset of the cloud-free regime around 2900 K, and below 2100 K, we see formation of deep/buried clouds. As a case study, we also model Trappist-1 and show that even mass-limited silicate grains subtly modify its emergent spectrum, suppressing near-infrared flux and reddening the mid-infrared slope via shallow cloud formation near 1e-2 bar. In sum, SPHINX II provides an improved framework for constraining the fundamental properties of mid-to-late M-dwarfs.",
          "authors": [
            "Aishwarya R. Iyer",
            "Michael R. Line",
            "Philip S. Muirhead",
            "Jonathan J. Fortney",
            "Jacqueline K. Faherty"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02274",
          "title": "Gravitational radiation from hyperbolic orbits: comparison between self-force, post-Minkowskian, post-Newtonian, and numerical relativity results",
          "abstract": "In this work I use a frequency-domain Regge-Wheeler-Zerilli approach to compute the gravitational wave energy radiated by a compact body moving along a hyperbolic or parabolic geodesic of a Schwarzschild black hole. I compare my results with the latest post-Minkowskian (PM) calculations for the radiated energy and find agreement for hyperbolic orbits with large impact parameters and characterized by a velocity at infinity, $v_\\infty$, as large as $v_\\infty/c=0.7$. I also find agreement between my results and the leading-order PM expansion for the radiation absorbed by the black hole. I make further comparisons with post-Newtonian (PN) theory and show the effectiveness of a simple PN-PM hybrid model. Finally, I make a first comparison of the radiated energy between self-force and numerical relativity.",
          "authors": [
            "Niels Warburton"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02274",
          "title": "Gravitational radiation from hyperbolic orbits: comparison between self-force, post-Minkowskian, post-Newtonian, and numerical relativity results",
          "abstract": "In this work I use a frequency-domain Regge-Wheeler-Zerilli approach to compute the gravitational wave energy radiated by a compact body moving along a hyperbolic or parabolic geodesic of a Schwarzschild black hole. I compare my results with the latest post-Minkowskian (PM) calculations for the radiated energy and find agreement for hyperbolic orbits with large impact parameters and characterized by a velocity at infinity, $v_\\infty$, as large as $v_\\infty/c=0.7$. I also find agreement between my results and the leading-order PM expansion for the radiation absorbed by the black hole. I make further comparisons with post-Newtonian (PN) theory and show the effectiveness of a simple PN-PM hybrid model. Finally, I make a first comparison of the radiated energy between self-force and numerical relativity.",
          "authors": [
            "Niels Warburton"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02277",
          "title": "Measuring $^{19,20}$O(p,n)$^{20,21}$F reactions using an active target detector",
          "abstract": "Proton capture on $^{19,20}$O nuclei is measured in inverse kinematics with the active target detector MuSIC@Indiana using CH$_4$ as the target gas. Rejection of unreacted and inelastically scattered beam, along with transfer and fusion on the $^{12}$C allows extraction of the (p,n) cross section. As the cross-section for direct (p,n) processes at these energies is small, the measurement provides access to the proton fusion cross-section. An analysis approach that allows extraction of the proton fusion cross-section is detailed.",
          "authors": [
            "Rohit Kumar",
            "H. Desilets",
            "R.T. deSouza"
          ],
          "primary_category": "nucl-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02292",
          "title": "Solitary Alfvén Waves",
          "abstract": "We present a three-dimensional numerical model of a solitary spherically polarized Alfvén wave packet -- an Alfvénon, characterized by open field-line topology and magnetic field reversals, resembling the switchbacks observed by Parker Solar Probe to be a nearly ubiquitous feature of turbulence in the inner heliosphere. Direct magnetohydrodynamic simulations of the constructed Alfvénon demonstrates remarkable stability, confirming its nature as an exact, nonlinear solution of the ideal MHD equations.",
          "authors": [
            "Zesen Huang",
            "Marco Velli",
            "Chen Shi",
            "Yuliang Ding"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02292",
          "title": "Solitary Alfvén Waves",
          "abstract": "We present a three-dimensional numerical model of a solitary spherically polarized Alfvén wave packet -- an Alfvénon, characterized by open field-line topology and magnetic field reversals, resembling the switchbacks observed by Parker Solar Probe to be a nearly ubiquitous feature of turbulence in the inner heliosphere. Direct magnetohydrodynamic simulations of the constructed Alfvénon demonstrates remarkable stability, confirming its nature as an exact, nonlinear solution of the ideal MHD equations.",
          "authors": [
            "Zesen Huang",
            "Marco Velli",
            "Chen Shi",
            "Yuliang Ding"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02295",
          "title": "Driving mechanisms of solar active region geysers: The role of interacting magnetic flux",
          "abstract": "Active region recurrent jets are manifestations of episodic magnetic energy release processes driven by complex interactions in the lower solar atmosphere. While magnetic flux emergence and cancellation are widely recognized as key contributors to jet formation, the mechanisms behind repeated magnetic reconnection remain poorly understood. In this letter, we report a sequence of nine recurrent jets originating from active region AR 12715 during its decay phase, where the jet activity was associated with a complex distribution of fragmented magnetic flux. Non-linear force-free field (NLFFF) extrapolations reveal the presence of low-lying, current-carrying loops beneath overarching open magnetic fields near the jet footpoints. These magnetic structures were perturbed by (i) emerging flux elements and (ii) interactions between oppositely polarized moving magnetic features (MMFs). To interpret these observations, we compare them with 3D radiative MHD simulation from the Bifrost model, which reproduce jet formation driven by interacting bipolar MMFs, leading to subsequent flux cancellation in the photosphere. Our results emphasize the critical role of MMF-driven flux interactions in initiating and sustaining recurrent jet activity in active regions.",
          "authors": [
            "Aabha Monga",
            "Satoshi Inoue",
            "Jeongwoo Lee",
            "Haimin Wang",
            "Viggo Hansteen"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02296",
          "title": "Observing binary neutron star subpopulations with the Einstein Telescope",
          "abstract": "The formation channels of binary neutron stars (BNSs) remain uncertain. The detection of GW190425 by LIGO/Virgo/KAGRA (LVK) suggests a subpopulation of massive BNSs, possibly formed through unstable \"case BB\" mass transfer with short merger delays. We investigate whether next-generation detectors such as the Einstein Telescope (ET) can identify and characterise such subpopulations. Using the latest LVK constraints on the BNS merger rate, we generate mock ET catalogues containing a mixture of light and heavy subpopulations. The redshift distribution of each subpopulation is modeled as the convolution of the cosmic star formation rate with a time-delay distribution: heavy BNSs have fixed short delays, while light BNSs follow power-law delays with indices -0.5,-1,-1.5. Hierarchical Bayesian analyses are then performed on catalogues of 100-5,000 events. With hundreds of detections from ET, we will be able to establish that the total mass distribution is bimodal. A few thousand events are sufficient to disentangle the redshift distributions of the two subpopulations for moderate time-delay indices (-0.5 or -1). For steeper indices (-1.5), the differences are more subtle, requiring larger catalogues, beyond what we could explore given our computational resources. Next-generation detectors should enable the detection of multiple BNS subpopulations and their redshift evolution, providing valuable insight into their formation pathways.",
          "authors": [
            "Alexandre Toubiana",
            "Irina Dvorkin"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02296",
          "title": "Observing binary neutron star subpopulations with the Einstein Telescope",
          "abstract": "The formation channels of binary neutron stars (BNSs) remain uncertain. The detection of GW190425 by LIGO/Virgo/KAGRA (LVK) suggests a subpopulation of massive BNSs, possibly formed through unstable \"case BB\" mass transfer with short merger delays. We investigate whether next-generation detectors such as the Einstein Telescope (ET) can identify and characterise such subpopulations. Using the latest LVK constraints on the BNS merger rate, we generate mock ET catalogues containing a mixture of light and heavy subpopulations. The redshift distribution of each subpopulation is modeled as the convolution of the cosmic star formation rate with a time-delay distribution: heavy BNSs have fixed short delays, while light BNSs follow power-law delays with indices -0.5,-1,-1.5. Hierarchical Bayesian analyses are then performed on catalogues of 100-5,000 events. With hundreds of detections from ET, we will be able to establish that the total mass distribution is bimodal. A few thousand events are sufficient to disentangle the redshift distributions of the two subpopulations for moderate time-delay indices (-0.5 or -1). For steeper indices (-1.5), the differences are more subtle, requiring larger catalogues, beyond what we could explore given our computational resources. Next-generation detectors should enable the detection of multiple BNS subpopulations and their redshift evolution, providing valuable insight into their formation pathways.",
          "authors": [
            "Alexandre Toubiana",
            "Irina Dvorkin"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02308",
          "title": "Geant4 Modeling of Energy and Charge Deposition in Satellites Solar Cells",
          "abstract": "Understanding radiation effects in spacecraft components is critical for predicting long-term performance degradation. In this work, a Geant4 Monte Carlo model is developed to compute charge and energy deposition in satellite solar-cell materials exposed to electrons, protons, and X-ray environments. The model is validated against published experimental and computational benchmarks and shows strong agreement across multiple energy ranges. Power-density deposition profiles are then evaluated for a multi-layer solar-cell structure under blackbody soft X-rays, mono-energetic X-rays, and high-energy electrons. The results show that low-energy X-rays dominate damage in surface layers, while high-energy particles penetrate deeper into semiconductor and substrate layers, posing risk to electronic components. These findings highlight the importance of radiation-specific shielding strategies for space solar-cell design.",
          "authors": [
            "Youssef Abouhussien",
            "Gennady Miloshevsky"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02320",
          "title": "How much gas and dust is in the $z=5.7$ Lyman Break Galaxy HZ10? An ALMA Band 10 to 4 and JWST/NIRSpec study of its interstellar medium",
          "abstract": "A complete overview of the stellar, gas and dust contents of galaxies is key to understanding their assembly at early times. However, an estimation of molecular and atomic gas reservoirs at high redshift relies on various indirect tracers, while robust dust mass measurements require multi-band far-infrared continuum observations. We take census of the full baryonic content of the main-sequence star-forming galaxy HZ10 at $z=5.65$, a unique case study where all necessary tracers are available. We present new ALMA Band 10 ($\\lambda_\\mathrm{rest}=50\\mu$m) and Band 4 ($300\\mu$m) observations towards HZ10, which combined with previously taken ALMA Band 6 through 9 data ($70-200\\mu$m) constrains its dust properties. We complete the baryonic picture using archival high-resolution [CII] observations that provide both a dynamical mass and molecular and atomic gas mass estimates, a JVLA CO(2-1)-based molecular gas mass, and JWST metallicity and stellar mass measurements. We detect continuum emission from HZ10 in Bands 10 and 4 at the $3.4-4.0\\sigma$ level, and measure a dust temperature of $T_\\mathrm{dust} = 37_{-5}^{+6}$K and dust mass $\\log(M_\\mathrm{dust}/M_\\odot) = 8.0 \\pm 0.1$. Leveraging the dynamical constraints, we infer its total gas budget, and find that commonly used [CII]-to-H$_2$ and [CII]-to-HI conversions overpredict the gas mass relative to the dynamical mass. For this reason, we derive a [CII]-to-total ISM mass (atomic + molecular) conversion factor, which for HZ10 corresponds to $\\alpha_\\mathrm{[CII]}^\\mathrm{ISM} = 39^{+50}_{-25}M_\\odot L_\\odot^{-1}$. We also find that HZ10 falls below the local scaling relation between dust-to-gas ratio and metallicity, suggesting inefficient ISM dust growth. These results demonstrate a powerful synergy between ALMA and JWST in disentangling the baryonic components of early galaxies, paving the way for future studies of larger samples.",
          "authors": [
            "H. S. B. Algera",
            "R. Herrera-Camus",
            "M. Aravena",
            "R. Assef",
            "T. L. J. C. Bakx",
            "A. Bolatto",
            "K. Cescon",
            "C.-C. Chen",
            "E. da Cunha",
            "P. Dayal",
            "I. De Looze",
            "T. Diaz-Santos",
            "A. Faisst",
            "A. Ferrara",
            "N. Förster Schreiber",
            "N. Hathi",
            "R. Ikeda",
            "H. Inami",
            "G. C. Jones",
            "A. Koekemoer",
            "D. Lutz",
            "M. Relaño",
            "M. Romano",
            "L. Rowland",
            "L. Sommovigo",
            "L. Vallini",
            "A. Vijayan",
            "V. Villanueva",
            "P. van der Werf"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02338",
          "title": "Leading effective field theory corrections to the Kerr metric at all spins",
          "abstract": "The leading corrections to General Relativity can be parametrized by higher-derivative interactions in a low-energy effective field theory, in a way that is general and agnostic to the precise UV completion of gravity. Using pseudospectral methods, we compute the leading-order corrections to the Kerr metric across the entire range of sub-extremal values of spin and analyse their impact on physical quantities. We find that near-extremal black holes are most affected by the higher-derivative corrections, making them especially sensitive probes of new physics. A dataset of solutions and the code used to produce them are publicly available.",
          "authors": [
            "Pedro G. S. Fernandes"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02338",
          "title": "Leading effective field theory corrections to the Kerr metric at all spins",
          "abstract": "The leading corrections to General Relativity can be parametrized by higher-derivative interactions in a low-energy effective field theory, in a way that is general and agnostic to the precise UV completion of gravity. Using pseudospectral methods, we compute the leading-order corrections to the Kerr metric across the entire range of sub-extremal values of spin and analyse their impact on physical quantities. We find that near-extremal black holes are most affected by the higher-derivative corrections, making them especially sensitive probes of new physics. A dataset of solutions and the code used to produce them are publicly available.",
          "authors": [
            "Pedro G. S. Fernandes"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02356",
          "title": "Segmented-Polynomial-fitting Least Squares (SPLS): An optimized algorithm to find Earth twins",
          "abstract": "Detecting Earth twins remains challenging because their shallow, long-period transits are difficult to distinguish from background noise. Motivated by the challenge, we developed Segmented-Polynomial-fitting Least Squares (SPLS), a new algorithm that simultaneously fits planetary transits and background trends using a segmented double polynomial model. Prior to signal detection, the optimal polynomial order for the trend component is selected using Bayes factor-based model comparison. During the periodogram search, the Signal Detection Efficiency metric is used to assess signal significance. The algorithm is accelerated by a three-step approximation and nonlinear parameter sampling tailored to SPLS. We compare the performance of SPLS with traditional detrending-detection approaches across different orbital periods, signal-to-noise ratios (SNR), planet radii and stellar noise levels on an injection-recovery test. When detecting signals with periods between 10 and 480 days and SNRs below 9, SPLS achieves at least a 22.6% higher true positive rate than other methods at the same 10% false positive rate. Using the threshold determined from the Receiver Operating Characteristic curve analysis, our method also recovers the most true signals while yielding the fewest false positives among all injected samples, and reaches a 97% recovery fraction in Kepler confirmed single-planet systems. The tests demonstrate that SPLS improves the detection of transiting planets, particularly for low-SNR, long-period signals. It offers the potential for finding Earth twins in future applications to data from Kepler, TESS, and upcoming PLATO and Earth 2.0 missions.",
          "authors": [
            "Shuyue Zheng",
            "Fabo Feng",
            "Yicheng Rui"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02357",
          "title": "Padé Approximants for Fast Radio Bursts Diffuse Dispersion Measure",
          "abstract": "Fast Radio Bursts (FRBs) have become an indispensable tool for studying the Universe's ionisation properties, as well as its cosmological parameters. This is achieved by analysing their diffuse dispersion measure (${\\rm DM}_{\\rm diff}$) as a function of redshift. However, this requires an integration along the line-of-sight, which is time-consuming. In this work, we derive an analytical approximation formula for ${\\rm DM}_{\\rm diff}$ for flat, $\\Lambda$CDM and $w$CDM universes. We show that our approximation works well for the ranges $0.01 \\leq z \\leq 2$, $0.2 \\leq \\Omega_m \\leq 1.0$ and $-3.0 \\leq w \\leq -0.5$, with relative fractional error to a numerically evaluated ${\\rm DM}_{\\rm diff}$ always smaller than $3.5\\ \\%$, in the worst case scenario, and in most cases smaller than $0.5\\ \\%$. Moreover, the approximation is more than $15$ ($2$) times faster than the numerical solution of $\\Lambda$CDM ($w$CDM). Therefore, we hope that it could be a useful tool for the FRB community.",
          "authors": [
            "Marios Kalomenopoulos",
            "Jiaming Zhuge"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02360",
          "title": "The first extragalactic ultra-compact X-ray binary : a candidate black hole-white dwarf system",
          "abstract": "M31 UCXB-1 is one of the brightest X-ray point sources in the bulge of M31, with a peak X-ray luminosity $ L_{\\mathrm{0.5-10 \\: keV}} = 2.9^{+0.2}_{-0.2} \\times 10^{38} \\: \\mathrm{erg} \\: \\mathrm{s}^{-1} $. Both XMM-Newton and Chandra observations have detected an eclipsing signal with a period of about 465 seconds from this source, and we note that the periodic signal is detected exclusively during the source's high-luminosity states. This signal probably originates from its orbital motion, therefore it is an ultra-compact X-ray binary (UCXB) candidate with the highest X-ray luminosity. Our theoretical analyses show that M31 UCXB-1 is in good agreement with the luminosity-orbital period relation ($ L_{\\mathrm{2-10 \\: keV}}-P_{\\mathrm{orb}} $) of the black hole/neutron star--white dwarf (BH/NS--WD) UCXB system. Moreover, our spectral analyses indicate that the primary in M31 UCXB-1 is more likely to be a BH rather than an NS. The results show that M31 UCXB-1 is a BH--WD system, with the shortest orbital period, the possibly strongest gravitational wave emission, and the most massive white dwarf among the known UCXBs.",
          "authors": [
            "Qian-Qi Ma",
            "Jiachang Zhang",
            "Wei-Min Gu",
            "Zhiyuan Li",
            "Shan-Shan Weng",
            "Tong Bao"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02391",
          "title": "\"SNe Ia twins\" in the Hubble flow, and the determination of H0",
          "abstract": "We have applied our approach of using ''SNe Ia twins''in the Hubble flow to obtain distances to SNe Ia at z $>$ 0.015 and derive H$_{0}$. Our results, taking a single step between the low z domain and the Hubble flow, validate the three rung classical method. We find, however, that the full compilation of distances, both in Pantheon+ and in the Carnegie-Chicago Hubble Program (CCHP), contain some inaccurate values in the colors due to an underestimate of reddening by dust. This produces odd individual values for H$_{0}$ from single SNe Ia. On the average, those erroneous estimates do not affect the mean value of H$_{0}$, which is characterized by the bulk of well--modeled SNe Ia. Our sample of carefully addressed SNe Ia in the Hubble flow contains a dozen supernovae, for which the distances are determined with high accuracy. Three of these SNe Ia are of the Broad Line subtype and can be compared with SN 1989B in M66, a host galaxy with a unique convergence of the Cepheid distance determination and the Tip of the Red Giant Branch stars (TRGB) determination by the CCHP group. They point to a weighted average of H$_{0}$ $=$ 73.556 $\\pm$ 2.084 (stat) km s$^{-1}$ Mpc $^{-1}$. There is as well a very good agreement on the distances to NGC 7250 and NGC 5643 between those derived with Cepheids by SH0ES and those derived with the use of J-Asymptotic Giant Branch stars (JAGB stars) by the CCHP, which makes them very good anchors. The sample of 12 SNe Ia gives a value of H$_{0}$ $=$ 72.833 $\\pm$ 1.306(stat) $\\pm$ 1.151 (sys) km s$^{-1}$ Mpc$^{-1}$, when anchored in Cepheids, and of H$_{0}$ $=$ 72.388 $\\pm$ 1.272 (stat) $\\pm$ 1.015 (sys) km s$^{-1}$ Mpc$^{-1}$, when anchored in JAGBs by the CCHP. We take a mean of the two values of H$_{0}$ and obtain H$_{0}$ $=$ 72.610 $\\pm$ 1.289(stat) $\\pm$ 1.085 (sys) km s$^{-1}$ Mpc$^{-1}$.",
          "authors": [
            "Pilar Ruiz-Lapuente",
            "Antonio Quintana-Estellés",
            "Jonay I. González Hernández",
            "Andrea Pastorello"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02407",
          "title": "Non-diagonal DVCS with spinless hadron-to-two-hadron transition $γ^* π\\to γππ$",
          "abstract": "We present the formalism of hadron-to-two-hadron transition generalized parton distributions (GPDs) for spinless hadron case. Definitions of the twist-2 unpolarized and polarized $\\pi\\to\\pi\\pi$ transition GPDs are introduced with a particular choice of kinematic variables that characterize the produced two-pion system. In the vicinity of $\\rho(770)$, we work out the two-pion decay angular distributions of the $e^-\\pi\\to e^-\\gamma\\pi\\pi$ cross section, incorporating both the Bethe-Heitler and deeply virtual Compton scattering processes. Each cross section exhibits a distinctive angular distribution, which is sensitive to the polarization states of the produced $\\rho(770)$ resonance. In addition, we construct the double partial-wave expansion of $\\pi\\to\\pi\\pi$ transition GPDs in the two-pion decay angles as a generalization of GPDs for transition from a pion to a spin-$\\ell$ resonance state. With the help of the Omnès representation, we constrain the $\\pi\\to\\pi\\pi$ transition GPDs in terms of the low energy $\\pi\\pi$ scattering phase shift and build a phenomenological model for these GPDs.",
          "authors": [
            "Sangyeong Son"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02407",
          "title": "Non-diagonal DVCS with spinless hadron-to-two-hadron transition $γ^* π\\to γππ$",
          "abstract": "We present the formalism of hadron-to-two-hadron transition generalized parton distributions (GPDs) for spinless hadron case. Definitions of the twist-2 unpolarized and polarized $\\pi\\to\\pi\\pi$ transition GPDs are introduced with a particular choice of kinematic variables that characterize the produced two-pion system. In the vicinity of $\\rho(770)$, we work out the two-pion decay angular distributions of the $e^-\\pi\\to e^-\\gamma\\pi\\pi$ cross section, incorporating both the Bethe-Heitler and deeply virtual Compton scattering processes. Each cross section exhibits a distinctive angular distribution, which is sensitive to the polarization states of the produced $\\rho(770)$ resonance. In addition, we construct the double partial-wave expansion of $\\pi\\to\\pi\\pi$ transition GPDs in the two-pion decay angles as a generalization of GPDs for transition from a pion to a spin-$\\ell$ resonance state. With the help of the Omnès representation, we constrain the $\\pi\\to\\pi\\pi$ transition GPDs in terms of the low energy $\\pi\\pi$ scattering phase shift and build a phenomenological model for these GPDs.",
          "authors": [
            "Sangyeong Son"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02431",
          "title": "High-Precision Amplitude-Modulated Continuous-Wave Lunar Laser Ranging",
          "abstract": "Lunar laser ranging (LLR) currently delivers mm-class tests of relativistic gravity and the lunar interior, but further gains are limited by photon-starved pulsed systems, array-induced pulse broadening, and atmospheric variability. Pushing into the sub-0.1mm regime is required to probe ultra-slow tidal dissipation, long-period librations, uHz-band gravitational waves. We develop a complete amplitude-modulated continuous-wave (AM-CW) framework for high-power LLR, including measurement models, estimators, a unified covariance description, and an observatory CONOPS. CW LLR is treated as RF phase metrology on a bright CW optical carrier: 2-way range and 1-way line-of-sight range-rate obtained from the phase and phase slope of a GHz-class modulation tone. The joint estimators are characterized by a covariance matrix decomposed into photon, atmospheric, instrumental, oscillator, nonlinearity contributions, mapped into subsystem requirements, including a closed-form range-rate bias from modulation-frequency slew across the ~2.56s round trip and synthetic-wavelength constraints on multi-tone nonlinearity. Using realistic photon budgets for a 1 kW, 1064 nm CW transmitter on a 1-m telescope ranging to 10cm corner-cube retroreflectors, we show that the photon-statistical floor for 2-way range at a GHz-class modulation frequency is at the level of a few-10 um in ~100s. With allocations to residual atmosphere and instrument, the resulting single-station 2-way precision is ~80 um, with range-rate sensitivities of ~0.1-1 um/s. Differential LLR between reflectors separated on the Moon by ~1000km can deliver 20-50 um and few (0.1-1) um/s differential range and range-rate. These precisions are realized across three representative regimes that span detected photon rates of (5-7) x 10^3-10^5 s^{-1} and are translated directly into hardware and CONOPS requirements for next-generation high-power AM-CW LLR.",
          "authors": [
            "Slava G. Turyshev"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02434",
          "title": "The exotic black hole-neutron star binaries in our Galaxy",
          "abstract": "It has been suggested that there are $\\sim 10^5$ black hole-neutron star (BH-NS) binaries in our Galaxy. However, despite the effort of intensive radio search for decades, none of these binaries has been found to date. These binaries are regarded as a holy grail of astronomy because they can greatly improve our understanding about relativistic systems of compact objects and fundamental physics. In this article, we propose the existence of exotic BH-NS binaries which can open a new way in searching the missing BH-NS binaries in our Galaxy. By considering the possible dark matter density spikes formed around the primordial black holes in the BH-NS binaries, we show that extremely high temperature ($\\sim 10^6$ K) could be maintained on the surface of the neutron stars due to effective dark matter capture. This interesting feature can also help reveal the nature of dark matter and possibly further improve the upper limit of dark matter scattering cross section well below $10^{-47}$ cm$^2$.",
          "authors": [
            "Man Ho Chan"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02439",
          "title": "Structure and Mass-Radius Stability of Charged Compact Objects in Symmetric Teleparallel Euler-Heisenberg Gravity",
          "abstract": "In this work, we develop a new relativistic model for a charged anisotropic compact star in the framework of modified symmetric teleparallel gravity, namely $f(Q)$-Euler-Heisenberg gravity. By employing the MIT bag model equation of state, we establish a relation between the metric potentials, leading to an exact solution of the field equations for an anisotropic fluid configuration coupled with a non-linear electromagnetic source. The interior spacetime is smoothly matched with the exterior geometry calculated from the theoretical setup of $f(Q)$-Euler-Heisenberg gravity using the Darmois-Israel junction conditions, ensuring the continuity of the metric functions and their derivatives at the stellar boundary. The physical viability of the model is examined through regularity, energy, and causality conditions, all of which are satisfied throughout the stellar interior. The study highlights how the pressure anisotropy, the propagation speeds of sound, and the Tolman-Oppenheimer-Volkoff balance condition are interconnected, showing that the star remains in mechanical equilibrium only when the gravitational, hydrostatic, electric, and anisotropic contributions counterbalance one another appropriately. The dynamical stability of the configuration is further supported by the requirement $\\Gamma > \\tfrac{4}{3}$ for the adiabatic index, indicating resilience against small radial perturbations. The plots of compactness, surface redshift, and the mass--radius profiles confirm that all physical quantities behave regularly and vary smoothly throughout the stellar interior. We graphically plotted the mass-radius curves.",
          "authors": [
            "Allah Ditta",
            "M.Yousaf",
            "G.Mustafa",
            "S.K.Maurya",
            "Farruh Atamurotov",
            "Orhan Donmez",
            "Sardor Murodov"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02440",
          "title": "Evolution and Mass Dependence of UV-to-near-IR Color Gradients up to z=2.5 from HST+JWST",
          "abstract": "We present the redshift evolution of radial color gradients (in rest-frame ${\\textit{U}} - {\\textit{V}}$ and ${\\textit{V}} - {\\textit{J}}$) for galaxies in the range $0.5<$ z $<2.5$ and investigate their origin and dependence on stellar mass. We select $\\sim 10,200$ galaxies with stellar masses $M_\\star>10^{9.5}~{\\text{M}}_\\odot$ from publicly available JWST/NIRCam-selected catalogs. Using 2D Sérsic profile fits to account for PSF broadening, we perform spatially resolved SED fitting on HST and JWST/NIRCam photometry retrieving accurate rest-frame ${\\textit{U}} - {\\textit{V}}$ and ${\\textit{V}} - {\\textit{J}}$ color gradients within 2$R_\\text{e, F444W}$. Star-forming galaxies generally exhibit negative ${\\textit{V}} - {\\textit{J}}$ color gradients that are strongly mass and redshift dependent. For massive star-forming galaxies ($M_\\star>10^{10.5}~{\\text{M}}_\\odot$) at $z>1.5$ ${\\textit{V}} - {\\textit{J}}$ colors are $\\approx 0.5$ mag redder within the effective radius than outside, on average. We find that, at all redshifts and across the entire stellar mass range, ${\\textit{V}} - {\\textit{J}}$ gradients strongly correlate with global attenuation ($A_V$), suggesting that they predominantly trace dust attenuation gradients. Edge-on galaxies are redder and have stronger gradients at all $z$, although the correlation weakens at higher $z$. The ${\\textit{U}} - {\\textit{V}}$ and ${\\textit{V}} - {\\textit{J}}$ color gradients in the quiescent galaxy population, in contrast, are weakly negative (from $\\approx -0.1$ to $\\approx- 0.2$ mag), though significant, and show little or no dependence on stellar mass, redshift or axis ratio. The implication is that quiescent galaxies must be largely transparent, with low $A_V$, and color gradients mostly attributable to stellar population gradients.",
          "authors": [
            "Marco Martorano",
            "Arjen van der Wel",
            "Andrea Gebek",
            "Eric F. Bell",
            "Gabriel Brammer",
            "Sharon E. Meidt",
            "Angelos Nersesian",
            "Katherine Whitaker",
            "Stijn Wuyts"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02475",
          "title": "Neutron-deuteron scattering revisited with the EKM chiral nuclear force and the WPCD method",
          "abstract": "We revisit the neutron-deuteron scattering using the Wave-Packet Continuum Discretization (WPCD) method with the EKM chiral nuclear force at various chiral orders. We rederive the permutation operator and solve the Faddeev-AGS equations directly, without rewriting the initial Faddeev kernel $tG_0$ and introducing pseudo-states, thereby rendering the approach easily extendable to a relativistic framework. We find that up to the next-to-next-to-next-to-leading order (N$^3$LO), although one can well describe the differential cross sections, one cannot resolve the long-standing $A_y$ puzzle, consistent with previous studies. The fact that the N$^3$LO chiral forces can well describe the $NN$ phase shifts and the results obtained with the EKM and Idaho N$^3$LO chiral forces agree with each other underscores the need for further investigations to resolve the $A_y$ puzzle, e.g., considering three-body forces or relativistic effects.",
          "authors": [
            "Qing-Yu Zhai",
            "Dan-Yang Pang",
            "Wen-Di Chen",
            "O. A. Rubtsova",
            "Rui-Rui Xu",
            "Jun-Xu Lu",
            "Haozhao Liang",
            "Li-Sheng Geng"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02475",
          "title": "Neutron-deuteron scattering revisited with the EKM chiral nuclear force and the WPCD method",
          "abstract": "We revisit the neutron-deuteron scattering using the Wave-Packet Continuum Discretization (WPCD) method with the EKM chiral nuclear force at various chiral orders. We rederive the permutation operator and solve the Faddeev-AGS equations directly, without rewriting the initial Faddeev kernel $tG_0$ and introducing pseudo-states, thereby rendering the approach easily extendable to a relativistic framework. We find that up to the next-to-next-to-next-to-leading order (N$^3$LO), although one can well describe the differential cross sections, one cannot resolve the long-standing $A_y$ puzzle, consistent with previous studies. The fact that the N$^3$LO chiral forces can well describe the $NN$ phase shifts and the results obtained with the EKM and Idaho N$^3$LO chiral forces agree with each other underscores the need for further investigations to resolve the $A_y$ puzzle, e.g., considering three-body forces or relativistic effects.",
          "authors": [
            "Qing-Yu Zhai",
            "Dan-Yang Pang",
            "Wen-Di Chen",
            "O. A. Rubtsova",
            "Rui-Rui Xu",
            "Jun-Xu Lu",
            "Haozhao Liang",
            "Li-Sheng Geng"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02475",
          "title": "Neutron-deuteron scattering revisited with the EKM chiral nuclear force and the WPCD method",
          "abstract": "We revisit the neutron-deuteron scattering using the Wave-Packet Continuum Discretization (WPCD) method with the EKM chiral nuclear force at various chiral orders. We rederive the permutation operator and solve the Faddeev-AGS equations directly, without rewriting the initial Faddeev kernel $tG_0$ and introducing pseudo-states, thereby rendering the approach easily extendable to a relativistic framework. We find that up to the next-to-next-to-next-to-leading order (N$^3$LO), although one can well describe the differential cross sections, one cannot resolve the long-standing $A_y$ puzzle, consistent with previous studies. The fact that the N$^3$LO chiral forces can well describe the $NN$ phase shifts and the results obtained with the EKM and Idaho N$^3$LO chiral forces agree with each other underscores the need for further investigations to resolve the $A_y$ puzzle, e.g., considering three-body forces or relativistic effects.",
          "authors": [
            "Qing-Yu Zhai",
            "Dan-Yang Pang",
            "Wen-Di Chen",
            "O. A. Rubtsova",
            "Rui-Rui Xu",
            "Jun-Xu Lu",
            "Haozhao Liang",
            "Li-Sheng Geng"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02484",
          "title": "Properties of Stable Massive Quark Stars in Holography",
          "abstract": "We study a holographic D3/D7 system, whose dilaton profile has been phenomenologically adjusted in the infrared. The model is used to describe a deconfined yet massive quark phase of QCD at finite density, concluding that the equation of state of such a phase can be stiff enough to support exotic dense stars as massive as 2 solar masses. Nucleons are modeled phenomenologically using the this http URL EFT baryon phases. For the stiff phenomenological baryon phases the transition to the quark phase is weakly first order allowing for stable quark cores. We also find that holographic baryons, modeled as wrapped D5-branes, provide unrealistic pressures (in the homogeneous approximation) and have to be discarded. We compute the mass vs. radius relation and tidal deformability for these hybrid stars. Contrary to a large number of other holographic models, this holographic model indicates that quark matter could be present at the core of heavy compact stars and may be used to explore the phenomenology of such objects.",
          "authors": [
            "Kazem Bitaghsir Fadafan",
            "Jesús Cruz Rojas",
            "Jonas Mager"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02484",
          "title": "Properties of Stable Massive Quark Stars in Holography",
          "abstract": "We study a holographic D3/D7 system, whose dilaton profile has been phenomenologically adjusted in the infrared. The model is used to describe a deconfined yet massive quark phase of QCD at finite density, concluding that the equation of state of such a phase can be stiff enough to support exotic dense stars as massive as 2 solar masses. Nucleons are modeled phenomenologically using the this http URL EFT baryon phases. For the stiff phenomenological baryon phases the transition to the quark phase is weakly first order allowing for stable quark cores. We also find that holographic baryons, modeled as wrapped D5-branes, provide unrealistic pressures (in the homogeneous approximation) and have to be discarded. We compute the mass vs. radius relation and tidal deformability for these hybrid stars. Contrary to a large number of other holographic models, this holographic model indicates that quark matter could be present at the core of heavy compact stars and may be used to explore the phenomenology of such objects.",
          "authors": [
            "Kazem Bitaghsir Fadafan",
            "Jesús Cruz Rojas",
            "Jonas Mager"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02484",
          "title": "Properties of Stable Massive Quark Stars in Holography",
          "abstract": "We study a holographic D3/D7 system, whose dilaton profile has been phenomenologically adjusted in the infrared. The model is used to describe a deconfined yet massive quark phase of QCD at finite density, concluding that the equation of state of such a phase can be stiff enough to support exotic dense stars as massive as 2 solar masses. Nucleons are modeled phenomenologically using the this http URL EFT baryon phases. For the stiff phenomenological baryon phases the transition to the quark phase is weakly first order allowing for stable quark cores. We also find that holographic baryons, modeled as wrapped D5-branes, provide unrealistic pressures (in the homogeneous approximation) and have to be discarded. We compute the mass vs. radius relation and tidal deformability for these hybrid stars. Contrary to a large number of other holographic models, this holographic model indicates that quark matter could be present at the core of heavy compact stars and may be used to explore the phenomenology of such objects.",
          "authors": [
            "Kazem Bitaghsir Fadafan",
            "Jesús Cruz Rojas",
            "Jonas Mager"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02506",
          "title": "Non-vanishing non-linear Static Love Number of a Class of Extremal Reissner-Nordstrom Black Holes",
          "abstract": "We compute the tidal Love numbers for a particular axially symmetric configuration of extremal Reissner-Nordstrom geometry. By exactly solving the non-linear Einstein equations, we investigate the tidal response of extremal Reissner-Nordstrom black holes in four-dimensional spacetimes under external gravitational fields. We show that, for the specific geometry considered, the static tidal Love number remains finite and non-vanishing to all orders in the external tidal field. By contrast, we verify that the Love number of an isolated extremal Reissner-Nordstrom black hole remains zero, in agreement with previous expectations. Furthermore, we explicitly calculate the Zerilli-Moncrief master functions and match them with the effective field theory description.",
          "authors": [
            "L.R. Gounis",
            "A. Kehagias",
            "G. Panagopoulos",
            "A. Riotto"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02506",
          "title": "Non-vanishing non-linear Static Love Number of a Class of Extremal Reissner-Nordstrom Black Holes",
          "abstract": "We compute the tidal Love numbers for a particular axially symmetric configuration of extremal Reissner-Nordstrom geometry. By exactly solving the non-linear Einstein equations, we investigate the tidal response of extremal Reissner-Nordstrom black holes in four-dimensional spacetimes under external gravitational fields. We show that, for the specific geometry considered, the static tidal Love number remains finite and non-vanishing to all orders in the external tidal field. By contrast, we verify that the Love number of an isolated extremal Reissner-Nordstrom black hole remains zero, in agreement with previous expectations. Furthermore, we explicitly calculate the Zerilli-Moncrief master functions and match them with the effective field theory description.",
          "authors": [
            "L.R. Gounis",
            "A. Kehagias",
            "G. Panagopoulos",
            "A. Riotto"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02506",
          "title": "Non-vanishing non-linear Static Love Number of a Class of Extremal Reissner-Nordstrom Black Holes",
          "abstract": "We compute the tidal Love numbers for a particular axially symmetric configuration of extremal Reissner-Nordstrom geometry. By exactly solving the non-linear Einstein equations, we investigate the tidal response of extremal Reissner-Nordstrom black holes in four-dimensional spacetimes under external gravitational fields. We show that, for the specific geometry considered, the static tidal Love number remains finite and non-vanishing to all orders in the external tidal field. By contrast, we verify that the Love number of an isolated extremal Reissner-Nordstrom black hole remains zero, in agreement with previous expectations. Furthermore, we explicitly calculate the Zerilli-Moncrief master functions and match them with the effective field theory description.",
          "authors": [
            "L.R. Gounis",
            "A. Kehagias",
            "G. Panagopoulos",
            "A. Riotto"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02524",
          "title": "Relativistic correction to the binding energies of two-body hadronic molecular states",
          "abstract": "This study presents a systematic estimation of the relativistic correction to the binding energies of two-body hadronic molecular states by comparing the numerical solutions of the three-dimensional (3D) Schr{ö}dinger, 3D Salpeter, and fully relativistic four-dimensional (4D) Bethe-Salpeter (BS) equations derived from the same underlying interaction. The numerical results reveal a counter-intuitive property: for hadronic molecular states whose binding energies are in the MeV range, the relativistic correction is unexpectedly large. This finding contradicts the conventional expectation that a heavier exchanged mass in the interaction implies suppressed relativistic effects. Specifically, we first benchmark the results using the Wick-Cutkosky model with a one-boson-exchange (OBE) interaction of mass $m_{ex}$, and then extend the analysis to the physical $D\\bar{D}$ system. We find within the $1\\sim 50$ MeV binding energy region, the relativistic correction is substantial, amounting to $-90\\% \\sim -70\\%$ of the non-relativistic result. Such a significant correction strongly suggests that analyses based solely on the 3D Schr{ö}dinger or 3D Salpeter equations for hadronic molecular states should be treated with caution.",
          "authors": [
            "Lin-Qing Song",
            "Hai-Qing Zhou"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02524",
          "title": "Relativistic correction to the binding energies of two-body hadronic molecular states",
          "abstract": "This study presents a systematic estimation of the relativistic correction to the binding energies of two-body hadronic molecular states by comparing the numerical solutions of the three-dimensional (3D) Schr{ö}dinger, 3D Salpeter, and fully relativistic four-dimensional (4D) Bethe-Salpeter (BS) equations derived from the same underlying interaction. The numerical results reveal a counter-intuitive property: for hadronic molecular states whose binding energies are in the MeV range, the relativistic correction is unexpectedly large. This finding contradicts the conventional expectation that a heavier exchanged mass in the interaction implies suppressed relativistic effects. Specifically, we first benchmark the results using the Wick-Cutkosky model with a one-boson-exchange (OBE) interaction of mass $m_{ex}$, and then extend the analysis to the physical $D\\bar{D}$ system. We find within the $1\\sim 50$ MeV binding energy region, the relativistic correction is substantial, amounting to $-90\\% \\sim -70\\%$ of the non-relativistic result. Such a significant correction strongly suggests that analyses based solely on the 3D Schr{ö}dinger or 3D Salpeter equations for hadronic molecular states should be treated with caution.",
          "authors": [
            "Lin-Qing Song",
            "Hai-Qing Zhou"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02526",
          "title": "Updates on dipolar anisotropy in local measurements of the Hubble constant from Cosmicflows-4",
          "abstract": "Recent observations show a persistent tension in the Hubble constant $H_0$, suggesting an incomplete understanding of cosmic expansion and local dynamics. Using the Cosmicflows-4 catalogue, we mapped the angular and radial variations of $H_0$ in radial shells with a distance modulus $\\mu \\in [29,36]$ (approximately corresponding to $[20,100]$ $h^{-1}$ Mpc) and equal-area sky patches, applied adaptive weighing, and fitted spherical harmonics up to the octupole. Our results reveal a clear, distance-decreasing dipole that remains coherent across shells, with subdominant higher-order multipoles, and the octupole fit capturing the main anisotropic features except in sparsely sampled or SDSS-dominated shells. The direction and amplitude of the dipole depend on whether the observed radial recessional velocities are corrected for peculiar velocities or not. If the correction is not applied, the dipole aligns with the major gravitational structures in the local universe. If it is applied, a global dipole still seems to be present, but the signal is much weaker and with much lower statistical significance. This decrease in the amplitude of the dipole supports the idea of a differential expansion rate in our universe, but does not clarify whether the origin is astrophysical or cosmological. Finally, we verify that, while this anisotropy could influence local measurements of the Hubble constant, its effect on the large-scale Hubble tension appears to be limited, as the distribution of galaxies hosting SNeIa, both used as calibrators to constrain $H_0$ and in the Hubble-flow, does not show a strong correlation with the dipole signal.",
          "authors": [
            "Vincenzo Salzano",
            "J. Beltrán Jiménez",
            "Dario Bettoni",
            "Philippe Brax",
            "Aurélien Valade"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02526",
          "title": "Updates on dipolar anisotropy in local measurements of the Hubble constant from Cosmicflows-4",
          "abstract": "Recent observations show a persistent tension in the Hubble constant $H_0$, suggesting an incomplete understanding of cosmic expansion and local dynamics. Using the Cosmicflows-4 catalogue, we mapped the angular and radial variations of $H_0$ in radial shells with a distance modulus $\\mu \\in [29,36]$ (approximately corresponding to $[20,100]$ $h^{-1}$ Mpc) and equal-area sky patches, applied adaptive weighing, and fitted spherical harmonics up to the octupole. Our results reveal a clear, distance-decreasing dipole that remains coherent across shells, with subdominant higher-order multipoles, and the octupole fit capturing the main anisotropic features except in sparsely sampled or SDSS-dominated shells. The direction and amplitude of the dipole depend on whether the observed radial recessional velocities are corrected for peculiar velocities or not. If the correction is not applied, the dipole aligns with the major gravitational structures in the local universe. If it is applied, a global dipole still seems to be present, but the signal is much weaker and with much lower statistical significance. This decrease in the amplitude of the dipole supports the idea of a differential expansion rate in our universe, but does not clarify whether the origin is astrophysical or cosmological. Finally, we verify that, while this anisotropy could influence local measurements of the Hubble constant, its effect on the large-scale Hubble tension appears to be limited, as the distribution of galaxies hosting SNeIa, both used as calibrators to constrain $H_0$ and in the Hubble-flow, does not show a strong correlation with the dipole signal.",
          "authors": [
            "Vincenzo Salzano",
            "J. Beltrán Jiménez",
            "Dario Bettoni",
            "Philippe Brax",
            "Aurélien Valade"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02526",
          "title": "Updates on dipolar anisotropy in local measurements of the Hubble constant from Cosmicflows-4",
          "abstract": "Recent observations show a persistent tension in the Hubble constant $H_0$, suggesting an incomplete understanding of cosmic expansion and local dynamics. Using the Cosmicflows-4 catalogue, we mapped the angular and radial variations of $H_0$ in radial shells with a distance modulus $\\mu \\in [29,36]$ (approximately corresponding to $[20,100]$ $h^{-1}$ Mpc) and equal-area sky patches, applied adaptive weighing, and fitted spherical harmonics up to the octupole. Our results reveal a clear, distance-decreasing dipole that remains coherent across shells, with subdominant higher-order multipoles, and the octupole fit capturing the main anisotropic features except in sparsely sampled or SDSS-dominated shells. The direction and amplitude of the dipole depend on whether the observed radial recessional velocities are corrected for peculiar velocities or not. If the correction is not applied, the dipole aligns with the major gravitational structures in the local universe. If it is applied, a global dipole still seems to be present, but the signal is much weaker and with much lower statistical significance. This decrease in the amplitude of the dipole supports the idea of a differential expansion rate in our universe, but does not clarify whether the origin is astrophysical or cosmological. Finally, we verify that, while this anisotropy could influence local measurements of the Hubble constant, its effect on the large-scale Hubble tension appears to be limited, as the distribution of galaxies hosting SNeIa, both used as calibrators to constrain $H_0$ and in the Hubble-flow, does not show a strong correlation with the dipole signal.",
          "authors": [
            "Vincenzo Salzano",
            "J. Beltrán Jiménez",
            "Dario Bettoni",
            "Philippe Brax",
            "Aurélien Valade"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02560",
          "title": "Excitation function of femtoscopic Lévy source parameters of pion pairs in EPOS4",
          "abstract": "Three-dimensional (3D) femtoscopic source parameters of pions provide a sensitive probe of the space-time structure of particle-emitting sources in high-energy heavy-ion collisions. Compared to one-dimensional measurements, 3D femtoscopy not only provides a valuable cross-check but also offers a more complete characterization of the source geometry and its dynamical evolution. Particularly, differences between the \"out\" and \"side\" directions are sensitive to signals of a strong first-order phase transition, while the collision-energy dependence of Levy radii may reveal non-monotonic features related to the equation of state (EoS). In this work, we systematically investigate the transverse mass and collision-energy dependence of the three-dimensional femtoscopic parameters of pion pairs with Levy-type sources in the STAR Beam Energy Scan (BES) range from $\\sqrt{s_{NN}} = 7.7$ to $200$ GeV using the EPOS4 model. The analyzed parameters include the Levy index $\\alpha$, the correlation strength $\\lambda$, and the three-dimensional radii $R_{\\rm {out}}$, $R_{\\rm side}$ and $R_{\\rm long}$ , derived quantities such as the radius difference $R_{\\rm diff} = R_{\\rm out}^2 - R_{\\rm side}^2$ and the ratio $R_{\\rm out}/R_{\\rm side}$ are also investigated. The results show that the extracted radii $R_{\\rm {side}}$ and $R_{\\rm long}$ decrease with increasing transverse momentum and increase gradually with collision energy, while $R_{\\rm {out}}$ shows little energy dependence. The Levy index $\\alpha$ exhibits only a mild dependence on $m_T$ and collision energy, whereas the correlation strength $\\lambda$ shows a clear $m_T$ dependence and generally decreases with increasing collision energy. A comparison with EPOS3 results indicates general agreement within approximately 2$\\sigma$, with the notable exception of $R_{\\rm side}$, which is systematically smaller in EPOS4.",
          "authors": [
            "Yan Huang",
            "Matyas Molnar",
            "Daniel Kincses",
            "Mate Csanad"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02560",
          "title": "Excitation function of femtoscopic Lévy source parameters of pion pairs in EPOS4",
          "abstract": "Three-dimensional (3D) femtoscopic source parameters of pions provide a sensitive probe of the space-time structure of particle-emitting sources in high-energy heavy-ion collisions. Compared to one-dimensional measurements, 3D femtoscopy not only provides a valuable cross-check but also offers a more complete characterization of the source geometry and its dynamical evolution. Particularly, differences between the \"out\" and \"side\" directions are sensitive to signals of a strong first-order phase transition, while the collision-energy dependence of Levy radii may reveal non-monotonic features related to the equation of state (EoS). In this work, we systematically investigate the transverse mass and collision-energy dependence of the three-dimensional femtoscopic parameters of pion pairs with Levy-type sources in the STAR Beam Energy Scan (BES) range from $\\sqrt{s_{NN}} = 7.7$ to $200$ GeV using the EPOS4 model. The analyzed parameters include the Levy index $\\alpha$, the correlation strength $\\lambda$, and the three-dimensional radii $R_{\\rm {out}}$, $R_{\\rm side}$ and $R_{\\rm long}$ , derived quantities such as the radius difference $R_{\\rm diff} = R_{\\rm out}^2 - R_{\\rm side}^2$ and the ratio $R_{\\rm out}/R_{\\rm side}$ are also investigated. The results show that the extracted radii $R_{\\rm {side}}$ and $R_{\\rm long}$ decrease with increasing transverse momentum and increase gradually with collision energy, while $R_{\\rm {out}}$ shows little energy dependence. The Levy index $\\alpha$ exhibits only a mild dependence on $m_T$ and collision energy, whereas the correlation strength $\\lambda$ shows a clear $m_T$ dependence and generally decreases with increasing collision energy. A comparison with EPOS3 results indicates general agreement within approximately 2$\\sigma$, with the notable exception of $R_{\\rm side}$, which is systematically smaller in EPOS4.",
          "authors": [
            "Yan Huang",
            "Matyas Molnar",
            "Daniel Kincses",
            "Mate Csanad"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02572",
          "title": "The near-Sun Heliospheric Current Sheet, fluid and kinetic properties",
          "abstract": "The heliospheric current sheet (HCS) is an important large-scale structure of the heliosphere, and, for the first time, the Parker Solar Probe (PSP) mission enables us to study its properties statistically close to the Sun. We visually identify the 39 HCS crossings measured by PSP below 50~\\Rs~during encounters 6 to 21, and investigate the occurrence and properties of magnetic reconnection, the behavior of the spectral properties of the turbulent energy cascade, and the occurrence of kinetic instabilities at the HCS. We find that 82\\% of HCS crossings present signatures of reconnection jets, showing that the HCS is continuously reconnecting close to the Sun. The proportion of inward/outward jets depends on heliocentric distance, and the main HCS reconnection X-line has a higher probability of being located close to the Alfvén surface. We also observe a radial asymmetry in jet acceleration, where inward jets do not reach the local Alfvén speed, contrary to outward jets. We find that turbulence levels are enhanced in the ion kinetic range, consistent with the triggering of an inverse cascade by magnetic reconnection. Finally, we highlight the ubiquity of magnetic hole trains in the high $\\beta$ environment of the HCS, showing that the mirror mode instability plays a key role in regulating the ion temperature anisotropy in HCS reconnection. Our findings shed new light on the properties of magnetic reconnection in the high $\\beta$ plasma environment of the HCS, its interplay with the turbulent cascade and the role of the mirror mode instability.",
          "authors": [
            "Naïs Fargette",
            "Jonathan P. Eastwood",
            "Tai D. Phan",
            "Lorenzo Matteini",
            "Luca Franci"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02574",
          "title": "Modeling Particle Acceleration and MWL Emission of a PeVatron Microquasar V4641 Sgr",
          "abstract": "The Large High Altitude Air Shower Observatory (LHAASO) has recently reported five Galactic microquasars as Ultra-High-Energy (UHE) $\\gamma$-ray emitters (> 100 TeV). Among these sources, the microquasar V4641 Sgr exhibits $\\gamma$-ray emission up to $\\sim$0.8 PeV, requiring the acceleration of particles to multi-PeV energies, as well as the hardest UHE spectrum. The mechanisms behind particle acceleration to such energies are not well understood. Furthermore, the limited multi-wavelength (MWL) information on this source appears contradictory, further complicating interpretation and suggesting that V4641 Sgr may represent a particularly unusual case. In this work, we present a detailed physical model of V4641 Sgr that combines first-principles simulations of stochastic (turbulent) particle acceleration with MWL emission modeling. We adopt a leptonic scenario in which electrons are accelerated via the second-order Fermi process driven by relativistic strong turbulence ($\\delta B/B \\sim 1$). The particle energization is simulated using a dedicated Monte Carlo framework STRIPE that incorporates the effects of intermittent energy gains and radiative losses. The resulting accelerated electrons produce UHE $\\gamma$-rays through inverse Compton scattering on both the cosmic microwave background (CMB) and the interstellar radiation fields (ISRF). Our model is capable of reproducing key observational characteristics of the system, including particle acceleration to energies of tens of PeV, as well as the TeV-PeV $\\gamma$-ray spectrum and the hard spectral index measured by LHAASO. Nonetheless, several aspects remain unresolved, highlighting the need for deeper observational coverage and further theoretical refinement.",
          "authors": [
            "Anton Dmytriiev",
            "Frans van der Merwe",
            "Markus Böttcher"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02587",
          "title": "Quantification of abundance uncertainties in chemical models of exoplanet atmospheres",
          "abstract": "Chemical models are routinely used to predict the atmospheric composition of exoplanets and compare it with the composition retrieved from observations, but little is known about the reliability of the calculated composition. We carried out a sensitivity analysis to quantify the uncertainties in the abundances calculated by a state-of-the-art chemical atmosphere model of the widely observed planets WASP-33b, HD209458b, HD189733b, WASP-39b, GJ436b, and GJ1214b. We found that the abundance uncertainties in the observable atmosphere are relatively small, below one order of magnitude and in many cases below a factor of two, where vertical mixing is a comparable or even larger source of uncertainty than (photo)chemical kinetics. In general, planets with a composition close to chemical equilibrium have smaller abundance uncertainties than planets whose composition is dominated by photochemistry. Some molecules, such as H2O, CO, CO2, and SiO, show low abundance uncertainties, while others such as HCN, SO2, PH3, and TiO have more uncertain abundances. We identified several critical albeit poorly constrained processes involving S-, P-, Si-, and Ti-bearing species whose better characterization should lead to a global improvement in the accuracy of models. Some of these key processes are the three-body association reactions S + H2, Si + O, NH + N, and N2H2 + H; the chemical reactions S + OH --> SO + H, NS + NH2 --> H2S + N2, P + PH --> P2 + H, and N + NH3 --> N2H + H2; and the photodissociation of molecules such as P2, PH2, SiS, CH, and TiO.",
          "authors": [
            "Marcelino Agundez"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02588",
          "title": "A Statistical Analysis of Fluence and Energy Distributions of Non-repeating Fast Radio Bursts Detected by CHIME",
          "abstract": "Fast Radio Bursts (FRBs) are energetic radio bursts that typically last for milliseconds. They are mostly of extragalactic origin, but the progenitors, trigger mechanisms and radiation processes are still largely unknown. Here we present a comprehensive analysis on 415 non-repeating FRBs detected by CHIME, applying manual filtering to ensure sample completeness. It is found that the distribution of fluence can be approximated by a three-segment power-law function, with the power-law indices being $-3.76 \\pm 1.61$, $0.20 \\pm 0.68$ and $2.06 \\pm 0.90$ in the low, middle, and high fluence segments, respectively. Both the total dispersion measure (\\text{DM}) and the extragalactic \\text{DM} follow a smoothly broken power-law distribution, with characteristic break DM values of $\\sim 703$ pc $\\rm cm^{-3}$ and $\\sim 639$ pc $\\rm cm^{-3}$, respectively. The redshifts are estimated from the extragalactic \\text{DM} by using the Macquart relation, which are found to peak at $ z \\sim 0.6$. The isotropic energy release ($E_{\\text{iso}}$) is also derived for each burst. Two-Gaussian components are revealed in the distribution of $E_{\\text{iso}}$, with the major population narrowly clustered at $\\sim 2.3 \\times 10^{40} {\\rm erg}$. The minor population have a characteristic energy of $\\sim 1.6 \\times 10^{39}$ erg and span approximately one order of magnitude. The distribution hints a near-uniform energy release mechanism for the dominant population as expected from some catastrophic channels, whereas the lower-energy component (potentially including repeat-capable sources) may reflect a broader diversity in FRB origins, emission mechanisms and evolutionary stages.",
          "authors": [
            "Nurimangul Nurmamat",
            "Yong-Feng Huang",
            "Xiao-Fei Dong",
            "Chen-Ran Hu",
            "Orkash Amat",
            "Ze-Cheng Zou",
            "Abdusattar Kurban",
            "Jin-Jun Geng",
            "Chen Deng"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02594",
          "title": "Radio, X-ray, and EUV signatures of internal and external reconnection of an erupting flux rope",
          "abstract": "We analyse imaging (EUV, X-ray) and spectral (radio, X-ray) data obtained by ground based and space instruments on board space missions both on Earth (Fermi, Hinode, Solar Dynamics Observatory) and solar orbit (Solar Orbiter, STEREO-A), which provide a multi-directional view on the same event. The combination of EUV and X-ray images and X-ray spectra allowed us to identify hot loops in the vicinity of the filament before its eruption. We interpreted their interaction with the rising filament as a signature of an arcade-to-rope reconnection geometry. The subsequent EUV brightening within the filament revealed helical structure of the erupting rope. We explained co-temporal radio slowly positively drifting bursts as a result of beam acceleration within the magnetic rope and propagation along the helical structure. Corresponding X-ray spectra were consistent with a thermal origin. The filament rising was accompanied by co-temporal normal and reverse drift type III radio bursts. We interpreted them as a signature of a reconnection event and estimated electron density at the reconnection site. Further untwisting of the helical structure led to formation of a quasi-circular EUV structure seen from Earth and STEREO-A. Its occurrence was co-temporal with a unique tangle of radio U- and inverse U-bursts. We proposed that several accelerated beams propagate within that complex structure and generate the burst tangle. During the start of the flare hard X-ray emission was concentrated near the filament leg only suggesting predominant propagation of the beams towards its rooting. We collected multi-wavelength observations indicating interaction of the erupting magnetic flux rope with the overlying arcade and internal magnetic reconnection inside the rising flux rope.",
          "authors": [
            "Jana Kašparová",
            "Jaroslav Dudík",
            "Marian Karlický",
            "Alena Zemanová",
            "Paolo Massa",
            "Samuel Krucker",
            "Frédéric Schuller",
            "Ján Rybák"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02601",
          "title": "Stellar chemistry and planet size: insights from GALAH DR4",
          "abstract": "The well-known correlation between stellar metallicity and planet occurrence is strongest for giant planets, but weaker for smaller planets, suggesting that detailed elemental patterns beyond [Fe/H] may be relevant. Using abundances from the fourth data release of the GALAH spectroscopic survey, we analyzed 104 host stars with 141 confirmed transiting planets. We divide planets at 2.6 Earth radii, the theoretical threshold radius above which planets are unlikely to be pure-water worlds. We find that large-planet hosts are enriched by approximately 0.2 dex in iron and show a possible excess of highly volatile elements (C, N, O), though these measurements are affected by observational limitations, whereas small-planet hosts exhibit an enhanced contribution of the classical rock-forming elements (Mg, Si, Ca, Ti) relative to iron, corresponding to a modest [Rock/Fe] offset of 0.06 dex, which is statistically significant, with a p value of 10^{-4}. These offsets remain significant for alternative radius cuts. A matched control sample of non-planet-host stars shows only weak and mostly statistically insignificant similar trends, confirming that the stronger chemical signatures are linked to the planetary characteristics. As our study relies on transiting planets, it mainly probes short-period systems (periods shorter than 100 days). These results refine the planet-metallicity relation, highlighting the role of the relative balance between iron, volatiles, and rock-forming elements in planet formation.",
          "authors": [
            "N. Sussholz",
            "S. Zucker",
            "R. Helled",
            "D. Bashi"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02614",
          "title": "Stranger Things: A Grid-based Survey of Strange Modes in Post-Main Sequence Models",
          "abstract": "We present a systematic survey of strange mode pulsations in Cepheids using MESA and for the linear stability analysis, MESA RSP. Our model grid spans $2-15\\,M_\\odot$ in mass and [Fe/H] $= -0.95$-$0.17$ ($Z = 0.0015$-$0.0200$) in metallicity, with four convective overshoot prescriptions. Strange modes were identified in a relatively small fraction ($5-12.5$ %) of models, occurring at $n_\\mathrm{pg} = 5-9$, with $n_\\mathrm{pg} = 6$-$7$ as the most frequent radial modes. No unstable solutions were identified beyond $n_\\mathrm{pg} = 9$, in contrast to earlier studies reporting strange modes at $n_\\mathrm{pg} = 10-12$. We quantified the duration of the instability crossing phase ($\\tau_\\mathrm{IS}$), the strange mode phase ($\\tau_\\mathrm{s}$), and their ratio $\\mathcal{P}_\\mathrm{s} = \\tau_\\mathrm{s} / \\tau_\\mathrm{IS}$. Toward higher masses, both $\\tau_\\mathrm{IS}$ and $\\tau_\\mathrm{s}$ decrease, yet their ratio shows no systematic trend with mass in models that include convective core overshoot. The absolute timescales for strange modes remain short, typically $\\tau_\\mathrm{s} \\sim 10^{4.5}$-$10^{6}$ years, while $\\tau_\\mathrm{IS}$ is often an order of magnitude shorter, implying that these stars may spend a larger fraction of their life in the strange mode phase than in the instability strip itself. The extended duration of the strange mode phase may enhance the detectability of strange mode pulsators, provided that observational precision is sufficient to capture their low-amplitude variability. The predicted periods ($0.6-6.3$ days) are well covered by a single $27-$day TESS sector, making strange mode pulsators potentially detectable with current space-based photometry, although blending with nearby sources may pose challenges.",
          "authors": [
            "D. Tarczay-Nehéz",
            "L. Molnár",
            "M. Joyce"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02629",
          "title": "Silicate emission in a type-2 quasar: JWST/MIRI constraints on torus geometry and radiative feedback",
          "abstract": "Type-2 quasars (QSO2s) are AGN seen through a significant amount of dust and gas that obscures the central supermassive black hole and the broad line region. Despite this, recent mid-infrared spectra of the central 0.5-1.1 kpc of five QSO2s at z~0.1, obtained with the MRS module of JWST/MIRI, revealed 9.7, 18, and 23 micron silicate features in emission in two of them. This indicates that the high angular resolution of JWST/MIRI now allows us to peer into their nuclear region, exposing some of the directly illuminated dusty clouds that produce silicate emission. To test this, we fitted the nuclear mid-infrared spectrum of the QSO2 with the strongest silicate features, J1010, with two different sets of torus models implemented in an updated version of the Bayesian tool {\\tt BayesClumpy}. These are the CLUMPY and the CAT3D-WIND models. The CAT3D-WIND model is preferred by the observations based on the marginal likelihood and fit residuals, although the two torus models successfully reproduce the spectrum by means of intermediate covering factors ($\\rm C_T=0.45\\pm^{0.26}_{0.18}$ and $\\rm C_T=0.66\\pm^{0.16}_{0.17}$ for the CLUMPY and CAT3D-WIND models) and low inclinations ($\\rm i=50^\\circ\\pm^{8^\\circ}_{9^\\circ}$ and $\\rm i=13^\\circ\\pm^{7^\\circ}_{6^\\circ}$). Indeed, four of the five QSO2s with JWST/MIRI observations, including J1010, are in the blowout or ''forbidden'' region of the Eddington ratio-column density diagram, indicating that they are actively clearing gas and dust from their nuclear regions, leading to reduced covering factors. This is in contrast with Seyfert 2 galaxies observed with JWST, which are in the ''permitted'' regions of the diagram and show 9.7 micron silicate features in absorption. This supports a scenario where the more luminous the AGN and the higher their Eddington ratio, the lower the torus covering factor, driven by radiation pressure on dusty gas.",
          "authors": [
            "C. Ramos Almeida",
            "A. Asensio Ramos",
            "C. Westerdorp Plaza",
            "I. García-Bernete",
            "E. Lopez-Rodriguez",
            "S. Hönig",
            "A. Audibert",
            "S. García-Burillo",
            "M. Pereira-Santaella",
            "F. Donnan",
            "A. Alonso-Herrero",
            "O. González-Martín",
            "N. Levenson",
            "D. Rigopoulou",
            "C. Tadhunter",
            "G. Speranza"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02635",
          "title": "Unified Functional-Holographic Theory of the QCD Critical End Point",
          "abstract": "We present a first-principles, multi-scale theory of the QCD critical end point. It unifies Dyson-Schwinger dynamics of quark propagation, functional renormalization-group evolution of the scale-dependent effective action, and Polyakov-Nambu-Jona-Lasinio thermodynamics for chiral and deconfinement order parameters. It also includes a holographic Maxwell-Chern-Simons sector that supplies baryonic and topological response within a single, renormalization group consistent framework. Within this construction the axial-anomaly channel is evolved rather than tuned. The holographic topological susceptibility feeds directly into the flow of the determinantal interaction. As a result, anomaly-induced flavor mixing weakens as deconfinement sets in. This behavior drives the chiral condensate and the Polyakov loop toward a self-dual fixed point. At this point their renormalizations coincide, their residual mixing vanishes, and a unified order parameter controls criticality. The theory is anchored to continuum-extrapolated lattice thermodynamics and conserved-charge fluctuations at vanishing baryon density. This anchoring is implemented through a lattice-calibrated Polyakov sector. The framework respects exact thermodynamic identities by enforcing stationarity at each scale. It also recovers the ideal-gas limit at high temperature and the Goldstone limit at low temperature. Solving the coupled Dyson-Schwinger, renormalization-group, and holographic equations yields the critical end point as an output rather than an assumption. The critical end point appears at temperatures around one hundred forty megaelectronvolts and baryon chemical potentials of a few hundred megaelectronvolts. The theory predicts a small positive curvature of the crossover line near zero density.",
          "authors": [
            "Sameer Ahmad Mir",
            "Saeed Uddin",
            "Swatantra Kumar Tiwari",
            "Mir Faizal"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02640",
          "title": "Probing fully coherent radiation and parton densities using (virtual) photons at the LHC",
          "abstract": "Prompt photon production in pA collisions has long been suggested as a sensitive probe of the nuclear parton distribution functions (nPDFs). In this study, we present recent results on another cold nuclear matter effect, namely fully coherent radiation induced by parton multiple scattering, which may influence the nuclear dependence of prompt photon production. Medium-induced radiation effects, implemented in leading-order direct and fragmentation photon processes, are computed for pPb collisions at the LHC. At backward rapidity, photons are sensitive to fully coherent energy loss (FCEL), while at forward rapidity, fully coherent energy gain (FCEG) plays a crucial role due to the dominance of the $qg \\to q\\gamma$ scattering channel. In contrast, for virtual photon production, the impact of fully coherent radiation is marginal, making Drell-Yan (DY) one of the best ways to probe nuclear PDFs. The power of the DY process is demonstrated by reweighting nPDF sets at next-to-leading order using realistic pseudo-data for LHC Run 3.",
          "authors": [
            "François Arleo",
            "Djessy Bourgeais",
            "Maxime Guilbaud",
            "Greg Jackson",
            "Víctor Valencia Torres"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02640",
          "title": "Probing fully coherent radiation and parton densities using (virtual) photons at the LHC",
          "abstract": "Prompt photon production in pA collisions has long been suggested as a sensitive probe of the nuclear parton distribution functions (nPDFs). In this study, we present recent results on another cold nuclear matter effect, namely fully coherent radiation induced by parton multiple scattering, which may influence the nuclear dependence of prompt photon production. Medium-induced radiation effects, implemented in leading-order direct and fragmentation photon processes, are computed for pPb collisions at the LHC. At backward rapidity, photons are sensitive to fully coherent energy loss (FCEL), while at forward rapidity, fully coherent energy gain (FCEG) plays a crucial role due to the dominance of the $qg \\to q\\gamma$ scattering channel. In contrast, for virtual photon production, the impact of fully coherent radiation is marginal, making Drell-Yan (DY) one of the best ways to probe nuclear PDFs. The power of the DY process is demonstrated by reweighting nPDF sets at next-to-leading order using realistic pseudo-data for LHC Run 3.",
          "authors": [
            "François Arleo",
            "Djessy Bourgeais",
            "Maxime Guilbaud",
            "Greg Jackson",
            "Víctor Valencia Torres"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02642",
          "title": "The role of the galaxy stellar mass function in determining the cosmological distribution of astrophysical transients with applications to fast radio bursts and merging binary black holes",
          "abstract": "The cosmological distribution and formation rate of compact astrophysical objects such as fast radio bursts (FRBs) are typically assumed to be proportional to a linear combination of cosmological star formation rate and stellar mass. In the literature, a template for star formation rate, which is just a function of redshift, is typically used. In this work, we point out the importance of galaxy stellar mass function which captures the host galaxy information of observed FRBs as well as the redshift evolution of galaxy stellar mass. Using this information, we find that FRB formation efficiency per stellar mass has to be more efficient (by a factor of $\\approx 3$) than previously calculated, in order to reproduce the observed volumetric rate of FRBs at $z=0$. We show that cosmological population studies of FRBs have to include host galaxy information along with its redshift evolution in order to obtain unbiased results. This consideration is also applicable to other transients, e.g. gamma-ray bursts and merging binary black hole events. We show that our approach may open up the possibility to infer the host galaxy stellar mass of merging binary black holes with a detection of few thousand gravitational wave events.",
          "authors": [
            "Sandeep Kumar Acharya"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02655",
          "title": "Reevaluating the $a_1(1420)$ enhancement and its molecular partners in the low-lying axial-vector meson spectrum",
          "abstract": "We assess possible axial-vector states with $G$-parity $\\left(G=\\pm 1\\right)$ dynamically generated by pseudoscalar-vector interactions in coupled channels, driven by the Weinberg-Tomozawa term at leading order in chiral perturbation theory. The $S$-wave amplitudes are unitarized via the Bethe-Salpeter equation, and poles of the unitarized amplitudes are searched for in the complex energy plane. In the isovector sector with $I^G(J^{PC})=1^{\\pm}(1^{+\\mp})$, we identify two poles around 1400 MeV in the second Riemann sheet below the $K^*\\bar{K}$ mass threshold. The $G=+1$ and $G=-1$ poles can be one of the origins of the peaks in the $f_0(980)\\pi$ and $\\phi\\pi^0$ mass spectra reported by the COMPASS and BESIII collaborations, respectively, in the $\\pi N \\to \\pi\\pi\\pi N$ and $J/\\psi \\to \\eta \\phi\\pi$ processes, in addition to triangle singularity effects discussed in the literature. Additionally, the poles in the isoscalar sector may explain the nontrivial behavior of the $K^*\\bar{K}$ spectra line shapes measured by several experiments in different reactions. Specifically, for the $0^+(1^{++})$ case, we find a sizeable $K^*\\bar{K}$ component for the $f_1(1420)$. In the $0^-(1^{+-})$ scenario, the pole strongly coupled to $\\rho\\pi$ can be associated with the $h_1(1170)$ resonance. Lastly, in this same sector, we identify a higher pole that dominates the $K^*\\bar{K}$ invariant mass in the $\\chi_{cJ} \\to \\phi K^*\\bar{K}$ decay, where the \\(h_1(1415)\\) is observed in the BESIII data.",
          "authors": [
            "Mao-Jun Yan",
            "Chun-Sheng An",
            "Cheng-Rong Deng"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02656",
          "title": "KM3NeT/ARCA stacking search for high-energy neutrinos from blazars",
          "abstract": "Blazars are promising targets for neutrino astronomy, as highlighted by IceCube's identification of TXS 0506+056 as a cosmic neutrino source candidate. High-frequency-peaked BL Lacs (HBLs) stand out due to their characteristic electromagnetic high-energy emission properties, which makes them as well promising candidates for the production of high-energy neutrinos. Such neutrinos could be detected by KM3NeT/ARCA, a next-generation deep-sea Cherenkov detector under construction in the Mediterranean Sea. This contribution presents the results of a binned likelihood stacking analysis investigating high-energy neutrino emissions from a subset of HBLs. A total of 232 sources have been selected from the 3HSP catalogue and targeted in the analysis of KM3NeT/ARCA data taken with several detector configurations, specifically in the period in which from 6 to 21 detection units were deployed. The analysis is based on neutrino emission models of blazars developed using the LeHa-Paris numerical code, which simulates the spectral energy distribution of jetted active galactic nuclei.",
          "authors": [
            "Francesco Carenini",
            "Giulia Illuminati"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02672",
          "title": "Exploring Leptogenesis, WIMP Dark Matter, and Gravitational Waves in an extended Scalar Framework",
          "abstract": "We explore extensions of type I seesaw framework with a scalar mediator ($\\Phi$) connecting to a complex scalar dark field ($S$), and right handed neutrinos ($N_i$), with an aim to correlate neutrino mass generation, leptogenesis, and dark matter. $\\mathcal{Z}_4\\times CP$ turns out to be a phenomenologically viable choice of the extended symmetry, which can accommodate a dimension five effective interaction $\\bar{l}_L^\\alpha \\tilde{H}\\Phi N_i$, involving the SM lepton isodoublet ${l}_L$, and Higgs $H$; prohibiting the canonical Yukawa term $\\bar{l}_L^\\alpha \\tilde{H} N_i$. The $\\mathcal{Z}_{4}$ symmetry is spontaneously broken via the vacuum expectation value (VEV) of the $\\Phi$ filed, which directly affects neutrino mass generation and leptogenesis; while the $CP$ symmetry stabilises one component of $S$, making it a viable dark matter candidate. The discrete symmetry breaking creates domain wall, which needs to be annihilated before the over-closure of the Universe. This paves the way for gravitational wave signal associated with the model set up, which probes the symmetry breaking scale, and indirectly connects to the other phenomena.",
          "authors": [
            "Subhaditya Bhattacharya",
            "Niloy Mondal",
            "Arunansu Sil"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02672",
          "title": "Exploring Leptogenesis, WIMP Dark Matter, and Gravitational Waves in an extended Scalar Framework",
          "abstract": "We explore extensions of type I seesaw framework with a scalar mediator ($\\Phi$) connecting to a complex scalar dark field ($S$), and right handed neutrinos ($N_i$), with an aim to correlate neutrino mass generation, leptogenesis, and dark matter. $\\mathcal{Z}_4\\times CP$ turns out to be a phenomenologically viable choice of the extended symmetry, which can accommodate a dimension five effective interaction $\\bar{l}_L^\\alpha \\tilde{H}\\Phi N_i$, involving the SM lepton isodoublet ${l}_L$, and Higgs $H$; prohibiting the canonical Yukawa term $\\bar{l}_L^\\alpha \\tilde{H} N_i$. The $\\mathcal{Z}_{4}$ symmetry is spontaneously broken via the vacuum expectation value (VEV) of the $\\Phi$ filed, which directly affects neutrino mass generation and leptogenesis; while the $CP$ symmetry stabilises one component of $S$, making it a viable dark matter candidate. The discrete symmetry breaking creates domain wall, which needs to be annihilated before the over-closure of the Universe. This paves the way for gravitational wave signal associated with the model set up, which probes the symmetry breaking scale, and indirectly connects to the other phenomena.",
          "authors": [
            "Subhaditya Bhattacharya",
            "Niloy Mondal",
            "Arunansu Sil"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02680",
          "title": "Peculiar SN Ic 2022esa: An explosion of a massive Wolf-Rayet star in a binary as a precursor to a BH-BH binary?",
          "abstract": "A class of supernovae (SNe) termed `SN Ic-CSM' are characterized by late-time emergence of narrow emission lines of elements formed in the oxygen core of a massive star. A popular scenario is the interaction of the SN ejecta and O-rich circumstellar medium (CSM), i.e., Circumstellar Interaction (CSI). Uncovering the progenitor system of SNe Ic-CSM plays a critical role in understanding the final evolution of a massive star to a bare C+O star. In this Letter, we present observations of SN 2022esa which we show is an SN Ic-CSM. Surprisingly, a stable periodicity of ~32 days is found in its light-curve evolution with a hint of a slowly increasing period over ~200 days. We argue that the main power source is likely the interaction of the SN ejecta and O-rich CSM, while the energy input by the post-SN eccentric binary interaction within the SN ejecta is another possibility. In either case, we propose a massive Wolf-Rayet (WR) star as the progenitor, in a WR-WR or WR-BH (black hole) binary that will eventually evolve to a BH-BH binary. Specifically, in the CSI scenario, the progenitor system is an eccentric binary system with an orbital period of about a year, leading to the observed periodicity through the modulation in the CSM density structure. We also show that some other objects, superluminous SN I 2018ibb (a pair-instability SN candidate) and peculiar SN Ic 2022jli (the first example showing stable periodic modulation), show observational similarities to SNe Ic-CSM and may be categorized as SN Ic-CSM variants. Complemented with a large diversity in their light-curve evolution, we propose that SNe Ic-CSM (potentially linked to SNe Ibn/Icn) are a mixture of multiple channels that cover a range of properties in the progenitor star, the binary companion, and the binary orbit.",
          "authors": [
            "Keiichi Maeda",
            "Hanindyo Kuncarayakti",
            "Takashi Nagao",
            "Miho Kawabata",
            "Kenta Taguchi",
            "Kohki Uno",
            "Kishalay De"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02692",
          "title": "Nucleon decays into three leptons: noncontact contributions",
          "abstract": "We investigate baryon number violating (BNV) nucleon decays into three leptons from noncontact contributions that are induced by dimension-6 (dim-6) BNV operators in low-energy effective field theory (LEFT) with an exchange of a baryon, meson, lepton, or photon field. We systematically classify all these processes that change lepton flavor by one unit and formulate their decay widths in terms of the dim-6 LEFT Wilson coefficients. By applying constraints on these Wilson coefficients derived from current experimental limits on BNV two-body nucleon decays, we obtain stringent and robust bounds on the rates of these triple-lepton modes. These bounds vary significantly from one dim-6 operator to another under consideration. Our results for the $\\Delta(B-L)=0$ modes differ by several orders of magnitude from previous phase-space estimates in the literature, thereby providing a more reliable assessment of their potential occurrence. In addition, we provide improved bounds on $\\Delta(B+L)=0$ modes compared to the existing experimental limits.",
          "authors": [
            "Jing Chen",
            "Yi Liao",
            "Xiao-Dong Ma",
            "Hao-Lin Wang"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02693",
          "title": "Search for persistent radio emission towards selected localised Fast Radio Burst positions using the MeerKAT Telescope",
          "abstract": "Fast Radio Bursts (FRBs) are millisecond-duration radio pulses originating from cosmological distances, as indicated by their large dispersion measures. While numerous FRBs have now been localised to their host galaxies, a distinct class of compact electromagnetic counterpart, a Persistent Radio Source (PRS), has also been identified in some cases. Currently, only three, and possible a fourth repeating FRBs (FRB20121102A, FRB20190417A, FRB20190520B, and FRB20240114A) have confirmed associations with a PRS. Insight into progenitors, local environments, and the evolution of FRBs can be clarified by characterising these PRSs. In this work, we present 2 detected candidate PRSs using MeerKAT radio telescope data and one non-detection (as part of a larger study involving 25 FRB positions). Both FRB20221106 and FRB20181112 were found to have a host galaxy, and whether the detected radio continuum emission comes from the host galaxy or PRS is still an open question. High-resolution observations from a telescope such as e-MERLIN are required to resolve this question. If a compact PRS is detected, this telescope will provide the size, and investigate the flux variability and spectral shape of this compact PRS. Lastly, in the case of FRB220190102, which was observed over two epochs, no radio continuum was detected. However, a flux upper limit is provided for both epochs.",
          "authors": [
            "Thulo Letsele",
            "Lebogang Mfulwane",
            "Christo Venter",
            "James O. Chibueze",
            "Mechiel Christiaan Bezuidenhout"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02703",
          "title": "Lepton Flavor Physics in the flipped 3-3-1-1 Model: Non-Universality and Violation",
          "abstract": "We investigate the flavor violation (FV) of Z decays to leptons at tree level and flavor conserving Z decays to leptons in the frame work of the flipped $ SU(3)_C\\otimes SU(3)_L \\otimes U(1)_X\\otimes U(1)_N$,(F3311) model. In addition, we analyze the processes $l_i\\rightarrow l_j \\gamma$ and the leptonic three-body decay. Using the experimental bounds on these decays we set the constraint on $\\sin \\phi$ which represents the mixing between Z-Z' boson. The most stringent limits arises from $\\mu \\rightarrow e \\gamma$ decay where $\\sin \\phi \\sim \\mathcal{ O}(10^{-3})$. The leptonic three-body decay set lower bound on the mass of the new neural gauge boson $m_{Z'} \\geq 3.2TeV$. Using the LUX-ZEPLIN (LZ) experiment data we set bounds to the mass of the dark matter candidates. Subsequently, we investigate the lepton non-universality in B decays within the $F3311$ model by calculating the generic one-loop contribution to the process $u_i\\rightarrow d_j e_b \\bar{\\nu}_a$ in the unitary gauge as well as numerical evaluating the branching ratio $R_D, R_{D^{(*)}},R(X_c)$. We demonstrate that the $F3311$ model can address the $3.3 \\sigma$ discrepancies between Standard Model and experimental data. To reaffirm our results, we also analyze the $d \\to u$ transitions and $s\\to u$ transitions. These two transitions also give consistent result with experiment data. Combine all experiment dat a we obtain the operating region for the mass of the model specifically $m_E \\in [6.5, 9 ]TeV$, $m_Q \\in [6,11]TeV$ and the dark matter candidate $m_\\xi \\in [1.5,2 ]TeV$.",
          "authors": [
            "D.T.Huong",
            "V.H.Binh",
            "N.T.Huong",
            "H.T.Hung",
            "Duong Van Loi",
            "D.T.Binh"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02708",
          "title": "Spectropolarimetric characterisation of exoplanet host stars in preparation of the $Ariel$ mission II. The magnetised wind environment of TOI-1860, DS Tuc A, and HD 63433",
          "abstract": "We update the status of the spectropolarimetric campaign dedicated to characterise the magnetic field properties of a sample of known exoplanet-hosting stars included in the current target list of the $Ariel$ mission. We analysed spectropolarimetric data collected for 15 G-M type stars with Neo-Narval, HARPSpol, and SPIRou to assess the detectability of the large-scale magnetic field. For three stars we reconstructed the magnetic field topology and its temporal evolution via Zeeman-Doppler imaging (ZDI). Such reconstructions were then used to perform 3D MHD simulations of the stellar wind and environment impinging on the hosted exoplanets. We detected the magnetic field of six stars. Of these, we performed ZDI reconstructions for the first time of TOI-1860 and DS Tuc A, and for the second time of HD 63433, providing temporal information of its large-scale magnetic field. Consistently with previous results on young ($\\rm\\sim 50-100~Myr$) solar-like stars, the large-scale magnetic field is moderately strong (30-60 G on average) and complex, with a significant fraction of magnetic energy in the toroidal component and high-order poloidal components. We found the orbit of TOI-1860 b to be almost completely sub-Alfvénic, the orbits of DS Tuc A b and HD 63433 d to be trans-Alfvénic, and the orbits of HD 63433 b and c to be super-Alfvénic. We obtained marginal detections of the magnetic field for TOI-836 and TOI-2076, and detections for TOI-1136, but the number of observations is not sufficient for magnetic mapping. A magnetic star-planet connection can occur for most of TOI-1860 b's orbit. This can happen more sporadically for DS Tuc A b and HD 63433 c given the lower fraction of their orbit in the sub-Alfvénic regime. The orbit of HD 63433 c is nevertheless more sub-Alfvénic than previously simulated owing to the temporal evolution of the stellar magnetic field.",
          "authors": [
            "S. Bellotti",
            "A. Lavail",
            "D. Evensberget",
            "A.A. Vidotto",
            "C. Danielski",
            "B. Edwards",
            "G.A.J. Hussain",
            "T. Lüftinger",
            "J. Morin",
            "P. Petit",
            "S. Boro Saikia",
            "G. Micela",
            "A. López Ariste"
          ],
          "primary_category": "astro-ph.SR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02714",
          "title": "Quasinormal modes of a static black hole in nonlinear electrodynamics",
          "abstract": "We investigate the axial electromagnetic quasinormal modes of a static, asymptotically Anti--de Sitter (AdS) black hole sourced by a nonlinear electrodynamics model of Plebański type. Starting from the master equation governing axial perturbations, we impose ingoing boundary conditions at the event horizon and normalizable (Dirichlet) behavior at the AdS boundary. Following the approach of Jansen, we recast the radial equation into a linear generalized eigenvalue problem by using an ingoing Eddington--Finkelstein formulation, compactifying the radial domain, and regularizing the asymptotic coefficients. The resulting problem is solved using a Chebyshev--Lobatto pseudospectral discretization. We compute the fundamental quasinormal mode frequencies for both the purely electric ($Q_m=0$) and purely magnetic ($Q_e=0$) sectors, emphasizing the role of the nonlinearity parameter $\\beta$ and the effective charge magnitude $Q$. Our results show that increasing either $\\beta$ or $Q$ raises both the oscillation frequency $\\omega_R$ and the damping rate $-\\omega_I$, leading to faster but more rapidly decaying ringdown profiles. Nonlinear electrodynamics breaks the isospectrality between electric and magnetic configurations: magnetic modes are systematically less oscillatory and more weakly damped than their electric counterparts. For sufficiently large $\\beta$ and small $Q_m$, the fundamental mode becomes purely imaginary ($\\omega_R \\approx 0$), in agreement with the absence of a trapping potential barrier in this regime. These findings reveal qualitative signatures of nonlinear electromagnetic effects on black hole perturbations and may have implications for high-field or high-charge astrophysical environments.",
          "authors": [
            "Mohsen Fathi",
            "Ariel Guzmán",
            "J.R. Villanueva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02714",
          "title": "Quasinormal modes of a static black hole in nonlinear electrodynamics",
          "abstract": "We investigate the axial electromagnetic quasinormal modes of a static, asymptotically Anti--de Sitter (AdS) black hole sourced by a nonlinear electrodynamics model of Plebański type. Starting from the master equation governing axial perturbations, we impose ingoing boundary conditions at the event horizon and normalizable (Dirichlet) behavior at the AdS boundary. Following the approach of Jansen, we recast the radial equation into a linear generalized eigenvalue problem by using an ingoing Eddington--Finkelstein formulation, compactifying the radial domain, and regularizing the asymptotic coefficients. The resulting problem is solved using a Chebyshev--Lobatto pseudospectral discretization. We compute the fundamental quasinormal mode frequencies for both the purely electric ($Q_m=0$) and purely magnetic ($Q_e=0$) sectors, emphasizing the role of the nonlinearity parameter $\\beta$ and the effective charge magnitude $Q$. Our results show that increasing either $\\beta$ or $Q$ raises both the oscillation frequency $\\omega_R$ and the damping rate $-\\omega_I$, leading to faster but more rapidly decaying ringdown profiles. Nonlinear electrodynamics breaks the isospectrality between electric and magnetic configurations: magnetic modes are systematically less oscillatory and more weakly damped than their electric counterparts. For sufficiently large $\\beta$ and small $Q_m$, the fundamental mode becomes purely imaginary ($\\omega_R \\approx 0$), in agreement with the absence of a trapping potential barrier in this regime. These findings reveal qualitative signatures of nonlinear electromagnetic effects on black hole perturbations and may have implications for high-field or high-charge astrophysical environments.",
          "authors": [
            "Mohsen Fathi",
            "Ariel Guzmán",
            "J.R. Villanueva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02714",
          "title": "Quasinormal modes of a static black hole in nonlinear electrodynamics",
          "abstract": "We investigate the axial electromagnetic quasinormal modes of a static, asymptotically Anti--de Sitter (AdS) black hole sourced by a nonlinear electrodynamics model of Plebański type. Starting from the master equation governing axial perturbations, we impose ingoing boundary conditions at the event horizon and normalizable (Dirichlet) behavior at the AdS boundary. Following the approach of Jansen, we recast the radial equation into a linear generalized eigenvalue problem by using an ingoing Eddington--Finkelstein formulation, compactifying the radial domain, and regularizing the asymptotic coefficients. The resulting problem is solved using a Chebyshev--Lobatto pseudospectral discretization. We compute the fundamental quasinormal mode frequencies for both the purely electric ($Q_m=0$) and purely magnetic ($Q_e=0$) sectors, emphasizing the role of the nonlinearity parameter $\\beta$ and the effective charge magnitude $Q$. Our results show that increasing either $\\beta$ or $Q$ raises both the oscillation frequency $\\omega_R$ and the damping rate $-\\omega_I$, leading to faster but more rapidly decaying ringdown profiles. Nonlinear electrodynamics breaks the isospectrality between electric and magnetic configurations: magnetic modes are systematically less oscillatory and more weakly damped than their electric counterparts. For sufficiently large $\\beta$ and small $Q_m$, the fundamental mode becomes purely imaginary ($\\omega_R \\approx 0$), in agreement with the absence of a trapping potential barrier in this regime. These findings reveal qualitative signatures of nonlinear electromagnetic effects on black hole perturbations and may have implications for high-field or high-charge astrophysical environments.",
          "authors": [
            "Mohsen Fathi",
            "Ariel Guzmán",
            "J.R. Villanueva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02714",
          "title": "Quasinormal modes of a static black hole in nonlinear electrodynamics",
          "abstract": "We investigate the axial electromagnetic quasinormal modes of a static, asymptotically Anti--de Sitter (AdS) black hole sourced by a nonlinear electrodynamics model of Plebański type. Starting from the master equation governing axial perturbations, we impose ingoing boundary conditions at the event horizon and normalizable (Dirichlet) behavior at the AdS boundary. Following the approach of Jansen, we recast the radial equation into a linear generalized eigenvalue problem by using an ingoing Eddington--Finkelstein formulation, compactifying the radial domain, and regularizing the asymptotic coefficients. The resulting problem is solved using a Chebyshev--Lobatto pseudospectral discretization. We compute the fundamental quasinormal mode frequencies for both the purely electric ($Q_m=0$) and purely magnetic ($Q_e=0$) sectors, emphasizing the role of the nonlinearity parameter $\\beta$ and the effective charge magnitude $Q$. Our results show that increasing either $\\beta$ or $Q$ raises both the oscillation frequency $\\omega_R$ and the damping rate $-\\omega_I$, leading to faster but more rapidly decaying ringdown profiles. Nonlinear electrodynamics breaks the isospectrality between electric and magnetic configurations: magnetic modes are systematically less oscillatory and more weakly damped than their electric counterparts. For sufficiently large $\\beta$ and small $Q_m$, the fundamental mode becomes purely imaginary ($\\omega_R \\approx 0$), in agreement with the absence of a trapping potential barrier in this regime. These findings reveal qualitative signatures of nonlinear electromagnetic effects on black hole perturbations and may have implications for high-field or high-charge astrophysical environments.",
          "authors": [
            "Mohsen Fathi",
            "Ariel Guzmán",
            "J.R. Villanueva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02714",
          "title": "Quasinormal modes of a static black hole in nonlinear electrodynamics",
          "abstract": "We investigate the axial electromagnetic quasinormal modes of a static, asymptotically Anti--de Sitter (AdS) black hole sourced by a nonlinear electrodynamics model of Plebański type. Starting from the master equation governing axial perturbations, we impose ingoing boundary conditions at the event horizon and normalizable (Dirichlet) behavior at the AdS boundary. Following the approach of Jansen, we recast the radial equation into a linear generalized eigenvalue problem by using an ingoing Eddington--Finkelstein formulation, compactifying the radial domain, and regularizing the asymptotic coefficients. The resulting problem is solved using a Chebyshev--Lobatto pseudospectral discretization. We compute the fundamental quasinormal mode frequencies for both the purely electric ($Q_m=0$) and purely magnetic ($Q_e=0$) sectors, emphasizing the role of the nonlinearity parameter $\\beta$ and the effective charge magnitude $Q$. Our results show that increasing either $\\beta$ or $Q$ raises both the oscillation frequency $\\omega_R$ and the damping rate $-\\omega_I$, leading to faster but more rapidly decaying ringdown profiles. Nonlinear electrodynamics breaks the isospectrality between electric and magnetic configurations: magnetic modes are systematically less oscillatory and more weakly damped than their electric counterparts. For sufficiently large $\\beta$ and small $Q_m$, the fundamental mode becomes purely imaginary ($\\omega_R \\approx 0$), in agreement with the absence of a trapping potential barrier in this regime. These findings reveal qualitative signatures of nonlinear electromagnetic effects on black hole perturbations and may have implications for high-field or high-charge astrophysical environments.",
          "authors": [
            "Mohsen Fathi",
            "Ariel Guzmán",
            "J.R. Villanueva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02733",
          "title": "Heavy sterile neutrinos in $B$ decays and new QCD corrections to their semi-hadronic decay rates",
          "abstract": "In modern experiments on flavour physics it is possible to search for the decays of $B$ or $D$ mesons or $\\tau$ leptons into final states with heavy neutrinos $N$ (a.k.a. heavy neutral leptons). I present a common study of theorists and experimentalists from Belle II on constraints on $B \\rightarrow D^{*} \\ell N$. Next I discuss the status of the theory predictions of the various $N$ decay rates. In scenarios in which $N$ interacts with SM particles only through sterile-active neutrino mixing, the dependence of the lifetime on the relevant mixing angles is important to determine whether $N$ decays in the detector or outside. To calculate the inclusive decay rate into semi-hadronic final states reliably one needs to include radiative QCD corrections. I present analytic results for the QCD-corrected decay rates and discuss their phenomenological impact.",
          "authors": [
            "Tim Kretz"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02736",
          "title": "Experimental constraints on $γ$-ray strength function of $^{72}$Ga from $^{72}\\mathrm{Ga(n,γ)^{72}Ga}$ capture data and reevaluation of Maxwellian-averaged cross sections of $^{71}$Ga",
          "abstract": "The $\\gamma$-ray strength function of medium-mass neutron rich nuclei $^{72}$Ga has been extracted from the statistical Hauser-Feshbach analysis of the available capture data of $^{71}\\mathrm{Ga}(n,\\gamma){}^{72}\\mathrm{Ga}$ over the 0.01 - 3 MeV energy range with the required nuclear level density (NLD) of the $^{72}$Ga constraint from the work of R. Santra et al.,[\\href{ this https URL }{Physical Review C 107, 064611 (2023)}]. The Gogny D1M model for the E1 and M1 strength functions, including low-energy upbends of $^{72}$Ga nuclei, is experimentally constrained in the present work. Subsequently, the Maxwellian-averaged cross section(MACS) of $^{71}\\mathrm{Ga}$ has been reevaluated based on the present $\\gamma$-ray strength function. It is found that the present MACS value at \\(kT = 30\\) keV is 115.35$^{+11.92}_{-10.44}$ mb, which is consistent with previous work.",
          "authors": [
            "Sajid Ali",
            "Rajkumar Santra",
            "Gautam Gangopahyay"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02773",
          "title": "Leptophilic Gauge Interactions in the SMEFT Era",
          "abstract": "We develop a \"precision-ready\", model-independent EFT framework that connects general leptophilic gauge interactions to their low-energy manifestations in SMEFT and LEFT. Starting from a broad U(1)'_ell extension in which leptons carry family-dependent charges (q_e, q_mu, q_tau) while quarks remain neutral, quantum consistency is ensured through a minimal set of vectorlike leptons, chiral under U(1)'_ell but vectorlike under the SM, together with singlet scalars responsible for symmetry breaking and the masses of both Z_ell and the heavy leptons. In the heavy-mediator limit, we integrate out Z_ell at tree level and derive compact, analytic SMEFT Wilson coefficients for four-lepton operators and Higgs-current structures, including hypercharge-U(1)'_ell kinetic mixing proportional to Tr(Y Q'). Renormalization-group evolution down to the electroweak scale and matching onto LEFT produce closed-form expressions directly applicable to e+e- -> l+l-, neutrino trident production, nu e scattering, parity-violating Moeller observables, and muon-decay parameters. A single parameter combination, Lambda_eff = M_Zell / (g_ell * sqrt(|q q'|)), governs all leading EFT signatures, offering a unified way to map UV charge assignments onto precision observables. We delineate the validity domain of this EFT and outline its use as a \"plug-and-play\" interface for global fits, collider recasts, and future-collider projections.",
          "authors": [
            "Seyit Okan Kara"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02782",
          "title": "Universality and Falsifiability of Quantum Spacetime Decoherence: A Gauge-Invariant Framework for Gravitational-Wave Phase Diffusion",
          "abstract": "We develop a fully gauge-invariant and rigorously derived framework for computing the cumulative decoherence of gravitational waves (GWs) propagating through a stochastic quantum spacetime. Working directly with the Riemann-tensor two-point function and exploiting the extreme adiabaticity of cosmological GW propagation, we show that phase diffusion, rather than amplitude attenuation or mode mixing, is the unique leading-order imprint of microscopic curvature fluctuations. Our main theoretical result is a universality theorem: for any quantum-gravity model whose curvature fluctuations possess a finite correlation length, the accumulated phase variance grows linearly with distance, independent of the underlying microphysics. This diffusive scaling contrasts sharply with coherent astrophysical effects and with nonlocal models. The frequency exponent therefore becomes a clean spectral discriminator, separating string-foam recoil, holographic or scale-invariant noise, and causal-set discreteness. We obtain these results from first principles by evaluating the projected Riemann correlator along null geodesics and determining the exact conditions under which deviations from universality can arise. Finally, we outline a hierarchical Bayesian strategy for measuring this effect with LIGO, LISA, and Pulsar Timing Arrays. Although standard Planck-scale fluctuations remain far below current sensitivity, this framework provides a sharp and falsifiable test of exotic quantum-spacetime scenarios, particularly those with macroscopic correlation lengths or strong energy dependence.",
          "authors": [
            "Hu Cang",
            "Yuan Wang"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02782",
          "title": "Universality and Falsifiability of Quantum Spacetime Decoherence: A Gauge-Invariant Framework for Gravitational-Wave Phase Diffusion",
          "abstract": "We develop a fully gauge-invariant and rigorously derived framework for computing the cumulative decoherence of gravitational waves (GWs) propagating through a stochastic quantum spacetime. Working directly with the Riemann-tensor two-point function and exploiting the extreme adiabaticity of cosmological GW propagation, we show that phase diffusion, rather than amplitude attenuation or mode mixing, is the unique leading-order imprint of microscopic curvature fluctuations. Our main theoretical result is a universality theorem: for any quantum-gravity model whose curvature fluctuations possess a finite correlation length, the accumulated phase variance grows linearly with distance, independent of the underlying microphysics. This diffusive scaling contrasts sharply with coherent astrophysical effects and with nonlocal models. The frequency exponent therefore becomes a clean spectral discriminator, separating string-foam recoil, holographic or scale-invariant noise, and causal-set discreteness. We obtain these results from first principles by evaluating the projected Riemann correlator along null geodesics and determining the exact conditions under which deviations from universality can arise. Finally, we outline a hierarchical Bayesian strategy for measuring this effect with LIGO, LISA, and Pulsar Timing Arrays. Although standard Planck-scale fluctuations remain far below current sensitivity, this framework provides a sharp and falsifiable test of exotic quantum-spacetime scenarios, particularly those with macroscopic correlation lengths or strong energy dependence.",
          "authors": [
            "Hu Cang",
            "Yuan Wang"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02801",
          "title": "Models for differential cross section in neutron-proton scattering and their implications",
          "abstract": "A few analytic exponential models of elastic differential cross section, constructed as purely phenomenological models, are proposed and tested. The models incorporate energy-dependent exponential slopes, power-law prefactors, and localized Gaussian modifications which are built to reproduce the observed dip region, supplemented in some cases by logarithmic $t$-dependent slopes. Simple additive sub-leading exponential contributions that represent charge conjugation and isospin roles are introduced in the models to increase applicability and quality of fit across elastic differential cross section data of $np$, $n\\bar{p}$, $pp$, and $p\\bar{p}$ elastic scattering. The models reproduce the characteristic features of the elastic scattering data such as the dip-bump structure, shrinkage of the forward peak, and controlled curvature that is localized around the dip. Parameters of the models are found by fitting the experimental data of elastic $np$ differential cross section in an energy range of $\\sqrt{s}$ = 3.36 GeV to 26.02 GeV, across a momentum range of $0.065 \\leq \\mid t\\mid \\leq 5.341 \\textrm{GeV}^{2}$. The parameter values and their ranges, obtained by $\\chi^{2}$ minimization are found within their assumed expected bounds with the $np$ data fitting. The total cross section, the slope parameter, the interaction radius, the total elastic cross section, the inelastic cross section, the ratios $\\sigma_{el}/\\sigma_{tot}$, and $\\sigma_{inel}/\\sigma_{tot}$ are predicted by the models for the $np$ scattering at all the energies, which show accurate quantitative agreement with their reference values. The results show that the proposed models not only provide accurate quantitative description of $np$ elastic differential cross section but also yield estimates of the observables that are consistent with theoretical expectations from Regge phenomenology and high-energy scattering constraints.",
          "authors": [
            "Muhammad Saad Ashraf",
            "Nosheen Akbar"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02802",
          "title": "SDSS-V LVM: Resolving Physical Conditions in the Trifid Nebula",
          "abstract": "The chemical abundance of the interstellar medium sets the initial conditions for star formation and provides a probe of chemical galaxy evolution models. However, unresolved inhomogeneities in the electron temperature can lead to a systematic underestimation of the abundances. We aim to directly test this effect. We use the SDSS-V Local Volume Mapper to spatially map the physical conditions of the Trifid Nebula (M 20), a Galactic H II region ionized by a single mid-type O star, at 0.24 pc resolution. We exploit various emission lines (e.g., Hydrogen recombination lines and collisionally excited lines, including also faint auroral lines) and compute spatially resolved maps of [O II] and [S II] electron densities; [N II], [O II], [S II], [S III] electron temperatures; and the ionic oxygen abundances. We find internal variations of electron density that result from the ionization front, along with a negative radial gradient. However, we do not find strong gradients or structures in the electron temperature and the total oxygen abundance, making the Trifid Nebula a relatively homogeneous H II region at the observed spatial scale. We compare these spatially resolved properties with equivalent integrated measurements of the Trifid Nebula and find no significant variations between integrated and spatially resolved conditions. This isolated H II region, ionized by a single O-star, represents a test case of an ideal Strömgren sphere. The physical conditions in the Trifid Nebula behave as expected, with no significant differences between integrated and resolved measurements.",
          "authors": [
            "Natascha Sattler",
            "J. Eduardo Méndez-Delgado",
            "Kathryn Kreckel",
            "Christophe Morisset",
            "Oleg Egorov",
            "Evgeniya Egorova",
            "Ahmad Nemer",
            "Fu-Heng Liang",
            "A.A.C. Sander",
            "Alexandre Roman-Lopes",
            "Carlos G. Román-Zúñiga",
            "Evelyn J. Johnston",
            "Sebastián F. Sánchez",
            "José G. Fernández-Trincado",
            "Niv Drory",
            "Amrita Singh",
            "Dmitry Bizyaev",
            "Sumit K. Sarbadhicary",
            "Pablo García",
            "Alfredo Mejía-Narváez",
            "Guillermo A. Blanc"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02804",
          "title": "A novel design of general-purpose spectrometer with nucleon polarimeter function",
          "abstract": "The spin polarization of hadrons is a key observable for probing the details of particle and nuclear interactions, offering information not available from other measurements. Currently, general-purpose spectrometers lack the capability to access final-state polarization. A novel technique to measure nucleon polarization within such a spectrometer has been proposed. Using this technique, a new design based on the proposed hyperon-nucleon spectrometer is developed. Systematic optimization confirms that the nucleon polarimeter functions effectively without impairing the detector's conventional performance. This successful integration, the first attempt of the general-purpose spectrometer, sets a valuable benchmark for future experiments. Ultimately, correlating spin polarization with four-momentum data will lead to a more profound understanding of the underlying physics.",
          "authors": [
            "Chuang-Xin Lin",
            "Xiao-Rong Lv",
            "Boxing Gou",
            "Ai-Qiang Guo",
            "Yu-Tie Liang"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02805",
          "title": "Direct observational evidence that higher-luminosity type 1 active galactic nuclei are most commonly triggered by galaxy mergers",
          "abstract": "We examine the connection between galaxy mergers and the triggering of active galactic nuclei (AGNs) using a sample of 614 type 1 AGNs at $z<0.07$, along with a control sample of inactive galaxies matched to the AGNs for comparison. We used tidal features, detected in deep images from the DESI Legacy Imaging Survey, as direct evidence of recent mergers. We find that the fraction of type 1 AGN hosts with tidal features ($f_T$) is higher for AGNs with higher luminosities and (to a lesser extent) more massive black holes. Specifically, $f_T$ rapidly increases from $0.05\\pm0.03$ to $0.75\\pm0.13$ as the luminosity of the $[\\mathrm{O\\,{\\scriptstyle III}}]$ $\\lambda$5007 emission line ($L_{[\\mathrm{O\\,{\\scriptstyle III}}]}$), an indicator for bolometric AGN luminosity, increases in the range $10^{39.5}\\lesssim L_{[\\mathrm{O\\,{\\scriptstyle III}}]}/(\\mathrm{erg\\,s}^{-1}) \\lesssim10^{42.5}$. In addition, $f_T$ increases from $0.13\\pm0.03$ to $0.43\\pm0.09$ as black hole mass ($M_\\mathrm{BH}$) increases in the range $10^{6.0}\\lesssim M_\\mathrm{BH}/M_{\\odot}\\lesssim10^{8.5}$. The fraction $f_T$ also increases with the Eddington ratio, although the trend is less significant compared to that with $L_{[\\mathrm{O\\,{\\scriptstyle III}}]}$ and $M_\\mathrm{BH}$. The excess of $f_T$, defined as the ratio of $f_T$ for AGNs to that of their matched inactive counterparts, exhibits similar trends, primarily increasing with $L_{[\\mathrm{O\\,{\\scriptstyle III}}]}$ and weakly with $M_\\mathrm{BH}$. Our results indicate that, in the local Universe, galaxy mergers are the predominant triggering mechanism for high-luminosity AGNs, whereas they play a lesser role in triggering lower-luminosity AGNs. Additionally, strong events, such as galaxy mergers, may be more necessary to activate massive black holes in more massive galaxies due to their lower gas fractions.",
          "authors": [
            "Yongmin Yoon",
            "Yongjung Kim",
            "Dohyeong Kim",
            "Kyungwon Chun",
            "Woowon Byun"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02806",
          "title": "A New Application of the Gibbons-Werner Method: Bound Orbits of Massive Particles in Stationary Spacetimes",
          "abstract": "The Gibbons-Werner (GW) method provides a geometric framework for calculating the deflection angle of particles in curved spacetimes, and numerous extensions based on the original version have been developed in recent years to expand its applicability. Most existing studies, however, are restricted to unbound orbits. The finite-distance deflection angle, which assumes both the source and observer to be located at finite distances, motivates us to investigate the bending of bound orbits. In this work, we broaden the GW method to bound orbits of massive particles in stationary axisymmetric (SAS) spacetimes, following our previous extension in static spherically symmetric (SSS) backgrounds [Huang et al., Phys. Rev. D 107, 104046 (2023)]. By employing our generalized GW method for SAS spacetimes [Huang et al., J. Cosmol. Astropart. Phys. 01(2024)013], (a) We obtain a formula for the deflection angle of bound massive particles in SAS spacetimes by dividing bound orbits that azimuthally overlap with themselves into multiple non-overlapping segments. This division enables the application of the GW method -- originally developed for unbound orbits -- to each segment in a consistent manner. (b) We overcome the limitation associated with the loss of positive definiteness of the Jacobi-Maupertuis Randers-Finsler (JMRF) metric, which occurs because bound massive particles have energies below unity. To show the practical implementation of our approach, we carry out the calculation in Kerr spacetime and obtain the deflection angle between two arbitrary points along the bound orbit of massive particles.",
          "authors": [
            "Yang Huang"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02836",
          "title": "The Large Sky Area Multi-object Fiber Spectroscopic Telescope (LAMOST) Quasar Survey: Quasar Properties from Data Release 10 to 12",
          "abstract": "We present the quasar catalog from Data Releases 10 to 12 of the Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) Quasar Survey, comprising quasars observed between September 2021 and June 2024. We robustly identified $11,346$ quasars, of which $5,386$ are newly discovered objects not present in the Million Quasars catalog. This release brings the total number of quasars identified by the 12-year LAMOST survey to $67,521$, of which $29,513$ are newly discovered. While the absolute flux calibration for LAMOST quasar spectra from Data Releases 6 to 9 was previously performed using the SDSS/PanSTARRS1 multi-band photometric data, the inherent variability of quasars can affect the flux accuracy. To address this limitation, we recalibrated the LAMOST spectra using (quasi-)simultaneous photometric data from Zwicky Transient Facility (ZTF), which has conducted high-cadence sky monitoring since March 2018. Based on the recalibrated single-epoch spectra, we estimated the emission line fluxes, continuum fluxes, and virial black hole masses. These improved spectra facilitate direct comparison with the spectra of common quasars from the Sloan Digital Sky Survey (SDSS), enabling searches for rare quasars, such as changing-look quasars exhibiting the appearance or disappearance of broad emission lines and broad absorption line quasars. The combined dataset of photometry and multi-epoch spectra will enhance the detections of AGN-related transients, such as Bowen fluorescence flares and extreme variability quasars, thereby improving our understanding of quasar variability.",
          "authors": [
            "Bing Lyu",
            "Xue-Bing Wu",
            "Jun-Jie Jin",
            "Yuming Fu",
            "Yuxuan Pang",
            "Huimei Wang",
            "Rui Zhu",
            "Su Yao",
            "Yan-Li Ai",
            "Yan-xia Zhang",
            "Hai-long Yuan",
            "Zhi-ying Huo"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02839",
          "title": "VHE FSRQs with Fermi-LAT: VHE and even brighter states in high-z FSRQs due to an HBL-like component?",
          "abstract": "Very high-energy (VHE) detected flat-spectrum radio quasars (FSRQs) are relatively few despite being the most persistent bright MeV-GeV sources. Focusing on VHE emission, we investigated the spectral and temporal properties of VHE-detected FSRQs using 14-year Fermi-LAT data. All are highly variable (flux-amplitude$>$100) with VHE detection associated with brighter flux states and relatively harder spectra. Above a flux limit, flux anti-correlates with spectral index, exhibiting a bluer-when-brighter trend. The low-flux state spectral energy distributions (SEDs) for all resembles a power-law, while high-flux and VHE-associated states resemble a log-parabola, accompanied by an almost nil (PKS0736+017, PKS1510-089) to marginal (4C+21.35, 3C279) to significant (B21420+32, TON0599, PKS1441+25, S30218+35, PKS0346-27, OP313) MeV-GeV peak-upshift -- more prominent in high-redshift sources. For no/marginal peak-upshift, the VHE emission is consistent with external Comptonization of infrared photons (EC-IR) driven primarily by a power-law continuation of the particle spectrum to higher energies. For those with a significant MeV-GeV peak-upshift, PKS0346-27 and OP313 shows peak-upshift in the synchrotron spectrum, and thus VHE is EC-IR origin, while for others without synchrotron-peak upshift, we attribute the VHE to an HBL-like component with a Compton-Dominance (CD) like FSRQs, with VHE driven primarily by particle spectrum continuation. In some, even high-state SEDs seem to require an HBL-like component. Thus, VHE activities in FSRQs mainly result from particle spectrum continuation, aided by spectral transition or a new HBL-like component with FSRQ-like CD. Such spectral changes naturally brighten the GeV-VHE flux, overcoming extragalactic background light absorption without requiring extraordinary brightening under the traditional EC-IR scenario than normally exhibited.",
          "authors": [
            "Megha",
            "Pankaj Kushwaha"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02854",
          "title": "From Dark Sectors to the Axion-Neutrino Connection",
          "abstract": "The Standard Model (SM) of particle physics provides a successful description of fundamental particles and their interactions but fails to explain phenomena such as neutrino oscillations, dark matter (DM), and the baryon asymmetry of the Universe. These clear signs of BSM physics motivate extensions introducing new particles and symmetries. Theoretical questions like the flavor puzzle and the strong CP problem further guide BSM frameworks. This thesis explores BSM scenarios based on two guiding principles: constructing unified frameworks that address multiple open problems in (astro)particle physics and cosmology, and emphasizing their experimental testability through detailed phenomenological analyses. This approach uncovers deep connections between seemingly disconnected sectors, offering a more complete view of fundamental physics. We investigate dark sector models for the origin of neutrino masses, proposing a novel setup: dark linear seesaw, which radiatively links neutrino mass generation to DM candidates and predicts charged lepton flavor violation. In these scenarios, dark sector particles can constitute WIMP DM, testable via direct detection experiments. We study spontaneous CP violation induced by a complex scalar singlet, acting as a common origin of low- and high-energy CP violating effects relevant for leptogenesis. We also analyze a Nelson-Barr model that solves the strong CP problem, generates a realistic CKM matrix radiatively, and yields scalar WIMP DM. Additionally, we present unified axion frameworks in which a colored sector radiatively generates neutrino masses. These models predict distinctive axion couplings to photons and fermions and accommodate axion DM in both pre- and post-inflationary cosmologies. Finally, we explore minimal flavored Peccei-Quinn symmetries that link the flavor puzzle, neutrino masses and DM within a predictive and testable framework.",
          "authors": [
            "H. B. Câmara"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02857",
          "title": "On Constraining the Proposed Hierarchical Triple Scenario for an Eccentric Milli-Second Pulsar Binary PSR J1618-3921",
          "abstract": "A very recent and meticulous timing effort suggests that an eccentric millisecond pulsar (eMSP) binary, namely PSR J1618-3921, is likely to be a part of a hierarchical triple (HT) system with a $0.6M_{\\odot}$ companion in a $\\sim 300$yr orbit. We investigate observational implications of the proposed HT scenario for PSR J1618-3921 and our ability to constrain the scenario. We model the MSP-Helium White Dwarf binary to be a part of bound point-mass HT, while incorporating the effects due to the quadrupolar interactions between the inner and outer binaries, along with dominant order general relativistic contributions to the periastron precession of the inner binary. If the proposed HT system is indeed undergoing Kozai oscillations at the present epoch, the orbital eccentricity ($e$) would be expected to decrease, while the rate of periastron advance ($\\dot{\\omega}$) would correspondingly increase, for plausible ranges of the HT parameters. Furthermore, the fractional variations in $e$ are anticipated to be at the level of a few parts in $10^{5}$-a magnitude that is substantially larger than the current measurement precision of $e$. We find that, for this eccentric MSP binary, the HT configurations that minimize the temporal evolution of orbital eccentricity and argument of periastron are mutually incompatible. This indicates that the continued high-precision timing of PSR J1618-3921-when analyzed within the framework introduced here-should place stringent limits on the presence and properties of a potential third body in the system.",
          "authors": [
            "Adya Shukla",
            "A. Gopakumar",
            "Paramasivan Arumugam"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02865",
          "title": "Evidence of Spin-Interference Effects in Exclusive $J/ψ\\to e^+e^-$ Photoproduction in Ultraperipheral Heavy-Ion Collisions",
          "abstract": "We report the first evidence of spin interference in exclusive $J/\\psi \\to e^+e^-$ photoproduction in ultraperipheral Au+Au and isobar (Ru+Ru, Zr+Zr) collisions ($\\sqrt{s_{NN}} = 200$~GeV) at STAR. A negative $\\cos(2\\phi)$ modulation is observed for $p_T < 100$ MeV/$c$, opposite in sign to that in $\\rho^{0}\\!\\to\\!\\pi^+\\pi^-$ photoproduction. This establishes for the first time that the interference sign is controlled by the spin structure of the final-state daughters, resolving the ambiguity present in the all-boson $\\rho^0$ channel. The compact $J/\\psi$ probes gluon distributions at perturbative scales, resulting in a weaker modulation and providing stringent constraints on Color Glass Condensate calculations. These findings demonstrate that spin-dependent interference in heavy vector mesons provides a new, experimentally accessible handle on gluon structure beyond traditional cross-section measurements.",
          "authors": [
            "STAR Collaboration"
          ],
          "primary_category": "nucl-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02865",
          "title": "Evidence of Spin-Interference Effects in Exclusive $J/ψ\\to e^+e^-$ Photoproduction in Ultraperipheral Heavy-Ion Collisions",
          "abstract": "We report the first evidence of spin interference in exclusive $J/\\psi \\to e^+e^-$ photoproduction in ultraperipheral Au+Au and isobar (Ru+Ru, Zr+Zr) collisions ($\\sqrt{s_{NN}} = 200$~GeV) at STAR. A negative $\\cos(2\\phi)$ modulation is observed for $p_T < 100$ MeV/$c$, opposite in sign to that in $\\rho^{0}\\!\\to\\!\\pi^+\\pi^-$ photoproduction. This establishes for the first time that the interference sign is controlled by the spin structure of the final-state daughters, resolving the ambiguity present in the all-boson $\\rho^0$ channel. The compact $J/\\psi$ probes gluon distributions at perturbative scales, resulting in a weaker modulation and providing stringent constraints on Color Glass Condensate calculations. These findings demonstrate that spin-dependent interference in heavy vector mesons provides a new, experimentally accessible handle on gluon structure beyond traditional cross-section measurements.",
          "authors": [
            "STAR Collaboration"
          ],
          "primary_category": "nucl-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02865",
          "title": "Evidence of Spin-Interference Effects in Exclusive $J/ψ\\to e^+e^-$ Photoproduction in Ultraperipheral Heavy-Ion Collisions",
          "abstract": "We report the first evidence of spin interference in exclusive $J/\\psi \\to e^+e^-$ photoproduction in ultraperipheral Au+Au and isobar (Ru+Ru, Zr+Zr) collisions ($\\sqrt{s_{NN}} = 200$~GeV) at STAR. A negative $\\cos(2\\phi)$ modulation is observed for $p_T < 100$ MeV/$c$, opposite in sign to that in $\\rho^{0}\\!\\to\\!\\pi^+\\pi^-$ photoproduction. This establishes for the first time that the interference sign is controlled by the spin structure of the final-state daughters, resolving the ambiguity present in the all-boson $\\rho^0$ channel. The compact $J/\\psi$ probes gluon distributions at perturbative scales, resulting in a weaker modulation and providing stringent constraints on Color Glass Condensate calculations. These findings demonstrate that spin-dependent interference in heavy vector mesons provides a new, experimentally accessible handle on gluon structure beyond traditional cross-section measurements.",
          "authors": [
            "STAR Collaboration"
          ],
          "primary_category": "nucl-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02865",
          "title": "Evidence of Spin-Interference Effects in Exclusive $J/ψ\\to e^+e^-$ Photoproduction in Ultraperipheral Heavy-Ion Collisions",
          "abstract": "We report the first evidence of spin interference in exclusive $J/\\psi \\to e^+e^-$ photoproduction in ultraperipheral Au+Au and isobar (Ru+Ru, Zr+Zr) collisions ($\\sqrt{s_{NN}} = 200$~GeV) at STAR. A negative $\\cos(2\\phi)$ modulation is observed for $p_T < 100$ MeV/$c$, opposite in sign to that in $\\rho^{0}\\!\\to\\!\\pi^+\\pi^-$ photoproduction. This establishes for the first time that the interference sign is controlled by the spin structure of the final-state daughters, resolving the ambiguity present in the all-boson $\\rho^0$ channel. The compact $J/\\psi$ probes gluon distributions at perturbative scales, resulting in a weaker modulation and providing stringent constraints on Color Glass Condensate calculations. These findings demonstrate that spin-dependent interference in heavy vector mesons provides a new, experimentally accessible handle on gluon structure beyond traditional cross-section measurements.",
          "authors": [
            "STAR Collaboration"
          ],
          "primary_category": "nucl-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02871",
          "title": "Limiting Reduction and Modified Gravity",
          "abstract": "Modified Newtonian Dynamics (MOND) is a framework of theories that adjust Newton's laws of gravity to explain effects such as galactic rotation anomalies, offering an alternative to dark matter. This essay examines the justification of MOND by assessing its inter-theoretical relationship to established theories across relevant scales, in particular its connection to Newtonian gravitation. We argue that MOND fails a key condition for a theory's justification--what we call 'reduction-wise justification'--since it does not adequately reduce to Newtonian gravity in a fully non-arbitrary way. More precisely, despite satisfying the standard formal criteria for successful limiting reduction, MOND does not properly reduce to Newtonian gravitation because of (i) the absence of a fundamental theoretical framework to justify the interpolating function introduced in MOND and (ii) the lack of a unified mathematical structure working across all scales, independent of Newtonian theory. Hence, the case study of MOND provides crucial results for the general debate on inter-theoretic reduction in science: MOND's failure as a case of reduction highlights important limitations in standard accounts of limiting reduction. We respond by proposing a more refined framework for limiting reduction that introduces two additional criteria to better distinguish successful from pathological reductions. More broadly, this case illustrates how analysing reduction-wise justification can serve as a powerful tool for evaluating the validity of novel theories that are not yet empirically established.",
          "authors": [
            "Antonis Antoniou",
            "Lorenzo Lorenzetti"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02871",
          "title": "Limiting Reduction and Modified Gravity",
          "abstract": "Modified Newtonian Dynamics (MOND) is a framework of theories that adjust Newton's laws of gravity to explain effects such as galactic rotation anomalies, offering an alternative to dark matter. This essay examines the justification of MOND by assessing its inter-theoretical relationship to established theories across relevant scales, in particular its connection to Newtonian gravitation. We argue that MOND fails a key condition for a theory's justification--what we call 'reduction-wise justification'--since it does not adequately reduce to Newtonian gravity in a fully non-arbitrary way. More precisely, despite satisfying the standard formal criteria for successful limiting reduction, MOND does not properly reduce to Newtonian gravitation because of (i) the absence of a fundamental theoretical framework to justify the interpolating function introduced in MOND and (ii) the lack of a unified mathematical structure working across all scales, independent of Newtonian theory. Hence, the case study of MOND provides crucial results for the general debate on inter-theoretic reduction in science: MOND's failure as a case of reduction highlights important limitations in standard accounts of limiting reduction. We respond by proposing a more refined framework for limiting reduction that introduces two additional criteria to better distinguish successful from pathological reductions. More broadly, this case illustrates how analysing reduction-wise justification can serve as a powerful tool for evaluating the validity of novel theories that are not yet empirically established.",
          "authors": [
            "Antonis Antoniou",
            "Lorenzo Lorenzetti"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02871",
          "title": "Limiting Reduction and Modified Gravity",
          "abstract": "Modified Newtonian Dynamics (MOND) is a framework of theories that adjust Newton's laws of gravity to explain effects such as galactic rotation anomalies, offering an alternative to dark matter. This essay examines the justification of MOND by assessing its inter-theoretical relationship to established theories across relevant scales, in particular its connection to Newtonian gravitation. We argue that MOND fails a key condition for a theory's justification--what we call 'reduction-wise justification'--since it does not adequately reduce to Newtonian gravity in a fully non-arbitrary way. More precisely, despite satisfying the standard formal criteria for successful limiting reduction, MOND does not properly reduce to Newtonian gravitation because of (i) the absence of a fundamental theoretical framework to justify the interpolating function introduced in MOND and (ii) the lack of a unified mathematical structure working across all scales, independent of Newtonian theory. Hence, the case study of MOND provides crucial results for the general debate on inter-theoretic reduction in science: MOND's failure as a case of reduction highlights important limitations in standard accounts of limiting reduction. We respond by proposing a more refined framework for limiting reduction that introduces two additional criteria to better distinguish successful from pathological reductions. More broadly, this case illustrates how analysing reduction-wise justification can serve as a powerful tool for evaluating the validity of novel theories that are not yet empirically established.",
          "authors": [
            "Antonis Antoniou",
            "Lorenzo Lorenzetti"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02880",
          "title": "Insights into Extragalactic Background Light constraints with MAGIC archival data",
          "abstract": "The Extragalactic Background Light (EBL) is the accumulated light emitted throughout the history of the universe, spanning the UV, optical, and IR spectral ranges. Stars and dust in galaxies are expected to be the main source of the EBL. However, recent direct measurements performed beyond Pluto's orbit (less affected by foregrounds than those performed from the Earth) hint at an EBL level in the optical band larger than the one expected from the integrated contribution of known galaxy populations. One approach that could solve this controversy uses Very High Energy (VHE) photons coming from sources at cosmological distances. These photons can interact with the EBL producing electron-positron pairs, a process that leaves an imprint on the observed VHE spectrum. This technique, however, requires assumptions on the intrinsic spectrum of the source, which can compromise the robustness of EBL constraints. In this contribution, we used Monte Carlo simulations and archival data of the MAGIC telescopes to study the impact that the assumptions adopted in the literature have on the estimate of the EBL density, and how using more generic ones would modify the results. Our results show how the EBL density constraints obtained highly depend on the intrinsic spectral shape assumed for the source. We have studied two different methods to reduce the assumptions on the intrinsic spectral shape to get more robust results. This will be especially important for upcoming with new VHE facilities, where systematic uncertainties are expected to play a more significant role compared to statistical ones.",
          "authors": [
            "R. Grau",
            "A. Moralejo"
          ],
          "primary_category": "astro-ph.HE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02900",
          "title": "Interacting Generalized Chaplygin-Jacobi gas: Thermodynamics approach",
          "abstract": "This work investigates a cosmological model featuring an interaction between dark energy and dark matter, where the dark energy component is described by the Generalized Chaplygin-Jacobi gas (GCJG). In this study, we establish a system in which the GCJG and a pressureless dark matter fluid exchange energy via a linear interaction term, $Q \\propto \\rho_x$, being $\\rho_{x}$ the dark energy density. By solving the conservation equations, we derive analytical expressions for the evolution of the dark energy and dark matter densities. The thermodynamic properties of this interacting system are then thoroughly analyzed. The thermodynamic analysis reveals that both dark components maintain positive temperatures, ensuring stability. Notably, the dark energy component transitions to a phantom regime in the past, a feature of interest for recent cosmological observations, without violating thermodynamic principles. The total entropy production is shown to be in agreement with the second law of thermodynamics. Furthermore, an analysis of the specific heats suggests that while the dark matter sector remains thermodynamically stable, the dark energy sector undergoes a late-time phase transition, consistent with its entering into the phantom domain at effective level.",
          "authors": [
            "Gilberto Aguilar-Pérez",
            "Miguel Cruz",
            "Mohsen Fathi",
            "J. R. Villanueva"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02921",
          "title": "Gravitational-wave imprints of Kerr--Bertotti--Robinson black holes: frequency blue-shift and waveform dephasing",
          "abstract": "We investigate the orbital dynamics and gravitational-wave signatures of extreme mass-ratio inspirals (EMRIs) in the spacetime of a Kerr black hole immersed in an asymptotically uniform magnetic field, described by the exact Kerr--Bertotti--Robinson (Kerr--BR) solution~\\cite{Podolsky:2025tle}. In contrast to the widely used Kerr--Melvin metric, the Kerr--BR spacetime is of algebraic type~D, admits a clear asymptotic structure, and allows for a systematic analytic treatment of geodesics. By analyzing the innermost stable circular orbit (ISCO), we find that the external magnetic field consistently pushes the ISCO to larger radii \\(r_{\\rm ISCO}\\) for all spin configurations considered. Counterintuitively, despite this outward radial shift, the ISCO orbital frequency \\(\\Omega_{\\rm ISCO}\\) increases monotonically with the magnetic-field strength, leading to a robust ``blue-shift'' of the gravitational-wave cutoff frequency. We further show that retrograde orbits are significantly more sensitive to magnetic fields than prograde orbits, and identify a frequency crossover phenomenon in which magnetic corrections can invert the usual spin--frequency hierarchy at the ISCO. Finally, employing a semi-analytic adiabatic evolution scheme driven by exact geodesic relations and a leading-order quadrupole flux, we generate inspiral waveforms and quantify the substantial dephasing induced by the magnetic field. Our results indicate that large-scale magnetic environments can leave observable imprints in EMRI signals for future space-based detectors such as LISA, TianQin, and Taiji, and that neglecting such effects in waveform models may introduce non-negligible biases in parameter estimation, particularly for the black-hole spin.",
          "authors": [
            "Xiang-Qian Li",
            "Hao-Peng Yan",
            "Xiao-Jun Yue"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02923",
          "title": "Distinguishing ram pressure from gravitational interactions: Applying the Size-Shape Difference method to real galaxies",
          "abstract": "In dense environments, mechanisms like ram pressure stripping (RPS) and gravitational interactions can induce similar morphological features in galaxies, distinguishable only through detailed study of their stellar properties. While RPS affects recently formed stars by displacing the gas disk from which they form, gravitational interactions perturb stars of all ages rather similarly. We present the first observational test of the Size-Shape Difference (SSD) measure, a novel approach validated for simulated galaxies, that quantifies morphological differences between young and intermediate-age stellar populations to distinguish RPS from gravitationally interacting galaxies. We analyze 67 galaxies from the GASP survey using spatially-resolved star formation histories derived using SINOPSIS. In our fiducial model, we compare stellar populations in two age bins (t < 20 Myr and 20 Myr <= t < 570 Myr) to calculate SSD values. The sample includes confirmed RPS cases with different stripping intensities, as well as undisturbed and gravitationally interacting galaxies. We find that extreme cases of RPS show SSD values ~3.5x higher than undisturbed and gravitationally interacting galaxies (56(+24/-15) as compared to 16(+6/-2) and 16(+6/-3), respectively), confirming simulation predictions. This enhancement reflects RPS-induced asymmetries: youngest stars are compressed along the leading edge and/or displaced into the extended tails of cold gas, while older populations remain undisturbed. In contrast, gravitational interactions perturb all stars uniformly, producing lower SSD values. SSD robustly distinguishes strong RPS cases, even adopting different age bins. This holds even without correcting for disk inclination, or when single-band imaging are used to trace stellar distributions. This makes SSD a promising tool to select RPS candidates for spectroscopic follow-up in upcoming surveys.",
          "authors": [
            "Augusto E. Lassen",
            "Rory Smith",
            "Benedetta Vulcani",
            "Stephanie Tonnesen",
            "Paula Calderón-Castillo",
            "Bianca M. Poggianti",
            "Jacopo Fritz",
            "Koshy George",
            "Alessandro Ignesti",
            "Yara Jaffé",
            "Antonino Marasco",
            "Luka Matijevič",
            "Alessia Moretti",
            "Mario Radovich",
            "Neven Tomičič"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02943",
          "title": "Can Eccentric Binary Black Hole Signals Mimic Gravitational-Wave Microlensing?",
          "abstract": "Gravitational lensing in the wave-optics regime imprints characteristic frequency-dependent amplitude and phase modulations on gravitational-wave (GW) signals, yet to be detected by ground-based interferometers. Similar modulations may also arise from orbital eccentricity, raising the possibility of degeneracies that could lead to false microlensing claims. We investigate the extent to which eccentric binary black hole (BBH) signals can mimic microlensing signatures produced by an isolated point-mass lens. With a simulated population of eccentric signals using numerical relativity simulations and \\texttt{TEOBResumS-Dalí} waveform model, we perform a Bayesian model-comparison study, supported by a complementary \\textit{mismatch} analysis. We find a strong degeneracy for high eccentricities, low total masses, and high signal-to-noise ratios (SNRs): under these conditions, quasicircular microlensed model can be strongly favored over quasicircular unlensed model, even when the true signal is unlensed. For moderate SNRs ($\\sim 30$), binaries with $M_\\mathrm{tot}\\lesssim 100\\,M_\\odot$ and eccentricity $e \\gtrsim 0.4$ are particularly susceptible to misclassifications. In such cases, inferred microlens parameters exhibit well-constrained posteriors despite being unphysical. Crucially, the degeneracy is completely removed when the recovery uses waveform models that incorporate eccentricity, which overwhelmingly favors the eccentric hypothesis over microlensing. Our results demonstrate that any event exhibiting strong Bayesian evidence for microlensing should also be analyzed with eccentric waveform models and vice-versa to avoid false positives and biased astrophysical inference. This work contributes to developing robust strategies for interpreting signals in the era of precision GW astronomy.",
          "authors": [
            "Anuj Mishra",
            "Apratim Ganguly"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02954",
          "title": "The suppression of the matter power spectrum: strong feedback from X-ray gas mass fractions, kSZ effect profiles, and galaxy-galaxy lensing",
          "abstract": "Baryon feedback redistributes gas relative to the underlying dark matter distribution and suppresses the matter power spectrum on small scales, but the amplitude and scale dependence of this effect are uncertain. We constrain the impact of baryon feedback on the matter power spectrum by jointly analysing X-ray gas mass fractions from the eROSITA and HSC-XXL samples and SDSS/DESI+ACT kinetic Sunyaev-Zel'dovich (kSZ) effect profiles; the samples are characterised with galaxy-galaxy lensing and together span group and cluster masses at $0<z<1$. Using the baryonification framework, our joint eROSITA and kSZ model gives precise constraints on the suppression of the matter power spectrum: $10 \\pm 2\\%$ at $k=1~h~\\mathrm{Mpc}^{-1}$. The inferred gas profiles are more extended and the power suppression is stronger than predicted by the fiducial models of recent hydrodynamical simulation suites, including FLAMINGO and BAHAMAS. The HSC-XXL gas mass fractions, which the fiducial simulations were calibrated to reproduce, prefer more moderate power suppression than the kSZ and eROSITA data: $5 \\pm 4\\%$ at $k=1~h~\\mathrm{Mpc}^{-1}$. With a simulated LSST Year 1 weak lensing analysis, we demonstrate a framework for next-generation surveys: calibrating feedback models with multi-wavelength gas observables to recover the small-scale statistical power of cosmic shear.",
          "authors": [
            "Jared Siegel",
            "Leah Bigwood",
            "Alexandra Amon",
            "Jamie McCullough",
            "Masaya Yamamoto",
            "Ian G. McCarthy",
            "Matthieu Schaller",
            "Aurel Schneider",
            "Joop Schaye"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02992",
          "title": "The Composite Spectrum of QSO Absorption Line Systems in DESI DR2",
          "abstract": "We present details regarding the construction of a composite spectrum of quasar (QSO) absorption line systems. In this composite spectrum we identify more than 70 absorption lines, and observe oxygen and hydrogen emission features at a higher signal-to-noise ratio than in any previous study. As the light from a distant quasar travels towards an observer, it may interact with the circumgalactic medium environment of an intervening galaxy, forming absorption lines. In order to maximize the signal of these absorption lines, we have selected a sample of 238,838 quasar spectra from the second data release of the Dark Energy Spectroscopic Instrument (DESI), each identified to have absorption lines resulting from such an interaction. By stacking these spectra in the restframe of the absorption, and calculating a median composite spectrum, we are able to isolate and enhance these absorption lines. We provide a full atlas of all detected absorption and emission lines as well as their fit centroids and equivalent width values. This atlas should aid in future studies investigating the compositions and physical conditions of these absorbers.",
          "authors": [
            "Lucas Napolitano",
            "Adam D. Myers",
            "Adam Tedeschi",
            "Abhijeet Anand",
            "Hiram K. Herrera-Alcantar",
            "Jessica Aguilar",
            "Steven Ahlen",
            "Stephen Bailey",
            "Segev BenZvi",
            "Davide Bianchi",
            "David Brooks",
            "Todd Claybaugh",
            "Andrei Cuceu",
            "Axel de la Macorra",
            "Arjun Dey",
            "Biprateep Dey",
            "Peter Doel",
            "Andreu Font-Ribera",
            "Jaime E. Forero-Romero",
            "Enrique Gaztanaga",
            "Satya Gontcho A Gontcho",
            "Gaston Gutierrez",
            "Julien Guy",
            "Dick Joyce",
            "Anthony Kremin",
            "Martin Landriau",
            "Laurent Le Guillou",
            "Marc Manera",
            "Aaron Meisner",
            "Ramon Miquel",
            "John Moustakas",
            "Seshadri Nadathur",
            "Nathalie Palanque-Delabrouille",
            "Will Percival",
            "Francisco Prada",
            "Ignasi Perez-Rafols",
            "Graziano Rossi",
            "Eusebio Sanchez",
            "David Schlegel",
            "Michael Schubnell",
            "Joesph Harry Silber",
            "David Sprayberry",
            "Gregory Tarle",
            "Benjamin Alan Weaver",
            "Rongpu Zhou",
            "Hu Zou"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02997",
          "title": "MIRI spectrophotometry of GN-z11: Detection and nature of an optical red continuum component",
          "abstract": "We present new MIRI F560W, F770W and F1000W imaging of GN-z11, extending the previous rest-frame coverage from 0.38 to 0.86$\\mu$m. We report significant detections (14$\\sigma$) in the F560W and F770W images, and a marginal detection (3.2$\\sigma$) in F1000W. Here, we analyse its SED combining new MIRI imaging data with archival NIRSpec/Prism and MRS spectroscopy, and NIRCam imaging. The continuum emission shows a flat energy distribution, in f$_\\nu$, up to 0.5$\\mu$m, compatible with the presence of a mixed stellar population of young (4$\\pm$1 Myr) and mature (63$\\pm$23 Myr) stars that also account for the [O III], H$\\beta$ and H$\\alpha$ emission lines. The continuum at rest-frame 0.66$\\mu$m shows a 36$\\pm$3% flux excess above the predicted flux for a mixed stellar population, pointing to the presence of an additional source contributing at these wavelengths. This excess increases to 91$\\pm$28% at rest-frame 0.86$\\mu$m, although with a large uncertainty due to the marginal detection in the F1000W filter. We consider that hot dust emission in the dusty torus around a type 2 AGN could be responsible for the observed excess. Alternatively, this excess could be due to hot dust emission or to a photoluminiscence dust process (Extended Red Emission, ERE) under the extreme UV radiation field, as observed in some local metal-poor galaxies and in young compact starbursts. The presence of a type 1 AGN is not supported by the observed SED since high-z QSOs contribute at wavelengths above rest-frame 1$\\mu$m, and an additional ad-hoc red source would be required to explain the observed flux excess at 0.66 and 0.86$\\mu$m. Additional deep MIRI imaging covering the rest-frame near-IR are needed to confirm the flux detection at 10$\\mu$m with higher significance, and to discriminate between the different hot dust emission in the extreme starburst and AGN scenarios with MIRI imaging at longer wavelengths.",
          "authors": [
            "A. Crespo Gómez",
            "L. Colina",
            "P. G. Pérez-González",
            "J. Álvarez-Márquez",
            "M. García-Marín",
            "A. Alonso-Herrero",
            "M. Annunziatella",
            "A. Bik",
            "S. Bosman",
            "A. J. Bunker",
            "A. Labiano",
            "D. Langeroodi",
            "P. Rinaldi",
            "G. Östlin",
            "L. Boogaard",
            "S. Gillman",
            "G. Barro",
            "S. L. Finkelstein",
            "G. C. K. Leung"
          ],
          "primary_category": "astro-ph.GA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03003",
          "title": "The role of the top Yukawa coupling in triple Higgs production at the LHC",
          "abstract": "In this letter I quantify the effects of varying the top Yukawa coupling in the process of production of three Higgs bosons at the LHC. Modifications of the coupling within experimentally observed ranges have a sizeable impact on the total cross-section, but do not have large effects on the distributions of the invariant mass of the three-Higgs system and other global observables.",
          "authors": [
            "Luca Panizzi"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03006",
          "title": "Modeling dark matter halos with self-interacting fermions",
          "abstract": "In this work we study the possibility of modeling the dark matter content in galaxies as a core-halo model consisting of self-gravitating, self-interacting fermions. For the core of the halo, the dark matter fermions are degenerate, while for the halo we have considered two possibilities: the fermions have thermalized as a perfect fluidor they will follow a standard cold dark matter Navarro-Frenk-White profile. The core density profile is obtained by solving the Tolman-Oppenheimer-Volkoff equations, and their properties are determined by the fermion mass, the central density and the interaction strength. The mass of the fermion and the strength of the fermion self-interaction is fixed by doing a $\\chi^2$ analysis to fit that fit the rotational curves of Low Surface Brightness galaxies. It was found that the fermion mass should be in the range $38.73~\\rm{eV}< m_{f} < 42.11~\\rm{eV}$ and the interparticle strength in the range $269.69 < y <348.48$ at $68$ C.L. in order to reproduce the rotational curves adequately, in the case when the halo is modeled as a thermalized ideal gas. Similar values are obtained if the halo is modeled following a Navarro-Frenk-White case, namely $41.54 ~\\rm{eV} < m_{f} <49.87 ~\\rm{eV}$ and $5606.06< y < 17484.84$. Once fixed the values of the mass of the fermion $m_f$ and the interaction strength $y$, we tested the core-halo model with data from the Milky Way and the SPARC database. We have found good agreement between the data and the core-halo models, varying only one free parameter: the central density. Thus a single fermion can fit hundreds of galaxies. Nevertheless, the dark matter halo surface density relation or the halo total mass and radius depend strongly on the model for the halo.",
          "authors": [
            "Fabian Hernandez-Gutierrez",
            "Juan Barranco"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03006",
          "title": "Modeling dark matter halos with self-interacting fermions",
          "abstract": "In this work we study the possibility of modeling the dark matter content in galaxies as a core-halo model consisting of self-gravitating, self-interacting fermions. For the core of the halo, the dark matter fermions are degenerate, while for the halo we have considered two possibilities: the fermions have thermalized as a perfect fluidor they will follow a standard cold dark matter Navarro-Frenk-White profile. The core density profile is obtained by solving the Tolman-Oppenheimer-Volkoff equations, and their properties are determined by the fermion mass, the central density and the interaction strength. The mass of the fermion and the strength of the fermion self-interaction is fixed by doing a $\\chi^2$ analysis to fit that fit the rotational curves of Low Surface Brightness galaxies. It was found that the fermion mass should be in the range $38.73~\\rm{eV}< m_{f} < 42.11~\\rm{eV}$ and the interparticle strength in the range $269.69 < y <348.48$ at $68$ C.L. in order to reproduce the rotational curves adequately, in the case when the halo is modeled as a thermalized ideal gas. Similar values are obtained if the halo is modeled following a Navarro-Frenk-White case, namely $41.54 ~\\rm{eV} < m_{f} <49.87 ~\\rm{eV}$ and $5606.06< y < 17484.84$. Once fixed the values of the mass of the fermion $m_f$ and the interaction strength $y$, we tested the core-halo model with data from the Milky Way and the SPARC database. We have found good agreement between the data and the core-halo models, varying only one free parameter: the central density. Thus a single fermion can fit hundreds of galaxies. Nevertheless, the dark matter halo surface density relation or the halo total mass and radius depend strongly on the model for the halo.",
          "authors": [
            "Fabian Hernandez-Gutierrez",
            "Juan Barranco"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03008",
          "title": "Radiative decays of the $Σ_c$, $Ξ'_c$ and $Ω_c$ charmed baryons",
          "abstract": "In this work, we study the radiative decays of the $\\Sigma_c$, $\\Xi'_c$ and $\\Omega_c$ charmed baryons, which belong to the flavor sextet ($\\bf {6}_{\\rm F}$), within the constituent quark model formalism. The electromagnetic transitions are calculated from the ground and $P$-wave states to ground states, as well as from the second shell states to both the ground and $P$-wave final states. These decays play a crucial role in confirming the existence of certain resonances when strong decays are not allowed. %A relevant case is the $\\Omega_c^{0}$ spin excitation with $\\bf J^P ={\\frac{3}{2}}^{+}$ denoted as $\\Omega_c^{*0}$. This state cannot decay strongly, but has a nonvanishing predicted electromagnetic decay width in the $\\Omega_c^{0} \\gamma$ channel. The $\\Omega_c^{*0}$ was precisely observed in this channel. Moreover, electromagnetic decay widths are particularly useful for identifying resonances when states have the same mass and total decay width. A relevant case is the $\\Omega_c (3327)$ state, whose branching ratios between the strong decay channels are comparable; thus, the radiative decay widths may help assign this state. We also make the assignment of the recently discovered $\\Xi'_c(2923)^{+}$ baryon, which is consistent with being the isospin partner of the $\\Xi'_c(2923)^{0}$. This study presents, for the first time, the calculation of electromagnetic decays for $D_\\rho$-wave states, $\\rho-\\lambda$ mixed states, and $\\rho$-mode radially excited states in the charm sector. Throughout our calculations, we account for uncertainties arising from both experimental and model-dependent errors.",
          "authors": [
            "A. Dávila-Rivera",
            "H. García-Tecocoatzi",
            "A. Ramirez-Morales",
            "Ailier Rivero-Acosta",
            "E. Santopinto",
            "Carlos Alberto Vaquera-Araujo"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03009",
          "title": "Constraining Zero-Point Length from Gravitational Baryogenesis",
          "abstract": "The existence of a fundamental zero-point length, $l_0$, a minimal spacetime scale predicted by T-duality in string theory or quantum gravity theories, modifies the entropy associated with the horizon of spacetime. In the cosmological setup, this leads to correction to the Friedmann equations governing the evolution of the Universe. In this paper, we investigate the implications of zero-point length $l_0$-corrected gravity for gravitational baryogenesis and early universe thermodynamics, deriving constraints on $l_0$ from observational baryon asymmetry data. We observe that under the condition of non-equilibrium thermodynamics, $l_0$ generates $\\dot{\\mathcal{R}}\\neq 0$ during radiation epoch, where $\\mathcal{R}$ is the Ricci scalar. This yields a baryon asymmetry parameter $\\eta \\propto l_0^2 T_D^9/M_{\\rm Pl}^7$. The observed baryon asymmetry $\\eta \\sim 9.9 \\times 10^{-11}$ constrains $l_0 \\lesssim 7.1 \\times 10^{-33} m$, approximately $440$ times the Planck length. Furthermore, our analysis reveals that the zero-point length correction in the Friedmann equation, effectively slows the expansion rate at high energies, resulting in a modified time-temperature relationship where the Universe maintains higher temperatures for longer time during early epochs compared to standard cosmology. Our results establish zero-point length cosmology as a testable framework connecting quantum gravity to cosmological observables, with implications for early universe thermal history and fundamental length scales.",
          "authors": [
            "Ava Shahbazi Sooraki",
            "Ahmad Sheykhi"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03016",
          "title": "Topological Shell Structures in Neutron Stars: Effects on Equilibrium, Oscillations, and Gravitational-Wave Signatures",
          "abstract": "We study the structural and dynamical consequences of introducing a distributional density profile inside a neutron star, representing a massless, topological shell located at an arbitrary radius. We incorporate this effect into the structure of neutron star and construct equilibrium sequence for several realistic equations of state. Radial stability is examined through the Sturm-Liouville formulation of the $\\ell=0$ perturbation equation, supplemented with a jump condition and imprinting distinct features on the fundamental $f$-mode spectrum. We find strong, non-monotonic variations in the mode frequency relative to standard no-shell models. Using first-principles scaling relations, we estimate various gravitational wave observables such as the damping time, quality factor, luminosity and characteristic strain. These observables are then compared with the sensitivity of Advanced LIGO, and third-generation detectors such as the Einstein Telescope and Cosmic Explorer. Our results demonstrate that internal topological shells can leave potentially observable signatures in the oscillation and gravitational wave properties of neutron stars.",
          "authors": [
            "Debojoti Kuzur",
            "Kamal Krishna Nath"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03016",
          "title": "Topological Shell Structures in Neutron Stars: Effects on Equilibrium, Oscillations, and Gravitational-Wave Signatures",
          "abstract": "We study the structural and dynamical consequences of introducing a distributional density profile inside a neutron star, representing a massless, topological shell located at an arbitrary radius. We incorporate this effect into the structure of neutron star and construct equilibrium sequence for several realistic equations of state. Radial stability is examined through the Sturm-Liouville formulation of the $\\ell=0$ perturbation equation, supplemented with a jump condition and imprinting distinct features on the fundamental $f$-mode spectrum. We find strong, non-monotonic variations in the mode frequency relative to standard no-shell models. Using first-principles scaling relations, we estimate various gravitational wave observables such as the damping time, quality factor, luminosity and characteristic strain. These observables are then compared with the sensitivity of Advanced LIGO, and third-generation detectors such as the Einstein Telescope and Cosmic Explorer. Our results demonstrate that internal topological shells can leave potentially observable signatures in the oscillation and gravitational wave properties of neutron stars.",
          "authors": [
            "Debojoti Kuzur",
            "Kamal Krishna Nath"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03037",
          "title": "Neutron stars in $f(\\mathbb{Q})$ gravity",
          "abstract": "We investigate the challenges of constructing neutron star (NS) solutions in $f(\\mathbb{Q})$ gravity, highlighting the importance of treating the affine connection as an active, dynamical component of the theory. We begin by clarifying under what conditions standard simplifications -such as the coincident gauge or General Relativity (GR)-like connections- inadvertently lead to GR behavior, even in non-trivial $f(\\mathbb{Q})$ models. Building on previous work in black hole (BH) spacetimes, we adapt the formalism to NS and extend it to non-vacuum configurations. Focusing on two representative models, $f(\\mathbb{Q}) = \\mathbb{Q} + \\alpha \\mathbb{Q}^2$ and $f(\\mathbb{Q}) = \\mathbb{Q}^\\beta$, our analysis suggests that, under standard regularity assumptions, solutions with Maclaurin/Laurent-type series recover GR dynamics, pointing to more intricate structures as the likely seat of beyond-GR effects, and reflecting the constraints imposed by the connection's dynamics on the asymptotic behavior of genuinely beyond-GR solutions. We then formulate the problem as a boundary value problem (BVP) and highlight the numerical pathologies that may arise, together with possible strategies to prevent them. This work aims to provide a concrete framework for future numerical studies and outlines the theoretical consistency conditions required to construct physically meaningful beyond-GR NS solutions in $f(\\mathbb{Q})$ gravity.",
          "authors": [
            "Lavinia Heisenberg",
            "Carlos Pastor-Marcos"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03037",
          "title": "Neutron stars in $f(\\mathbb{Q})$ gravity",
          "abstract": "We investigate the challenges of constructing neutron star (NS) solutions in $f(\\mathbb{Q})$ gravity, highlighting the importance of treating the affine connection as an active, dynamical component of the theory. We begin by clarifying under what conditions standard simplifications -such as the coincident gauge or General Relativity (GR)-like connections- inadvertently lead to GR behavior, even in non-trivial $f(\\mathbb{Q})$ models. Building on previous work in black hole (BH) spacetimes, we adapt the formalism to NS and extend it to non-vacuum configurations. Focusing on two representative models, $f(\\mathbb{Q}) = \\mathbb{Q} + \\alpha \\mathbb{Q}^2$ and $f(\\mathbb{Q}) = \\mathbb{Q}^\\beta$, our analysis suggests that, under standard regularity assumptions, solutions with Maclaurin/Laurent-type series recover GR dynamics, pointing to more intricate structures as the likely seat of beyond-GR effects, and reflecting the constraints imposed by the connection's dynamics on the asymptotic behavior of genuinely beyond-GR solutions. We then formulate the problem as a boundary value problem (BVP) and highlight the numerical pathologies that may arise, together with possible strategies to prevent them. This work aims to provide a concrete framework for future numerical studies and outlines the theoretical consistency conditions required to construct physically meaningful beyond-GR NS solutions in $f(\\mathbb{Q})$ gravity.",
          "authors": [
            "Lavinia Heisenberg",
            "Carlos Pastor-Marcos"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03038",
          "title": "A new constraint on the $y$-distortion with FIRAS: implications for feedback models in galaxy formation and cosmic shear measurements",
          "abstract": "The $y$-type distortion of the blackbody spectrum of the cosmic microwave background radiation probes the pressure of the gas trapped in galaxy groups and clusters. We reanalyze archival data of the FIRAS instrument with an improved astrophysical foreground cleaning technique, and measure a mean $y$-distortion of $\\langle y\\rangle = (1.2\\pm 2.0) \\times 10^{-6}$ ($\\langle y\\rangle\\lesssim 5.2\\times 10^{-6}$ at 95\\% C.L.), a factor of $\\sim 3$ tighter than the original FIRAS results. This measurement directly rules out many models of baryonic feedback as implemented in cosmological hydrodynamical simulations, mostly using information in objects with mass $M\\lesssim 10^{14} {\\rm M}_{\\odot}$. We discuss its implications for the analysis of cosmic shear and kinetic Sunyaev-Zel'dovich effect data, and future spectral distortion experiments.",
          "authors": [
            "Giulio Fabbian",
            "Federico Bianchini",
            "Alina Sabyr",
            "J. Colin Hill",
            "Christopher C. Lovell",
            "Leander Thiele",
            "David N. Spergel"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 2,
      "size": 62,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2512.02353",
          "title": "A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler",
          "abstract": "Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.",
          "primary_category": "cs.IT",
          "authors": [
            "Ruizhe Wang",
            "Hong Ren",
            "Cunhua Pan",
            "Ruisong Weng",
            "Jiangzhou Wang"
          ]
        },
        {
          "id": "arXiv:2512.02683",
          "title": "Distributed and Autonomic Minimum Spanning Trees",
          "abstract": "The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.",
          "primary_category": "cs.DC",
          "authors": [
            "Luiz A. Rodrigues",
            "Elias P. Duarte Jr.",
            "Luciana Arantes"
          ]
        },
        {
          "id": "arXiv:2512.02353",
          "title": "A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler",
          "abstract": "Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.",
          "primary_category": "cs.IT",
          "authors": [
            "Ruizhe Wang",
            "Hong Ren",
            "Cunhua Pan",
            "Ruisong Weng",
            "Jiangzhou Wang"
          ]
        },
        {
          "id": "arXiv:2512.02370",
          "title": "Diffusion-Model-enhanced Multiobjective Optimization for Improving Forest Monitoring Efficiency in UAV-enabled Internet-of-Things",
          "abstract": "The Internet-of-Things (IoT) is widely applied for forest monitoring, since the sensor nodes (SNs) in IoT network are low-cost and have computing ability to process the monitoring data. To further improve the performance of forest monitoring, uncrewed aerial vehicles (UAVs) are employed as the data processors to enhance computing capability. However, efficient forest monitoring with limited energy budget and computing resource presents a significant challenge. For this purpose, this paper formulates a multi-objective optimization framework to simultaneously consider three optimization objectives, which are minimizing the maximum computing delay, minimizing the total motion energy consumption, and minimizing the maximum computing resource, corresponding to efficient forest monitoring, energy consumption reduction, and computing resource control, respectively. Due to the hybrid solution space that consists of continuous and discrete solutions, we propose a diffusion model-enhanced improved multi-objective grey wolf optimizer (IMOGWO) to solve the formulated framework. The simulation results show that the proposed IMOGWO outperforms other benchmarks for solving the formulated framework. Specifically, for a small-scale network with $6$ UAVs and $50$ SNs, compared to the suboptimal benchmark, IMOGWO reduces the motion energy consumption and the computing resource by $53.32\\%$ and $9.83\\%$, respectively, while maintaining computing delay at the same level. Similarly, for a large-scale network with $8$ UAVs and $100$ SNs, IMOGWO achieves reductions of $41.81\\%$ in motion energy consumption and $7.93\\%$ in computing resource, with the computing delay also remaining comparable.",
          "primary_category": "cs.NI",
          "authors": [
            "Hongyang Pan",
            "Bin Lin",
            "Yanheng Liu",
            "Shuang Liang",
            "Chau Yuen"
          ]
        },
        {
          "id": "arXiv:2512.02398",
          "title": "ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs",
          "abstract": "We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.",
          "primary_category": "cs.NI",
          "authors": [
            "Zhiyu Zhou",
            "Xin Zhe Khooi",
            "Satis Kumar Permal",
            "Mun Choon Chan"
          ]
        },
        {
          "id": "arXiv:2512.02449",
          "title": "Optimal Handover Strategies in LEO Satellite Networks",
          "abstract": "Existing theoretical analyses of satellite mega-constellations often rely on restrictive assumptions, such as short serving times, or lack tractability when evaluating realistic handover strategies. Motivated by these limitations, this paper develops a general analytical framework for accurately characterising the ergodic capacity of low Earth orbit (LEO) satellite networks under arbitrary handover strategies. Specifically, we model the transmission link as shadowed-Rician fading and introduce the persistent satellite channel, wherein the channel process is governed by an i.i.d. renewal process under mild assumptions of uncoordinated handover decisions and knowledge of satellite ephemeris and fading parameters. Within this framework, we derive the ergodic capacity (persistent capacity) of the persistent satellite channel using renewal theory and establish its relation to the non-persistent capacity studied in prior work. To address computational challenges, we present closed-form upper and lower bounds on persistent capacity. The optimal handover problem is formulated as a non-linear fractional program, obtaining an explicit decision rule via a variant of Dinkelbach's algorithm. We further demonstrate that a simpler handover strategy maximising serving capacity closely approximates the optimal strategy, providing practical insights for designing high-throughput LEO satellite communication systems.",
          "primary_category": "cs.IT",
          "authors": [
            "Brendon McBain",
            "Yi Hong",
            "Emanuele Viterbo"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2301.12766",
          "title": "GPS-Spoofing Attack Detection Mechanism for UAV Swarms",
          "abstract": "Recently autonomous and semi-autonomous Unmanned Aerial Vehicle (UAV) swarms started to receive a lot of research interest and demand from various civil application fields. However, for successful mission execution, UAV swarms require Global navigation satellite system signals and in particular, Global Positioning System (GPS) signals for navigation. Unfortunately, civil GPS signals are unencrypted and unauthenticated, which facilitates the execution of GPS spoofing attacks. During these attacks, adversaries mimic the authentic GPS signal and broadcast it to the targeted UAV in order to change its course, and force it to land or crash. In this study, we propose a GPS spoofing detection mechanism capable of detecting single-transmitter and multi-transmitter GPS spoofing attacks to prevent the outcomes mentioned above. Our detection mechanism is based on comparing the distance between each two swarm members calculated from their GPS coordinates to the distance acquired from Impulse Radio Ultra-Wideband ranging between the same swarm members. If the difference in distances is larger than a chosen threshold the GPS spoofing attack is declared detected.",
          "authors": [
            "Pavlo Mykytyn",
            "Marcin Brzozowski",
            "Zoya Dyka",
            "Peter Langendoerfer"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.14782",
          "title": "Energy-Efficient Multi-UAV-Enabled MEC Systems over Space-Air-Ground Integrated Networks",
          "abstract": "With the development of artificial intelligence integrated next-generation communication networks, mobile users (MUs) are increasingly demanding the efficient processing of computation-intensive and latency-sensitive tasks. However, existing mobile computing networks struggle to support the rapidly growing computational needs of the MUs. Fortunately, space-air-ground integrated network (SAGIN) supported mobile edge computing (MEC) is regarded as an effective solution, offering the MUs multi-tier and efficient computing services. In this paper, we consider an SAGIN supported MEC system, where a low Earth orbit satellite and multiple unmanned aerial vehicles (UAVs) are dispatched to provide computing services for MUs. An energy efficiency maximization problem is formulated, with the joint optimization of the MU-UAV association, the UAV trajectory, the task offloading decision, the computing frequency, and the transmission power control. Since the problem is non-convex, we decompose it into four subproblems, and propose an alternating optimization based algorithm to solve it. Simulation results confirm that the proposed algorithm outperforms the benchmarks.",
          "authors": [
            "Wenchao Liu",
            "Xuhui Zhang",
            "Chunjie Wang",
            "Jinke Ren",
            "Zheng Xing",
            "Bo Yang",
            "Shuqiang Wang",
            "Yanyan Shen"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.06861",
          "title": "CSI-BERT2: A BERT-inspired Framework for Efficient CSI Prediction and Classification in Wireless Communication and Sensing",
          "abstract": "Channel state information (CSI) is a fundamental component in both wireless communication and sensing systems, enabling critical functions such as radio resource optimization and environmental perception. In wireless sensing, data scarcity and packet loss hinder efficient model training, while in wireless communication, high-dimensional CSI matrices and short coherent times caused by high mobility present challenges in CSI estimation. To address these issues, we propose a unified framework named CSI-BERT2 for CSI prediction and classification tasks, built on CSI-BERT, which adapts BERT to capture the complex relationships among CSI sequences through a bidirectional self-attention mechanism. We introduce a two-stage training method that first uses a mask language model (MLM) to enable the model to learn general feature extraction from scarce datasets in an unsupervised manner, followed by fine-tuning for specific downstream tasks. Specifically, we extend MLM into a mask prediction model (MPM), which efficiently addresses the CSI prediction task. To further enhance the representation capacity of CSI data, we modify the structure of the original CSI-BERT. We introduce an adaptive re-weighting layer (ARL) to enhance subcarrier representation and a multi-layer perceptron (MLP)-based temporal embedding module to mitigate temporal information loss problem inherent in the original Transformer. Extensive experiments on both real-world collected and simulated datasets demonstrate that CSI-BERT2 achieves state-of-the-art performance across all tasks. Our results further show that CSI-BERT2 generalizes effectively across varying sampling rates and robustly handles discontinuous CSI sequences caused by packet loss-challenges that conventional methods fail to address. The dataset and code are publicly available at this https URL .",
          "authors": [
            "Zijian Zhao",
            "Fanyi Meng",
            "Zhonghao Lyu",
            "Hang Li",
            "Xiaoyang Li",
            "Guangxu Zhu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.06861",
          "title": "CSI-BERT2: A BERT-inspired Framework for Efficient CSI Prediction and Classification in Wireless Communication and Sensing",
          "abstract": "Channel state information (CSI) is a fundamental component in both wireless communication and sensing systems, enabling critical functions such as radio resource optimization and environmental perception. In wireless sensing, data scarcity and packet loss hinder efficient model training, while in wireless communication, high-dimensional CSI matrices and short coherent times caused by high mobility present challenges in CSI estimation. To address these issues, we propose a unified framework named CSI-BERT2 for CSI prediction and classification tasks, built on CSI-BERT, which adapts BERT to capture the complex relationships among CSI sequences through a bidirectional self-attention mechanism. We introduce a two-stage training method that first uses a mask language model (MLM) to enable the model to learn general feature extraction from scarce datasets in an unsupervised manner, followed by fine-tuning for specific downstream tasks. Specifically, we extend MLM into a mask prediction model (MPM), which efficiently addresses the CSI prediction task. To further enhance the representation capacity of CSI data, we modify the structure of the original CSI-BERT. We introduce an adaptive re-weighting layer (ARL) to enhance subcarrier representation and a multi-layer perceptron (MLP)-based temporal embedding module to mitigate temporal information loss problem inherent in the original Transformer. Extensive experiments on both real-world collected and simulated datasets demonstrate that CSI-BERT2 achieves state-of-the-art performance across all tasks. Our results further show that CSI-BERT2 generalizes effectively across varying sampling rates and robustly handles discontinuous CSI sequences caused by packet loss-challenges that conventional methods fail to address. The dataset and code are publicly available at this https URL .",
          "authors": [
            "Zijian Zhao",
            "Fanyi Meng",
            "Zhonghao Lyu",
            "Hang Li",
            "Xiaoyang Li",
            "Guangxu Zhu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.04142",
          "title": "An Uncertainty Quantification Framework for Deep Learning-Based Automatic Modulation Classification",
          "abstract": "Deep learning has been shown to be highly effective for automatic modulation classification (AMC), which is a pivotal technology for next-generation cognitive communications. Yet, existing deep learning methods for AMC often lack robust mechanisms for uncertainty quantification (UQ). This limitation restricts their ability to produce accurate and reliable predictions in real-world environments, where signals can be perturbed as a result of several factors such as interference and low signal-to-noise ratios (SNR). To address this problem, we propose a deep ensemble approach that leverages multiple convolutional neural networks (CNNs) to generate predictive distributions, as opposed to point estimates produced by standard deep learning models, which produce statistical characteristics that quantify the uncertainty associated with each prediction. We validate our approach using real-world AMC data, evaluating performance through multiple UQ metrics in a variety of signal environments. Our results show that our proposed ensemble-based framework captures uncertainty to a greater degree compared to previously proposed baselines in multiple settings, including in-distribution samples, out-of-distribution samples, and low SNR signals. These findings highlight the strong UQ capabilities of our ensemble-based AMC approach, paving the way for more robust deep learning-based AMC.",
          "authors": [
            "Huian Yang",
            "Rajeev Sahay"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.24051",
          "title": "NASP: Network Slice as a Service Platform for 5G Networks",
          "abstract": "With 5G's rapid global uptake, demand for agile private networks has exploded. A defining beyond-5G capability is network slicing. 3GPP specifies three core slice categories, massive Machine-Type Communications (mMTC), enhanced Mobile Broadband (eMBB), and Ultra-Reliable Low-Latency Communications (URLLC), while ETSI's Zero-Touch Network and Service Management (ZSM) targets human-less operation. Yet existing documents do not spell out end-to-end (E2E) management spanning multiple domains and subnet instances. We introduce the Network Slice-as-a-Service Platform (NASP), designed to work across 3GPP and non-3GPP networks. NASP (i) translates business-level slice requests into concrete physical instances and inter-domain interfaces, (ii) employs a hierarchical orchestrator that aligns distributed management functions, and (iii) exposes clean south-bound APIs toward domain controllers. A prototype was built by unifying guidance from 3GPP, ETSI, and O-RAN, identifying overlaps and gaps among them. We tested NASP with two exemplary deployments, 3GPP and non-3GPP, over four scenarios: mMTC, URLLC, 3GPP-Shared, and non-3GPP. The Communication Service Management Function handled all requests, underlining the platform's versatility. Measurements show that core-network configuration dominates slice-creation time (68 %), and session setup in the URLLC slice is 93 % faster than in the Shared slice. Cost analysis for orchestrating five versus ten concurrent slices reveals a 112 % delta between edge and centralized deployments. These results demonstrate that NASP delivers flexible, standards-aligned E2E slicing while uncovering opportunities to reduce latency and operational cost.",
          "authors": [
            "Felipe Hauschild Grings",
            "Gustavo Zanatta Bruno",
            "Lucio Rene Prade",
            "Cristiano Bonato Both",
            "José Marcos Camara Brito"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.14987",
          "title": "CNN-Enabled Scheduling for Probabilistic Real-Time Guarantees in Industrial URLLC",
          "abstract": "Ensuring packet-level communication quality is vital for ultra-reliable, low-latency communications (URLLC) in large-scale industrial wireless networks. We enhance the Local Deadline Partition (LDP) algorithm by introducing a CNN-based dynamic priority prediction mechanism for improved interference coordination in multi-cell, multi-channel networks. Unlike LDP's static priorities, our approach uses a Convolutional Neural Network and graph coloring to adaptively assign link priorities based on real-time traffic, transmission opportunities, and network conditions. Assuming that first training phase is performed offline, our approach introduced minimal overhead, while enabling more efficient resource allocation, boosting network capacity, SINR, and schedulability. Simulation results show SINR gains of up to 113\\%, 94\\%, and 49\\% over LDP across three network configurations, highlighting its effectiveness for complex URLLC scenarios.",
          "authors": [
            "Eman Alqudah",
            "Ashfaq Khokhar"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06911",
          "title": "Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G",
          "abstract": "Data-intensive Artificial Intelligence (AI) applications at the network edge demand a fundamental shift in Radio Access Network (RAN) design, from merely consuming AI for network optimization, to actively enabling distributed AI workloads. This presents a significant opportunity for network operators to monetize AI while leveraging existing infrastructure. To realize this vision, this article presents a novel converged O-RAN and AI-RAN architecture for unified orchestration and management of telecommunications and AI workloads on shared infrastructure. The proposed architecture extends the Open RAN principles of modularity, disaggregation, and cloud-nativeness to support heterogeneous AI deployments. We introduce two key architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN Service Management and Orchestration (SMO) to enable integrated resource and allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide distributed edge AI platforms with real-time processing capabilities. The proposed architecture enables flexible orchestration, meeting requirements for managing heterogeneous workloads at different time scales while maintaining open, standardized interfaces and multi-vendor interoperability.",
          "authors": [
            "Michele Polese",
            "Niloofar Mohamadi",
            "Salvatore D'Oro",
            "Leonardo Bonati",
            "Tommaso Melodia"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06911",
          "title": "Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G",
          "abstract": "Data-intensive Artificial Intelligence (AI) applications at the network edge demand a fundamental shift in Radio Access Network (RAN) design, from merely consuming AI for network optimization, to actively enabling distributed AI workloads. This presents a significant opportunity for network operators to monetize AI while leveraging existing infrastructure. To realize this vision, this article presents a novel converged O-RAN and AI-RAN architecture for unified orchestration and management of telecommunications and AI workloads on shared infrastructure. The proposed architecture extends the Open RAN principles of modularity, disaggregation, and cloud-nativeness to support heterogeneous AI deployments. We introduce two key architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN Service Management and Orchestration (SMO) to enable integrated resource and allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide distributed edge AI platforms with real-time processing capabilities. The proposed architecture enables flexible orchestration, meeting requirements for managing heterogeneous workloads at different time scales while maintaining open, standardized interfaces and multi-vendor interoperability.",
          "authors": [
            "Michele Polese",
            "Niloofar Mohamadi",
            "Salvatore D'Oro",
            "Leonardo Bonati",
            "Tommaso Melodia"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.01044",
          "title": "Coordinated Decentralized Resource Optimization for Cell-Free ISAC Systems",
          "abstract": "Integrated Sensing and Communication (ISAC) is emerging as a key enabler for 6G wireless networks, allowing the joint use of spectrum and infrastructure for both communication and sensing. While prior ISAC solutions have addressed resource optimization, including power allocation, beamforming, and waveform design, they often rely on centralized architectures with full network knowledge, limiting their scalability in distributed systems. In this paper, we propose two coordinated decentralized optimization algorithms for beamforming and power allocation tailored to cell-free ISAC networks. The first algorithm employs locally designed fixed beamformers at access points (APs), combined with a centralized power allocation scheme computed at a central server (CS). The second algorithm jointly optimizes beamforming and power control through a fully decentralized consensus ADMM framework. Both approaches rely on local information at APs and limited coordination with the CS. Simulation results obtained using our proposed Python-based simulation framework evaluate their fronthaul overhead and system-level performance, demonstrating their practicality for scalable ISAC deployment in decentralized, cell-free architectures.",
          "authors": [
            "Mehdi Zafari",
            "Rang Liu",
            "A. Lee Swindlehurst"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.01044",
          "title": "Coordinated Decentralized Resource Optimization for Cell-Free ISAC Systems",
          "abstract": "Integrated Sensing and Communication (ISAC) is emerging as a key enabler for 6G wireless networks, allowing the joint use of spectrum and infrastructure for both communication and sensing. While prior ISAC solutions have addressed resource optimization, including power allocation, beamforming, and waveform design, they often rely on centralized architectures with full network knowledge, limiting their scalability in distributed systems. In this paper, we propose two coordinated decentralized optimization algorithms for beamforming and power allocation tailored to cell-free ISAC networks. The first algorithm employs locally designed fixed beamformers at access points (APs), combined with a centralized power allocation scheme computed at a central server (CS). The second algorithm jointly optimizes beamforming and power control through a fully decentralized consensus ADMM framework. Both approaches rely on local information at APs and limited coordination with the CS. Simulation results obtained using our proposed Python-based simulation framework evaluate their fronthaul overhead and system-level performance, demonstrating their practicality for scalable ISAC deployment in decentralized, cell-free architectures.",
          "authors": [
            "Mehdi Zafari",
            "Rang Liu",
            "A. Lee Swindlehurst"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.19401",
          "title": "Ray-Tracing Based Narrow-Beam Channel Simulation, Characterization and Performance Evaluation for 5G-R Systems",
          "abstract": "This paper investigates narrow-beam channel characterization and performance evaluation for 5G for railway (5G-R) systems based on ray-tracing (RT) simulation. Three representative high-speed railway (HSR) scenarios including viaduct, cutting, and station are established, and RT-based dynamic narrow-beam channel simulations are conducted using a designed beam tracking scheme that ensures continuous alignment with the moving train. The channel characteristics are analyzed in terms of both large-scale and small-scale fading, as well as non-stationarity, providing statistical insights into path loss, shadow fading, fading severity, time-frequency-space dispersion, and stationarity interval. The influence of beamwidth on these channel properties is also examined. Furthermore, the performance of 5G-R systems operating in such narrow-beam channels is evaluated using the Vienna 5G simulator, with a focus on block error rate, throughput, and spectral efficiency. A hardware-in-the-loop simulation platform is developed to further assess synchronization signal reference signal received power, signal-to-interference-plus-noise ratio, and reference signal received quality. The results provide valuable guidance for the design and optimization of 5G-R systems in HSR environments.",
          "authors": [
            "Tao Zhou",
            "Liying Geng",
            "Kaifeng Bao",
            "Tianyun Feng",
            "Liu Liu",
            "Bo Ai"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15970",
          "title": "An Enhanced Whale Optimization Algorithm with Log-Normal Distribution for Optimizing Coverage of Wireless Sensor Networks",
          "abstract": "Wireless Sensor Networks (WSNs) are essential for monitoring and communication in complex environments, where coverage optimization directly affects performance and energy efficiency. However, traditional algorithms such as the Whale Optimization Algorithm (WOA) often suffer from limited exploration and premature convergence. To overcome these issues, this paper proposes an enhanced WOA which is called GLNWOA. GLNWOA integrates a log-normal distribution model into WOA to improve convergence dynamics and search diversity. GLNWOA employs a Good Nodes Set initialization for uniform population distribution, a Leader Cognitive Guidance Mechanism for efficient information sharing, and an Enhanced Spiral Updating Strategy to balance global exploration and local exploitation. Tests on benchmark functions verify its superior convergence accuracy and robustness. In WSN coverage optimization, deploying 25 nodes in a 60 m $\\times$ 60 m area achieved a 99.0013\\% coverage rate, outperforming AROA, WOA, HHO, ROA, and WOABAT by up to 15.5\\%. These results demonstrate that GLNWOA offers fast convergence, high stability, and excellent optimization capability for intelligent network deployment.",
          "authors": [
            "Junhao Wei",
            "Yanzhao Gu",
            "Ran Zhang",
            "Yanxiao Li",
            "Wenxuan Zhu",
            "Jinhong Song",
            "Yapeng Wang",
            "Xu Yang",
            "Ngai Cheong"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21906",
          "title": "Quantized Distributed Estimation with Event-triggered Communication and Packet Loss",
          "abstract": "This paper focuses on the problem of quantized distributed estimation with event-triggered communication and packet loss, aiming to reduce the number of transmitted bits. The main challenge lies in the inability to differentiate between an untriggered event and a packet loss occurrence. This paper proposes an event-triggered distributed estimation algorithm with quantized communication and quantized measurement, in which it introduces a one-bit information reconstruction method to deal with packet loss. The almost sure convergence and convergence rate of the proposed algorithm are established. Besides, it is demonstrated that the global average communication bit-rate decreases to zero over time. Moreover, the trade-off between communication rate and convergence rate is revealed, providing guidance for designing the communication rate required to achieve the algorithm's convergence rate. A numerical example is supplied to validate the findings.",
          "authors": [
            "Ying Wang",
            "Yanlong Zhao",
            "Ji-Feng Zhang",
            "Karl Henrik Johansson"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21906",
          "title": "Quantized Distributed Estimation with Event-triggered Communication and Packet Loss",
          "abstract": "This paper focuses on the problem of quantized distributed estimation with event-triggered communication and packet loss, aiming to reduce the number of transmitted bits. The main challenge lies in the inability to differentiate between an untriggered event and a packet loss occurrence. This paper proposes an event-triggered distributed estimation algorithm with quantized communication and quantized measurement, in which it introduces a one-bit information reconstruction method to deal with packet loss. The almost sure convergence and convergence rate of the proposed algorithm are established. Besides, it is demonstrated that the global average communication bit-rate decreases to zero over time. Moreover, the trade-off between communication rate and convergence rate is revealed, providing guidance for designing the communication rate required to achieve the algorithm's convergence rate. A numerical example is supplied to validate the findings.",
          "authors": [
            "Ying Wang",
            "Yanlong Zhao",
            "Ji-Feng Zhang",
            "Karl Henrik Johansson"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02079",
          "title": "Robust Geospatial Coordination of Multi-Agent Communications Networks Under Attrition",
          "abstract": "Fast, efficient, robust communication during wildfire and other emergency responses is critical. One way to achieve this is by coordinating swarms of autonomous aerial vehicles carrying communications equipment to form an ad-hoc network connecting emergency response personnel to both each other and central command. However, operating in such extreme environments may lead to individual networking agents being damaged or rendered inoperable, which could bring down the network and interrupt communications. To overcome this challenge and enable multi-agent UAV networking in difficult environments, this paper introduces and formalizes the problem of Robust Task Networking Under Attrition (RTNUA), which extends connectivity maintenance in multi-robot systems to explicitly address proactive redundancy and attrition recovery. We introduce Physics-Informed Robust Employment of Multi-Agent Networks ($\\Phi$IREMAN), a topological algorithm leveraging physics-inspired potential fields to solve this problem. Through simulation across 25 problem configurations, $\\Phi$IREMAN consistently outperforms the DCCRS baseline, and on large-scale problems with up to 100 tasks and 500 drones, maintains $>99.9\\%$ task uptime despite substantial attrition, demonstrating both effectiveness and scalability.",
          "authors": [
            "Jonathan S. Kent",
            "Eliana Stefani",
            "Brian K. Plancher"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02079",
          "title": "Robust Geospatial Coordination of Multi-Agent Communications Networks Under Attrition",
          "abstract": "Fast, efficient, robust communication during wildfire and other emergency responses is critical. One way to achieve this is by coordinating swarms of autonomous aerial vehicles carrying communications equipment to form an ad-hoc network connecting emergency response personnel to both each other and central command. However, operating in such extreme environments may lead to individual networking agents being damaged or rendered inoperable, which could bring down the network and interrupt communications. To overcome this challenge and enable multi-agent UAV networking in difficult environments, this paper introduces and formalizes the problem of Robust Task Networking Under Attrition (RTNUA), which extends connectivity maintenance in multi-robot systems to explicitly address proactive redundancy and attrition recovery. We introduce Physics-Informed Robust Employment of Multi-Agent Networks ($\\Phi$IREMAN), a topological algorithm leveraging physics-inspired potential fields to solve this problem. Through simulation across 25 problem configurations, $\\Phi$IREMAN consistently outperforms the DCCRS baseline, and on large-scale problems with up to 100 tasks and 500 drones, maintains $>99.9\\%$ task uptime despite substantial attrition, demonstrating both effectiveness and scalability.",
          "authors": [
            "Jonathan S. Kent",
            "Eliana Stefani",
            "Brian K. Plancher"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02153",
          "title": "Hardware Distortion Aware Precoding for ISAC Systems",
          "abstract": "The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs.",
          "authors": [
            "Murat Babek Salman",
            "Emil Björnson",
            "Özlem Tugfe Demir"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02153",
          "title": "Hardware Distortion Aware Precoding for ISAC Systems",
          "abstract": "The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs.",
          "authors": [
            "Murat Babek Salman",
            "Emil Björnson",
            "Özlem Tugfe Demir"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02153",
          "title": "Hardware Distortion Aware Precoding for ISAC Systems",
          "abstract": "The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs.",
          "authors": [
            "Murat Babek Salman",
            "Emil Björnson",
            "Özlem Tugfe Demir"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02245",
          "title": "Wavenumber-Division Multiplexing in Holographic MIMO with NLoS Channels",
          "abstract": "Wavenumber-division multiplexing (WDM) was introduced as a counterpart of orthogonal frequency-division multiplexing in the spatial-frequency domain for line-of-sight holographic multiple-input multiple-output (MIMO) systems. In this paper, we extend WDM to holographic MIMO channels with non-line-of-sight (NLoS) propagation. We show that applying WDM to the NLoS channel yields the corresponding angular-domain representation, which we characterize through the power spectral factor and power spectral density. We further obtain a closed-form characterization for the case of isotropic scattering, recovering Jakes' isotropic model. The analysis is complemented by numerical results evaluating the degrees of freedom and ergodic capacity under both isotropic and non-isotropic scattering.",
          "authors": [
            "Ashutosh Prajapati",
            "Prathapasinghe Dharmawansa",
            "Marco Di Renzo",
            "Italo Atzeni"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02252",
          "title": "Optimal-Length Labeling Schemes and Fast Algorithms for k-gathering and k-broadcasting",
          "abstract": "We consider basic communication tasks in arbitrary radio networks: $k$-broadcasting and $k$-gathering. In the case of $k$-broadcasting messages from $k$ sources have to get to all nodes in the network. The goal of $k$-gathering is to collect messages from $k$ source nodes in a designated sink node. We consider these problems in the framework of distributed algorithms with advice. risko and Miller showed in 2021 that the optimal size of advice for $k$-broadcasting is $\\Theta(\\min(\\log \\Delta,$ $ \\log k))$, where $\\Delta$ is equal to the maximum degree of a vertex of the input communication graph. We show that the same bound $\\Theta(\\min(\\log \\Delta, \\log k))$ on the size of optimal labeling scheme holds also for the $k$-gathering problems. Moreover, we design fast algorithms for both problems with asymptotically optimal size of advice. For $k$-gathering our algorithm works in at most $D+k$ rounds, where $D$ is the diameter of the communication graph. This time bound is optimal even for centralized algorithms. We apply the $k$-gathering algorithm for $k$-broadcasting to achieve an algorithm working in time $O(D+\\log^2 n+k)$ rounds. We also exhibit a logarithmic time complexity gap between distributed algorithms with advice of optimal size and distributed algorithms with distinct arbitrary labels.",
          "authors": [
            "Adam Ganczorzand Tomasz Jurdzinski"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02255",
          "title": "Low-Power Double RIS-Assisted Mobile LEO Satellite Communications",
          "abstract": "We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.",
          "authors": [
            "Kunnathully Sadanandan Sanila",
            "Rickard Nilsson",
            "Emad Ibrahim",
            "Neelakandan Rajamohan"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02255",
          "title": "Low-Power Double RIS-Assisted Mobile LEO Satellite Communications",
          "abstract": "We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.",
          "authors": [
            "Kunnathully Sadanandan Sanila",
            "Rickard Nilsson",
            "Emad Ibrahim",
            "Neelakandan Rajamohan"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02255",
          "title": "Low-Power Double RIS-Assisted Mobile LEO Satellite Communications",
          "abstract": "We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.",
          "authors": [
            "Kunnathully Sadanandan Sanila",
            "Rickard Nilsson",
            "Emad Ibrahim",
            "Neelakandan Rajamohan"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02297",
          "title": "The xApp Store: A Framework for xApp Onboarding and Deployment in O-RAN",
          "abstract": "5G and beyond mobile telecommunication networks are increasingly embracing software technologies in their operation and control, similar to what has powered the growth of the cloud. This is most recently seen in the radio access network (RAN). In this new approach, the RAN is increasingly controlled by software applications known as xApps, and opens the door to third party development of xApps bringing diversity to the ecosystem, similar to mobile phone apps. This model aligns closely with the controllers in the ITU-T architecture for autonomous networks, and provides a pathway towards autonomous operation in the RAN. Unfortunately, no marketplace to host or supply xApps currently exists. This work describes our experiences in leveraging open-source O-RAN implementations to design and develop an xApp store.",
          "authors": [
            "Philip Rodgers",
            "Paul Harvey"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02297",
          "title": "The xApp Store: A Framework for xApp Onboarding and Deployment in O-RAN",
          "abstract": "5G and beyond mobile telecommunication networks are increasingly embracing software technologies in their operation and control, similar to what has powered the growth of the cloud. This is most recently seen in the radio access network (RAN). In this new approach, the RAN is increasingly controlled by software applications known as xApps, and opens the door to third party development of xApps bringing diversity to the ecosystem, similar to mobile phone apps. This model aligns closely with the controllers in the ITU-T architecture for autonomous networks, and provides a pathway towards autonomous operation in the RAN. Unfortunately, no marketplace to host or supply xApps currently exists. This work describes our experiences in leveraging open-source O-RAN implementations to design and develop an xApp store.",
          "authors": [
            "Philip Rodgers",
            "Paul Harvey"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02332",
          "title": "Age of Information for Constrained Scheduling with Imperfect Feedback",
          "abstract": "This paper considers a downlink system where an access point sends the monitored status of multiple sources to multiple users. By jointly accounting for imperfect feedback and constrained transmission rate, which are key limited factors in practical systems, we aim to design scheduling algorithms to optimize the age of information (AoI) over the infinite time horizon. For zero feedback under the generate-at-will traffic, we derive a closed-form lower bound of achievable AoI, which, to the best of our knowledge, reflects the impact of zero feedback for the first time, and propose a policy that achieves this bound in many cases by jointly applying rate splitting and modular arithmetic. For zero feedback under the Bernoulli traffic, we develop a drift-plus-penalty (DPP) policy with a threshold structure based on the theory of Lyapunov optimization and provide a closed-form performance guarantee. Furthermore, we extend the design of this DPP policy to support general imperfect feedback without increasing the online computational complexity. Numerical results verify our theoretical analysis and the AoI advantage of the proposed policies over state-of-the-art policies.",
          "authors": [
            "Yuqing Zhu",
            "Yuan-Hsun Lo",
            "Yan Lin",
            "Yijin Zhang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02332",
          "title": "Age of Information for Constrained Scheduling with Imperfect Feedback",
          "abstract": "This paper considers a downlink system where an access point sends the monitored status of multiple sources to multiple users. By jointly accounting for imperfect feedback and constrained transmission rate, which are key limited factors in practical systems, we aim to design scheduling algorithms to optimize the age of information (AoI) over the infinite time horizon. For zero feedback under the generate-at-will traffic, we derive a closed-form lower bound of achievable AoI, which, to the best of our knowledge, reflects the impact of zero feedback for the first time, and propose a policy that achieves this bound in many cases by jointly applying rate splitting and modular arithmetic. For zero feedback under the Bernoulli traffic, we develop a drift-plus-penalty (DPP) policy with a threshold structure based on the theory of Lyapunov optimization and provide a closed-form performance guarantee. Furthermore, we extend the design of this DPP policy to support general imperfect feedback without increasing the online computational complexity. Numerical results verify our theoretical analysis and the AoI advantage of the proposed policies over state-of-the-art policies.",
          "authors": [
            "Yuqing Zhu",
            "Yuan-Hsun Lo",
            "Yan Lin",
            "Yijin Zhang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02347",
          "title": "Coalitional Game Framework for Multicast in Wireless Networks",
          "abstract": "We consider a wireless network in which there is a transmitter and a set of users, all of whom want to download a popular file from the transmitter. Using the framework of cooperative game theory, we investigate conditions under which users have incentives to cooperate among themselves to form coalitions for the purpose of receiving the file via multicast from the transmitter. First, using the solution concept of core, we investigate conditions under which it is beneficial for all users to cooperate, i.e., the grand coalition is stable. We provide several sets of sufficient conditions under which the core is non-empty as well as those under which the core is empty. Next, we use the concept of $\\mathbb{D}_c$-stability to identify a set of sufficient conditions under which the users in the network form a certain fixed number of coalitions such that all the users within each coalition cooperate among themselves. Our analytical results show how the values of different system parameters, e.g., data rates of different users, transmit and receive power, file size, bandwidth cost, etc., influence stability properties of coalitions, and provide a systematic approach to evaluating cooperation of users for multicast. We also study cooperation among different users using numerical computations. The problem of coalition formation in the context of multicast addressed in this paper is fundamental, and our analysis provides new insights into the feasibility of stable cooperative multicast strategies, contributing to a deeper understanding of cooperation in wireless networks.",
          "authors": [
            "Anjali Yadav",
            "Arya Agarwal",
            "Alok Kumar",
            "Tushar S. Muratkar",
            "Gaurav S. Kasbekar"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02353",
          "title": "A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler",
          "abstract": "Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.",
          "authors": [
            "Ruizhe Wang",
            "Hong Ren",
            "Cunhua Pan",
            "Ruisong Weng",
            "Jiangzhou Wang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02353",
          "title": "A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler",
          "abstract": "Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.",
          "authors": [
            "Ruizhe Wang",
            "Hong Ren",
            "Cunhua Pan",
            "Ruisong Weng",
            "Jiangzhou Wang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02370",
          "title": "Diffusion-Model-enhanced Multiobjective Optimization for Improving Forest Monitoring Efficiency in UAV-enabled Internet-of-Things",
          "abstract": "The Internet-of-Things (IoT) is widely applied for forest monitoring, since the sensor nodes (SNs) in IoT network are low-cost and have computing ability to process the monitoring data. To further improve the performance of forest monitoring, uncrewed aerial vehicles (UAVs) are employed as the data processors to enhance computing capability. However, efficient forest monitoring with limited energy budget and computing resource presents a significant challenge. For this purpose, this paper formulates a multi-objective optimization framework to simultaneously consider three optimization objectives, which are minimizing the maximum computing delay, minimizing the total motion energy consumption, and minimizing the maximum computing resource, corresponding to efficient forest monitoring, energy consumption reduction, and computing resource control, respectively. Due to the hybrid solution space that consists of continuous and discrete solutions, we propose a diffusion model-enhanced improved multi-objective grey wolf optimizer (IMOGWO) to solve the formulated framework. The simulation results show that the proposed IMOGWO outperforms other benchmarks for solving the formulated framework. Specifically, for a small-scale network with $6$ UAVs and $50$ SNs, compared to the suboptimal benchmark, IMOGWO reduces the motion energy consumption and the computing resource by $53.32\\%$ and $9.83\\%$, respectively, while maintaining computing delay at the same level. Similarly, for a large-scale network with $8$ UAVs and $100$ SNs, IMOGWO achieves reductions of $41.81\\%$ in motion energy consumption and $7.93\\%$ in computing resource, with the computing delay also remaining comparable.",
          "authors": [
            "Hongyang Pan",
            "Bin Lin",
            "Yanheng Liu",
            "Shuang Liang",
            "Chau Yuen"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02398",
          "title": "ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs",
          "abstract": "We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.",
          "authors": [
            "Zhiyu Zhou",
            "Xin Zhe Khooi",
            "Satis Kumar Permal",
            "Mun Choon Chan"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02449",
          "title": "Optimal Handover Strategies in LEO Satellite Networks",
          "abstract": "Existing theoretical analyses of satellite mega-constellations often rely on restrictive assumptions, such as short serving times, or lack tractability when evaluating realistic handover strategies. Motivated by these limitations, this paper develops a general analytical framework for accurately characterising the ergodic capacity of low Earth orbit (LEO) satellite networks under arbitrary handover strategies. Specifically, we model the transmission link as shadowed-Rician fading and introduce the persistent satellite channel, wherein the channel process is governed by an i.i.d. renewal process under mild assumptions of uncoordinated handover decisions and knowledge of satellite ephemeris and fading parameters. Within this framework, we derive the ergodic capacity (persistent capacity) of the persistent satellite channel using renewal theory and establish its relation to the non-persistent capacity studied in prior work. To address computational challenges, we present closed-form upper and lower bounds on persistent capacity. The optimal handover problem is formulated as a non-linear fractional program, obtaining an explicit decision rule via a variant of Dinkelbach's algorithm. We further demonstrate that a simpler handover strategy maximising serving capacity closely approximates the optimal strategy, providing practical insights for designing high-throughput LEO satellite communication systems.",
          "authors": [
            "Brendon McBain",
            "Yi Hong",
            "Emanuele Viterbo"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02449",
          "title": "Optimal Handover Strategies in LEO Satellite Networks",
          "abstract": "Existing theoretical analyses of satellite mega-constellations often rely on restrictive assumptions, such as short serving times, or lack tractability when evaluating realistic handover strategies. Motivated by these limitations, this paper develops a general analytical framework for accurately characterising the ergodic capacity of low Earth orbit (LEO) satellite networks under arbitrary handover strategies. Specifically, we model the transmission link as shadowed-Rician fading and introduce the persistent satellite channel, wherein the channel process is governed by an i.i.d. renewal process under mild assumptions of uncoordinated handover decisions and knowledge of satellite ephemeris and fading parameters. Within this framework, we derive the ergodic capacity (persistent capacity) of the persistent satellite channel using renewal theory and establish its relation to the non-persistent capacity studied in prior work. To address computational challenges, we present closed-form upper and lower bounds on persistent capacity. The optimal handover problem is formulated as a non-linear fractional program, obtaining an explicit decision rule via a variant of Dinkelbach's algorithm. We further demonstrate that a simpler handover strategy maximising serving capacity closely approximates the optimal strategy, providing practical insights for designing high-throughput LEO satellite communication systems.",
          "authors": [
            "Brendon McBain",
            "Yi Hong",
            "Emanuele Viterbo"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02454",
          "title": "Widening the Coverage of Reference Broadcast Infrastructure Synchronization in Wi-Fi Networks",
          "abstract": "Precise clock synchronization protocols are increasingly used to ensure that all the nodes in a network share the very same time base. They enable several mechanisms aimed at improving determinism at both the application and communication levels, which makes them highly relevant to industrial environments. Reference Broadcast Infrastructure Synchronization (RBIS) is a solution specifically conceived for Wi-Fi that exploits existing beacons and can run on commercial devices. In this paper, an evolution of RBIS is presented, we call DOMINO, whose coverage area is much larger than the single Wi-Fi infrastructure network, potentially including the whole plant. In particular, wireless stations that can see more than one access point at the same time behave as boundary clocks and propagate the reference time across overlapping networks.",
          "authors": [
            "Gianluca Cena",
            "Pietro Chiavassa",
            "Gabriele Formis",
            "Stefano Scanzio"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02455",
          "title": "Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments",
          "abstract": "Wi-Fi is currently considered one of the most promising solutions for interconnecting mobile equipment (e.g., autonomous mobile robots and active exoskeletons) in industrial environments. However, relability requirements imposed by the industrial context, such as ensuring bounded transmission latency, are a major challenge for over-the-air communication. One of the aspects of Wi-Fi technology that greatly affects the probability of a packet reaching its destination is the selection of the appropriate transmission rate. Rate adaptation algorithms are in charge of this operation, but their design and implementation are not regulated by the IEEE 802.11 standard. One of the most popular solutions, available as open source, is Minstrel, which is the default choice for the Linux Kernel. In this paper, Minstrel performance is evaluated for both static and mobility scenarios. Our analysis focuses on metrics of interest for industrial contexts, i.e., latency and packet loss ratio, and serves as a preliminary evaluation for the future development of enhanced rate adaptation algorithms based on centralized digital twins.",
          "authors": [
            "Pietro Chiavassa",
            "Stefano Scanzio",
            "Gianluca Cena"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02461",
          "title": "Artificial Noise Aided Physical Layer Security for Near-Field MIMO with Fluid Antenna Systems",
          "abstract": "With the evolution of wireless systems toward large-scale arrays and high-frequency reconfigurable architectures, fluid antenna systems (FAS) operating in the near-field (NF) regime provide new degrees of freedom (DoF) for physical layer security (PLS). This paper proposes an artificial-noise (AN)-aided PLS scheme for NF fluid-antenna multiple-input multiple-output (FA-MIMO) systems, with joint beamforming (BF) and AN design for both compact and large arrays. An alternating-optimization (AO) framework addresses the sparsity-constrained non-convex design by splitting it into a continuous BF/AN joint-design subproblem and a discrete FAS port-selection subproblem. Closed-form fully digital BF/AN solutions are obtained via a generalized spectral water-filling procedure within a block coordinate descent (BCD) surrogate and realized by a hardware-efficient hybrid beamforming (HBF) architecture that embeds AN in the baseband without extra radio-frequency (RF) chains. For FAS port selection, a row-energy based prune--refit rule, aligned with Karush--Kuhn--Tucker (KKT) conditions of a group-sparsity surrogate, enables efficient active-port determination. Simulation results confirm that the proposed design exploits the geometry and position-domain DoF of FAS and significantly improves secrecy performance, particularly for non-extremely-large arrays where NF beam focusing alone is inadequate.",
          "authors": [
            "Peng Zhang",
            "Jian Dang",
            "Miaowen Wen",
            "Ziyang Liu",
            "Chen Zhao",
            "Huaifeng Shi",
            "Chengsheng Pan",
            "Zaichen Zhang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02461",
          "title": "Artificial Noise Aided Physical Layer Security for Near-Field MIMO with Fluid Antenna Systems",
          "abstract": "With the evolution of wireless systems toward large-scale arrays and high-frequency reconfigurable architectures, fluid antenna systems (FAS) operating in the near-field (NF) regime provide new degrees of freedom (DoF) for physical layer security (PLS). This paper proposes an artificial-noise (AN)-aided PLS scheme for NF fluid-antenna multiple-input multiple-output (FA-MIMO) systems, with joint beamforming (BF) and AN design for both compact and large arrays. An alternating-optimization (AO) framework addresses the sparsity-constrained non-convex design by splitting it into a continuous BF/AN joint-design subproblem and a discrete FAS port-selection subproblem. Closed-form fully digital BF/AN solutions are obtained via a generalized spectral water-filling procedure within a block coordinate descent (BCD) surrogate and realized by a hardware-efficient hybrid beamforming (HBF) architecture that embeds AN in the baseband without extra radio-frequency (RF) chains. For FAS port selection, a row-energy based prune--refit rule, aligned with Karush--Kuhn--Tucker (KKT) conditions of a group-sparsity surrogate, enables efficient active-port determination. Simulation results confirm that the proposed design exploits the geometry and position-domain DoF of FAS and significantly improves secrecy performance, particularly for non-extremely-large arrays where NF beam focusing alone is inadequate.",
          "authors": [
            "Peng Zhang",
            "Jian Dang",
            "Miaowen Wen",
            "Ziyang Liu",
            "Chen Zhao",
            "Huaifeng Shi",
            "Chengsheng Pan",
            "Zaichen Zhang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02462",
          "title": "Bayesian Probability Fusion for Multi-AP Collaborative Sensing in Mobile Networks",
          "abstract": "Integrated sensing and communication is widely acknowledged as a foundational technology for next-generation mobile networks. Compared with monostatic sensing, multi-access point (AP) collaborative sensing endows mobile networks with broader, more accurate, and resilient sensing capabilities, which are critical for diverse location-based sectors. This paper focuses on collaborative sensing in multi-AP networks and proposes a Bayesian probability fusion framework for target parameter estimation using orthogonal frequency-division multiplexing waveform. The framework models multi-AP received signals as probability distributions to capture stochastic observations from channel noise and scattering coefficients. Prior information is then incorporated into the joint probability density function to cast the problem as a constrained maximum a posteriori estimation. To address the high-dimensional optimization, we develop a prior-constrained gradient ascent (PCGA) algorithm that decouples correlated parameters and performs efficient gradient updates guided by the target prior. Theoretical analysis covers optimal fusion weights for global signal-to-noise ratio maximization, PCGA convergence, and the Cramer-Rao lower bound of the estimator, with insights applicable to broader fusion schemes. Extensive numerical simulations and real-world experiments with commercial devices show the framework reduces transmission overhead by 90% versus signal fusion and lowers estimation error by 41% relative to parameter fusion. Notably, field tests achieve submeter accuracy with 50% probability in typical coverage of mmWave APs. These improvements highlight a favorable balance between communication efficiency and estimation accuracy for practical multi-AP sensing deployment. The dataset is released for research purposes and is publicly available at: this http URL",
          "authors": [
            "Shengheng Liu",
            "Xingkang Li",
            "Yongming Huang",
            "Yuan Fang",
            "Qingji Jiang",
            "Dazhuan Xu",
            "Ziguo Zhong",
            "Dongming Wang",
            "Xiaohu You"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02464",
          "title": "Channel Knowledge Map Enabled Low-Altitude ISAC Networks: Joint Air Corridor Planning and Base Station Deployment",
          "abstract": "This letter addresses the joint air corridor planning and base station (BS) deployment problem for low-altitude integrated sensing and communication (ISAC) networks. In the considered system, unmanned aerial vehicles (UAVs) operate within a structured air corridor composed of connected cubic segments, and multiple BSs need to be selectively deployed at a set of candidate locations to ensure both sensing and communication coverage throughout the corridor. In particular, we leverage the channel knowledge map (CKM) to characterize wireless channels for candidate BS sites prior to deployment, thereby facilitating the offline planning. Under this setup, we minimize the system cost in terms of the weighted sum of the air corridor length and the number of deployed BSs, subject to the constraints on both sensing and communication performance across the corridor. To solve the formulated large-scale nonconvex integer programming problem, we develop a hierarchical coarse-to-fine grid decomposition algorithm. Simulation results demonstrate the benefit of the proposed joint design in reducing the overall deployment cost while ensuring the coverage of the low-altitude ISAC networks.",
          "authors": [
            "Jiaxuan Li",
            "Yilong Chen",
            "Fan Liu",
            "Jie Xu"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02501",
          "title": "Cell-free versus Conventional Massive MIMO : An Analysis of Channel Capacity based on Channel Measurement in the FR3 Band",
          "abstract": "Cell-free massive MIMO (CF-mMIMO) has emerged as a promising technology for next generation wireless systems, combining the benefits of distributed antenna systems (DAS) and traditional MIMO technology. In this work, we present the first extensive channel measurements for CF-mMIMO in the mid-band (FR3, 6-24 GHz), using a virtual widely distributed antenna array comprising 512 elements in the urban Macrocell (UMa) environment. Based on the measurement data, this paper compares the channel capacity of CF-mMIMO and Conventional mMIMO under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions across a range of signal-to-noise ratios (SNRs). We then analyze how channel capacity varies with Rx positions from the perspectives of the full array and of individual subarrays. Finally, we conclude that the 64-element array configuration yields the greatest advantage in channel capacity for CF-mMIMO in the measurement environment considered, with gains of 14.02\\% under LOS and 24.61\\% under NLOS conditions. This in-depth analysis of channel capacity in the FR3 band provides critical insights for optimizing CF-mMIMO systems in next generation wireless networks.",
          "authors": [
            "Qi Zhen",
            "Pan Tang",
            "Haiyang Miao",
            "Enrui Liu",
            "Ximan Liu",
            "Zihang Ding",
            "Jianhua Zhang"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02557",
          "title": "Deep Learning-Based Joint Uplink-Downlink CSI Acquisition for Next-Generation Upper Mid-Band Systems",
          "abstract": "In next-generation wireless communication systems, the newly designated upper mid-band has attracted considerable attention, also called frequency range 3 (FR3), highlighting the need for downlink (DL) transmission design, which fundamentally relies on accurate CSI. However, CSI acquisition in FR3 systems faces significant challenges: the increased number of antennas and wider transmission bandwidth introduces prohibitive training overhead with traditional estimation approaches, as each probing captures only incomplete spatial-frequency observation, while higher carrier frequencies lead to faster temporal channel variation. To address these challenges, we propose a novel CSI acquisition framework that integrates CSI feedback, uplink (UL) and DL channel estimation, as well as channel prediction in the FR3 TDD massive MIMO systems. Specifically, we first develop the Joint UL and DL Channel Estimation Network (JUDCEN) to fuse incomplete observations based on the SRSs and CSI-RSs. By exploiting the complementary characteristics of preliminary UL and DL estimation features, obtained through initial UL estimation and quantized-feedback-assisted DL estimation, it enables full CSI reconstruction in the spatial domain. To mitigate the performance degradation in the feedback process, we propose the Transformer-MLP CSI Feedback Network (TMCFN), employing an MLP-based module to jointly exploit angle- and delay-domain features. Building upon the reconstructed full CSI, we further develop the Mamba-based Channel Prediction Network (MCPN), which exploits selective state-space model (SSM) mechanism to capture long-range temporal dynamics in the angle-delay domain for future CSI prediction. Simulation results demonstrate that the proposed framework consistently outperforms benchmarks in both CSI acquisition accuracy and transmission spectral efficiency with lower computational complexity.",
          "authors": [
            "Xuan He",
            "Hongwei Hou",
            "Yafei Wang",
            "Wenjin Wang",
            "Shi Jin",
            "Symeon Chatzinotas",
            "Björn Ottersten"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02563",
          "title": "Predictive Beamforming in Low-Altitude Wireless Networks: A Cross-Attention Approach",
          "abstract": "Accurate beam prediction is essential for maintaining reliable links and high spectral efficiency in dynamic low-altitude wireless networks. However, existing approaches often fail to capture the deep correlations across heterogeneous sensing modalities, limiting their adaptability in complex three-dimensional environments. To overcome these challenges, we propose a multi-modal predictive beamforming method based on a cross-attention fusion mechanism that jointly leverages visual and structured sensor data. The proposed model utilizes a Convolutional Neural Network (CNN) to learn multi-scale spatial feature hierarchies from visual images and a Transformer encoder to capture cross-dimensional dependencies within sensor data. Then, a cross-attention fusion module is introduced to integrate complementary information between the two modalities, generating a unified and discriminative representation for accurate beam prediction. Through experimental evaluations conducted on a real-world dataset, our method reaches 79.7% Top-1 accuracy and 99.3% Top-3 accuracy, surpassing the 3D ResNet-Transformer baseline by 4.4%-23.2% across Top-1 to Top-5 metrics. These results verify that multi-modal cross-attention fusion is effective for intelligent beam selection in dynamic low-altitude wireless networks.",
          "authors": [
            "Xiaotong Zhao",
            "Yuanhao Cui",
            "Weijie Yuan",
            "Ziye Jia",
            "Heng Liu",
            "Chengwen Xing"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02573",
          "title": "Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities",
          "abstract": "In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference.",
          "authors": [
            "Juan Vidal Alegría",
            "Ashkan Sheikhi",
            "Ove Edfors"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02573",
          "title": "Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities",
          "abstract": "In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference.",
          "authors": [
            "Juan Vidal Alegría",
            "Ashkan Sheikhi",
            "Ove Edfors"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02573",
          "title": "Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities",
          "abstract": "In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference.",
          "authors": [
            "Juan Vidal Alegría",
            "Ashkan Sheikhi",
            "Ove Edfors"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02582",
          "title": "Deep Q-Learning-Driven Power Control for Enhanced Noma User Performance",
          "abstract": "Cell-edge users (CEUs) in cellular networks typically suffer from poor channel conditions due to long distances from serving base stations and physical obstructions, resulting in much lower data rates compared to cell-center users (CCUs). This paper proposes an Unmanned Aerial Vehicles (UAV)-assisted cellular network with intelligent power control to address the performance gap between CEUs and CCUs. Unlike conventional approaches that either deploy UAVs for all users or use no UAV assistance, our model uses a distance-based criterion where only users beyond a reference distance receive UAV relay assistance. Each UAV operates as an amplify-and-forward relay, enabling assisted users to receive signals from both the base station and the UAV simultaneously, thereby achieving diversity gain. To optimize transmission power allocation across base stations, we employ a Deep Q-Network (DQN) learning framework that learns power control policies without requiring accurate channel models. Simulation results show that the proposed approach achieves a peak average rate of 2.28 bps/Hz at the optimal reference distance of 400m, which represents a 3.6% improvement compared to networks without UAV assistance and 0.9% improvement compared to networks where all users receive UAV support. The results also reveal that UAV altitude and reference distance are critical factors affecting system performance, with lower altitudes providing better performance.",
          "authors": [
            "Bach Hung Luu",
            "Sinh Cong Lam",
            "Nam Hoang Nguyen"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02582",
          "title": "Deep Q-Learning-Driven Power Control for Enhanced Noma User Performance",
          "abstract": "Cell-edge users (CEUs) in cellular networks typically suffer from poor channel conditions due to long distances from serving base stations and physical obstructions, resulting in much lower data rates compared to cell-center users (CCUs). This paper proposes an Unmanned Aerial Vehicles (UAV)-assisted cellular network with intelligent power control to address the performance gap between CEUs and CCUs. Unlike conventional approaches that either deploy UAVs for all users or use no UAV assistance, our model uses a distance-based criterion where only users beyond a reference distance receive UAV relay assistance. Each UAV operates as an amplify-and-forward relay, enabling assisted users to receive signals from both the base station and the UAV simultaneously, thereby achieving diversity gain. To optimize transmission power allocation across base stations, we employ a Deep Q-Network (DQN) learning framework that learns power control policies without requiring accurate channel models. Simulation results show that the proposed approach achieves a peak average rate of 2.28 bps/Hz at the optimal reference distance of 400m, which represents a 3.6% improvement compared to networks without UAV assistance and 0.9% improvement compared to networks where all users receive UAV support. The results also reveal that UAV altitude and reference distance are critical factors affecting system performance, with lower altitudes providing better performance.",
          "authors": [
            "Bach Hung Luu",
            "Sinh Cong Lam",
            "Nam Hoang Nguyen"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02628",
          "title": "Joint Beamforming and Matching for Ultra-Dense Massive Antenna Arrays",
          "abstract": "Massive multiple-input multiple-output (MIMO) offers substantial spectral-efficiency gains, but scaling to very large antenna arrays with conventional all-digital and hybrid beamforming architectures quickly results in excessively high costs and power consumption. Low-cost, switch-based architectures have recently emerged as a potential alternative. However, prior studies rely on simplified models that ignore (among others) antenna coupling, radiation patterns, and matching losses, resulting in inaccurate performance predictions. In this paper, we use a physically consistent electromagnetic modeling framework to analyze an ultra-dense patch-antenna array architecture that performs joint beamforming and matching using networks of inexpensive RF switches. Our results demonstrate that simple, switch-based beamforming architectures can approach the antenna-gain of all-digital solutions at significantly lower cost and complexity.",
          "authors": [
            "Carolina Nolasco-Ferencikova",
            "Georg Schwan",
            "Raphael Rolny",
            "Alexander Stutz-Tirri",
            "Christoph Studer"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02628",
          "title": "Joint Beamforming and Matching for Ultra-Dense Massive Antenna Arrays",
          "abstract": "Massive multiple-input multiple-output (MIMO) offers substantial spectral-efficiency gains, but scaling to very large antenna arrays with conventional all-digital and hybrid beamforming architectures quickly results in excessively high costs and power consumption. Low-cost, switch-based architectures have recently emerged as a potential alternative. However, prior studies rely on simplified models that ignore (among others) antenna coupling, radiation patterns, and matching losses, resulting in inaccurate performance predictions. In this paper, we use a physically consistent electromagnetic modeling framework to analyze an ultra-dense patch-antenna array architecture that performs joint beamforming and matching using networks of inexpensive RF switches. Our results demonstrate that simple, switch-based beamforming architectures can approach the antenna-gain of all-digital solutions at significantly lower cost and complexity.",
          "authors": [
            "Carolina Nolasco-Ferencikova",
            "Georg Schwan",
            "Raphael Rolny",
            "Alexander Stutz-Tirri",
            "Christoph Studer"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02628",
          "title": "Joint Beamforming and Matching for Ultra-Dense Massive Antenna Arrays",
          "abstract": "Massive multiple-input multiple-output (MIMO) offers substantial spectral-efficiency gains, but scaling to very large antenna arrays with conventional all-digital and hybrid beamforming architectures quickly results in excessively high costs and power consumption. Low-cost, switch-based architectures have recently emerged as a potential alternative. However, prior studies rely on simplified models that ignore (among others) antenna coupling, radiation patterns, and matching losses, resulting in inaccurate performance predictions. In this paper, we use a physically consistent electromagnetic modeling framework to analyze an ultra-dense patch-antenna array architecture that performs joint beamforming and matching using networks of inexpensive RF switches. Our results demonstrate that simple, switch-based beamforming architectures can approach the antenna-gain of all-digital solutions at significantly lower cost and complexity.",
          "authors": [
            "Carolina Nolasco-Ferencikova",
            "Georg Schwan",
            "Raphael Rolny",
            "Alexander Stutz-Tirri",
            "Christoph Studer"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02634",
          "title": "A Communication-Efficient Distributed Optimization Algorithm with Coupled Constraints",
          "abstract": "With the advancement of industrialization and Industry 4.0, the Industrial Internet of Things (IIoT) has emerged as a novel paradigm for information exchange in industrial production environments. To ensure the efficient operation of IIoT, it is imperative to develop communication-efficient methods for transmitting massive production data. This paper designs a communication-efficient distributed optimization algorithm for optimization problems subject to coupled equality constraints. While compressed communication is employed to enhance efficiency, it comes at the cost of introducing compression errors that may impair algorithm performance. To eliminate the influence of compression errors, differential compression techniques along with dynamic scaling factors are incorporated into the algorithm design. Linear convergence and constraint satisfaction of the algorithm are established under different types of compressors. Numerical results further demonstrate its effectiveness across three compression scenarios with specific quantizers.",
          "authors": [
            "Yuzhu Duan",
            "Ziwen Yang",
            "Xiaoming Duan",
            "Shanying Zhu"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02649",
          "title": "Rural Connectivity Inequalities in Finland and Sweden: Evidence, Measures, and Policy Reflections",
          "abstract": "Persistent rural-urban disparities in broadband connectivity remain a major policy challenge, even in digitally advanced countries. This paper examines how these inequalities manifest in northern Finland and Sweden, where sparse populations, long distances, and seasonal variations in demand create persistent gaps in service quality and reliability. Drawing on survey data (n = 148), in-depth interviews, and spatial analysis, the study explores the lived experience of connectivity in Arctic rural communities and introduces a novel Cellular Coverage Inequality (CCI) Index. The index combines measures of rurality and network performance to quantify spatial disparities that are masked by national coverage statistics. Results reveal that headline indicators overstate inclusiveness, while local users report chronic connectivity gaps affecting work, safety, and access to services. Building on these findings, the paper outlines policy reflections in six areas: shared infrastructure and roaming frameworks, spectrum flexibility for rural operators, performance-based Quality-of-Service monitoring, standardized and transparent reporting, temporal and seasonal capacity management, and digital-skills initiatives. Together, these recommendations highlight the need for multidimensional metrics and governance mechanisms that link technical performance, spatial equity, and user experience. The analysis contributes to ongoing debates on how broadband policy in sparsely populated regions can move beyond nominal coverage targets toward genuine inclusion and reliability.",
          "authors": [
            "Sameera Bandaranayake",
            "Amirreza Moradi",
            "Tanja Suomalainen",
            "Harri Saarnisaari",
            "Pasi Karppinen",
            "Payal Gupta",
            "Jaap van de Beek"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02663",
          "title": "Theoretical analysis of beaconless geocast protocols in 1D",
          "abstract": "Beaconless geocast protocols are routing protocols used to send messages in mobile ad-hoc wireless networks, in which the only information available to each node is its own location. Messages get routed in a distributed manner: each node uses local decision rules based on the message source and destination, and its own location. In this paper we analyze six different beaconless geocast protocols, focusing on two relevant 1D scenarios. The selection of protocols reflects the most relevant types of protocols proposed in the literature, including those evaluated in previous computer simulations. We present a formal and structured analysis of the maximum number of messages that a node can receive, for each protocol, in each of the two scenarios. This is a measure of the network load incurred by each protocol. Our analysis, that for some of the protocols requires an involved probabilistic analysis, confirms behaviors that had been observed only through simulations before.",
          "authors": [
            "Joachim Gudmundsson",
            "Irina Kostitsyna",
            "Maarten Löffler",
            "Tobias Müller",
            "Vera Sacristán",
            "Rodrigo I. Silveira"
          ],
          "primary_category": "cs.CG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02683",
          "title": "Distributed and Autonomic Minimum Spanning Trees",
          "abstract": "The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.",
          "authors": [
            "Luiz A. Rodrigues",
            "Elias P. Duarte Jr.",
            "Luciana Arantes"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02757",
          "title": "Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations",
          "abstract": "The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.",
          "authors": [
            "Yunzhe Zhu",
            "Xuewen Liao",
            "Zhenzhen Gao",
            "Yong Zeng"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02843",
          "title": "ISAC-Powered Distributed Matching and Resource Allocation in Multi-band NTN",
          "abstract": "Scalability is a major challenge in non-geostationary orbit (NGSO) satellite networks due to the massive number of ground users sharing the limited sub-6 GHz spectrum. Using K- and higher bands is a promising alternative to increase the accessible bandwidth, but these bands are subject to significant atmospheric attenuation, notably rainfall, which can lead to degraded performance and link outages. We present an integrated sensing and communications (ISAC)-powered framework for resilient and efficient operation of multi-band satellite networks. It is based on distributed mechanisms for atmospheric sensing, cell-to-satellite matching, and resource allocation (RA) in a 5G Non-Terrestrial Network (NTN) wide-area scenario with quasi-Earth fixed cells and a beam hopping mechanism. Results with a multi-layer multi-band constellation with satellites operating in the S- and K-bands demonstrate the benefits of our framework for ISAC-powered multi-band systems, which achieves 73% higher throughput per user when compared to single S- and K-band systems.",
          "authors": [
            "Israel Leyva-Mayorga",
            "Shashi Raj Pandey",
            "Petar Popovski",
            "Fabio Saggese",
            "Beatriz Soret",
            "Cedomir Stefanovic"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02913",
          "title": "On the Performance of Multi-Wavelength Underwater Optical Channels in the Presence of Optical Turbulence",
          "abstract": "This paper presents an analysis of the performance of a Gaussian optical beam as it propagates through the turbulent underwater optical channel (UWOC) under the weak turbulence regime, where optical signal experiences significant fading and scattering, all of which can severely degrade communication quality. It is assumed that on-off keying (OOK) modulation with direct detection is utilized to establish a duplex communication link. A multi-wavelength beam approach is implemented to enhance the performance by leveraging the distinct propagation characteristics of different wavelengths. Performance is established in terms of the probability of fade, number of fade per second, mean fade duration, and mean time between fades. The use of multi-wavelength beam is shown to enhance performance by a sizable margin.",
          "authors": [
            "Shideh Tayebnaimi",
            "Kamran Kiasaleh"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02994",
          "title": "GNSS Array-Based Multipath Detection Employing UKF on Manifolds",
          "abstract": "Global Navigation Satellite Systems (GNSS) applications are often hindered by various sources of error, with multipath interference being one of the most challenging, particularly in urban environments. In this work, we build on previous research by implementing a GNSS array-based multipath detection algorithm, incorporating real-time attitude estimation for dynamic scenarios. The method fuses GNSS and IMU data using an Unscented Kalman Filter (UKF) on a manifold, enabling continuous attitude tracking. The proposed approach utilizes attitude information from satellite combinations to identify and exclude multipath-affected satellites, improving the accuracy of both positioning and attitude determination. To address computational challenges associated with evaluating large numbers of satellite combinations, we propose the use of the Random Sample Consensus (RANSAC) algorithm, which reduces the number of combinations assessed while maintaining high detection performance. Performance evaluations are conducted using trajectories and IMU readings from the KITTI dataset. GNSS observations are simulated based on ground truth positions and satellite ephemeris. The results demonstrate the effectiveness of the proposed approach in detecting satellites affected by multipath interference. Significant improvements in positioning accuracy are observed, particularly in scenarios where a large portion of the visible satellites are contaminated by severe multipath.",
          "authors": [
            "Abdelgabar Ahmed",
            "Tarig Ballal",
            "Xing Liu",
            "Mohanad Ahmed",
            "Tareq Y. Al-Naffouri"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02994",
          "title": "GNSS Array-Based Multipath Detection Employing UKF on Manifolds",
          "abstract": "Global Navigation Satellite Systems (GNSS) applications are often hindered by various sources of error, with multipath interference being one of the most challenging, particularly in urban environments. In this work, we build on previous research by implementing a GNSS array-based multipath detection algorithm, incorporating real-time attitude estimation for dynamic scenarios. The method fuses GNSS and IMU data using an Unscented Kalman Filter (UKF) on a manifold, enabling continuous attitude tracking. The proposed approach utilizes attitude information from satellite combinations to identify and exclude multipath-affected satellites, improving the accuracy of both positioning and attitude determination. To address computational challenges associated with evaluating large numbers of satellite combinations, we propose the use of the Random Sample Consensus (RANSAC) algorithm, which reduces the number of combinations assessed while maintaining high detection performance. Performance evaluations are conducted using trajectories and IMU readings from the KITTI dataset. GNSS observations are simulated based on ground truth positions and satellite ephemeris. The results demonstrate the effectiveness of the proposed approach in detecting satellites affected by multipath interference. Significant improvements in positioning accuracy are observed, particularly in scenarios where a large portion of the visible satellites are contaminated by severe multipath.",
          "authors": [
            "Abdelgabar Ahmed",
            "Tarig Ballal",
            "Xing Liu",
            "Mohanad Ahmed",
            "Tareq Y. Al-Naffouri"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 3,
      "size": 8,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2410.23574",
          "title": "Online Convex Optimization with Memory and Limited Predictions",
          "abstract": "This paper addresses an online convex optimization problem where the cost function at each step depends on a history of past decisions (i.e., memory), and the decision maker has access to limited predictions of future cost values within a finite window. The goal is to design an algorithm that minimizes the dynamic regret against the optimal sequence of decisions in hindsight. To this end, we propose a novel predictive algorithm and establish strong theoretical guarantees for its performance. We show that the algorithm's dynamic regret decays exponentially with the length of the prediction window. Our algorithm comprises two general subroutines of independent interest. The first subroutine solves online convex optimization with memory and bandit feedback, achieving a $\\sqrt{TV_T}$-dynamic regret, where $V_T$ measures the variation of the optimal decision sequence. The second is a zeroth-order method that attains a linear convergence rate for general convex optimization, matching the best achievable rate of first-order methods. The key to our algorithm is a novel truncated Gaussian smoothing technique when querying the decision points to obtain the predictions. We validate our theoretical results with numerical experiments.",
          "primary_category": "math.OC",
          "authors": [
            "Zhengmiao Wang",
            "Zhi-Wei Liu",
            "Ming Chi",
            "Xiaoling Wang",
            "Housheng Su",
            "Lintao Ye"
          ]
        },
        {
          "id": "arXiv:2501.18183",
          "title": "Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization",
          "abstract": "We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of $O(T^{\\theta})$ and number of linear optimization oracle calls of $O(T^{2\\theta})$ for decentralized upper-linearizable function optimization, for any $0\\le \\theta \\le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.",
          "primary_category": "math.OC",
          "authors": [
            "Yiyang Lu",
            "Mohammad Pedramfar",
            "Vaneet Aggarwal"
          ]
        },
        {
          "id": "arXiv:2501.18183",
          "title": "Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization",
          "abstract": "We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of $O(T^{\\theta})$ and number of linear optimization oracle calls of $O(T^{2\\theta})$ for decentralized upper-linearizable function optimization, for any $0\\le \\theta \\le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.",
          "primary_category": "math.OC",
          "authors": [
            "Yiyang Lu",
            "Mohammad Pedramfar",
            "Vaneet Aggarwal"
          ]
        },
        {
          "id": "arXiv:2501.18183",
          "title": "Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization",
          "abstract": "We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of $O(T^{\\theta})$ and number of linear optimization oracle calls of $O(T^{2\\theta})$ for decentralized upper-linearizable function optimization, for any $0\\le \\theta \\le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.",
          "primary_category": "math.OC",
          "authors": [
            "Yiyang Lu",
            "Mohammad Pedramfar",
            "Vaneet Aggarwal"
          ]
        },
        {
          "id": "arXiv:2512.02494",
          "title": "A Fully First-Order Layer for Differentiable Optimization",
          "abstract": "Differentiable optimization layers enable learning systems to make decisions by solving embedded optimization problems. However, computing gradients via implicit differentiation requires solving a linear system with Hessian terms, which is both compute- and memory-intensive. To address this challenge, we propose a novel algorithm that computes the gradient using only first-order information. The key insight is to rewrite the differentiable optimization as a bilevel optimization problem and leverage recent advances in bilevel methods. Specifically, we introduce an active-set Lagrangian hypergradient oracle that avoids Hessian evaluations and provides finite-time, non-asymptotic approximation guarantees. We show that an approximate hypergradient can be computed using only first-order information in $\\tilde{\\oo}(1)$ time, leading to an overall complexity of $\\tilde{\\oo}(\\delta^{-1}\\epsilon^{-3})$ for constrained bilevel optimization, which matches the best known rate for non-smooth non-convex optimization. Furthermore, we release an open-source Python library that can be easily adapted from existing solvers. Our code is available here: this https URL .",
          "primary_category": "cs.LG",
          "authors": [
            "Zihao Zhao",
            "Kai-Chia Mo",
            "Shing-Hei Ho",
            "Brandon Amos",
            "Kai Wang"
          ]
        },
        {
          "id": "arXiv:2510.15734",
          "title": "Optimization in Theory and Practice",
          "abstract": "Algorithms for continuous optimization problems have a rich history of design and innovation over the past several decades, in which mathematical analysis of their convergence and complexity properties plays a central role. Besides their theoretical properties, optimization algorithms are interesting also for their practical usefulness as computational tools for solving real-world problems. There are often gaps between the practical performance of an algorithm and what can be proved about it. These two facets of the field -- the theoretical and the practical -- interact in fascinating ways, each driving innovation in the other. This work focuses on the development of algorithms in two areas -- linear programming and unconstrained minimization of smooth functions -- outlining major algorithm classes in each area along with their theoretical properties and practical performance, and highlighting how advances in theory and practice have influenced each other in these areas. In discussing theory, we focus mainly on non-asymptotic complexity, which are upper bounds on the amount of computation required by a given algorithm to find an approximate solution of problems in a given class.",
          "primary_category": "math.OC",
          "authors": [
            "Stephen J. Wright"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2410.23574",
          "title": "Online Convex Optimization with Memory and Limited Predictions",
          "abstract": "This paper addresses an online convex optimization problem where the cost function at each step depends on a history of past decisions (i.e., memory), and the decision maker has access to limited predictions of future cost values within a finite window. The goal is to design an algorithm that minimizes the dynamic regret against the optimal sequence of decisions in hindsight. To this end, we propose a novel predictive algorithm and establish strong theoretical guarantees for its performance. We show that the algorithm's dynamic regret decays exponentially with the length of the prediction window. Our algorithm comprises two general subroutines of independent interest. The first subroutine solves online convex optimization with memory and bandit feedback, achieving a $\\sqrt{TV_T}$-dynamic regret, where $V_T$ measures the variation of the optimal decision sequence. The second is a zeroth-order method that attains a linear convergence rate for general convex optimization, matching the best achievable rate of first-order methods. The key to our algorithm is a novel truncated Gaussian smoothing technique when querying the decision points to obtain the predictions. We validate our theoretical results with numerical experiments.",
          "authors": [
            "Zhengmiao Wang",
            "Zhi-Wei Liu",
            "Ming Chi",
            "Xiaoling Wang",
            "Housheng Su",
            "Lintao Ye"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.23574",
          "title": "Online Convex Optimization with Memory and Limited Predictions",
          "abstract": "This paper addresses an online convex optimization problem where the cost function at each step depends on a history of past decisions (i.e., memory), and the decision maker has access to limited predictions of future cost values within a finite window. The goal is to design an algorithm that minimizes the dynamic regret against the optimal sequence of decisions in hindsight. To this end, we propose a novel predictive algorithm and establish strong theoretical guarantees for its performance. We show that the algorithm's dynamic regret decays exponentially with the length of the prediction window. Our algorithm comprises two general subroutines of independent interest. The first subroutine solves online convex optimization with memory and bandit feedback, achieving a $\\sqrt{TV_T}$-dynamic regret, where $V_T$ measures the variation of the optimal decision sequence. The second is a zeroth-order method that attains a linear convergence rate for general convex optimization, matching the best achievable rate of first-order methods. The key to our algorithm is a novel truncated Gaussian smoothing technique when querying the decision points to obtain the predictions. We validate our theoretical results with numerical experiments.",
          "authors": [
            "Zhengmiao Wang",
            "Zhi-Wei Liu",
            "Ming Chi",
            "Xiaoling Wang",
            "Housheng Su",
            "Lintao Ye"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.18183",
          "title": "Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization",
          "abstract": "We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of $O(T^{\\theta})$ and number of linear optimization oracle calls of $O(T^{2\\theta})$ for decentralized upper-linearizable function optimization, for any $0\\le \\theta \\le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.",
          "authors": [
            "Yiyang Lu",
            "Mohammad Pedramfar",
            "Vaneet Aggarwal"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.18183",
          "title": "Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization",
          "abstract": "We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of $O(T^{\\theta})$ and number of linear optimization oracle calls of $O(T^{2\\theta})$ for decentralized upper-linearizable function optimization, for any $0\\le \\theta \\le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.",
          "authors": [
            "Yiyang Lu",
            "Mohammad Pedramfar",
            "Vaneet Aggarwal"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.18183",
          "title": "Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization",
          "abstract": "We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\\theta/2})$ with communication complexity of $O(T^{\\theta})$ and number of linear optimization oracle calls of $O(T^{2\\theta})$ for decentralized upper-linearizable function optimization, for any $0\\le \\theta \\le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.",
          "authors": [
            "Yiyang Lu",
            "Mohammad Pedramfar",
            "Vaneet Aggarwal"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.15734",
          "title": "Optimization in Theory and Practice",
          "abstract": "Algorithms for continuous optimization problems have a rich history of design and innovation over the past several decades, in which mathematical analysis of their convergence and complexity properties plays a central role. Besides their theoretical properties, optimization algorithms are interesting also for their practical usefulness as computational tools for solving real-world problems. There are often gaps between the practical performance of an algorithm and what can be proved about it. These two facets of the field -- the theoretical and the practical -- interact in fascinating ways, each driving innovation in the other. This work focuses on the development of algorithms in two areas -- linear programming and unconstrained minimization of smooth functions -- outlining major algorithm classes in each area along with their theoretical properties and practical performance, and highlighting how advances in theory and practice have influenced each other in these areas. In discussing theory, we focus mainly on non-asymptotic complexity, which are upper bounds on the amount of computation required by a given algorithm to find an approximate solution of problems in a given class.",
          "authors": [
            "Stephen J. Wright"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.15734",
          "title": "Optimization in Theory and Practice",
          "abstract": "Algorithms for continuous optimization problems have a rich history of design and innovation over the past several decades, in which mathematical analysis of their convergence and complexity properties plays a central role. Besides their theoretical properties, optimization algorithms are interesting also for their practical usefulness as computational tools for solving real-world problems. There are often gaps between the practical performance of an algorithm and what can be proved about it. These two facets of the field -- the theoretical and the practical -- interact in fascinating ways, each driving innovation in the other. This work focuses on the development of algorithms in two areas -- linear programming and unconstrained minimization of smooth functions -- outlining major algorithm classes in each area along with their theoretical properties and practical performance, and highlighting how advances in theory and practice have influenced each other in these areas. In discussing theory, we focus mainly on non-asymptotic complexity, which are upper bounds on the amount of computation required by a given algorithm to find an approximate solution of problems in a given class.",
          "authors": [
            "Stephen J. Wright"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02494",
          "title": "A Fully First-Order Layer for Differentiable Optimization",
          "abstract": "Differentiable optimization layers enable learning systems to make decisions by solving embedded optimization problems. However, computing gradients via implicit differentiation requires solving a linear system with Hessian terms, which is both compute- and memory-intensive. To address this challenge, we propose a novel algorithm that computes the gradient using only first-order information. The key insight is to rewrite the differentiable optimization as a bilevel optimization problem and leverage recent advances in bilevel methods. Specifically, we introduce an active-set Lagrangian hypergradient oracle that avoids Hessian evaluations and provides finite-time, non-asymptotic approximation guarantees. We show that an approximate hypergradient can be computed using only first-order information in $\\tilde{\\oo}(1)$ time, leading to an overall complexity of $\\tilde{\\oo}(\\delta^{-1}\\epsilon^{-3})$ for constrained bilevel optimization, which matches the best known rate for non-smooth non-convex optimization. Furthermore, we release an open-source Python library that can be easily adapted from existing solvers. Our code is available here: this https URL .",
          "authors": [
            "Zihao Zhao",
            "Kai-Chia Mo",
            "Shing-Hei Ho",
            "Brandon Amos",
            "Kai Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 4,
      "size": 72,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2307.16178",
          "title": "Quick Updates for the Perturbed Static Output Feedback Control Problem in Linear Systems with Applications to Power Systems",
          "abstract": "This paper introduces a method for efficiently updating a nominal stabilizing static output feedback (SOF) controller in perturbed linear systems. As operating points and state-space matrices change in dynamic systems, accommodating updates to the SOF controller are necessary. Traditional methods address such changes by re-solving for the updated SOF gain, which is often (i) computationally expensive due to the NP-hard nature of the problem or (ii) infeasible due to the limitations of its semidefinite programming relaxations. To overcome this, we leverage the concept of minimum destabilizing real perturbation (MDRP) to formulate a norm minimization problem that yields fast, reliable controller updates. This approach accommodates a variety of known perturbations, including abrupt changes, model inaccuracies, and equilibrium-dependent linearizations. We remark that the application of our proposed approach is limited to the class of SOF controllers in perturbed linear systems. We also introduce geometric metrics to quantify the proximity to instability and rigorously define stability-guaranteed regions. Extensive numerical simulations validate the efficiency and robustness of the proposed method. Moreover, such extensive numerical simulations corroborate that although we utilize a heuristic optimization method to compute the MDRP, it performs quite well in practice compared to an existing approximation method in the literature, namely the hybrid expansion-contraction (HEC) method. We demonstrate the results on the SOF control of multi-machine power networks with changing operating points, and demonstrate that the computed quick updates produce comparable solutions to the traditional SOF ones, while requiring orders of magnitude less computational time.",
          "primary_category": "eess.SY",
          "authors": [
            "MirSaleh Bahavarnia",
            "Ahmad F. Taha"
          ]
        },
        {
          "id": "arXiv:2512.02452",
          "title": "Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems",
          "abstract": "As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.",
          "primary_category": "eess.SY",
          "authors": [
            "Tianyou Xiang",
            "Cheng Zhao"
          ]
        },
        {
          "id": "arXiv:2512.02452",
          "title": "Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems",
          "abstract": "As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.",
          "primary_category": "eess.SY",
          "authors": [
            "Tianyou Xiang",
            "Cheng Zhao"
          ]
        },
        {
          "id": "arXiv:2512.02406",
          "title": "Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning",
          "abstract": "With increased travelling needs more than ever, traffic congestion has become a major concern in most urban areas. Allocating spaces for on-street parking, further hinders traffic flow, by limiting the effective road width available for driving. With the advancement of vehicle-to-infrastructure connectivity technologies, we explore how the impact of on-street parking on traffic congestion could be minimized, by dynamically configuring on-street parking spaces. Towards that end, we formulate dynamic on-street parking space configuration as an optimization problem, and we follow a data driven approach, considering the nature of our problem. Our proposed solution comprises a two-layer multi agent reinforcement learning based framework, which is inherently scalable to large road networks. The lane level agents are responsible for deciding the optimal parking space configuration for each lane, and we introduce a novel Deep Q-learning architecture which effectively utilizes long short term memory networks and graph attention networks to capture the spatio-temporal correlations evident in the given problem. The block level agents control the actions of the lane level agents and maintain a sufficient level of parking around the block. We conduct a set of comprehensive experiments using SUMO, on both synthetic data as well as real-world data from the city of Melbourne. Our experiments show that the proposed framework could reduce the average travel time loss of vehicles significantly, reaching upto 47%, with a negligible increase in the walking distance for parking.",
          "primary_category": "cs.LG",
          "authors": [
            "Oshada Jayasinghe",
            "Farhana Choudhury",
            "Egemen Tanin",
            "Shanika Karunasekera"
          ]
        },
        {
          "id": "arXiv:2512.02386",
          "title": "Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection",
          "abstract": "This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \\textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.",
          "primary_category": "cs.LG",
          "authors": [
            "Chuhan Xie"
          ]
        },
        {
          "id": "arXiv:2512.02386",
          "title": "Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection",
          "abstract": "This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \\textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.",
          "primary_category": "cs.LG",
          "authors": [
            "Chuhan Xie"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2307.16178",
          "title": "Quick Updates for the Perturbed Static Output Feedback Control Problem in Linear Systems with Applications to Power Systems",
          "abstract": "This paper introduces a method for efficiently updating a nominal stabilizing static output feedback (SOF) controller in perturbed linear systems. As operating points and state-space matrices change in dynamic systems, accommodating updates to the SOF controller are necessary. Traditional methods address such changes by re-solving for the updated SOF gain, which is often (i) computationally expensive due to the NP-hard nature of the problem or (ii) infeasible due to the limitations of its semidefinite programming relaxations. To overcome this, we leverage the concept of minimum destabilizing real perturbation (MDRP) to formulate a norm minimization problem that yields fast, reliable controller updates. This approach accommodates a variety of known perturbations, including abrupt changes, model inaccuracies, and equilibrium-dependent linearizations. We remark that the application of our proposed approach is limited to the class of SOF controllers in perturbed linear systems. We also introduce geometric metrics to quantify the proximity to instability and rigorously define stability-guaranteed regions. Extensive numerical simulations validate the efficiency and robustness of the proposed method. Moreover, such extensive numerical simulations corroborate that although we utilize a heuristic optimization method to compute the MDRP, it performs quite well in practice compared to an existing approximation method in the literature, namely the hybrid expansion-contraction (HEC) method. We demonstrate the results on the SOF control of multi-machine power networks with changing operating points, and demonstrate that the computed quick updates produce comparable solutions to the traditional SOF ones, while requiring orders of magnitude less computational time.",
          "authors": [
            "MirSaleh Bahavarnia",
            "Ahmad F. Taha"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2307.16178",
          "title": "Quick Updates for the Perturbed Static Output Feedback Control Problem in Linear Systems with Applications to Power Systems",
          "abstract": "This paper introduces a method for efficiently updating a nominal stabilizing static output feedback (SOF) controller in perturbed linear systems. As operating points and state-space matrices change in dynamic systems, accommodating updates to the SOF controller are necessary. Traditional methods address such changes by re-solving for the updated SOF gain, which is often (i) computationally expensive due to the NP-hard nature of the problem or (ii) infeasible due to the limitations of its semidefinite programming relaxations. To overcome this, we leverage the concept of minimum destabilizing real perturbation (MDRP) to formulate a norm minimization problem that yields fast, reliable controller updates. This approach accommodates a variety of known perturbations, including abrupt changes, model inaccuracies, and equilibrium-dependent linearizations. We remark that the application of our proposed approach is limited to the class of SOF controllers in perturbed linear systems. We also introduce geometric metrics to quantify the proximity to instability and rigorously define stability-guaranteed regions. Extensive numerical simulations validate the efficiency and robustness of the proposed method. Moreover, such extensive numerical simulations corroborate that although we utilize a heuristic optimization method to compute the MDRP, it performs quite well in practice compared to an existing approximation method in the literature, namely the hybrid expansion-contraction (HEC) method. We demonstrate the results on the SOF control of multi-machine power networks with changing operating points, and demonstrate that the computed quick updates produce comparable solutions to the traditional SOF ones, while requiring orders of magnitude less computational time.",
          "authors": [
            "MirSaleh Bahavarnia",
            "Ahmad F. Taha"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2307.16178",
          "title": "Quick Updates for the Perturbed Static Output Feedback Control Problem in Linear Systems with Applications to Power Systems",
          "abstract": "This paper introduces a method for efficiently updating a nominal stabilizing static output feedback (SOF) controller in perturbed linear systems. As operating points and state-space matrices change in dynamic systems, accommodating updates to the SOF controller are necessary. Traditional methods address such changes by re-solving for the updated SOF gain, which is often (i) computationally expensive due to the NP-hard nature of the problem or (ii) infeasible due to the limitations of its semidefinite programming relaxations. To overcome this, we leverage the concept of minimum destabilizing real perturbation (MDRP) to formulate a norm minimization problem that yields fast, reliable controller updates. This approach accommodates a variety of known perturbations, including abrupt changes, model inaccuracies, and equilibrium-dependent linearizations. We remark that the application of our proposed approach is limited to the class of SOF controllers in perturbed linear systems. We also introduce geometric metrics to quantify the proximity to instability and rigorously define stability-guaranteed regions. Extensive numerical simulations validate the efficiency and robustness of the proposed method. Moreover, such extensive numerical simulations corroborate that although we utilize a heuristic optimization method to compute the MDRP, it performs quite well in practice compared to an existing approximation method in the literature, namely the hybrid expansion-contraction (HEC) method. We demonstrate the results on the SOF control of multi-machine power networks with changing operating points, and demonstrate that the computed quick updates produce comparable solutions to the traditional SOF ones, while requiring orders of magnitude less computational time.",
          "authors": [
            "MirSaleh Bahavarnia",
            "Ahmad F. Taha"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.10767",
          "title": "Ergodic-risk Criterion for Stochastically Stabilizing Policy Optimization",
          "abstract": "This paper introduces ergodic-risk criteria, which capture long-term cumulative risks associated with controlled Markov chains through probabilistic limit theorems--in contrast to existing methods that require assumptions of either finite hitting time, finite state/action space, or exponentiation necessitating light-tailed distributions. Using tailored Functional Central Limit Theorems (FCLT), we demonstrate that the time-correlated terms in the ergodic-risk criteria converge under uniform ergodicity and establish conditions for the convergence of these criteria in non-stationary general-state Markov chains involving heavy-tailed distributions. For quadratic risk functionals on stochastic linear systems, in addition to internal stability, this requires the (possibly heavy-tailed) process noise to have only a finite fourth moment. After quantifying cumulative uncertainties in risk functionals that account for extreme deviations, these ergodic-risk criteria are then incorporated into policy optimizations, thereby extending the standard average optimal synthesis to a risk-sensitive framework. Finally, by establishing the strong duality of the constrained policy optimization, we propose a primal-dual algorithm that optimizes average performance while ensuring that certain risks associated with these ergodic-risk criteria are constrained. Our risk-sensitive framework offers a theoretically guaranteed policy iteration for the long-term risk-sensitive control of processes involving heavy-tailed noise, which is shown to be effective through several simulations.",
          "authors": [
            "Shahriar Talebi",
            "Na Li"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.10767",
          "title": "Ergodic-risk Criterion for Stochastically Stabilizing Policy Optimization",
          "abstract": "This paper introduces ergodic-risk criteria, which capture long-term cumulative risks associated with controlled Markov chains through probabilistic limit theorems--in contrast to existing methods that require assumptions of either finite hitting time, finite state/action space, or exponentiation necessitating light-tailed distributions. Using tailored Functional Central Limit Theorems (FCLT), we demonstrate that the time-correlated terms in the ergodic-risk criteria converge under uniform ergodicity and establish conditions for the convergence of these criteria in non-stationary general-state Markov chains involving heavy-tailed distributions. For quadratic risk functionals on stochastic linear systems, in addition to internal stability, this requires the (possibly heavy-tailed) process noise to have only a finite fourth moment. After quantifying cumulative uncertainties in risk functionals that account for extreme deviations, these ergodic-risk criteria are then incorporated into policy optimizations, thereby extending the standard average optimal synthesis to a risk-sensitive framework. Finally, by establishing the strong duality of the constrained policy optimization, we propose a primal-dual algorithm that optimizes average performance while ensuring that certain risks associated with these ergodic-risk criteria are constrained. Our risk-sensitive framework offers a theoretically guaranteed policy iteration for the long-term risk-sensitive control of processes involving heavy-tailed noise, which is shown to be effective through several simulations.",
          "authors": [
            "Shahriar Talebi",
            "Na Li"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.10767",
          "title": "Ergodic-risk Criterion for Stochastically Stabilizing Policy Optimization",
          "abstract": "This paper introduces ergodic-risk criteria, which capture long-term cumulative risks associated with controlled Markov chains through probabilistic limit theorems--in contrast to existing methods that require assumptions of either finite hitting time, finite state/action space, or exponentiation necessitating light-tailed distributions. Using tailored Functional Central Limit Theorems (FCLT), we demonstrate that the time-correlated terms in the ergodic-risk criteria converge under uniform ergodicity and establish conditions for the convergence of these criteria in non-stationary general-state Markov chains involving heavy-tailed distributions. For quadratic risk functionals on stochastic linear systems, in addition to internal stability, this requires the (possibly heavy-tailed) process noise to have only a finite fourth moment. After quantifying cumulative uncertainties in risk functionals that account for extreme deviations, these ergodic-risk criteria are then incorporated into policy optimizations, thereby extending the standard average optimal synthesis to a risk-sensitive framework. Finally, by establishing the strong duality of the constrained policy optimization, we propose a primal-dual algorithm that optimizes average performance while ensuring that certain risks associated with these ergodic-risk criteria are constrained. Our risk-sensitive framework offers a theoretically guaranteed policy iteration for the long-term risk-sensitive control of processes involving heavy-tailed noise, which is shown to be effective through several simulations.",
          "authors": [
            "Shahriar Talebi",
            "Na Li"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.03898",
          "title": "Feedback stabilization for a spatial-dependent Sterile Insect Technique model with Allee Effect",
          "abstract": "This work focuses on feedback control strategies for applying the sterile insect technique (SIT) to eliminate pest populations. The presentation is centered on the case of mosquito populations, but most of the results can be extended to other species by adapting the model and selecting appropriate parameter values to describe the reproduction and movement dynamics of the species under consideration. In our study, we address the spatial distribution of the population in a two dimensional bounded domain by extending the temporal SIT model analyzed in [2], thereby obtaining a reaction-diffusion SIT model. After the analysis of the existence and the uniqueness of the solution of this problem, we construct a feedback law that globally asymptotically stabilizes the extinction equilibrium thus yielding a robust strategy to keep the pest population at very low levels in the long term.",
          "authors": [
            "Kala Agbo Bidi",
            "Luís Almeida",
            "Jean-Michel Coron"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.20922",
          "title": "Space science & the space economy",
          "abstract": "Will it be possible in the future to realize large, complex space missions dedicated to basic science like HST, Chandra and JWST? Or will their cost be too great? Today's space scene is completely different from that of even five years ago, and certainly from that of the time when HST, Chandra and JWST were conceived and built. Space-related investments have grown exponentially in recent years, with a monetary investment exceeding half a trillion dollars per year since 2023. This boom is greatly aided by the rise of the so-called 'new space' economy driven by private commercial funding, which for the first time last year surpassed public investments in space. The establishment of a market logic to space activities results in more competition and a resulting dramatic cost and schedule reduction. Can space science take advantage of the benefits of the new space economy to reduce cost and development time and at the same time succeed in producing powerful missions in basic science? The prospects for Europe and the United States are considered here. We argue that this goal would be achievable if the scientific community could take advantage of the three pillars underlying the innovation of the new space economy: (1) technology innovation proceeding through both incremental innovation and disruptive innovation, (2) business innovation, through vertical integration, scale production, and service-oriented business model, and (3) cultural innovation, through openness to risk and iterative development.",
          "authors": [
            "F. Fiore",
            "M. Elvis"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.01638",
          "title": "Convex Computations for Controlled Safety Invariant Sets of Black-box Discrete-time Dynamical Systems",
          "abstract": "Identifying controlled safety invariant sets (CSISs) is essential for safety-critical systems. This paper addresses the problem of computing CSISs for black-box discrete-time systems, where the dynamics are unknown and only limited simulation data are available. Traditionally, a CSIS requires that for every state in the set, there exists a control input that keeps the system within the set at the next step. However, enforcing such universal invariance, i.e., requiring the set to remain controlled invariant for all states, is often overly restrictive or impractical for black-box systems. To address this, we introduce the notion of a Probably Approximately Correct (PAC) CSIS, in which, with prescribed confidence, there exists a suitable control input to keep the system within the set at the next step for at least a specified fraction of the states. Our approach leverages barrier functions and scenario optimization, yielding a tractable linear programming method for estimating PAC CSISs. Several illustrative examples demonstrate the effectiveness of the proposed framework.",
          "authors": [
            "Taoran Wu",
            "Yiling Xue",
            "Jingduo Pan",
            "Dejin Ren",
            "Arvind Easwaran",
            "Bai Xue"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.01638",
          "title": "Convex Computations for Controlled Safety Invariant Sets of Black-box Discrete-time Dynamical Systems",
          "abstract": "Identifying controlled safety invariant sets (CSISs) is essential for safety-critical systems. This paper addresses the problem of computing CSISs for black-box discrete-time systems, where the dynamics are unknown and only limited simulation data are available. Traditionally, a CSIS requires that for every state in the set, there exists a control input that keeps the system within the set at the next step. However, enforcing such universal invariance, i.e., requiring the set to remain controlled invariant for all states, is often overly restrictive or impractical for black-box systems. To address this, we introduce the notion of a Probably Approximately Correct (PAC) CSIS, in which, with prescribed confidence, there exists a suitable control input to keep the system within the set at the next step for at least a specified fraction of the states. Our approach leverages barrier functions and scenario optimization, yielding a tractable linear programming method for estimating PAC CSISs. Several illustrative examples demonstrate the effectiveness of the proposed framework.",
          "authors": [
            "Taoran Wu",
            "Yiling Xue",
            "Jingduo Pan",
            "Dejin Ren",
            "Arvind Easwaran",
            "Bai Xue"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.15954",
          "title": "A Switched Systems Approach to Image-Based Feature Tracking for Autonomous Satellite Inspection",
          "abstract": "This paper presents an information-based guidance and control architecture for an autonomous deputy spacecraft tasked with inspecting a chief satellite in orbit. The primary objective is for the deputy spacecraft to maximize information gain while tracking features on the chief satellite. The deputy spacecraft needs to respect various constraints such as illumination, field-of-view (FOV), fuel limitations, and avoidance regions. Additionally, the absence of GPS information poses a significant challenge for relative localization within the space environment. To learn the structure of the chief satellite while achieving relative self-localization and maximizing the information gain, this paper integrates a memory regression extension (MRE)-based distance observer with an information-maximizing adaptive controller. The distance observer utilizes feedback from a camera. A switched systems approach is used to determine the minimum dwell time required for a feature to remain within the FOV of the camera to ensure accurate estimation. A k-means clustering algorithm acts as a high-level planner to intermittently generate goal locations that guide the deputy spacecraft toward the nearest cluster of uninspected points on the chief satellite, subject to illumination and FOV constraints. A Lyapunov-based stability analysis is conducted to analyze the developed architecture, and simulation results validate the theoretical results of the paper.",
          "authors": [
            "Tochukwu Elijah Ogri",
            "Muzaffar Qureshi",
            "Zachary I. Bell",
            "Wanjiku A. Makumi",
            "Kyle Volle",
            "Rushikesh Kamalapurkar"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.15954",
          "title": "A Switched Systems Approach to Image-Based Feature Tracking for Autonomous Satellite Inspection",
          "abstract": "This paper presents an information-based guidance and control architecture for an autonomous deputy spacecraft tasked with inspecting a chief satellite in orbit. The primary objective is for the deputy spacecraft to maximize information gain while tracking features on the chief satellite. The deputy spacecraft needs to respect various constraints such as illumination, field-of-view (FOV), fuel limitations, and avoidance regions. Additionally, the absence of GPS information poses a significant challenge for relative localization within the space environment. To learn the structure of the chief satellite while achieving relative self-localization and maximizing the information gain, this paper integrates a memory regression extension (MRE)-based distance observer with an information-maximizing adaptive controller. The distance observer utilizes feedback from a camera. A switched systems approach is used to determine the minimum dwell time required for a feature to remain within the FOV of the camera to ensure accurate estimation. A k-means clustering algorithm acts as a high-level planner to intermittently generate goal locations that guide the deputy spacecraft toward the nearest cluster of uninspected points on the chief satellite, subject to illumination and FOV constraints. A Lyapunov-based stability analysis is conducted to analyze the developed architecture, and simulation results validate the theoretical results of the paper.",
          "authors": [
            "Tochukwu Elijah Ogri",
            "Muzaffar Qureshi",
            "Zachary I. Bell",
            "Wanjiku A. Makumi",
            "Kyle Volle",
            "Rushikesh Kamalapurkar"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.19238",
          "title": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees",
          "abstract": "Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.",
          "authors": [
            "Sourav Ganguly",
            "Arnob Ghosh",
            "Kishan Panaganti",
            "Adam Wierman"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.19238",
          "title": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees",
          "abstract": "Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.",
          "authors": [
            "Sourav Ganguly",
            "Arnob Ghosh",
            "Kishan Panaganti",
            "Adam Wierman"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.10488",
          "title": "Multiobjective Aerodynamic Design Optimization of the NASA Common Research Model",
          "abstract": "Aircraft aerodynamic design optimization must account for the varying operating conditions along the cruise segment as opposed to designing at one fixed operating condition, to arrive at more realistic designs. Conventional approaches address this by performing a ``multi-point'' optimization that assumes a weighted average of the objectives at a set of sub-segments along the cruise segment. We argue that since such multi-point approaches are, inevitably, biased by the specification of the weights, they can lead to sub-optimal designs. Instead, we propose to optimize the aircraft design at multiple sub-segments simultaneously -- that is, via multiobjective optimization that leads to a set of Pareto optimal solutions. However, existing work in multiobjective optimization suffers from (i) lack of sample efficiency (that is, keeping the number of function evaluations to convergence minimal), (ii) scalability {in the absence of derivative information}, and (iii) the ability to generate a batch of iterates for synchronous parallel evaluations. To overcome these limitations, we {apply} a novel multiobjective Bayesian optimization methodology {for aerodynamic design optimization} that demonstrates improved sample efficiency and accuracy compared to the state of the art. Inspired by Thompson sampling, our approach leverages Gaussian process surrogates and Bayesian decision theory to generate a sequence of iterates according to the probability that they are Pareto optimal. Our approach, named batch Pareto optimal Thompson sampling (\\qpots)\\footnote{Here, $q$ stands for selecting a batch of $q$ iterates at every step.}, demonstrates superior empirical performance on a variety of synthetic experiments as well as a $24$ dimensional two-objective aerodynamic design optimization of the NASA common research model. We also provide open-source software of our methodology {and experiments}.",
          "authors": [
            "Kade Carlson",
            "Ashwin Renganathan"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.13963",
          "title": "Convergent Reinforcement Learning Algorithms for Stochastic Shortest Path Problem",
          "abstract": "In this paper we propose two algorithms in the tabular setting and an algorithm for the function approximation setting for the Stochastic Shortest Path (SSP) problem. SSP problems form an important class of problems in Reinforcement Learning (RL), as other types of cost-criteria in RL can be formulated in the setting of SSP. We show asymptotic almost-sure convergence for all our algorithms. We observe superior performance of our tabular algorithms compared to other well-known convergent RL algorithms. We further observe reliable performance of our function approximation algorithm compared to other algorithms in the function approximation setting.",
          "authors": [
            "Soumyajit Guin",
            "Shalabh Bhatnagar"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.04963",
          "title": "EV Charging in Smart Grids: Mean Field Equilibrium and Approximate Non-Cooperative and Cooperative Strategies",
          "abstract": "We study the optimal charging strategies for large-scale electric vehicles in smart grids within a finite-horizon mean field game framework. We first establish the existence and uniqueness of the solution to the consistency condition equation, which characterizes the optimal charging behavior in the mean field limit. Building on this result, we construct approximate optimal charging strategies for a finite population of vehicles in both non-cooperative and cooperative settings. Finally, we provide numerical analyses that illustrate and compare the approximate strategies in the non-cooperative and cooperative games.",
          "authors": [
            "Lijun Bo",
            "Fengcheng Liu",
            "Shihua Wang"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05809",
          "title": "Coherent estimation of risk measures",
          "abstract": "We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.",
          "authors": [
            "Martin Aichele",
            "Igor Cialenco",
            "Damian Jelito",
            "Marcin Pitera"
          ],
          "primary_category": "q-fin.RM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05809",
          "title": "Coherent estimation of risk measures",
          "abstract": "We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.",
          "authors": [
            "Martin Aichele",
            "Igor Cialenco",
            "Damian Jelito",
            "Marcin Pitera"
          ],
          "primary_category": "q-fin.RM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05809",
          "title": "Coherent estimation of risk measures",
          "abstract": "We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.",
          "authors": [
            "Martin Aichele",
            "Igor Cialenco",
            "Damian Jelito",
            "Marcin Pitera"
          ],
          "primary_category": "q-fin.RM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.20199",
          "title": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents",
          "abstract": "Constrained optimization provides a common framework for dealing with conflicting objectives in reinforcement learning (RL). In most of these settings, the objectives (and constraints) are expressed though the expected accumulated reward. However, this formulation neglects risky or even possibly catastrophic events at the tails of the reward distribution, and is often insufficient for high-stakes applications in which the risk involved in outliers is critical. In this work, we propose a framework for risk-aware constrained RL, which exhibits per-stage robustness properties jointly in reward values and time using optimized certainty equivalents (OCEs). Our framework ensures an exact equivalent to the original constrained problem within a parameterized strong Lagrangian duality framework under appropriate constraint qualifications, and yields a simple algorithmic recipe which can be wrapped around standard RL solvers, such as PPO. Lastly, we establish the convergence of the proposed algorithm under common assumptions, and verify the risk-aware properties of our approach through several numerical experiments.",
          "authors": [
            "Jane H. Lee",
            "Baturay Saglam",
            "Spyridon Pougkakiotis",
            "Amin Karbasi",
            "Dionysis Kalogerias"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06576",
          "title": "Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids",
          "abstract": "This paper introduces a dissipativity-based framework for the joint design of distributed controllers and communication topologies in AC microgrids (MGs), providing robust performance guarantees for voltage regulation, frequency synchronization, and proportional power sharing across distributed generators (DGs). The closed-loop AC MG is represented as a networked system in which DGs, distribution lines, and loads function as interconnected subsystems linked through cyber-physical networks. Each DG utilizes a three-layer hierarchical control structure: a steady-state controller for operating point configuration, a local feedback controller for voltage tracking, and a distributed droop-free controller implementing normalized power consensus for frequency coordination and proportional power distribution. The operating point design is formulated as an optimization problem. Leveraging dissipativity theory, we derive necessary and sufficient subsystem dissipativity conditions. The global co-design is then cast as a convex linear matrix inequality (LMI) optimization that jointly determines distributed controller parameters and sparse communication architecture while managing the highly nonlinear, coupled dq-frame dynamics characteristic of AC systems.",
          "authors": [
            "Mohammad Javad Najafirad",
            "Shirantha Welikala",
            "Lei Wu",
            "Panos J. Antsaklis"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06576",
          "title": "Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids",
          "abstract": "This paper introduces a dissipativity-based framework for the joint design of distributed controllers and communication topologies in AC microgrids (MGs), providing robust performance guarantees for voltage regulation, frequency synchronization, and proportional power sharing across distributed generators (DGs). The closed-loop AC MG is represented as a networked system in which DGs, distribution lines, and loads function as interconnected subsystems linked through cyber-physical networks. Each DG utilizes a three-layer hierarchical control structure: a steady-state controller for operating point configuration, a local feedback controller for voltage tracking, and a distributed droop-free controller implementing normalized power consensus for frequency coordination and proportional power distribution. The operating point design is formulated as an optimization problem. Leveraging dissipativity theory, we derive necessary and sufficient subsystem dissipativity conditions. The global co-design is then cast as a convex linear matrix inequality (LMI) optimization that jointly determines distributed controller parameters and sparse communication architecture while managing the highly nonlinear, coupled dq-frame dynamics characteristic of AC systems.",
          "authors": [
            "Mohammad Javad Najafirad",
            "Shirantha Welikala",
            "Lei Wu",
            "Panos J. Antsaklis"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.09530",
          "title": "The fastest way through a traffic light",
          "abstract": "We give a rigorous solution of an optimisation problem of minimizing the expected delay caused by encountering a red traffic light on a road journey. The problem incorporates simple constraints on maximum speed, acceleration and braking rates, and depends on the assumed distribution of the remaining time until the traffic light will turn green, after it is first noticed. We assume that this distribution has a bounded and non-increasing density, which is natural since this holds for the law of the excess time in any stationary renewal process. In two special cases, where this distribution is either Uniform or Exponential, we give a complete characterisation of all possible combinations of phases of maximum acceleration, maximum speed, maximum braking, following an Euler--Lagrange curve, and standing stationary at the traffic light, which can make up an optimal solution. The key technique is to write the problem in terms of a two-dimensional pressure integral, so that the problem becomes analogous to filling a tank with a given quantity of liquid.",
          "authors": [
            "Márton Balázs",
            "Edward Crane",
            "Alexander Tallis"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16469",
          "title": "Observer Design for Networked Linear Systems with Fast and Slow Dynamics under Measurement Noise",
          "abstract": "This paper addresses the emulation-based observer design for networked control systems (NCS) with linear plants that operate at two time scales in the presence of measurement noise. The system is formulated as a hybrid singularly perturbed dynamical system, enabling the systematic use of singular perturbation techniques to derive explicit bounds on the maximum allowable transmission intervals (MATI) for both fast and slow communication channels. Under the resulting conditions, the proposed observer guarantees that the estimation error satisfies a global exponential derivative-input-to-state stability (DISS)-like property, where the ultimate bound scales proportionally with the magnitudes of the measurement noise and the time derivative of the control input. The effectiveness of the approach is illustrated through a numerical example.",
          "authors": [
            "Weixuan Wang",
            "Alejandro I. Maass",
            "Dragan Nešić",
            "Ying Tan",
            "Romain Postoyan",
            "W.P.M.H. Heemels"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16469",
          "title": "Observer Design for Networked Linear Systems with Fast and Slow Dynamics under Measurement Noise",
          "abstract": "This paper addresses the emulation-based observer design for networked control systems (NCS) with linear plants that operate at two time scales in the presence of measurement noise. The system is formulated as a hybrid singularly perturbed dynamical system, enabling the systematic use of singular perturbation techniques to derive explicit bounds on the maximum allowable transmission intervals (MATI) for both fast and slow communication channels. Under the resulting conditions, the proposed observer guarantees that the estimation error satisfies a global exponential derivative-input-to-state stability (DISS)-like property, where the ultimate bound scales proportionally with the magnitudes of the measurement noise and the time derivative of the control input. The effectiveness of the approach is illustrated through a numerical example.",
          "authors": [
            "Weixuan Wang",
            "Alejandro I. Maass",
            "Dragan Nešić",
            "Ying Tan",
            "Romain Postoyan",
            "W.P.M.H. Heemels"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17598",
          "title": "Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning",
          "abstract": "Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.",
          "authors": [
            "Zhizuo Chen",
            "Theodore T. Allen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17598",
          "title": "Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning",
          "abstract": "Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.",
          "authors": [
            "Zhizuo Chen",
            "Theodore T. Allen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17598",
          "title": "Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning",
          "abstract": "Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.",
          "authors": [
            "Zhizuo Chen",
            "Theodore T. Allen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19505",
          "title": "Sequential Convex Programming for Multimode Spacecraft Trajectory Optimization",
          "abstract": "Spacecraft equipped with multiple propulsion modes or systems can offer enhanced performance and mission flexibility compared with traditional configurations. Despite these benefits, the trajectory optimization of spacecraft utilizing such configurations remains a complex challenge. This paper presents a sequential convex programming (SCP) approach for the optimal design of multi-mode and multi-propulsion spacecraft trajectories. The method extends the dynamical linearization within SCP using sparse automatic differentiation, enabling efficient inclusion of multiple propulsion modes or systems without complex manual reformulation while maintaining comparable computational efficiency. New constraint formulations are introduced to ensure selection of a single propulsion mode at each time step and limit the total number of modes used. The approach is demonstrated for (i) a low-thrust Earth-67P rendezvous using the SPT-140 thruster with 20 discrete modes, and (ii) an Earth-Mars transfer employing both a low-thrust engine and a solar sail. Results confirm that the proposed method can efficiently compute optimal trajectories for these scenarios.",
          "authors": [
            "Jack Yarndley"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19505",
          "title": "Sequential Convex Programming for Multimode Spacecraft Trajectory Optimization",
          "abstract": "Spacecraft equipped with multiple propulsion modes or systems can offer enhanced performance and mission flexibility compared with traditional configurations. Despite these benefits, the trajectory optimization of spacecraft utilizing such configurations remains a complex challenge. This paper presents a sequential convex programming (SCP) approach for the optimal design of multi-mode and multi-propulsion spacecraft trajectories. The method extends the dynamical linearization within SCP using sparse automatic differentiation, enabling efficient inclusion of multiple propulsion modes or systems without complex manual reformulation while maintaining comparable computational efficiency. New constraint formulations are introduced to ensure selection of a single propulsion mode at each time step and limit the total number of modes used. The approach is demonstrated for (i) a low-thrust Earth-67P rendezvous using the SPT-140 thruster with 20 discrete modes, and (ii) an Earth-Mars transfer employing both a low-thrust engine and a solar sail. Results confirm that the proposed method can efficiently compute optimal trajectories for these scenarios.",
          "authors": [
            "Jack Yarndley"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19505",
          "title": "Sequential Convex Programming for Multimode Spacecraft Trajectory Optimization",
          "abstract": "Spacecraft equipped with multiple propulsion modes or systems can offer enhanced performance and mission flexibility compared with traditional configurations. Despite these benefits, the trajectory optimization of spacecraft utilizing such configurations remains a complex challenge. This paper presents a sequential convex programming (SCP) approach for the optimal design of multi-mode and multi-propulsion spacecraft trajectories. The method extends the dynamical linearization within SCP using sparse automatic differentiation, enabling efficient inclusion of multiple propulsion modes or systems without complex manual reformulation while maintaining comparable computational efficiency. New constraint formulations are introduced to ensure selection of a single propulsion mode at each time step and limit the total number of modes used. The approach is demonstrated for (i) a low-thrust Earth-67P rendezvous using the SPT-140 thruster with 20 discrete modes, and (ii) an Earth-Mars transfer employing both a low-thrust engine and a solar sail. Results confirm that the proposed method can efficiently compute optimal trajectories for these scenarios.",
          "authors": [
            "Jack Yarndley"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21466",
          "title": "Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization",
          "abstract": "We study Consensus-Based Optimization (CBO) for two-layer neural network training. We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. Additionally, in the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. In the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.",
          "authors": [
            "William De Deyn",
            "Michael Herty",
            "Giovanni Samaey"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21466",
          "title": "Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization",
          "abstract": "We study Consensus-Based Optimization (CBO) for two-layer neural network training. We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. Additionally, in the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. In the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.",
          "authors": [
            "William De Deyn",
            "Michael Herty",
            "Giovanni Samaey"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02138",
          "title": "Scalable Distributed Nonlinear Control Under Flatness-Preserving Coupling",
          "abstract": "We study distributed control for a network of nonlinear, differentially flat subsystems subject to dynamic coupling. Although differential flatness simplifies planning and control for isolated subsystems, the presence of coupling can destroy this property for the overall joint system. Focusing on subsystems in pure-feedback form, we identify a class of compatible lower-triangular dynamic couplings that preserve flatness and guarantee that the flat outputs of the subsystems remain the flat outputs of the coupled system. Further, we show that the joint flatness diffeomorphism can be constructed from those of the individual subsystems and, crucially, its sparsity structure reflects that of the coupling. Exploiting this structure, we synthesize a distributed tracking controller that computes control actions from local information only, thereby ensuring scalability. We validate our proposed framework on a simulated example of planar quadrotors dynamically coupled via aerodynamic downwash, and show that the distributed controller achieves accurate trajectory tracking.",
          "authors": [
            "Fengjun Yang",
            "Jake Welde",
            "Nikolai Matni"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02138",
          "title": "Scalable Distributed Nonlinear Control Under Flatness-Preserving Coupling",
          "abstract": "We study distributed control for a network of nonlinear, differentially flat subsystems subject to dynamic coupling. Although differential flatness simplifies planning and control for isolated subsystems, the presence of coupling can destroy this property for the overall joint system. Focusing on subsystems in pure-feedback form, we identify a class of compatible lower-triangular dynamic couplings that preserve flatness and guarantee that the flat outputs of the subsystems remain the flat outputs of the coupled system. Further, we show that the joint flatness diffeomorphism can be constructed from those of the individual subsystems and, crucially, its sparsity structure reflects that of the coupling. Exploiting this structure, we synthesize a distributed tracking controller that computes control actions from local information only, thereby ensuring scalability. We validate our proposed framework on a simulated example of planar quadrotors dynamically coupled via aerodynamic downwash, and show that the distributed controller achieves accurate trajectory tracking.",
          "authors": [
            "Fengjun Yang",
            "Jake Welde",
            "Nikolai Matni"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02163",
          "title": "Distributed Time-Varying Coverage Control via Singular Perturbations",
          "abstract": "This paper presents a novel dynamic coverage control algorithm allowing a group of robots to track an optimal-deployment configuration for arbitrary time-varying density functions. Building on singular perturbation theory, the proposed design employs a two-time scale separation approach, with a fast time scale corresponding to communication and a slow time scale corresponding to agent motion. The resulting algorithm is distributed over the 2-hop Delaunay graph and, for small enough values of the perturbation parameter, achieves the same performance as its centralized counterpart. We also introduce three discrete-time versions that rely only on 1-hop communication at the cost of having to use delayed information and formally establish their asymptotic convergence properties. Our technical approach combines computational geometry, singular perturbation theory, generating functions, and linear iterations with delayed updates. Various simulations illustrate the performance of the proposed algorithms.",
          "authors": [
            "Brandon Bao",
            "Jorge Cortes",
            "Sonia Martinez"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02262",
          "title": "Verifying Closed-Loop Contractivity of Learning-Based Controllers via Partitioning",
          "abstract": "We address the problem of verifying closed-loop contraction in nonlinear control systems whose controller and contraction metric are both parameterized by neural networks. By leveraging interval analysis and interval bound propagation, we derive a tractable and scalable sufficient condition for closed-loop contractivity that reduces to checking that the dominant eigenvalue of a symmetric Metzler matrix is nonpositive. We combine this sufficient condition with a domain partitioning strategy to integrate this sufficient condition into training. The proposed approach is validated on an inverted pendulum system, demonstrating the ability to learn neural network controllers and contraction metrics that provably satisfy the contraction condition.",
          "authors": [
            "Alexander Davydov"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02262",
          "title": "Verifying Closed-Loop Contractivity of Learning-Based Controllers via Partitioning",
          "abstract": "We address the problem of verifying closed-loop contraction in nonlinear control systems whose controller and contraction metric are both parameterized by neural networks. By leveraging interval analysis and interval bound propagation, we derive a tractable and scalable sufficient condition for closed-loop contractivity that reduces to checking that the dominant eigenvalue of a symmetric Metzler matrix is nonpositive. We combine this sufficient condition with a domain partitioning strategy to integrate this sufficient condition into training. The proposed approach is validated on an inverted pendulum system, demonstrating the ability to learn neural network controllers and contraction metrics that provably satisfy the contraction condition.",
          "authors": [
            "Alexander Davydov"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02262",
          "title": "Verifying Closed-Loop Contractivity of Learning-Based Controllers via Partitioning",
          "abstract": "We address the problem of verifying closed-loop contraction in nonlinear control systems whose controller and contraction metric are both parameterized by neural networks. By leveraging interval analysis and interval bound propagation, we derive a tractable and scalable sufficient condition for closed-loop contractivity that reduces to checking that the dominant eigenvalue of a symmetric Metzler matrix is nonpositive. We combine this sufficient condition with a domain partitioning strategy to integrate this sufficient condition into training. The proposed approach is validated on an inverted pendulum system, demonstrating the ability to learn neural network controllers and contraction metrics that provably satisfy the contraction condition.",
          "authors": [
            "Alexander Davydov"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02270",
          "title": "Property-Guided Cyber-Physical Reduction and Surrogation for Safety Analysis in Robotic Vehicles",
          "abstract": "We propose a methodology for falsifying safety properties in robotic vehicle systems through property-guided reduction and surrogate execution. By isolating only the control logic and physical dynamics relevant to a given specification, we construct lightweight surrogate models that preserve property-relevant behaviors while eliminating unrelated system complexity. This enables scalable falsification via trace analysis and temporal logic oracles. We demonstrate the approach on a drone control system containing a known safety flaw. The surrogate replicates failure conditions at a fraction of the simulation cost, and a property-guided fuzzer efficiently discovers semantic violations. Our results suggest that controller reduction, when coupled with logic-aware test generation, provides a practical and scalable path toward semantic verification of cyber-physical systems.",
          "authors": [
            "Nazmus Shakib Sayom",
            "Luis Garcia"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02294",
          "title": "Neural networks for multi-horizon stochastic programming",
          "abstract": "This paper proposes a machine-learning-based solution approach for solving multi-horizon stochastic programs. The approach embeds a deep learning neural network into a multi-horizon stochastic program to approximate the recourse operational objective function. The proposed approach is demonstrated on a UK power system planning problem with uncertainty at investment and operational timescales. The results show that (1) the surrogate neural network performs well across three different architectures, (2) the proposed approach is up to 34.72 times faster than the direct solution of the monolithic deterministic equivalent counterpart, (3) the surrogate-based solutions yield comparable in-sample stability and improved out-of-sample performance relative to the deterministic equivalent, indicating better generalisation to unseen scenarios. The main contributions of the paper are: (1) we propose a machine-learning-based framework for solving multi-horizon stochastic programs, (2) we introduce a neural network embedding formulation tailored to multi-horizon stochastic programs with continuous first-stage decisions and fixed scenario sets, extending existing surrogate modelling approaches from two-stage to multi-horizon settings, and (3) we provide an extensive computational study on a realistic UK power system planning problem, demonstrating the trade-off between approximation accuracy, computational efficiency, and solution robustness for different neural network architectures and scenario set sizes.",
          "authors": [
            "Hongyu Zhang",
            "Gabriele Sormani",
            "Enza Messina",
            "Alan King",
            "Francesca Maggioni"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02311",
          "title": "Nonlinear MPC with PWM applied on a small satellite",
          "abstract": "This paper employs Pulse Width Modulation (PWM) method to a Nonlinear Model Predictive Control (NMPC) for satellite attitude control and detumbling. Magnetic torquers have been used as actuators for the stabilization and attitude control of small satellites. NMPC generates the control input which is continuous and smooth. As a result, it is challenging for the on-board actuators to produce these continuous magnetic moments as a control input. Thus, PWM is applied to discretize the control input reducing the load on the actuators. Simulations are presented for detumbling and attitude control to illustrate the effectiveness and feasibility of the proposed method.",
          "authors": [
            "Jinaykumar Patel"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02367",
          "title": "On the Convergence of Density-Based Predictive Control for Multi-Agent Non-Uniform Area Coverage",
          "abstract": "This paper presents Density-based Predictive Control (DPC), a novel multi-agent control strategy for efficient non-uniform area coverage, grounded in optimal transport theory. In large-scale scenarios such as search and rescue or environmental monitoring, traditional uniform coverage fails to account for varying regional priorities. DPC leverages a pre-constructed reference distribution to allocate agents' coverage efforts, spending more time in high-priority or densely sampled regions. We analyze convergence conditions using the Wasserstein distance, derive an analytic optimal control law for unconstrained cases, and propose a numerical method for constrained scenarios. Simulations on first-order dynamics and linearized quadrotor models demonstrate that DPC achieves trajectories closely matching the non-uniform reference distribution, outperforming existing coverage methods.",
          "authors": [
            "Sungjun Seo",
            "Kooktae Lee"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02367",
          "title": "On the Convergence of Density-Based Predictive Control for Multi-Agent Non-Uniform Area Coverage",
          "abstract": "This paper presents Density-based Predictive Control (DPC), a novel multi-agent control strategy for efficient non-uniform area coverage, grounded in optimal transport theory. In large-scale scenarios such as search and rescue or environmental monitoring, traditional uniform coverage fails to account for varying regional priorities. DPC leverages a pre-constructed reference distribution to allocate agents' coverage efforts, spending more time in high-priority or densely sampled regions. We analyze convergence conditions using the Wasserstein distance, derive an analytic optimal control law for unconstrained cases, and propose a numerical method for constrained scenarios. Simulations on first-order dynamics and linearized quadrotor models demonstrate that DPC achieves trajectories closely matching the non-uniform reference distribution, outperforming existing coverage methods.",
          "authors": [
            "Sungjun Seo",
            "Kooktae Lee"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02381",
          "title": "Fleet Size and Mix Capacitated Vehicle Routing Problem with Time Windows for Mobile Fast Chargers",
          "abstract": "The electrification of off-road heavy equipment presents operational challenges for agencies serving remote sites with limited fixed charging infrastructure. Existing mobile fast charging vehicle (MFCV) planning approaches typically treat fleet design and routing as separate problems, fixing vehicle characteristics before dispatch. This paper formulates a fleet size and mix capacitated vehicle routing problem with time windows (FSMCVRPTW) for MFCV deployment, jointly optimizing fleet composition, charger specifications, routing, and scheduling within a unified mixed-integer linear program. The model incorporates heterogeneous MFCV types with varying power ratings, battery capacities, fuel range, and cost structures, minimizing total daily cost from labor, fuel, amortized capital expenditure, and energy purchase under temporal service windows, resource budgets, and energy-delivery constraints. The formulation is implemented in Python/Gurobi and applied to two case studies using California Department of Transportation wheel-loader data in Los Angeles (dense urban) and Truckee (sparse mountainous). Results show that simultaneous optimization yields compact, well-utilized fleets that meet all service windows while revealing strong sensitivity of unit cost to demand density and geography. The proposed FSMCVRPTW framework provides a generalizable decision-support methodology that co-designs fleet size, charger power, routing, and service schedules in a single optimization layer for context-aware, cost-efficient mobile fast charging.",
          "authors": [
            "Farhang Motallebi Araghi",
            "Armin Abdolmohammdi",
            "Navid Mojahed",
            "Shima Nazari"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02381",
          "title": "Fleet Size and Mix Capacitated Vehicle Routing Problem with Time Windows for Mobile Fast Chargers",
          "abstract": "The electrification of off-road heavy equipment presents operational challenges for agencies serving remote sites with limited fixed charging infrastructure. Existing mobile fast charging vehicle (MFCV) planning approaches typically treat fleet design and routing as separate problems, fixing vehicle characteristics before dispatch. This paper formulates a fleet size and mix capacitated vehicle routing problem with time windows (FSMCVRPTW) for MFCV deployment, jointly optimizing fleet composition, charger specifications, routing, and scheduling within a unified mixed-integer linear program. The model incorporates heterogeneous MFCV types with varying power ratings, battery capacities, fuel range, and cost structures, minimizing total daily cost from labor, fuel, amortized capital expenditure, and energy purchase under temporal service windows, resource budgets, and energy-delivery constraints. The formulation is implemented in Python/Gurobi and applied to two case studies using California Department of Transportation wheel-loader data in Los Angeles (dense urban) and Truckee (sparse mountainous). Results show that simultaneous optimization yields compact, well-utilized fleets that meet all service windows while revealing strong sensitivity of unit cost to demand density and geography. The proposed FSMCVRPTW framework provides a generalizable decision-support methodology that co-designs fleet size, charger power, routing, and service schedules in a single optimization layer for context-aware, cost-efficient mobile fast charging.",
          "authors": [
            "Farhang Motallebi Araghi",
            "Armin Abdolmohammdi",
            "Navid Mojahed",
            "Shima Nazari"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02386",
          "title": "Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection",
          "abstract": "This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \\textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.",
          "authors": [
            "Chuhan Xie"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02386",
          "title": "Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection",
          "abstract": "This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \\textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.",
          "authors": [
            "Chuhan Xie"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02406",
          "title": "Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning",
          "abstract": "With increased travelling needs more than ever, traffic congestion has become a major concern in most urban areas. Allocating spaces for on-street parking, further hinders traffic flow, by limiting the effective road width available for driving. With the advancement of vehicle-to-infrastructure connectivity technologies, we explore how the impact of on-street parking on traffic congestion could be minimized, by dynamically configuring on-street parking spaces. Towards that end, we formulate dynamic on-street parking space configuration as an optimization problem, and we follow a data driven approach, considering the nature of our problem. Our proposed solution comprises a two-layer multi agent reinforcement learning based framework, which is inherently scalable to large road networks. The lane level agents are responsible for deciding the optimal parking space configuration for each lane, and we introduce a novel Deep Q-learning architecture which effectively utilizes long short term memory networks and graph attention networks to capture the spatio-temporal correlations evident in the given problem. The block level agents control the actions of the lane level agents and maintain a sufficient level of parking around the block. We conduct a set of comprehensive experiments using SUMO, on both synthetic data as well as real-world data from the city of Melbourne. Our experiments show that the proposed framework could reduce the average travel time loss of vehicles significantly, reaching upto 47%, with a negligible increase in the walking distance for parking.",
          "authors": [
            "Oshada Jayasinghe",
            "Farhana Choudhury",
            "Egemen Tanin",
            "Shanika Karunasekera"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02452",
          "title": "Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems",
          "abstract": "As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.",
          "authors": [
            "Tianyou Xiang",
            "Cheng Zhao"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02452",
          "title": "Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems",
          "abstract": "As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.",
          "authors": [
            "Tianyou Xiang",
            "Cheng Zhao"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02452",
          "title": "Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems",
          "abstract": "As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.",
          "authors": [
            "Tianyou Xiang",
            "Cheng Zhao"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02467",
          "title": "Theory and Design of Extended PID Control for Stochastic Systems with Structural Uncertainties",
          "abstract": "Since the classical proportional-integral-derivative (PID) controller has continued to be the most widely used feedback methods in engineering systems by far, it is crucial to investigate the working mechanism of PID in dealing with nonlinearity, uncertainty and random noises. Recently, Zhao and Guo (2022) has established the global stability of PID control for a class of uncertain nonlinear control systems with relative degree two without random perturbations. In this paper, we will consider a more general class of nonlinear stochastic systems with an arbitrary relative degree $n$, and discuss the stability and design of extended PID controller (a natural extension of PID). We demonstrate that, the closed-loop control systems will be globally stable in mean square with bounded tracking errors provided the extended PID parameters are selected from an $(n+1)$-dimensional unbounded set, even if both the system nonlinear drift and diffusion terms contain a wide range of structural uncertainties. Moreover, the steady-state tracking error is proved to be proportional to the noise intensity at the setpoint, which can also be made arbitrarily small by choosing the controller parameters suitably large.",
          "authors": [
            "Baoyou Qu",
            "Cheng Zhao"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02511",
          "title": "Time-delayed feedback control for random dynamical systems",
          "abstract": "We extend the Pyragas time-delayed feedback control (TDFC) to apply it to random dynamical systems and introduce an extended classification based on Lyapunov exponents and trajectory fluctuations. We demonstrate the applicability of this framework using the random logistic map and the stochastic Rössler system. Our results reveal that noise-induced chaos triggers a transition from stable to unstable regimes based on a phenomenon inherent to random dynamical systems.",
          "authors": [
            "Miki U. Kobayashi",
            "Yuzuru Sato"
          ],
          "primary_category": "nlin.CD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02562",
          "title": "Intervention Strategies for Fairness and Efficiency at Autonomous Single-Intersection Traffic Flows",
          "abstract": "Intersections present significant challenges in traffic management, where ensuring safety and efficiency is essential for effective flow. However, these goals are often achieved at the expense of fairness, which is critical for trustworthiness and long-term sustainability. This paper investigates how the timing of centralized intervention affects the management of autonomous agents at a signal-less, orthogonal intersection, while satisfying safety constraints, evaluating efficiency, and ensuring fairness. A mixed-integer linear programming (MILP) approach is used to optimize agent coordination within a circular control zone centered at the intersection. We introduce the concept of fairness, measured via pairwise reversal counts, and incorporate fairness constraints into the MILP framework. We then study the relationship between fairness and system efficiency and its impact on platoon formation. Finally, simulation studies analyze the effectiveness of early versus late intervention strategies and fairness-aware control, focusing on safe, efficient, and robust management of agents within the control zone.",
          "authors": [
            "Salman Ghori",
            "Ania Adil",
            "Melkior Ornik",
            "Eric Feron"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02562",
          "title": "Intervention Strategies for Fairness and Efficiency at Autonomous Single-Intersection Traffic Flows",
          "abstract": "Intersections present significant challenges in traffic management, where ensuring safety and efficiency is essential for effective flow. However, these goals are often achieved at the expense of fairness, which is critical for trustworthiness and long-term sustainability. This paper investigates how the timing of centralized intervention affects the management of autonomous agents at a signal-less, orthogonal intersection, while satisfying safety constraints, evaluating efficiency, and ensuring fairness. A mixed-integer linear programming (MILP) approach is used to optimize agent coordination within a circular control zone centered at the intersection. We introduce the concept of fairness, measured via pairwise reversal counts, and incorporate fairness constraints into the MILP framework. We then study the relationship between fairness and system efficiency and its impact on platoon formation. Finally, simulation studies analyze the effectiveness of early versus late intervention strategies and fairness-aware control, focusing on safe, efficient, and robust management of agents within the control zone.",
          "authors": [
            "Salman Ghori",
            "Ania Adil",
            "Melkior Ornik",
            "Eric Feron"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02579",
          "title": "Reduced-order Smith predictor for state feedback control with guaranteed stability",
          "abstract": "This article deals with the implementation of the Smith Predictor for state feedback control in state space representation. The desired control law, obtained using partial differential equations and backstepping control, contains an integral term that has to be approximated for implementation. In this article, we propose a new way to implement this control law using a dynamic controller. The control law is composed of a state feedback term and a dynamic term that approaches the integral term that has to be estimated for implementation. Using a Lyapunov functional, we provide sufficient conditions, in terms of a linear matrix inequality, to guarantee that the closed-loop system is stable when the proposed control law is applied. We use three examples, taken from the literature, to show the benefits of the proposed approach.",
          "authors": [
            "Jesus-Pablo Toledo-Zucco",
            "Frédéric Gouaisbaut",
            "Gaetan Chapput"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02579",
          "title": "Reduced-order Smith predictor for state feedback control with guaranteed stability",
          "abstract": "This article deals with the implementation of the Smith Predictor for state feedback control in state space representation. The desired control law, obtained using partial differential equations and backstepping control, contains an integral term that has to be approximated for implementation. In this article, we propose a new way to implement this control law using a dynamic controller. The control law is composed of a state feedback term and a dynamic term that approaches the integral term that has to be estimated for implementation. Using a Lyapunov functional, we provide sufficient conditions, in terms of a linear matrix inequality, to guarantee that the closed-loop system is stable when the proposed control law is applied. We use three examples, taken from the literature, to show the benefits of the proposed approach.",
          "authors": [
            "Jesus-Pablo Toledo-Zucco",
            "Frédéric Gouaisbaut",
            "Gaetan Chapput"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02579",
          "title": "Reduced-order Smith predictor for state feedback control with guaranteed stability",
          "abstract": "This article deals with the implementation of the Smith Predictor for state feedback control in state space representation. The desired control law, obtained using partial differential equations and backstepping control, contains an integral term that has to be approximated for implementation. In this article, we propose a new way to implement this control law using a dynamic controller. The control law is composed of a state feedback term and a dynamic term that approaches the integral term that has to be estimated for implementation. Using a Lyapunov functional, we provide sufficient conditions, in terms of a linear matrix inequality, to guarantee that the closed-loop system is stable when the proposed control law is applied. We use three examples, taken from the literature, to show the benefits of the proposed approach.",
          "authors": [
            "Jesus-Pablo Toledo-Zucco",
            "Frédéric Gouaisbaut",
            "Gaetan Chapput"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02662",
          "title": "Modal Analysis of Core Inertial Dynamics: Re-evaluating Grid-Forming Control Design Principles",
          "abstract": "This paper employs modal analysis to study the core inertial dynamics of governor-controlled synchronous generators (GC-SG), droop-based grid-forming (GFM) converters, and their most fundamental interactions. The results indicate that even in the simplest cases, the prevailing industry paradigm of emulating legacy GC-SG behaviour in GFM converters (high inertia to slow down the system and large droop to increase damping) could be a suboptimal policy. It is shown that GC-SGs exhibit a fundamental trade-off: adequate damping of the turbine-governor mode requires large droop constants, inevitably increasing steady-state frequency deviation and dependence on secondary regulation. In contrast, droop-based GFM converters invert this relationship: decreasing the droop constant simultaneously reduces steady-state frequency deviations and increases damping, while allowing virtual inertia to be freely chosen. When two GC-SGs are coupled, the poorly damped electromechanical swing mode emerges. Results show that replacing one GC-SG with a GFM converter of equivalent droop and inertia already significantly improves damping of both swing and turbine-governor modes. Counter-intuitively, further and remarkable damping gains are achieved by substantially lowering the GFM virtual inertia constant. These findings suggest that current industry trends may be constraining the potential benefits of Inverter Based Resources (IBRs). Optimal stability and performance are instead obtained with low droop and low virtual inertia, yielding tightly bounded frequency variations and strongly-damped electromechanical modes. The results indicate a need to re-evaluate GFM control design principles and emerging grid-code requirements.",
          "authors": [
            "Gerardo Medrano",
            "Santiago Cóbreces"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02662",
          "title": "Modal Analysis of Core Inertial Dynamics: Re-evaluating Grid-Forming Control Design Principles",
          "abstract": "This paper employs modal analysis to study the core inertial dynamics of governor-controlled synchronous generators (GC-SG), droop-based grid-forming (GFM) converters, and their most fundamental interactions. The results indicate that even in the simplest cases, the prevailing industry paradigm of emulating legacy GC-SG behaviour in GFM converters (high inertia to slow down the system and large droop to increase damping) could be a suboptimal policy. It is shown that GC-SGs exhibit a fundamental trade-off: adequate damping of the turbine-governor mode requires large droop constants, inevitably increasing steady-state frequency deviation and dependence on secondary regulation. In contrast, droop-based GFM converters invert this relationship: decreasing the droop constant simultaneously reduces steady-state frequency deviations and increases damping, while allowing virtual inertia to be freely chosen. When two GC-SGs are coupled, the poorly damped electromechanical swing mode emerges. Results show that replacing one GC-SG with a GFM converter of equivalent droop and inertia already significantly improves damping of both swing and turbine-governor modes. Counter-intuitively, further and remarkable damping gains are achieved by substantially lowering the GFM virtual inertia constant. These findings suggest that current industry trends may be constraining the potential benefits of Inverter Based Resources (IBRs). Optimal stability and performance are instead obtained with low droop and low virtual inertia, yielding tightly bounded frequency variations and strongly-damped electromechanical modes. The results indicate a need to re-evaluate GFM control design principles and emerging grid-code requirements.",
          "authors": [
            "Gerardo Medrano",
            "Santiago Cóbreces"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02704",
          "title": "Conformal Correction for Efficiency May be at Odds with Entropy",
          "abstract": "Conformal prediction (CP) provides a comprehensive framework to produce statistically rigorous uncertainty sets for black-box machine learning models. To further improve the efficiency of CP, conformal correction is proposed to fine-tune or wrap the base model with an extra module using a conformal-aware inefficiency loss. In this work, we empirically and theoretically identify a trade-off between the CP efficiency and the entropy of model prediction. We then propose an entropy-constrained conformal correction method, exploring a better Pareto optimum between efficiency and entropy. Extensive experimental results on both computer vision and graph datasets demonstrate the efficacy of the proposed method. For instance, it can significantly improve the efficiency of state-of-the-art CP methods by up to 34.4%, given an entropy threshold.",
          "authors": [
            "Senrong Xu",
            "Tianyu Wang",
            "Zenan Li",
            "Yuan Yao",
            "Taolue Chen",
            "Feng Xu",
            "Xiaoxing Ma"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02769",
          "title": "Reinforcement learning for irreversible reinsurance problems: the randomized singular control approach",
          "abstract": "This paper studies the continuous-time reinforcement learning for stochastic singular control with the application to an infinite-horizon irreversible reinsurance problems. The singular control is equivalently characterized as a pair of regions of time and the augmented states, called the singular control law. To encourage the exploration in the learning procedure, we propose a randomization method for the singular control laws, new to the literature, by considering an auxiliary singular control and entropy regularization. The exploratory singular control problem is formulated as a two-stage optimal control problem, where the time-inconsistency issue arises in the outer problem. In the specific model setup with known model coefficients, we provide the full characterization of the time-consistent equilibrium singular controls for the two-stage problem. Taking advantage of the solution structure, we can consider the proper parameterization of the randomized equilibrium policy and the value function when the model is unknown and further devise the actor-critic reinforcement learning algorithms. In the numerical experiment, we present the superior convergence of parameter iterations towards the true values based on the randomized equilibrium policy and illustrate how the exploration may advance the learning performance in the context of singular controls.",
          "authors": [
            "Zongxia Liang",
            "Xiaodong Luo",
            "Xiang Yu"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02797",
          "title": "Gain-Scheduling Data-Enabled Predictive Control for Nonlinear Systems with Linearized Operating Regions",
          "abstract": "This paper presents a Gain-Scheduled Data-Enabled Predictive Control (GS-DeePC) framework for nonlinear systems based on multiple locally linear data representations. Instead of relying on a single global Hankel matrix, the operating range of a measurable scheduling variable is partitioned into regions, and regional Hankel matrices are constructed from persistently exciting data. To ensure smooth transitions between linearization regions and suppress region-induced chattering, composite regions are introduced, merging neighboring data sets and enabling a robust switching mechanism. The proposed method maintains the original DeePC problem structure and can achieve reduced computational complexity by requiring only short, locally informative data sequences. Extensive experiments on a nonlinear DC-motor with an unbalanced disc demonstrate the significantly improved control performance compared to standard DeePC.",
          "authors": [
            "Sebastian Zieglmeier",
            "Mathias Hudoba de Badyn",
            "Narada D. Warakagoda",
            "Thomas R. Krogstad",
            "Paal Engelstad"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02797",
          "title": "Gain-Scheduling Data-Enabled Predictive Control for Nonlinear Systems with Linearized Operating Regions",
          "abstract": "This paper presents a Gain-Scheduled Data-Enabled Predictive Control (GS-DeePC) framework for nonlinear systems based on multiple locally linear data representations. Instead of relying on a single global Hankel matrix, the operating range of a measurable scheduling variable is partitioned into regions, and regional Hankel matrices are constructed from persistently exciting data. To ensure smooth transitions between linearization regions and suppress region-induced chattering, composite regions are introduced, merging neighboring data sets and enabling a robust switching mechanism. The proposed method maintains the original DeePC problem structure and can achieve reduced computational complexity by requiring only short, locally informative data sequences. Extensive experiments on a nonlinear DC-motor with an unbalanced disc demonstrate the significantly improved control performance compared to standard DeePC.",
          "authors": [
            "Sebastian Zieglmeier",
            "Mathias Hudoba de Badyn",
            "Narada D. Warakagoda",
            "Thomas R. Krogstad",
            "Paal Engelstad"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02858",
          "title": "PAC-Bayesian Optimal Control with Stability and Generalization Guarantees",
          "abstract": "Stochastic Nonlinear Optimal Control (SNOC) seeks to minimize a cost function that accounts for random disturbances acting on a nonlinear dynamical system. Since the expectation over all disturbances is generally intractable, a common surrogate is the empirical cost, obtained by averaging over a finite dataset of sampled noise realizations. This substitution, however, introduces the challenge of guaranteeing performance under unseen disturbances. The issue is particularly severe when the dataset is limited, as the trained controllers may overfit, leading to substantial gaps between their empirical cost and the deployment cost. In this work, we develop a PAC-Bayesian framework that establishes rigorous generalization bounds for SNOC. Building on these bounds, we propose a principled controller design method that balances empirical performance and prior knowledge. To ensure tractability, we derive computationally efficient relaxations of the bounds and employ approximate inference methods. Our framework further leverages expressive neural controller parameterizations, guaranteeing closed-loop stability. Through simulated examples, we highlight how prior knowledge can be incorporated into control design and how more reliable controllers can be synthesized for cooperative robotics.",
          "authors": [
            "Mahrokh Ghoddousi Boroujeni",
            "Clara Lucía Galimberti",
            "Andreas Krause",
            "Giancarlo Ferrari-Trecate"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02858",
          "title": "PAC-Bayesian Optimal Control with Stability and Generalization Guarantees",
          "abstract": "Stochastic Nonlinear Optimal Control (SNOC) seeks to minimize a cost function that accounts for random disturbances acting on a nonlinear dynamical system. Since the expectation over all disturbances is generally intractable, a common surrogate is the empirical cost, obtained by averaging over a finite dataset of sampled noise realizations. This substitution, however, introduces the challenge of guaranteeing performance under unseen disturbances. The issue is particularly severe when the dataset is limited, as the trained controllers may overfit, leading to substantial gaps between their empirical cost and the deployment cost. In this work, we develop a PAC-Bayesian framework that establishes rigorous generalization bounds for SNOC. Building on these bounds, we propose a principled controller design method that balances empirical performance and prior knowledge. To ensure tractability, we derive computationally efficient relaxations of the bounds and employ approximate inference methods. Our framework further leverages expressive neural controller parameterizations, guaranteeing closed-loop stability. Through simulated examples, we highlight how prior knowledge can be incorporated into control design and how more reliable controllers can be synthesized for cooperative robotics.",
          "authors": [
            "Mahrokh Ghoddousi Boroujeni",
            "Clara Lucía Galimberti",
            "Andreas Krause",
            "Giancarlo Ferrari-Trecate"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02872",
          "title": "AC/DC Frequency-Dependent Power Flow Jacobian: Quantifying Grid Support and Stability Implications",
          "abstract": "This letter proposes an AC/DC frequency-dependent power flow Jacobian analysis to identify the system support capabilities. In addition, the analyses reveal that system support capabilities do not necessarily enhance the system stability margin, suggesting that technical requirements of narrow-frequency-band and AC-side focused specifications may not lead to the expected performance of GFM.",
          "authors": [
            "Dongyeong Lee",
            "Eros Avdiaj",
            "Jef Beerten"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02872",
          "title": "AC/DC Frequency-Dependent Power Flow Jacobian: Quantifying Grid Support and Stability Implications",
          "abstract": "This letter proposes an AC/DC frequency-dependent power flow Jacobian analysis to identify the system support capabilities. In addition, the analyses reveal that system support capabilities do not necessarily enhance the system stability margin, suggesting that technical requirements of narrow-frequency-band and AC-side focused specifications may not lead to the expected performance of GFM.",
          "authors": [
            "Dongyeong Lee",
            "Eros Avdiaj",
            "Jef Beerten"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02893",
          "title": "Statistical-Symbolic Verification of Perception-Based Autonomous Systems using State-Dependent Conformal Prediction",
          "abstract": "Reachability analysis has been a prominent way to provide safety guarantees for neurally controlled autonomous systems, but its direct application to neural perception components is infeasible due to imperfect or intractable perception models. Typically, this issue has been bypassed by complementing reachability with statistical analysis of perception error, say with conformal prediction (CP). However, existing CP methods for time-series data often provide conservative bounds. The corresponding error accumulation over time has made it challenging to combine statistical bounds with symbolic reachability in a way that is provable, scalable, and minimally conservative. To reduce conservatism and improve scalability, our key insight is that perception error varies significantly with the system's dynamical state. This article proposes state-dependent conformal prediction, which exploits that dependency in constructing tight high-confidence bounds on perception error. Based on this idea, we provide an approach to partition the state space, using a genetic algorithm, so as to optimize the tightness of conformal bounds. Finally, since using these bounds in reachability analysis leads to additional uncertainty and branching in the resulting hybrid system, we propose a branch-merging reachability algorithm that trades off uncertainty for scalability so as to enable scalable and tight verification. The evaluation of our verification methodology on two complementary case studies demonstrates reduced conservatism compared to the state of the art.",
          "authors": [
            "Yuang Geng",
            "Thomas Waite",
            "Trevor Turnquist",
            "Radoslav Ivanov",
            "Ivan Ruchkin"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02893",
          "title": "Statistical-Symbolic Verification of Perception-Based Autonomous Systems using State-Dependent Conformal Prediction",
          "abstract": "Reachability analysis has been a prominent way to provide safety guarantees for neurally controlled autonomous systems, but its direct application to neural perception components is infeasible due to imperfect or intractable perception models. Typically, this issue has been bypassed by complementing reachability with statistical analysis of perception error, say with conformal prediction (CP). However, existing CP methods for time-series data often provide conservative bounds. The corresponding error accumulation over time has made it challenging to combine statistical bounds with symbolic reachability in a way that is provable, scalable, and minimally conservative. To reduce conservatism and improve scalability, our key insight is that perception error varies significantly with the system's dynamical state. This article proposes state-dependent conformal prediction, which exploits that dependency in constructing tight high-confidence bounds on perception error. Based on this idea, we provide an approach to partition the state space, using a genetic algorithm, so as to optimize the tightness of conformal bounds. Finally, since using these bounds in reachability analysis leads to additional uncertainty and branching in the resulting hybrid system, we propose a branch-merging reachability algorithm that trades off uncertainty for scalability so as to enable scalable and tight verification. The evaluation of our verification methodology on two complementary case studies demonstrates reduced conservatism compared to the state of the art.",
          "authors": [
            "Yuang Geng",
            "Thomas Waite",
            "Trevor Turnquist",
            "Radoslav Ivanov",
            "Ivan Ruchkin"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 5,
      "size": 17,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2407.07814",
          "title": "Optimal sampling for least squares approximation with general dictionaries",
          "abstract": "We consider the problem of approximating an unknown function from point evaluations. This problem is a crucial subproblem in many modern (nonlinear) approximation schemes. When obtaining these point evaluations is costly, minimising the required sample size becomes crucial. Recently, an increasing focus has been on employing importance sampling strategies to achieve this. For the approximation in a $d$-dimensional linear space, an optimal i.i.d. sampling measure achieves a sampling complexity of $\\mathcal{O}(d\\log (d))$. However, the corresponding sampling measure depends on an orthonormal basis of the linear space, which is rarely known (in particular in the context of nonlinear approximation where the linear space arises as a local linearisation of a nonlinear model class like neural networks or tensor networks). Consequently, sampling from these measures is challenging in practice. This manuscript presents a strategy for estimating an orthonormal basis. This strategy can be performed offline and does not require evaluations of the sought function. We establish convergence and illustrate the practical performance through numerical experiments. Comparing the presented approach with standard Monte Carlo sampling demonstrates a significant reduction in the number of samples required to achieve a good estimation of an orthonormal basis.",
          "primary_category": "math.NA",
          "authors": [
            "Philipp Trunschke",
            "Anthony Nouy"
          ]
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "primary_category": "q-bio.MN",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ]
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "primary_category": "q-bio.MN",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ]
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "primary_category": "q-bio.MN",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ]
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "primary_category": "q-bio.MN",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ]
        },
        {
          "id": "arXiv:2512.02204",
          "title": "MoRSAIK: Sequence Motif Reactor Simulation, Analysis and Inference Kit in Python",
          "abstract": "Origins of life research investigates how life could emerge from prebiotic chemistry only. One possible explanation provides the RNA world hypothesis. It states that life could emerge from RNA strands only, storing and transferring biological information, as well as catalyzing reactions as ribozymes. Before this state could have emerged, however, the prebiotic world was probably a purely chemical pool of short RNA strands with random sequences and without biological function performing hybridization and dehybridization, as well as ligation and cleavage. In this context relevant questions are what are the conditions that allow longer RNA strands to be built and how can information carrying in RNA sequence emerge? In order to investigate such RNA reactors, efficient simulations are needed because the space of possible RNA sequences increases exponentially with the length of the strands, as well as the number of reactions between two strands. In addition, simulations have to be compared to experimental data for validation and parameter calibration. Here, we present the MoRSAIK python package for sequence motif (or k-mer) reactor simulation, analysis and inference. It enables users to simulate RNA sequence motif dynamics in the mean field approximation as well as to infer the reaction parameters from data with Bayesian methods and to analyze results by computing observables and plotting. MoRSAIK simulates an RNA reactor by following the reactions and the concentrations of all strands inside up to a certain length (of four nucleotides by default). Longer strands are followed indirectly, by tracking the concentrations of their containing sequence motifs of that maximum length.",
          "primary_category": "physics.bio-ph",
          "authors": [
            "Johannes Harth-Kitzerow",
            "Ulrich Gerland",
            "Torsten A. Enßlin"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2407.07814",
          "title": "Optimal sampling for least squares approximation with general dictionaries",
          "abstract": "We consider the problem of approximating an unknown function from point evaluations. This problem is a crucial subproblem in many modern (nonlinear) approximation schemes. When obtaining these point evaluations is costly, minimising the required sample size becomes crucial. Recently, an increasing focus has been on employing importance sampling strategies to achieve this. For the approximation in a $d$-dimensional linear space, an optimal i.i.d. sampling measure achieves a sampling complexity of $\\mathcal{O}(d\\log (d))$. However, the corresponding sampling measure depends on an orthonormal basis of the linear space, which is rarely known (in particular in the context of nonlinear approximation where the linear space arises as a local linearisation of a nonlinear model class like neural networks or tensor networks). Consequently, sampling from these measures is challenging in practice. This manuscript presents a strategy for estimating an orthonormal basis. This strategy can be performed offline and does not require evaluations of the sought function. We establish convergence and illustrate the practical performance through numerical experiments. Comparing the presented approach with standard Monte Carlo sampling demonstrates a significant reduction in the number of samples required to achieve a good estimation of an orthonormal basis.",
          "authors": [
            "Philipp Trunschke",
            "Anthony Nouy"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2407.07814",
          "title": "Optimal sampling for least squares approximation with general dictionaries",
          "abstract": "We consider the problem of approximating an unknown function from point evaluations. This problem is a crucial subproblem in many modern (nonlinear) approximation schemes. When obtaining these point evaluations is costly, minimising the required sample size becomes crucial. Recently, an increasing focus has been on employing importance sampling strategies to achieve this. For the approximation in a $d$-dimensional linear space, an optimal i.i.d. sampling measure achieves a sampling complexity of $\\mathcal{O}(d\\log (d))$. However, the corresponding sampling measure depends on an orthonormal basis of the linear space, which is rarely known (in particular in the context of nonlinear approximation where the linear space arises as a local linearisation of a nonlinear model class like neural networks or tensor networks). Consequently, sampling from these measures is challenging in practice. This manuscript presents a strategy for estimating an orthonormal basis. This strategy can be performed offline and does not require evaluations of the sought function. We establish convergence and illustrate the practical performance through numerical experiments. Comparing the presented approach with standard Monte Carlo sampling demonstrates a significant reduction in the number of samples required to achieve a good estimation of an orthonormal basis.",
          "authors": [
            "Philipp Trunschke",
            "Anthony Nouy"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.05266",
          "title": "Sampling, approximation, and interpolation of differential forms by admissible integral k-meshes",
          "abstract": "In this work we introduce the concept of admissible integral $k$-mesh for sampling differential forms with contiuous coefficients on a real body $E\\subset \\R^n$, and provide two techniques for the construction of admissible integral $k$-meshes on real bodies enjoying the Markov or the Bernstein inequality. Admissible integral $k$-meshes allow for the construction of robust approximation schemes, and are used to extract interpolation sets with high stability properties. To this end, the concepts of Fekete currents and Leja sequences of currents are formalized, and a numerical scheme for their approximation is proposed.",
          "authors": [
            "Ludovico Bruni Bruno",
            "Federico Piazzon"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.05266",
          "title": "Sampling, approximation, and interpolation of differential forms by admissible integral k-meshes",
          "abstract": "In this work we introduce the concept of admissible integral $k$-mesh for sampling differential forms with contiuous coefficients on a real body $E\\subset \\R^n$, and provide two techniques for the construction of admissible integral $k$-meshes on real bodies enjoying the Markov or the Bernstein inequality. Admissible integral $k$-meshes allow for the construction of robust approximation schemes, and are used to extract interpolation sets with high stability properties. To this end, the concepts of Fekete currents and Leja sequences of currents are formalized, and a numerical scheme for their approximation is proposed.",
          "authors": [
            "Ludovico Bruni Bruno",
            "Federico Piazzon"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.12282",
          "title": "Kernel interpolation on generalized sparse grids",
          "abstract": "We consider scattered data approximation on product regions of equal and different dimensionality. On each of these regions, we assume quasi-uniform but unstructured data sites and construct optimal sparse grids for scattered data interpolation on the product region. For this, we derive new improved error estimates for the respective kernel interpolation error by invoking duality arguments. An efficient algorithm to solve the underlying linear system of equations is proposed. The algorithm is based on the sparse grid combination technique, where a sparse direct solver is used for the elementary anisotropic tensor product kernel interpolation problems. The application of the sparse direct solver is facilitated by applying a samplet matrix compression to each univariate kernel matrix, resulting in an essentially sparse representation of the latter. In this way, we obtain a method that is able to deal with large problems up to billions of interpolation points, especially in case of reproducing kernels of nonlocal nature. Numerical results are presented to qualify and quantify the approach.",
          "authors": [
            "Michael Griebel",
            "Helmut Harbrecht",
            "Michael Multerer"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.12282",
          "title": "Kernel interpolation on generalized sparse grids",
          "abstract": "We consider scattered data approximation on product regions of equal and different dimensionality. On each of these regions, we assume quasi-uniform but unstructured data sites and construct optimal sparse grids for scattered data interpolation on the product region. For this, we derive new improved error estimates for the respective kernel interpolation error by invoking duality arguments. An efficient algorithm to solve the underlying linear system of equations is proposed. The algorithm is based on the sparse grid combination technique, where a sparse direct solver is used for the elementary anisotropic tensor product kernel interpolation problems. The application of the sparse direct solver is facilitated by applying a samplet matrix compression to each univariate kernel matrix, resulting in an essentially sparse representation of the latter. In this way, we obtain a method that is able to deal with large problems up to billions of interpolation points, especially in case of reproducing kernels of nonlocal nature. Numerical results are presented to qualify and quantify the approach.",
          "authors": [
            "Michael Griebel",
            "Helmut Harbrecht",
            "Michael Multerer"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.08366",
          "title": "kNNSampler: Stochastic Imputations for Recovering Missing Value Distributions",
          "abstract": "We study a missing-value imputation method, termed kNNSampler, that imputes a given unit's missing response by randomly sampling from the observed responses of the $k$ most similar units to the given unit in terms of the observed covariates. This method can sample unknown missing values from their distributions, quantify the uncertainties of missing values, and be readily used for multiple imputation. Unlike popular kNNImputer, which estimates the conditional mean of a missing response given an observed covariate, kNNSampler is theoretically shown to estimate the conditional distribution of a missing response given an observed covariate. Experiments illustrate the performance of kNNSampler. The code for kNNSampler is made publicly available ( this https URL ).",
          "authors": [
            "Parastoo Pashmchi",
            "Jérôme Benoit",
            "Motonobu Kanagawa"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.08366",
          "title": "kNNSampler: Stochastic Imputations for Recovering Missing Value Distributions",
          "abstract": "We study a missing-value imputation method, termed kNNSampler, that imputes a given unit's missing response by randomly sampling from the observed responses of the $k$ most similar units to the given unit in terms of the observed covariates. This method can sample unknown missing values from their distributions, quantify the uncertainties of missing values, and be readily used for multiple imputation. Unlike popular kNNImputer, which estimates the conditional mean of a missing response given an observed covariate, kNNSampler is theoretically shown to estimate the conditional distribution of a missing response given an observed covariate. Experiments illustrate the performance of kNNSampler. The code for kNNSampler is made publicly available ( this https URL ).",
          "authors": [
            "Parastoo Pashmchi",
            "Jérôme Benoit",
            "Motonobu Kanagawa"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.08366",
          "title": "kNNSampler: Stochastic Imputations for Recovering Missing Value Distributions",
          "abstract": "We study a missing-value imputation method, termed kNNSampler, that imputes a given unit's missing response by randomly sampling from the observed responses of the $k$ most similar units to the given unit in terms of the observed covariates. This method can sample unknown missing values from their distributions, quantify the uncertainties of missing values, and be readily used for multiple imputation. Unlike popular kNNImputer, which estimates the conditional mean of a missing response given an observed covariate, kNNSampler is theoretically shown to estimate the conditional distribution of a missing response given an observed covariate. Experiments illustrate the performance of kNNSampler. The code for kNNSampler is made publicly available ( this https URL ).",
          "authors": [
            "Parastoo Pashmchi",
            "Jérôme Benoit",
            "Motonobu Kanagawa"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02204",
          "title": "MoRSAIK: Sequence Motif Reactor Simulation, Analysis and Inference Kit in Python",
          "abstract": "Origins of life research investigates how life could emerge from prebiotic chemistry only. One possible explanation provides the RNA world hypothesis. It states that life could emerge from RNA strands only, storing and transferring biological information, as well as catalyzing reactions as ribozymes. Before this state could have emerged, however, the prebiotic world was probably a purely chemical pool of short RNA strands with random sequences and without biological function performing hybridization and dehybridization, as well as ligation and cleavage. In this context relevant questions are what are the conditions that allow longer RNA strands to be built and how can information carrying in RNA sequence emerge? In order to investigate such RNA reactors, efficient simulations are needed because the space of possible RNA sequences increases exponentially with the length of the strands, as well as the number of reactions between two strands. In addition, simulations have to be compared to experimental data for validation and parameter calibration. Here, we present the MoRSAIK python package for sequence motif (or k-mer) reactor simulation, analysis and inference. It enables users to simulate RNA sequence motif dynamics in the mean field approximation as well as to infer the reaction parameters from data with Bayesian methods and to analyze results by computing observables and plotting. MoRSAIK simulates an RNA reactor by following the reactions and the concentrations of all strands inside up to a certain length (of four nucleotides by default). Longer strands are followed indirectly, by tracking the concentrations of their containing sequence motifs of that maximum length.",
          "authors": [
            "Johannes Harth-Kitzerow",
            "Ulrich Gerland",
            "Torsten A. Enßlin"
          ],
          "primary_category": "physics.bio-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02204",
          "title": "MoRSAIK: Sequence Motif Reactor Simulation, Analysis and Inference Kit in Python",
          "abstract": "Origins of life research investigates how life could emerge from prebiotic chemistry only. One possible explanation provides the RNA world hypothesis. It states that life could emerge from RNA strands only, storing and transferring biological information, as well as catalyzing reactions as ribozymes. Before this state could have emerged, however, the prebiotic world was probably a purely chemical pool of short RNA strands with random sequences and without biological function performing hybridization and dehybridization, as well as ligation and cleavage. In this context relevant questions are what are the conditions that allow longer RNA strands to be built and how can information carrying in RNA sequence emerge? In order to investigate such RNA reactors, efficient simulations are needed because the space of possible RNA sequences increases exponentially with the length of the strands, as well as the number of reactions between two strands. In addition, simulations have to be compared to experimental data for validation and parameter calibration. Here, we present the MoRSAIK python package for sequence motif (or k-mer) reactor simulation, analysis and inference. It enables users to simulate RNA sequence motif dynamics in the mean field approximation as well as to infer the reaction parameters from data with Bayesian methods and to analyze results by computing observables and plotting. MoRSAIK simulates an RNA reactor by following the reactions and the concentrations of all strands inside up to a certain length (of four nucleotides by default). Longer strands are followed indirectly, by tracking the concentrations of their containing sequence motifs of that maximum length.",
          "authors": [
            "Johannes Harth-Kitzerow",
            "Ulrich Gerland",
            "Torsten A. Enßlin"
          ],
          "primary_category": "physics.bio-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ],
          "primary_category": "q-bio.MN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ],
          "primary_category": "q-bio.MN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ],
          "primary_category": "q-bio.MN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02478",
          "title": "Simulation and inference methods for non-Markovian stochastic biochemical reaction networks",
          "abstract": "Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.",
          "authors": [
            "Thomas P. Steele",
            "David J. Warne"
          ],
          "primary_category": "q-bio.MN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02528",
          "title": "Assessment of Simulation-based Inference Methods for Stochastic Compartmental Models",
          "abstract": "Global pandemics, such as the recent COVID-19 crisis, highlight the need for stochastic epidemic models that can capture the randomness inherent in the spread of disease. Such models must be accompanied by methods for estimating parameters in order to generate fast nowcasts and short-term forecasts that can inform public health decisions. This paper presents a comparison of two advanced Bayesian inference methods: 1) pseudo-marginal particle Markov chain Monte Carlo, short Particle Filters (PF), and 2) Conditional Normalizing Flows (CNF). We investigate their performance on two commonly used compartmental models: a classical Susceptible-Infected-Recovered (SIR) model and a two-variant Susceptible-Exposed-Infected-Recovered (SEIR) model, complemented by an observation model that maps latent trajectories to empirical data. Addressing the challenges of intractable likelihoods for parameter inference in stochastic settings, our analysis highlights how these likelihood-free methods provide accurate and robust inference capabilities. The results of our simulation study further underscore the effectiveness of these approaches in capturing the stochastic dynamics of epidemics, providing prediction capabilities for the control of epidemic outbreaks. Results on an Ethiopian cohort study demonstrate operational robustness under real-world noise and irregular data sampling. To facilitate reuse and to enable building pipelines that ultimately contribute to better informed decision making in public health, we make code and synthetic datasets publicly available.",
          "authors": [
            "Vincent Wieland",
            "Nils Wassmuth",
            "Lorenzo Contento",
            "Martin Kühn",
            "Jan Hasenauer"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02908",
          "title": "Imperfect molecular detection renormalizes apparent kinetic rates in stochastic gene regulatory networks",
          "abstract": "Imperfect molecular detection in single-cell experiments introduces technical noise that obscures the true stochastic dynamics of gene regulatory networks. While binomial models of molecular capture provide a principled description of imperfect detection, they have so far been analyzed only for simple gene-expression models that do not explicitly account for regulation. Here, we extend binomial models of capture to general gene regulatory networks to understand how imperfect capture reshapes the observed time-dependent statistics of molecular counts. Our results reveal when capture effects correspond to a renormalization of a subset of the kinetic rates and when they cannot be absorbed into effective rates, providing a systematic basis for interpreting noisy single-cell measurements. In particular, we show that rate renormalization emerges either under significant transcription factor abundance or when promoter-state transitions occur on a distinct (much slower or faster) timescale than other reactions. In these cases, technical noise causes the apparent mean burst size of synthesized gene products to appear reduced while transcription factor binding reactions appear faster. These effects hold for gene regulatory networks of arbitrary connectivity and remain valid under time-dependent kinetic rates.",
          "authors": [
            "Iryna Zabaikina",
            "Ramon Grima"
          ],
          "primary_category": "q-bio.MN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 6,
      "size": 830,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:1112.2297",
          "title": "Stability of Synchronized Motion in Complex Networks",
          "abstract": "We give a succinct and self-contained description of the synchronized motion on networks of mutually coupled oscillators. Usually, the stability criterion for the stability of synchronized motion is obtained in terms of Lyapunov exponents. We consider the fully diffusive case which is amenable to treatment in terms of uniform contractions. This approach provides a rigorous, yet clear and concise, way to the important results.",
          "primary_category": "nlin.AO",
          "authors": [
            "Tiago Pereira"
          ]
        },
        {
          "id": "arXiv:2512.02477",
          "title": "Qudits offer no advantages over dits for sending random messages",
          "abstract": "We consider the following simple scenario: Alice has one of many possible messages, drawn from a known distribution, and wants to maximize the probability that Bob guesses her message correctly. We prove that if Alice can send only a qudit to Bob, without preshared entanglement, there is never any advantage over sending him a classical dit. This result was previously known only for a uniform distribution. We also prove a mixed-state generalization of this result in the form of an upper bound on the success probability of discriminating between mixed quantum states with a single measurement. This bound is based solely on the dimension, probability distribution, and eigenvalues of the states and is sharp among such bounds.",
          "primary_category": "quant-ph",
          "authors": [
            "Ronit Shah"
          ]
        },
        {
          "id": "arXiv:2512.02479",
          "title": "Orbital-resolved three-body recombination across a p-wave Feshbach resonance in ultracold $^6$Li",
          "abstract": "We report precision, orbital-resolved measurements of three-body recombination near the 159~G $p$-wave Feshbach resonance in an ultracold gas of $^{6}$Li atoms prepared in their lowest hyperfine state. Using a radio-frequency gated protocol that suppresses magnetic-field transients below the milligauss level, we resolve loss features associated with the $|m_\\ell|=1$ and $m_\\ell=0$ orbital projections. The measured three-body loss coefficient $L_3$ is well captured by a thermally averaged cascade-recombination model, enabling extraction of the resonance splitting $\\delta B$ and effective-range parameter $k_e$. At the lowest temperature, we obtain $\\delta B = 7.6(3)$~mG and $k_e = 0.151(6)\\,a_0^{-1}$, both in quantitative agreement with coupled-channel theory. These results establish orbital-resolved three-body spectroscopy as a precision probe of $p$-wave scattering and provide a benchmark for microscopic models of resonant few-body loss.",
          "primary_category": "cond-mat.quant-gas",
          "authors": [
            "Shaokun Liu",
            "Zhekang Xu",
            "Shuai Peng",
            "Sijia Peng",
            "Tangqian Shu",
            "Jiaming Li",
            "Le Luo"
          ]
        },
        {
          "id": "arXiv:2512.02488",
          "title": "Translational symmetry breaking in the electronic nematic phase of BaFe2As2",
          "abstract": "The microscopic origin of the nematicity, namely, four-fold rotational symmetry breaking in iron-based superconductors has been controversial since its discovery. In particular, its relationship with the stripe-type spin-density-wave order and the orthorhombic lattice distortion in the antiferromagnetic orthorhombic (AFO) phase, which exists at temperatures below the electronic nematic phase, has been highly debated. Here, we report on the temperature evolution of angle-resolved photoemission spectra of the parent compound BaFe2As2, ranging from the AFO to nematic to paramagnetic phases. The Dirac cone feature, which is formed in the AFO phase, is found to persist in the nematic phase, suggesting that an antiferroic order of the same periodicity as the AFO phase persists in the nematic phase. Considering the relatively shallow d_xy orbital in BaFe2As2, we propose that an antiferro-orbital order involving the d_xy and other orbitals takes place in the nematic phase.",
          "primary_category": "cond-mat.supr-con",
          "authors": [
            "K. Koshiishi",
            "L. Liu",
            "K. Okazaki",
            "H. Suzuki",
            "J. Xu",
            "M. Horio",
            "H. Kumigashira",
            "K. Ono",
            "M. Nakajima",
            "S. Ishida",
            "K. Kihou",
            "C. H. Lee",
            "A. Iyo",
            "H. Eisaki",
            "S. Uchida",
            "A. Fujimori"
          ]
        },
        {
          "id": "arXiv:2512.02490",
          "title": "Quasi-steady electron-excitonic complexes coupling in a two-dimensional semiconductor",
          "abstract": "Excitons and their complexes govern optical-related behaviors in semiconductors. Here, using angle-resolved photoemission spectroscopy (ARPES), we have elucidated the light-matter interaction mediated by quasi-steady excitonic complexes within a monolayer of the prototypical two-dimensional (2D) semiconductor WSe2. Under continuous incident light, we have observed the generation of quasi-steady excitons and their complexes, encompassing ground and excited state excitons, trions, as well as their intricate interplay. We further show spectral evidence of electronic excitation states within the background of quasi-steady excitonic complexes, characterized by valence band (VB) effective mass renormalization, the enhanced spin-orbit coupling (SOC), the formation of an excitonic gap near the Fermi level (EF ) of the conduction band (CB), and intervalley excitonic band folding. Our findings not only unveil a quasi-steady excitonic complex background for the creation of diverse electronic excitations in 2D semiconductors but also offer new insights into the role of excitons in the charge density wave (CDW) formation mechanism and facilitate the advancement of correlated electronic state engineering based on the coupling between electrons and excitonic complexes in a quasi-equilibrium state.",
          "primary_category": "cond-mat.str-el",
          "authors": [
            "Shangkun Mo",
            "Hao Zhong",
            "Keming Zhao",
            "Yunfei Bai",
            "Dingkun Qin",
            "Chunlong Wu",
            "Qiang Wan",
            "Renzhe Li",
            "Cao Peng",
            "Xingzhe Wang",
            "Enting Li",
            "Sheng Meng",
            "Nan Xu"
          ]
        },
        {
          "id": "arXiv:2512.02493",
          "title": "Superchannel without Tears: A Generalized Occam's Razor for Quantum Processes",
          "abstract": "Quantum channels function as the operational primitives of quantum theory, while superchannels describe the most general transformations acting upon them. Yet the prevailing framework for superchannels is both internally inconsistent, owing to the coexistence of distinct Choi operator constructions, and structurally incomplete, lacking the analogue of representations that ground channel theory. We resolve these issues by combining tensor-network methods with a generalized Occam's razor introduced here, establishing a unified foundation for superchannels. Our framework establishes the connections between competing Choi formulations, develops the Kraus, Stinespring, and Liouville representations for superchannels, and provides a simplified derivation of the realization theorem that identifies the minimal memory required to implement a given transformation. These structural tools also enable characterizations of superchannels that destroy quantum correlations or causal structure, opening a systematic route to non-Markovian quantum dynamics.",
          "primary_category": "quant-ph",
          "authors": [
            "Yunlong Xiao"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:1112.2297",
          "title": "Stability of Synchronized Motion in Complex Networks",
          "abstract": "We give a succinct and self-contained description of the synchronized motion on networks of mutually coupled oscillators. Usually, the stability criterion for the stability of synchronized motion is obtained in terms of Lyapunov exponents. We consider the fully diffusive case which is amenable to treatment in terms of uniform contractions. This approach provides a rigorous, yet clear and concise, way to the important results.",
          "authors": [
            "Tiago Pereira"
          ],
          "primary_category": "nlin.AO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:1112.2297",
          "title": "Stability of Synchronized Motion in Complex Networks",
          "abstract": "We give a succinct and self-contained description of the synchronized motion on networks of mutually coupled oscillators. Usually, the stability criterion for the stability of synchronized motion is obtained in terms of Lyapunov exponents. We consider the fully diffusive case which is amenable to treatment in terms of uniform contractions. This approach provides a rigorous, yet clear and concise, way to the important results.",
          "authors": [
            "Tiago Pereira"
          ],
          "primary_category": "nlin.AO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:1112.2297",
          "title": "Stability of Synchronized Motion in Complex Networks",
          "abstract": "We give a succinct and self-contained description of the synchronized motion on networks of mutually coupled oscillators. Usually, the stability criterion for the stability of synchronized motion is obtained in terms of Lyapunov exponents. We consider the fully diffusive case which is amenable to treatment in terms of uniform contractions. This approach provides a rigorous, yet clear and concise, way to the important results.",
          "authors": [
            "Tiago Pereira"
          ],
          "primary_category": "nlin.AO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:1512.08473",
          "title": "Shotgun assembly of random regular graphs",
          "abstract": "Mossel and Ross (2019) introduce the shotgun assembly problem for random graphs: what radius $R$ ensures that the random graph $G$ can be uniquely recovered from its list of rooted $R$-neighborhoods, with high probability? Here we consider this question for random regular graphs of fixed degree $d\\ge3$. A result of Bollobás (1982) implies efficient recovery at $R = (1 + \\epsilon) \\frac12 \\log_{d-1}n$ with high probability -- moreover, this recovery algorithm uses only a summary of the distances in each neighborhood. We show that using the full neighborhood structure gives a sharper bound \\[ R = \\frac{\\log n + \\log\\log n}{2\\log(d-1)} + O(1)\\,, \\] which we prove is tight up to the $O(1)$ term. One consequence of our proof is that if $G,H$ are independent graphs where $G$ follows the random regular law, then with high probability the graphs are non-isomorphic; furthermore, this can be efficiently certified by testing the $R$-neighborhood list of $H$ against the $R$-neighborhood of a single adversarially chosen vertex of $G$.",
          "authors": [
            "Brice Huang",
            "Elchanan Mossel",
            "Nike Sun",
            "Claire Zhang",
            "Leqi Zhou"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2102.13372",
          "title": "A stable $\\infty$-category for equivariant $KK$-theory",
          "abstract": "For a countable group $G$ we construct a small, idempotent complete, symmetric monoidal, stable $\\infty$-category $\\mathrm{KK}^{G}_{\\mathrm{sep}}$ whose homotopy category recovers the triangulated equivariant Kasparov category of separable $G$-$C^*$-algebras, and exhibit its universal property. Likewise, we consider an associated presentably symmetric monoidal, stable $\\infty$-category $\\mathrm{KK}^{G}$ which receives a symmetric monoidal functor $\\mathrm{kk}^{G}$ from possibly non-separable $G$-$C^*$-algebras and discuss its universal property. In addition to the symmetric monoidal structures, we construct various change-of-group functors relating these KK-categories for varying $G$. We use this to define and establish key properties of a (spectrum valued) equivariant, locally finite $K$-homology theory on proper and locally compact $G$-topological spaces, allowing for coefficients in arbitrary $G$-$C^*$-algebras. Finally, we extend the functor $\\mathrm{kk}^{G}$ from $G$-$C^*$-algebras to $G$-$C^*$-categories. These constructions are key in a companion paper about a form of equivariant Paschke duality and assembly maps.",
          "authors": [
            "Ulrich Bunke",
            "Alexander Engel",
            "Markus Land"
          ],
          "primary_category": "math.OA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.05304",
          "title": "Spin conductivity of the XXZ chain in the antiferromagnetic massive regime",
          "abstract": "We present a series representation for the dynamical two-point function of the local spin current for the XXZ chain in the antiferromagnetic massive regime at zero temperature. From this series we can compute the correlation function with very high accuracy up to very long times and large distances. Each term in the series corresponds to the contribution of all scattering states of an even number of excitations. These excitations can be interpreted in terms of an equal number of particles and holes. The lowest term in the series comprises all scattering states of one hole and one particle. This term determines the long-time large-distance asymptotic behaviour which can be obtained explicitly from a saddle-point analysis. The space-time Fourier transform of the two-point function of currents at zero momentum gives the optical spin conductivity of the model. We obtain highly accurate numerical estimates for this quantity by numerically Fourier transforming our data. For the one-particle, one-hole contribution, equivalently interpreted as a two-spinon contribution, we obtain an exact and explicit expression in terms of known special functions. For large enough anisotropy, the two-spinon contribution carries most of the spectral weight, as can be seen by calculating the f-sum rule.",
          "authors": [
            "Frank Göhmann",
            "Karol K. Kozlowski",
            "Jesko Sirker",
            "Junji Suzuki"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.05304",
          "title": "Spin conductivity of the XXZ chain in the antiferromagnetic massive regime",
          "abstract": "We present a series representation for the dynamical two-point function of the local spin current for the XXZ chain in the antiferromagnetic massive regime at zero temperature. From this series we can compute the correlation function with very high accuracy up to very long times and large distances. Each term in the series corresponds to the contribution of all scattering states of an even number of excitations. These excitations can be interpreted in terms of an equal number of particles and holes. The lowest term in the series comprises all scattering states of one hole and one particle. This term determines the long-time large-distance asymptotic behaviour which can be obtained explicitly from a saddle-point analysis. The space-time Fourier transform of the two-point function of currents at zero momentum gives the optical spin conductivity of the model. We obtain highly accurate numerical estimates for this quantity by numerically Fourier transforming our data. For the one-particle, one-hole contribution, equivalently interpreted as a two-spinon contribution, we obtain an exact and explicit expression in terms of known special functions. For large enough anisotropy, the two-spinon contribution carries most of the spectral weight, as can be seen by calculating the f-sum rule.",
          "authors": [
            "Frank Göhmann",
            "Karol K. Kozlowski",
            "Jesko Sirker",
            "Junji Suzuki"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.05304",
          "title": "Spin conductivity of the XXZ chain in the antiferromagnetic massive regime",
          "abstract": "We present a series representation for the dynamical two-point function of the local spin current for the XXZ chain in the antiferromagnetic massive regime at zero temperature. From this series we can compute the correlation function with very high accuracy up to very long times and large distances. Each term in the series corresponds to the contribution of all scattering states of an even number of excitations. These excitations can be interpreted in terms of an equal number of particles and holes. The lowest term in the series comprises all scattering states of one hole and one particle. This term determines the long-time large-distance asymptotic behaviour which can be obtained explicitly from a saddle-point analysis. The space-time Fourier transform of the two-point function of currents at zero momentum gives the optical spin conductivity of the model. We obtain highly accurate numerical estimates for this quantity by numerically Fourier transforming our data. For the one-particle, one-hole contribution, equivalently interpreted as a two-spinon contribution, we obtain an exact and explicit expression in terms of known special functions. For large enough anisotropy, the two-spinon contribution carries most of the spectral weight, as can be seen by calculating the f-sum rule.",
          "authors": [
            "Frank Göhmann",
            "Karol K. Kozlowski",
            "Jesko Sirker",
            "Junji Suzuki"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.05304",
          "title": "Spin conductivity of the XXZ chain in the antiferromagnetic massive regime",
          "abstract": "We present a series representation for the dynamical two-point function of the local spin current for the XXZ chain in the antiferromagnetic massive regime at zero temperature. From this series we can compute the correlation function with very high accuracy up to very long times and large distances. Each term in the series corresponds to the contribution of all scattering states of an even number of excitations. These excitations can be interpreted in terms of an equal number of particles and holes. The lowest term in the series comprises all scattering states of one hole and one particle. This term determines the long-time large-distance asymptotic behaviour which can be obtained explicitly from a saddle-point analysis. The space-time Fourier transform of the two-point function of currents at zero momentum gives the optical spin conductivity of the model. We obtain highly accurate numerical estimates for this quantity by numerically Fourier transforming our data. For the one-particle, one-hole contribution, equivalently interpreted as a two-spinon contribution, we obtain an exact and explicit expression in terms of known special functions. For large enough anisotropy, the two-spinon contribution carries most of the spectral weight, as can be seen by calculating the f-sum rule.",
          "authors": [
            "Frank Göhmann",
            "Karol K. Kozlowski",
            "Jesko Sirker",
            "Junji Suzuki"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2203.02539",
          "title": "Linear and nonlinear edge dynamics of trapped fractional quantum Hall droplets",
          "abstract": "We report numerical studies of the linear and nonlinear edge dynamics of a non-harmonically confined macroscopic fractional quantum Hall fluid. In the long-wavelength and weak excitation limit, observable consequences of the fractional transverse conductivity are recovered. The first non-universal corrections to the chiral Luttinger liquid theory are then characterized: for a weak excitation in the linear response regime, cubic corrections to the linear wave dispersion and a broadening of the dynamical structure factor of the edge excitations are identified; for stronger excitations, sizable nonlinear effects are found in the dynamics. The numerically observed features are quantitatively captured by a nonlinear chiral Luttinger liquid quantum Hamiltonian that reduces to a driven Korteweg-de Vries equation in the semiclassical limit. Experimental observability of our predictions is finally discussed.",
          "authors": [
            "Alberto Nardin",
            "Iacopo Carusotto"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2203.02539",
          "title": "Linear and nonlinear edge dynamics of trapped fractional quantum Hall droplets",
          "abstract": "We report numerical studies of the linear and nonlinear edge dynamics of a non-harmonically confined macroscopic fractional quantum Hall fluid. In the long-wavelength and weak excitation limit, observable consequences of the fractional transverse conductivity are recovered. The first non-universal corrections to the chiral Luttinger liquid theory are then characterized: for a weak excitation in the linear response regime, cubic corrections to the linear wave dispersion and a broadening of the dynamical structure factor of the edge excitations are identified; for stronger excitations, sizable nonlinear effects are found in the dynamics. The numerically observed features are quantitatively captured by a nonlinear chiral Luttinger liquid quantum Hamiltonian that reduces to a driven Korteweg-de Vries equation in the semiclassical limit. Experimental observability of our predictions is finally discussed.",
          "authors": [
            "Alberto Nardin",
            "Iacopo Carusotto"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2203.08905",
          "title": "Probing confinement in a $\\mathbb{Z}_2$ lattice gauge theory on a quantum computer",
          "abstract": "Gauge theories describe the fundamental forces in the standard model of particle physics and play an important role in condensed matter physics. The constituents of gauge theories, for example charged matter and electric gauge field, are governed by local gauge constraints, which lead to key phenomena such as confinement of particles that are not fully understood. In this context, quantum simulators may address questions that are challenging for classical methods. While engineering gauge constraints is highly demanding, recent advances in quantum computing are beginning to enable digital quantum simulations of gauge theories. Here, we simulate confinement dynamics in a $\\mathbb{Z}_2$ lattice gauge theory on a superconducting quantum processor. Tuning a term that couples only to the electric field produces confinement of charges, a manifestation of the tight bond that the gauge constraint generates between both. Moreover, we show how a modification of the gauge constraint from $\\mathbb{Z}_2$ towards $\\mathrm{U}(1)$ symmetry freezes the system dynamics. Our work illustrates the restriction that the underlying gauge constraint imposes on the dynamics of a lattice gauge theory, it showcases how gauge constraints can be modified and protected, and it promotes the study of other models governed by multi-body interactions.",
          "authors": [
            "Julius Mildenberger",
            "Wojciech Mruczkiewicz",
            "Jad C. Halimeh",
            "Zhang Jiang",
            "Philipp Hauke"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2203.08905",
          "title": "Probing confinement in a $\\mathbb{Z}_2$ lattice gauge theory on a quantum computer",
          "abstract": "Gauge theories describe the fundamental forces in the standard model of particle physics and play an important role in condensed matter physics. The constituents of gauge theories, for example charged matter and electric gauge field, are governed by local gauge constraints, which lead to key phenomena such as confinement of particles that are not fully understood. In this context, quantum simulators may address questions that are challenging for classical methods. While engineering gauge constraints is highly demanding, recent advances in quantum computing are beginning to enable digital quantum simulations of gauge theories. Here, we simulate confinement dynamics in a $\\mathbb{Z}_2$ lattice gauge theory on a superconducting quantum processor. Tuning a term that couples only to the electric field produces confinement of charges, a manifestation of the tight bond that the gauge constraint generates between both. Moreover, we show how a modification of the gauge constraint from $\\mathbb{Z}_2$ towards $\\mathrm{U}(1)$ symmetry freezes the system dynamics. Our work illustrates the restriction that the underlying gauge constraint imposes on the dynamics of a lattice gauge theory, it showcases how gauge constraints can be modified and protected, and it promotes the study of other models governed by multi-body interactions.",
          "authors": [
            "Julius Mildenberger",
            "Wojciech Mruczkiewicz",
            "Jad C. Halimeh",
            "Zhang Jiang",
            "Philipp Hauke"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2203.08905",
          "title": "Probing confinement in a $\\mathbb{Z}_2$ lattice gauge theory on a quantum computer",
          "abstract": "Gauge theories describe the fundamental forces in the standard model of particle physics and play an important role in condensed matter physics. The constituents of gauge theories, for example charged matter and electric gauge field, are governed by local gauge constraints, which lead to key phenomena such as confinement of particles that are not fully understood. In this context, quantum simulators may address questions that are challenging for classical methods. While engineering gauge constraints is highly demanding, recent advances in quantum computing are beginning to enable digital quantum simulations of gauge theories. Here, we simulate confinement dynamics in a $\\mathbb{Z}_2$ lattice gauge theory on a superconducting quantum processor. Tuning a term that couples only to the electric field produces confinement of charges, a manifestation of the tight bond that the gauge constraint generates between both. Moreover, we show how a modification of the gauge constraint from $\\mathbb{Z}_2$ towards $\\mathrm{U}(1)$ symmetry freezes the system dynamics. Our work illustrates the restriction that the underlying gauge constraint imposes on the dynamics of a lattice gauge theory, it showcases how gauge constraints can be modified and protected, and it promotes the study of other models governed by multi-body interactions.",
          "authors": [
            "Julius Mildenberger",
            "Wojciech Mruczkiewicz",
            "Jad C. Halimeh",
            "Zhang Jiang",
            "Philipp Hauke"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2203.08905",
          "title": "Probing confinement in a $\\mathbb{Z}_2$ lattice gauge theory on a quantum computer",
          "abstract": "Gauge theories describe the fundamental forces in the standard model of particle physics and play an important role in condensed matter physics. The constituents of gauge theories, for example charged matter and electric gauge field, are governed by local gauge constraints, which lead to key phenomena such as confinement of particles that are not fully understood. In this context, quantum simulators may address questions that are challenging for classical methods. While engineering gauge constraints is highly demanding, recent advances in quantum computing are beginning to enable digital quantum simulations of gauge theories. Here, we simulate confinement dynamics in a $\\mathbb{Z}_2$ lattice gauge theory on a superconducting quantum processor. Tuning a term that couples only to the electric field produces confinement of charges, a manifestation of the tight bond that the gauge constraint generates between both. Moreover, we show how a modification of the gauge constraint from $\\mathbb{Z}_2$ towards $\\mathrm{U}(1)$ symmetry freezes the system dynamics. Our work illustrates the restriction that the underlying gauge constraint imposes on the dynamics of a lattice gauge theory, it showcases how gauge constraints can be modified and protected, and it promotes the study of other models governed by multi-body interactions.",
          "authors": [
            "Julius Mildenberger",
            "Wojciech Mruczkiewicz",
            "Jad C. Halimeh",
            "Zhang Jiang",
            "Philipp Hauke"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2206.07358",
          "title": "The Complexity of Contracting Bipartite Graphs into Small Cycles",
          "abstract": "For a positive integer $\\ell \\geq 3$, the $C_\\ell$-Contractibility problem takes as input an undirected simple graph $G$ and determines whether $G$ can be transformed into a graph isomorphic to $C_\\ell$ (the induced cycle on $\\ell$ vertices) using only edge contractions. Brouwer and Veldman [JGT 1987] showed that $C_4$-Contractibility is NP-complete in general graphs. It is easy to verify that $C_3$-Contractibility is polynomial-time solvable. Dabrowski and Paulusma [IPL 2017] showed that $C_{\\ell}$-Contractibility is \\NP-complete\\ on bipartite graphs for $\\ell = 6$ and posed as open problems the status of the problem when $\\ell$ is 4 or 5. In this paper, we show that both $C_5$-Contractibility and $C_4$-Contractibility are NP-complete on bipartite graphs.",
          "authors": [
            "R. Krithika",
            "Roohani Sharma",
            "Prafullkumar Tale"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2207.09148",
          "title": "A characterisation of orthomodular spaces by Sasaki maps",
          "abstract": "Given a Hilbert space $H$, the set $P(H)$ of one-dimensional subspaces of $H$ becomes an orthoset when equipped with the orthogonality relation $\\perp$ induced by the inner product on $H$. Here, an \\emph{orthoset} is a pair $(X,\\perp)$ of a set $X$ and a symmetric, irreflexive binary relation $\\perp$ on $X$. In this contribution, we investigate what conditions on an orthoset $(X,\\perp)$ are sufficient to conclude that the orthoset is isomorphic to $(P(H),\\perp)$ for some orthomodular space $H$, where \\emph{orthomodular spaces} are linear spaces that generalize Hilbert spaces. In order to achieve this goal, we introduce \\emph{Sasaki maps} on orthosets, which are strongly related to Sasaki projections on orthomodular lattices. We show that any orthoset $(X,\\perp)$ with sufficiently many Sasaki maps is isomorphic to $(P(H),\\perp)$ for some orthomodular space, and we give more conditions on $(X,\\perp)$ to assure that $H$ is actually a Hilbert space over $\\mathbb R$, $\\mathbb C$ or $\\mathbb H$.",
          "authors": [
            "Bert Lindenhovius",
            "Thomas Vetterlein"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2207.09148",
          "title": "A characterisation of orthomodular spaces by Sasaki maps",
          "abstract": "Given a Hilbert space $H$, the set $P(H)$ of one-dimensional subspaces of $H$ becomes an orthoset when equipped with the orthogonality relation $\\perp$ induced by the inner product on $H$. Here, an \\emph{orthoset} is a pair $(X,\\perp)$ of a set $X$ and a symmetric, irreflexive binary relation $\\perp$ on $X$. In this contribution, we investigate what conditions on an orthoset $(X,\\perp)$ are sufficient to conclude that the orthoset is isomorphic to $(P(H),\\perp)$ for some orthomodular space $H$, where \\emph{orthomodular spaces} are linear spaces that generalize Hilbert spaces. In order to achieve this goal, we introduce \\emph{Sasaki maps} on orthosets, which are strongly related to Sasaki projections on orthomodular lattices. We show that any orthoset $(X,\\perp)$ with sufficiently many Sasaki maps is isomorphic to $(P(H),\\perp)$ for some orthomodular space, and we give more conditions on $(X,\\perp)$ to assure that $H$ is actually a Hilbert space over $\\mathbb R$, $\\mathbb C$ or $\\mathbb H$.",
          "authors": [
            "Bert Lindenhovius",
            "Thomas Vetterlein"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2211.12936",
          "title": "Big Ramsey Degrees in Ultraproducts of Finite Structures",
          "abstract": "We develop a transfer principle of structural Ramsey theory from finite structures to ultraproducts. We show that under certain mild conditions, when a class of finite structures has finite small Ramsey degrees, under the (Generalized) Continuum Hypothesis the ultraproduct has finite big Ramsey degrees for internal colorings. The necessity of restricting to internal colorings is demonstrated by the example of the ultraproduct of finite linear orders. Under CH, this ultraproduct $\\fLL^*$ has, as a spine, $\\eta_1$, an uncountable analogue of the order type of rationals $\\eta$. Finite big Ramsey degrees for $\\eta$ were exactly calculated by Devlin in \\cite{Devlin}. It is immediate from \\cite{Tod87} that $\\eta_1$ fails to have finite big Ramsey degrees. Moreover, we extend Devlin's coloring to $\\eta_1$ to show that it witnesses big Ramsey degrees of finite tuples in $\\eta$ on every copy of $\\eta$ in $\\eta_1,$ and consequently in $\\fLL^*$. This work gives additional confirmation that ultraproducts are a suitable environment for studying Ramsey properties of finite and infinite structures.",
          "authors": [
            "Dana Bartošová",
            "Mirna Džamonja",
            "Rehana Patel",
            "Lynn Scow"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2212.02120",
          "title": "On the equivalence of binary cubic forms",
          "abstract": "We consider the question of determining whether two binary cubic forms over an arbitrary field $K$ whose characteristic is not $2$ or $3$ are equivalent under the actions of either GL$(2,K)$ or SL$(2,K)$, deriving two necessary and sufficient criteria for such equivalence in each case. One of these involves an algebraic invariant of binary cubic forms which we call the Cardano invariant, which is closely connected to classical formulas and also appears in the work of Bhargava et al. The second criterion is expressed in terms of the base field itself, and also gives explicit matrices in SL$(2,K)$ or GL$(2,K)$ transforming one cubic into the other, if any exist, in terms of the coefficients of bilinear factors of a bicovariant of the two cubics. We also consider automorphisms of a single binary cubic form, show how to use our results to test equivalence of binary cubic forms over an integral domain such as~$\\mathbb{Z}$, and briefly recall some connections between binary cubic forms and the arithmetic of elliptic curves. The methods used are elementary, and similar to those used in our earlier work with Fisher concerning equivalences between binary quartic forms.",
          "authors": [
            "J E Cremona"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2302.04142",
          "title": "The Nash-Tognoli theorem over the rationals and its version for isolated singularities",
          "abstract": "Let $\\mathbb{Q}$ be the field of rational numbers and let $X$ be a subset of $\\mathbb{R}^n$. We say that $X$ is $\\mathbb{Q}$-algebraic if it is the common zero set in $\\mathbb{R}^n$ of a family of polynomials in $\\mathbb{Q}[\\mathtt{x}_1,\\ldots,\\mathtt{x}_n]$. If $X$ is $\\mathbb{Q}$-algebraic and of dimension $d$, then we say that $X$ is $\\mathbb{Q}$-nonsingular if, for all $a\\in X$, there exist a neighborhood $U$ of $a$ in $\\mathbb{R}^n$ and $f_1,\\ldots,f_{n-d}\\in\\mathbb{Q}[\\mathtt{x}_1,\\ldots,\\mathtt{x}_n]$ such that $\\nabla f_1(a),\\ldots,\\nabla f_{n-d}(a)$ are linearly independent and $X\\cap U=\\{x\\in U:f_1(x)=0,\\cdots,f_{n-d}(x)=0\\}$. The celebrated Nash-Tognoli theorem asserts the following: if $M$ is a compact smooth manifold of dimension $d$ and $\\psi:M\\to\\mathbb{R}^{2d+1}$ is a smooth embedding, then $\\psi$ can be approximated by an arbitrarily close smooth embedding $\\phi:M\\to\\mathbb{R}^{2d+1}$ whose image $\\phi(M)$ is a nonsingular algebraic subset of $\\mathbb{R}^{2d+1}$. In this article, we prove that $\\phi$ can be chosen in such a way that $\\phi(M)$ is a $\\mathbb{Q}$-nonsingular $\\mathbb{Q}$-algebraic subset of $\\mathbb{R}^{2d+1}$. This guarantees for the first time that, up to smooth diffeomorphisms, every compact smooth manifold $M$ can be described both globally and locally by means of finitely many exact data, such as a finite system of generators of the ideal of polynomials in $\\mathbb{Q}[\\mathtt{x}_1,\\ldots,\\mathtt{x}_{2d+1}]$ vanishing on $\\phi(M)$. We extend our result to the singular setting by proving that every real algebraic set with finitely many singularities is semialgebraically homeomorphic to a $\\mathbb{Q}$-algebraic set with the same number of singularities.",
          "authors": [
            "Riccardo Ghiloni",
            "Enrico Savi"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2302.04522",
          "title": "Hardness of monadic second-order formulae over succinct graphs",
          "abstract": "Our main result is a succinct counterpoint to Courcelle's meta-theorem as follows: every cw-nontrivial monadic second-order (MSO) property is either NP-hard or coNP-hard over graphs given by succinct representations. Succint representations are Boolean circuits computing the adjacency relation. Cw-nontrivial properties are those which have infinitely many models and infinitely many countermodels with bounded cliquewidth. Moreover, we explore what happens when the cw-nontriviality condition is dropped and show that, under a reasonable complexity assumption, the previous dichotomy fails, even for questions expressible in first-order logic.",
          "authors": [
            "Guilhem Gamard",
            "Aliénor Goubault-Larrecq",
            "Pierre Guillon",
            "Pierre Ohlmann",
            "Kévin Perrot",
            "Guillaume Theyssier"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2302.13985",
          "title": "A remark on deformation of Gromov non-squeezing",
          "abstract": "Let $R,r$ be as in the classical Gromov non-squeezing theorem, and let $\\epsilon = (\\pi R ^{2} - \\pi r ^{2})/ \\pi r ^{2} $. We first conjecture that the Gromov non-squeezing phenomenon persists for deformations of the symplectic form on the range $C ^{0}$ (w.r.t. the standard metric) $\\epsilon $-nearby to the standard symplectic form. We prove this in some special cases, in particular when the dimension is four and when $R < \\sqrt 2 r$. Given such a perturbation, we can no longer compactify the range and hence the classical Gromov argument breaks down. Our main method consists of a certain trap idea for holomorphic curves, analogous to traps in dynamical systems.",
          "authors": [
            "Yasha Savelyev"
          ],
          "primary_category": "math.SG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2303.08382",
          "title": "Homogenization theory of random walks among deterministic conductances",
          "abstract": "We study the asymptotic distribution of random walks on $\\mathbb Z^d$ ($d\\ge1$) in deterministic reversible environments defined by an assignment of a positive conductance to each edge of $\\mathbb Z^d$. We identify a deterministic set of conductance configurations for which the walk obeys an Invariance Principle; i.e., converges in law to a non-degenerate Brownian motion under diffusive scaling of space and time. This set is closed under translations and zero-density perturbations and carries all ergodic conductance laws subject to certain moment conditions. The proofs rely on martingale approximations whose main step is the conversion of averages in time and physical space under the deterministic environment to those in a suitable stochastic counterpart. Our study sets up a framework for \"de-randomized homogenization\" of other motions in disordered media.",
          "authors": [
            "Marek Biskup"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2303.08382",
          "title": "Homogenization theory of random walks among deterministic conductances",
          "abstract": "We study the asymptotic distribution of random walks on $\\mathbb Z^d$ ($d\\ge1$) in deterministic reversible environments defined by an assignment of a positive conductance to each edge of $\\mathbb Z^d$. We identify a deterministic set of conductance configurations for which the walk obeys an Invariance Principle; i.e., converges in law to a non-degenerate Brownian motion under diffusive scaling of space and time. This set is closed under translations and zero-density perturbations and carries all ergodic conductance laws subject to certain moment conditions. The proofs rely on martingale approximations whose main step is the conversion of averages in time and physical space under the deterministic environment to those in a suitable stochastic counterpart. Our study sets up a framework for \"de-randomized homogenization\" of other motions in disordered media.",
          "authors": [
            "Marek Biskup"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2304.03114",
          "title": "Renormalization of a 1d quadratic Schr{ö}dinger model with additive noise",
          "abstract": "The study is devoted to the interpretation and wellposedness of the stochastic NLS model \\begin{equation*} (\\imath \\partial_t-\\Delta)u=|u|^2+\\dot{B}, \\quad u_0=0,\\quad \\quad t\\in \\mathbb{R}, \\ x\\in \\mathbb{T}, \\end{equation*} where $\\dot{B}$ stands for a space-time fractional noise with index $H=(H_0,H_1)$ in a subset of $(0,1)^{2}$. We first establish that in the situation where $0<2H_0+H_1\\leq 2$, the equation cannot be interpreted in a (classical) functional sense.\\\\ \\indent Our investigations then focus on the rough regime corresponding to the condition $\\frac74<2H_0+H_1\\leq 2$. In this specific case, we exhibit an \\textit{explicit} renormalization procedure allowing to restore the (local) convergence of the approximated solutions. We follow a pathwise-type approach emphasizing the distinction between the stochastic objects at the core of the dynamics and the general deterministic machinery.",
          "authors": [
            "Aurélien Deya",
            "Reika Fukuizumi",
            "Laurent Thomann"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2305.00291",
          "title": "Refermionized theory of the edge modes of a fractional quantum Hall cloud",
          "abstract": "Making use of refermionization techniques, we map the nonlinear chiral Luttinger liquid model of the edge modes of a spatially confined fractional quantum Hall cloud developed in our recent work [Phys. Rev. A 107, 033320 (2023)] onto a one-dimensional system of massive and interacting chiral fermions, whose mass and interactions are set by the filling factor of the quantum Hall fluid and the shape of the external confining potential at the position of the edge. As an example of the predictive power of the refermionized theory, we report a detailed study of the dynamic structure factor and of the spectral function of a fractional quantum Hall cloud. Among other features, our refermionized theory provides a physical understanding of the effective decay of the edge excitations and of the universal power-law exponents at the thresholds of the dynamic structure factor. The quantitative accuracy of the refermionized theory is validated against a full two-dimensional calculation based on a combination of exact diagonalization and Monte Carlo sampling.",
          "authors": [
            "Alberto Nardin",
            "Iacopo Carusotto"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2306.01486",
          "title": "Robust and scalable rf spectroscopy in first-order magnetic sensitive states at second-long coherence time",
          "abstract": "Trapped-ion quantum sensors have become highly sensitive tools for the search of physics beyond the Standard Model. Recently, stringent tests of local Lorentz-invariance (LLI) have been conducted with precision spectroscopy in trapped ions. We here elaborate on robust radio-frequency composite-pulse spectroscopy at second long coherence times in the magnetic sublevels of the long-lived $^{2}F_{7/2}$ state of a trapped $^{172}$Yb$^{+}$ ion which is scalable to spatially extended multi-ion systems. We compare two Ramsey-type composite rf pulse sequences, a GSE sequence and a UR10 that decouple the energy levels from magnetic field noise, enabling robust and accurate spectroscopy. Both sequences are characterized theoretically and experimentally in the spin-$1/2$\\ $^{2}S_{1/2}$ electronic ground state of $^{172}$Yb$^+$ and results show that the UR10 sequence is 38 (13) times more robust against pulse duration (frequency detuning) errors than the GSE sequence. We extend our simulations to the eight-level manifold of the $^2F_{7/2}$ state, which is highly sensitive to a possible violation of LLI, and show that the UR10 sequence can be used for high-fidelity Ramsey spectroscopy in noisy environments. The UR10 sequence is implemented experimentally in the $^2F_{7/2}$ manifold and a coherent signal of up to 2.5\\,s is reached. In reference we have implemented this sequence and used it to perform the most stringent test of LLI in the electron-photon sector to date with a single Yb$^{+}$ ion. Due to the high robustness of the UR10 sequence, it can be applied on larger ion crystals to improve tests of Lorentz symmetry further. We demonstrate that the sequence can also be used to extract the quadrupole moment of the meta-stable $^{2}F_{7/2}$ state, obtaining a value of $\\Theta\\,=\\,-0.0298(38)\\,ea^{2}_{0}$ which is in agreement with the value deduced from clock measurements.",
          "authors": [
            "C.-H. Yeh",
            "K. C. Grensemann",
            "L. S. Dreissen",
            "H. A. Fürst",
            "T. E. Mehlstäubler"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2306.01486",
          "title": "Robust and scalable rf spectroscopy in first-order magnetic sensitive states at second-long coherence time",
          "abstract": "Trapped-ion quantum sensors have become highly sensitive tools for the search of physics beyond the Standard Model. Recently, stringent tests of local Lorentz-invariance (LLI) have been conducted with precision spectroscopy in trapped ions. We here elaborate on robust radio-frequency composite-pulse spectroscopy at second long coherence times in the magnetic sublevels of the long-lived $^{2}F_{7/2}$ state of a trapped $^{172}$Yb$^{+}$ ion which is scalable to spatially extended multi-ion systems. We compare two Ramsey-type composite rf pulse sequences, a GSE sequence and a UR10 that decouple the energy levels from magnetic field noise, enabling robust and accurate spectroscopy. Both sequences are characterized theoretically and experimentally in the spin-$1/2$\\ $^{2}S_{1/2}$ electronic ground state of $^{172}$Yb$^+$ and results show that the UR10 sequence is 38 (13) times more robust against pulse duration (frequency detuning) errors than the GSE sequence. We extend our simulations to the eight-level manifold of the $^2F_{7/2}$ state, which is highly sensitive to a possible violation of LLI, and show that the UR10 sequence can be used for high-fidelity Ramsey spectroscopy in noisy environments. The UR10 sequence is implemented experimentally in the $^2F_{7/2}$ manifold and a coherent signal of up to 2.5\\,s is reached. In reference we have implemented this sequence and used it to perform the most stringent test of LLI in the electron-photon sector to date with a single Yb$^{+}$ ion. Due to the high robustness of the UR10 sequence, it can be applied on larger ion crystals to improve tests of Lorentz symmetry further. We demonstrate that the sequence can also be used to extract the quadrupole moment of the meta-stable $^{2}F_{7/2}$ state, obtaining a value of $\\Theta\\,=\\,-0.0298(38)\\,ea^{2}_{0}$ which is in agreement with the value deduced from clock measurements.",
          "authors": [
            "C.-H. Yeh",
            "K. C. Grensemann",
            "L. S. Dreissen",
            "H. A. Fürst",
            "T. E. Mehlstäubler"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2306.03300",
          "title": "Quantum Boltzmann dynamics and bosonized particle-hole interactions in fermion gases",
          "abstract": "In this paper, we study a cold gas of $N \\gg 1$ weakly interacting fermions. We describe the time evolution of states that are perturbations of the Fermi ball, and analyze the dynamics in particle-hole variables. Our main result states that, for small values of the coupling constant and for appropriate initial data, the effective dynamics of the momentum distribution is determined by a discrete collision operator of quantum Boltzmann form.",
          "authors": [
            "Esteban Cárdenas",
            "Thomas Chen"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2306.03300",
          "title": "Quantum Boltzmann dynamics and bosonized particle-hole interactions in fermion gases",
          "abstract": "In this paper, we study a cold gas of $N \\gg 1$ weakly interacting fermions. We describe the time evolution of states that are perturbations of the Fermi ball, and analyze the dynamics in particle-hole variables. Our main result states that, for small values of the coupling constant and for appropriate initial data, the effective dynamics of the momentum distribution is determined by a discrete collision operator of quantum Boltzmann form.",
          "authors": [
            "Esteban Cárdenas",
            "Thomas Chen"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2306.10726",
          "title": "First moment of central values of Hecke $L$-functions with Fixed Order Characters",
          "abstract": "We evaluate asymptotically the smoothed first moment of central values of families of quadratic, cubic, quartic and sextic Hecke $L$-functions over various imaginary quadratic number fields of class number one, using the method of double Dirichlet series. In particular, we obtain asymptotic formulas for the quadratic families with error terms of size $O(X^{1/4+\\varepsilon})$ under the generalized Riemann hypothesis.",
          "authors": [
            "Peng Gao",
            "Liangyi Zhao"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2307.05214",
          "title": "Theory of coherent interaction-free detection of pulses",
          "abstract": "Quantum physics allows an object to be detected even in the absence of photon absorption by the use of so-called interaction-free measurements. We provide a formulation of this protocol using a three-level system, where the object to be detected is a pulse coupled resonantly to the second transition. In the original formulation of interaction-free measurements, the absorption is associated with a projection operator onto the third state. We perform an in-depth analytical and numerical analysis of the coherent protocol, where coherent interaction between the object and the detector replaces the projective operators, resulting in higher detection efficiencies. We provide approximate asymptotic analytical results to support this finding. We find that our protocol reaches the Heisenberg limit when evaluating the Fisher information at small strengths of the pulses we aim to detect -- in contrast to the projective protocol that can only reach the standard quantum limit. We also demonstrate that the coherent protocol remains remarkably robust under errors such as pulse-rotation phases and strengths, the effects of relaxation rates and detunings, as well as different thermalized initial states.",
          "authors": [
            "John J. McCord",
            "Shruti Dogra",
            "Gheorghe Sorin Paraoanu"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2308.09627",
          "title": "Simplicial presheaves of Green complexes and twisting cochains",
          "abstract": "We construct three simplicial presheaves on the site of ringed spaces, and in particular on that of complex manifolds. The descent objects for these simplicial presheaves yield Toledo--Tong's twisting cochains, simplicial twisting cochains, and complexes that appear in Green's thesis on Chern classes for coherent analytic sheaves, respectively. We thus extend the aforementioned constructions to the equivariant setting, and more generally to stacks. This is the first step in achieving push-forwards in K-theory and Riemann--Roch theorems for appropriate stacks, as was achieved by Toledo and Tong for arbitrary complex manifolds, and further pursued by O'Brian and Green.",
          "authors": [
            "Timothy Hosgood",
            "Mahmoud Zeinalian"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2308.11024",
          "title": "Quantitative Transversal Theorems in the Plane",
          "abstract": "Hadwiger's theorem is a Helly-type theorem involving common transversals to families of convex sets instead of common intersections. Subsequently, Pollack and Wenger identified a necessary and sufficient condition, called a consistent $k$-ordering, for the existence of a hyperplane transversal for sets in $\\mathbb{R}^d$. We obtain a quantitative generalization of Hadwiger's theorem in $\\mathbb{R}^2$, showing that compact convex sets in $\\mathbb{R}^2$ with a quantitative version of consistent ordering have a transversal satisfying quantitative requirements. Our proof generalizes the methods in Wenger's proof of Hadwiger's theorem in $\\mathbb{R}^2$. We also prove colorful versions of our results.",
          "authors": [
            "Ilani Axelrod-Freed",
            "João Pedro Carvalho",
            "Yuki Takahashi"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2310.17400",
          "title": "Maslov Index, Spectral Flow and Bifurcation of Electromagnetic Geodesics Within an Energy Level",
          "abstract": "We develop appropriate notions of Maslov index and spectral flow for electromagnetic geodesics within a fixed energy level and prove a Morse Index type theorem in this context. This is then applied to the problem of electromagnetic geodesics, all of whose energy are the same, bifurcating from a given one.",
          "authors": [
            "Henrique Vitório"
          ],
          "primary_category": "math.CA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2311.00637",
          "title": "Analysis of the Single Reference Coupled Cluster Method for Electronic Structure Calculations: The Discrete Coupled Cluster Equations",
          "abstract": "Coupled cluster methods are widely regarded as the gold standard of computational quantum chemistry as they are perceived to offer the best compromise between computational cost and a high-accuracy resolution of the ground state eigenvalue of the electronic Hamiltonian -- an unbounded, self-adjoint operator acting on a Hilbert space of antisymmetric functions that describes electronic properties of molecular systems. The present contribution is the second in a series of two articles where we introduce a new numerical analysis of the single-reference coupled cluster method based on the invertibility of the coupled cluster Fréchet derivative. In this contribution, we study discretisations of the single-reference coupled cluster equations based on a prior mean-field (Hartree-Fock) calculation. We show that under some structural assumptions on the associated discretisation spaces and assuming that the discretisation is fine enough, the discrete coupled cluster equations are locally well-posed, and we derive a priori and residual-based a posteriori error estimates for the discrete coupled cluster solutions. Preliminary numerical experiments indicate that the structural assumptions that we impose for our analysis can be expected to hold for several small molecules and the theoretical constants that appear in our error estimates are an improvement over those obtained from earlier approaches.",
          "authors": [
            "Muhammad Hassan",
            "Yvon Maday"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2311.00637",
          "title": "Analysis of the Single Reference Coupled Cluster Method for Electronic Structure Calculations: The Discrete Coupled Cluster Equations",
          "abstract": "Coupled cluster methods are widely regarded as the gold standard of computational quantum chemistry as they are perceived to offer the best compromise between computational cost and a high-accuracy resolution of the ground state eigenvalue of the electronic Hamiltonian-- an unbounded, self-adjoint operator acting on a Hilbert space of antisymmetric functions that describes electronic properties of molecular systems. The present contribution is the second in a series of two articles where we introduce a new numerical analysis of the single-reference coupled cluster method based on the invertibility of the coupled cluster Fréchet derivative. In this contribution, we study discretisations of the single-reference coupled cluster equations based on a prior mean-field (Hartree-Fock) calculation. We show that under some structural assumptions on the associated discretisation spaces and assuming that the discretisation is fine enough, the discrete coupled cluster equations are locally well-posed, and we derive a priori and residual-based a posteriori error estimates for the discrete coupled cluster solutions. Preliminary numerical experiments indicate that the structural assumptions that we impose for our analysis can be expected to hold for several small molecules and the theoretical constants that appear in our error estimates are an improvement over those obtained from earlier approaches.",
          "authors": [
            "Muhammad Hassan",
            "Yvon Maday"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.02109",
          "title": "Prismatic crystals for smooth schemes in characteristic $p$ with Frobenius lifting mod $p^2$",
          "abstract": "Let $(A,(p))$ be a crystalline prism with $A_n = A/p^{n+1}A$ for all $n\\geq 0$. Let $\\frakX_0$ be a smooth scheme over $A_0$. Suppose that $\\frakX_0$ admits a lifting $\\frakX_n$ over $A_n$ and the absolute Frobenius $\\rF_{\\frakX_0}:\\frakX_0\\to \\frakX_0$ admits a lifting over $A_1$. Then we show that there is an equivalence between the category of the prismatic crystals of truncation $n$ on $(\\frakX_0/A)_{\\Prism}$ and the category of $p$-connections over $\\frakX_n$, which is compatible with cohomologies. This generalises a previous work of Ogus. We also give some remarks on trivializing the Hodge--Tate gerbe $\\pi_{\\frakX_0}^{\\rm HT}:\\frakX_0^{\\rm HT}\\to\\frakX_0$ introduced by Bhatt--Lurie.",
          "authors": [
            "Yupeng Wang"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.06241",
          "title": "Quantum Automorphism Group of Direct Sum of Cuntz Algebras",
          "abstract": "In this article, we explore the quantum symmetry of the direct sum of a finite family of Cuntz algebras $\\{\\mathcal{O}_{n_i} \\}_{i=1}^{m}$, viewing them as graph $C^*$-algebras associated to the graphs $\\{L_{n_i}\\}_{i=1}^{m}$ (where $L_n$ denotes the graph containing $n$ loops based at a single vertex), in the category introduced by Joardar and Mandal. It has been shown that the quantum automorphism group of the direct sum of non-isomorphic Cuntz algebras is ${U}_{n_1}^{+}*{U}_{n_2}^{+}* \\cdots *{U}_{n_m}^{+}$ for distinct $n_i$'s, i.e. \\begin{equation*} Q_{\\tau}^{Lin}(\\sqcup_{i=1}^{m} ~ L_{n_i}) \\cong *_{i=1}^{m} ~~ Q_{\\tau}^{Lin}(L_{n_i}) \\cong {U}_{n_1}^{+}*{U}_{n_2}^{+}* \\cdots *{U}_{n_m}^{+}, \\end{equation*} where $Q_{\\tau}^{Lin}(\\Gamma)$ denotes the quantum automorphism group of the graph $C^*$-algebra associated to $\\Gamma$. Also, the quantum automorphism group of the direct sum of $m$ copies of isomorphic Cuntz algebra $\\mathcal{O}_n$ is $U_n^+ \\wr_* S_m^+$, i.e. \\begin{equation*} Q_{\\tau}^{Lin}(\\sqcup_{i=1}^{m} ~ L_n) \\cong Q_{\\tau}^{Lin}(L_n) \\wr_* S_m^+ \\cong U_n^+ \\wr_* S_m^+. \\end{equation*} Furthermore, we have provided counter-examples to demonstrate that the isomorphisms mentioned above cannot be generalized to arbitrary graph $C^*$-algebras, whereas analogous relations can be extended in the context of quantum automorphism groups of graphs in the sense of Banica and Bichon.",
          "authors": [
            "Ujjal Karmakar",
            "Arnab Mandal"
          ],
          "primary_category": "math.OA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.12039",
          "title": "On Higher Topological T-duality Functors",
          "abstract": "We use String Field Theory (SFT) to construct a higher analogue of Bunke-Schick's functor $P: \\mathbf{Top}^{op} \\to \\mathbf{Set}$ \\cite{BunkeS1} by geometrizing $P.$ We use the projection of SFT onto its massless modes \\cite{SFTDiffeo} to construct the category $\\C$ whose objects are pairs (which we identify with SFT backgrounds) and whose maps are morphisms of pairs (which are gauge transformations). Using $\\C$ and categorical equivalence, for any $CW-$complex $X$ we define the moduli space $G(X)$ of SFT backgrounds which are pairs over $X$ up to gauge equivalence. We use the homotopy theory of the moduli space $G(X)$ to define functors on the category of $CW-$complexes $P_k:\\mathbf{CW}^{op} \\to \\mathbf{Grpd}$ such that $P_0 \\simeq P,$ $P_1$ is nontrivial and $P_k(X)$ are always trivial for $k \\geq 2.$ Arrows in $P_1(X)$ are shown to be isotopy classes of maps in the mapping class group of $X$ acting on (isomorphism classes of) pairs over $X.$ We discuss applications to Topological T-duality for triples and to modelling doubled geometries and T-folds \\cite{HullT}.",
          "authors": [
            "Ashwin S. Pande"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.12039",
          "title": "On Higher Topological T-duality Functors",
          "abstract": "We use String Field Theory (SFT) to construct a higher analogue of Bunke-Schick's functor $P: \\mathbf{Top}^{op} \\to \\mathbf{Set}$ \\cite{BunkeS1} by geometrizing $P.$ We use the projection of SFT onto its massless modes \\cite{SFTDiffeo} to construct the category $\\C$ whose objects are pairs (which we identify with SFT backgrounds) and whose maps are morphisms of pairs (which are gauge transformations). Using $\\C$ and categorical equivalence, for any $CW-$complex $X$ we define the moduli space $G(X)$ of SFT backgrounds which are pairs over $X$ up to gauge equivalence. We use the homotopy theory of the moduli space $G(X)$ to define functors on the category of $CW-$complexes $P_k:\\mathbf{CW}^{op} \\to \\mathbf{Grpd}$ such that $P_0 \\simeq P,$ $P_1$ is nontrivial and $P_k(X)$ are always trivial for $k \\geq 2.$ Arrows in $P_1(X)$ are shown to be isotopy classes of maps in the mapping class group of $X$ acting on (isomorphism classes of) pairs over $X.$ We discuss applications to Topological T-duality for triples and to modelling doubled geometries and T-folds \\cite{HullT}.",
          "authors": [
            "Ashwin S. Pande"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.12039",
          "title": "On Higher Topological T-duality Functors",
          "abstract": "We use String Field Theory (SFT) to construct a higher analogue of Bunke-Schick's functor $P: \\mathbf{Top}^{op} \\to \\mathbf{Set}$ \\cite{BunkeS1} by geometrizing $P.$ We use the projection of SFT onto its massless modes \\cite{SFTDiffeo} to construct the category $\\C$ whose objects are pairs (which we identify with SFT backgrounds) and whose maps are morphisms of pairs (which are gauge transformations). Using $\\C$ and categorical equivalence, for any $CW-$complex $X$ we define the moduli space $G(X)$ of SFT backgrounds which are pairs over $X$ up to gauge equivalence. We use the homotopy theory of the moduli space $G(X)$ to define functors on the category of $CW-$complexes $P_k:\\mathbf{CW}^{op} \\to \\mathbf{Grpd}$ such that $P_0 \\simeq P,$ $P_1$ is nontrivial and $P_k(X)$ are always trivial for $k \\geq 2.$ Arrows in $P_1(X)$ are shown to be isotopy classes of maps in the mapping class group of $X$ acting on (isomorphism classes of) pairs over $X.$ We discuss applications to Topological T-duality for triples and to modelling doubled geometries and T-folds \\cite{HullT}.",
          "authors": [
            "Ashwin S. Pande"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.06408",
          "title": "Module Categories As Spans",
          "abstract": "We establish a correspondence between modules and spans of algebras within a general monoidal 2-category $\\mathfrak{C}$. Specifically, for an algebra $A$ in $\\mathfrak{C}$, we construct a normalized lax 3-functor from the 2-category of $A$-modules to the 3-category of 2-spans of algebras in $\\mathfrak{C}$ under $A$. This framework unifies and generalizes the realization of module functors and module natural transformations as spans of monoidal functors. We demonstrate the utility of this theory by recovering the realization of module objects in several familiar 2-categories and discuss its extension to the 2-categories $\\mathbf{MCat}$ and $\\mathbf{BrCat}$. In these cases, module objects correspond to central module monoidal categories over a braided monoidal category and central braided monoidal categories over a symmetric monoidal category, respectively.",
          "authors": [
            "Hao Xu"
          ],
          "primary_category": "math.CT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.00654",
          "title": "Large deviations of current for the symmetric simple exclusion process on a semi-infinite line, and on an infinite line with a slow bond",
          "abstract": "Two influential exact results in classical one-dimensional diffusive transport are about current statistics for the symmetric simple exclusion process: one in the stationary state on a finite line coupled with two unequal reservoirs at the boundaries, and the other in the non-stationary state on an infinite line. We present the corresponding result for the intermediate geometry of a semi-infinite line coupled with a single reservoir. This result is obtained using the fluctuating hydrodynamics approach of macroscopic fluctuation theory and confirmed by rare event simulations using a cloning algorithm. We apply our exact result for solving several related challenging problems, namely, the full counting statistics in presence of a defect bond, exclusion process with localized injection, survival of a tagged particle in presence of an absorbing boundary, and the stretched exponential decay in a kinetically constrained model.",
          "authors": [
            "Kapil Sharma",
            "Soumyabrata Saha",
            "Sandeep Jangid",
            "Tridib Sadhu"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.00654",
          "title": "Large deviations of current for the symmetric simple exclusion process on a semi-infinite line, and on an infinite line with a slow bond",
          "abstract": "Two influential exact results in classical one-dimensional diffusive transport are about current statistics for the symmetric simple exclusion process: one in the stationary state on a finite line coupled with two unequal reservoirs at the boundaries, and the other in the non-stationary state on an infinite line. We present the corresponding result for the intermediate geometry of a semi-infinite line coupled with a single reservoir. This result is obtained using the fluctuating hydrodynamics approach of macroscopic fluctuation theory and confirmed by rare event simulations using a cloning algorithm. We apply our exact result for solving several related challenging problems, namely, the full counting statistics in presence of a defect bond, exclusion process with localized injection, survival of a tagged particle in presence of an absorbing boundary, and the stretched exponential decay in a kinetically constrained model.",
          "authors": [
            "Kapil Sharma",
            "Soumyabrata Saha",
            "Sandeep Jangid",
            "Tridib Sadhu"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.00654",
          "title": "Large deviations of current for the symmetric simple exclusion process on a semi-infinite line, and on an infinite line with a slow bond",
          "abstract": "Two influential exact results in classical one-dimensional diffusive transport are about current statistics for the symmetric simple exclusion process: one in the stationary state on a finite line coupled with two unequal reservoirs at the boundaries, and the other in the non-stationary state on an infinite line. We present the corresponding result for the intermediate geometry of a semi-infinite line coupled with a single reservoir. This result is obtained using the fluctuating hydrodynamics approach of macroscopic fluctuation theory and confirmed by rare event simulations using a cloning algorithm. We apply our exact result for solving several related challenging problems, namely, the full counting statistics in presence of a defect bond, exclusion process with localized injection, survival of a tagged particle in presence of an absorbing boundary, and the stretched exponential decay in a kinetically constrained model.",
          "authors": [
            "Kapil Sharma",
            "Soumyabrata Saha",
            "Sandeep Jangid",
            "Tridib Sadhu"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.14526",
          "title": "The formation of Schrodinger cat-like states in the process of spontaneous parametric down-conversion",
          "abstract": "In recent years, there has been an increased interest in the generation of superpositions of coherent states with opposite phases, the so-called photonic Schrodinger cat states. These experiments are challenging, and, so far, cats involving only small photon numbers have been implemented. Here, we propose to consider two-mode squeezed states as examples of Schrodinger cat-like states. For this, we apply criteria that aim to identify macroscopic superpositions in a more general sense. We extend some of these criteria to the two-mode continuous variable regime. Furthermore, we compare the size of states obtained in several experiments and discuss experimental challenges for further improvements. Our results not only promote two-mode squeezed states for exploring quantum effects at the macroscopic level but also provide direct measures to evaluate their usefulness for quantum metrology.",
          "authors": [
            "Ranjit Singh",
            "Alexander E. Teretenkov"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.18500",
          "title": "$L^{p}$-estimates, local well-posedness and controllability for linear and semilinear backward SPDEs",
          "abstract": "In this paper, we study linear backward parabolic SPDEs in bounded domains and present new a priori estimates for their weak solutions. Inspired by the seminal work of Y. Hu, J. Ma and J. Yong from 2002 on strong solutions, we establish $L^p$-estimates requiring minimal assumptions on the regularity of the coefficients, the terminal data, and the external force. Our approach relies on direct, constructive, and quantitative arguments, adapted from known methods in the theory of SPDEs to this setting. In particular, we develop a new Itô's formula for the $L^p$-norm of the backward solution, tailored to this setting and extending the classical result in the $L^2$-framework. This formula is then used to improve further the regularity of the first component of the solution up to $L^\\infty$. We also present two applications: a local existence result for a semilinear equation without imposing any growth condition on the nonlinear term, and a novel local controllability result for semilinear backward SPDEs that partially resolves an open problem in the field.",
          "authors": [
            "Víctor Hernández-Santamaría",
            "Kévin Le Balc'h",
            "Liliana Peralta"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2407.03553",
          "title": "Shrinking the Jung radius: Maximizing partial coverage of finite point sets",
          "abstract": "Jung's theorem says that planar sets of diameter $1$ can be covered by a closed circular disk of radius $\\frac 1{\\sqrt3}$. In this paper we consider a fractional Jung-type problem for finite planar point-sets. Let $\\mathcal{P}_n$ be the family of all finite sets of $n$ points in the plane, of diameter at most $1$. Let the function value $N_n(r)$ ($0 < r \\leq 1$) be the largest integer $k$ so that for every point set $P \\in \\mathcal{P}_n$ there is a closed circular disk of radius $r$ which covers at least $k$ points of $P$. We focus on the radii $r=\\frac 12$ and $r=\\frac 14$ and prove exact maximum values. Concerning the radius $r= \\frac 12$, we prove $N_n(\\frac{1}{2})=\\lceil \\frac{n}{3}\\rceil+1$. Concerning the radius $r= \\frac 14$, we prove that $N_{n}(\\frac{1}{4}) = \\lceil \\frac{n}{7}\\rceil$ if $n$ is not a multiple of 7, and $N_{n}(\\frac{1}{4})$ is $ \\frac{n}{7}$ or $ \\frac{n}{7}+1$ otherwise. We also initiate further study of the function $N_n(r)$ by giving lower and upper bounds for $N_n(r)$ ($0 < r < \\frac 1{\\sqrt3}$).",
          "authors": [
            "András Bezdek",
            "Owen Henderschedt"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2407.16801",
          "title": "Qudit Quantum Programming with Projective Cliffords",
          "abstract": "This paper introduces a novel abstraction for programming quantum operations, specifically projective Cliffords, as functions over the qudit Pauli group. Generalizing the idea behind Pauli tableaux, we introduce a type system and lambda calculus for projective Cliffords called LambdaPC, which captures well-formed Clifford operations via a Curry-Howard correspondence with a particular encoding of the Clifford and Pauli groups. Importantly, the language captures not just qubit operations, but qudit operations for any dimension $d$. Throughout the paper we explore what it means to program with projective Cliffords through a number of examples and a case study focusing on stabilizer error correcting codes.",
          "authors": [
            "Jennifer Paykin",
            "Sam Winnick"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2407.16801",
          "title": "Qudit Quantum Programming with Projective Cliffords",
          "abstract": "This paper introduces a novel abstraction for programming quantum operations, specifically projective Cliffords, as functions over the qudit Pauli group. Generalizing the idea behind Pauli tableaux, we introduce a type system and lambda calculus for projective Cliffords called LambdaPC, which captures well-formed Clifford operations via a Curry-Howard correspondence with a particular encoding of the Clifford and Pauli groups. Importantly, the language captures not just qubit operations, but qudit operations for any dimension $d$. Throughout the paper we explore what it means to program with projective Cliffords through a number of examples and a case study focusing on stabilizer error correcting codes.",
          "authors": [
            "Jennifer Paykin",
            "Sam Winnick"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.00464",
          "title": "Optimally robust shortcuts to population inversion in cat-state qubits",
          "abstract": "Cat-state qubits formed by photonic coherent states are a promising candidate for realizing fault-tolerant quantum computing. Such logic qubits have a biased noise channel that the bit-flip error dominates over all the other errors. In this manuscript, we propose an optimally robust protocol using the control method of shortcuts to adiabaticity to realize a nearly perfect population inversion in a cat-state qubit. We construct a shortcut based on the Lewis-Riesenfeld invariant and examine the stability versus different types of perturbations for the fast and robust population inversion. Numerical simulations demonstrate that the population inversion can be mostly insensitive to systematic errors in our protocol. Even when the parameter imperfection rate for bit-flip control is $20\\%$, the final population of the target state can still reach $\\geq 99\\%$. The optimally robust control provides a feasible method for fault-tolerant and scalable quantum computation.",
          "authors": [
            "Shao-Wei Xu",
            "Zhong-Zheng Zhang",
            "Yue-Ying Guo",
            "Ye-Hong Chen",
            "Yan Xia"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.04007",
          "title": "Reducing depth and measurement weights in Pauli-based computation",
          "abstract": "Pauli-based computation (PBC) is a universal measurement-based quantum computation model steered by an adaptive sequence of independent and compatible Pauli measurements on separable magic-state qubits. Here, we propose several new techniques for reducing the weight of the Pauli measurements and their associated \\textsc{cnot} complexity; we also demonstrate how to decrease this model's computational depth. We start by proving new upper bounds on the required weights and computational depth, obtained via a pre-compilation step. We also propose a heuristic algorithm that can contribute reductions of over 30\\% to the average weight of Pauli measurements (and associated \\textsc{cnot} count) when simulating and compiling Clifford-dominated random quantum circuits with up to 22 $T$ gates and over 20\\% for instances with larger $T$ counts. This PBC-compilation scheme, boosted by the heuristic algorithm, outperforms state-of-the-art compilers for the former circuits, reducing the \\textsc{cnot} count by 18\\% to 96\\% compared with the values achieved by other techniques. In contrast, for the latter circuits with larger $T$ counts, it leads to a number of \\textsc{cnot}s roughly 30\\% larger. Finally, inspired by known state-transfer methods, we introduce incPBC, a universal model for quantum computation requiring a larger number of (now incompatible) Pauli measurements of weight at most 2.",
          "authors": [
            "Filipa C. R. Peres",
            "Ernesto F. Galvão"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.05260",
          "title": "Fault-tolerant quantum input/output",
          "abstract": "Usual scenarios of fault-tolerant computation are concerned with the fault-tolerant realization of quantum algorithms that compute classical functions, such as Shor's algorithm for factoring. In particular, this means that input and output to the quantum algorithm are classical. In contrast to stand-alone single-core quantum computers, in many distributed scenarios, quantum information might have to be passed on from one quantum information processing system to another one, possibly via noisy quantum communication channels with noise levels above fault-tolerant thresholds. In such situations, quantum information processing devices will have quantum inputs, quantum outputs or even both, which pass qubits among each other. Working in the fault-tolerant framework of [Kitaev, 1997], we show that any quantum circuit with quantum input and output can be transformed into a fault-tolerant circuit that produces the ideal circuit with some controlled noise applied at the input and output. The framework allows the direct composition of the statements, enabling versatile future applications. We illustrate this with a concrete application, namely, communication over a noisy channel with faulty encoding and decoding operations [Christandl and M{ü}ller-Hermes, 2024]. For communication codes with linear minimum distance, we construct fault-tolerant encoders and decoders for general noise (including coherent errors). For the weaker, but standard, model of local stochastic noise, we obtain fault-tolerant encoders and decoders for any communication code that can correct a constant fraction random errors.",
          "authors": [
            "Matthias Christandl",
            "Omar Fawzi",
            "Ashutosh Goswami"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.16406",
          "title": "Improved Circuit Lower Bounds and Quantum-Classical Separations",
          "abstract": "We continue the study of the circuit class GC^0, which augments AC^0 with unbounded-fan-in gates that compute arbitrary functions inside a sufficiently small Hamming ball but must be constant outside it. While GC^0 can compute functions requiring exponential-size circuits, Kumar (CCC 2023) showed that switching-lemma lower bounds for AC^0 extend to GC^0 with no loss in parameters. We prove a parallel result for the polynomial method: any lower bound for AC^0[p] obtained via the polynomial method extends to GC^0[p] without loss in parameters. As a consequence, we show that the majority function MAJ requires depth-$d$ GC^0[p] circuits of size $2^{\\Omega(n^{1/2(d-1)})}$, matching the best-known lower bounds for AC^0[p]. This yields the most expressive class of non-monotone circuits for which exponential-size lower bounds are known for an explicit function. We also prove a similar result for the algorithmic method, showing that E^NP requires exponential-size GCC^0 circuits, extending a result of Williams (JACM 2014). Finally, leveraging our improved classical lower bounds, we establish the strongest known unconditional separations between quantum and classical circuit classes. We separate QNC^0 from GC^0 and GC^0[p] in various settings and show that BQLOGTIME is not contained in GC^0. As a consequence, we construct an oracle relative to which BQP lies outside uniform GC^0, extending the Raz-Tal oracle separation between BQP and PH (STOC 2019).",
          "authors": [
            "Sabee Grewal",
            "Vinayak M. Kumar"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.16406",
          "title": "Improved Circuit Lower Bounds and Quantum-Classical Separations",
          "abstract": "We continue the study of the circuit class GC^0, which augments AC^0 with unbounded-fan-in gates that compute arbitrary functions inside a sufficiently small Hamming ball but must be constant outside it. While GC^0 can compute functions requiring exponential-size circuits, Kumar (CCC 2023) showed that switching-lemma lower bounds for AC^0 extend to GC^0 with no loss in parameters. We prove a parallel result for the polynomial method: any lower bound for AC^0[p] obtained via the polynomial method extends to GC^0[p] without loss in parameters. As a consequence, we show that the majority function MAJ requires depth-$d$ GC^0[p] circuits of size $2^{\\Omega(n^{1/2(d-1)})}$, matching the best-known lower bounds for AC^0[p]. This yields the most expressive class of non-monotone circuits for which exponential-size lower bounds are known for an explicit function. We also prove a similar result for the algorithmic method, showing that E^NP requires exponential-size GCC^0 circuits, extending a result of Williams (JACM 2014). Finally, leveraging our improved classical lower bounds, we establish the strongest known unconditional separations between quantum and classical circuit classes. We separate QNC^0 from GC^0 and GC^0[p] in various settings and show that BQLOGTIME is not contained in GC^0. As a consequence, we construct an oracle relative to which BQP lies outside uniform GC^0, extending the Raz-Tal oracle separation between BQP and PH (STOC 2019).",
          "authors": [
            "Sabee Grewal",
            "Vinayak M. Kumar"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.01146",
          "title": "Homogeneous Khovanskii bases and MUVAK bases",
          "abstract": "In 2019, Kaveh and Manon introduced Khovanskii bases as a special 'Gröbner-like' generating system of an algebra. We extend their work by considering an arbitrary grading on the algebra and propose a definition for a 'homogeneous Khovanskii basis' that respects this grading. We generalize Khovanskii bases further by taking multiple valuations into account (MUVAK bases). We give algorithms in both cases. MUVAK bases appear in the computation of the Cox ring of a minimal model of a quotient singularity. Our algorithm is an improvement of an algorithm by Yamagishi in this situation.",
          "authors": [
            "Johannes Schmitt"
          ],
          "primary_category": "math.AC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.04441",
          "title": "An efficient finite-resource formulation of non-Abelian lattice gauge theories beyond one dimension",
          "abstract": "Non-Abelian gauge theories provide the most accurate description of fundamental interactions, showing remarkable agreement with experimental data in cosmology and particle physics. Highly precise predictions can be made using standard techniques, both in the continuum and in the lattice frameworks. However, classical methods have limitations, particularly when attempting to extrapolate the continuum limit from the study of lattice gauge theories. Complementing classical computations or combining them with quantum computational methods, to improve the predictions towards the continuum limit with current quantum resources, is a formidable open challenge. In this paper, we propose a resource-efficient method to compute the running of the coupling in non-Abelian gauge theories beyond one spatial dimension. We first represent the Hamiltonian on periodic lattices in terms of loop variables and conjugate loop electric fields, exploiting the Gauss law to retain the gauge-independent ones. Then, we identify a local basis for small and large loops variationally to minimize the truncation error while computing the running of the coupling on small tori. Our method enables computations at arbitrary values of the bare coupling and lattice spacing with current quantum computers, simulators and tensor-network calculations, in regimes otherwise inaccessible.",
          "authors": [
            "Pierpaolo Fontana",
            "Marc Miranda Riaza",
            "Alessio Celi"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.04441",
          "title": "An efficient finite-resource formulation of non-Abelian lattice gauge theories beyond one dimension",
          "abstract": "Non-Abelian gauge theories provide the most accurate description of fundamental interactions, showing remarkable agreement with experimental data in cosmology and particle physics. Highly precise predictions can be made using standard techniques, both in the continuum and in the lattice frameworks. However, classical methods have limitations, particularly when attempting to extrapolate the continuum limit from the study of lattice gauge theories. Complementing classical computations or combining them with quantum computational methods, to improve the predictions towards the continuum limit with current quantum resources, is a formidable open challenge. In this paper, we propose a resource-efficient method to compute the running of the coupling in non-Abelian gauge theories beyond one spatial dimension. We first represent the Hamiltonian on periodic lattices in terms of loop variables and conjugate loop electric fields, exploiting the Gauss law to retain the gauge-independent ones. Then, we identify a local basis for small and large loops variationally to minimize the truncation error while computing the running of the coupling on small tori. Our method enables computations at arbitrary values of the bare coupling and lattice spacing with current quantum computers, simulators and tensor-network calculations, in regimes otherwise inaccessible.",
          "authors": [
            "Pierpaolo Fontana",
            "Marc Miranda Riaza",
            "Alessio Celi"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.06251",
          "title": "Mechanistic Modeling of Continuous Lyophilization for Biopharmaceutical Manufacturing",
          "abstract": "Lyophilization (aka freeze drying) is a typical process in pharmaceutical manufacturing used for improving the stability of various drug products, including its recent applications to mRNA vaccines. While extensive efforts have been dedicated to shifting the pharmaceutical industry toward continuous manufacturing, the majority of industrial-scale lyophilization is still being operated in a batch mode. This article presents the first mechanistic model for a complete continuous lyophilization process, which comprehensively incorporates and describes key transport phenomena in all three steps of lyophilization, namely freezing, primary drying, and secondary drying. The proposed model considers the state-of-the-art lyophilization technology, in which vials are suspended and move continuously through the process. The validated model can accurately predict the evolution of critical process parameters, including the product temperature, ice/water fraction, sublimation front position, and concentration of bound water, for the entire process. Several applications related to model-based process design and optimization of continuous lyophilization are also demonstrated. The final model is made available in MATLAB and Julia as an open-source software package called ContLyo, which can ultimately be leveraged for guiding the design and development of future continuous lyophilization processes.",
          "authors": [
            "Prakitr Srisuma",
            "Gang Chen",
            "Richard D. Braatz"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.06251",
          "title": "Mechanistic Modeling of Continuous Lyophilization for Biopharmaceutical Manufacturing",
          "abstract": "Lyophilization (aka freeze drying) is a typical process in pharmaceutical manufacturing used for improving the stability of various drug products, including its recent applications to mRNA vaccines. While extensive efforts have been dedicated to shifting the pharmaceutical industry toward continuous manufacturing, the majority of industrial-scale lyophilization is still being operated in a batch mode. This article presents the first mechanistic model for a complete continuous lyophilization process, which comprehensively incorporates and describes key transport phenomena in all three steps of lyophilization, namely freezing, primary drying, and secondary drying. The proposed model considers the state-of-the-art lyophilization technology, in which vials are suspended and move continuously through the process. The validated model can accurately predict the evolution of critical process parameters, including the product temperature, ice/water fraction, sublimation front position, and concentration of bound water, for the entire process. Several applications related to model-based process design and optimization of continuous lyophilization are also demonstrated. The final model is made available in MATLAB and Julia as an open-source software package called ContLyo, which can ultimately be leveraged for guiding the design and development of future continuous lyophilization processes.",
          "authors": [
            "Prakitr Srisuma",
            "Gang Chen",
            "Richard D. Braatz"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.12484",
          "title": "Every finite nilpotent loop has a supernilpotent loop as reduct",
          "abstract": "A basic fact taught in undergraduate algebra courses is that every finite nilpotent group is a direct product of $p$-groups. Already Bruck observed that this does not generalize to loops. In particular, there exist nilpotent loops of size $6$ which are not direct products of loops of size $2$ and $3$. Still we show that every finite nilpotent loop $(A,\\cdot)$ has a binary term operation $*$ such that $(A,*)$ is a direct product of nilpotent loops of prime power order, i.e., $(A,*)$ is supernilpotent. As an application we obtain that every nilpotent loop of order $pq$ for primes $p,q$ has a finite basis for its equational theory.",
          "authors": [
            "Michael Kompatscher",
            "Peter Mayr"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.14243",
          "title": "Explicit error bounds with commutator scaling for time-dependent product and multi-product formulas",
          "abstract": "Product formula (PF), which approximates the time evolution under a many-body Hamiltonian by the product of local time evolution operators, is one of the central approaches for simulating quantum dynamics by quantum computers. It has been of great interest whether PFs have a bound of the error from the exact time evolution, which is expressed by commutators among local terms (called commutator scaling), since it brings the substantial suppression of the computational cost in the system size. Although recent studies have revealed the presence and the explicit formulas of the PF error bounds for time-independent systems, those for time-dependent Hamiltonians remain to be a difficult problem except for low-order PFs. In this paper, we derive an explicit error bound of generic PFs for smooth time-dependent Hamiltonians, which is expressed by commutators among local terms and their time derivatives. This error bound can also host the substantial suppression in the system size for generic local Hamiltonians with finite-, short-, and long-ranged interactions, thereby giving a much better estimate of gate counts. Our derivation employs Floquet theory; Embedding generic smooth time-dependent Hamiltonians into time-periodic ones, we map the time-dependent PF error to the time-independent one defined on an infinite-dimensional space. This approach allows to obtain the error bounds not only for the ordinary time-dependent PF but also for its various family. In particular, we also clarify the explicit error bound of a time-dependent multi-product formula, with which we can achieve much smaller error by a linear combination of time-dependent PFs. Our results will shed light on various applications of quantum computers, ranging from quantum simulation of nonequilibrium materials to faster algorithms exploiting time-dependent Hamiltonians like adiabatic state preparation.",
          "authors": [
            "Kaoru Mizuta",
            "Tatsuhiko N. Ikeda",
            "Keisuke Fujii"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.14243",
          "title": "Explicit error bounds with commutator scaling for time-dependent product and multi-product formulas",
          "abstract": "Product formula (PF), which approximates the time evolution under a many-body Hamiltonian by the product of local time evolution operators, is one of the central approaches for simulating quantum dynamics by quantum computers. It has been of great interest whether PFs have a bound of the error from the exact time evolution, which is expressed by commutators among local terms (called commutator scaling), since it brings the substantial suppression of the computational cost in the system size. Although recent studies have revealed the presence and the explicit formulas of the PF error bounds for time-independent systems, those for time-dependent Hamiltonians remain to be a difficult problem except for low-order PFs. In this paper, we derive an explicit error bound of generic PFs for smooth time-dependent Hamiltonians, which is expressed by commutators among local terms and their time derivatives. This error bound can also host the substantial suppression in the system size for generic local Hamiltonians with finite-, short-, and long-ranged interactions, thereby giving a much better estimate of gate counts. Our derivation employs Floquet theory; Embedding generic smooth time-dependent Hamiltonians into time-periodic ones, we map the time-dependent PF error to the time-independent one defined on an infinite-dimensional space. This approach allows to obtain the error bounds not only for the ordinary time-dependent PF but also for its various family. In particular, we also clarify the explicit error bound of a time-dependent multi-product formula, with which we can achieve much smaller error by a linear combination of time-dependent PFs. Our results will shed light on various applications of quantum computers, ranging from quantum simulation of nonequilibrium materials to faster algorithms exploiting time-dependent Hamiltonians like adiabatic state preparation.",
          "authors": [
            "Kaoru Mizuta",
            "Tatsuhiko N. Ikeda",
            "Keisuke Fujii"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.14891",
          "title": "LUCI in the Surface Code with Dropouts",
          "abstract": "Recently, usage of detecting regions facilitated the discovery of new circuits for fault-tolerantly implementing the surface code. Building on these ideas, we present LUCI, a framework for constructing fault-tolerant circuits flexible enough to construct aperiodic and anisotropic circuits, making it a clear step towards quantum error correction beyond static codes. We show that LUCI can be used to adapt surface code circuits to lattices with imperfect qubit and coupler yield, a key challenge for fault-tolerant quantum computers using solid-state architectures. These circuits preserve spacelike distance for isolated broken couplers or isolated broken measure qubits in exchange for halving timelike distance, substantially reducing the penalty for dropout compared to the state of the art and creating opportunities in device architecture design. For qubit and coupler dropout rates of 1% and a patch diameter of 15, LUCI achieves an average spacelike distance of 13.1, compared to 9.1 for the best method in the literature. For a SI1000(0.001) circuit noise model, this translates to a 36x improvement in median logical error rate per round, a factor which increases with device performance. At these dropout and error rates, LUCI requires roughly 25% fewer physical qubits to reach algorithmically relevant one-in-a-trillion logical codeblock error rates.",
          "authors": [
            "Dripto M. Debroy",
            "Matt McEwen",
            "Craig Gidney",
            "Noah Shutty",
            "Adam Zalcman"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.20457",
          "title": "Dynamical random field Ising model at zero temperature",
          "abstract": "In this paper, we study the evolution of the zero-temperature random field Ising model as the mean of the external field $M$ increases from $-\\infty$ to $\\infty$. We focus on two types of evolutions: the ground state evolution and the Glauber evolution. For the ground state evolution, we investigate the occurrence of global avalanche, a moment where a large fraction of spins flip simultaneously from minus to plus. In two dimensions, no global avalanche occurs, while in three or higher dimensions, there is a phase transition: a global avalanche happens when the noise intensity is small, but not when it is large. Additionally, we study the zero-temperature Glauber evolution, where spins are updated locally to minimize the Hamiltonian. Our results show that for small noise intensity, in dimensions $d =2$ or $3$, most spins flip around a critical time $c_d = \\frac{2 \\sqrt{d}}{1 + \\sqrt{d}}$ (but we cannot decide whether such flipping occurs simultaneously or not). We also connect this process to polluted bootstrap percolation and solve an open problem on it.",
          "authors": [
            "Jian Ding",
            "Peng Yang",
            "Zijie Zhuang"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.20457",
          "title": "Dynamical random field Ising model at zero temperature",
          "abstract": "In this paper, we study the evolution of the zero-temperature random field Ising model as the mean of the external field $M$ increases from $-\\infty$ to $\\infty$. We focus on two types of evolutions: the ground state evolution and the Glauber evolution. For the ground state evolution, we investigate the occurrence of global avalanche, a moment where a large fraction of spins flip simultaneously from minus to plus. In two dimensions, no global avalanche occurs, while in three or higher dimensions, there is a phase transition: a global avalanche happens when the noise intensity is small, but not when it is large. Additionally, we study the zero-temperature Glauber evolution, where spins are updated locally to minimize the Hamiltonian. Our results show that for small noise intensity, in dimensions $d =2$ or $3$, most spins flip around a critical time $c_d = \\frac{2 \\sqrt{d}}{1 + \\sqrt{d}}$ (but we cannot decide whether such flipping occurs simultaneously or not). We also connect this process to polluted bootstrap percolation and solve an open problem on it.",
          "authors": [
            "Jian Ding",
            "Peng Yang",
            "Zijie Zhuang"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.23196",
          "title": "Relative volume of comparable pairs under semigroup majorization",
          "abstract": "Any semigroup $\\mathcal{S}$ of stochastic matrices induces a semigroup majorization relation $\\prec^{\\mathcal{S}}$ on the set $\\Delta_{n-1}$ of probability $n$-vectors. Pick $X,Y$ at random in $\\Delta_{n-1}$: what is the probability that $X$ and $Y$ are comparable under $\\prec^{\\mathcal{S}}$? We review recent asymptotic ($n\\to\\infty$) results and conjectures in the case of majorization relation (when $\\mathcal{S}$ is the set of doubly stochastic matrices), discuss natural generalisations, and prove a new asymptotic result in the case of majorization, and new exact finite-$n$ formulae in the case of UT-majorization relation, i.e. when $\\mathcal{S}$ is the set of upper-triangular stochastic matrices.",
          "authors": [
            "Fabio Deelan Cunden",
            "Jakub Czartowski",
            "Giovanni Gramegna",
            "A. de Oliveira Junior"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.23196",
          "title": "Relative volume of comparable pairs under semigroup majorization",
          "abstract": "Any semigroup $\\mathcal{S}$ of stochastic matrices induces a semigroup majorization relation $\\prec^{\\mathcal{S}}$ on the set $\\Delta_{n-1}$ of probability $n$-vectors. Pick $X,Y$ at random in $\\Delta_{n-1}$: what is the probability that $X$ and $Y$ are comparable under $\\prec^{\\mathcal{S}}$? We review recent asymptotic ($n\\to\\infty$) results and conjectures in the case of majorization relation (when $\\mathcal{S}$ is the set of doubly stochastic matrices), discuss natural generalisations, and prove a new asymptotic result in the case of majorization, and new exact finite-$n$ formulae in the case of UT-majorization relation, i.e. when $\\mathcal{S}$ is the set of upper-triangular stochastic matrices.",
          "authors": [
            "Fabio Deelan Cunden",
            "Jakub Czartowski",
            "Giovanni Gramegna",
            "A. de Oliveira Junior"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.23196",
          "title": "Relative volume of comparable pairs under semigroup majorization",
          "abstract": "Any semigroup $\\mathcal{S}$ of stochastic matrices induces a semigroup majorization relation $\\prec^{\\mathcal{S}}$ on the set $\\Delta_{n-1}$ of probability $n$-vectors. Pick $X,Y$ at random in $\\Delta_{n-1}$: what is the probability that $X$ and $Y$ are comparable under $\\prec^{\\mathcal{S}}$? We review recent asymptotic ($n\\to\\infty$) results and conjectures in the case of majorization relation (when $\\mathcal{S}$ is the set of doubly stochastic matrices), discuss natural generalisations, and prove a new asymptotic result in the case of majorization, and new exact finite-$n$ formulae in the case of UT-majorization relation, i.e. when $\\mathcal{S}$ is the set of upper-triangular stochastic matrices.",
          "authors": [
            "Fabio Deelan Cunden",
            "Jakub Czartowski",
            "Giovanni Gramegna",
            "A. de Oliveira Junior"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.02087",
          "title": "An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Linear Systems",
          "abstract": "Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task. In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.",
          "authors": [
            "Allan Grønlund",
            "Kasper Green Larsen"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.02087",
          "title": "An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Linear Systems",
          "abstract": "Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task. In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.",
          "authors": [
            "Allan Grønlund",
            "Kasper Green Larsen"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.03719",
          "title": "Spontaneous emission in Casimir-Rabi oscillations through a weak optomechanical coupling",
          "abstract": "The dynamical Casimir effect (DCE) describes the energy conversion from a mechanical motion to the electromagnetic fields. When the mechanical oscillator is in a mechanically excited state, the free evolution due to the DCE produces radiation in the vacuum, in analogy with the spontaneous emission from an excited atom. In this manuscript, we investigate such a spontaneous radiation process by employing the quantum trajectory approach. When the dissipation rate of the system is very low, there can be a reversible energy exchange between the mirror in the excited state and the vacuum field, and this reversible exchange is called vacuum Casimir-Rabi oscillations. Multiple quantum trajectory simulations of this process show that the number of trajectories responsible for the generation of radiation can reach a significant value when the mechanical dissipation rate is less than the photon dissipation rate. We also find that two-photon (two/three-phonon) bundle emission occurs in photon (phonon) emission. In comparison to pure two-photon and three-phonon free dissipation, the probability of two-photon bundle emission and two-phonon bundle emission are observed to be marginally elevated as a consequence of the presence of the DCE. This pattern may assist in developing a deeper comprehension of the physical characteristics of photon and phonon emission in the DCE.",
          "authors": [
            "Ke-Xiong Yan",
            "Yuan Qiu",
            "Yang Xiao",
            "Jie Song",
            "Ye-Hong Chen",
            "Yan Xia"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.04639",
          "title": "Complexity theory of orbit closure intersection for tensors: reductions, completeness, and graph isomorphism hardness",
          "abstract": "Many natural computational problems in computer science, mathematics, physics, and other sciences amount to deciding if two objects are equivalent. Often this equivalence is defined in terms of group actions. A natural question is to ask when two objects can be distinguished by polynomial functions that are invariant under the group action. For finite groups, this is the usual notion of equivalence, but for continuous groups like the general linear groups it gives rise to a new notion, called orbit closure intersection. It captures, among others, the graph isomorphism problem, noncommutative PIT, null cone problems in invariant theory, equivalence problems for tensor networks, and the classification of multiparty quantum states. Despite recent algorithmic progress in celebrated special cases, the computational complexity of general orbit closure intersection problems is currently quite unclear. In particular, tensors seem to give rise to the most difficult problems. In this work we start a systematic study of orbit closure intersection from the complexity-theoretic viewpoint. To this end, we define a complexity class TOCI that captures the power of orbit closure intersection problems for general tensor actions, give an appropriate notion of algebraic reductions that imply polynomial-time reductions in the usual sense, but are amenable to invariant-theoretic techniques, identify natural tensor problems that are complete for TOCI, including the equivalence of 2D tensor networks with constant physical dimension, and show that the graph isomorphism problem can be reduced to these complete problems, hence GI$\\subseteq$TOCI. As such, our work establishes the first lower bound on the computational complexity of orbit closure intersection problems, and it explains the difficulty of finding unconditional polynomial-time algorithms beyond special cases, as has been observed in the literature.",
          "authors": [
            "Vladimir Lysikov",
            "Michael Walter"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.04639",
          "title": "Complexity theory of orbit closure intersection for tensors: reductions, completeness, and graph isomorphism hardness",
          "abstract": "Many natural computational problems in computer science, mathematics, physics, and other sciences amount to deciding if two objects are equivalent. Often this equivalence is defined in terms of group actions. A natural question is to ask when two objects can be distinguished by polynomial functions that are invariant under the group action. For finite groups, this is the usual notion of equivalence, but for continuous groups like the general linear groups it gives rise to a new notion, called orbit closure intersection. It captures, among others, the graph isomorphism problem, noncommutative PIT, null cone problems in invariant theory, equivalence problems for tensor networks, and the classification of multiparty quantum states. Despite recent algorithmic progress in celebrated special cases, the computational complexity of general orbit closure intersection problems is currently quite unclear. In particular, tensors seem to give rise to the most difficult problems. In this work we start a systematic study of orbit closure intersection from the complexity-theoretic viewpoint. To this end, we define a complexity class TOCI that captures the power of orbit closure intersection problems for general tensor actions, give an appropriate notion of algebraic reductions that imply polynomial-time reductions in the usual sense, but are amenable to invariant-theoretic techniques, identify natural tensor problems that are complete for TOCI, including the equivalence of 2D tensor networks with constant physical dimension, and show that the graph isomorphism problem can be reduced to these complete problems, hence GI$\\subseteq$TOCI. As such, our work establishes the first lower bound on the computational complexity of orbit closure intersection problems, and it explains the difficulty of finding unconditional polynomial-time algorithms beyond special cases, as has been observed in the literature.",
          "authors": [
            "Vladimir Lysikov",
            "Michael Walter"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.04690",
          "title": "Asymptotic distribution of the derivative of the taut string accompanying Wiener process",
          "abstract": "In the article, we find the asymptotic distribution of the derivative of the taut string accompanying a Wiener process in a strip of fixed width on long time intervals. This enables to find explicit expressions for minimal energy (averaged function of the derivative) of an absolutely continuous function in this strip. For example, for kinetic energy which was considered earlier by Lifshits and Setterqvist, the minimal energy per unit of time tends to $\\pi^2/6r^2$ where $r$ is the strip width.",
          "authors": [
            "Mikhail Lifshits",
            "Andrei Podchishchailov"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.06956",
          "title": "Optimal Liouville theorems for the Lane-Emden equation on Riemannian manifolds",
          "abstract": "We study degenerate quasilinear elliptic equations on Riemannian manifolds and obtain several Liouville theorems. Notably, we provide rigorous proof asserting the nonexistence of positive solutions to the subcritical Lane-Emden-Fowler equations over complete Riemannian manifolds with nonnegative Ricci curvature. These findings serve as a significant generalization of Gidas and Spruck's pivotal work (Comm. Pure Appl. Math. 34, 525-598, 1981) which focused on the semilinear case, as well as Serrin and Zou's contributions (Acta Math. 189, 79-142, 2002) within the context of Euclidean geometries.",
          "authors": [
            "Jie He",
            "Linlin Sun",
            "Youde Wang"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.08121",
          "title": "Cavity-Vacuum-Induced Chiral Spin Liquids in Kagome Lattices: Tuning and Probing Topological Quantum Phases via Cavity Quantum Electrodynamics",
          "abstract": "Topological phases in frustrated quantum magnetic systems have captivated researchers for decades, with the chiral spin liquid (CSL) standing out as one of the most compelling examples. Featured by long-range entanglement, topological order, and exotic fractional excitations, the CSL has inspired extensive exploration for practical realizations. In this work, we demonstrate that CSLs can emerge in a kagome lattice driven by vacuum quantum fluctuations over the non-interacting vacuum within a single-mode gyrotropic cavity. The gyrotropic cavity imprints quantum fluctuations with time-reversal symmetry breaking and stabilizes a robust CSL phase without external laser excitation. Moreover, we identify experimentally accessible observables -- such as average photon number and transport properties -- that reveal connections between photon dynamics and the emergent chiral order. Our findings establish a novel pathway for creating, controlling, and probing topological and symmetry-breaking quantum phases in strongly correlated systems.",
          "authors": [
            "Chenan Wei",
            "Liu Yang",
            "Qing-Dong Jiang"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.08121",
          "title": "Cavity-Vacuum-Induced Chiral Spin Liquids in Kagome Lattices: Tuning and Probing Topological Quantum Phases via Cavity Quantum Electrodynamics",
          "abstract": "Topological phases in frustrated quantum magnetic systems have captivated researchers for decades, with the chiral spin liquid (CSL) standing out as one of the most compelling examples. Featured by long-range entanglement, topological order, and exotic fractional excitations, the CSL has inspired extensive exploration for practical realizations. In this work, we demonstrate that CSLs can emerge in a kagome lattice driven by vacuum quantum fluctuations over the non-interacting vacuum within a single-mode gyrotropic cavity. The gyrotropic cavity imprints quantum fluctuations with time-reversal symmetry breaking and stabilizes a robust CSL phase without external laser excitation. Moreover, we identify experimentally accessible observables -- such as average photon number and transport properties -- that reveal connections between photon dynamics and the emergent chiral order. Our findings establish a novel pathway for creating, controlling, and probing topological and symmetry-breaking quantum phases in strongly correlated systems.",
          "authors": [
            "Chenan Wei",
            "Liu Yang",
            "Qing-Dong Jiang"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.08121",
          "title": "Cavity-Vacuum-Induced Chiral Spin Liquids in Kagome Lattices: Tuning and Probing Topological Quantum Phases via Cavity Quantum Electrodynamics",
          "abstract": "Topological phases in frustrated quantum magnetic systems have captivated researchers for decades, with the chiral spin liquid (CSL) standing out as one of the most compelling examples. Featured by long-range entanglement, topological order, and exotic fractional excitations, the CSL has inspired extensive exploration for practical realizations. In this work, we demonstrate that CSLs can emerge in a kagome lattice driven by vacuum quantum fluctuations over the non-interacting vacuum within a single-mode gyrotropic cavity. The gyrotropic cavity imprints quantum fluctuations with time-reversal symmetry breaking and stabilizes a robust CSL phase without external laser excitation. Moreover, we identify experimentally accessible observables -- such as average photon number and transport properties -- that reveal connections between photon dynamics and the emergent chiral order. Our findings establish a novel pathway for creating, controlling, and probing topological and symmetry-breaking quantum phases in strongly correlated systems.",
          "authors": [
            "Chenan Wei",
            "Liu Yang",
            "Qing-Dong Jiang"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.17708",
          "title": "Ultrashort-pulse-pumped, single-mode type-0 squeezers in lithium niobate nanophotonics",
          "abstract": "We present design principles for ultrashort-pulse, type-0 phase-matched optical parametric amplifiers to generate and measure spectrally pure degenerate squeezed light. We consider a fundamental signal (second-harmonic) mode at 2090 (1045) nm and show that our proposed design achieves a Schmidt number of $K \\approx 1.02$ with squeezing levels greater than 15 dB on a single temporal mode spanning over $5$ THz in bandwidth with cm-scale devices on thin-film lithium niobate (TFLN) on insulator platform. Our work opens up promising avenues for large-scale circuits for ultrafast quantum information processing and quantum sensing applications on the rapidly advancing TFLN platform with already demonstrated linear components and photodetection capabilities.",
          "authors": [
            "Martin Houde",
            "Liam Beaudoin",
            "Robert Kwolek",
            "Kazuki Hirota",
            "Rajveer Nehra",
            "Nicolás Quesada"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.17708",
          "title": "Ultrashort-pulse-pumped, single-mode type-0 squeezers in lithium niobate nanophotonics",
          "abstract": "We present design principles for ultrashort-pulse, type-0 phase-matched optical parametric amplifiers to generate and measure spectrally pure degenerate squeezed light. We consider a fundamental signal (second-harmonic) mode at 2090 (1045) nm and show that our proposed design achieves a Schmidt number of $K \\approx 1.02$ with squeezing levels greater than 15 dB on a single temporal mode spanning over $5$ THz in bandwidth with cm-scale devices on thin-film lithium niobate (TFLN) on insulator platform. Our work opens up promising avenues for large-scale circuits for ultrafast quantum information processing and quantum sensing applications on the rapidly advancing TFLN platform with already demonstrated linear components and photodetection capabilities.",
          "authors": [
            "Martin Houde",
            "Liam Beaudoin",
            "Robert Kwolek",
            "Kazuki Hirota",
            "Rajveer Nehra",
            "Nicolás Quesada"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.18740",
          "title": "Chain Conditions and Optimal Elements in Generalized Union-Closed Families of Sets",
          "abstract": "The union-closed sets conjecture (sometimes referred to as Frankl's conjecture) states that every finite, nontrivial union-closed family of sets has an element that is in at least half of its members. Although the conjecture is known to be false in the infinite setting, we show that many interesting results can still be recovered by imposing suitable chain conditions and considering carefully chosen elements called optimal elements. We use these elements to show that the union-closed conjecture holds for both finite and infinite union-closed families such that the cardinality of any chain of sets is at most three. We also show that the conjecture holds for all nontrivial topological spaces satisfying the descending chain condition on its open sets. Notably, none of those arguments depend on the cardinality of the underlying family or its universe. Finally, we provide an interesting class of families that satisfy the conclusion of the conjecture but are not necessarily union-closed.",
          "authors": [
            "Cory H. Colbert"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.05958",
          "title": "Lower Bound on the Representation Complexity of Antisymmetric Tensor Product Functions",
          "abstract": "Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings reveal that low-rank TPFs are fundamentally unsuitable for high-dimensional problems where antisymmetry is essential.",
          "authors": [
            "Yuyang Wang",
            "Yukuan Hu",
            "Xin Liu"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.05958",
          "title": "Lower Bound on the Representation Complexity of Antisymmetric Tensor Product Functions",
          "abstract": "Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings reveal that low-rank TPFs are fundamentally unsuitable for high-dimensional problems where antisymmetry is essential.",
          "authors": [
            "Yuyang Wang",
            "Yukuan Hu",
            "Xin Liu"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.05958",
          "title": "Lower Bound on the Representation Complexity of Antisymmetric Tensor Product Functions",
          "abstract": "Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings reveal that low-rank TPFs are fundamentally unsuitable for high-dimensional problems where antisymmetry is essential.",
          "authors": [
            "Yuyang Wang",
            "Yukuan Hu",
            "Xin Liu"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.07874",
          "title": "Sobolev inequalities for canceling operators",
          "abstract": "Sobolev type inequalities involving homogeneous elliptic canceling differential operators and rearrangement-invariant norms on the Euclidean space are considered. They are characterized via considerably simpler one-dimensional Hardy type inequalities. As a consequence, they are shown to hold exactly for the same norms as their counterparts depending on the standard gradient operator of the same order. The results offered provide a unified framework for the theory of Sobolev embeddings for the elliptic canceling operators. They build upon and incorporate earlier fundamental contributions dealing with the endpoint case of $L^1$-norms. They also include previously available results for the symmetric gradient, a prominent instance of an elliptic canceling operator. In particular, the optimal rearrangement-invariant target norm associated with any given domain norm in a Sobolev inequality for any elliptic canceling operator is exhibited. Its explicit form is detected for specific families of rearrangement-invariant spaces, such as the Orlicz spaces and the Lorentz-Zygmund spaces. Especially relevant instances of inequalities for domain spaces neighboring $L^1$ are singled out.",
          "authors": [
            "Dominic Breit",
            "Andrea Cianchi",
            "Daniel Spector"
          ],
          "primary_category": "math.FA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.11129",
          "title": "Optimal Binary Variable-Length Codes with a Bounded Number of 1's per Codeword: Design, Analysis, and Applications",
          "abstract": "In this paper, we consider the problem of constructing optimal average-length binary codes under the constraint that each codeword must contain at most $D$ ones, where $D$ is a given input parameter. We provide an $O(n^2D)$-time complexity algorithm for the construction of such codes, where $n$ is the number of codewords. We also describe several scenarios where the need to design these kinds of codes naturally arises. We also provide a Kraft-like inequality for the existence of (optimal) variable-length binary codes, subject to the above-described constraint on the number of 1's in each codeword.",
          "authors": [
            "Roberto Bruno",
            "Roberto De Prisco",
            "Ugo Vaccaro"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.11129",
          "title": "Optimal Binary Variable-Length Codes with a Bounded Number of 1's per Codeword: Design, Analysis, and Applications",
          "abstract": "In this paper, we consider the problem of constructing optimal average-length binary codes under the constraint that each codeword must contain at most $D$ ones, where $D$ is a given input parameter. We provide an $O(n^2D)$-time complexity algorithm for the construction of such codes, where $n$ is the number of codewords. We also describe several scenarios where the need to design these kinds of codes naturally arises. We also provide a Kraft-like inequality for the existence of (optimal) variable-length binary codes, subject to the above-described constraint on the number of 1's in each codeword.",
          "authors": [
            "Roberto Bruno",
            "Roberto De Prisco",
            "Ugo Vaccaro"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.12726",
          "title": "Exponential stability for an infinite memory wave equation with frictional damping and logarithmic nonlinear terms",
          "abstract": "This article is concerned with the energy decay of an infinite memory wave equation with a logarithmic nonlinear term and a frictional damping term. The problem is formulated in a bounded domain in $\\mathbb R^d$ ($d\\ge3$) with a smooth boundary, on which we prescribe a mixed boundary condition of the Dirichlet and the acoustic types. We establish an exponential decay result for the energy with a general material density $\\rho(x)$ under certain assumptions on the involved coefficients. The proof is based on a contradiction argument, the multiplier method and some microlocal analysis techniques. In addition, if $\\rho(x)$ takes a special form, our result even holds without the damping effect, that is, the infinite memory effect alone is strong enough to guarantee the exponential stability of the system.",
          "authors": [
            "Qingqing Peng",
            "Yikan Liu"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.12944",
          "title": "Stability of travelling wave solutions to reaction-diffusion equations driven by additive noise with Hölder continuous paths",
          "abstract": "In this paper we investigate stability of travelling wave solutions to a class of reaction-diffusion equations perturbed by infinite-dimensional additive noise with Hölder continuous paths, covering in particular fractional Brownian motion with general Hurst index. We obtain long- and short time asymptotic error bounds on the maximal distance from the solution of the stochastic reaction-diffusion equation to the orbit of travelling wave fronts. These bounds, in terms of Hurst index and Hölder exponent, apply to a large class of infinite-dimensional self-similar drivers with Hölder continuous paths, such as linear fractional stable motion. We find that for short times, higher Hurst indices imply higher stability, while for large times, a smaller gap between Hurst index and Hölder exponent implies stability for larger noise amplitudes.",
          "authors": [
            "Amjad Saef",
            "Wilhelm Stannat"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.16013",
          "title": "Geometry of genus sixteen K3 surfaces",
          "abstract": "Polarized K3 surfaces of genus sixteen have a Mukai vector bundle of rank two. We study the geometry of the projectivization of this bundle. We prove that it has an embedding in $\\mathbb{P}_9$ with an ideal generated by quadrics. We give an effective method to compute these quadrics from a general choice in Mukai's unirationalization of the moduli space. This linear system gives a double cover of $\\mathbb{P}_9$ ramified on a degree $10$ hypersurface. It gives relative Weddle/Kummer surfaces over a Peskine variety associated to an explicit trivector. This work is also motivated by hyperkähler geometry and Debarre-Voisin varieties. Oberdieck showed that the Hilbert square of a general K3-surface of genus $16$ is a Debarre-Voisin variety for some trivector. We start to investigate the relationship between these two trivectors.",
          "authors": [
            "Frederic Han"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.17730",
          "title": "The rational Gurarii space and its linear isometry group",
          "abstract": "We show that the classes of partial isometries in finite-dimensional polyhedral spaces and in finite-dimensional rational polyhedral spaces do not have the weak amalgamation property. This implies that the linear isometry group of the rational Gurarii space does not have a comeager conjugacy class. Our methods demonstrate also that the classes of finite-dimensional polyhedral spaces and of finite-dimensional rational polyhedral spaces fail to have the Hrushovski property.",
          "authors": [
            "Ondřej Kurka",
            "Maciej Malicki"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.18491",
          "title": "Magnetism and hidden quantum geometry in charge neutral twisted trilayer graphene",
          "abstract": "Here we present a theory of mirror-symmetric magic angle twisted trilayer graphene. The electronic properties are described by a Hubbard model with long range tunneling matrix elements. The electronic properties are obtained by solving the mean field Hubbard model. We obtain the bandstructure with characteristic flat bands and a Dirac cone. At charge neutrality, turning on electron-electron interactions results in metallic to antiferomagnetic phase transition, for Hubbard interaction strength considerably smaller than in other graphene multilayers. We analyze the stability of the antiferromagnetic state against the symmetry breaking induced by hexagonal boron nitride encapsulation, and mirror symmetry breaking caused by the application of electric fields that mix the Dirac cone with the flat bands. Additionally, we explore the topological properties of the system, revealing a hidden quantum geometry. Despite the flat bands having zero Chern numbers, the multiband Berry curvature distribution over the moiré Brillouin zone exhibits a non-trivial structure. Finally, we propose a mechanism to tune this quantum geometry, providing a pathway to control the system's topological properties.",
          "authors": [
            "Alina Wania Rodrigues",
            "Maciej Bieniek",
            "Daniel Miravet",
            "Pawel Hawrylak"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.01264",
          "title": "Generalized Lanczos method for systematic optimization of neural-network quantum states",
          "abstract": "Recently, artificial intelligence for science has made significant inroads into various fields of natural science research. In the field of quantum many-body computation, researchers have developed numerous ground state solvers based on neural-network quantum states (NQSs), achieving ground state energies with accuracy comparable to or surpassing traditional methods such as variational Monte Carlo methods, density matrix renormalization group, and quantum Monte Carlo methods. Here, we combine supervised learning, variational Monte Carlo (VMC), and the Lanczos method to develop a systematic approach to improving the NQSs of many-body systems, which we refer to as the NQS Lanczos method. The algorithm mainly consists of two parts: the supervised learning part and the VMC optimization part. Through supervised learning, the Lanczos states are represented by the NQSs. Through VMC, the NQSs are further optimized. We analyze the reasons for the underfitting problem and demonstrate how the NQS Lanczos method systematically improves the energy in the highly frustrated regime of the two-dimensional Heisenberg $J_1$-$J_2$ model. Compared to the existing method that combines the Lanczos method with the restricted Boltzmann machine, the primary advantage of the NQS Lanczos method is its linearly increasing computational cost.",
          "authors": [
            "Jia-Qi Wang",
            "Rong-Qiang He",
            "Zhong-Yi Lu"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.01264",
          "title": "Generalized Lanczos method for systematic optimization of neural-network quantum states",
          "abstract": "Recently, artificial intelligence for science has made significant inroads into various fields of natural science research. In the field of quantum many-body computation, researchers have developed numerous ground state solvers based on neural-network quantum states (NQSs), achieving ground state energies with accuracy comparable to or surpassing traditional methods such as variational Monte Carlo methods, density matrix renormalization group, and quantum Monte Carlo methods. Here, we combine supervised learning, variational Monte Carlo (VMC), and the Lanczos method to develop a systematic approach to improving the NQSs of many-body systems, which we refer to as the NQS Lanczos method. The algorithm mainly consists of two parts: the supervised learning part and the VMC optimization part. Through supervised learning, the Lanczos states are represented by the NQSs. Through VMC, the NQSs are further optimized. We analyze the reasons for the underfitting problem and demonstrate how the NQS Lanczos method systematically improves the energy in the highly frustrated regime of the two-dimensional Heisenberg $J_1$-$J_2$ model. Compared to the existing method that combines the Lanczos method with the restricted Boltzmann machine, the primary advantage of the NQS Lanczos method is its linearly increasing computational cost.",
          "authors": [
            "Jia-Qi Wang",
            "Rong-Qiang He",
            "Zhong-Yi Lu"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.01264",
          "title": "Generalized Lanczos method for systematic optimization of neural-network quantum states",
          "abstract": "Recently, artificial intelligence for science has made significant inroads into various fields of natural science research. In the field of quantum many-body computation, researchers have developed numerous ground state solvers based on neural-network quantum states (NQSs), achieving ground state energies with accuracy comparable to or surpassing traditional methods such as variational Monte Carlo methods, density matrix renormalization group, and quantum Monte Carlo methods. Here, we combine supervised learning, variational Monte Carlo (VMC), and the Lanczos method to develop a systematic approach to improving the NQSs of many-body systems, which we refer to as the NQS Lanczos method. The algorithm mainly consists of two parts: the supervised learning part and the VMC optimization part. Through supervised learning, the Lanczos states are represented by the NQSs. Through VMC, the NQSs are further optimized. We analyze the reasons for the underfitting problem and demonstrate how the NQS Lanczos method systematically improves the energy in the highly frustrated regime of the two-dimensional Heisenberg $J_1$-$J_2$ model. Compared to the existing method that combines the Lanczos method with the restricted Boltzmann machine, the primary advantage of the NQS Lanczos method is its linearly increasing computational cost.",
          "authors": [
            "Jia-Qi Wang",
            "Rong-Qiang He",
            "Zhong-Yi Lu"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.05570",
          "title": "Collective Behavior and Memory States in Flow Networks with Tunable Bistability",
          "abstract": "Multistability-induced hysteresis has been widely studied in mechanical systems, but such behavior has proven more difficult to reproduce experimentally in flow networks. Natural flow networks like animal and plant vasculature can exhibit complex nonlinear behavior to facilitate fluid transport, so multistable flows may inform their functionality. To probe such phenomena in an analogous model system, we utilize an electronic network of hysteretic bistable resistors designed to have tunable negative differential resistivity. We demonstrate our system's capability to generate complex global memory states in the form of voltage patterns, which is mediated by the tunable nonlinearity of each element's current-voltage characteristic. We investigate avalanching behavior arising from effective interactions, and demonstrate how to encode explicit interactions of arbitrary form by taking advantage of the tunable circuitry design.",
          "authors": [
            "Lauren E. Altman",
            "Nadia Aguilar",
            "Douglas J. Durian",
            "Miguel Ruiz-Garcia",
            "Eleni Katifori"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.08270",
          "title": "Superconductivity near an Ising nematic quantum critical point in two dimensions",
          "abstract": "Near a two-dimensional Ising-type nematic quantum critical point, the quantum fluctuations of the nematic order parameter are coupled to the electrons, leading to non-Fermi liquid behavior and unconventional superconductivity. The interplay between these two effects has been extensively studied through the Eliashberg equations for the superconducting gap. However, previous studies often rely on various approximations that may introduce uncertainties in the results. Here, we re-visit the issue of how the superconducting transition temperature $T_{c}$ is affected by removing certain common approximations. We numerically solve the self-consistent Dyson-Schwinger equations of the electron propagator $G(p)$, the nematic propagator $D(q)$, and the vertex function $\\Gamma_{\\mathrm{v}}^{\\mathrm{1L}}(p+q,p)$ expanded up to the triangle order, without introducing further approximations. Our calculations reveal that the extended $s$-wave superconducting gap is the only convergent solution to the nonlinear gap equations. We investigate the evolution of $T_{c}$ as the system approaches the nematic quantum critical point from the disordered (tetragonal) phase. Under the bare vertex approximation, $T_{c}$ is monotonically enhanced. However, when vertex corrections are incorporated, $T_{c}$ initially increases but then decreases, with the maximum value of $T_{c}$ occurring at a point away from the quantum critical point. The obtained gap symmetry and the non-monotonic behavior of $T_{c}$ are compared with recent experiments on doped FeSe materials.",
          "authors": [
            "Jie Huang",
            "Zhao-Kun Yang",
            "Jing-Rong Wang",
            "Guo-Zhu Liu"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.09397",
          "title": "Spectral Bifurcation and Anomalous Supercurrent in Dissipative Topological Insulator-based Josephson Junctions",
          "abstract": "The interplay between topological protection and dissipation constitutes a critical frontier in the realization of hybrid quantum devices. Here, we investigate the transport signatures in a dissipative topological insulator-based Josephson junction, a platform that directly probes the competition between quantum coherence and loss. We model dissipation by coupling a `lossy' metallic lead to the junction, described effectively by a non-Hermitian Hamiltonian derived using the Lindblad formalism. We observe that the junction exhibits an asymmetric complex Andreev spectrum, where the imaginary energy component imposes a finite lifetime on the quasi-bound states. Furthermore, beyond specific phase intervals, the real component of the spectrum bifurcates: one branch merges with the continuum, while the other penetrates just below the superconducting gap. Crucially, the characteristic zero-energy crossing shifts away from $\\phi=\\pi$ and acquires a non-zero imaginary component; consequently, the associated Majorana bound states acquire a finite lifetime, signaling a loss of robustness against dissipation. Finally, this spectral asymmetry drives an anomalous supercurrent, manifested as a non-vanishing current at zero phase difference. Our results reveal how dissipation fundamentally reshapes superconducting transport in topological junctions, opening new directions for dissipation-engineered quantum devices.",
          "authors": [
            "Ardamon Sten",
            "Paramita Dutta",
            "Sudeep Kumar Ghosh"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.10323",
          "title": "A taxonomy of categories for relations",
          "abstract": "The study of categories that abstract the structural properties of relations has been extensively developed over the years, resulting in a rich and diverse body of work. This paper strives to provide a modern presentation of these ``categories for relations'', including their enriched version, further showing how they arise as Kleisli categories of symmetric monoidal monads. The resulting taxonomy aims at bringing clarity and organisation to the many related concepts and frameworks occurring in the literature.",
          "authors": [
            "Cipriano Junior Cioffo",
            "Fabio Gadducci",
            "Davide Trotta"
          ],
          "primary_category": "math.CT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.10323",
          "title": "A taxonomy of categories for relations",
          "abstract": "The study of categories that abstract the structural properties of relations has been extensively developed over the years, resulting in a rich and diverse body of work. This paper strives to provide a modern presentation of these ``categories for relations'', including their enriched version, further showing how they arise as Kleisli categories of symmetric monoidal monads. The resulting taxonomy aims at bringing clarity and organisation to the many related concepts and frameworks occurring in the literature.",
          "authors": [
            "Cipriano Junior Cioffo",
            "Fabio Gadducci",
            "Davide Trotta"
          ],
          "primary_category": "math.CT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.13033",
          "title": "Classical notions of computation and the Hasegawa-Thielecke theorem (extended version)",
          "abstract": "In the spirit of the Curry-Howard correspondence between proofs and programs, we define and study a syntax and semantics for classical logic equipped with a computationally involutive negation, using a polarised effect calculus, the linear classical L-calculus. A main challenge in designing a denotational semantics for the calculus is to accommodate both call-by-value and call-by-name evaluation strategies, which leads to a failure of associativity of composition. In order to tackle this issue, we define a notion of adjunction between graph morphisms on non-associative categories, which we use to formulate polarized and non-associative notions of symmetric monoidal closed duploid and of dialogue duploid. We show that they provide a direct style counterpart to adjunction models: linear effect adjunctions for the (linear) call-by-push-value calculus and dialogue chiralities for linear continuations, respectively. In particular, we show that the syntax of the linear classical L-calculus can be interpreted in any dialogue duploid, and that it defines in fact a syntactic dialogue duploid. As an application, we establish, by semantic as well as syntactic means, the Hasegawa-Thielecke theorem, which states that the notions of central map and of thunkable map coincide in any dialogue duploid (in particular, for any double negation monad on a symmetric monoidal category).",
          "authors": [
            "Éléonore Mangel",
            "Paul-André Melliès",
            "Guillaume Munch-Maccagnoni"
          ],
          "primary_category": "cs.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.13033",
          "title": "Classical notions of computation and the Hasegawa-Thielecke theorem (extended version)",
          "abstract": "In the spirit of the Curry-Howard correspondence between proofs and programs, we define and study a syntax and semantics for classical logic equipped with a computationally involutive negation, using a polarised effect calculus, the linear classical L-calculus. A main challenge in designing a denotational semantics for the calculus is to accommodate both call-by-value and call-by-name evaluation strategies, which leads to a failure of associativity of composition. In order to tackle this issue, we define a notion of adjunction between graph morphisms on non-associative categories, which we use to formulate polarized and non-associative notions of symmetric monoidal closed duploid and of dialogue duploid. We show that they provide a direct style counterpart to adjunction models: linear effect adjunctions for the (linear) call-by-push-value calculus and dialogue chiralities for linear continuations, respectively. In particular, we show that the syntax of the linear classical L-calculus can be interpreted in any dialogue duploid, and that it defines in fact a syntactic dialogue duploid. As an application, we establish, by semantic as well as syntactic means, the Hasegawa-Thielecke theorem, which states that the notions of central map and of thunkable map coincide in any dialogue duploid (in particular, for any double negation monad on a symmetric monoidal category).",
          "authors": [
            "Éléonore Mangel",
            "Paul-André Melliès",
            "Guillaume Munch-Maccagnoni"
          ],
          "primary_category": "cs.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.14871",
          "title": "Accurate analytic approximation for a fractional differential equation with a modified Bessel function term",
          "abstract": "A new analytical approximation function is proposed to accurately fit the solution of a fractional differential equation of order one-half, whose nonhomogeneous term is defined by a modified Bessel function of the first kind. The exact analytical solution of this equation is expressed as the product of two modified Bessel functions. The approximation is constructed using an extended multipoint quasi-rational method, which simultaneously incorporates the series expansion and the asymptotic behavior of the Bessel function. A key modification is introduced in the structure of the fitting function, allowing it to reproduce two terms of the asymptotic expansion instead of only one, thereby improving accuracy for large arguments. Numerical analysis shows that for representative parameter values, the maximum relative error between the proposed fitting function and the exact solution of the fractional differential equation is approximately \\(0.18\\%\\), demonstrating the high precision achieved with only six fitting parameters.",
          "authors": [
            "Byron Droguett",
            "Pablo Martin",
            "Eduardo Rojas",
            "Jorge Olivares"
          ],
          "primary_category": "math.GM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.20496",
          "title": "Abstraction Functions as Types",
          "abstract": "Software development depends on the use of libraries whose public specifications inform client code and impose obligations on private implementations; it follows that verification at scale must also be modular, preserving such abstraction. Hoare's influential methodology uses abstraction functions to demonstrate the coherence between such concrete implementations and their abstract specifications. However, the Hoare methodology relies on a conventional separation between implementation and specification, providing no linguistic support for ensuring that this convention is obeyed. This paper proposes a synthetic account of Hoare's methodology within univalent dependent type theory by encoding the data of abstraction functions within types themselves. This is achieved via a phase distinction, which gives rise to a gluing construction that renders an abstraction function as a type and a pair of modalities that fracture a type into its concrete and abstract parts. A noninterference theorem governing the phase distinction characterizes the modularity guarantees provided by the theory. This approach scales to verification of cost, allowing the analysis of client cost relative to a cost-aware specification. A monadic sealing effect facilitates modularity of cost, permitting an implementation to be upper-bounded by its specification in cases where private details influence observable cost. The resulting theory supports modular development of programs and proofs in a manner that hides private details of no concern to clients while permitting precise specifications of both the cost and behavior of programs.",
          "authors": [
            "Harrison Grodin",
            "Runming Li",
            "Robert Harper"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.00100",
          "title": "FuzzifiED : Julia Package for Numerics on the Fuzzy Sphere",
          "abstract": "The Julia package FuzzifiED aims at simplifying the numerical calculations on the fuzzy sphere. It supports exact diagonalisation (ED) and density matrix renormalisation group (DMRG) calculations. FuzzifiED can also apply to generic fermionic and bosonic models. This documentation provides a review of the fuzzy sphere regularisation and an instruction for using FuzzifiED for numerical calculations.",
          "authors": [
            "Zheng Zhou"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.00100",
          "title": "FuzzifiED : Julia Package for Numerics on the Fuzzy Sphere",
          "abstract": "The Julia package FuzzifiED aims at simplifying the numerical calculations on the fuzzy sphere. It supports exact diagonalisation (ED) and density matrix renormalisation group (DMRG) calculations. FuzzifiED can also apply to generic fermionic and bosonic models. This documentation provides a review of the fuzzy sphere regularisation and an instruction for using FuzzifiED for numerical calculations.",
          "authors": [
            "Zheng Zhou"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.05465",
          "title": "Compare Similarities Between DNA Sequences Using Permutation-Invariant Quantum Kernel",
          "abstract": "Computing the similarity between two DNA sequences is of vital importance in bioscience, yet it can be computationally expensive on classical hardware. For example, the edit distance with move operations (EDM), a DNA similarity measure of interest in biology, is proven to be NP-Complete to compute exactly on classical hardware. Recently, applied quantum algorithms have been anticipated to offer potential advantages over classical approaches. In this paper, we propose a novel variational quantum kernel model served as a surrogate model for estimating similarity between DNA sequences defined by EDM. Since the EDM metric exhibits a pairwise permutation-insensitive property, we incorporate a permutation-invariant structure into the variational quantum kernel to approximate this symmetry. Furthermore, to encode the four nucleotide bases as quantum states, we introduce a theoretically motivated encoding scheme based on symmetric informationally complete positive operator-valued measure (SIC-POVM) states. This encoding ensures mutual equivalence among bases, as each pair of symbols is mapped to quantum states that are equidistant on the Bloch sphere. We experimentally show that, equipped with the permutation-invariant circuit design and mutual-equivalence encoding, the proposed quantum kernel model achieves strong performance in approximating the similarity defined by EDM. Compared with classical kernel learning methods, our quantum approach achieves significantly higher accuracy while using substantially fewer trainable parameters.",
          "authors": [
            "Chenyu Shi",
            "Gabriele Leoni",
            "Mauro Petrillo",
            "Antonio Puertas Gallardo",
            "Hao Wang"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.06133",
          "title": "Embeddings of edge-colored dual graphs of balanced 3- and 4-manifolds",
          "abstract": "This article focuses on a class of properly edge-colored graphs, which arise from topological combinatorics, and investigates their embeddings onto surfaces. Specifically, these graphs are known as the dual graphs of balanced normal pseudomanifolds. We introduce the concept of the balanced genus, which represents the smallest genus of a surface onto which the dual graph of a normal pseudomanifold can embed regularly. As a key result, we establish that for any 3-manifold $ M $ that is not a sphere, the balanced genus satisfies the lower bound $ \\mathcal{G}_M \\geq m+3 $, where $ m $ is the rank of its fundamental group of $M$. Furthermore, we prove that a 3-manifold $ M $ is homeomorphic to the 3-sphere if and only if its balanced genus $ \\mathcal{G}_M $ is at most 3. Similarly, for 4-manifolds, we establish that if $ M $ is not homeomorphic to a sphere, then its balanced genus is bounded below by $ \\mathcal{G}_M \\geq 2\\chi(M) + 5m + 11 $. Moreover, a 4-manifold $ M $ is PL homeomorphic to the 4-sphere if and only if its balanced genus satisfies $ \\mathcal{G}_M \\leq 2\\chi(M) + 10 $. We believe that the balanced genus offers a new perspective in graph theory and combinatorics and will inspire further developments in the field in connection with algebraic combinatorics. To this end, we outline several directions for future research.",
          "authors": [
            "Biplab Basak",
            "Sourav Sarkar"
          ],
          "primary_category": "math.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.07350",
          "title": "Energy decay of nonlocal viscoelastic equations with nonlinear damping and polynomial nonlinearity",
          "abstract": "This paper is concerned with the energy decay of a viscoelastic variable coefficient wave equation with nonlocality in time as well as nonlinear damping and polynomial nonlinear terms. Using the Lyapunov method, we establish a polynomial energy decay for the solution under relatively weak assumptions regarding the kernel of the nonlocal term. More specifically, we improve the decay rate of the energy by additionally imposing a certain convexity assumption on the kernel. Several examples are provided to confirm such improvements to faster polynomial or even exponential decays.",
          "authors": [
            "Qingqing Peng",
            "Yikan Liu"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.08184",
          "title": "Julia in HEP",
          "abstract": "Julia is a mature general-purpose programming language, with a large ecosystem of libraries and more than 12000 third-party packages, which specifically targets scientific computing. As a language, Julia is as dynamic, interactive, and accessible as Python with NumPy, but achieves run-time performance on par with C/C++. In this paper, we describe the state of adoption of Julia in HEP, where momentum has been gathering over a number of years. HEP-oriented Julia packages can already, via this http URL , read HEP's major file formats, including TTree and RNTuple. Interfaces to some of HEP's major software packages, such as through this http URL , are available too. Jet reconstruction algorithms in Julia show excellent performance. A number of full HEP analyses have been performed in Julia. We show how, as the support for HEP has matured, developments have benefited from Julia's core design choices, which makes reuse from and integration with other packages easy. In particular, libraries developed outside HEP for plotting, statistics, fitting, and scientific machine learning are extremely useful. We believe that the powerful combination of flexibility and speed, the wide selection of scientific programming tools, and support for all modern programming paradigms and tools, make Julia the ideal choice for a future language in HEP.",
          "authors": [
            "Graeme Andrew Stewart",
            "Alexander Moreno Briceño",
            "Philippe Gras",
            "Benedikt Hegner",
            "Uwe Hernandez Acosta",
            "Tamas Gal",
            "Jerry Ling",
            "Pere Mato",
            "Mikhail Mikhasenko",
            "Oliver Schulz",
            "Sam Skipsey"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.08184",
          "title": "Julia in HEP",
          "abstract": "Julia is a mature general-purpose programming language, with a large ecosystem of libraries and more than 12000 third-party packages, which specifically targets scientific computing. As a language, Julia is as dynamic, interactive, and accessible as Python with NumPy, but achieves run-time performance on par with C/C++. In this paper, we describe the state of adoption of Julia in HEP, where momentum has been gathering over a number of years. HEP-oriented Julia packages can already, via this http URL , read HEP's major file formats, including TTree and RNTuple. Interfaces to some of HEP's major software packages, such as through this http URL , are available too. Jet reconstruction algorithms in Julia show excellent performance. A number of full HEP analyses have been performed in Julia. We show how, as the support for HEP has matured, developments have benefited from Julia's core design choices, which makes reuse from and integration with other packages easy. In particular, libraries developed outside HEP for plotting, statistics, fitting, and scientific machine learning are extremely useful. We believe that the powerful combination of flexibility and speed, the wide selection of scientific programming tools, and support for all modern programming paradigms and tools, make Julia the ideal choice for a future language in HEP.",
          "authors": [
            "Graeme Andrew Stewart",
            "Alexander Moreno Briceño",
            "Philippe Gras",
            "Benedikt Hegner",
            "Uwe Hernandez Acosta",
            "Tamas Gal",
            "Jerry Ling",
            "Pere Mato",
            "Mikhail Mikhasenko",
            "Oliver Schulz",
            "Sam Skipsey"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09502",
          "title": "Tremblay-Turbiner-Winternitz (TTW) system at integer index $k$: polynomial algebras of integrals",
          "abstract": "An infinite 3-parametric family of superintegrable and exactly-solvable quantum models on a plane, admitting separation of variables in polar coordinates, marked by integer index $k$ was introduced in Journ Phys A 42 (2009) 242001 and was called in literature the TTW system. In this paper it is conjectured that the Hamiltonian and both integrals of TTW system have hidden algebra $g^{(k)}$ - it was checked for $k=1,2,3,4$ - having its finite-dimensional representation spaces as the invariant subspaces. It is checked that for $k=1,2,3,4$ that the Hamiltonian $H$, two integrals ${\\cal I}_{1,2}$ and their commutator ${\\cal I}_{12} = [{\\cal I}_1,{\\cal I}_2]$ are four generating elements of the polynomial algebra of integrals of the order $(k+1)$: $[{\\cal I}_1,{\\cal I}_{12}] = P_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, $[{\\cal I}_2,{\\cal I}_{12}] = Q_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, where $P_{k+1},Q_{k+1}$ are polynomials of degree $(k+1)$ written in terms of ordered monomials of $H, {\\cal I}_{1,2},{\\cal I}_{12}$. This implies that polynomial algebra of integrals is subalgebra of $g^{(k)}$. It is conjectured that all is true for any integer $k$.",
          "authors": [
            "Juan Carlos López Vieyra",
            "Alexander V Turbiner"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09502",
          "title": "Tremblay-Turbiner-Winternitz (TTW) system at integer index $k$: polynomial algebras of integrals",
          "abstract": "An infinite 3-parametric family of superintegrable and exactly-solvable quantum models on a plane, admitting separation of variables in polar coordinates, marked by integer index $k$ was introduced in Journ Phys A 42 (2009) 242001 and was called in literature the TTW system. In this paper it is conjectured that the Hamiltonian and both integrals of TTW system have hidden algebra $g^{(k)}$ - it was checked for $k=1,2,3,4$ - having its finite-dimensional representation spaces as the invariant subspaces. It is checked that for $k=1,2,3,4$ that the Hamiltonian $H$, two integrals ${\\cal I}_{1,2}$ and their commutator ${\\cal I}_{12} = [{\\cal I}_1,{\\cal I}_2]$ are four generating elements of the polynomial algebra of integrals of the order $(k+1)$: $[{\\cal I}_1,{\\cal I}_{12}] = P_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, $[{\\cal I}_2,{\\cal I}_{12}] = Q_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, where $P_{k+1},Q_{k+1}$ are polynomials of degree $(k+1)$ written in terms of ordered monomials of $H, {\\cal I}_{1,2},{\\cal I}_{12}$. This implies that polynomial algebra of integrals is subalgebra of $g^{(k)}$. It is conjectured that all is true for any integer $k$.",
          "authors": [
            "Juan Carlos López Vieyra",
            "Alexander V Turbiner"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09502",
          "title": "Tremblay-Turbiner-Winternitz (TTW) system at integer index $k$: polynomial algebras of integrals",
          "abstract": "An infinite 3-parametric family of superintegrable and exactly-solvable quantum models on a plane, admitting separation of variables in polar coordinates, marked by integer index $k$ was introduced in Journ Phys A 42 (2009) 242001 and was called in literature the TTW system. In this paper it is conjectured that the Hamiltonian and both integrals of TTW system have hidden algebra $g^{(k)}$ - it was checked for $k=1,2,3,4$ - having its finite-dimensional representation spaces as the invariant subspaces. It is checked that for $k=1,2,3,4$ that the Hamiltonian $H$, two integrals ${\\cal I}_{1,2}$ and their commutator ${\\cal I}_{12} = [{\\cal I}_1,{\\cal I}_2]$ are four generating elements of the polynomial algebra of integrals of the order $(k+1)$: $[{\\cal I}_1,{\\cal I}_{12}] = P_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, $[{\\cal I}_2,{\\cal I}_{12}] = Q_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, where $P_{k+1},Q_{k+1}$ are polynomials of degree $(k+1)$ written in terms of ordered monomials of $H, {\\cal I}_{1,2},{\\cal I}_{12}$. This implies that polynomial algebra of integrals is subalgebra of $g^{(k)}$. It is conjectured that all is true for any integer $k$.",
          "authors": [
            "Juan Carlos López Vieyra",
            "Alexander V Turbiner"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09502",
          "title": "Tremblay-Turbiner-Winternitz (TTW) system at integer index $k$: polynomial algebras of integrals",
          "abstract": "An infinite 3-parametric family of superintegrable and exactly-solvable quantum models on a plane, admitting separation of variables in polar coordinates, marked by integer index $k$ was introduced in Journ Phys A 42 (2009) 242001 and was called in literature the TTW system. In this paper it is conjectured that the Hamiltonian and both integrals of TTW system have hidden algebra $g^{(k)}$ - it was checked for $k=1,2,3,4$ - having its finite-dimensional representation spaces as the invariant subspaces. It is checked that for $k=1,2,3,4$ that the Hamiltonian $H$, two integrals ${\\cal I}_{1,2}$ and their commutator ${\\cal I}_{12} = [{\\cal I}_1,{\\cal I}_2]$ are four generating elements of the polynomial algebra of integrals of the order $(k+1)$: $[{\\cal I}_1,{\\cal I}_{12}] = P_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, $[{\\cal I}_2,{\\cal I}_{12}] = Q_{k+1}(H, {\\cal I}_{1,2},{\\cal I}_{12})$, where $P_{k+1},Q_{k+1}$ are polynomials of degree $(k+1)$ written in terms of ordered monomials of $H, {\\cal I}_{1,2},{\\cal I}_{12}$. This implies that polynomial algebra of integrals is subalgebra of $g^{(k)}$. It is conjectured that all is true for any integer $k$.",
          "authors": [
            "Juan Carlos López Vieyra",
            "Alexander V Turbiner"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.09577",
          "title": "Permutation-based Strategies for Labeled Chip-Firing on $k$-ary Trees",
          "abstract": "Chip-firing is a combinatorial game on a graph, in which chips are placed and dispersed among its vertices until a stable configuration is achieved. We specifically study a chip-firing variant on an infinite, rooted, directed $k$-ary tree where we place $k^n$ chips labeled $0,1,\\dots, k^n-1$ on the root for some nonnegative integer $n$, and we say a vertex $v$ can fire if it has at least $k$ chips. When a vertex fires, we select $k$ labeled chips and send the $i$th smallest chip among them to its $i$th leftmost child. A stable configuration is reached when no vertex can fire. In this paper, we focus on stable configurations resulting from specific firing strategies based on permutations of $1, 2, \\dots, n$. We then express the stable configuration as a permutation of $0,1, 2, \\dots, k^n-1$ and explore its properties, such as the number of inversions and descents.",
          "authors": [
            "Ryota Inagaki",
            "Tanya Khovanova",
            "Austin Luo"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.12870",
          "title": "Low-Overhead Tailoring and Learning of Noise in Graph States",
          "abstract": "Graph and hypergraph states are important resource states for realizing universal quantum computation and diverse non-local physical phenomena. However, noise learning in such states is challenging due to their large entanglement and magic. This work establishes a low Clifford hierarchy circuit-based scheme for tailoring and learning noise in (hyper)graph states generated by multiple controlled-Z gates. The key is to convert the noisy input state into a diagonal form and derive the convolution equation of diagonal noise rate, which proves to have a lower resource overhead. Such a diagonal form can be used in real quantum simulation by using the same tailoring technique into the graph state input. We demonstrate that a single-depth Bell measurement is sufficient in our scheme for arbitrary graph states, while noise tailoring can be done via Pauli operations. After that, we suggest the Walsh-Hadamard transform and some approximation method for decoding the noise. We prove that constant sampling and polynomial time complexities are sufficient to guarantee bounded noise estimation error with respect to the $l_2$-norm, which usually requires exponential complexity with existing noise estimation methods. The polynomial complexities are maintained even for the more stringent $l_1$ approximation under the sparse noise assumption. Conclusively, we propose novel methods for characterizing the noise properties of an entangled state at a lower cost than that of state generation. Moreover, compared with state verification methods, we can attain richer information on noise rates and enable noise mitigation, thereby providing guarantees for the preparation of graph states.",
          "authors": [
            "Guedong Park",
            "Jinzhao Sun",
            "Hyunseok Jeong"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.16923",
          "title": "Nonreciprocal Current-Induced Zero-Resistance State in Valley-Polarized Superconductors",
          "abstract": "The recently observed nonreciprocal current-induced zero-resistance state (CIZRS) in twisted trilayer graphene/WSe$_2$ heterostructure has posed a significant theoretical challenge. In the experiment, the system shows a zero-resistance state only when a sufficiently large current is applied in a particular direction, while stays in an incipient superconducting state with small resistance when the current is small or flows in the opposite direction. In this Letter, we provide a theory of CIZRS. We show that the threefold degenerate Fulde-Ferrell (FF) states are stabilized by the valley polarization and trigonal warping effects of twisted trilayer graphene/WSe$_2$ heterostructures. Moreover, a current flowing in a particular direction breaks the threefold degeneracy and favors a particular FF pairing domain. We therefore propose that the incipient superconducting state is naturally understood as a multidomain state where the interdomain supercurrent is difficult to flow due to the tiny Josephson coupling caused by the mismatch of Cooper-pair momenta between different FF domains. Nevertheless, a sufficiently large current in a particular direction can selectively populate a certain FF state and create monodomain pathways with zero resistance. Crucially, due to the threefold symmetry of the system, a current flowing in the opposite direction can fail to generate the zero-resistance pathways, thus giving rise to the observed nonreciprocity. Finally, we suggest that the long-sought-after triangular finite-momentum state can also be realized in valley-polarized superconductors.",
          "authors": [
            "Akito Daido",
            "Youichi Yanase",
            "K. T. Law"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.19473",
          "title": "Non-classical nucleation pathways in liquid condensation revealed by simulation and theory",
          "abstract": "Using state-of-the-art rare-event sampling simulations, we precisely characterize the nucleation of liquid droplets from a supersaturated Lennard-Jones gas and uncover a key physical feature: critical clusters nucleate with a density that differ substantially from that of the macroscopic equilibrium liquid. Our atomistic simulations also reveal a non-classical nucleation pathway showing simultaneous growth and densification in liquid condensation. We then exploit these insights to develop a two-variable nucleation theory, in which the cluster density is allowed to vary. Our accessible model based on the capillary approximation is able to quantitatively retrieve the numerical results in nucleation rate and critical cluster properties over a large range of supersaturation. Remarkably, the two-variable model successfully captures the observed nucleation pathway. The effectiveness of this integrated numerical and theoretical framework demonstrates that the cluster density is a decisive variable in nucleation, highlighting the limitations of the single-variable description while offering a robust foundation for its refinement.",
          "authors": [
            "Yijian Wu",
            "Thomas Philippe",
            "Aymane Graini",
            "Julien Lam"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.19473",
          "title": "Non-classical nucleation pathways in liquid condensation revealed by simulation and theory",
          "abstract": "Using state-of-the-art rare-event sampling simulations, we precisely characterize the nucleation of liquid droplets from a supersaturated Lennard-Jones gas and uncover a key physical feature: critical clusters nucleate with a density that differ substantially from that of the macroscopic equilibrium liquid. Our atomistic simulations also reveal a non-classical nucleation pathway showing simultaneous growth and densification in liquid condensation. We then exploit these insights to develop a two-variable nucleation theory, in which the cluster density is allowed to vary. Our accessible model based on the capillary approximation is able to quantitatively retrieve the numerical results in nucleation rate and critical cluster properties over a large range of supersaturation. Remarkably, the two-variable model successfully captures the observed nucleation pathway. The effectiveness of this integrated numerical and theoretical framework demonstrates that the cluster density is a decisive variable in nucleation, highlighting the limitations of the single-variable description while offering a robust foundation for its refinement.",
          "authors": [
            "Yijian Wu",
            "Thomas Philippe",
            "Aymane Graini",
            "Julien Lam"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.20620",
          "title": "Combination theorems for Wise's power alternative",
          "abstract": "We show that Wise's power alternative is stable under certain group constructions, use this to prove the power alternative for new classes of groups, and recover known results from a unified perspective. For groups acting on trees, we introduce a dynamical condition that allows us to deduce the power alternative for the group from the power alternative for its stabilisers of points. As an application, we reduce the power alternative for Artin groups to the power alternative for free-of-infinity Artin groups, under some conditions on their parabolic subgroups. We also introduce a uniform version of the power alternative and prove it, among other things, for a large family of two-dimensional Artin groups. As a corollary, we deduce that these Artin groups have uniform exponential growth. Finally, we prove that the power alternative is stable under taking relatively hyperbolic groups. We apply this to show that various examples, including all free-by-$\\mathbb{Z}$ groups and a natural subclass of hierarchically hyperbolic groups, satisfy the uniform power alternative.",
          "authors": [
            "Mark Hagen",
            "Alexandre Martin",
            "Giovanni Sartori"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.01325",
          "title": "Coarse chain recurrence, Morse graphs with finite errors, and persistence of circulations",
          "abstract": "This paper provides a unified framework connecting dynamical systems with tools from topological data analysis and geometric topology and inspires new interactions among dynamical systems, topology, and nonlinear analysis. To this end, we introduce a one-parameter family of ``chain recurrences'' that generalizes chain recurrence and induces a natural filtration on the underlying metric space of a dynamical system. In particular, the forward directions of the filtrations characterize the level of control required to return to the original position, and the backward directions capture the robustness of the recurrence. The resulting filtrations yield potentials and bifurcation diagrams of dynamical systems that encode the evolution of recurrent sets under bounded total or stepwise perturbations. In addition, we extend Morse graphs to one-parameter families of ``coarse Morse graphs,'' which evolve through vertex collapses reflecting coarse recurrence transitions. These constructions not only refine Conley's decomposition but also reveal singular limit behaviors as the perturbation level vanishes. Furthermore, we establish analogous filtrations for difference equations to bridge the theoretical framework with numerical analysis.",
          "authors": [
            "Tomoo Yokoyama"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.02619",
          "title": "Existence of solutions for time-dependent Signorini-type problems in linearised viscoelasticity",
          "abstract": "In this paper we establish the existence of solutions for a model describing the evolution of a linearly viscoelastic body which is constrained to remain confined in a prescribed half-space. The confinement condition under consideration is of Signorini type, and is given over the boundary of the linearly viscoelastic body under consideration. We show that one such variational problem admits solutions and we coin a novel concept of solution which, differently from the available literature, is valid even in the case where the viscoelastic body starts its motion in contact with the obstacle. Additionally, under additional assumptions on the constituting material, we show that when the applied body force is lifted the deformed linearly viscoelastic body returns to its rest position at an exponential rate of decay.",
          "authors": [
            "Paolo Piersanti"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.02673",
          "title": "QUITS: A modular Qldpc code circUIT Simulator",
          "abstract": "To achieve quantum fault tolerance with lower overhead, quantum low-density parity-check (QLDPC) codes have emerged as a promising alternative to topological codes such as the surface code, offering higher code rates. To support their study, an end-to-end framework for simulating QLDPC codes at the circuit level is needed. In this work, we present QUITS, a modular and flexible circuit-level simulator for QLDPC codes. Its design allows users to freely combine LDPC code constructions, syndrome extraction circuits, decoding algorithms, and noise models, enabling comprehensive and customizable studies of the performance of QLDPC codes under circuit-level noise. QUITS supports several leading QLDPC families, including hypergraph product codes, lifted product codes, and balanced product codes. As part of the framework, we introduce a syndrome extraction circuit improved from Tremblay, Delfosse, and Beverland [Phys. Rev. Lett. 129, 050504 (2022)] that applies to all three code families. In particular, for a small hypergraph product code, our circuit achieves lower depth than the conventional method, resulting in improved logical performance. Using QUITS, we evaluate the performance of state-of-the-art QLDPC codes and decoders under various settings, revealing trade-offs between the decoding runtime and the logical failure rate. The source code of QUITS is available online.",
          "authors": [
            "Mingyu Kang",
            "Yingjia Lin",
            "Hanwen Yao",
            "Mert Gökduman",
            "Arianna Meinking",
            "Kenneth R. Brown"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.04624",
          "title": "Notes on Quantum Soundscapes and Music",
          "abstract": "We describe our investigations involving the sonification of data from experiments involving various mesoscopic mechanical oscillator systems cooled to close to their quantum ground states, as well as the sonification of measured data from a single qubit subject to various unitary rotations designed to test the Leggett-Garg inequality. \"Listening\" to data via their resulting sonifications facilitates the discovery of signals that might otherwise be hard to detect in common graphic (i.e., visual) representations, and for the qubit experiment provides a complementary way to discern when the data violates macroscopic realism with some prior listening training. The resulting soundscapes and music also provide a complementary window into the quantum realm that is accessible to non-experts with open ears.",
          "authors": [
            "Miles Blencowe",
            "Michael Casey",
            "Kimberly Tan"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.08485",
          "title": "Iterated random walks in random scenery (PAPAPA)",
          "abstract": "We establish a limit theorem for a new model of 3-dimensional random walk in an inhomogeneous lattice with random orientations. This model can be seen as a 3dimensional version of the Matheron and de Marsily model [12]. This new model leads us naturally to the study of iterated random walk in random scenery, which is a new process that can be described as a random walk in random scenery evolving in a second random scenery. We use the french acronym PAPAPA for this new process and answer a question about its stochastic behaviour asked about twenty years ago by St{é}phane Le Borgne.",
          "authors": [
            "Nadine Guillotin-Plantard",
            "Françoise Pène",
            "Frédérique Watbled"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.13083",
          "title": "Feedforward suppression of readout-induced faults in quantum error correction",
          "abstract": "Qubit measurements in quantum devices involve various types of errors, including erroneous state determination, correlated preparation errors and measurement-induced leakage from the computational states. We propose a feedforward protocol to reduce readout-induced faults, applicable for qubits with errors biased between the different states, in settings like quantum error correction with repeated measurement cycles. The method consists of an adaptive readout sequence conditioned on each check qubit's readout result from the previous cycle, which is optimized for the expected measured state. Focusing on a simple realization of conditionally flipping (by an X gate) the state of check qubits before their measurement, we investigate the effect of such state-dependent errors using simulations in the setup of a low-density parity check code. We show that the suggested protocol can reduce both logical errors and decoding time, two important aspects of fault-tolerant quantum computations.",
          "authors": [
            "Liran Shirizly",
            "Dekel Meirom",
            "Malcolm Carroll",
            "Haggai Landa"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.17158",
          "title": "Utilizing Symmetry in Finding New Permutiples from Known Examples",
          "abstract": "A permutiple is a natural number whose representation in some base, $b>1$, is an integer multiple of a number whose base-$b$ representation has the same collection of digits. Previous efforts have made progress in finding such numbers using graph-theoretical and finite-state-machine constructions. These are the mother graph and the Hoey-Sloane machine. In this paper, we leverage the inherent symmetry of the above constructions for the purpose of finding new permutiples from old. Such results also help us to see previous work through a new lens.",
          "authors": [
            "Benjamin V. Holt"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.18747",
          "title": "Covert Communication Over a Quantum MAC with a Helper",
          "abstract": "We study covert classical communication over a quantum multiple-access channel (MAC) with a helper. Specifically, we consider three transmitters, where one transmitter helps the other two transmitters communicate covertly with a receiver. We demonstrate the feasibility of achieving a positive covert rate over this channel and establish an achievable rate region. Our result recovers as a special case known results for classical communication over classical MACs with a degraded message set, classical communication over quantum MACs, and classical communication over MACs with a helper. To the best of our knowledge, our result is the first to achieve covert communication with positive rates over both classical and quantum MACs.",
          "authors": [
            "Hassan ZivariFard",
            "Rémi A. Chou",
            "Xiaodong Wang"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.21542",
          "title": "The intersection of the subgroups of finite $p$-index in a multiple HNN-extension of an infinite cyclic group",
          "abstract": "Let $G$ be a multiple HNN-extension of an infinite cyclic group. We will calculate the intersection $(N_{p}){_\\omega}(G)$ of the normal subgroups of finite $p$-index in $G$ thus generalizing the result of Moldavanskii for Baumslag-Solitar groups. As a corollary we give necessary and sufficient conditions for $G$ to be residually finite $p$-group.",
          "authors": [
            "V. Metaftsis",
            "D. Tsipa"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.02651",
          "title": "Hydrodynamics of two-dimensional CFTs",
          "abstract": "We demonstrate that the geometric action on a coadjoint orbit of the Virasoro group appropriately describes non-dissipative two-dimensional conformal fluids. While this action had already appeared in the context of AdS$_3$ gravity, the hydrodynamical interpretation given here is new. We use this to argue that the geometric action manifestly controls both sides of the fluid/gravity correspondence, where the gravitational `hologram' gives an effective hydrodynamical description of the dual CFT. As a byproduct, our work sheds light on the nature of the AdS$_3$ reparametrization theory used to effectively compute Virasoro vacuum blocks at large central charge, as the reparametrization mode is now understood as a fluctuation of the fluid velocity.",
          "authors": [
            "Kevin Nguyen"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.03963",
          "title": "Combinatorial K3 surfaces and the Mori fan of the Dolgachev--Nikulin--Voisin family in degree 2",
          "abstract": "We introduce the notion of a combinatorial K3 surface. Those form a certain class of type III semistable K3 surfaces and are completely determined by combinatorial data called curve structures. Emphasis is put on degree $2$ combinatorial K3 surfaces, but the approach can be used to study higher degree as well. We describe elementary modifications both in terms of the curve structures as well as on the Picard groups. Together with a description of the nef cone in terms of curve structures, this provides an approach to explicitly computing the Mori fan of the Dolgachev--Nikulin--Voisin family in degree $2$.",
          "authors": [
            "Klaus Hulek",
            "Christian Lehn"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.04216",
          "title": "Computational Model for Photoionization in Pure SF6 Streamer at 1-15 atm",
          "abstract": "Photoionization plays a crucial role in achieving accurate quantitative predictions in SF6 streamer simulations, but accurate models for SF6 photoionization remains limited, motivating this paper. First, we develop a computational model for SF6 photoionization and provide the detailed theoretical modeling process, as well as comparison between experiment and simulation. A concise summary of model parameters within the comprehensive pressure range of 1 - 15 atm is provided for direct reference. Then, we perform comparative studies against simplified approaches. The results demonstrate that the proposed model effectively captures the non-local effects of SF6 photoionization, enhancing both the spatial numerical convergence and the accuracy of the streamer structure. Finally, we perform comparative studies by artificially increasing the photoionization intensity through multiplying the photoionization source term Sph by a factor of 50 (50*Sph) relative to the baseline intensity. Regarding breakdown voltage prediction, 50*Sph leads to a significant underestimation of the breakdown voltage for positive streamers, introducing errors greater than 0.5 kV, while exerting a small impact on negative streamers. Regarding streamer propagation dynamics, the radius of the positive streamer head exhibits pronounced shrinking, and 50*Sph reduces this shrinking and significantly lowers the head field by more than 700 Td. In contrast, 50*Sph has little impact on the morphology of the negative streamers and slightly enhances the head field by less than 30 Td.",
          "authors": [
            "Zihao Feng",
            "Liyang Zhang",
            "Xiaobing Zou",
            "Haiyun Luo"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.06369",
          "title": "Yang-Lee Quantum Criticality in Various Dimensions",
          "abstract": "The Yang-Lee universality class arises when imaginary magnetic field is tuned to its critical value in the paramagnetic phase of the $d<6$ Ising model. In $d=2$, this non-unitary Conformal Field Theory (CFT) is exactly solvable via the $M(2,5)$ minimal model. As found long ago by von Gehlen using Exact Diagonalization, the corresponding real-time, quantum critical behavior arises in the periodic Ising spin chain when the imaginary longitudinal magnetic field is tuned to its critical value from below. Even though the Hamiltonian is not Hermitian, the energy levels are real due to the $PT$ symmetry. In this paper, we explore the analogous quantum critical behavior in higher dimensional non-Hermitian Hamiltonians on regularized spheres $S^{d-1}$. For $d=3$, we use the recently invented, powerful fuzzy sphere method, as well as discretization by the platonic solids cube, icosahedron and dodecaherdron. The low-lying energy levels and structure constants we find are in agreement with expectations from the conformal symmetry. The energy levels are in good quantitative agreement with the high-temperature expansions and with Padé extrapolations of the $6-\\epsilon$ expansions in Fisher's $i\\phi^3$ Euclidean field theory for the Yang-Lee criticality. In the course of this work, we clarify some aspects of matching between operators in this field theory and quasiprimary fields in the $M(2,5)$ minimal model. For $d=4$, we obtain new results by replacing the $S^3$ with the self-dual polytope called the $24$-cell.",
          "authors": [
            "Erick Arguello Cruz",
            "Igor R. Klebanov",
            "Grigory Tarnopolsky",
            "Yuan Xin"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.07725",
          "title": "Quantum Process Tomography with Digital Twins of Error Matrices",
          "abstract": "Accurate and robust quantum process tomography (QPT) is crucial for verifying quantum gates and diagnosing implementation faults in experiments aimed at building universal quantum computers. However, the reliability of QPT protocols is often compromised by faulty probes, particularly state preparation and measurement (SPAM) errors, which introduce fundamental inconsistencies in traditional QPT algorithms. We propose and investigate enhanced QPT for multi-qubit systems by integrating the error matrix in a digital twin of the identity process matrix, enabling statistical refinement of SPAM error learning and improving QPT precision. Through numerical simulations, we demonstrate that our approach enables highly accurate and faithful process characterization. We further validate our method experimentally using superconducting quantum gates, achieving at least an order-of-magnitude fidelity improvement over standard QPT. Our results provide a practical and precise method for assessing quantum gate fidelity and enhancing QPT on a given hardware.",
          "authors": [
            "Tangyou Huang",
            "Akshay Gaikwad",
            "Ilya Moskalenko",
            "Anuj Aggarwal",
            "Tahereh Abad",
            "Marko Kuzmanovic",
            "Yu-Han Chang",
            "Ognjen Stanisavljevic",
            "Emil Hogedal",
            "Christopher Warren",
            "Irshad Ahmad",
            "Janka Biznárová",
            "Amr Osman",
            "Mamta Dahiya",
            "Marcus Rommel",
            "Anita Fadavi Rousari",
            "Andreas Nylander",
            "Liangyu Chen",
            "Jonas Bylander",
            "Gheorghe Sorin Paraoanu",
            "Anton Frisk Kockum",
            "Giovanna Tancredi"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.11220",
          "title": "Singularity Categories of Bäckström Orders",
          "abstract": "Bäckström orders are a class of algebras over complete discrete valuation rings. Their Cohen-Macaulay representations are in correspondence with the representations of certain quivers/species by Ringel and Roggenkamp. In this paper, we give explicit descriptions of the singularity categories of Bäckström orders via certain von Neumann regular algebras and associated bimodules. We further provide singular equivalences between Bäckström orders and specific finite dimensional radical square zero algebras. We also classify weakly regular, Gorenstein, Iwanaga-Gorenstein and sg-Hom-finite Bäckström orders.",
          "authors": [
            "Hongrui Wei"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.11414",
          "title": "A Multigraph Characterization of Permutiple Strings",
          "abstract": "A permutiple is a natural number whose representation in some base is an integer multiple of a number whose representation has the same collection of digits. A previous paper utilizes a finite-state-machine construction and its state graph to recognize permutiples and to generate new examples. Permutiples are associated with walks on the state graph which necessarily satisfy certain conditions. However, the above effort does not provide sufficient conditions for the existence of permutiples. In this paper, we provide such a condition which we will state using the language of multigraphs.",
          "authors": [
            "Benjamin V. Holt"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.12093",
          "title": "Root-$T\\overline{T}$ deformed CFT partition functions at large central charge",
          "abstract": "In this work, we investigate the partition function of 2d CFT under root-$T\\bar{T}$ deformation. We demonstrate that the deformed partition function satisfies a flow equation. At large central charge sector, the deformed partition function reduces to a redefinition of the modular parameters, which preserves modular invariance under the deformed parameters. We then derive a Cardy-like formula for the asymptotic density of states using modular bootstrap trick. In the context of AdS/CFT, it was proposed the root-$T\\bar{T}$ deformed CFT corresponds to the AdS$_3$ with certain deformed boundary condition. We show the deformed BTZ black hole is a quotient of hyperbolic space. In terms of Chern-Simons formulation, we compute the root-$T\\bar{T}$ deformed BTZ black hole entropy and find that it obeys a Cardy-like formula, which is consistent with the modular bootstrap result. Furthermore, employing the Wilson spool technique, we compute the one-loop partition functions for the root-$T\\bar{T}$ deformed AdS$_3$ geometry. Our results reveal an exact match between one-loop gravitational partition function and the large $c$ expansion of root-$T\\bar{T}$ deformed CFT partition function.",
          "authors": [
            "Miao He"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.12093",
          "title": "Root-$T\\overline{T}$ deformed CFT partition functions at large central charge",
          "abstract": "In this work, we investigate the partition function of 2d CFT under root-$T\\bar{T}$ deformation. We demonstrate that the deformed partition function satisfies a flow equation. At large central charge sector, the deformed partition function reduces to a redefinition of the modular parameters, which preserves modular invariance under the deformed parameters. We then derive a Cardy-like formula for the asymptotic density of states using modular bootstrap trick. In the context of AdS/CFT, it was proposed the root-$T\\bar{T}$ deformed CFT corresponds to the AdS$_3$ with certain deformed boundary condition. We show the deformed BTZ black hole is a quotient of hyperbolic space. In terms of Chern-Simons formulation, we compute the root-$T\\bar{T}$ deformed BTZ black hole entropy and find that it obeys a Cardy-like formula, which is consistent with the modular bootstrap result. Furthermore, employing the Wilson spool technique, we compute the one-loop partition functions for the root-$T\\bar{T}$ deformed AdS$_3$ geometry. Our results reveal an exact match between one-loop gravitational partition function and the large $c$ expansion of root-$T\\bar{T}$ deformed CFT partition function.",
          "authors": [
            "Miao He"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.13960",
          "title": "Inelastic Boltzmann equation under shear heating",
          "abstract": "In this paper, we study the spatially homogeneous inelastic Boltzmann equation for the angular cutoff pseudo-Maxwell molecules with an additional term of linear deformation. We establish the existence of non-Maxwellian self-similar profiles under the assumption of small deformation in the nearly elastic regime, and also obtain weak convergence to these self-similar profiles for global-in-time solutions with initial data that have finite mass and finite $p$-th order moment for any $2<p\\leq 4$. Our results confirm the competition between shear heating and inelastic cooling that governs the large time behavior of temperature. Specifically, temperature increases to infinity if shear heating dominates, decreases to zero if inelastic cooling prevails, and converges to a positive constant if the two effects are balanced. In the balanced scenario, the corresponding self-similar profile aligns with the steady solution.",
          "authors": [
            "José A. Carrillo",
            "Kam Fai Chan",
            "Renjun Duan",
            "Zongguang Li"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.16545",
          "title": "$\\mathcal{PT-}$Symmetric Open Quantum Systems: Information Theoretic Facets",
          "abstract": "The theory of an $\\eta$-pseudo Hermitian Hamiltonian with $\\mathcal{PT}$ symmetry is reviewed and extended to include open system dynamics. A first-principles derivation of the generalized Gorini-Kossakowski-Sudarshan-Lindblad master equation appropriate for a $\\mathcal{PT}-$symmetric Hamiltonian is presented. Inspired by a simple light matter interaction open system model, information theoretic quantities like a non-Markovian witness and fidelity are calculated for the $\\mathcal{PT-}$symmetric Hamiltonian, and the results are compared with their corresponding Hermitian counterparts. The nature of entanglement between two $\\mathcal{PT-}$symmetric and Hermitian open quantum systems is calculated, and the contrast observed.",
          "authors": [
            "Baibhab Bose",
            "Devvrat Tiwari",
            "Subhashish Banerjee"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.16545",
          "title": "$\\mathcal{PT-}$Symmetric Open Quantum Systems: Information Theoretic Facets",
          "abstract": "The theory of an $\\eta$-pseudo Hermitian Hamiltonian with $\\mathcal{PT}$ symmetry is reviewed and extended to include open system dynamics. A first-principles derivation of the generalized Gorini-Kossakowski-Sudarshan-Lindblad master equation appropriate for a $\\mathcal{PT}-$symmetric Hamiltonian is presented. Inspired by a simple light matter interaction open system model, information theoretic quantities like a non-Markovian witness and fidelity are calculated for the $\\mathcal{PT-}$symmetric Hamiltonian, and the results are compared with their corresponding Hermitian counterparts. The nature of entanglement between two $\\mathcal{PT-}$symmetric and Hermitian open quantum systems is calculated, and the contrast observed.",
          "authors": [
            "Baibhab Bose",
            "Devvrat Tiwari",
            "Subhashish Banerjee"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.17811",
          "title": "Light-Driven Bound State of Interacting Impurities in a Dirac-Like Bath",
          "abstract": "Strongly correlated quantum impurities under periodic driving can exhibit emergent non-Hermitian phenomena, yet a microscopic understanding has been lacking. We introduce an auxiliary-fermion framework that captures the bath's spin-orbit and angular-momentum structure and generates an effective low-energy theory with symmetry-protected spin-selective gain-loss channels. Exceptional points (EPs) arise dynamically from hybridization, without inserting non-Hermitian terms by hand, while causality is preserved via sign-reversing contributions. Near EPs, eigenvector non-orthogonality strongly enhances the impurity density of states, boosting the Kondo scale according to the condition number of the effective Hamiltonian. This DOS enhancement provides a directly measurable signature of EPs in impurity systems when spin-flip processes are induced experimentally. The pseudo-Hermitian structure further enables a biorthogonal thermodynamic Bethe ansatz treatment of interactions. Our results establish a unified route by which driven environments can engineer correlated, emergent non-Hermitian impurity states, opening a new avenue to control quantum many-body systems far from equilibrium.",
          "authors": [
            "Vinayak M. Kulkarni"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.20153",
          "title": "The Harmonic Entropy Estimator: Minimax Optimality and Semiparametric Efficiency for Infinite Alphabets",
          "abstract": "This paper considers the estimation of Shannon entropy for discrete distributions with countably infinite support. While minimax rates for finite-support distributions are established, infinite-support distributions present distinct challenges regarding bias control as probabilities vanish. We address this by introducing the \\textit{harmonic entropy estimator}, a statistic derived from an exact algebraic identity relating the expectation of harmonic-transformed binomial counts to the logarithm of underlying success probabilities. We establish two main results characterizing the statistical limits of this problem. First, for the class of distributions with at least quadratically decaying tails ($p_j\\lesssim j^{-2}$), we prove that the estimator achieves the parametric $L_2$-minimax convergence rate of order $1/n$. Second, under the stronger condition $p_j =o(j^{-2})$, we demonstrate that the estimator is semiparametrically efficient, converging to a normal distribution with variance matching the asymptotic efficiency bound $\\textrm{Var}[\\log p(X)]$. These results unify entropy estimation theory for finite-variance distributions, and provide a simple, one-step estimator with sharp theoretical guarantees.",
          "authors": [
            "Octavio César Mesner"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.20153",
          "title": "The Harmonic Entropy Estimator: Minimax Optimality and Semiparametric Efficiency for Infinite Alphabets",
          "abstract": "This paper considers the estimation of Shannon entropy for discrete distributions with countably infinite support. While minimax rates for finite-support distributions are established, infinite-support distributions present distinct challenges regarding bias control as probabilities vanish. We address this by introducing the \\textit{harmonic entropy estimator}, a statistic derived from an exact algebraic identity relating the expectation of harmonic-transformed binomial counts to the logarithm of underlying success probabilities. We establish two main results characterizing the statistical limits of this problem. First, for the class of distributions with at least quadratically decaying tails ($p_j\\lesssim j^{-2}$), we prove that the estimator achieves the parametric $L_2$-minimax convergence rate of order $1/n$. Second, under the stronger condition $p_j =o(j^{-2})$, we demonstrate that the estimator is semiparametrically efficient, converging to a normal distribution with variance matching the asymptotic efficiency bound $\\textrm{Var}[\\log p(X)]$. These results unify entropy estimation theory for finite-variance distributions, and provide a simple, one-step estimator with sharp theoretical guarantees.",
          "authors": [
            "Octavio César Mesner"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.20159",
          "title": "Many-body localization in a quantum Ising model with the long-range interaction: Accurate determination of the transition point",
          "abstract": "Many-body localization (MBL) transition emerges at strong disorder in interacting systems, separating chaotic and reversible dynamics. Although the existence of MBL transition within the macroscopic limit in spin chains with a short-range interaction was proved rigorously, the transition point is not found yet because of the dramatic sensitivity of the transition point to the chain length at computationally accessible lengths, possible due to local fluctuations destroying localization. Here we investigate MBL transition in the quantum Ising model (Ising model in a transverse field) with the long-range interaction suppressing the fluctuations similarly to that for the second-order phase transitions. We estimate the MBL threshold within the logarithmic accuracy using exact results for a somewhat similar localization problem on a Bethe lattice problem and show that our expectations are fully consistent with the estimate of the transition point using exact diagonalization. In spite of unlimited growing of the critical disorder within the thermodynamic limit, this result offers the opportunity to probe the critical behavior of the system near the transition point. Moreover, the model is relevant for the wide variety of physical systems with the long-range dipole-dipole, elastic or indirect exchange interactions.",
          "authors": [
            "Illia Lukin",
            "Andrii Sotnikov",
            "Alexander L. Burin"
          ],
          "primary_category": "cond-mat.dis-nn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22083",
          "title": "Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz",
          "abstract": "In this work, we introduce the first type of non-Euclidean neural quantum state (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent neural networks (RNNs)), to be used in the Variational Monte Carlo method of approximating the ground state energy for quantum many-body systems. In particular, we examine the performances of NQS ansatzes constructed from both conventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical settings of the one- and two-dimensional transverse field Ising models (TFIM) and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$ systems. By virtue of the fact that, for all of the experiments performed in this work, hyperbolic GRU can yield performances comparable to or better than Euclidean RNNs, which have been extensively studied in these settings in the literature, our work is a proof-of-concept for the viability of hyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum many-body systems. Furthermore, in settings where the Hamiltonian displays a clear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ & $J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor interactions, our results show that hyperbolic GRU definitively outperforms its Euclidean version in almost all instances. The fact that these results are reminiscent of the established ones from natural language processing where hyperbolic GRU almost always outperforms Euclidean RNNs when the training data exhibit a tree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU NQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin systems that involve different degrees of nearest neighbor interactions. Finally, with this work, we hope to initiate future studies of other types of non-Euclidean NQS beyond hyperbolic GRU.",
          "authors": [
            "H. L. Dao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22083",
          "title": "Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz",
          "abstract": "In this work, we introduce the first type of non-Euclidean neural quantum state (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent neural networks (RNNs)), to be used in the Variational Monte Carlo method of approximating the ground state energy for quantum many-body systems. In particular, we examine the performances of NQS ansatzes constructed from both conventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical settings of the one- and two-dimensional transverse field Ising models (TFIM) and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$ systems. By virtue of the fact that, for all of the experiments performed in this work, hyperbolic GRU can yield performances comparable to or better than Euclidean RNNs, which have been extensively studied in these settings in the literature, our work is a proof-of-concept for the viability of hyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum many-body systems. Furthermore, in settings where the Hamiltonian displays a clear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ & $J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor interactions, our results show that hyperbolic GRU definitively outperforms its Euclidean version in almost all instances. The fact that these results are reminiscent of the established ones from natural language processing where hyperbolic GRU almost always outperforms Euclidean RNNs when the training data exhibit a tree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU NQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin systems that involve different degrees of nearest neighbor interactions. Finally, with this work, we hope to initiate future studies of other types of non-Euclidean NQS beyond hyperbolic GRU.",
          "authors": [
            "H. L. Dao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22083",
          "title": "Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz",
          "abstract": "In this work, we introduce the first type of non-Euclidean neural quantum state (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent neural networks (RNNs)), to be used in the Variational Monte Carlo method of approximating the ground state energy for quantum many-body systems. In particular, we examine the performances of NQS ansatzes constructed from both conventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical settings of the one- and two-dimensional transverse field Ising models (TFIM) and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$ systems. By virtue of the fact that, for all of the experiments performed in this work, hyperbolic GRU can yield performances comparable to or better than Euclidean RNNs, which have been extensively studied in these settings in the literature, our work is a proof-of-concept for the viability of hyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum many-body systems. Furthermore, in settings where the Hamiltonian displays a clear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ & $J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor interactions, our results show that hyperbolic GRU definitively outperforms its Euclidean version in almost all instances. The fact that these results are reminiscent of the established ones from natural language processing where hyperbolic GRU almost always outperforms Euclidean RNNs when the training data exhibit a tree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU NQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin systems that involve different degrees of nearest neighbor interactions. Finally, with this work, we hope to initiate future studies of other types of non-Euclidean NQS beyond hyperbolic GRU.",
          "authors": [
            "H. L. Dao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22083",
          "title": "Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz",
          "abstract": "In this work, we introduce the first type of non-Euclidean neural quantum state (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent neural networks (RNNs)), to be used in the Variational Monte Carlo method of approximating the ground state energy for quantum many-body systems. In particular, we examine the performances of NQS ansatzes constructed from both conventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical settings of the one- and two-dimensional transverse field Ising models (TFIM) and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$ systems. By virtue of the fact that, for all of the experiments performed in this work, hyperbolic GRU can yield performances comparable to or better than Euclidean RNNs, which have been extensively studied in these settings in the literature, our work is a proof-of-concept for the viability of hyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum many-body systems. Furthermore, in settings where the Hamiltonian displays a clear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ & $J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor interactions, our results show that hyperbolic GRU definitively outperforms its Euclidean version in almost all instances. The fact that these results are reminiscent of the established ones from natural language processing where hyperbolic GRU almost always outperforms Euclidean RNNs when the training data exhibit a tree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU NQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin systems that involve different degrees of nearest neighbor interactions. Finally, with this work, we hope to initiate future studies of other types of non-Euclidean NQS beyond hyperbolic GRU.",
          "authors": [
            "H. L. Dao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22557",
          "title": "On lattice-polarized K3 surfaces",
          "abstract": "We propose modifications to the commonly used definitions of lattice-polarized and lattice-quasipolarized smooth K3 surfaces, collecting various versions of the definition, and determining the effects of these choices on the resulting moduli space. We fill a gap in the theory, by replacing Weyl chambers with the new notion of a ``small cone'': the true datum in the definition of lattice quasipolarized K3 surfaces. In addition, we describe the separated moduli stack and moduli space for lattice-polarized K3 surfaces with $ADE$ singularities, an important notion for applications.",
          "authors": [
            "Valery Alexeev",
            "Philip Engel"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.02329",
          "title": "A remark on Continuous K-theory and Fourier-Sato transform",
          "abstract": "In this note, we prove a generalization of Efimov's computation for the universal localizing invariant of categories of sheaves with certain microsupport constraints. The proof is based on certain categorical equivalences given by the Fourier-Sato transform, which is different from the original proof. As an application, we compute the universal localizing invariant of the category of almost quasi-coherent sheaves on the Novikov toric scheme introduced by Vaintrob.",
          "authors": [
            "Bingyu Zhang"
          ],
          "primary_category": "math.AT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.03937",
          "title": "Unveiling the different scaling regimes of the one-dimensional Kardar-Parisi-Zhang--Burgers equation using the functional renormalisation group",
          "abstract": "The Kardar-Parisi-Zhang (KPZ) equation is a celebrated non-linear stochastic equation featuring non-equilibrium scaling. Although in one dimension, its statistical properties are very well understood, a new scaling regime has been reported in recent numerical simulations. This new regime is characterised by a dynamical exponent $z=1$, markedly different from the expected one $z=3/2$ for the KPZ universality class, and it emerges when approaching the inviscid limit. The origin of this scaling has been traced down to the existence of a new fixed point, termed the inviscid Burgers (IB) fixed point, which was uncovered using the functional renormalisation group (FRG). The FRG equations can be solved analytically in the asymptotic regime of vanishing viscosity and large momenta, showing that indeed $z=1$ exactly at the IB fixed point. In this work, we set up an advanced method to numerically solve the full FRG flow equations in a certain approximation, which allows us to determine in a unified way the correlation function over the whole range of momenta, not restricted to some particular regime. We analyse the crossover between the different fixed points, and quantitatively determine the extent of the IB regime.",
          "authors": [
            "Liubov Gosteva",
            "Nicolás Wschebor",
            "Léonie Canet"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.04520",
          "title": "Free Probability approach to spectral and operator statistics in Rosenzweig-Porter random matrix ensembles",
          "abstract": "Utilizing the framework of free probability, we analyze the spectral and operator statistics of the Rosenzweig-Porter random matrix ensembles, which exhibit a rich phase structure encompassing ergodic, fractal, and localized regimes. Leveraging subordination formulae, we develop a perturbative scheme that yields semi-analytic expressions for the density of states up to second order in system size, in good agreement with numerical results. We compute higher-point correlation functions in the ergodic regime using both numerical and suitable analytic approximations. Our analysis of operator statistics for various spin operators across these regimes reveals close agreement with free probability predictions in the ergodic phase, in contrast to persistent deviations observed in the fractal and localized phases, even at late times. Notably, the fractal phase exhibits partial freeness while retaining memory of the initial spectrum, highlighting the importance of non-localized eigenstates and associated with the late-time dynamics of cumulative out-of-time-ordered-correlators (OTOCs). Employing distance measures and statistical tools such as the $\\chi^2$ statistic, Kullback-Leibler divergence, and Kolmogorov-Smirnov hypothesis testing, we define a characteristic time scale-the free time-that marks the onset of the validity of free probability predictions for operator spectral statistics in the ergodic phase. Remarkably, our findings demonstrate consistency across these different approaches.",
          "authors": [
            "Viktor Jahnke",
            "Pratik Nandy",
            "Kuntal Pal",
            "Hugo A. Camargo",
            "Keun-Young Kim"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.04520",
          "title": "Free Probability approach to spectral and operator statistics in Rosenzweig-Porter random matrix ensembles",
          "abstract": "Utilizing the framework of free probability, we analyze the spectral and operator statistics of the Rosenzweig-Porter random matrix ensembles, which exhibit a rich phase structure encompassing ergodic, fractal, and localized regimes. Leveraging subordination formulae, we develop a perturbative scheme that yields semi-analytic expressions for the density of states up to second order in system size, in good agreement with numerical results. We compute higher-point correlation functions in the ergodic regime using both numerical and suitable analytic approximations. Our analysis of operator statistics for various spin operators across these regimes reveals close agreement with free probability predictions in the ergodic phase, in contrast to persistent deviations observed in the fractal and localized phases, even at late times. Notably, the fractal phase exhibits partial freeness while retaining memory of the initial spectrum, highlighting the importance of non-localized eigenstates and associated with the late-time dynamics of cumulative out-of-time-ordered-correlators (OTOCs). Employing distance measures and statistical tools such as the $\\chi^2$ statistic, Kullback-Leibler divergence, and Kolmogorov-Smirnov hypothesis testing, we define a characteristic time scale-the free time-that marks the onset of the validity of free probability predictions for operator spectral statistics in the ergodic phase. Remarkably, our findings demonstrate consistency across these different approaches.",
          "authors": [
            "Viktor Jahnke",
            "Pratik Nandy",
            "Kuntal Pal",
            "Hugo A. Camargo",
            "Keun-Young Kim"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.04520",
          "title": "Free Probability approach to spectral and operator statistics in Rosenzweig-Porter random matrix ensembles",
          "abstract": "Utilizing the framework of free probability, we analyze the spectral and operator statistics of the Rosenzweig-Porter random matrix ensembles, which exhibit a rich phase structure encompassing ergodic, fractal, and localized regimes. Leveraging subordination formulae, we develop a perturbative scheme that yields semi-analytic expressions for the density of states up to second order in system size, in good agreement with numerical results. We compute higher-point correlation functions in the ergodic regime using both numerical and suitable analytic approximations. Our analysis of operator statistics for various spin operators across these regimes reveals close agreement with free probability predictions in the ergodic phase, in contrast to persistent deviations observed in the fractal and localized phases, even at late times. Notably, the fractal phase exhibits partial freeness while retaining memory of the initial spectrum, highlighting the importance of non-localized eigenstates and associated with the late-time dynamics of cumulative out-of-time-ordered-correlators (OTOCs). Employing distance measures and statistical tools such as the $\\chi^2$ statistic, Kullback-Leibler divergence, and Kolmogorov-Smirnov hypothesis testing, we define a characteristic time scale-the free time-that marks the onset of the validity of free probability predictions for operator spectral statistics in the ergodic phase. Remarkably, our findings demonstrate consistency across these different approaches.",
          "authors": [
            "Viktor Jahnke",
            "Pratik Nandy",
            "Kuntal Pal",
            "Hugo A. Camargo",
            "Keun-Young Kim"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.04520",
          "title": "Free Probability approach to spectral and operator statistics in Rosenzweig-Porter random matrix ensembles",
          "abstract": "Utilizing the framework of free probability, we analyze the spectral and operator statistics of the Rosenzweig-Porter random matrix ensembles, which exhibit a rich phase structure encompassing ergodic, fractal, and localized regimes. Leveraging subordination formulae, we develop a perturbative scheme that yields semi-analytic expressions for the density of states up to second order in system size, in good agreement with numerical results. We compute higher-point correlation functions in the ergodic regime using both numerical and suitable analytic approximations. Our analysis of operator statistics for various spin operators across these regimes reveals close agreement with free probability predictions in the ergodic phase, in contrast to persistent deviations observed in the fractal and localized phases, even at late times. Notably, the fractal phase exhibits partial freeness while retaining memory of the initial spectrum, highlighting the importance of non-localized eigenstates and associated with the late-time dynamics of cumulative out-of-time-ordered-correlators (OTOCs). Employing distance measures and statistical tools such as the $\\chi^2$ statistic, Kullback-Leibler divergence, and Kolmogorov-Smirnov hypothesis testing, we define a characteristic time scale-the free time-that marks the onset of the validity of free probability predictions for operator spectral statistics in the ergodic phase. Remarkably, our findings demonstrate consistency across these different approaches.",
          "authors": [
            "Viktor Jahnke",
            "Pratik Nandy",
            "Kuntal Pal",
            "Hugo A. Camargo",
            "Keun-Young Kim"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.04520",
          "title": "Free Probability approach to spectral and operator statistics in Rosenzweig-Porter random matrix ensembles",
          "abstract": "Utilizing the framework of free probability, we analyze the spectral and operator statistics of the Rosenzweig-Porter random matrix ensembles, which exhibit a rich phase structure encompassing ergodic, fractal, and localized regimes. Leveraging subordination formulae, we develop a perturbative scheme that yields semi-analytic expressions for the density of states up to second order in system size, in good agreement with numerical results. We compute higher-point correlation functions in the ergodic regime using both numerical and suitable analytic approximations. Our analysis of operator statistics for various spin operators across these regimes reveals close agreement with free probability predictions in the ergodic phase, in contrast to persistent deviations observed in the fractal and localized phases, even at late times. Notably, the fractal phase exhibits partial freeness while retaining memory of the initial spectrum, highlighting the importance of non-localized eigenstates and associated with the late-time dynamics of cumulative out-of-time-ordered-correlators (OTOCs). Employing distance measures and statistical tools such as the $\\chi^2$ statistic, Kullback-Leibler divergence, and Kolmogorov-Smirnov hypothesis testing, we define a characteristic time scale-the free time-that marks the onset of the validity of free probability predictions for operator spectral statistics in the ergodic phase. Remarkably, our findings demonstrate consistency across these different approaches.",
          "authors": [
            "Viktor Jahnke",
            "Pratik Nandy",
            "Kuntal Pal",
            "Hugo A. Camargo",
            "Keun-Young Kim"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.04847",
          "title": "Quantum Dialogue through Non-destructive Discrimination of Cluster State",
          "abstract": "We propose an efficient, measurement-based quantum dialogue protocol through non-destructive discrimination (NDD) of cluster state. We use ancilla-based measurements that allow the state to be reused without destroying its entanglement. The initial state is a local unitary (LU-) equivalent of the five-qubit cluster state, which significantly reduces the state components from 32 to 4, simultaneously allowing one to write its different subspaces using two different bases. The protocol utilizes single qubit unitaries from the Pauli group to encode the messages, thus preserving the stabilizer nature of the initial state throughout. We demonstrate that the proposed protocol is secure under common quantum attacks and outlining the procedure for the scalability of the scheme to transmit an n-bit message. The proposed protocol has been experimentally verified using IBM quantum backend 'IBM-Torino' as a proof of concept. Using the stabilizer nature of the state, we further introduce a single-qubit error correction mechanism that enhances robustness against noise without requiring any additional qubits. further, the use of NDD allows one to reuse the quantum resources in advancing the two-way dialogue, marking the importance and novelty of the proposed scheme over preexisting methods.",
          "authors": [
            "Mandar Thatte",
            "Shreya Banerjee",
            "Prasanta K. Panigrahi"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.07618",
          "title": "Error-mitigated quantum metrology via enhanced virtual purification",
          "abstract": "Quantum metrology stands as a leading application of quantum science and technology, yet noise often constrains its precision and sensitivity. In near-term quantum metrology, existing protocols largely depend on virtual state purification, but significant noise accumulation and additional noise from the implementations of these protocols can impede their effectiveness. We propose enhanced virtual channel purification to address these problems, yielding enhanced virtual state purification as a by-product. Within sequential quantum metrology schemes, our error analysis reveals substantial bias reduction and quantum advantages in sampling cost when the number of encoding channels is ${\\mathcal{O}}(p^{-1})$, where $p$ represents the error rate of encoding channels. In this range, our methods demonstrate significant improvements in parameter estimation precision and robustness against practical noise, as evidenced by numerical simulations for both single- and multi-parameter tasks. Particularly, these methods can naturally extend beyond quantum metrology, indicating their broad applicability in quantum information and quantum computation.",
          "authors": [
            "Xiaodie Lin",
            "Haidong Yuan"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.09356",
          "title": "Engineering Cryogenic FETs: Addressing SCEs and Impact of Interface Traps Down to 2 K Temperature",
          "abstract": "This paper presents the design and benchmarking of cryogenic bulk-FETs using an experimentally calibrated TCAD framework that integrates 2-D electrostatics and interface-trap effects from $T = 2$ K to 300 K. For a 28-nm node device, carrier transport is predominantly ballistic at $T = 2$ K and becomes quasi-ballistic as temperature increases. At cryogenic temperatures, higher interface-trap densities increase the effective threshold voltage and suppress subthreshold conduction. However, when the ON-state bias is adjusted to account for the trap-induced $V_t$ shift, interface traps are found to \\emph{worsen} $I_{\\mathrm{ON}}/I_{\\mathrm{OFF}}$ along with degrading the subthreshold swing (SS) and reducing mobility across all temperatures. The spatial standard deviation $\\sigma$ of the trap distribution modulates these behaviors: highly localized traps ($\\sigma \\sim 1$--$2$ nm) exacerbate short-channel effects (SCEs), whereas broader, nearly uniform distributions ($\\sigma \\ge 50$ nm) elevate the entire barrier and suppress SCEs until saturation as $\\sigma \\to L_g$. The TCAD predictions closely match experimental data at 4.2 K, 77 K, and 300 K, providing design guidelines to optimize $I_{\\mathrm{ON}}/I_{\\mathrm{OFF}}$, SS, mobility, and DIBL for cryogenic CMOS technology nodes.",
          "authors": [
            "Nilesh Pandey",
            "Dipanjan Basu",
            "Sanjay K. Banerjee"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.10965",
          "title": "Apparent inconsistency between Streda formula and Hall conductivity in reentrant integer quantum anomalous Hall effect in twisted MoTe$_2$",
          "abstract": "Recent experiments in twisted bilayer MoTe$_2$ (tMoTe$_2$) have uncovered a rich landscape of correlated phases. In this work, we investigate the reentrant integer quantum anomalous Hall (RIQAH) states reported by F. Xu, arXiv.2504.06972 which display a notable mismatch between the Hall conductivity measured via transport and that inferred from the Streda formula. We argue that this discrepancy can be explained if the RIQAH state is a quantum Hall bubble or Wigner crystal phase, analogous to similar well-established phenomena in two-dimensional (2D) GaAs quantum wells. While this explains the RIQAH state at filling $\\nu = -0.63$, F. Xu et al. report that the other RIQAH state at $\\nu = -0.7$ has a smaller slope, necessitating a different interpretation. We propose and substantiate with analysis of the experimental data that this discrepancy arises due to a nearby resistive peak masking the true slope. Furthermore, we identify this resistive peak as a signature of a phase transition near $\\nu = -0.75$, possibly driven by a van Hove singularity. The anomalous Hall response and Landau fan evolution across this transition suggest a change in Fermi-surface topology and a metallic phase with a non quantized Hall response. These observations offer new insights into the nature of the RIQAH states and raise the possibility that the nearby superconducting phase may have a valley-imbalanced metal parent state.",
          "authors": [
            "Yi Huang",
            "Seth Musser",
            "Jihang Zhu",
            "Yang-Zhi Chou",
            "Sankar Das Sarma"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12418",
          "title": "Noise tolerance via reinforcement: Learning a reinforced quantum dynamics",
          "abstract": "The performance of quantum simulations heavily depends on the efficiency of noise mitigation techniques and error correction algorithms. Reinforcement has emerged as a powerful strategy to enhance the efficiency of learning and optimization algorithms. In this study, we demonstrate that a reinforced quantum dynamics can exhibit significant robustness against interactions with a noisy environment. We study a quantum annealing process where, through reinforcement, the system is encouraged to maintain its current state or follow a noise-free evolution. A learning algorithm is employed to derive a concise approximation of this reinforced dynamics, reducing the total evolution time and, consequently, the system's exposure to noisy interactions. This also avoids the complexities associated with implementing quantum feedback in such reinforcement algorithms. The efficacy of our method is demonstrated through numerical simulations of reinforced quantum annealing with one- and two-qubit systems under Pauli noise.",
          "authors": [
            "Abolfazl Ramezanpour"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12418",
          "title": "Noise tolerance via reinforcement: Learning a reinforced quantum dynamics",
          "abstract": "The performance of quantum simulations heavily depends on the efficiency of noise mitigation techniques and error correction algorithms. Reinforcement has emerged as a powerful strategy to enhance the efficiency of learning and optimization algorithms. In this study, we demonstrate that a reinforced quantum dynamics can exhibit significant robustness against interactions with a noisy environment. We study a quantum annealing process where, through reinforcement, the system is encouraged to maintain its current state or follow a noise-free evolution. A learning algorithm is employed to derive a concise approximation of this reinforced dynamics, reducing the total evolution time and, consequently, the system's exposure to noisy interactions. This also avoids the complexities associated with implementing quantum feedback in such reinforcement algorithms. The efficacy of our method is demonstrated through numerical simulations of reinforced quantum annealing with one- and two-qubit systems under Pauli noise.",
          "authors": [
            "Abolfazl Ramezanpour"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12418",
          "title": "Noise tolerance via reinforcement: Learning a reinforced quantum dynamics",
          "abstract": "The performance of quantum simulations heavily depends on the efficiency of noise mitigation techniques and error correction algorithms. Reinforcement has emerged as a powerful strategy to enhance the efficiency of learning and optimization algorithms. In this study, we demonstrate that a reinforced quantum dynamics can exhibit significant robustness against interactions with a noisy environment. We study a quantum annealing process where, through reinforcement, the system is encouraged to maintain its current state or follow a noise-free evolution. A learning algorithm is employed to derive a concise approximation of this reinforced dynamics, reducing the total evolution time and, consequently, the system's exposure to noisy interactions. This also avoids the complexities associated with implementing quantum feedback in such reinforcement algorithms. The efficacy of our method is demonstrated through numerical simulations of reinforced quantum annealing with one- and two-qubit systems under Pauli noise.",
          "authors": [
            "Abolfazl Ramezanpour"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.14564",
          "title": "Revisiting a Successful Reduction Rule for Dominating Set",
          "abstract": "Given a graph $G = (V, E)$ with $n$ vertices and $m$ edges, the DominatingSet problem asks for a set $D \\subseteq V$ of minimal cardinality such that every vertex either is in $D$ or adjacent to a member of $D$. Although there is little hope for a kernelization algorithm on general graphs due to the W[2]-hardness of DominatingSet, data reduction rules are extensively used in practice. In this context, Rule1 due to Alber, Fellows, and Niedermeier [JACM 2004] has been shown to be very powerful, yet its best-known running time is $\\mathcal{O}(n^3)$ ($= \\mathcal{O}(nm)$) for general graphs. In this work, we propose, to the best of our knowledge, the first $\\mathcal{O}(n + m)$-time algorithm for Rule1 on general graphs. We additionally propose simple, but practically significant, extensions to our algorithmic framework to further prune the input instances. We complement our theoretical claims with experiments that confirm the practicality of our approach. On average, we see significant speedups of over one order of magnitude while removing $59.8\\times$ more nodes and $410.9\\times$ more edges than the original formulation across a large dataset comprised of real-world and synthetic networks.",
          "authors": [
            "Lukas Geis",
            "Alexander Leonhardt",
            "Johannes Meintrup",
            "Ulrich Meyer",
            "Manuel Penschuck",
            "Lukas Retschmeier"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.15071",
          "title": "The logical structure of contextuality and nonclassicality",
          "abstract": "Quantum contextuality represents a fundamental form of nonclassicality in quantum mechanics. To provide a more complete characterization of nonclassical properties in quantum systems, we adopt a logical perspective and propose a mathematical framework based on exclusive partial Boolean algebras (epBAs). This framework enables a unified description of contextuality and nonclassicality across finite general, quantum, and classical systems. We establish a unified and minimal classical counterpart for any finite general system. Within this framework, we formalize major categories of quantum contextuality, demonstrating that: 12 projectors suffice to generate Kochen-Specker scenarios; 10 projectors suffice to witness state-independent contextuality; and 3 observables suffice to witness quantum contextuality. Finally, we prove that contextuality is a sufficient but not necessary condition for nonclassicality.",
          "authors": [
            "Songyi Liu",
            "Yongjun Wang",
            "Baoshan Wang",
            "Chang He",
            "Jincheng Wang"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.16861",
          "title": "Matrix Invariants as Homotopy Invariants in Finite $T_0$-spaces",
          "abstract": "We establish a bijection between the set of finite topological $T_0$-spaces (or partially ordered sets) and equivalence classes of square matrices. The absolute value of the determinant or the rank of these matrices serve as simple homotopy invariants for the corresponding topological spaces, and consequently, for finite simplicial complexes. To conclude, we explore further relationships and problems concerning finite posets within the context of these matrices.",
          "authors": [
            "Pedro J. Chocano"
          ],
          "primary_category": "math.AT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.20230",
          "title": "Crystallization of Chiral Active Brownian Particles at Low Densities",
          "abstract": "Chiral active matter is a variant of active matter systems in which the motion of the constituent particles violates mirror symmetry. In this letter, we simulate two-dimensional chiral Active Brownian Particles, the simplest chiral model in which each particle undergoes circular motion, and show that the system crystallizes at low densities well below the melting point of the equilibrium counterpart. Crystallization is only possible if the orbital radius is long enough to align the circulating particles, but short enough for neighboring particles to avoid collisions. Of course, the system must be driven sufficiently far from equilibrium, since chirality cannot affect thermodynamic properties in classical equilibrium systems. The fluid-crystal phase diagram shows a re-entrant melting transition as a function of the radius of the circles. We show that at least one of the two transitions follows the same two-step melting scenario as in equilibrium systems.",
          "authors": [
            "Kangeun Jeong",
            "Yuta Kuroda",
            "Yuki Asatani",
            "Takeshi Kawasaki",
            "Kunimasa Miyazaki"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.21466",
          "title": "The Markov property for $φ^4_3$ on the cylinder",
          "abstract": "We prove that the $\\varphi^4_3$ model satisfies a version of Segal's axioms in the special case of three-dimensional tori and cylinders. As a consequence, we give the first proof that this model satisfies a Markov property and we characterize its boundary law up to absolutely continuous perturbations. In addition, we use Segal's axioms to give an alternative construction of the $\\varphi^4_3$ Hamiltonian on two-dimensional tori as compared with Glimm (Comm. Math. Phys., 1968). We exploit this probabilistic approach to prove novel fundamental spectral properties of the Hamiltonian, such as discrete spectrum and a Perron-Froebenius type result on its ground state. The key technical contributions of this article are the development of tools to analyze $\\varphi^4_3$ models with rough boundary conditions. We heavily use the variational approach to $\\varphi^4_3$ models introduced in Barashkov and Gubinelli (Duke, 2020) that is based on the Boué-Dupuis formula and dual to Polchinski's continuous renormalization group.",
          "authors": [
            "Nikolay Barashkov",
            "Trishen S. Gunaratnam"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.21466",
          "title": "The Markov property for $φ^4_3$ on the cylinder",
          "abstract": "We prove that the $\\varphi^4_3$ model satisfies a version of Segal's axioms in the special case of three-dimensional tori and cylinders. As a consequence, we give the first proof that this model satisfies a Markov property and we characterize its boundary law up to absolutely continuous perturbations. In addition, we use Segal's axioms to give an alternative construction of the $\\varphi^4_3$ Hamiltonian on two-dimensional tori as compared with Glimm (Comm. Math. Phys., 1968). We exploit this probabilistic approach to prove novel fundamental spectral properties of the Hamiltonian, such as discrete spectrum and a Perron-Froebenius type result on its ground state. The key technical contributions of this article are the development of tools to analyze $\\varphi^4_3$ models with rough boundary conditions. We heavily use the variational approach to $\\varphi^4_3$ models introduced in Barashkov and Gubinelli (Duke, 2020) that is based on the Boué-Dupuis formula and dual to Polchinski's continuous renormalization group.",
          "authors": [
            "Nikolay Barashkov",
            "Trishen S. Gunaratnam"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.22288",
          "title": "Daemonic ergotropy of Gaussian quantum states and the role of measurement-induced purification via general-dyne detection",
          "abstract": "According to the Maxwell demon paradigm, additional work can be extracted from a classical or quantum system by exploiting information obtained through measurements on a correlated ancillary system. In the quantum setting, the maximum work extractable via unitary operations in such measurement-assisted protocols is referred to as daemonic ergotropy. In this work, we explore this concept in the context of continuous-variable quantum systems, focusing on Gaussian states and general-dyne (Gaussian) measurements. We derive a general expression for the daemonic ergotropy and examine two key scenarios: (i) bipartite Gaussian states where a general-dyne measurement is performed on one of the two parties, and (ii) open Gaussian quantum systems under continuous general-dyne monitoring of the environment. Remarkably, we show that for single-mode Gaussian states, the ergotropy depends solely on the state's energy and purity. This enables us to express the daemonic ergotropy as a simple function of the unconditional energy and the purity of the conditional states, revealing that enhanced daemonic work extraction is directly linked to measurement-induced purification. We illustrate our findings through two paradigmatic examples: extracting daemonic work from a two-mode squeezed thermal state and from a continuously monitored optical parametric oscillator. In both case we identify the optimal general-dyne strategies that maximize the conditional purity and, in turn, the daemonic ergotropy.",
          "authors": [
            "K. H. Kua",
            "Alessio Serafini",
            "Marco G. Genoni"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.24122",
          "title": "Approximate half-integer quantization in anomalous planar transport in $d$-wave altermagnets",
          "abstract": "We investigate anomalous planar transport phenomena in a recently identified class of collinear magnetic materials known as $d$-wave altermagnets. The anomalous planar effects manifest in a configuration when the applied electric field/temperature gradient, magnetic field, and the measured Hall voltage are all co-planar, but the planar magnetic field is instrumental in breaking $\\hat{C}_{4z}\\hat{\\mathcal{T}}$ symmetry of the $d$-wave altermagnet, where $\\hat{\\mathcal{T}}$ is the time reversal operator, resulting in a Zeeman gap at a shifted Dirac node and a nonzero Berry curvature monopole. We demonstrate that these systems exhibit nearly half-quantized anomalous planar Hall and planar thermal Hall effects at low temperatures that persist over a range of magnetic fields. The angular dependence of the planar transport reveals a $\\cos2\\phi$ dependence on the magnetic field direction, where $\\phi$ is the azimuthal angle made by the magnetic field. We also discuss the anomalous planar Nernst effect, or transverse thermopower, and demonstrate that the Nernst conductivity peaks when the chemical potential lies just outside the induced Zeeman gap and vanishes within the gap. We further explore the dependence of all three coefficients on the polar and the azimuthal angle of the magnetic field when it is rotated in the full $3D$ space. Our results reveal the presence of approximately half-quantized anomalous planar thermal Hall plateau for a range of in-plane magnetic fields without requiring topological superconductivity and conducting Majorana modes, and can be probed in experiments in $d$-wave altermagnets.",
          "authors": [
            "Srimayi Korrapati",
            "Snehasish Nandy",
            "Sumanta Tewari"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.00661",
          "title": "Creep failure in heterogeneous materials from the barrier landscape",
          "abstract": "Stressed under a constant load, materials creep with a final acceleration of deformation and for any given applied stress and material, the creep failure time can strongly vary. We investigate creep on sheets of paper and confront the statistics with a simple fiber bundle model of creep failure in a disordered landscape. In the experiments, acoustic emission event times $t_j$ were recorded, and both this data and simulation event series reveal sample-dependent history effects with log-normal statistics and non-Markovian behavior. This leads to a relationship between $t_j$ and the failure time $t_f$ with a power law relationship, evolving with time. These effects and the predictability result from how the energy gap distribution develops during creep.",
          "authors": [
            "Juan Carlos Verano-Espitia",
            "Tero Mäkinen",
            "Mikko J. Alava",
            "Jérôme Weiss"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.02469",
          "title": "On the rate of exponential decay of coefficients on homogeneous spaces",
          "abstract": "For any homogeneous space of a noncompact semisimple Lie group $G$, we define an exponent with multiple interpretations from representation theory and group theory. As an application, we give a temperedness criterion for $L^2 (G/H)$ for any closed subgroup $H$ of $G$, which extends the existing ones of Benoist--Kobayashi for connected subgroups and Lutsko--Weich--Wolf for discrete subgroups.",
          "authors": [
            "Yves Benoist",
            "Siwei Liang"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.04063",
          "title": "On the rigidity of k-step nilpotent graph Lie algebras",
          "abstract": "We thoroughly explore the class of k-step nilpotent Lie algebras associated with a simple graph looking for k-step nilpotent Lie algebras which are rigid in the variety of at most k-step nilpotent Lie algebras. We find out that, besides the complete graph, the only examples arise for k=2 and graphs of at most 4 vertices. A key tool to prove non-k-rigidity in this context, is a general construction of non-trivial deformations for naturally graded nilpotent Lie algebras.",
          "authors": [
            "Josefina Barrionuevo",
            "Paulo Tirao"
          ],
          "primary_category": "math.RA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.07304",
          "title": "Scalable ADER-DG Transport Method with Polynomial Order Independent CFL Limit",
          "abstract": "Discontinuous Galerkin (DG) methods are known to suffer from increasingly restrictive explicit time-step constraints as the polynomial order increases, limiting their efficiency at high orders for explicit time-stepping schemes. In this paper, we introduce a novel \\emph{locally implicit}, but \\emph{globally explicit} ADER-DG scheme designed for transport-dominated problems. The method achieves a maximum stable time step governed by an element-width based CFL condition that is independent of the polynomial degree. By solving a set of element-local implicit problems at each time step, our approach more effectively utilises the domain of dependence. As a result, our method remains stable for CFL numbers up to $\\approx 1/\\sqrt{d}$ in $d$ spatial dimensions. We provide a rigorous stability proof in one dimension, and extend the analysis to two and three dimensions using a semi-analytical von Neumann stability analysis. The accuracy and convergence of the method are demonstrated through numerical experiments for both linear and nonlinear test cases, including numerical simulations of a transport problem on a cubed sphere 2D manifold embedded in 3D.",
          "authors": [
            "Kieran Ricardo",
            "Kenneth Duru"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.07304",
          "title": "Scalable ADER-DG Transport Method with Polynomial Order Independent CFL Limit",
          "abstract": "Discontinuous Galerkin (DG) methods are known to suffer from increasingly restrictive explicit time-step constraints as the polynomial order increases, limiting their efficiency at high orders for explicit time-stepping schemes. In this paper, we introduce a novel \\emph{locally implicit}, but \\emph{globally explicit} ADER-DG scheme designed for transport-dominated problems. The method achieves a maximum stable time step governed by an element-width based CFL condition that is independent of the polynomial degree. By solving a set of element-local implicit problems at each time step, our approach more effectively utilises the domain of dependence. As a result, our method remains stable for CFL numbers up to $\\approx 1/\\sqrt{d}$ in $d$ spatial dimensions. We provide a rigorous stability proof in one dimension, and extend the analysis to two and three dimensions using a semi-analytical von Neumann stability analysis. The accuracy and convergence of the method are demonstrated through numerical experiments for both linear and nonlinear test cases, including numerical simulations of a transport problem on a cubed sphere 2D manifold embedded in 3D.",
          "authors": [
            "Kieran Ricardo",
            "Kenneth Duru"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.07304",
          "title": "Scalable ADER-DG Transport Method with Polynomial Order Independent CFL Limit",
          "abstract": "Discontinuous Galerkin (DG) methods are known to suffer from increasingly restrictive explicit time-step constraints as the polynomial order increases, limiting their efficiency at high orders for explicit time-stepping schemes. In this paper, we introduce a novel \\emph{locally implicit}, but \\emph{globally explicit} ADER-DG scheme designed for transport-dominated problems. The method achieves a maximum stable time step governed by an element-width based CFL condition that is independent of the polynomial degree. By solving a set of element-local implicit problems at each time step, our approach more effectively utilises the domain of dependence. As a result, our method remains stable for CFL numbers up to $\\approx 1/\\sqrt{d}$ in $d$ spatial dimensions. We provide a rigorous stability proof in one dimension, and extend the analysis to two and three dimensions using a semi-analytical von Neumann stability analysis. The accuracy and convergence of the method are demonstrated through numerical experiments for both linear and nonlinear test cases, including numerical simulations of a transport problem on a cubed sphere 2D manifold embedded in 3D.",
          "authors": [
            "Kieran Ricardo",
            "Kenneth Duru"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.07942",
          "title": "The Richness of CSP Non-redundancy",
          "abstract": "In the field of constraint satisfaction problems (CSP), a clause is called redundant if its satisfaction is implied by satisfying all other clauses. An instance of CSP$(P)$ is called non-redundant if it does not contain any redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum number of clauses in a non-redundant instance of CSP$(P)$, as a function of the number of variables $n$. Recent progress has shown that non-redundancy is crucially linked to many other important questions in computer science and mathematics including sparsification, kernelization, query complexity, universal algebra, and extremal combinatorics. Given that non-redundancy is a nexus for many of these important problems, the central goal of this paper is to more deeply understand non-redundancy. Our first main result shows that for every rational number $r \\ge 1$, there exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is $\\Theta(n^r)$. Our second main result explores the concept of conditional non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We completely classify the conditional non-redundancy of all binary predicates (i.e., constraints on two variables) by connecting these non-redundancy problems to the structure of high-girth graphs in extremal combinatorics. Inspired by these concrete results, we build off the work of Carbonnel [CP 2022] to develop an algebraic theory of conditional non-redundancy. As an application of this algebraic theory, we revisit the notion of Mal'tsev embeddings, which is the most general technique known to date for establishing that a predicate has linear non-redundancy. For example, we provide the first example of predicate with a Mal'tsev embedding that cannot be attributed to the structure of an Abelian group, but rather to the structure of the quantum Pauli group.",
          "authors": [
            "Joshua Brakensiek",
            "Venkatesan Guruswami",
            "Bart M. P. Jansen",
            "Victor Lagerkvist",
            "Magnus Wahlström"
          ],
          "primary_category": "cs.DM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.07942",
          "title": "The Richness of CSP Non-redundancy",
          "abstract": "In the field of constraint satisfaction problems (CSP), a clause is called redundant if its satisfaction is implied by satisfying all other clauses. An instance of CSP$(P)$ is called non-redundant if it does not contain any redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum number of clauses in a non-redundant instance of CSP$(P)$, as a function of the number of variables $n$. Recent progress has shown that non-redundancy is crucially linked to many other important questions in computer science and mathematics including sparsification, kernelization, query complexity, universal algebra, and extremal combinatorics. Given that non-redundancy is a nexus for many of these important problems, the central goal of this paper is to more deeply understand non-redundancy. Our first main result shows that for every rational number $r \\ge 1$, there exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is $\\Theta(n^r)$. Our second main result explores the concept of conditional non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We completely classify the conditional non-redundancy of all binary predicates (i.e., constraints on two variables) by connecting these non-redundancy problems to the structure of high-girth graphs in extremal combinatorics. Inspired by these concrete results, we build off the work of Carbonnel [CP 2022] to develop an algebraic theory of conditional non-redundancy. As an application of this algebraic theory, we revisit the notion of Mal'tsev embeddings, which is the most general technique known to date for establishing that a predicate has linear non-redundancy. For example, we provide the first example of predicate with a Mal'tsev embedding that cannot be attributed to the structure of an Abelian group, but rather to the structure of the quantum Pauli group.",
          "authors": [
            "Joshua Brakensiek",
            "Venkatesan Guruswami",
            "Bart M. P. Jansen",
            "Victor Lagerkvist",
            "Magnus Wahlström"
          ],
          "primary_category": "cs.DM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.08090",
          "title": "Degree-one foliations on complete intersections",
          "abstract": "We prove that, under mild restrictions, the space of codimension-one foliations of degree one on a smooth projective complete intersection has two irreducible components of logarithmic type. We also prove that the same conclusion holds for any smooth hypersurface of dimension at least three that is not a quadric threefold. The proof of these results follows essentially from a more general structure theorem for foliations on manifolds covered by lines.",
          "authors": [
            "Mateus Figueira",
            "Crislaine Kuster",
            "Ruben Lizarbe",
            "Alan Muniz"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.08187",
          "title": "Stability of discrete-symmetry flocks: sandwich state, traveling domains and motility-induced pinning",
          "abstract": "Polar flocks in discrete active systems are often assumed to be robust, yet recent studies reveal their fragility under both imposed and spontaneous fluctuations. Here, we revisit the four-state active Potts model (APM) and show that its globally ordered phase is metastable across a broad swath of parameter space. Small counter-propagating droplets disrupt the flocking phase by inducing a persistent sandwich state, where the droplet-induced opposite-polarity lane remains embedded within the original flock, particularly pronounced at low noise, influenced by spatial anisotropy. In contrast, small transversely propagating droplets, when introduced into the flock, can trigger complete phase reversal due to their alignment orthogonal to the dominant flow and their enhanced persistence. At low diffusion and strong self-propulsion, such transverse droplets also emerge spontaneously, fragmenting the flock into multiple traveling domains and giving rise to a short-range order (SRO) regime. We further identify a motility-induced pinning (MIP) transition in small diffusion and low-temperature regimes when particles of opposite polarity interact, flip their state, hop, and pin an interface. Our comprehensive phase diagrams, encompassing full reversal, sandwich coexistence, stripe bands, SRO, and MIP, delineate how thermal fluctuations, self-propulsion strength, and diffusion govern flock stability in discrete active matter systems.",
          "authors": [
            "Swarnajit Chatterjee",
            "Mintu Karmakar",
            "Matthieu Mangeat",
            "Heiko Rieger",
            "Raja Paul"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.10988",
          "title": "Short geodesics and multiplicities of eigenvalues of hyperbolic surfaces",
          "abstract": "In this paper, we obtain upper bounds on the multiplicity of Laplacian eigenvalues for closed hyperbolic surfaces in terms of the number of short closed geodesics and the genus $g$. For example, we show that if the number of short closed geodesics is sublinear in $g$, then the multiplicity of the first eigenvalue is also sublinear in $g$. This makes new progress on a conjecture by Colin de Verdière in the mid 1980s.",
          "authors": [
            "Xiang He",
            "Yunhui Wu",
            "Haohao Zhang"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.12678",
          "title": "Exponential speed-up in VQE molecular energy ranking with Sridhara-compressed Hamiltonians",
          "abstract": "Polycyclic aromatic hydrocarbons (PAHs) are residual and intermediary molecules in the Chemical Vapor Deposition (CVD) to produce graphene from methane. Ranking a combinatorial space of variants of PAHs by energy allows the CVD to be optimized, while simulations of PAHs are strong candidates for quantum advantage in quantum computers. We extend on Sridhara's root formula to perform block diagonalization (SBD) of six PAHs using Hartree-Fock Hamiltonians with STO-3G basis set and $(2,2)$, $(4,4)$, $(6,6)$ settings of active orbitals and active electrons. We show that the proposed SBD algorithm followed by Variational Quantum Eigensolver (VQE) allows ranking molecules by ground state energy with $77.8\\%$ of success in comparison with the uncompressed VQE, while speeding up the VQE simulation in $164.16\\%$ (median) keeping its average error of active space reduction down to $0.09\\%$. We conclude that the flexibilization of constraints of the SBD algorithm makes it a fast and reliable estimator for active space reduction in molecular simulation.",
          "authors": [
            "Dennis Lima",
            "Saif Al-Kuwari"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.12678",
          "title": "Exponential speed-up in VQE molecular energy ranking with Sridhara-compressed Hamiltonians",
          "abstract": "Polycyclic aromatic hydrocarbons (PAHs) are residual and intermediary molecules in the Chemical Vapor Deposition (CVD) to produce graphene from methane. Ranking a combinatorial space of variants of PAHs by energy allows the CVD to be optimized, while simulations of PAHs are strong candidates for quantum advantage in quantum computers. We extend on Sridhara's root formula to perform block diagonalization (SBD) of six PAHs using Hartree-Fock Hamiltonians with STO-3G basis set and $(2,2)$, $(4,4)$, $(6,6)$ settings of active orbitals and active electrons. We show that the proposed SBD algorithm followed by Variational Quantum Eigensolver (VQE) allows ranking molecules by ground state energy with $77.8\\%$ of success in comparison with the uncompressed VQE, while speeding up the VQE simulation in $164.16\\%$ (median) keeping its average error of active space reduction down to $0.09\\%$. We conclude that the flexibilization of constraints of the SBD algorithm makes it a fast and reliable estimator for active space reduction in molecular simulation.",
          "authors": [
            "Dennis Lima",
            "Saif Al-Kuwari"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.14149",
          "title": "Integral fractional viscoelastic models in SPH: LAOS simulations versus experimental data",
          "abstract": "The rheological behaviour of a polymer was investigated by performing numerical simulations in complex flow and comparing them to experiments. For our simulations, we employed a Smoothed Particle Hydrodynamics scheme, utilizing an integral fractional model based on the K-BKZ framework. The results are compared with experiments performed on melt-state isotactic polypropylene under medium and large amplitude oscillatory shear. The numerical results are in good agreement with the experimental data, and the model is able to capture and predict both the linear and the non-linear viscoelastic behaviours of the polymer melt. Results show that equipping SPH with an integral fractional model is promising approach for the simulation of complex polymeric materials under realistic conditions.",
          "authors": [
            "Luca Santelli",
            "Adolfo Vázquez-Quesada",
            "Aizeti Burgoa",
            "Aitor Arriaga",
            "Rikardo Hernandez",
            "Marco Ellero"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.15835",
          "title": "Gauge dependence of momentum running in higher-derivative gravity",
          "abstract": "Recent works have argued that improved one-loop beta-functions capturing the physical momentum dependence of one-loop corrected higher-derivative gravity theories are the most suitable to describe their high-energy behaviour. This work critically tests the validity of this claim. We compute the explicit gauge dependence of the one-loop momentum running of curvature-squared operators in quadratic gravity and conformal gravity using the background field method. We find them to be gauge dependent, and we discuss the implications of this result for the theory and its physical predictivity.",
          "authors": [
            "Diego Buccio",
            "Gustavo P. De Brito",
            "Luca Parente"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.15835",
          "title": "Gauge dependence of momentum running in higher-derivative gravity",
          "abstract": "Recent works have argued that improved one-loop beta-functions capturing the physical momentum dependence of one-loop corrected higher-derivative gravity theories are the most suitable to describe their high-energy behaviour. This work critically tests the validity of this claim. We compute the explicit gauge dependence of the one-loop momentum running of curvature-squared operators in quadratic gravity and conformal gravity using the background field method. We find them to be gauge dependent, and we discuss the implications of this result for the theory and its physical predictivity.",
          "authors": [
            "Diego Buccio",
            "Gustavo P. De Brito",
            "Luca Parente"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.17720",
          "title": "Simulating the interplay of dipolar and quadrupolar interactions in NMR by spin dynamic mean-field theory",
          "abstract": "The simulation of nuclear magnetic resonance (NMR) experiments is a notoriously difficult task, if many spins participate in the dynamics. The recently established dynamic mean-field theory for high-temperature spin systems (spinDMFT) represents an efficient yet accurate method to deal with this scenario. SpinDMFT reduces a complex lattice system to a time-dependent single-site problem, which can be solved numerically with small computational effort. Since the approach retains local quantum degrees of freedom, a quadrupolar term can be exactly incorporated. This allows us to study the interplay of dipolar and quadrupolar interactions for any parameter range, i.e., without the need for a perturbative treatment. We obtain a remarkable agreement with experimental data for an aluminium nitride monocrystal, which strongly suggests the use of spinDMFT as a prediction tool. Furthermore, we draw a comparison between a quantum-mechanical and a classical version of spinDMFT showing that local quantum effects are of great importance for the studied type of system.",
          "authors": [
            "Timo Gräßer",
            "Götz S. Uhrig"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.17720",
          "title": "Simulating the interplay of dipolar and quadrupolar interactions in NMR by spin dynamic mean-field theory",
          "abstract": "The simulation of nuclear magnetic resonance (NMR) experiments is a notoriously difficult task, if many spins participate in the dynamics. The recently established dynamic mean-field theory for high-temperature spin systems (spinDMFT) represents an efficient yet accurate method to deal with this scenario. SpinDMFT reduces a complex lattice system to a time-dependent single-site problem, which can be solved numerically with small computational effort. Since the approach retains local quantum degrees of freedom, a quadrupolar term can be exactly incorporated. This allows us to study the interplay of dipolar and quadrupolar interactions for any parameter range, i.e., without the need for a perturbative treatment. We obtain a remarkable agreement with experimental data for an aluminium nitride monocrystal, which strongly suggests the use of spinDMFT as a prediction tool. Furthermore, we draw a comparison between a quantum-mechanical and a classical version of spinDMFT showing that local quantum effects are of great importance for the studied type of system.",
          "authors": [
            "Timo Gräßer",
            "Götz S. Uhrig"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.20432",
          "title": "Quasimodular forms that detect primes are Eisenstein",
          "abstract": "MacMahon's partition functions and their extensions provide equations that identify prime numbers as solutions. These results depend on the theory of (mixed weight) quasimodular forms on $SL_2(\\mathbb{Z})$. Two of the authors, along with Craig, conjectured an explicit description of the set of prime-detecting quasimodular forms in terms of Eisenstein series and their derivatives. Kane et al.\\ recently verified this conjecture using analytic methods. We offer an alternative proof using the theory of $\\ell$-adic Galois representations associated to modular forms.",
          "authors": [
            "Jan-Willem van Ittersum",
            "Lukas Mauth",
            "Ken Ono",
            "Ajit Singh"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.02745",
          "title": "Functional renormalization group study of rho condensate at a finite isospin chemical potential in the quark meson model",
          "abstract": "We investigate the effect of an isospin chemical potential ($\\mu_{I}$) within the quark-meson model, which approximates quantum chromodynamics (QCD) by modeling low energy phenomena such as chiral symmetry breaking and phase structure under varying conditions of temperature and chemical potential. Using the functional renormalization group (FRG) flow equations, we calculate the phase diagram in the chiral limit within the two-flavor quark-meson model in a finite $\\mu_{I}$ with $\\rho$ vector meson interactions. The $\\rho$ vector meson is condensed (in addition to the chiral condensate) when the isospin chemical potential reaches a critical value $\\mu_{I} = \\mu_{Icrit}$ for various chemical potentials. This occurs when $\\mu_{I} > \\mu_{Icrit}$. The $\\rho$ condensation that results is numerically produced at varying $\\rho$ meson couplings. The region dominated by the $\\rho$ meson is separated by a second-order phase transition line at low critical $\\mu_{I}$ and a first-order transition line at slightly higher values.",
          "authors": [
            "Mohammed Osman",
            "Defu Hou",
            "Wentao Wang",
            "Hui Zhang"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.02798",
          "title": "On harmonic approximation of Lipschitz functions on compacts in $\\mathbb{R}^d$",
          "abstract": "Given a porous compact $K \\subset \\mathbb{R}^d$ and a continuity modulus $\\omega$, we prove a quantitative Jackson-Bernstein type theorem on harmonic approximation. That is, a function $f$ belongs to the class $\\mathrm{Lip}_{\\omega}(K)$ if and only if $f$ can be approximated uniformly on $K$ with a rate of $\\omega(\\delta)$ by a function that is harmonic in the $\\delta$-neighborhood of $K$, provided the uniform estimate $\\omega(\\delta)/\\delta$ on the gradient holds.",
          "authors": [
            "Nikolai A. Shirokov",
            "Andrei V. Vasin"
          ],
          "primary_category": "math.FA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.03208",
          "title": "Topological band insulators without translational symmetry",
          "abstract": "In the research of the topological band phases, the conventional wisdom is to start from the crystalline translational symmetry systems. Nevertheless, the translational symmetry is not always a necessary condition for the energy bands. Here we propose a systematic method of constructing the topological band insulators without translational symmetry in the amorphous systems. By way of the isospectral reduction approach from spectral graph theory, we reduce the structural-disordered systems formed by different multi-atomic cells into the isospectral effective periodic systems with the energy-dependent hoppings and potentials. We identify the topological band insulating phases with extended bulk states and topological in-gap edge states by the topological invariants of the reduced systems, density of states, and the commutation of the transfer matrix. In addition, when the building blocks of the two multi-atomic cells have different number of the lattice sites, our numerical calculations demonstrate that the existences of the flat band and the macroscopic bound states in the continuum in the amorphous systems. Our findings uncover an arena for the exploration of the topological band states beyond translational symmetry systems paradigm.",
          "authors": [
            "Shuo Wang",
            "Jing-Run Lin",
            "Zheng-Wei Zuo"
          ],
          "primary_category": "cond-mat.dis-nn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.05593",
          "title": "Entangled Quantum Walkers for Secure Quantum Key Distribution",
          "abstract": "Quantum Key Distribution (QKD) is an emerging cryptographic method designed for secure key sharing. Its security is theoretically guaranteed by fundamental principles of quantum mechanics, making it a leading candidate for future communication protocols. Quantum Random Walks (QRWs), on the other hand, are quantum processes that exhibit intriguing phenomena such as interference and superposition, enabling the generation of decentralized and asymmetric probability distributions. Inspired by both fields of study, we propose a novel QKD protocol based on two entangled quantum walkers. Our protocol exploits the unique correlations between the walkers at extremal positions of the walk to establish secret keys shared exclusively by the two parties. The security of the protocol is augmented by analyzing the joint probability distributions of the walkers' measured positions and their associated coin states.",
          "authors": [
            "Chia-Tso Lai"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.06912",
          "title": "Anisotropic Water Structure at Charged Interfaces Studied by Depth Resolved Vibrational SFG/DFG Spectroscopy",
          "abstract": "The molecular water structure at charged aqueous interfaces is shaped by interfacial electric fields, which can induce significant anisotropy in the molecular orientations extending over nanometer-scale distances. Despite great relevance, very little is known about the details of this depth-dependent anisotropic water structure, mainly due to the lack of appropriate experimental techniques. Here, we present a depth-resolved study of the water anisotropy at the interface to insoluble charged surfactants using a newly developed technique which allows for directly correlating nonlinear vibrational spectra with depth information on the nanometer scale. We demonstrate that the obtained data allows for a full reconstruction of the nonlinear vibrational responses as function of depth. The results for the case of low salinity solutions show the presence of two pronounced regions within the interfacial anisotropy with largely deviating degrees of preferential molecular orientations. A spectral analysis of the depth-dependent vibrational responses furthermore reveals that the natural local hydrogen-bond structure of bulk water remains largely unperturbed throughout the interfacial region, including water in direct proximity of the surface charges. These findings significantly refine our understanding of the anisotropic water structure at the interface to hydrophilic charged surfactants and showcase the large potential of our depth-resolved spectroscopic technique.",
          "authors": [
            "Álvaro Diaz-Duque",
            "Vasileios Balos",
            "Martin Wolf",
            "Alexander P. Fellows",
            "Martin Thämer"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.06912",
          "title": "Anisotropic Water Structure at Charged Interfaces Studied by Depth Resolved Vibrational SFG/DFG Spectroscopy",
          "abstract": "The molecular water structure at charged aqueous interfaces is shaped by interfacial electric fields, which can induce significant anisotropy in the molecular orientations extending over nanometer-scale distances. Despite great relevance, very little is known about the details of this depth-dependent anisotropic water structure, mainly due to the lack of appropriate experimental techniques. Here, we present a depth-resolved study of the water anisotropy at the interface to insoluble charged surfactants using a newly developed technique which allows for directly correlating nonlinear vibrational spectra with depth information on the nanometer scale. We demonstrate that the obtained data allows for a full reconstruction of the nonlinear vibrational responses as function of depth. The results for the case of low salinity solutions show the presence of two pronounced regions within the interfacial anisotropy with largely deviating degrees of preferential molecular orientations. A spectral analysis of the depth-dependent vibrational responses furthermore reveals that the natural local hydrogen-bond structure of bulk water remains largely unperturbed throughout the interfacial region, including water in direct proximity of the surface charges. These findings significantly refine our understanding of the anisotropic water structure at the interface to hydrophilic charged surfactants and showcase the large potential of our depth-resolved spectroscopic technique.",
          "authors": [
            "Álvaro Diaz-Duque",
            "Vasileios Balos",
            "Martin Wolf",
            "Alexander P. Fellows",
            "Martin Thämer"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.08447",
          "title": "Locally Associated Orders in Real Quadratic Number Fields",
          "abstract": "In 2025, the concept of an order in a number field being associated, ideal-preserving, or locally associated was introduced in order to tackle problems in factorization. In this paper, we explore locally associated orders in real quadratic number fields of the form $\\mathbb{Q}[\\sqrt{p}]$, with $p\\in\\mathbb{N}$ prime. In particular, we develop strategies and produce results which make determining when a given order in such a number field is (or is not) locally associated much easier. We also highlight the relatively few cases which defy simple characterization, leading to a conjecture on the solutions to Pell's equations of the form $x^2-y^2p=1$.",
          "authors": [
            "Grant Moles",
            "Talha Khan"
          ],
          "primary_category": "math.AC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09266",
          "title": "SFEM for the unsteady Navier-Stokes Equations on a stationary surface",
          "abstract": "In this paper we consider a fully discrete numerical method for the unsteady Navier-Stokes equations on a smooth closed stationary surface in $\\mathbb{R}^3$. We use the surface finite element method (SFEM) with a generalized Taylor-Hood finite element pair $\\mathrm{\\mathbf{P}}_{k_u}$-- $\\mathrm{P}_{k_{pr}}$-- $\\mathrm{P}_{k_{\\lambda}}$, where we enforce the tangential condition of the velocity field weakly, by introducing an extra Lagrange multiplier $\\lambda$. Depending on the richness of the finite element space involving this extra Lagrange multiplier we present a fully discrete stability and error analysis. For the velocity, we establish optimal $L^{2}(a_h)$-norm bounds ($a_h$ - an energy norm) when $k_\\lambda=k_u$ and suboptimal with respect to the geometric approximation error when $k_{\\lambda} = k_u-1$ (optimal when \\emph{super-parametric finite elements} are used). For the pressure, optimal $L^2(L^2)$-norm error bounds are established when $k_\\lambda=k_u$. Assuming further regularity assumptions for our continuous problem, we are also able to show optimal convergence (using \\emph{super-parametric finite elements} again) when $k_\\lambda=k_u-1$. Numerical simulations that confirm the established theory are provided, along with a comparative analysis against a penalty approach.",
          "authors": [
            "Charles M. Elliott",
            "Achilleas Mavrakis"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09266",
          "title": "SFEM for the unsteady Navier-Stokes Equations on a stationary surface",
          "abstract": "In this paper we consider a fully discrete numerical method for the unsteady Navier-Stokes equations on a smooth closed stationary surface in $\\mathbb{R}^3$. We use the surface finite element method (SFEM) with a generalized Taylor-Hood finite element pair $\\mathrm{\\mathbf{P}}_{k_u}$-- $\\mathrm{P}_{k_{pr}}$-- $\\mathrm{P}_{k_{\\lambda}}$, where we enforce the tangential condition of the velocity field weakly, by introducing an extra Lagrange multiplier $\\lambda$. Depending on the richness of the finite element space involving this extra Lagrange multiplier we present a fully discrete stability and error analysis. For the velocity, we establish optimal $L^{2}(a_h)$-norm bounds ($a_h$ - an energy norm) when $k_\\lambda=k_u$ and suboptimal with respect to the geometric approximation error when $k_{\\lambda} = k_u-1$ (optimal when \\emph{super-parametric finite elements} are used). For the pressure, optimal $L^2(L^2)$-norm error bounds are established when $k_\\lambda=k_u$. Assuming further regularity assumptions for our continuous problem, we are also able to show optimal convergence (using \\emph{super-parametric finite elements} again) when $k_\\lambda=k_u-1$. Numerical simulations that confirm the established theory are provided, along with a comparative analysis against a penalty approach.",
          "authors": [
            "Charles M. Elliott",
            "Achilleas Mavrakis"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09690",
          "title": "Symanzik effective action for Karsten-Wilczek minimally doubled fermions",
          "abstract": "Karsten-Wilczek (KW) fermions are a popular variant of minimally doubled fermions. We construct Symanzik effective action for KW fermions, which is known to break the hypercubic symmetry of the lattice action. In this work we make the two fermionic modes, called tastes, explicit using the point-splitting proposal of Creutz and Misumi and write the KW action in terms of the taste fields. We identify the symmetries of the point-split action and write down the Symanzik effective action up to dimension-5, including the divergent dimension-3, operators for both free and interacting KW fermions.",
          "authors": [
            "Kunal Shukre",
            "Subhasish Basak"
          ],
          "primary_category": "hep-lat",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.14322",
          "title": "Quadrupole-conserving dynamics in the non-commutative plane",
          "abstract": "Inspired by ``fracton hydrodynamic\" universality classes of dynamics with unusual conservation laws, we present a new dynamical universality class that arises out of local area-preserving dynamics in the non-commutative plane. On this symplectic manifold, the area-preserving spatial symmetry group $\\mathrm{SL}(2,\\mathbb{R})\\rtimes \\mathbb{R}^2$ is a symmetry group compatible with non-trivial many-body dynamics. The conservation laws associated to this symmetry group correspond to the dipole and quadrupole moments of the particles. We study the unusual dynamics of a crystal lattice subject to such symmetries, and argue that the hydrodynamic description of lattice dynamics breaks down due to relevant nonlinearities. Numerical simulations of classical Hamiltonian dynamical systems with this symmetry are largely consistent with a tree-level effective field theory estimate for the endpoint of this instability.",
          "authors": [
            "Isabella Zane",
            "Andrew Lucas"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.16497",
          "title": "Correlation thresholds in the steady states of particle systems and spin glasses",
          "abstract": "A growing body of theoretical and empirical evidence shows that the global steady-state distributions of many equilibrium and nonequilibrium systems approximately satisfy an analogue of the Boltzmann distribution, with a local dynamical property of states playing the role of energy. The correlation between the effective potential of the steady-state distribution and the logarithm of the exit rates determines the quality of this approximation. We demonstrate and explain this phenomenon in a simple one-dimensional particle system and in random dynamics of the Sherrington-Kirkpatrick spin glass by providing the first explicit estimates of this correlation. We find that, as parameters of the dynamics vary, each system exhibits a threshold above and below which the correlation dramatically differs. We explain how these thresholds arise from underlying transitions in the relationship between the local and global \"parts\" of the effective potential.",
          "authors": [
            "Jacob Calvert",
            "Dana Randall"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.16497",
          "title": "Correlation thresholds in the steady states of particle systems and spin glasses",
          "abstract": "A growing body of theoretical and empirical evidence shows that the global steady-state distributions of many equilibrium and nonequilibrium systems approximately satisfy an analogue of the Boltzmann distribution, with a local dynamical property of states playing the role of energy. The correlation between the effective potential of the steady-state distribution and the logarithm of the exit rates determines the quality of this approximation. We demonstrate and explain this phenomenon in a simple one-dimensional particle system and in random dynamics of the Sherrington-Kirkpatrick spin glass by providing the first explicit estimates of this correlation. We find that, as parameters of the dynamics vary, each system exhibits a threshold above and below which the correlation dramatically differs. We explain how these thresholds arise from underlying transitions in the relationship between the local and global \"parts\" of the effective potential.",
          "authors": [
            "Jacob Calvert",
            "Dana Randall"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.19840",
          "title": "Multi-mode Deep Strong Coupling in a Multi Quantum Well Fabry-Perot Cavity",
          "abstract": "We present multi-mode deep-strong coupling in a multi-quantum well (N=166) heterostructure. The heterostructure itself acts as a Fabry-Perot cavity, for which the even cavity modes strongly couple to the cyclotron resonance to form Landau polaritons. The experimentally observed vacuum Rabi splitting is larger than the mode spacing and well into the deep-strong coupling regime ($\\eta>1$) resulting in a rich multi-mode polaritonic spectrum which is accurately reproduced by an all-to-all multi-photonic, multi-electronic Hopfield coupling model. Remarkably, light-matter decoupling is observed across the whole measurable spectrum, including in the low frequency limit ($\\lambda>>L_{cav}$) where the normalized coupling strength reaches $\\eta=8.1$. The system demonstrates a robust platform for exploring extreme coupling regimes and its chiral nature holds potential for chiral cavity and chiral mirror applications.",
          "authors": [
            "Lucy Hale",
            "Johan Andberger",
            "Ethan Koskas",
            "Frieder Lindel",
            "Mattias Beck",
            "Giacomo Scalari",
            "Jérôme Faist"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.19840",
          "title": "Multi-mode Deep Strong Coupling in a Multi Quantum Well Fabry-Perot Cavity",
          "abstract": "We present multi-mode deep-strong coupling in a multi-quantum well (N=166) heterostructure. The heterostructure itself acts as a Fabry-Perot cavity, for which the even cavity modes strongly couple to the cyclotron resonance to form Landau polaritons. The experimentally observed vacuum Rabi splitting is larger than the mode spacing and well into the deep-strong coupling regime ($\\eta>1$) resulting in a rich multi-mode polaritonic spectrum which is accurately reproduced by an all-to-all multi-photonic, multi-electronic Hopfield coupling model. Remarkably, light-matter decoupling is observed across the whole measurable spectrum, including in the low frequency limit ($\\lambda>>L_{cav}$) where the normalized coupling strength reaches $\\eta=8.1$. The system demonstrates a robust platform for exploring extreme coupling regimes and its chiral nature holds potential for chiral cavity and chiral mirror applications.",
          "authors": [
            "Lucy Hale",
            "Johan Andberger",
            "Ethan Koskas",
            "Frieder Lindel",
            "Mattias Beck",
            "Giacomo Scalari",
            "Jérôme Faist"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.20061",
          "title": "Frame Vector Group Representations and Amenability Properties",
          "abstract": "We provide a new characterization of amenability for countable groups, based on frame representations admitting almost invariant vectors. By relaxing the frame inequalities, thereby weakening amenability, we obtain a large class of countable groups which we call {\\it framenable}. We show that this class has some permanence properties, stands in contrast with property (T), and contains, for example, all free groups $\\mathbb{F}_n$, $\\textup{Aut}(\\mathbb{F}_2)$ and $\\textup{Aut}(\\mathbb{F}_3)$, all (countable) lattices of $SL(2,\\mathbb{R})$, the Baumslag-Solitar groups $BS_{p,q}$, the braid groups $B_n$, and Thompson's group $F$.",
          "authors": [
            "Dorin Ervin Dutkay",
            "Catalin Georgescu",
            "Gabriel Picioroaga"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.21638",
          "title": "Discrete quantum group coaction on the circle",
          "abstract": "We prove by an explicit calculation that if any Kac-type $C^*$-algebraic discrete quantum group $\\mathcal{Q}$ has a `weakly faithful' coaction on $C(S^1)$ which is `linear' in the sense that it leaves the space spanned by $\\{ Z, \\overline{Z} \\}$ invariant, then $\\mathcal{Q}$ must be classical, i.e. isomorphic with $C_0(\\Gamma)$ for some discrete group $\\Gamma$. This parallels the well-known result of non-existence of genuine compact quantum group symmetry obtained by the first author and his collaborators ([32] and the references therein).",
          "authors": [
            "Debashish Goswami",
            "Suchetana Samadder"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.00268",
          "title": "Remotely sensing stress evolution in elastic media: a passive approach to earthquake monitoring",
          "abstract": "Stress evolution governs material failure across scales, from microscopic fractures to large earthquakes, yet direct observation of its dynamics in natural systems has remained elusive. Laboratory experiments using active ultrasonic measurements have shown that seismic velocity and attenuation are sensitive to stress, but such monitoring has not previously been achievable remotely or passively. Here we introduce a stress-sensitive frequency-domain transform that enables passive monitoring of stress evolution using ambient seismic or acoustic noise. The method quantifies relative energy shifts between adjacent frequency bands, capturing subtle changes in wave-propagation properties linked to evolving shear and normal stress. Applied across scales, from laboratory stick-slip and slow-slip experiments to natural fault systems including the 2018 Kilauea collapse, Cascadia slow-slip episodes, and major earthquakes such as the 2011 Tohoku, 2010 Maule, 2002 Denali, and 2023 Turkey-Syria events, the transform consistently reveals distinctive precursory trajectories and stress-cycle patterns. These results demonstrate that stress evolution in elastic Earth materials can be remotely and passively monitored, bridging laboratory rock physics and large-scale seismology and offering a new foundation for real-time tracking of fault mechanics and earthquake preparation.",
          "authors": [
            "Nader Shakibay Senobari"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.00268",
          "title": "Remotely sensing stress evolution in elastic media: a passive approach to earthquake monitoring",
          "abstract": "Stress evolution governs material failure across scales, from microscopic fractures to large earthquakes, yet direct observation of its dynamics in natural systems has remained elusive. Laboratory experiments using active ultrasonic measurements have shown that seismic velocity and attenuation are sensitive to stress, but such monitoring has not previously been achievable remotely or passively. Here we introduce a stress-sensitive frequency-domain transform that enables passive monitoring of stress evolution using ambient seismic or acoustic noise. The method quantifies relative energy shifts between adjacent frequency bands, capturing subtle changes in wave-propagation properties linked to evolving shear and normal stress. Applied across scales, from laboratory stick-slip and slow-slip experiments to natural fault systems including the 2018 Kilauea collapse, Cascadia slow-slip episodes, and major earthquakes such as the 2011 Tohoku, 2010 Maule, 2002 Denali, and 2023 Turkey-Syria events, the transform consistently reveals distinctive precursory trajectories and stress-cycle patterns. These results demonstrate that stress evolution in elastic Earth materials can be remotely and passively monitored, bridging laboratory rock physics and large-scale seismology and offering a new foundation for real-time tracking of fault mechanics and earthquake preparation.",
          "authors": [
            "Nader Shakibay Senobari"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.00268",
          "title": "Remotely sensing stress evolution in elastic media: a passive approach to earthquake monitoring",
          "abstract": "Stress evolution governs material failure across scales, from microscopic fractures to large earthquakes, yet direct observation of its dynamics in natural systems has remained elusive. Laboratory experiments using active ultrasonic measurements have shown that seismic velocity and attenuation are sensitive to stress, but such monitoring has not previously been achievable remotely or passively. Here we introduce a stress-sensitive frequency-domain transform that enables passive monitoring of stress evolution using ambient seismic or acoustic noise. The method quantifies relative energy shifts between adjacent frequency bands, capturing subtle changes in wave-propagation properties linked to evolving shear and normal stress. Applied across scales, from laboratory stick-slip and slow-slip experiments to natural fault systems including the 2018 Kilauea collapse, Cascadia slow-slip episodes, and major earthquakes such as the 2011 Tohoku, 2010 Maule, 2002 Denali, and 2023 Turkey-Syria events, the transform consistently reveals distinctive precursory trajectories and stress-cycle patterns. These results demonstrate that stress evolution in elastic Earth materials can be remotely and passively monitored, bridging laboratory rock physics and large-scale seismology and offering a new foundation for real-time tracking of fault mechanics and earthquake preparation.",
          "authors": [
            "Nader Shakibay Senobari"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.02405",
          "title": "Compactness of compositions of strictly singular operators on direct sums of Baernstein, Schreier and $\\ell_p$-spaces",
          "abstract": "Let $X$ be the direct sum of finitely many Banach spaces chosen from the following three families: (i) the Baernstein spaces $B_p$ for $1<p<\\infty$; (ii) the $p$-convexified Schreier spaces $S_p$ for $1\\le p<\\infty$; (iii) the sequence spaces $\\ell_p$ for $1\\le p<\\infty$ (and $c_0$). We show that the quotient algebra of strictly singular by compact operators on $X$ is nilpotent; that is, there is a natural number $k$, dependent only on the collections of direct summands from each of the three families, such that: - every composition of $k+1$ strictly singular operators on $X$ is compact; - there are $k$ strictly singular operators on $X$ whose composition is not compact.",
          "authors": [
            "Niels Jakob Laustsen",
            "Henrik Wirzenius"
          ],
          "primary_category": "math.FA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.05077",
          "title": "The Deligne-Riemann-Roch isomorphism",
          "abstract": "This work establishes the geometric component of Deligne's longstanding program on refined Grothendieck-Riemann-Roch formulas expressed through determinants of cohomology. The approach relies on a newly developed universal category of Chern classes together with an associated relative intersection theory. As an example of the applications, we provide a structural description of the coefficients in the Knudsen-Mumford expansion and establish a fundamental Mumford-type isomorphism for the alternating product of Griffiths bundles.",
          "authors": [
            "Dennis Eriksson",
            "Gerard Freixas i Montplet"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.06305",
          "title": "Efficient Convex Optimization for Bosonic State Tomography",
          "abstract": "Quantum states encoded in electromagnetic fields, also known as bosonic states, have been widely applied in quantum sensing, quantum communication, and quantum error correction. Accurate characterization is therefore essential yet difficult when states cannot be reconstructed with sparse Pauli measurements. Tomography must work with dense measurement bases, high-dimensional Hilbert spaces, and often sample-based data. However, existing convex optimization-based techniques are not efficient enough and scale poorly when extended to large and multi-mode systems. In this work, we explore convex optimization as an effective framework to address problems in bosonic state tomography, introducing three techniques to enhance efficiency and scalability: efficient displacement operator computation, Hilbert space truncation, and stochastic convex optimization, which mitigate common limitations of existing approaches. Then we propose a sample-based, convex maximum-likelihood estimation (MLE) method specifically designed for flying mode tomography. Numerical simulations of flying four-mode and nine-mode problems demonstrate the accuracy and practicality of our methods. This method provides practical tools for reliable bosonic mode quantum state reconstruction in high-dimensional and multi-mode systems.",
          "authors": [
            "Shengyong Li",
            "Yanjin Yue",
            "Ying Hu",
            "Rui-Yang Gong",
            "Qianchuan Zhao",
            "Zhihui Peng",
            "Hou Ian",
            "Pengtao Song",
            "Zeliang Xiang",
            "Jing Zhang"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.13016",
          "title": "Arithmetic Duality",
          "abstract": "In the 1950s and 1960s Tate proved some duality theorems in the Galois cohomology of finite modules and abelian varieties. As for most of Tate's work this has had a profound influence on mathematics with many applications and further developments. In this article, I discuss Tate's theorems and some of these developments.",
          "authors": [
            "James S. Milne"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.13277",
          "title": "Odd-parity longitudinal magnetoconductivity in time-reversal symmetry broken materials",
          "abstract": "Magnetotransport measurements are a sensitive probe of symmetry and electronic structure in quantum materials. While conventional metals exhibit longitudinal magnetoconductivity that is even in a magnetic field ($B$) for small $B$, we show that magnetic materials which intrinsically break time-reversal symmetry (TRS) show an {\\it odd-parity magnetoconductivity} (OMC), with a leading linear-$B$ response. Using semiclassical transport theory, we derive explicit expressions for the longitudinal and transverse conductivities and identify their origin in Berry curvature and orbital magnetic moment. Crystalline symmetry analysis shows that longitudinal OMC follows the same point-group constraints as the anomalous Hall effect, while transverse OMC obeys distinct rules, providing an independent probe of TRS breaking. In the large $B$ quantum oscillation regime, we uncover both odd- and even-$B$ contributions, demonstrating OMC beyond the semiclassical picture. Explicit calculations in valley-polarized gapped graphene show that OMC peaks near the band edges, vanish in the band gap and follow the temperature dependence of the magnetic order parameter. Our results explain the odd-parity magnetoresistance recently observed in magnetized graphene and establish OMC as a robust transport signature of intrinsic TRS breaking in metals.",
          "authors": [
            "Sunit Das",
            "Akash Adhikary",
            "Divya Sahani",
            "Aveek Bid",
            "Amit Agarwal"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.17887",
          "title": "Coxeter-Dynkin algebras of canonical type",
          "abstract": "We propose a definition of Coxeter-Dynkin algebras of canonical type generalising the definition as a path algebra of a quiver. Moreover, we construct two tilting objects over the squid algebra - one via generalised APR-tilting and one via one-point-extensions and reflection functors - and identify their endomorphism algebras with the Coxeter-Dynkin algebra. This shows that our definition gives another representative in the derived equivalence class of the squid algebra, and hence of the corresponding canonical algebra. Finally, we have a closer look at the Grothendieck group and the Euler form which illustrates the connection to Saito's classification of marked extended affine root systems. On the other hand, this enables us to prove that in the domestic case Coxeter-Dynkin algebras are of finite representation type.",
          "authors": [
            "Daniel Perniok"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18923",
          "title": "Magnetic Ordering in Moiré Graphene Multilayers from a Continuum Hartree+U Approach",
          "abstract": "Recently, symmetry-broken ground states, such as correlated insulating states, magnetic order and superconductivity, have been discovered in twisted bilayer graphene (tBLG) and twisted trilayer graphene (tTLG) near the so-called magic-angle. Understanding the magnetic order in these systems is challenging, however, as atomistic methods become extremely expensive near the magic angle and continuum approaches fail to capture important atomistic details. In this work, we develop an approach to incorporate short-ranged Hubbard interactions self-consistently in a continuum model. In addition, we include long-ranged Coulomb interactions, which are known to be important when doping the flat bands of tBLG and tTLG. Therefore, for the first time, magnetic order in moiré graphene multilayers is self-consistently explored in a continuum model with atomistic detail. With this approach, we perform a systematic analysis of the magnetic phase diagram of tBLG as a function of doping level and twist angle, near the magic angle. Our results are consistent with previous perturbative atomistic Hartree+U calculations. Furthermore, we investigated magnetic order of tTLG, which were found to be similar to those in tBLG. In the future, the developed continuum model can be utilized to investigate magnetic ordering tendencies from short-range exchange interactions in other moiré graphene multilayers as a function of doping, twist angle, screening environment, among other variables.",
          "authors": [
            "Christopher T. S. Cheung",
            "Valerio Vitale",
            "Lennart Klebl",
            "Ammon Fischer",
            "Dante M. Kennes",
            "Arash A. Mostofi",
            "Johannes Lischner",
            "Zachary A. H. Goodwin"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.21516",
          "title": "Semi-Random Graphs, Robust Asymmetry, and Reconstruction",
          "abstract": "The Graph Reconstruction Conjecture famously posits that any undirected graph on at least three vertices is determined up to isomorphism by its family of (unlabeled) induced subgraphs. At present, the conjecture admits partial resolutions of two types: 1) casework-based demonstrations of reconstructibility for families of graphs satisfying certain structural properties, and 2) probabilistic arguments establishing reconstructibility of random graphs by leveraging average-case phenomena. While results in the first category capture the worst-case nature of the conjecture, they play a limited role in understanding the general case. Results in the second category address much larger graph families, but it remains unclear how heavily the necessary arguments rely on optimistic distributional properties. Drawing on the perspectives of smoothed and semi-random analysis, we study the robustness of what are arguably the two most fundamental properties in this latter line of work: asymmetry and uniqueness of subgraphs. Notably, we find that various semi-random graph distributions exhibit these properties asymptotically, much like their Erdős-Rényi counterparts. In particular, Bollobás (1990) demonstrated that almost all Erdős-Rényi random graphs $G = (V, E) \\sim \\mathscr{G}(n, p)$ enjoy the property that their induced subgraphs on $n - \\Theta(1)$ vertices are asymmetric and mutually non-isomorphic, for $1 - p, p = \\Omega(\\log(n) / n)$. We show that this property is robust against perturbation -- even when an adversary is permitted to add/remove each vertex pair in $V^{(2)}$ with (independent) arbitrarily large constant probability. Exploiting this result, we derive asymptotic characterizations of asymmetry in random graphs with planted structure and bounded adversarial corruptions, along with improved bounds on the probability mass of nonreconstructible graphs in $\\mathscr{G}(n, p)$.",
          "authors": [
            "Julian Asilis",
            "Xi Chen",
            "Dutch Hansen",
            "Shang-Hua Teng"
          ],
          "primary_category": "cs.DM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.21516",
          "title": "Semi-Random Graphs, Robust Asymmetry, and Reconstruction",
          "abstract": "The Graph Reconstruction Conjecture famously posits that any undirected graph on at least three vertices is determined up to isomorphism by its family of (unlabeled) induced subgraphs. At present, the conjecture admits partial resolutions of two types: 1) casework-based demonstrations of reconstructibility for families of graphs satisfying certain structural properties, and 2) probabilistic arguments establishing reconstructibility of random graphs by leveraging average-case phenomena. While results in the first category capture the worst-case nature of the conjecture, they play a limited role in understanding the general case. Results in the second category address much larger graph families, but it remains unclear how heavily the necessary arguments rely on optimistic distributional properties. Drawing on the perspectives of smoothed and semi-random analysis, we study the robustness of what are arguably the two most fundamental properties in this latter line of work: asymmetry and uniqueness of subgraphs. Notably, we find that various semi-random graph distributions exhibit these properties asymptotically, much like their Erdős-Rényi counterparts. In particular, Bollobás (1990) demonstrated that almost all Erdős-Rényi random graphs $G = (V, E) \\sim \\mathscr{G}(n, p)$ enjoy the property that their induced subgraphs on $n - \\Theta(1)$ vertices are asymmetric and mutually non-isomorphic, for $1 - p, p = \\Omega(\\log(n) / n)$. We show that this property is robust against perturbation -- even when an adversary is permitted to add/remove each vertex pair in $V^{(2)}$ with (independent) arbitrarily large constant probability. Exploiting this result, we derive asymptotic characterizations of asymmetry in random graphs with planted structure and bounded adversarial corruptions, along with improved bounds on the probability mass of nonreconstructible graphs in $\\mathscr{G}(n, p)$.",
          "authors": [
            "Julian Asilis",
            "Xi Chen",
            "Dutch Hansen",
            "Shang-Hua Teng"
          ],
          "primary_category": "cs.DM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.26437",
          "title": "Evaluation of CZT Detector Performance in Alpha and Gamma Spectrometry",
          "abstract": "Presented is a work on the performance studies of Cadmium Zinc Telluride (CZT) planar detector structures. Current-voltage (IV), capacitance-voltage (CV), and gamma- and alpha-spectroscopy measurements were carried out to provide the essential baseline required for forthcoming defect configuration impact studies on the detector spectroscopy performance. For each tested sensor, spectroscopic responses were recorded with several bias voltages applied. The described suite of measurements provides the parameters needed to evaluate, bulk resistivity, signal efficiency, and energy resolution for characteristic peaks at different energies. Readout configurations and data processing are discussed in related sections.",
          "authors": [
            "N. Kramarenko",
            "M. Väänänen",
            "M. Kalliokoski",
            "M. Bezak",
            "R. Turpeinen",
            "A. Winkler"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.01816",
          "title": "Background Suppression in Quantum Sensing of Dark Matter via $W$ State Projection",
          "abstract": "We show that measuring dark matter signal by projecting quantum sensors in the collective excited state can highly suppress the non-collective noise background, hence improving the sensitivity significantly. We trace the evolution of the sensors' state in the presence of both dark matter effect and sensors' decoherence effects, optimizing the protocol execution time, and show that the suppression of background by a factor equal to the number of sensors is possible. This method does not require the entanglement of sensors during the signal accumulation time, hence circumventing the difficulty of maintaining the lifetime of the entangled state that is present in other enhancement proposals. This protocol is also general regarding the type of qubit sensors.",
          "authors": [
            "Shion Chen",
            "Hajime Fukuda",
            "Yutaro Iiyama",
            "Yuya Mino",
            "Takeo Moroi",
            "Mikio Nakahara",
            "Tatsumi Nitta",
            "Thanaporn Sichanugrist"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.01816",
          "title": "Background Suppression in Quantum Sensing of Dark Matter via $W$ State Projection",
          "abstract": "We show that measuring dark matter signal by projecting quantum sensors in the collective excited state can highly suppress the non-collective noise background, hence improving the sensitivity significantly. We trace the evolution of the sensors' state in the presence of both dark matter effect and sensors' decoherence effects, optimizing the protocol execution time, and show that the suppression of background by a factor equal to the number of sensors is possible. This method does not require the entanglement of sensors during the signal accumulation time, hence circumventing the difficulty of maintaining the lifetime of the entangled state that is present in other enhancement proposals. This protocol is also general regarding the type of qubit sensors.",
          "authors": [
            "Shion Chen",
            "Hajime Fukuda",
            "Yutaro Iiyama",
            "Yuya Mino",
            "Takeo Moroi",
            "Mikio Nakahara",
            "Tatsumi Nitta",
            "Thanaporn Sichanugrist"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.01816",
          "title": "Background Suppression in Quantum Sensing of Dark Matter via $W$ State Projection",
          "abstract": "We show that measuring dark matter signal by projecting quantum sensors in the collective excited state can highly suppress the non-collective noise background, hence improving the sensitivity significantly. We trace the evolution of the sensors' state in the presence of both dark matter effect and sensors' decoherence effects, optimizing the protocol execution time, and show that the suppression of background by a factor equal to the number of sensors is possible. This method does not require the entanglement of sensors during the signal accumulation time, hence circumventing the difficulty of maintaining the lifetime of the entangled state that is present in other enhancement proposals. This protocol is also general regarding the type of qubit sensors.",
          "authors": [
            "Shion Chen",
            "Hajime Fukuda",
            "Yutaro Iiyama",
            "Yuya Mino",
            "Takeo Moroi",
            "Mikio Nakahara",
            "Tatsumi Nitta",
            "Thanaporn Sichanugrist"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.02877",
          "title": "Testing Quantum Mechanics with Quantum Computers: Qubit Information Capacity",
          "abstract": "Motivated in part by John Wheeler's assertion that the continuum nature of Hilbert Space conceals the information-theoretic character of the quantum wavefunction, a specific discretisation of complex Hilbert Space is proposed. Although the Schrödinger equation is not modified, the bases in which the quantum state is mathematically defined must satisfy certain `rationality conditions'. This leads to the notion of Qubit Information Capacity $N_{\\mathrm{max}}$. For any $N > N_{\\mathrm{max}}$ - qubit state, there is insufficient information in the $N$ qubits (linearly growing in $N$) to allocate even one bit to each of the $2^{N+1}-2$ degrees of freedom demanded by complex Hilbert Space (exponentially growing in $N$) and hence unitary quantum mechanics (QM, where $N_{\\mathrm{max}}=\\infty$). Here, state reduction to the classical limit corresponds to a steady coarsening of the discretisation with time. Using the Diósi-Penrose model for gravitised state reduction, it is estimated that $N_{\\mathrm{max}}$ lies between about 200 and 400 for current qubit technologies, and will never exceed 1,000. It is therefore predicted that the exponential advantage of Shor's algorithm over classical algorithms, will have saturated at 1,000 qubits. Hence, insofar as a classical computer will never factor a 2048-bit RSA integer, neither will a quantum computer. This predicted breakdown of QM is potentially testable in a few years. Importantly, the proposed QIC is not itself due to gravitational or other types of state collapse.",
          "authors": [
            "Tim Palmer"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.06305",
          "title": "Interpretation of measured 3x3 partial depolarizing Mueller matrices",
          "abstract": "Mueller polarimetry is a powerful technique with broad applications in astronomy, remote sensing, advanced material analysis, and biomedical imaging. However, instrumental constraints frequently restrict the measurement to an incomplete Mueller matrix limited to its upper-left 3x3 submatrix. Simply padding the missing entries with zeros to form a 4x4 matrix can produce physically inconsistent results, even for nondepolarizing systems. To address this issue, we present a systematic procedure to complete 3x3 measured Mueller matrices into physically consistent 4x4 matrices. The method relies on the covariance matrix formalism and selects, among the infinitely many admissible completions, the one with maximal polarimetric purity. This criterion ensures that the synthesized matrix corresponds to the least random (most deterministic) model compatible with the measurement. The procedure is fully general and can be applied to any 3x3 partial Mueller polarimetric data, providing a reliable and physically grounded reconstruction tool for polarimetric imaging and materials characterization.",
          "authors": [
            "Jose J. Gil",
            "Ignacio San Jose",
            "Monica Canabal-Carbia",
            "Juan Campos",
            "Angel Lizana",
            "Irene Estevez"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.07771",
          "title": "Dimension- and Facet-Dependent Altermagnetic Biferroics and Ferromagnetic Biferroics and Triferroics in CrSb",
          "abstract": "Altermagnets have recently garnered significant interest due to their vanishing net magnetic moment and non-relativistic momentum-dependent spin splitting. However, altermagnetic (AM) multiferroics especially triferroics remain scarce. We investigate the experimentally synthesized non-van der Waals CrSb as a model system to explore the effects of dimensionality and facet orientation on its ferroic properties. NiAs, MnP, wurtzite (WZ), zincblende (ZB), and rocksalt (RS) phases are considered. Using first-principles calculations, we predict the altermagnetism of CrSb in MnP phase which has comparable stability with experimental NiAs phase. Both NiAs- and MnP-phase (110) facets exhibit AM-ferroelastic (FC) biferroics, while the WZ-phase bulk and (001) facets host ferromagnetic (FM) or AM-ferroelectric (FE) biferroics. Notably, the WZ-phase (110) facets are identified as FM/AM-FE-FC triferroics, with moderate energy barriers of 0.129 and 0.363 eV atom-1 for FE and FC switching, respectively. Both FE and FC switching can reverse the AM spin splitting in antiferromagnetic (AFM) configurations while preserving the high spin polarization in FM states. The magnetic anisotropy is highly tunable, exhibiting either uniaxial or in-plane behavior depending on the phase, dimension, and facet. This work establishes a framework for designing AM multiferroics through polymorphic, dimensional, and facet engineering, offering promising avenues for multifunctional spintronic applications.",
          "authors": [
            "Long Zhang",
            "Guoying Gao"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.07771",
          "title": "Dimension- and Facet-Dependent Altermagnetic Biferroics and Ferromagnetic Biferroics and Triferroics in CrSb",
          "abstract": "Altermagnets have recently garnered significant interest due to their vanishing net magnetic moment and non-relativistic momentum-dependent spin splitting. However, altermagnetic (AM) multiferroics especially triferroics remain scarce. We investigate the experimentally synthesized non-van der Waals CrSb as a model system to explore the effects of dimensionality and facet orientation on its ferroic properties. NiAs, MnP, wurtzite (WZ), zincblende (ZB), and rocksalt (RS) phases are considered. Using first-principles calculations, we predict the altermagnetism of CrSb in MnP phase which has comparable stability with experimental NiAs phase. Both NiAs- and MnP-phase (110) facets exhibit AM-ferroelastic (FC) biferroics, while the WZ-phase bulk and (001) facets host ferromagnetic (FM) or AM-ferroelectric (FE) biferroics. Notably, the WZ-phase (110) facets are identified as FM/AM-FE-FC triferroics, with moderate energy barriers of 0.129 and 0.363 eV atom-1 for FE and FC switching, respectively. Both FE and FC switching can reverse the AM spin splitting in antiferromagnetic (AFM) configurations while preserving the high spin polarization in FM states. The magnetic anisotropy is highly tunable, exhibiting either uniaxial or in-plane behavior depending on the phase, dimension, and facet. This work establishes a framework for designing AM multiferroics through polymorphic, dimensional, and facet engineering, offering promising avenues for multifunctional spintronic applications.",
          "authors": [
            "Long Zhang",
            "Guoying Gao"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.08168",
          "title": "Asymptotic behaviour of the weak inverse anisotropic mean curvature flow",
          "abstract": "We first establish a local gradient estimate for anisotropic $p$-harmonic functions. A key feature of our estimate is that the constant remains bounded as $p\\to 1$; consequently, in the limit $p\\to 1$, this estimate yields the local gradient estimate for weak solutions of the inverse anisotropic mean curvature flow (IAMCF). As an application, we show that the weak IAMCF is asymptotic to the expanding Wulff shape solution at the infinity, thereby extending the result of Huisken and Ilmanen in [8] to the anisotropic case.",
          "authors": [
            "Chaoqun Gao",
            "Yong Wei",
            "Rong Zhou"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.08473",
          "title": "An Improved Quantum Algorithm for 3-Tuple Lattice Sieving",
          "abstract": "The assumed hardness of the Shortest Vector Problem in high-dimensional lattices is one of the cornerstones of post-quantum cryptography. The fastest known heuristic attacks on SVP are via so-called sieving methods. While these still take exponential time in the dimension $d$, they are significantly faster than non-heuristic approaches and their heuristic assumptions are verified by extensive experiments. $k$-Tuple sieving is an iterative method where each iteration takes as input a large number of lattice vectors of a certain norm, and produces an equal number of lattice vectors of slightly smaller norm, by taking sums and differences of $k$ of the input vectors. Iterating these ''sieving steps'' sufficiently many times produces a short lattice vector. The fastest attacks (both classical and quantum) are for $k=2$, but taking larger $k$ reduces the amount of memory required for the attack. In this paper we improve the quantum time complexity of 3-tuple sieving from $2^{0.3098 d}$ to $2^{0.2846 d}$, using a two-level amplitude amplification aided by a preprocessing step that associates the given lattice vectors with nearby ''center points'' to focus the search on the neighborhoods of these center points. Our algorithm uses $2^{0.1887d}$ classical bits and QCRAM bits, and $2^{o(d)}$ qubits. This is the fastest known quantum algorithm for SVP when total memory is limited to $2^{0.1887d}$.",
          "authors": [
            "Lynn Engelberts",
            "Yanlin Chen",
            "Amin Shiraz Gilani",
            "Maya-Iggy van Hoof",
            "Stacey Jeffery",
            "Ronald de Wolf"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.08473",
          "title": "An Improved Quantum Algorithm for 3-Tuple Lattice Sieving",
          "abstract": "The assumed hardness of the Shortest Vector Problem in high-dimensional lattices is one of the cornerstones of post-quantum cryptography. The fastest known heuristic attacks on SVP are via so-called sieving methods. While these still take exponential time in the dimension $d$, they are significantly faster than non-heuristic approaches and their heuristic assumptions are verified by extensive experiments. $k$-Tuple sieving is an iterative method where each iteration takes as input a large number of lattice vectors of a certain norm, and produces an equal number of lattice vectors of slightly smaller norm, by taking sums and differences of $k$ of the input vectors. Iterating these ''sieving steps'' sufficiently many times produces a short lattice vector. The fastest attacks (both classical and quantum) are for $k=2$, but taking larger $k$ reduces the amount of memory required for the attack. In this paper we improve the quantum time complexity of 3-tuple sieving from $2^{0.3098 d}$ to $2^{0.2846 d}$, using a two-level amplitude amplification aided by a preprocessing step that associates the given lattice vectors with nearby ''center points'' to focus the search on the neighborhoods of these center points. Our algorithm uses $2^{0.1887d}$ classical bits and QCRAM bits, and $2^{o(d)}$ qubits. This is the fastest known quantum algorithm for SVP when total memory is limited to $2^{0.1887d}$.",
          "authors": [
            "Lynn Engelberts",
            "Yanlin Chen",
            "Amin Shiraz Gilani",
            "Maya-Iggy van Hoof",
            "Stacey Jeffery",
            "Ronald de Wolf"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.09111",
          "title": "Universality of critical behaviors in the three-dimensional (3D) Ising magnets",
          "abstract": "This article gives a brief overview on recent advances in experiments of critical exponents in three groups of magnetic materials. Revisiting experimental data verifies that a universality class with the critical exponents beta = 3/8, gamma = 5/4 and delta = 13/3 occurs in the three-dimensional (3D) Ising magnets, such as transition-metal intermetallics, rare-earth transition-metal compounds and manganites. Furthermore, the topological contributions to critical behaviors in the 3D Ising model are estimated by the difference between the exact solutions and the approximation values.",
          "authors": [
            "Zhidong Zhang"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12557",
          "title": "Transport properties of stochastic fluids",
          "abstract": "We study heat conduction and momentum transport in the context of stochastic fluid dynamics. We consider a fluid described by model H in the classification of Hohenberg and Halperin. We study both non-critical and critical fluids, and we investigate transport properties in two as well as three dimensions. Our results are based on numerical simulations of model H using a Metropolis algorithm, and we employ Kubo relations to extract transport coefficients. We observe the expected logarithmic divergence of the shear viscosity in a two-dimensional non-critical fluid. At a critical point, we find that the transport coefficients exhibit power-law scaling with the system size $L$. The strongest divergence is seen for the thermal conductivity $\\kappa$ in two dimensions. We find $\\kappa\\sim L^{x_\\kappa}$ with $x_\\kappa=1.6\\pm 0.1$. The divergence is weaker in three dimensions, $x_\\kappa=1.25 \\pm 0.3$, and the scaling exponent for the shear viscosity, $x_\\eta$, is significantly smaller than $x_\\kappa$ in both two and three dimensions.",
          "authors": [
            "Chandrodoy Chattopadhyay",
            "Josh Ott",
            "Thomas Schaefer",
            "Vladimir V. Skokov"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12557",
          "title": "Transport properties of stochastic fluids",
          "abstract": "We study heat conduction and momentum transport in the context of stochastic fluid dynamics. We consider a fluid described by model H in the classification of Hohenberg and Halperin. We study both non-critical and critical fluids, and we investigate transport properties in two as well as three dimensions. Our results are based on numerical simulations of model H using a Metropolis algorithm, and we employ Kubo relations to extract transport coefficients. We observe the expected logarithmic divergence of the shear viscosity in a two-dimensional non-critical fluid. At a critical point, we find that the transport coefficients exhibit power-law scaling with the system size $L$. The strongest divergence is seen for the thermal conductivity $\\kappa$ in two dimensions. We find $\\kappa\\sim L^{x_\\kappa}$ with $x_\\kappa=1.6\\pm 0.1$. The divergence is weaker in three dimensions, $x_\\kappa=1.25 \\pm 0.3$, and the scaling exponent for the shear viscosity, $x_\\eta$, is significantly smaller than $x_\\kappa$ in both two and three dimensions.",
          "authors": [
            "Chandrodoy Chattopadhyay",
            "Josh Ott",
            "Thomas Schaefer",
            "Vladimir V. Skokov"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12557",
          "title": "Transport properties of stochastic fluids",
          "abstract": "We study heat conduction and momentum transport in the context of stochastic fluid dynamics. We consider a fluid described by model H in the classification of Hohenberg and Halperin. We study both non-critical and critical fluids, and we investigate transport properties in two as well as three dimensions. Our results are based on numerical simulations of model H using a Metropolis algorithm, and we employ Kubo relations to extract transport coefficients. We observe the expected logarithmic divergence of the shear viscosity in a two-dimensional non-critical fluid. At a critical point, we find that the transport coefficients exhibit power-law scaling with the system size $L$. The strongest divergence is seen for the thermal conductivity $\\kappa$ in two dimensions. We find $\\kappa\\sim L^{x_\\kappa}$ with $x_\\kappa=1.6\\pm 0.1$. The divergence is weaker in three dimensions, $x_\\kappa=1.25 \\pm 0.3$, and the scaling exponent for the shear viscosity, $x_\\eta$, is significantly smaller than $x_\\kappa$ in both two and three dimensions.",
          "authors": [
            "Chandrodoy Chattopadhyay",
            "Josh Ott",
            "Thomas Schaefer",
            "Vladimir V. Skokov"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.16895",
          "title": "Phase assumption-free multiparty quantum clock synchronization",
          "abstract": "We investigate methods to broadcast timing information from a central clock to all other clocks by the use of multipartite entanglement. This task is a necessary step in establishing a coordinated universal time, currently performed using classical synchronization methods. Using an entanglement-based method has the advantage that the timing results are independent of the intervening medium. We generalize existing bipartite quantum clock synchronization methods and take special care to address issues of different phase conventions being adopted at each node (the ``Preskill phase problem''). Using supersinglet purification, we show that this allows for a scalable method with a time signal that is a constant with respect to the number of nodes.",
          "authors": [
            "Hatim A. Oujaa",
            "Qiao Liu",
            "Ebubechukwu O. Ilo-Okeke",
            "Valentin Ivannikov",
            "Jonathan P. Dowling",
            "Tim Byrnes"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.17630",
          "title": "Borel completeness of Tits buildings with no rank 3 residues of spherical type",
          "abstract": "We prove that, for every Coxeter diagram $D$ with no rank $3$ residues of spherical type and such that $D$ has not only edges labelled by $2$, the space of countable (Tits) buildings of type $D$ is Borel complete, that is, classifying countable buildings of type $D$ up to isomorphism is as hard as classifying countable graphs up to isomorphism. In particular, for every $n\\geq 3$, the space of countable generalised $n$-gons is Borel complete.",
          "authors": [
            "Gianluca Paolini",
            "Davide Emilio Quadrellaro"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.18686",
          "title": "Some classical formulæ for curves and surfaces",
          "abstract": "The goal of this text is to present the computation by Salmon, in the second half of the XIXth century, of various numbers enumerating planes with a prescribed tangency pattern with a sufficiently general surface $S$ in $\\mathbf{P}^3$ (or, equivalently, of hyperplane sections of $S$ with prescribed singularities). Emblematic among these are the number of tritangent planes, and the number of planes cutting out a curve with a tacnode.",
          "authors": [
            "Thomas Dedieu"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.18693",
          "title": "Chiral anomalies and Wilson fermions",
          "abstract": "The Wilson formulation of fermions in lattice gauge theory provides a unified description of the chiral anomalies in the standard model. The discrete Dirac operator diagonalizes into a series of two by two blocks. In each block the possible eigenvalues either form a complex pair or separate into two real eigenvalues that have specific chirality. The collision of these pairs of eigenvalues occurs outside the perturbative region and provides a path between topological sectors.",
          "authors": [
            "Michael Creutz"
          ],
          "primary_category": "hep-lat",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.19037",
          "title": "Sunflower Bound with a Sub-Logarithmic Base",
          "abstract": "We show that a family $\\mathcal{F}$ of sets each of cardinality $m \\in \\mathbb{Z}_{>2}$ includes a $k$-sunflower if $ |\\mathcal{F}| \\ge \\left( \\frac{c k^2 \\ln m}{\\ln \\ln m} \\right)^m$ for some constant $c>0$, where $k$-sunflower means a family of $k$ different sets with a common pairwise intersection. The base of the exponential lower bound is sub-logarithmic for each $k$ updating the current best-known result.",
          "authors": [
            "Junichiro Fukuyama"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.19718",
          "title": "Improving $R(3,k)$ in just two bites",
          "abstract": "We present a random construction proving that the extreme off-diagonal Ramsey numbers satisfy $R(3,k)\\ge \\left(\\frac12+o(1)\\right)\\frac{k^2}{\\log{k}}$. This bound has been conjectured to be asymptotically tight, and improves the previously best bound $R(3,k)\\ge \\left(\\frac13+o(1)\\right)\\frac{k^2}{\\log{k}}$. In contrast to all previous constructions achieving the correct order of magnitude, we do not use a nibble argument.",
          "authors": [
            "Zion Hefty",
            "Paul Horn",
            "Dylan King",
            "Florian Pfender"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.20355",
          "title": "Winding and focussing for geodesics passing a thin cuspidal neck",
          "abstract": "We study geodesics on a family $(M_\\varepsilon)$ of manifolds that have a thin neck, which degenerate to a space with an incomplete cuspidal singularity as $\\varepsilon\\to0$. There are essentially two classes of geodesics passing the waist, i.e. the cross section where the neck is thinnest: 1. Those hitting the waist almost vertically. We find that these exhibit a surprising focussing phenomenon as $\\varepsilon\\to0$: certain exit directions will be preferred, for a generic limiting singularity. 2. Those hitting the waist obliquely at a uniformly non-vertical angle. They wind around the neck more and more as $\\varepsilon\\to0$. We give a precise quantitative description of this winding. We illustrate both phenomena by numerical solutions. Our results rest on a detailed analysis at the two relevant scales: the points whose distance to the waist is of order $\\varepsilon$, and those much farther away. This multiscale analysis is efficiently expressed in terms of blow-up.",
          "authors": [
            "Daniel Grieser",
            "Jørgen Olsen Lye"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.21290",
          "title": "A Variational Framework for the Algorithmic Complexity of PDE Solutions",
          "abstract": "Partial Differential Equations (PDEs) are fundamental tools for modeling physical phenomena, yet most PDEs of practical interest cannot be solved analytically and require numerical approximations. The feasibility of such numerical methods, however, is ultimately constrained by the limitations of existing computation models. Since digital computers constitute the primary physical realizations of numerical computation, and Turing machines define their theoretical limits, the question of Turing computability of PDE solutions arises as a problem of fundamental theoretical significance. The Turing computability of PDE solutions provides a rigorous framework to distinguish equations that are, in principle, algorithmically solvable from those that inherently encode undecidable or non-computable behavior. Once computability is established, complexity theory extends the analysis by quantifying the computational resources required to approximate the corresponding PDE solutions. In this work, we present a novel framework based on least-squares variational formulations and their associated gradient flows to study the computability and complexity of PDE solutions from an optimization perspective. Our approach enables the approximation of PDE solution operators via discrete gradient flows, linking structural properties of the PDE, such as coercivity, ellipticity, and convexity, to the inherent complexity of their solutions. This framework characterizes both regimes where PDEs admit effective numerical solvers in polynomial-time and those exhibiting complexity blowup, where the input data possess polynomial-time complexity, yet the solution itself scales super-polynomially.",
          "authors": [
            "Juan Esteban Suarez Cardona",
            "Holger Boche",
            "Gitta Kutyniok"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.21290",
          "title": "A Variational Framework for the Algorithmic Complexity of PDE Solutions",
          "abstract": "Partial Differential Equations (PDEs) are fundamental tools for modeling physical phenomena, yet most PDEs of practical interest cannot be solved analytically and require numerical approximations. The feasibility of such numerical methods, however, is ultimately constrained by the limitations of existing computation models. Since digital computers constitute the primary physical realizations of numerical computation, and Turing machines define their theoretical limits, the question of Turing computability of PDE solutions arises as a problem of fundamental theoretical significance. The Turing computability of PDE solutions provides a rigorous framework to distinguish equations that are, in principle, algorithmically solvable from those that inherently encode undecidable or non-computable behavior. Once computability is established, complexity theory extends the analysis by quantifying the computational resources required to approximate the corresponding PDE solutions. In this work, we present a novel framework based on least-squares variational formulations and their associated gradient flows to study the computability and complexity of PDE solutions from an optimization perspective. Our approach enables the approximation of PDE solution operators via discrete gradient flows, linking structural properties of the PDE, such as coercivity, ellipticity, and convexity, to the inherent complexity of their solutions. This framework characterizes both regimes where PDEs admit effective numerical solvers in polynomial-time and those exhibiting complexity blowup, where the input data possess polynomial-time complexity, yet the solution itself scales super-polynomially.",
          "authors": [
            "Juan Esteban Suarez Cardona",
            "Holger Boche",
            "Gitta Kutyniok"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.21428",
          "title": "Exciton and biexciton preparation via coherent swing-up excitation in a GaAs quantum dot embedded in micropillar cavity",
          "abstract": "Coherent control of quantum emitters is essential for scalable quantum photonic technologies. The recently proposed swing-up of quantum emitter (SUPER) scheme allows efficient and coherent preparation of single photons via off-resonant, red-detuned laser pulses, simplifying laser suppression and enhancing photon collection. We present a systematic study of SUPER excitation applied to a single GaAs quantum dot in a low-Q micropillar cavity. We perform a comparison of the key figures of merit against the well-established two-photon excitation (TPE). Despite requiring higher excitation powers, SUPER achieves near-unity population inversion of the exciton state ($\\sim$95%) and high single-photon purity ($g^{(2)}=0.03$) comparable to that under TPE, while also exhibiting a shortened decay time ($\\sim$200 ps) reducing the time jitter in the exciton population. A polarization-resolved analysis reveals that when both excitation and collection are aligned with one of the exciton dipoles, SUPER results in polarized single-photon emission, exceeding the resonant TPE saturation by a factor of 1.45. Under optimized excitation conditions, we also observe biexciton preparation via a distinct SUPER resonance, confirmed by the appearance of the biexciton emission line, constituting the first experimental demonstration of biexciton preparation using SUPER. These findings are in good agreement with a proposed four-level theoretical model that incorporates the biexciton state. We also report that a slight misalignment of laser polarization induces an additional SUPER resonance that selectively populates the orthogonal exciton dipole, without altering the nominal excitation polarization. This unexpected behavior reveals a new degree of freedom for coherent state preparation. Our findings establish the SUPER scheme as a versatile tool for state-selective exciton and biexciton control.",
          "authors": [
            "Claudia Piccinini",
            "Aleksander Rodek",
            "Abdulmalik A. Madigawa",
            "Ailton Garcia Jr.",
            "Saimon F. Covre da Silva",
            "Martin A. Jacobsen",
            "Luca Vannucci",
            "Gregor Weihs",
            "Armando Rastelli",
            "Vikas Remesh",
            "Niels Gregersen",
            "Battulga Munkhbat"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.21428",
          "title": "Exciton and biexciton preparation via coherent swing-up excitation in a GaAs quantum dot embedded in micropillar cavity",
          "abstract": "Coherent control of quantum emitters is essential for scalable quantum photonic technologies. The recently proposed swing-up of quantum emitter (SUPER) scheme allows efficient and coherent preparation of single photons via off-resonant, red-detuned laser pulses, simplifying laser suppression and enhancing photon collection. We present a systematic study of SUPER excitation applied to a single GaAs quantum dot in a low-Q micropillar cavity. We perform a comparison of the key figures of merit against the well-established two-photon excitation (TPE). Despite requiring higher excitation powers, SUPER achieves near-unity population inversion of the exciton state ($\\sim$95%) and high single-photon purity ($g^{(2)}=0.03$) comparable to that under TPE, while also exhibiting a shortened decay time ($\\sim$200 ps) reducing the time jitter in the exciton population. A polarization-resolved analysis reveals that when both excitation and collection are aligned with one of the exciton dipoles, SUPER results in polarized single-photon emission, exceeding the resonant TPE saturation by a factor of 1.45. Under optimized excitation conditions, we also observe biexciton preparation via a distinct SUPER resonance, confirmed by the appearance of the biexciton emission line, constituting the first experimental demonstration of biexciton preparation using SUPER. These findings are in good agreement with a proposed four-level theoretical model that incorporates the biexciton state. We also report that a slight misalignment of laser polarization induces an additional SUPER resonance that selectively populates the orthogonal exciton dipole, without altering the nominal excitation polarization. This unexpected behavior reveals a new degree of freedom for coherent state preparation. Our findings establish the SUPER scheme as a versatile tool for state-selective exciton and biexciton control.",
          "authors": [
            "Claudia Piccinini",
            "Aleksander Rodek",
            "Abdulmalik A. Madigawa",
            "Ailton Garcia Jr.",
            "Saimon F. Covre da Silva",
            "Martin A. Jacobsen",
            "Luca Vannucci",
            "Gregor Weihs",
            "Armando Rastelli",
            "Vikas Remesh",
            "Niels Gregersen",
            "Battulga Munkhbat"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.21428",
          "title": "Exciton and biexciton preparation via coherent swing-up excitation in a GaAs quantum dot embedded in micropillar cavity",
          "abstract": "Coherent control of quantum emitters is essential for scalable quantum photonic technologies. The recently proposed swing-up of quantum emitter (SUPER) scheme allows efficient and coherent preparation of single photons via off-resonant, red-detuned laser pulses, simplifying laser suppression and enhancing photon collection. We present a systematic study of SUPER excitation applied to a single GaAs quantum dot in a low-Q micropillar cavity. We perform a comparison of the key figures of merit against the well-established two-photon excitation (TPE). Despite requiring higher excitation powers, SUPER achieves near-unity population inversion of the exciton state ($\\sim$95%) and high single-photon purity ($g^{(2)}=0.03$) comparable to that under TPE, while also exhibiting a shortened decay time ($\\sim$200 ps) reducing the time jitter in the exciton population. A polarization-resolved analysis reveals that when both excitation and collection are aligned with one of the exciton dipoles, SUPER results in polarized single-photon emission, exceeding the resonant TPE saturation by a factor of 1.45. Under optimized excitation conditions, we also observe biexciton preparation via a distinct SUPER resonance, confirmed by the appearance of the biexciton emission line, constituting the first experimental demonstration of biexciton preparation using SUPER. These findings are in good agreement with a proposed four-level theoretical model that incorporates the biexciton state. We also report that a slight misalignment of laser polarization induces an additional SUPER resonance that selectively populates the orthogonal exciton dipole, without altering the nominal excitation polarization. This unexpected behavior reveals a new degree of freedom for coherent state preparation. Our findings establish the SUPER scheme as a versatile tool for state-selective exciton and biexciton control.",
          "authors": [
            "Claudia Piccinini",
            "Aleksander Rodek",
            "Abdulmalik A. Madigawa",
            "Ailton Garcia Jr.",
            "Saimon F. Covre da Silva",
            "Martin A. Jacobsen",
            "Luca Vannucci",
            "Gregor Weihs",
            "Armando Rastelli",
            "Vikas Remesh",
            "Niels Gregersen",
            "Battulga Munkhbat"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.22386",
          "title": "On the complexity of the free space of a translating box in R^3",
          "abstract": "Consider a convex polyhedral robot $B$ that can translate (without rotating) amidst a finite set of non-moving polyhedral obstacles in $\\mathbb R^3$. The \"free space\" $\\mathcal F$ of $B$ is the set of all positions in which $B$ is disjoint from the interior of every obstacle. Aronov and Sharir (1997) derived an upper bound of $O(n^2\\log n)$ for the combinatorial complexity of $\\mathcal F$, where $n$ is the total number of vertices of the obstacles, and the complexity of $B$ is assumed constant. Halperin and Yap (1993) showed that, if $B$ is either a box or a \"flat\" convex polygon, then a tighter bound of $O(n^2\\alpha(n))$ holds. Here $\\alpha(n)$ is the inverse Ackermann function. In this paper we prove that if $B$ is a box, then the complexity of $\\mathcal F$ is $O(n^2)$. Furthermore, if $B$ is a convex polygon whose edges come in parallel pairs, then the complexity of $\\mathcal F$ is $O(n^2)$ as well. These results settle the question of the asymptotical worst-case complexity of $\\mathcal F$ for a box, as well as for all convex polygons.",
          "authors": [
            "Gabriel Nivasch"
          ],
          "primary_category": "cs.CG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23809",
          "title": "Recurrence Relations and Dispersive Techniques for Precision Multi-Loop Calculations",
          "abstract": "Ab initio predictions of two-loop electroweak contributions to observables are increasingly essential for precision collider experiments, yet their evaluation remains very challenging. We connect recurrence techniques and dispersive method in order to evaluate complex multi-loop Feynman diagrams. By expressing multi-point Passarino-Veltman functions in a two-point basis and using shifted space-time dimensions with recurrence relations, we minimize the number of required dispersive integrals. This approach reduces computation time and enables a precise and efficient analysis of one- and two-loop diagrams.",
          "authors": [
            "A. Aleksejevs",
            "S. Barkanova",
            "A. I. Davydychev"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23809",
          "title": "Recurrence Relations and Dispersive Techniques for Precision Multi-Loop Calculations",
          "abstract": "Ab initio predictions of two-loop electroweak contributions to observables are increasingly essential for precision collider experiments, yet their evaluation remains very challenging. We connect recurrence techniques and dispersive method in order to evaluate complex multi-loop Feynman diagrams. By expressing multi-point Passarino-Veltman functions in a two-point basis and using shifted space-time dimensions with recurrence relations, we minimize the number of required dispersive integrals. This approach reduces computation time and enables a precise and efficient analysis of one- and two-loop diagrams.",
          "authors": [
            "A. Aleksejevs",
            "S. Barkanova",
            "A. I. Davydychev"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.24064",
          "title": "Hausdorff dimension of sets of continued fractions with unbounded partial quotients along subsequence",
          "abstract": "Let $x=[a_1(x),a_2(x),\\ldots]$ be the continued fraction expansion of $x\\in[0,1)$. We prove that the Hausdorff dimension of \\begin{equation*}E_{even}=\\{x\\in[0,1)\\colon a_{2n}(x)\\to\\infty\\ (n\\to\\infty)\\}.\\end{equation*} is 1/2. In general, we study the set of continued fractions with unbounded partial quotients along subsequence \\begin{equation*}E_{\\{k_n\\}}=\\{x\\in[0,1)\\colon a_{k_n}(x)\\to\\infty\\ (n\\to\\infty)\\},\\end{equation*} where $\\{k_n\\}\\subset\\mathbb{N}$ is a subsequence. We show that $E_{\\{k_n\\}}$ has Hausdorff dimension 1/2 or 1 according to whether the set of indices $\\{k_n\\}_{n\\geq 1}$ has positive or zero upper density respectively.",
          "authors": [
            "Yuefeng Tang"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.25843",
          "title": "The Semi-Classical Limit of Quantum Gravity on Corners",
          "abstract": "We study quantum and classical systems defined by the quantum corner symmetry group $QCS = \\widetilde{SL}(2,\\mathbb{R}) \\ltimes H_3$, which arises in the context of quantum gravity. In particular, we relate the quantum observables, defined by representation-theoretic data, to their classical counterparts through generalized Perelomov coherent states and the framework of Berezin quantization. The resulting procedure provides a mathematically well-defined notion of the semi-classical limit of quantum gravity, viewed as the representation theory of the corner symmetry group.",
          "authors": [
            "Ludovic Varrin"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.25843",
          "title": "The Semi-Classical Limit of Quantum Gravity on Corners",
          "abstract": "We study quantum and classical systems defined by the quantum corner symmetry group $QCS = \\widetilde{SL}(2,\\mathbb{R}) \\ltimes H_3$, which arises in the context of quantum gravity. In particular, we relate the quantum observables, defined by representation-theoretic data, to their classical counterparts through generalized Perelomov coherent states and the framework of Berezin quantization. The resulting procedure provides a mathematically well-defined notion of the semi-classical limit of quantum gravity, viewed as the representation theory of the corner symmetry group.",
          "authors": [
            "Ludovic Varrin"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.25843",
          "title": "The Semi-Classical Limit of Quantum Gravity on Corners",
          "abstract": "We study quantum and classical systems defined by the quantum corner symmetry group $QCS = \\widetilde{SL}(2,\\mathbb{R}) \\ltimes H_3$, which arises in the context of quantum gravity. In particular, we relate the quantum observables, defined by representation-theoretic data, to their classical counterparts through generalized Perelomov coherent states and the framework of Berezin quantization. The resulting procedure provides a mathematically well-defined notion of the semi-classical limit of quantum gravity, viewed as the representation theory of the corner symmetry group.",
          "authors": [
            "Ludovic Varrin"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.26073",
          "title": "The Wiegold problem and free products of left-orderable groups",
          "abstract": "A group has normal rank (or weight) greater than one if no single element normally generates the group. The Wiegold problem from 1976 asks about the existence of a finitely generated perfect group of normal rank greater than one. We show that any free product of nontrivial left-orderable groups has normal rank greater than one. This solves the Wiegold problem by taking free products of finitely generated perfect left-orderable groups, a plethora of which are known to exist. We obtain our estimate of normal rank by a topological argument, proving a type of spectral gap property for an unsigned version of stable commutator length. A key ingredient in the proof is an intricate new construction of a family of left-orders on free products of two left-orderable groups.",
          "authors": [
            "Lvzhou Chen",
            "Yash Lodha"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.00495",
          "title": "Existence results for a biofilm free-boundary problem with dominant detachment",
          "abstract": "This work addresses the existence and uniqueness of a Wanner-Gujer free-boundary problem that models biofilms under conditions of prevailing detachment. This result significantly extends previous findings in both tumor growth modeling and the biofilm modeling field. Besides establishing local existence and uniqueness, we also prove the continuous dependence of the solution on initial and boundary data. Furthermore, global existence is deduced using a combination of invariance regions and energy estimates. The proof for local existence is obtained by utilizing fixed point arguments combined with semigroup theory.",
          "authors": [
            "Dieudonné Zirhumananana"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.00824",
          "title": "On almost strong approximation for linear algebraic groups",
          "abstract": "Let $G$ be a connected linear algebraic group over a number field $K$. In this article, we study the almost strong approximation property (ASA) of $G$ raised by Rapinchuk and Tralle. Building on Demarche's results on strong approximation with Brauer-Manin obstruction, we introduce a necessary and sufficient condition for (ASA) to hold in terms of the Brauer group of $G$. Using the criteria, we conclude that (ASA) can be completely controlled by the Dirichlet density of the places and the splitting field of $G$, which generalizes a result of Rapinchuk and Tralle.",
          "authors": [
            "Yang Cao",
            "Yijin Wang"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.01263",
          "title": "Minimal Degrees, Volume Growth, and Curvature Decay on Complete Kähler Manifolds",
          "abstract": "We consider noncompact complete Kähler manifolds with nonnegative bisectional curvature. Our main results are: 1. Precise relations among refined minimal degree of polynomial growth holomorphic functions and holomorphic volume forms, $\\operatorname{AVR}$ (asymptotic volume ratio) and $\\operatorname{ASCD}$ (average of scalar curvature decay) are established. 2. The Lyapunov asymptotic behavior of the Kähler-Ricci flow can be described in terms of polynomial growth holomorphic functions. This provides a unifying perspective that bridges the two distinct proofs of Yau's uniformization conjecture by Liu and Chau-Lee-Tam. These resolve two conjectures made by Yang. 3. The link of any tangent cone is homeomorphic to a sphere, providing a Kähler analogue of a result of Kapovitch in the Riemannian case.",
          "authors": [
            "Yuang Shi"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.01551",
          "title": "High-temperature superconducting Majorana fermions platforms in the layered Kitaev Materials: Case study of $Li_2IrO_3$",
          "abstract": "Recent advances in Kitaev materials have highlighted their potential to host Majorana fermions without or high-temperature of superconductivity. In this research, we propose $Li_2IrO_3$ as a promising High-temperature superconducting platform supporting Majorana edge modes due to its strong spin-orbit coupling, honeycomb lattice structure, and proximity to a quantum spin liquid (QSL) phase. A theoretical and numerical framework based on the Kitaev-Heisenberg Hamiltonian is developed to model spin interactions in $Li_2IrO_3$. Here, the existence of topological zero-energy states is demonstrated, and their signatures in the edge-localized spectral weight are identified. A device concept based on this material is also proposed with potential industrial applications in spintronics, magnetic field sensing, and topological quantum memory.",
          "authors": [
            "Elnaz Rostampour",
            "Badie Ghavami"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.01551",
          "title": "High-temperature superconducting Majorana fermions platforms in the layered Kitaev Materials: Case study of $Li_2IrO_3$",
          "abstract": "Recent advances in Kitaev materials have highlighted their potential to host Majorana fermions without or high-temperature of superconductivity. In this research, we propose $Li_2IrO_3$ as a promising High-temperature superconducting platform supporting Majorana edge modes due to its strong spin-orbit coupling, honeycomb lattice structure, and proximity to a quantum spin liquid (QSL) phase. A theoretical and numerical framework based on the Kitaev-Heisenberg Hamiltonian is developed to model spin interactions in $Li_2IrO_3$. Here, the existence of topological zero-energy states is demonstrated, and their signatures in the edge-localized spectral weight are identified. A device concept based on this material is also proposed with potential industrial applications in spintronics, magnetic field sensing, and topological quantum memory.",
          "authors": [
            "Elnaz Rostampour",
            "Badie Ghavami"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.01887",
          "title": "Modeling formation and transport of clusters at high temperature and pressure gradients by implying partial chemical equilibrium",
          "abstract": "A theoretical approach to describing transport of an entire ensemble of clusters with different sizes as a single species in gas has been developed. The major assumption is an existence of local partial chemical equilibrium between the clusters. It is shown that thermal diffusion emerges in the collective description as a significant factor even if it is negligible when transport of the original molecular species is considered. Analytical expressions for the effective diffusion and thermal diffusion coefficients at temperature, pressure, and chemical composition gradients have been derived. The theory has been applied to a technology of H2S conversion in a centrifugal plasma-chemical reactor and has made it possible to account for sulfur clusters in numerical process modeling.",
          "authors": [
            "Eugene V. Stepanov",
            "Alexander F. Gutsol"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.02758",
          "title": "Finite free probability and $S$ transforms of Jacobi processes",
          "abstract": "In this paper, we study the $S$ transforms of Jacobi processes in the frameworks of free and finite free probability theories. We begin by deriving a partial differential equation satisfied by the free $S$ transform of the free Jacobi process, and we provide a detailed analysis of its characteristic curves. We turn next our attention to the averaged characteristic polynomial of the Hermitian Jacobi process and to the dynamic of its roots, referred to as the \\emph{frozen Jacobi process}. In particular, we prove, for a specific set of parameters, that the former aligns up to a Szegö variable transformation with the Hermite unitary polynomial. We also provide an expansion of the averaged characteristic polynomial of the Hermitian process in the basis of Jacobi polynomials. Finally, we establish the convergence of the frozen Jacobi process to the free Jacobi process in high dimensions by using the finite free S transform. In doing so, we prove a general result, interesting in its own, on the convergence of the finite differences of the finite free $S$ transform, which paves the way to obtain asymptotics of differential-difference equations satisfied by time-dependent finite free S-transforms of polynomial sequences with positive roots.",
          "authors": [
            "Nizar Demni",
            "Nicolas Gilliers",
            "Tarek Hamdi"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.03385",
          "title": "Pure minimal injective resolutions and perfect modules for lattices",
          "abstract": "In a recent article, Iyama and Marczinzik showed that a lattice is distributive if and only if the incidence algebra is Auslander regular, giving a new connection between homological algebra and lattice theory. In this article we study when a distributive lattice has a pure minimal injective coresolution, a notion first introduced and studied in a work of Ajitabh, Smith and Zhang. We will see that this problem naturally leads to studying when certain antichain modules are perfect modules. We give a classification of perfect antichain modules under the assumption that their canonical antichain resolution is minimal and use this to give a completion classification in lattice theoretic terms of incidence algebras of distributive lattices with pure minimal injective coresolution. We use our results to answer a question raised by Ajitabh, Smith and Zhang by showing that there exist Auslander-Gorenstein polynomial identity rings without a pure injective coresolution.",
          "authors": [
            "Tal Gottesman",
            "Viktória Klász",
            "Markus Kleinau",
            "Rene Marczinzik"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05458",
          "title": "Trade-off between complexity and energy in quantum phase estimation",
          "abstract": "Driven by the desire to make quantum technologies more sustainable, in this work we introduce a framework for analysing the interplay between complexity and energy cost of quantum procedures. In particular, we study a sequential quantum phase estimation protocol, where a phase of physical significance is encoded in a quantum channel. The channel is applied to a probe state repetitively until the probe is measured and the outcome leads to an estimate on the phase. We establish a trade-off relation between the implementation energy of the channel and the number of times it is applied (complexity), while reaching a desired estimation precision. The principles of our analysis can be adapted to optimise the energy consumption in other quantum protocols and devices.",
          "authors": [
            "Yukuan Tao",
            "Madalin Guta",
            "Gerardo Adesso"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05783",
          "title": "Stability of parabolic equations in non-cylindrical domains",
          "abstract": "This paper addresses the stability of a class of parabolic equations in non-cylindrical domains. We investigate the $L^\\infty$-stability of systems for both nondegenerate and degenerate cases. Unlike in cylindrical domains, solutions to such problems may not exhibit exponential decay. An interesting phenomenon observed is that degeneracy has a positive impact on $L^\\infty$-norm estimates for solutions to the system.",
          "authors": [
            "Lingyang Liu"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06206",
          "title": "Structures of uninorms on bounded lattices via t-conorms, closure operators and t-subnorms",
          "abstract": "In this paper, we provide some structures of uninorms on bounded lattices via t-conorms, closure operators and t-subnorms, subject to certain constraints on the closure operators and t-subnorms. Importantly, these constraints are shown to be both sufficient and necessary. That is, the proposed methods reveal clear relationships between the structure of the resulting uninorms and the properties of the underlying components. Meanwhile, we present the degenerate cases of the aforementioned results, which are constructed using special closure operators and t-subnorms. Some of these cases correspond to well-known results documented in the literature. Moreover, the dual constructions of uninorms on bounded lattices, based on t-norms, interior operators and t-superconorms, are presented simultaneously.",
          "authors": [
            "Zhenyu Xiu",
            "Zhengyuan Si"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.08146",
          "title": "Second-Harmonic Magnetoacoustic Ultrasound from Magnetic Nanoparticles under Radiofrequency Electromagnetic Fields",
          "abstract": "We report experimental evidence of mechanical wave generation by magnetic nanoparticles (MNPs) under radiofrequency electromagnetic fields (EMFs, 65mT, 800 kHz, at 100ms bursts) in the ultrasonic (US) frequency range. We developed an experimental setup to detect the second harmonic (SH) signal under isothermal conditions. This SH-US signal was observed only in samples containing MNPs and consequently originated from the EMF interaction on samples containing MNPs. These findings suggest that US generation due to magneto-acoustic interaction in the MNPs could be responsible for the cell damage induced by EMF in cells containing MNPs without increasing the temperature. Experiments performed on magnetically aligned MNP clusters in gelatin significantly enhance the amplitude of the SH signal compared to non-aligned samples. This phenomenon could pave the way for new theoretical and practical approaches as for 'in vivo' magnetoacoustics theragnostic.",
          "authors": [
            "R. Marqués-Gómez",
            "J. Melchor",
            "A.C. Moreno Maldonado",
            "C. Marquina",
            "G. Goya",
            "M. R. Ibarra",
            "G. Rus"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.08146",
          "title": "Second-Harmonic Magnetoacoustic Ultrasound from Magnetic Nanoparticles under Radiofrequency Electromagnetic Fields",
          "abstract": "We report experimental evidence of mechanical wave generation by magnetic nanoparticles (MNPs) under radiofrequency electromagnetic fields (EMFs, 65mT, 800 kHz, at 100ms bursts) in the ultrasonic (US) frequency range. We developed an experimental setup to detect the second harmonic (SH) signal under isothermal conditions. This SH-US signal was observed only in samples containing MNPs and consequently originated from the EMF interaction on samples containing MNPs. These findings suggest that US generation due to magneto-acoustic interaction in the MNPs could be responsible for the cell damage induced by EMF in cells containing MNPs without increasing the temperature. Experiments performed on magnetically aligned MNP clusters in gelatin significantly enhance the amplitude of the SH signal compared to non-aligned samples. This phenomenon could pave the way for new theoretical and practical approaches as for 'in vivo' magnetoacoustics theragnostic.",
          "authors": [
            "R. Marqués-Gómez",
            "J. Melchor",
            "A.C. Moreno Maldonado",
            "C. Marquina",
            "G. Goya",
            "M. R. Ibarra",
            "G. Rus"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.08696",
          "title": "Full vectorial field sensing using liquid crystal droplet arrays",
          "abstract": "Determining the amplitude, phase, and polarization profile of light is essential for both fundamental scientific discovery and applications spanning optical metrology, microscopy, astronomy, and optical communication/computing technologies. However, most modern measurement approaches are unable to retrieve such parameters readily, often relying on bulky and expensive hardware, or lacking the capability for single-shot sensing. Here, we introduce a low cost, compact, full vectorial field sensor based on an inkjet-printed nematic liquid crystal droplet array that enables simultaneous measurement of these important characteristics of light. Polarization and intensity are measured via division-of-wavefront polarimetry, exploiting the droplets' spatially varying birefringence, while the phase is reconstructed by treating each droplet as a separate microlens in a Shack-Hartmann-like wavefront sensor configuration. To demonstrate the system's performance, we characterize aberrated dual-wavelength beams carrying distinct intensity, phase, and polarization information, confirming accurate retrieval of the optical field profiles for both spectral components.",
          "authors": [
            "Xuke Qiu",
            "Jinge Guo",
            "Jiahe Cui",
            "Runchen Zhang",
            "Zimo Zhao",
            "Yifei Ma",
            "Waqas Kamal",
            "Steve J. Elston",
            "Alfonso A. Castrejón-pita",
            "Stephen M. Morris",
            "Chao He"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.09922",
          "title": "Quantum Phase Gradient Imaging Using a Nonlocal Metasurface System",
          "abstract": "Quantum phase imaging enables the analysis of transparent samples with thickness and refractive index variations in scenarios requiring precise measurements under low-light conditions. Here, we present a compact quantum phase-gradient imaging system integrating a lithium niobate (LiNbO3) metasurface for generating spatially entangled photon pairs and a silicon (Si) metasurface for phase gradient extraction. By leveraging nonlocal resonances, the LiNbO3 metasurface enables efficient spontaneous parametric down-conversion (SPDC) with all-optically angularly tunable emission, while the Si metasurface provides a nearly linear optical transfer function (OTF) that differentiates the photon wavefunction and extracts phase this http URL proof-of-concept results demonstrate the imaging of up to 25~rad/mm phase gradients, achieving 89% similarity with the reference values. The pixel resolution of the system can be potentially enhanced by orders of magnitude by increasing the metasurface dimensions and resonance quality this http URL work showcases the application of metasurfaces in both generating and detecting quantum states and establishes a new paradigm for portable quantum phase-gradient imaging, with potential applications in quantum sensing, microscopy, and LiDAR technology.",
          "authors": [
            "Jinliang Ren",
            "Jinyong Ma",
            "Katsuya Tanaka",
            "Lukas Wesemann",
            "Ann Roberts",
            "Frank Setzpfandt",
            "Andrey A. Sukhorukov"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.09922",
          "title": "Quantum Phase Gradient Imaging Using a Nonlocal Metasurface System",
          "abstract": "Quantum phase imaging enables the analysis of transparent samples with thickness and refractive index variations in scenarios requiring precise measurements under low-light conditions. Here, we present a compact quantum phase-gradient imaging system integrating a lithium niobate (LiNbO3) metasurface for generating spatially entangled photon pairs and a silicon (Si) metasurface for phase gradient extraction. By leveraging nonlocal resonances, the LiNbO3 metasurface enables efficient spontaneous parametric down-conversion (SPDC) with all-optically angularly tunable emission, while the Si metasurface provides a nearly linear optical transfer function (OTF) that differentiates the photon wavefunction and extracts phase this http URL proof-of-concept results demonstrate the imaging of up to 25~rad/mm phase gradients, achieving 89% similarity with the reference values. The pixel resolution of the system can be potentially enhanced by orders of magnitude by increasing the metasurface dimensions and resonance quality this http URL work showcases the application of metasurfaces in both generating and detecting quantum states and establishes a new paradigm for portable quantum phase-gradient imaging, with potential applications in quantum sensing, microscopy, and LiDAR technology.",
          "authors": [
            "Jinliang Ren",
            "Jinyong Ma",
            "Katsuya Tanaka",
            "Lukas Wesemann",
            "Ann Roberts",
            "Frank Setzpfandt",
            "Andrey A. Sukhorukov"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.10096",
          "title": "Tailored Three Dimensional Betatron Dynamics in UltraStable Hybrid Laser Plasma RF Accelerators",
          "abstract": "The detailed theoretical and numerical investigation of hybrid laser plasma RF accelerators, elucidating the mechanisms governing transverse beam dynamics, betatron polarization, and radiation reaction in ultra-relativistic electron bunches is presented. This framework combines analytical models of spatiotemporal plasma wakefield modulation, phase-dependent RF-driven oscillations, and quantum-corrected Landau Lifshitz radiation reaction with fully self-consistent 3D particle in cell simulations using EPOCH. The results demonstrate that RF amplitude, frequency, and phase enable precise control over transverse focusing strengths, betatron oscillation amplitudes, and polarization states. Resonant alignment between RF fields and natural betatron frequencies amplifies transverse excursions while damping parasitic oscillations through enhanced focusing gradients and radiation reaction, yielding reductions in emittance and mitigation of synchrotron-like energy losses. Stability maps and 3D force landscapes reveal strong phase sensitivity, where initial conditions and RF component ratios govern the temporal evolution of betatron amplitudes, and longitudinal field gradients modulate {\\gamma} growth rates. These findings provide a comprehensive picture of nonlinear, resonant, and damping phenomena in hybrid laser plasma RF systems, highlighting the full spectrum of controllable transverse, longitudinal, and polarization dynamics in ultra relativistic electron beams.",
          "authors": [
            "A. A. Molavi Choobini",
            "M. Shahmansouri"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11374",
          "title": "Subradiant Decay in 2D and 3D Atomic Arrays",
          "abstract": "Subradiance is a phenomenon where coupled emitters radiate light at a slower rate than independent ones. While its observation was first reported in disordered cold atom clouds, ordered subwavelength arrays of emitters have emerged as promising platforms to design highly cooperative optical properties based on dipolar interactions. In this work we characterize the eigenmodes of 2D and 3D regular arrays, using a method which can be used for both infinite and very large systems. In particular, we show how finite-size effects impact the lifetimes of these large arrays. Our results may have interesting applications for quantum memories and topological effects in ordered atomic arrays.",
          "authors": [
            "Nicola Piovella",
            "Romain Bachelard"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11441",
          "title": "Multi-wavelength transparent microfluidics for UV-visible spectroscopy and X-ray scattering studies of photoactive systems",
          "abstract": "Microfluidic devices are increasingly used in synchrotron-based experiments to deliver and probe liquid samples, offering advantages such as minimal sample consumption and reduced radiation damage. Despite their growing use, few devices have been specifically designed for monitoring liquids under photoexcitation, a promising approach for fast structural transitions. Here, a microfluidic device that is transparent to X-rays in one direction, and simulaneously transmits UV and visible light in the perpendicular direction is presented. The device is fabricated using lamination and UV lithography on a dry-film resist, eliminating the need for cleanroom facilities and simplifying production. Its multi-wavelength transparency was validated through UV-visible spectroscopy, where photoexcitation at different wavelengths induced reversible trans-to-cis isomerization of azobenzene and fluoro-azobenzene. X-ray transparency was validated through Small Angle X-ray Scattering (SAXS) measurements on hemoglobin and CO-ligated hemoglobin sensitive to quaternary structural changes. These resusts confirm the suitability of the device for resolving protein structures and photoinduced conformational dynamics. The design further supports, as some proof of concept results show, temperature-jump and time resolved pump-probe experiments, providing a versatile platform for studying structural evolution in liquid samples using synchrotron SAXS.",
          "authors": [
            "Benedetta Marmiroli",
            "Sumea Klokic",
            "Barbara Sartori",
            "Marie Reissenbuechel",
            "Alessio Turchet",
            "Heinz Amenitsch"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11441",
          "title": "Multi-wavelength transparent microfluidics for UV-visible spectroscopy and X-ray scattering studies of photoactive systems",
          "abstract": "Microfluidic devices are increasingly used in synchrotron-based experiments to deliver and probe liquid samples, offering advantages such as minimal sample consumption and reduced radiation damage. Despite their growing use, few devices have been specifically designed for monitoring liquids under photoexcitation, a promising approach for fast structural transitions. Here, a microfluidic device that is transparent to X-rays in one direction, and simulaneously transmits UV and visible light in the perpendicular direction is presented. The device is fabricated using lamination and UV lithography on a dry-film resist, eliminating the need for cleanroom facilities and simplifying production. Its multi-wavelength transparency was validated through UV-visible spectroscopy, where photoexcitation at different wavelengths induced reversible trans-to-cis isomerization of azobenzene and fluoro-azobenzene. X-ray transparency was validated through Small Angle X-ray Scattering (SAXS) measurements on hemoglobin and CO-ligated hemoglobin sensitive to quaternary structural changes. These resusts confirm the suitability of the device for resolving protein structures and photoinduced conformational dynamics. The design further supports, as some proof of concept results show, temperature-jump and time resolved pump-probe experiments, providing a versatile platform for studying structural evolution in liquid samples using synchrotron SAXS.",
          "authors": [
            "Benedetta Marmiroli",
            "Sumea Klokic",
            "Barbara Sartori",
            "Marie Reissenbuechel",
            "Alessio Turchet",
            "Heinz Amenitsch"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.12674",
          "title": "Distortion-Driven Carrier Decoupling in Doped LiMgPO4",
          "abstract": "The interplay between lattice distortions and charge carriers governs the properties of many functional oxides. In alkali-doped LiMgPO4, a significant enhancement in dosimetric response is observed, but its microscopic origin is not understood. Using non-adiabatic molecular dynamics, we reveal a fundamental mechanism of carrier decoupling driven by a hierarchy of lattice distortions. We show that electrons localize into stable small polarons on an ultrafast timescale, trapped by the strong local potential induced by the dopant, while holes form more delocalized polarons that migrate efficiently through a lattice smoothed by global strain. The stark contrast between the dynamics of trapped electrons and mobile holes explains the suppressed recombination and enhanced energy storage. These results present a clear physical picture of how multiscale lattice distortions can independently control electron and hole transport, offering new insights into the physics of polarons in complex materials.",
          "authors": [
            "Zhihua Zheng",
            "Xiaolong Yao",
            "Cailian Yu",
            "Menghao Gao",
            "Fangping Ouyang",
            "Shiwu Gao"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.12674",
          "title": "Distortion-Driven Carrier Decoupling in Doped LiMgPO4",
          "abstract": "The interplay between lattice distortions and charge carriers governs the properties of many functional oxides. In alkali-doped LiMgPO4, a significant enhancement in dosimetric response is observed, but its microscopic origin is not understood. Using non-adiabatic molecular dynamics, we reveal a fundamental mechanism of carrier decoupling driven by a hierarchy of lattice distortions. We show that electrons localize into stable small polarons on an ultrafast timescale, trapped by the strong local potential induced by the dopant, while holes form more delocalized polarons that migrate efficiently through a lattice smoothed by global strain. The stark contrast between the dynamics of trapped electrons and mobile holes explains the suppressed recombination and enhanced energy storage. These results present a clear physical picture of how multiscale lattice distortions can independently control electron and hole transport, offering new insights into the physics of polarons in complex materials.",
          "authors": [
            "Zhihua Zheng",
            "Xiaolong Yao",
            "Cailian Yu",
            "Menghao Gao",
            "Fangping Ouyang",
            "Shiwu Gao"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.13066",
          "title": "Arithmetical Complexity and Absoluteness of Rigidity Phenomena for Ulam Sequences",
          "abstract": "We analyse the logical complexity and absoluteness of natural statements about Ulam sequences, with particular emphasis on the rigidity phenomena introduced by Hinman, Kuca, Schlesinger and Sheydvasser for the family $U(1,n)$. For each pair of coprime integers $a<b$ we view the associated Ulam sequence $U(a,b)$ as a recursive subset of $\\mathbb{N}$ and consider expansions of the form $(\\mathbb{N},+,\\mathrm{U}_{a,b})$. Our first main result is a uniform coding of Ulam sequences and of the ``interval with periodic mask'' patterns appearing in rigidity conjectures into first-order arithmetic. Using this, we show that the strong rigidity, regularity (eventual periodicity of gaps), and density statements for $U(a,b)$ are all arithmetical and lie at low levels of the arithmetical hierarchy (e.g.\\ $\\Sigma^0_2$ or $\\Pi^0_3$). As a consequence, these statements are absolute between transitive models of $\\mathrm{ZFC}$ with the same natural numbers: their truth value cannot be changed by forcing, and is independent of the Continuum Hypothesis and large cardinal axioms. We also study the expansions $(\\mathbb{N},+,\\mathrm{U}_{a,b})$ model-theoretically, showing that combinatorial rigidity implies tameness properties (NIP, dp-minimality, non-interpretability of multiplcation).",
          "authors": [
            "Frank Gilson"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.13792",
          "title": "Hyperelastic stability landscape: A check for HILL stability of isotropic, incompressible hyperelasticity depending on material parameters",
          "abstract": "In this paper, we describe a uniform and standardized approach for analytically verifying the stability of isotropic, incompressible hyperelastic material models. Here, we address {\\sl stability} as fulfillment of the {\\sc Hill} condition -- i.e.\\ the positive definiteness of the material modulus in the {\\sc Kirchhoff} stress -- log--strain relation. For incompressible material behavior, all mathematically and mechanically possible deformations lie within a range bounded, on the one hand, by uniaxial states and, on the other hand, by biaxial states; shear {deformation} states lie in between. This becomes particularly clear when the possible states are represented in the invariant plane. This very representation is now also used to visualize the regions of unstable material behavior depending on the selected strain energy function and the respective data set of material parameters. This demonstrates how, for some constellations of energy functions, with appropriate selection or calibration of parameters, stable and unstable regions can be observed. If such cases occur, it is no longer legitimate to use them to initiate, for example, finite element simulations. This is particularly striking when, for example, a fit appears stable in uniaxial tension, but the same parameter set for shear states results in unstable behavior without this being specifically investigated. The presented approach can reveal simple indicators for this.",
          "authors": [
            "Herbert Baaser"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.14678",
          "title": "Giant enhancement of attosecond tunnel ionization competes with disorder-driven decoherence in silicon",
          "abstract": "High-harmonic generation (HHG) is a strong-field phenomenon that is sensitive to the attosecond dynamics of tunnel ionization and coherent transport of electron-hole pairs in solids. While the foundations of solid HHG have been established, a deep understanding into the nature of decoherence on sub-cycle timescales remains elusive. Furthermore, there is a growing need for tools to control ionization at the nanoscale. Here, we study HHG in silicon along a crystalline-to-amorphous (c-Si to a-Si) structural phase transition and observe a dramatic reshaping of the spectrum, with enhanced lower-order harmonic yield accompanied by quenching of the higher-order harmonics. Modelling the real-space quantum dynamics links our observations to a giant enhancement (>250 times) of tunnel ionization yield in the amorphous phase and a disorder-induced decoherence that damps the electron-hole polarization over approximately six lattice sites. HHG spectroscopy also reveals remnant order that was not apparent with conventional probes. Finally, we observe a rapid and targeted non-resonant laser annealing of amorphous silicon islands. Our results offer a unique insight into attosecond decoherence in strong-field phenomena, establish HHG spectroscopy as a probe of structural disorder, and pave the way for new opportunities in lightwave nanoelectronics.",
          "authors": [
            "D. N. Purschke",
            "D. Vick",
            "A. Cárdenas",
            "N. Haram",
            "P. Bastani",
            "S. Gholam-Mirzaei",
            "S. Mokhtari",
            "V. Jelic",
            "J. Chen",
            "J. Canlas",
            "J. Tordiff",
            "Md. W. Rahman",
            "A. Yu. Naumov",
            "D. M. Villeneuve",
            "A. Staudte",
            "M. Salomons",
            "R. E. F. Silva",
            "Á. Jiménez-Galán",
            "G. Vampa"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.14737",
          "title": "Squeezing-Enhanced Photon-Number Measurements for GKP State Generation",
          "abstract": "We present an architecture for the generation of GKP states in which quadrature squeezing operations are used to control the average photon number statistics of probabilistic photon number measurements on Gaussian resource states. Specifically, we present an architecture employing a teleportation-based squeezing protocol and polynomial-gate applications integrated into a time-multiplexed multi-mode cluster state to generate cat states with high amplitudes, which are consequently used to generate GKP states with high quadrature effective squeezing. Compared to our previous work, in addition to using squeezing as a resource, the present architecture reduces damping and noise by minimizing the number of homodyne measurements required in GKP state generation. We demonstrate the effectiveness of these improvements - including dynamic input-state resetting and an improved breeding algorithm - by achieving a fault-tolerance threshold of 11.5 dB cluster squeezing using the RHG surface code for error correction, without requiring active switching or photon-number resource states.",
          "authors": [
            "Paul Renault",
            "Patrick Yard",
            "Raphael Pooser",
            "Hussain Zaidi"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15547",
          "title": "Non-Abelian Zero Modes in Fractional Quantum Hall-Superconductor Heterostructure",
          "abstract": "We discuss the emergence of non-Abelian zero modes from twist defects in Abelian topological phases. We consider a setup built from a fractional quantum Hall (or a fractional Chern insulator)-superconductor heterostructure, which effectively induces a phase transition, leading to a topological phase endowed with new anyonic symmetries, and accordingly supporting distinct types of zero modes at fixed filling. These defects are modeled at the interface between two copies of the same heterostructure arranged side by side, which produces counterpropagating modes that can be gapped by interactions that realize the anyonic symmetries. We characterize the parafermions associated with each anyonic symmetry and discuss how their presence affect the periodicity of Josephson tunneling current.",
          "authors": [
            "Gustavo M. Yoshitome",
            "Pedro R. S. Gomes"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15547",
          "title": "Non-Abelian Zero Modes in Fractional Quantum Hall-Superconductor Heterostructure",
          "abstract": "We discuss the emergence of non-Abelian zero modes from twist defects in Abelian topological phases. We consider a setup built from a fractional quantum Hall (or a fractional Chern insulator)-superconductor heterostructure, which effectively induces a phase transition, leading to a topological phase endowed with new anyonic symmetries, and accordingly supporting distinct types of zero modes at fixed filling. These defects are modeled at the interface between two copies of the same heterostructure arranged side by side, which produces counterpropagating modes that can be gapped by interactions that realize the anyonic symmetries. We characterize the parafermions associated with each anyonic symmetry and discuss how their presence affect the periodicity of Josephson tunneling current.",
          "authors": [
            "Gustavo M. Yoshitome",
            "Pedro R. S. Gomes"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16565",
          "title": "Generalized Three-Family Supersymmetric Pati-Salam Models from Type IIA Intersecting D6-Branes",
          "abstract": "Generalizing three-family chiral fermion conditions to $I_{ac}=-(3+h)$ and $I_{ac'}=h$, with positive integer $h$, we extend the landscape of three-family ${\\cal N}=1$ supersymmetric Pati-Salam models in a broader region. Differing from the former investigation with $I_{ac}=-3$ and $I_{ac'}=0$, we do not restrict that the $a$ stack of D6-branes must be parallel to the orientifold image of the $c$-stack along one of the three two-tori. In this investigation, without the simple parallel construction, we find four new classes of supersymmetric Pati-Salam models that are allowed by the extended three generation condition with $I_{ac}=3, I_{ac'}=-6$ and $I_{ac}=-1, I_{ac'}=-2$ through the intersections of $a$- and $c/c'$-branes. Moreover, with the $SU(2)'_{L}$ gauge coupling realized from $SU(2)_{L_1}\\times SU(2)_{L_2}$ symmetry breaking, the canonical normalization requirement of the gauge kinetic term provides an alternative approach that can be imposed before the renormalization group equation evolution for $SU(2)'_L$ gauge coupling. This turns out to be an effective mechanism to realize the string-scale gauge coupling relation, especially for the new supersymmetric Pati-Salam models with large $g_b/g_a$ ratio. We show that this symmetry-breaking modified renormalization group evolution can highly suppress $g_b/g_a$, and finally realizes string-scale gauge coupling relations for the extended supersymmetric Pati-Salam models as well.",
          "authors": [
            "Tianjun Li",
            "Qi Sun",
            "Rui Sun",
            "Lina Wu"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16565",
          "title": "Generalized Three-Family Supersymmetric Pati-Salam Models from Type IIA Intersecting D6-Branes",
          "abstract": "Generalizing three-family chiral fermion conditions to $I_{ac}=-(3+h)$ and $I_{ac'}=h$, with positive integer $h$, we extend the landscape of three-family ${\\cal N}=1$ supersymmetric Pati-Salam models in a broader region. Differing from the former investigation with $I_{ac}=-3$ and $I_{ac'}=0$, we do not restrict that the $a$ stack of D6-branes must be parallel to the orientifold image of the $c$-stack along one of the three two-tori. In this investigation, without the simple parallel construction, we find four new classes of supersymmetric Pati-Salam models that are allowed by the extended three generation condition with $I_{ac}=3, I_{ac'}=-6$ and $I_{ac}=-1, I_{ac'}=-2$ through the intersections of $a$- and $c/c'$-branes. Moreover, with the $SU(2)'_{L}$ gauge coupling realized from $SU(2)_{L_1}\\times SU(2)_{L_2}$ symmetry breaking, the canonical normalization requirement of the gauge kinetic term provides an alternative approach that can be imposed before the renormalization group equation evolution for $SU(2)'_L$ gauge coupling. This turns out to be an effective mechanism to realize the string-scale gauge coupling relation, especially for the new supersymmetric Pati-Salam models with large $g_b/g_a$ ratio. We show that this symmetry-breaking modified renormalization group evolution can highly suppress $g_b/g_a$, and finally realizes string-scale gauge coupling relations for the extended supersymmetric Pati-Salam models as well.",
          "authors": [
            "Tianjun Li",
            "Qi Sun",
            "Rui Sun",
            "Lina Wu"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17244",
          "title": "Optical Entanglement Facilitated by Opto-Mechanical Cooling",
          "abstract": "Optomechanical generation of entangled optical beams is usually hindered by thermal noise. We present a theoretical study of low frequency entanglement generation between two optical harmonics emitted from a cavity optomechanical system operating in the resolved-sideband regime. The system comprises three nearly equidistant optical modes in a high-finesse cavity, with the central mode coherently driven. This configuration enables radiation-pressure interactions that generate strong quantum correlations between the two sideband modes. Remarkably, these correlations persist even at large numbers of thermal quanta if one properly engineers the optical cooling rate of the mechanical mode. Our findings demonstrate the feasibility of robust entanglement under ambient conditions, opening new avenues for hybrid quantum technologies based on mechanical interfaces and continuous-variable quantum information processing.",
          "authors": [
            "Alexandr V. Karpenko",
            "Andrey B. Matsko",
            "Sergey P. Vyatchanin"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17244",
          "title": "Optical Entanglement Facilitated by Opto-Mechanical Cooling",
          "abstract": "Optomechanical generation of entangled optical beams is usually hindered by thermal noise. We present a theoretical study of low frequency entanglement generation between two optical harmonics emitted from a cavity optomechanical system operating in the resolved-sideband regime. The system comprises three nearly equidistant optical modes in a high-finesse cavity, with the central mode coherently driven. This configuration enables radiation-pressure interactions that generate strong quantum correlations between the two sideband modes. Remarkably, these correlations persist even at large numbers of thermal quanta if one properly engineers the optical cooling rate of the mechanical mode. Our findings demonstrate the feasibility of robust entanglement under ambient conditions, opening new avenues for hybrid quantum technologies based on mechanical interfaces and continuous-variable quantum information processing.",
          "authors": [
            "Alexandr V. Karpenko",
            "Andrey B. Matsko",
            "Sergey P. Vyatchanin"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19352",
          "title": "A construction of surface skein TQFTs and their extension to 4-dimensional 2-handlebodies",
          "abstract": "For a commutative Frobenius algebra $A$, we construct a $(2,3,3+\\varepsilon)$-dimensional TQFT $\\mathsf{AFK}_A$ that assigns to a 3-manifold a skein module of embedded $A$-decorated surfaces. These surface skein modules have been first defined by Asaeda--Frohman and Kaiser using skein relations that generalize the combinatorics of Bar-Natan's dotted cobordisms. For 3-manifolds with boundary, we show that surface skein modules carry an action by a certain surface skein category associated with the boundary, which yields a gluing formalism. Our main result concerns a partial extension of $\\mathsf{AFK}_A$ to dimension 4, which uses an inductive state-sum construction following Walker. As an example, the equivariant version of Lee's deformation of dotted cobordisms yields a TQFT that extends to 4-dimensional 2-handlebodies but not 3-handlebodies. Finally, we characterize the attachment of 4-dimensional 2-handles by means of a certain Kirby color and use it to compute the invariants of 4-dimensional 2-handlebodies in examples.",
          "authors": [
            "Leon J. Goertz"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19897",
          "title": "Parameterized Verification of Quantum Circuits (Technical Report)",
          "abstract": "We present the first fully automatic framework for verifying relational properties of parameterized quantum programs, i.e., a program that, given an input size, generates a corresponding quantum circuit. We focus on verifying input-output correctness as well as equivalence. At the core of our approach is a new automata model, synchronized weighted tree automata (SWTAs), which compactly and precisely captures the infinite families of quantum states produced by parameterized programs. We introduce a class of transducers to model quantum gate semantics and develop composition algorithms for constructing transducers of parameterized circuits. Verification is reduced to functional inclusion or equivalence checking between SWTAs, for which we provide decision procedures. Our implementation demonstrates both the expressiveness and practical efficiency of the framework by verifying a diverse set of representative parameterized quantum programs with verification times ranging from milliseconds to seconds.",
          "authors": [
            "Parosh Aziz Abdulla",
            "Yu-Fang Chen",
            "Michal Hečko",
            "Lukáš Holík",
            "Ondřej Lengál",
            "Jyun-Ao Lin",
            "Ramanathan S. Thinniyam"
          ],
          "primary_category": "cs.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20118",
          "title": "Formalization of Brownian motion in Lean",
          "abstract": "Brownian motion is a building block in modern probability theory. In this paper, we describe a formalization of Brownian motion using the Lean theorem prover. We build on the existing measure-theoretic foundations in Lean's mathematical library, Mathlib, and we develop several key components needed for the construction of Brownian motion, including the Carathéodory and Kolmogorov extension theorems, Gaussian measures in Banach spaces, and the Kolmogorov-Chentsov theorem for path continuity.",
          "authors": [
            "Rémy Degenne",
            "David Ledvinka",
            "Etienne Marion",
            "Peter Pfaffelhuber"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20379",
          "title": "Spin current symmetries generated by GdFeCo ferrimagnet across its magnetisation compensation temperature",
          "abstract": "Ferrimagnets, composed of antiferromagnetically coupled magnetic sublattices whose net magnetisation can be tuned by temperature, offer a unique platform for probing the symmetry of the spin currents they generate and for identifying the sublattice contributions to these currents. Here, we investigate the spin current symmetries produced by GdFeCo ferrimagnet at a fixed concentration and across a broad temperature range, including the magnetisation compensation point. Using complementary techniques based on spin-torque ferromagnetic resonance spectroscopy, we separate the contributions of the spin Hall effect (SHE) and the spin anomalous Hall effect (SAHE). We show that the torques arising from both mechanisms retain their sign across the magnetisation compensation temperature, and that the SAHE-driven damping-like torque has the opposite sign to the SHE-driven term. We suggest that both effects originates from distinct electronic subsystems: the SHE emerging from Gd 5d electrons, and the SAHE from FeCo 3d electrons. Consequently, the SHE sign remains insensitive to the magnetisation state, whereas the SAHE sign does not invert at compensation, reproducing our observations. Together, these insights clarify the interplay between sublattices in ferrimagnetic spin transport and highlight the potential of ferrimagnetic spin currents to generate spin torques in adjacent layers or within the ferrimagnet itself.",
          "authors": [
            "Héloïse Damas",
            "Michel Hehn",
            "Juan-Carlos Rojás-Sanchez",
            "Sébastien Petit-Watelot"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20438",
          "title": "Exponential frames and Riesz sequences at the critical density",
          "abstract": "We characterize exponential systems on sets of finite measure that form a frame or a Riesz sequence at the critical density. Namely, they are precisely those systems for which the underlying point set admits a weak limit that yields a Riesz basis. In combination with a recent result by Kozma, Nitzan and Olevskii, this shows that there exist sets that fail to possess a frame or Riesz sequence at the critical density, solving an open problem posed by Olevskii. As another consequence, we show that exponential frames and Riesz sequences over repetitive point sets (such as cut-and-project sets) at the critical density are already Riesz bases.",
          "authors": [
            "Ulrik Enstad",
            "Jordy Timo van Velthoven"
          ],
          "primary_category": "math.CA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20743",
          "title": "The Dual of Quantifier Elimination: Boolean Elimination over C and R",
          "abstract": "We show that every finite Boolean combination of polynomial equalities and inequalities in C^n admits two uniform normal forms: an $\\exists\\forall$ form and a $\\forall\\exists$ form, each using a single polynomial equation. Both forms have one existentially quantified variable and one universally quantified variable; regardless of the complexity of the original formula, no longer quantifier blocks are needed. The constructions are explicit and have linear degree bounds. Optimality results demonstrate that no purely existential or universal normal form is possible over C. Over R, similar normal forms exist, including a singly-quantified $\\exists$ form for Boolean combinations of equations and inequations, and $\\exists^d$ and $\\forall\\exists$ forms for Boolean combinations involving order inequalities. Prior results establish the existence of a $\\exists$ normal form for R by other methods. Finally, similar forms exist over Q as well. These results may be viewed as a dual to classical quantifier elimination: instead of removing quantifiers at the cost of increased Boolean complexity, they remove Boolean structure at the cost of a short, fixed quantifier prefix.",
          "authors": [
            "Matthew Frank"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20743",
          "title": "The Dual of Quantifier Elimination: Boolean Elimination over C and R",
          "abstract": "We show that every finite Boolean combination of polynomial equalities and inequalities in C^n admits two uniform normal forms: an $\\exists\\forall$ form and a $\\forall\\exists$ form, each using a single polynomial equation. Both forms have one existentially quantified variable and one universally quantified variable; regardless of the complexity of the original formula, no longer quantifier blocks are needed. The constructions are explicit and have linear degree bounds. Optimality results demonstrate that no purely existential or universal normal form is possible over C. Over R, similar normal forms exist, including a singly-quantified $\\exists$ form for Boolean combinations of equations and inequations, and $\\exists^d$ and $\\forall\\exists$ forms for Boolean combinations involving order inequalities. Prior results establish the existence of a $\\exists$ normal form for R by other methods. Finally, similar forms exist over Q as well. These results may be viewed as a dual to classical quantifier elimination: instead of removing quantifiers at the cost of increased Boolean complexity, they remove Boolean structure at the cost of a short, fixed quantifier prefix.",
          "authors": [
            "Matthew Frank"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20968",
          "title": "SVEMnet: An R package for Self-Validated Elastic-Net Ensembles and Multi-Response Optimization in Small-Sample Mixture--Process Experiments",
          "abstract": "SVEMnet is an R package for fitting Self-Validated Ensemble Models (SVEM) with elastic-net base learners and performing multi-response optimization in small-sample mixture-process design-of-experiments (DOE) studies with numeric, categorical, and mixture factors. SVEMnet wraps elastic-net and relaxed elastic-net models for Gaussian and binomial responses from glmnet in a fractional random-weight (FRW) resampling scheme with anti-correlated train/validation weights; penalties are selected by validation-weighted AIC- and BIC-type criteria, and predictions are averaged across replicates to stabilize fits near the interpolation boundary. In addition to the core SVEM engine, the package provides deterministic high-order formula expansion, a permutation-based whole-model test heuristic, and a mixture-constrained random-search optimizer that combines Derringer-Suich desirability functions, bootstrap-based uncertainty summaries, and optional mean-level specification-limit probabilities to generate scored candidate tables and diverse exploitation and exploration medoids for sequential fit--score--run--refit workflows. A simulated lipid nanoparticle (LNP) formulation study illustrates these tools in a small-sample mixture-process DOE setting, and simulation experiments based on sparse quadratic response surfaces benchmark SVEMnet against repeated cross-validated elastic-net baselines.",
          "authors": [
            "Andrew T. Karl"
          ],
          "primary_category": "stat.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21231",
          "title": "Non-semisimple CFT/TFT correspondence I: General setup",
          "abstract": "We extend the TFT construction of CFT correlators of [ arXiv:hep-th/0204148 ] to so-called finite logarithmic CFTs for which the algebraic input data is no longer semisimple but still finite. More specifically, starting from the data of a chiral CFT given in the form of a not necessarily semisimple modular tensor category C we use a three dimensional topological field theory with surface defects based on the surgery TFT of [ arXiv:1912.02063 ] to construct a full CFT as a braided monoidal oplax natural transformation. We make our construction explicit in the example of the transparent surface defect, resulting in the so-called Cardy case. In particular, we consider topological line defects and their action on bulk fields in these logarithmic CFTs, providing a source of examples for non-invertible and non-semisimple topological symmetries.",
          "authors": [
            "Aaron Hofer",
            "Ingo Runkel"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21231",
          "title": "Non-semisimple CFT/TFT correspondence I: General setup",
          "abstract": "We extend the TFT construction of CFT correlators of [ arXiv:hep-th/0204148 ] to so-called finite logarithmic CFTs for which the algebraic input data is no longer semisimple but still finite. More specifically, starting from the data of a chiral CFT given in the form of a not necessarily semisimple modular tensor category C we use a three dimensional topological field theory with surface defects based on the surgery TFT of [ arXiv:1912.02063 ] to construct a full CFT as a braided monoidal oplax natural transformation. We make our construction explicit in the example of the transparent surface defect, resulting in the so-called Cardy case. In particular, we consider topological line defects and their action on bulk fields in these logarithmic CFTs, providing a source of examples for non-invertible and non-semisimple topological symmetries.",
          "authors": [
            "Aaron Hofer",
            "Ingo Runkel"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21231",
          "title": "Non-semisimple CFT/TFT correspondence I: General setup",
          "abstract": "We extend the TFT construction of CFT correlators of [ arXiv:hep-th/0204148 ] to so-called finite logarithmic CFTs for which the algebraic input data is no longer semisimple but still finite. More specifically, starting from the data of a chiral CFT given in the form of a not necessarily semisimple modular tensor category C we use a three dimensional topological field theory with surface defects based on the surgery TFT of [ arXiv:1912.02063 ] to construct a full CFT as a braided monoidal oplax natural transformation. We make our construction explicit in the example of the transparent surface defect, resulting in the so-called Cardy case. In particular, we consider topological line defects and their action on bulk fields in these logarithmic CFTs, providing a source of examples for non-invertible and non-semisimple topological symmetries.",
          "authors": [
            "Aaron Hofer",
            "Ingo Runkel"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21639",
          "title": "Lower central series of the Riordan group over the field with two elements",
          "abstract": "The Riordan group ${\\cal R}$ over the field ${\\mathbb F}_2$ is a split extension of the Appell subgroup by the Nottingham group ${\\cal N}({\\mathbb F}_2)$. Using the lower central series of the Nottingham group obtained by C. Leedham-Green and S. McKay, the lower central series of ${\\cal R}({\\mathbb F}_2)$ is calculated. Considering the Riordan group over an arbitrary commutative ring with identity, where all Riordan arrays have only 1s on the main diagonal, it is also proved that the abelianization of this group is isomorphic to the direct product of the abelianization of the corresponding Lagrange subgroup and the additive group of the ground ring.",
          "authors": [
            "Nikolai A. Krylov"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22358",
          "title": "On Universal Graphs for Trees and Tree-Like Graphs",
          "abstract": "Chung and Graham [J. London Math. Soc., 1983] claimed to prove that there exists an $n$-vertex graph $G$ with $\\frac{5}{2}n \\log_2 n + O(n)$ edges that contains every $n$-vertex tree as a subgraph. Frati, Hoffmann and Tóth [Combin. Probab. Comput., 2023] discovered an error in the proof. By adding more edges to $G$ the error can be corrected, bringing the number of edges in $G$ to $\\frac{7}{2}n \\log_2 n + O(n). $ We make the first improvement to Chung and Graham's bound in over four decades by showing that there exists an $n$-vertex graph with $\\frac{14}{5}n \\log_2 n + O(n) $ edges that contains every $n$-vertex tree as a subgraph. Furthermore, we generalise this bound for treewidth-$k$ graphs by showing that there exists a graph with $O(kn\\log n)$ edges that contains every $n$-vertex treewidth-$k$ graph as a subgraph. This is best possible in the sense that $\\Omega(kn\\log{n})$ edges are required.",
          "authors": [
            "Neel Kaul",
            "Jaehoon Kim",
            "Minseo Kim",
            "David Wood"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22797",
          "title": "Splitting p-primary cohomology classes of tori in characteristic p",
          "abstract": "We prove that $p$-primary cohomology classes of a torus $T$ over a global function field of characteristic $p$ may be split by suitable separable $p$-primary extensions. More precisely, we show that such cohomology classes will split in any ``large'' $p$-primary extension (and in fact, prove the same for $\\ell$-primary classes over ``large'' $\\ell$-primary extensions for every prime $\\ell$, including $\\ell \\neq \\mathrm{char}(K)$), and we prove that $p^n$-torsion classes may be split by a (solvable) separable $p$-primary extension of degree $\\leq (p^n)^{1+cm\\mathrm{log}(m)^3}$ for an explicitly computable universal constant $c > 0$, where $m$ is the degree of a finite Galois extension splitting the torus $T$. Along the way, we also prove Grunwald-Wang type results of independent interest which allow one to approximate a given finite list of abelian $p$-primary local extensions of places of a global function field by a suitable global extension.",
          "authors": [
            "Zev Rosengarten"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22856",
          "title": "Algebraic Obstructions and the Collapse of Elementary Structure in the Kronecker Problem",
          "abstract": "While Kronecker coefficients $g(\\lambda,\\mu,\\nu)$ with bounded rows are polynomial-time computable via lattice-point methods, no explicit closed-form formulas have been obtained for genuinely three-row cases in the 87 years since Murnaghan's foundational work. This paper provides such formulas for the first time and identifies a universal structural boundary at parameter value 5 where elementary combinatorial patterns collapse. We analyze two independent families of genuinely three-row coefficients and establish that for $k \\leq 4$, the formulas exhibit elementary structure: oscillation bounds follow the triangular-Hogben pattern, and polynomial expressions factor completely over $\\mathbb{Z}$. At the critical threshold $k=5$, this structure collapses: the triangular pattern fails, and algebraic obstructions -- irreducible quadratic factors with negative discriminant -- emerge. We develop integer forcing, a proof technique exploiting the tension between continuous asymptotics and discrete integrality. As concrete results, we prove that $g((n,n,1)^3) = 2 - (n \\mod 2)$ for all $n \\geq 3$ -- the first explicit formula for a genuinely three-row Kronecker coefficient -- derive five explicit polynomial formulas for staircase-hook coefficients, and verify Saxl's conjecture for 132 three-row partitions.",
          "authors": [
            "Soong Kyum Lee"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22856",
          "title": "Algebraic Obstructions and the Collapse of Elementary Structure in the Kronecker Problem",
          "abstract": "While Kronecker coefficients $g(\\lambda,\\mu,\\nu)$ with bounded rows are polynomial-time computable via lattice-point methods, no explicit closed-form formulas have been obtained for genuinely three-row cases in the 87 years since Murnaghan's foundational work. This paper provides such formulas for the first time and identifies a universal structural boundary at parameter value 5 where elementary combinatorial patterns collapse. We analyze two independent families of genuinely three-row coefficients and establish that for $k \\leq 4$, the formulas exhibit elementary structure: oscillation bounds follow the triangular-Hogben pattern, and polynomial expressions factor completely over $\\mathbb{Z}$. At the critical threshold $k=5$, this structure collapses: the triangular pattern fails, and algebraic obstructions -- irreducible quadratic factors with negative discriminant -- emerge. We develop integer forcing, a proof technique exploiting the tension between continuous asymptotics and discrete integrality. As concrete results, we prove that $g((n,n,1)^3) = 2 - (n \\mod 2)$ for all $n \\geq 3$ -- the first explicit formula for a genuinely three-row Kronecker coefficient -- derive five explicit polynomial formulas for staircase-hook coefficients, and verify Saxl's conjecture for 132 three-row partitions.",
          "authors": [
            "Soong Kyum Lee"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22856",
          "title": "Algebraic Obstructions and the Collapse of Elementary Structure in the Kronecker Problem",
          "abstract": "While Kronecker coefficients $g(\\lambda,\\mu,\\nu)$ with bounded rows are polynomial-time computable via lattice-point methods, no explicit closed-form formulas have been obtained for genuinely three-row cases in the 87 years since Murnaghan's foundational work. This paper provides such formulas for the first time and identifies a universal structural boundary at parameter value 5 where elementary combinatorial patterns collapse. We analyze two independent families of genuinely three-row coefficients and establish that for $k \\leq 4$, the formulas exhibit elementary structure: oscillation bounds follow the triangular-Hogben pattern, and polynomial expressions factor completely over $\\mathbb{Z}$. At the critical threshold $k=5$, this structure collapses: the triangular pattern fails, and algebraic obstructions -- irreducible quadratic factors with negative discriminant -- emerge. We develop integer forcing, a proof technique exploiting the tension between continuous asymptotics and discrete integrality. As concrete results, we prove that $g((n,n,1)^3) = 2 - (n \\mod 2)$ for all $n \\geq 3$ -- the first explicit formula for a genuinely three-row Kronecker coefficient -- derive five explicit polynomial formulas for staircase-hook coefficients, and verify Saxl's conjecture for 132 three-row partitions.",
          "authors": [
            "Soong Kyum Lee"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22871",
          "title": "Wave-Particle Complementarity as the Optimal Limit of Unambiguous Quantum-State Discrimination",
          "abstract": "We establish a direct operational interpretation of wave--particle complementarity in induced-coherence interferometry by linking interference visibility to the optimal performance of unambiguous quantum-state discrimination. In the low-gain Zou--Wang--Mandel interferometer, the idler modes of the two SPDC crystals act as nonorthogonal which-crystal marker states, and we show that the single-photon visibility equals the minimal inconclusive probability of the optimal Ivanovic--Dieks--Peres (IDP) strategy, $V = P_I^{\\mathrm{opt}}$, so that the complementarity relation $D^{2}+V^{2}=1$ expresses a measurement-optimality boundary rather than a geometric constraint. Our results reveal that wave--particle duality in induced coherence is not limited by interferometer geometry but by measurement optimality in zero-error discrimination on the idler, with experimentally testable consequences predicting distinguishability beyond that inferred from visibility alone. In the presence of thermal noise we derive the hierarchy $V \\le F(\\rho_A,\\rho_B) \\le P_I^{\\mathrm{opt}}$, linking visibility, fidelity, and optimal discrimination. These results identify distinguishability as fundamentally measurement-limited and motivate discrimination-enhanced induced-coherence imaging and sensing.",
          "authors": [
            "Theerthagiri L"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23054",
          "title": "Magnetoelectric topology: the rope weaving in parameter space",
          "abstract": "Topology, as a mathematical concept, has been introduced into condensed matter physics since the discovery of quantum Hall effect, which characterizes new physical scenario beyond the Landau theory. The topologically protected physical quantities, such as the dissipationless quantum transport of edge/surface states as well as magnetic/dipole quasi-particles like skyrmions/bimerons, have attracted great research enthusiasms in the past decades. In recent years, another kind of topology in condensed matter was revealed in the magnetoelectric parameter space of multiferroics, which deepens our understanding of magnetoelectric physics. This topical review summarizes recent advances in this area, involving three type-II multiferroics. With magnetism-induced ferroelectricity, topological behaviors can be manifested during the magnetoelectric switching processes driven by magnetic/electric fields, such as Roman-surface/Riemann-surface magnetoelectricity and magnetic crankshaft. These exotic topological magnetoelectric behaviors may be helpful to pursuit energy-efficient and precise-control devices for spintronics and quantum computing.",
          "authors": [
            "Ying Zhou",
            "Ziwen Wang",
            "Fan Wang",
            "Haoshen Ye",
            "Shuai Dong"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23180",
          "title": "Liquid Tannaka Duality I: Classical Case",
          "abstract": "We prove a Tannaka duality statement for geometric stacks in the setting of analytic stacks modelled on globally finitely presented Stein spaces. The key ingredient is the theory of liquid vector spaces and liquid quasicoherent sheaves of Clausen-Scholze. As an application, we reconstruct the topological fundamental group of any complex algebraic variety from its category of liquid local systems. We also reconstruct a series of \"twisted fundamental groupoids\" whose representations correspond to meromorphic flat connections on the complex affine line with logarithmic or irregular singularities at the origin.",
          "authors": [
            "Waleed Qaisar",
            "Gregory Taroyan"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23197",
          "title": "A thermodynamic framework for the thermal conductivity of dense fluids",
          "abstract": "A thermodynamic framework that predicts the thermal conductivity $\\lambda$ of simple fluids beyond the dilute-gas limit is introduced. By generalizing the transition-rate approach of particles on a lattice to conserved quantities in continuous space, an expression for the ratio $\\lambda/\\lambda_{\\rm id}$ is derived, where $\\lambda_{\\rm id}$ is the dilute-gas value; the ratio depends solely on equilibrium thermodynamic properties and is therefore directly computable from any equation of state. The resulting formula quantitatively reproduces simulation data for hard spheres throughout almost the entire fluid range, and captures the behavior of Lennard-Jones fluids in the supercritical region where thermodynamic fluctuations remain moderate. Comparison with experimental data for argon, reported by other authors, also shows good agreement. These results provide evidence that transport coefficients of dense fluids can be expressed as their dilute-gas values multiplied by a universal function of equilibrium thermodynamic properties.",
          "authors": [
            "Miguel Hoyuelos"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23223",
          "title": "On restricted sums of four squares and Zhi-Wei Sun's $x+24y$ conjecture",
          "abstract": "In this paper, by using the arithmetic theory of ternary quadratic forms, we study some refinements on Lagrange's four-square theorem. For example, given positive integers $a,b$ satisfying some algebraic conditions and a positive integer $C\\ge3$, we will show that for any sufficiently large integer $n$ with $\\ord_2(n)\\le C$, there exist non-negative integers $x,y,z,w$ such that $$ \\begin{cases} x^2+y^2+z^2+w^2=n, ax+by\\in\\mathcal{S}, \\end{cases} $$ where $\\mathcal{S}$ is the set of all squares over $\\mathbb{Z}$. In particular, we obtain some progress on Zhi-Wei Sun's $x+24y$ conjecture.",
          "authors": [
            "Hai-Liang Wu",
            "Yue-Feng She"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23358",
          "title": "TypeDis: A Type System for Disentanglement",
          "abstract": "Disentanglement is a runtime property of parallel programs guaranteeing that parallel tasks remain oblivious to each other's allocations. As demonstrated in the MaPLe compiler and run-time system, disentanglement can be exploited for fast automatic memory management, especially task-local garbage collection with no synchronization between parallel tasks. However, as a low-level property, disentanglement can be difficult to reason about for programmers. The only means of statically verifying disentanglement so far has been DisLog, an Iris-fueled variant of separation logic, mechanized in the Rocq proof assistant. DisLog is a fully-featured program logic, allowing for proof of functional correctness as well as verification of disentanglement. Yet its employment requires significant expertise and per-program proof effort. This paper explores the route of automatic verification via a type system, ensuring that any well-typed program is disentangled and lifting the burden of carrying out manual proofs from the programmer. It contributes TypeDis, a type system inspired by region types, where each type is annotated with a timestamp, identifying the task that allocated it. TypeDis supports iso-recursive types as well as polymorphism over both types and timestamps. Crucially, timestamps are allowed to change during type-checking, at join points as well as via a form of subtyping, dubbed subtiming. The paper illustrates TypeDis and its features on a range of examples. The soundness of TypeDis and the examples are mechanized in the Rocq proof assistant, using an improved version of DisLog, dubbed DisLog2.",
          "authors": [
            "Alexandre Moine",
            "Stephanie Balzer",
            "Alex Xu",
            "Sam Westrick"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23472",
          "title": "RapunSL: Untangling Quantum Computing with Separation, Linear Combination and Mixing",
          "abstract": "Quantum Separation Logic (QSL) has been proposed as an effective tool to improve the scalability of deductive reasoning for quantum programs. In QSL, separation is interpreted as disentanglement, and the frame rule brings a notion of entanglement-local specification (one that only talks about the qubits entangled with those acted upon by the program). In this paper, we identify two notions of locality unique to the quantum domain, and we construct a novel quantum separation logic, RapunSL, which is able to soundly reduce reasoning about superposition states to reasoning about pure states (basis-locality), and reasoning about mixed states arising from measurement to reasoning about pure states (outcome-locality). To do so, we introduce two connectives, linear combination and mixing, which together with separation provide a dramatic improvement in the scalability of reasoning, as we demonstrate on a series of challenging case studies.",
          "authors": [
            "Yusuke Matsushita",
            "Kengo Hirata",
            "Ryo Wakizaka",
            "Emanuele D'Osualdo"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23472",
          "title": "RapunSL: Untangling Quantum Computing with Separation, Linear Combination and Mixing",
          "abstract": "Quantum Separation Logic (QSL) has been proposed as an effective tool to improve the scalability of deductive reasoning for quantum programs. In QSL, separation is interpreted as disentanglement, and the frame rule brings a notion of entanglement-local specification (one that only talks about the qubits entangled with those acted upon by the program). In this paper, we identify two notions of locality unique to the quantum domain, and we construct a novel quantum separation logic, RapunSL, which is able to soundly reduce reasoning about superposition states to reasoning about pure states (basis-locality), and reasoning about mixed states arising from measurement to reasoning about pure states (outcome-locality). To do so, we introduce two connectives, linear combination and mixing, which together with separation provide a dramatic improvement in the scalability of reasoning, as we demonstrate on a series of challenging case studies.",
          "authors": [
            "Yusuke Matsushita",
            "Kengo Hirata",
            "Ryo Wakizaka",
            "Emanuele D'Osualdo"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00247",
          "title": "On the Dynamics of Multiparticle Carroll-Schrdinger Quantum Systems",
          "abstract": "We study the dynamics of multiparticle Carroll-Schrödinger (CS) quantum systems in $1{+}1$ dimensions, where $x$ acts as the evolution variable and $t$ as the configuration coordinate. We derive the $N$-body theory on equal-$x$ slices as the Carrollian limit of a relativistic multi-time Klein-Gordon model, introducing temporal interactions via minimal coupling to the temporal energy operators. An $x$-dependent gauge transformation maps this to an equivalent description with explicit many-body potentials, illustrated by a temporal coupled-oscillator model that exhibits synchronization. Adopting a complementary spatial viewpoint with a static potential $U_{\\!tot}(\\mathbf x)$, we show that the evolution is driven by the collective force $\\sum_j\\partial_{x_j}U_{\\!tot}$; for any translation-invariant interaction (such as a regularized Coulomb potential), these internal forces cancel, rendering the collective dynamics free and highlighting Carrollian ultralocality. We also construct a coordinate duality mapping separable Schrödinger Hamiltonians to CS generators via Schwarzian derivatives. Exchange symmetry is formulated in the time domain, yielding temporal bunching for bosons and antibunching for fermions via the second-order coherence function $g^{(2)}(t,t')$. In second quantization, the contact limit yields a temporal derivative cubic--quintic nonlinear Schrödinger equation with a theoretically fixed nonlinearity coefficient $\\beta=-3/16$. Finally, by coupling canonical pairs to external scalar and gauge fields, we establish an isomorphism with one-dimensional current-density functional theory, outlining a Carrollian Hohenberg-Kohn mapping and Kohn-Sham scheme.",
          "authors": [
            "José Rojas",
            "Melvin Arias"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00263",
          "title": "A Uniform Rewriting Algorithm for Twisted Tensor Representations of Finite General Linear Groups",
          "abstract": "Let $q=p^f$ be a prime power and let $H$ be a classical group of type $A$, so $H \\cong \\mathrm{SL}_d(q)$ or $\\mathrm{GL}_d(q)$, acting on its natural module $V$ of dimension $d$ over $\\mathbb{F}_q$. Let $W$ be an absolutely irreducible $\\mathbb{F}_qH$--module such that, over an algebraic closure, $W$ is isomorphic (up to Frobenius twists) to a tensor product $\\bigotimes_{t=1}^r L(\\lambda^{(t)})$, where each $L(\\lambda^{(t)})$ is an irreducible polynomial representation of $\\mathrm{GL}_d$ of degree $k_t$, and the total degree $K=\\sum_t k_t$ satisfies $K<q-1$. We prove a base-$q$ injectivity lemma which shows that, for a Singer cycle $s \\in H$, the eigenvalues of $s$ on $W \\otimes_{\\mathbb{F}_q} \\mathbb{F}_{q^d}$ are parametrised by digit vectors of length $d$ with entries bounded by $K$. In particular, distinct weights of $W$ correspond to distinct eigenvalues. If in addition $W$ is multiplicity-free for the diagonal torus of $\\mathrm{GL}_d$, then every eigenspace of $s$ is one-dimensional, so $s$ has a simple spectrum on $W$. Using this spectral property we design a Las Vegas rewriting algorithm which, given $G \\leq \\mathrm{GL}(W)$ isomorphic to $H$ and acting irreducibly on $W$, constructs a projective representation of $G$ of degree $d$ equivalent to the natural representation of $H$. The expected running time is polynomial in $d$, $\\log q$ and $K$, and in the cost of field operations and discrete logarithm computations in $\\mathbb{F}_{q^d}$. This extends earlier rewriting algorithms of Magaard--O'Brien--Seress and of Gül--Ankaralıoğlu to a broader class of twisted tensor products of polynomial modules.",
          "authors": [
            "Dang Vo Phuc"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00561",
          "title": "Optimized Many-Hypercube Codes toward Lower Logical Error Rates and Earlier Realization",
          "abstract": "Many-hypercube codes [H. Goto, Sci. Adv. 10, eadp6388 (2024)], concatenated ${[[n,n-2,2]]}$ quantum error-detecting codes ($n$ is even), have recently been proposed as high-rate quantum codes suitable for fault-tolerant quantum computing. While the original many-hypercube codes with ${n=6}$ can achieve remarkably high encoding rates (about 30% and 20% at concatenation levels 3 and 4, respectively), they have large code block sizes at high levels (216 and 1296 physical qubits per block at levels 3 and 4, respectively), making not only experimental realization difficult but also logical error rates per block high. Toward earlier experimental realization and lower logical error rates, here we comprehensively investigate smaller many-hypercube codes with $[[6,4,2]]$ and/or $[[4,2,2]]$ codes, where, e.g., $D_{6,4,4}$ denotes the many-hypercube code using $[[6,4,2]]$ at level 1 and $[[4,2,2]]$ at levels 2 and 3. As a result, we found a notable fact that $D_{6,4,4}$ ($D_{6,6,4,4}$) can achieve lower block error rates than $D_{4,4,4}$ ($D_{4,4,4,4}$), despite its higher encoding rate. Focusing on level 3, we also developed efficient fault-tolerant encoders realizing about 60% overhead reduction while maintaining or even improving the performance, compared to the original design. Using them, we numerically confirmed that $D_{6,4,4}$ also achieves the best performance for logical controlled-NOT gates in a circuit-level noise model. These results will be useful for early experimental realization of fault-tolerant quantum computing with high-rate quantum codes.",
          "authors": [
            "Hayato Goto"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00561",
          "title": "Optimized Many-Hypercube Codes toward Lower Logical Error Rates and Earlier Realization",
          "abstract": "Many-hypercube codes [H. Goto, Sci. Adv. 10, eadp6388 (2024)], concatenated ${[[n,n-2,2]]}$ quantum error-detecting codes ($n$ is even), have recently been proposed as high-rate quantum codes suitable for fault-tolerant quantum computing. While the original many-hypercube codes with ${n=6}$ can achieve remarkably high encoding rates (about 30% and 20% at concatenation levels 3 and 4, respectively), they have large code block sizes at high levels (216 and 1296 physical qubits per block at levels 3 and 4, respectively), making not only experimental realization difficult but also logical error rates per block high. Toward earlier experimental realization and lower logical error rates, here we comprehensively investigate smaller many-hypercube codes with $[[6,4,2]]$ and/or $[[4,2,2]]$ codes, where, e.g., $D_{6,4,4}$ denotes the many-hypercube code using $[[6,4,2]]$ at level 1 and $[[4,2,2]]$ at levels 2 and 3. As a result, we found a notable fact that $D_{6,4,4}$ ($D_{6,6,4,4}$) can achieve lower block error rates than $D_{4,4,4}$ ($D_{4,4,4,4}$), despite its higher encoding rate. Focusing on level 3, we also developed efficient fault-tolerant encoders realizing about 60% overhead reduction while maintaining or even improving the performance, compared to the original design. Using them, we numerically confirmed that $D_{6,4,4}$ also achieves the best performance for logical controlled-NOT gates in a circuit-level noise model. These results will be useful for early experimental realization of fault-tolerant quantum computing with high-rate quantum codes.",
          "authors": [
            "Hayato Goto"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00685",
          "title": "Error analysis of an acceleration corrected diffusion approximation of Langevin dynamics with background flow",
          "abstract": "We consider the problem of approximating the Langevin dynamics of inertial particles being transported by a background flow. In particular, we study an acceleration corrected advection-diffusion approximation to the Langevin dynamics, a popular approximation in the study of turbulent transport. We prove error estimates in the averaging regime in which the dimensionless relaxation timescale $\\varepsilon$ is the small parameter. We show that for any finite time interval, the approximation error is of order $\\mathcal{O}(\\varepsilon)$ in the strong sense and $\\mathcal{O}(\\varepsilon^2)$ in the weak sense, whose optimality is checked against computational experiment. Furthermore, we present numerical evidence suggesting that this approximation also captures the long-time behavior of the Langevin dynamics.",
          "authors": [
            "Yoichiro Mori",
            "Chanoknun Sintavanuruk",
            "Truong-Son P. Van"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00685",
          "title": "Error analysis of an acceleration corrected diffusion approximation of Langevin dynamics with background flow",
          "abstract": "We consider the problem of approximating the Langevin dynamics of inertial particles being transported by a background flow. In particular, we study an acceleration corrected advection-diffusion approximation to the Langevin dynamics, a popular approximation in the study of turbulent transport. We prove error estimates in the averaging regime in which the dimensionless relaxation timescale $\\varepsilon$ is the small parameter. We show that for any finite time interval, the approximation error is of order $\\mathcal{O}(\\varepsilon)$ in the strong sense and $\\mathcal{O}(\\varepsilon^2)$ in the weak sense, whose optimality is checked against computational experiment. Furthermore, we present numerical evidence suggesting that this approximation also captures the long-time behavior of the Langevin dynamics.",
          "authors": [
            "Yoichiro Mori",
            "Chanoknun Sintavanuruk",
            "Truong-Son P. Van"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00726",
          "title": "First-principles calculations of elasto-optical properties of $R$Te$_3$",
          "abstract": "Rare-earth tritellurides ($R$Te$_3$) exhibit complex charge-density-wave (CDW) phases intertwined with lattice symmetry, offering a platform to explore unconventional symmetry breaking in correlated materials. Elasto-optical probing, which detects strain-induced changes in birefringence, provides a non-invasive approach to visualize anisotropy and emergent order in these quasi-two-dimensional systems. However, the magnitude and symmetry of the expected optical response remain poorly quantified, hindering experimental interpretation. Here, we perform first-principles calculations of the elastic, dielectric, and piezo-optical tensors of NdTe$_3$ to establish a quantitative framework for strain-induced optical anisotropy. These results establish a quantitative link between lattice strain and optical response in $R$Te$_3$, providing a predictive framework for probing symmetry-breaking states via elasto-birefringence.",
          "authors": [
            "Kuiqing Tang"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00751",
          "title": "Fragmentation is Efficiently Learnable by Quantum Neural Networks",
          "abstract": "Hilbert space fragmentation is a phenomenon in which the Hilbert space of a quantum system is dynamically decoupled into exponentially many Krylov subspaces. We can define the Schur transform as a unitary operation mapping some set of preferred bases of these Krylov subspaces to computational basis states labeling them. We prove that this transformation can be efficiently learned via gradient descent from a set of training data using quantum neural networks, provided that the fragmentation is sufficiently strong such that the summed dimension of the unique Krylov subspaces is polynomial in the system size. To demonstrate this, we analyze the loss landscapes of random quantum neural networks constructed out of Hilbert space fragmented systems. We prove that in this setting, it is possible to eliminate barren plateaus and poor local minima, suggesting efficient trainability when using gradient descent. Furthermore, as the algebra defining the fragmentation is not known a priori and not guaranteed to have sparse algebra elements, to the best of our knowledge there are no existing efficient classical algorithms generally capable of simulating expectation values in these networks. Our setting thus provides a rare example of a physically motivated quantum learning task with no known dequantization.",
          "authors": [
            "Mikhail Mints",
            "Eric R. Anschuetz"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00751",
          "title": "Fragmentation is Efficiently Learnable by Quantum Neural Networks",
          "abstract": "Hilbert space fragmentation is a phenomenon in which the Hilbert space of a quantum system is dynamically decoupled into exponentially many Krylov subspaces. We can define the Schur transform as a unitary operation mapping some set of preferred bases of these Krylov subspaces to computational basis states labeling them. We prove that this transformation can be efficiently learned via gradient descent from a set of training data using quantum neural networks, provided that the fragmentation is sufficiently strong such that the summed dimension of the unique Krylov subspaces is polynomial in the system size. To demonstrate this, we analyze the loss landscapes of random quantum neural networks constructed out of Hilbert space fragmented systems. We prove that in this setting, it is possible to eliminate barren plateaus and poor local minima, suggesting efficient trainability when using gradient descent. Furthermore, as the algebra defining the fragmentation is not known a priori and not guaranteed to have sparse algebra elements, to the best of our knowledge there are no existing efficient classical algorithms generally capable of simulating expectation values in these networks. Our setting thus provides a rare example of a physically motivated quantum learning task with no known dequantization.",
          "authors": [
            "Mikhail Mints",
            "Eric R. Anschuetz"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01058",
          "title": "Stability analysis of action potential generation using Markov models of voltage-gated sodium channel isoforms",
          "abstract": "We investigate a conductance-based neuron model to explore how voltage-gated ion channel isoforms influence action-potential generation. The model combines a six-state Markov representation of NaV channels with a first-order KV3.1 model, allowing us to vary maximal sodium and potassium conductances and compare nine NaV isoforms. Using bifurcation theory and local stability analysis, we map regions of stable limit cycles and visualize excitability landscapes via heatmap-based diagrams. These analyses show that isoforms NaV1.3, NaV1.4 and NaV1.6 support broad excitable regimes, while isoforms NaV1.7 and NaV1.9 exhibit minimal oscillatory behavior. Our findings provide insights into the role of channel heterogeneity in neuronal dynamics and may help to guide the design of synthetic excitable systems by narrowing the parameter space needed for robust action-potential trains.",
          "authors": [
            "Youssof Abdullah",
            "Violet Hart",
            "Moumita Das"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01058",
          "title": "Stability analysis of action potential generation using Markov models of voltage-gated sodium channel isoforms",
          "abstract": "We investigate a conductance-based neuron model to explore how voltage-gated ion channel isoforms influence action-potential generation. The model combines a six-state Markov representation of NaV channels with a first-order KV3.1 model, allowing us to vary maximal sodium and potassium conductances and compare nine NaV isoforms. Using bifurcation theory and local stability analysis, we map regions of stable limit cycles and visualize excitability landscapes via heatmap-based diagrams. These analyses show that isoforms NaV1.3, NaV1.4 and NaV1.6 support broad excitable regimes, while isoforms NaV1.7 and NaV1.9 exhibit minimal oscillatory behavior. Our findings provide insights into the role of channel heterogeneity in neuronal dynamics and may help to guide the design of synthetic excitable systems by narrowing the parameter space needed for robust action-potential trains.",
          "authors": [
            "Youssof Abdullah",
            "Violet Hart",
            "Moumita Das"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01268",
          "title": "ViscNet: Vision-Based In-line Viscometry for Fluid Mixing Process",
          "abstract": "Viscosity measurement is essential for process monitoring and autonomous laboratory operation, yet conventional viscometers remain invasive and require controlled laboratory environments that differ substantially from real process conditions. We present a computer-vision-based viscometer that infers viscosity by exploiting how a fixed background pattern becomes optically distorted as light refracts through the mixing-driven, continuously deforming free surface. Under diverse lighting conditions, the system achieves a mean absolute error of 0.113 in log m2 s^-1 units for regression and reaches up to 81% accuracy in viscosity-class prediction. Although performance declines for classes with closely clustered viscosity values, a multi-pattern strategy improves robustness by providing enriched visual cues. To ensure sensor reliability, we incorporate uncertainty quantification, enabling viscosity predictions with confidence estimates. This stand-off viscometer offers a practical, automation-ready alternative to existing viscometry methods.",
          "authors": [
            "Jongwon Sohn",
            "Juhyeon Moon",
            "Hyunjoon Jung",
            "Jaewook Nam"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01304",
          "title": "Higher-order spectral form factors of circular unitary ensemble",
          "abstract": "Spectral form factor (SFF), one of the key quantity from random matrix theory, serves as an important tool to probe universality in disordered quantum systems and quantum chaos. In this work, we present exact closed-form expressions for the second- and third-order SFFs in the circular unitary ensemble (CUE), valid for all real values of the time parameter, and analyze their asymptotic behavior in different regimes. In particular, for the second-order SFF, we derive an exact closed-form expression in terms of polygamma functions. In the limit of infinite matrix size, and when the time parameter is restricted to integer values, the second-order SFF reproduces the standard result established in earlier studies. When the time parameter is of order one relative to the matrix size, we demonstrate that the second-order SFF grows logarithmically with the ensemble dimension. For the third-order SFFs, a closed-form result in a special case is obtained by exploiting the translational invariance of CUE.",
          "authors": [
            "Sohail",
            "Youyi Huang",
            "Lu Wei"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01308",
          "title": "On the analytical behavior of the $k$--$ω$ turbulence model in buoyant-driven thermal convection",
          "abstract": "The representation of buoyancy-driven turbulence in Reynolds-averaged Navier--Stokes models remains unresolved, with no widely accepted standard formulation. A key difficulty is the lack of analytical guidance for incorporating buoyant effects, particularly under unstable stratification. This study derives an analytical solution of the standard $k$--$\\omega$ model for Rayleigh--Bénard convection in an infinite layer, where turbulent kinetic energy is generated solely by buoyancy. The solution provides explicit scaling relations among the Rayleigh ($\\Ra$), Prandtl ($\\Pran$), and Nusselt ($\\Nu$) numbers that capture the simulation trends: $\\Nu \\sim \\Ra^{1/3}\\Pran^{1/3}$ for $\\Pran \\ll 1$ and $\\Nu \\sim \\Ra^{1/3}\\Pran^{-0.415}$ for $\\Pran \\gg 1$. This framework quantifies the discrepancies in the conventional buoyancy treatment and clarifies their origin. Informed by this analysis, the buoyancy-related modelling terms are reformulated to recover the measured $\\Nu$--$\\Ra$--$\\Pran$ trends. Only two dimensionless algebraic functions are introduced, which vanish in the absence of buoyancy, ensuring full compatibility with the standard closure. The corrected model is validated across a range of buoyancy-driven flows, including two-dimensional Rayleigh--Bénard convection, internally heated convection in two configurations, unstably stratified Couette flow, and vertically heated natural convection with varying aspect ratios. Across all cases, it provides highly accurate predictions.",
          "authors": [
            "Da-Sol Joo"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01602",
          "title": "Uniqueness of the Bonnet problem in Thurston geometries",
          "abstract": "We study the Bonnet problem in Bianchi--Cartan--Vrănceanu spaces and in $\\mathrm{Sol}_3$. Our main contribution is to establish the uniqueness of Bonnet mates, which leads us to address the problem of determining when an isometric immersion can be continuously deformed through isometric immersions that preserve the principal curvatures -- a question originally posed in $\\mathbb{R}^3$ by Chern~\\cite{Chern}. For Bianchi--Cartan--Vrănceanu spaces, we complete the local classification of Bonnet pairs by studying the uniqueness of the results obtained by Gálvez, Martínez and Mira~\\cite{GMM}, and we provide new examples of Bonnet mates that were not previously considered. In particular, we prove that the aforesaid continuous deformations only exist for minimal surfaces in the product spaces $\\mathbb{S}^2\\times\\mathbb{R}$ and $\\mathbb{H}^2\\times\\mathbb{R}$ and otherwise only for surfaces with constant principal curvatures. In the case of $\\mathrm{Sol}_3$, we give a characterization of Bonnet mates via a system of two differential equations, addressing a problem proposed in~\\cite{GMM}. We conclude that the only surfaces admitting continuous isometric deformations that preserve the principal curvatures in $\\mathrm{Sol}_3$ are those with constant left-invariant Gauss map.",
          "authors": [
            "José S. Santiago"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01683",
          "title": "An innovative circuit for testing hot carrier and trap generation in GaN Devices",
          "abstract": "Microelectronic devices in modern systems are working continuously for prolonged periods of many years. Thus, there is a crucial need for reliability model that will enable us to predict precisely the life cycle of the device and point out on the governing failure mechanisms that are responsible for degradation and failure. This is even more important when high power and frequency devices, especially Normally Off Switch Power transistors are concerned, since the reliability research on those devices lay far behind that of low power digital devices. Our main goal in our lab is to investigate the failure mechanisms of GaN transistors, aimed at determining the reliability factors of the innovative MTOL model. The main goal is to understand the reason for the transformation of the failure mechanism. Employing the recorded data may enable us to predict the performance and life time of the device at different operation parameters such as current, voltage, frequency and temperatures. In this study we employ a new different use for the well-known boost convertor circuit, based on GaN Devices in order to stress the transistor to the maximum values of voltage and current which allows us to examine the reliability of the transistor and accelerating Hot Carrier And Trap Generation failures mechanisms. The acceleration of the failure mechanism should be done in a way that will not affect the electronic device detrimentally and on the other hand we would not need to wait a long time in order to observe the degradation. In this work we will present our new boost converter circuit based on high power GaN HEMT.",
          "authors": [
            "Moshe Azoulay",
            "Gilad Orr",
            "Gady Golan"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01683",
          "title": "An innovative circuit for testing hot carrier and trap generation in GaN Devices",
          "abstract": "Microelectronic devices in modern systems are working continuously for prolonged periods of many years. Thus, there is a crucial need for reliability model that will enable us to predict precisely the life cycle of the device and point out on the governing failure mechanisms that are responsible for degradation and failure. This is even more important when high power and frequency devices, especially Normally Off Switch Power transistors are concerned, since the reliability research on those devices lay far behind that of low power digital devices. Our main goal in our lab is to investigate the failure mechanisms of GaN transistors, aimed at determining the reliability factors of the innovative MTOL model. The main goal is to understand the reason for the transformation of the failure mechanism. Employing the recorded data may enable us to predict the performance and life time of the device at different operation parameters such as current, voltage, frequency and temperatures. In this study we employ a new different use for the well-known boost convertor circuit, based on GaN Devices in order to stress the transistor to the maximum values of voltage and current which allows us to examine the reliability of the transistor and accelerating Hot Carrier And Trap Generation failures mechanisms. The acceleration of the failure mechanism should be done in a way that will not affect the electronic device detrimentally and on the other hand we would not need to wait a long time in order to observe the degradation. In this work we will present our new boost converter circuit based on high power GaN HEMT.",
          "authors": [
            "Moshe Azoulay",
            "Gilad Orr",
            "Gady Golan"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01705",
          "title": "Slip, Differentiate, Observe: State and Parameter Estimation for Rate and State Friction from Noisy Data",
          "abstract": "Quantifying frictional properties of interfaces remains a major challenge in both terrestrial and extraterrestrial geomechanics, where available samples, laboratory apparatuses, and geophysical observations are inherently limited. We introduce an analytic and numerical framework, grounded in nonlinear control theory, to infer the emergent frictional behavior of seismic faults. From noisy slip measurements, we first reconstruct the slip rate and frictional response in finite time using a Robust Exact Filtering Differentiator (REFD) that attenuates measurement noise. Building on these reconstructions, we design an exponentially convergent adaptive-gain observer that estimates the internal state variable and the key parameters (a - b) and dc of the rate-and-state friction (RSF) law, widely used in fault mechanics. Numerical experiments show that, in fast slip regimes where data are sufficiently rich, the method recovers RSF parameters with errors on the order of 20% and accurately tracks the RSF state variable despite noise contamination, whereas slowly varying sliding periods lack the observability required for reliable estimation. We also establish observability and identifiability conditions for the extended system, enabling the determination of additional parameters and outlining pathways for more advanced control-theoretic approaches to friction and state identification in fault systems. Although we apply the approach to a reduced spring-slider analogue, it improves on classical RSF calibration methods that depend on laboratory access to shear and normal stress. It also offers convergence guarantees and explicit error bounds, and it can further support model-based inversions that embed RSF in forward simulations.",
          "authors": [
            "David Michael Riley",
            "Diego Gutiérrez-Oribio",
            "Ioannis Stefanou"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01811",
          "title": "Numerical cohomology for arithmetic surfaces and applications",
          "abstract": "In this paper, we introduce numerical cohomology for arithmetic surfaces, which leads to an absolute version of arithmetic Riemann-Roch formula. As an application, we derive an upper bound for the self-intersection number of relative dualizing sheaf in terms of successive minima with respect to $L^2$-norm. The result has the geometric analogue that the slopes of the Harder-Narasimhan filtration of relative dualizing sheaf provide an upper bound for self-intersection number. Suppose that the arithmetic surface admits a section and has generic fiber of genus at least two, we obtain a refined upper bound for the self-intersection number, which is governed by the topological and arithmetic information of the section.",
          "authors": [
            "Wei He"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01817",
          "title": "Sharp Self-Normalized Concentration Inequalities of Marginal Mean with Sample Variance Only",
          "abstract": "(This is the first version of a working paper. A more detailed follow-up with applications is in preparation.) We develop a family of self-normalized concentration inequalities for marginal mean under martingale-difference structure and $\\phi/\\tilde{\\phi}$-mixing conditions, where the latter includes many processes that are not strongly mixing. The variance term is fully data-observable: naive sample variance in the martingale case and an empirical block long-run variance under mixing conditions. Thus, no predictable variance proxy is required. No specific assumption on the decay of the mixing coefficients (e.g. summability) is needed for the validity. The constants are explicit and the bounds are ready to use.",
          "authors": [
            "Zihao Yuan"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01817",
          "title": "Sharp Self-Normalized Concentration Inequalities of Marginal Mean with Sample Variance Only",
          "abstract": "(This is the first version of a working paper. A more detailed follow-up with applications is in preparation.) We develop a family of self-normalized concentration inequalities for marginal mean under martingale-difference structure and $\\phi/\\tilde{\\phi}$-mixing conditions, where the latter includes many processes that are not strongly mixing. The variance term is fully data-observable: naive sample variance in the martingale case and an empirical block long-run variance under mixing conditions. Thus, no predictable variance proxy is required. No specific assumption on the decay of the mixing coefficients (e.g. summability) is needed for the validity. The constants are explicit and the bounds are ready to use.",
          "authors": [
            "Zihao Yuan"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01884",
          "title": "Onsager Condensation in Chiral Active Matter: Universality of Topological Gas Dynamics",
          "abstract": "We identify a thermodynamic phase transition in chiral active matter. Low-frequency disorder triggers global synchronisation and energy dissipation, while high disorder activates a topological heat pump, generating an inverse energy cascade. This drives the system towards an Onsager dipole, which can be arrested into a metastable vortex glass if dispersion is insufficient to overcome the defect lattice. We propose topological gas dynamics as a universality class governed by the interplay of active disorder and topological sorting, unifying active swarms and classical inviscid fluids.",
          "authors": [
            "Magnus F Ivarsen"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01884",
          "title": "Onsager Condensation in Chiral Active Matter: Universality of Topological Gas Dynamics",
          "abstract": "We identify a thermodynamic phase transition in chiral active matter. Low-frequency disorder triggers global synchronisation and energy dissipation, while high disorder activates a topological heat pump, generating an inverse energy cascade. This drives the system towards an Onsager dipole, which can be arrested into a metastable vortex glass if dispersion is insufficient to overcome the defect lattice. We propose topological gas dynamics as a universality class governed by the interplay of active disorder and topological sorting, unifying active swarms and classical inviscid fluids.",
          "authors": [
            "Magnus F Ivarsen"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01959",
          "title": "Divisibility Relations and $\\mathcal{D}$-Extremal ideals",
          "abstract": "A divisibility relation between the generators of a square-free monomial ideal formally encodes the situation when one generator divides the least common multiple of some other generators. The divisibility relations contribute to the deletion of some parts of the Taylor resolution of the ideal, and therefore lead to finding a resolution closer to the minimal one. Motivated by this observation, for a given set $\\mathcal{D}$ of divisibility relations, we study all square-free monomials satisfying the relations in $\\mathcal{D}$. We define a class of square-free monomial ideals called $\\mathcal{D}$-extremal ideals $\\mathcal{E}_\\mathcal{D}$ , and show it is optimal in the sense that it is an ideal satisfying exactly those divisibility relations coming from $\\mathcal{D}$, and no others. We then show that $\\mathcal{E}_\\mathcal{D}$ is extremal in the sense that the resolution and betti numbers of the powers of any square-free monomial ideal satisfying the relations in $\\mathcal{D}$ are bounded by those of the same powers of $\\mathcal{E}_\\mathcal{D}$.",
          "authors": [
            "Susan M. Cooper",
            "Sabine El Khoury",
            "Sara Faridi",
            "Susan Morey",
            "Liana M. Şega",
            "Sandra Spiroff"
          ],
          "primary_category": "math.AC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02021",
          "title": "FCDB (Functorial-Categorical Database): A Compositional Framework for Information Preservation and Anti-Commutativity Reduction",
          "abstract": "Conventional database architectures often secure local consistency by discarding information, entangling correctness with loss. We introduce the Functorial-Categorical Database (FCDb), which models data operations as morphisms in a layered functor category and establishes a Complete Preserving Family (CPF) of projections spanning content invariance (CAS), capability, and ownership, with optional observational projections for local order (B+Tree), temporal history (append-only/LSM), and adjacency (Graph). We identify a minimal kernel (F_core = Own o Cap o CAS) that preserves information and collapses non-commutativity to the ethical grant/revoke boundary. Under adjoint lifts and a fibred structure, operational pairs commute in the categorical limit while ownership integrity and capability constraints are maintained. The framework connects to information geometry via projection interpretations and supports empirical validation without discarding semantic, temporal, or relational entropy.",
          "authors": [
            "Jun Kawasaki"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02034",
          "title": "Simulations of zero pressure-gradient turbulent boundary layers over riblets",
          "abstract": "We computationally study the response of zero-pressure-gradient (ZPG) turbulent boundary layers (TBLs) to streamwise step changes from a smooth wall to riblets (S-R), and vice versa (R-S). We consider triangular riblets with tip angle $90^o$ (T9), that increase drag, with viscous-scaled spacing $50$. A novel grid-generation approach is developed for unstructured spectral-element codes, consistent with the size of turbulent scales across the TBL. We generate a ZPG TBL upstream of the step change (with thickness $\\delta_0$) with momentum thickness Reynolds number $Re_{\\theta_0} \\simeq 680$. The TBL departure from equilibrium due to the step change, and its subsequent relaxation, recall previous studies on step changes in surface roughness. Downstream of the R-S step change, the internal equilibrium layer thickness $\\delta_{IEL}$ reaches $0.4 \\delta_0$ within $12\\delta_0$. However, downstream of the S-R step change $\\delta_{IEL}$ reaches $0.4 \\delta_0$ within $4\\delta_0$. In all cases, $\\delta_{IEL}$ does not reach the boundary layer thickness, even up to a distance of $45\\delta_0$ downstream of the step change, owing to persistent history effects within the frozen wake region.",
          "authors": [
            "Vishal Kumar",
            "Amirreza Rouhi",
            "Oriol Lehmkuhl",
            "Wen Wu",
            "Melissa Kozul",
            "Alexander J. Smits"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02035",
          "title": "Application of riblets to separating turbulent boundary layers",
          "abstract": "We conduct direct numerical simulations of separating turbulent boundary layers (TBLs) over triangular riblets with tip angles $90^o$ (T9) and $60^o$ (T6). Our setup follows the separating TBL study of Wu et al.\\ ({\\it J. Fluid Mech.}, vol.\\ 883, 2020, p.\\ A45). An equilibrium zero pressure-gradient (ZPG) TBL is generated at a reference location, followed by imposition of a Gaussian suction profile to create a separation bubble. The ZPG TBLs over the riblets and the benchmark smooth case have matched momentum thickness Reynolds number $Re_{\\theta_0} = 583$ (friction Reynolds number 224). We employ a well-validated spectral-element solver, and leverage its unstructured-grid nature to generate an optimal grid, based on the size of turbulent scales across the TBL. At the reference location, the T9 and T6 riblets respectively increase and reduce drag, with viscous-scaled spacings $52$ and $13$. We discover that for both riblet cases, the mean separation location occurs at a distance of $140\\theta_0$ downstream of the reference location, $18\\%$ shorter than the mean separation distance for the smooth case ($170\\theta_0$). This outcome is related to the progressive enhancement of the Kelvin-Helmholtz (KH) rollers over the riblets, owing to the continuous rise in the adverse pressure-gradient. The KH rollers penetrate into the turbulent separation bubble, with significantly larger size and coherence compared to their counterparts upstream of the mean separation location.",
          "authors": [
            "Amirreza Rouhi",
            "Vishal Kumar",
            "Oriol Lehmkuhl",
            "Wen Wu",
            "Melissa Kozul",
            "Alexander J. Smits"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02039",
          "title": "Local-Order-Invariant Logic on Classes of Bounded Degree",
          "abstract": "Local-order-invariant (first-order) logic is an extension of first-order logic where formulae have access to a ternary local order relation on the Gaifman graph, provided that the truth value does not depend on the specific order relation chosen. Weinstein asked a number of questions about the expressive power of order-invariant and local-order-invariant logics on classes of finite structures of bounded degree, classes of finite structures in general, and classes of locally finite structures. We answer four of his five questions, including showing that local-order-invariant logic collapses to first-order logic on classes of bounded degree. We also investigate epsilon-invariant logic. We show that epsilon-invariant logic collapses to first-order logic on classes of bounded degree by containing it in local-order-invariant logic in this setting, and we give an upper bound for epsilon-invariant logic in terms of local-order-invariant logic on general finite structures. Finally, in the process of proving these theorems, we demonstrate some principles which suggest further directions for showing upper bounds on invariant logics, including an upper bound on epsilon-invariant logic in general.",
          "authors": [
            "Derek Aoki"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02039",
          "title": "Local-Order-Invariant Logic on Classes of Bounded Degree",
          "abstract": "Local-order-invariant (first-order) logic is an extension of first-order logic where formulae have access to a ternary local order relation on the Gaifman graph, provided that the truth value does not depend on the specific order relation chosen. Weinstein asked a number of questions about the expressive power of order-invariant and local-order-invariant logics on classes of finite structures of bounded degree, classes of finite structures in general, and classes of locally finite structures. We answer four of his five questions, including showing that local-order-invariant logic collapses to first-order logic on classes of bounded degree. We also investigate epsilon-invariant logic. We show that epsilon-invariant logic collapses to first-order logic on classes of bounded degree by containing it in local-order-invariant logic in this setting, and we give an upper bound for epsilon-invariant logic in terms of local-order-invariant logic on general finite structures. Finally, in the process of proving these theorems, we demonstrate some principles which suggest further directions for showing upper bounds on invariant logics, including an upper bound on epsilon-invariant logic in general.",
          "authors": [
            "Derek Aoki"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02040",
          "title": "On the existence of entire solutions to a system of nonlinear Fermat-type partial differential-difference equations",
          "abstract": "The aim of this study is to investigate the precise form of finite-order entire solutions to the following system of Fermat-type partial differential-difference equations: \\beas \\begin{cases} \\left(\\frac{\\partial f_1\\left(z_1, z_2, \\ldots, z_m \\right)}{\\partial z_1}\\right)^{n_1} + f_2^{m_1} \\left(z_1 + c_1, z_2 + c_2, \\ldots, z_m + c_m \\right) = 1,\\\\ \\left(\\frac{\\partial f_2\\left(z_1, z_2, \\ldots, z_m \\right)}{\\partial z_1}\\right)^{n_2} + f_1^{m_2} \\left(z_1 + c_1, z_2 + c_2, \\ldots, z_m + c_m \\right) = 1 \\end{cases} \\eeas for various combinations of the positive integers $n_1$, $n_2$, $m_1$ and $m_2$. Our results extend the work of Xu et al. (Entire solutions for several systems of non-linear difference and partial differential-difference equations of Fermat-type, J. Math. Anal. Appl., 483(2), 2020), generalizing the setting $\\mathbb{C}^2$ to $\\mathbb{C}^m$. Several examples are provided to illustrate the applicability and sharpness of the obtained results.",
          "authors": [
            "Junfeng Xu",
            "Sujoy Majumder",
            "Debabrata Pramanik"
          ],
          "primary_category": "math.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02041",
          "title": "Logic of Sets with Atoms",
          "abstract": "Orbit-finite models of computation generalise the standard models of computation, to allow computation over infinite objects that are finite up to symmetries on atoms, denoted by $\\mathbb{A}$. Set theory with atoms is used to reason about these objects. Recent work assumes that $\\mathbb{A}$ is countable and that the symmetries are the automorphisms of a structure on $\\mathbb{A}$. We study this set theory to understand generalisations of this approach. We show that: this construction is well-defined and sufficiently expressive; and that automorphism groups are adequate. Certain uncountable structures appear similar to countable structures, suggesting that the theory of orbit-finite constructions may apply to these uncountable structures. We prove results guaranteeing that the theory of symmetries of two structures are equal. Let: $PM(\\mathcal{A})$ be the universe of symmetries induced by adding atoms in bijection with $\\mathcal{A}$ and considering the symmetric universe; $\\underline{\\mathcal{A}}$ be the image of $\\mathcal{A}$ on the atoms; and $\\phi ^{PM(\\mathcal{A})}$ be the relativisation of $\\phi$ to $PM(\\mathcal{A})$. We prove that all symmetric universes of equality atoms have theory $Th(PM(\\left\\langle \\mathbb{N}\\right\\rangle))$. We prove that for structures $\\mathcal{A}$, `nicely' covered by a set of cardinality $\\kappa$, there is a structure $\\mathcal{B}\\equiv\\mathcal{A}$ of size $\\kappa$ such that for all formulae $\\phi(x)$ in one variable, \\begin{equation*} ZFC\\vdash \\phi(\\underline{\\mathcal{A}})^{PM(\\mathcal{A})}\\leftrightarrow\\phi(\\underline{\\mathcal{B}})^{PM(\\mathcal{B})} \\end{equation*}",
          "authors": [
            "Jake Masters"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02041",
          "title": "Logic of Sets with Atoms",
          "abstract": "Orbit-finite models of computation generalise the standard models of computation, to allow computation over infinite objects that are finite up to symmetries on atoms, denoted by $\\mathbb{A}$. Set theory with atoms is used to reason about these objects. Recent work assumes that $\\mathbb{A}$ is countable and that the symmetries are the automorphisms of a structure on $\\mathbb{A}$. We study this set theory to understand generalisations of this approach. We show that: this construction is well-defined and sufficiently expressive; and that automorphism groups are adequate. Certain uncountable structures appear similar to countable structures, suggesting that the theory of orbit-finite constructions may apply to these uncountable structures. We prove results guaranteeing that the theory of symmetries of two structures are equal. Let: $PM(\\mathcal{A})$ be the universe of symmetries induced by adding atoms in bijection with $\\mathcal{A}$ and considering the symmetric universe; $\\underline{\\mathcal{A}}$ be the image of $\\mathcal{A}$ on the atoms; and $\\phi ^{PM(\\mathcal{A})}$ be the relativisation of $\\phi$ to $PM(\\mathcal{A})$. We prove that all symmetric universes of equality atoms have theory $Th(PM(\\left\\langle \\mathbb{N}\\right\\rangle))$. We prove that for structures $\\mathcal{A}$, `nicely' covered by a set of cardinality $\\kappa$, there is a structure $\\mathcal{B}\\equiv\\mathcal{A}$ of size $\\kappa$ such that for all formulae $\\phi(x)$ in one variable, \\begin{equation*} ZFC\\vdash \\phi(\\underline{\\mathcal{A}})^{PM(\\mathcal{A})}\\leftrightarrow\\phi(\\underline{\\mathcal{B}})^{PM(\\mathcal{B})} \\end{equation*}",
          "authors": [
            "Jake Masters"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02042",
          "title": "Solutions of certain Fermat-type partial differential-difference equations",
          "abstract": "The purpose of this paper is to investigate the non-constant entire as well as meromorphic solutions of the Fermat-type partial differential-difference equation: \\[\\left(\\sum_{j=1}^m\\frac{\\partial f(z_1, z_2, \\ldots, z_m)}{\\partial z_j}\\right)^{m_1} + f^{m_2}(z_1 + c_1, z_2 + c_2, \\ldots, z_m + c_m ) = 1,\\] where $m_1$ and $m_2$ are positive integers such that $m_1+m_2>2$ and $(c_1, c_2, \\ldots, c_m)\\in \\mathbb{C}^m$. The results of our paper generalize the result of Xu and Wang \\cite {XW1} from $\\mathbb{C}^2$ to $\\mathbb{C}^m$. Also in the paper we give positive answer of the open problem addressed by Xu and Wang \\cite {XW1}. Moreover plenty of examples are provided to illustrate our findings.",
          "authors": [
            "Sujoy Majumder",
            "Debabrata Pramanik"
          ],
          "primary_category": "math.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02052",
          "title": "From Poincare Invariance to Gauge Theories: Yang-Mills and General Relativity",
          "abstract": "This article is founded on two fundamental principles: the principle field equations introduced in Refs. \\cite{S, S1, S2} and the Fock-Ivanenko covariant derivatives \\cite{FI, F}. The former yields the equations of motion for free fields of arbitrary spin and helicity. In the massless case, it also dictates that Lorentz transformations for tensor fields acquire an additional term, which takes the form of a gauge transformation \\cite{W, S1}. The latter principle, the Fock-Ivanenko derivative, introduces interactions based on the intrinsic and Poincaré groups. This framework allows us to recover a complete Yang-Mills theory, as well as general relativity in the connection-based formulations of Palatini and Ashtekar, both of which are theories with local gauge symmetries. While the standard approach begins with the symmetries of a matter action, we will instead derive dynamics directly from Poincaré invariance. This perspective reveals that for free fields, Lorentz invariance induces the gauge symmetry of massless tensors. A proper definition of these gauge transformations, in turn, requires the covariant derivatives provided by the Fock-Ivanenko approach. Considering matter fields, we derive the interacting Dirac equation in the presence of Yang-Mills and gravitational fields from its free counterpart.",
          "authors": [
            "Branislav Sazdovic"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02059",
          "title": "Emergent Grand Unified Structure in a 4 x 4 Nilpotent Matrix Algebra",
          "abstract": "We show that nilpotent matrices that yield the Schrodinger equation from its first order form encode the fingerprints of grand unified theories. We perform a rigorous search for all such nilpotent matrices and find that the resulting matrices naturally organize into suggestive group theoretic structures without any other a priori assumptions. The antisymmetric sector consists of three groups of sixteen matrices, each of which further splits as 16 = 12 + 4 and exhibits unique characteristics in the step potential scattering problem. The symmetric zero-diagonal sector also forms three families, mirroring the quark-lepton decomposition of the Pati-Salam model. These results may help answer why there are three families of fermions and also demonstrate that the 4 x 4 matrix algebra is a compact, nontrivial shadow of the SO(10) embedding, with fermion-like and gauge-like subspaces.",
          "authors": [
            "M. Adeel Ajaib"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02063",
          "title": "Dispersion Outperforms Absorption: EIT-Enhanced Atomic Localization and Gradient Sensing with Super-Gaussian Beams",
          "abstract": "This work presents a comprehensive theoretical comparison between absorption-based and electromagnetically induced transparency (EIT)-based atomic gradient sensing in a four-level tripod system. Both methods were evaluated under identical and optimized physical conditions to ensure a fair and unbiased comparison. The analysis demonstrates that EIT, driven by its steep dispersion response, consistently outperforms conventional absorption detection across a wide range of super-Gaussian beam profiles. Under optimal detuning, EIT achieved up to an order-of-magnitude enhancement in gradient sensitivity and maintained a twofold advantage even under identical detuning. Both approaches reached sub-diffraction spatial resolution in the range of 0.29lambda-0.40lambda, with EIT exhibiting sharper edge contrast and higher localization accuracy. These results confirm EIT as a fundamentally superior approach for precision atomic gradient sensing and sub-wavelength localization, offering clear guidance for the design of next-generation optical and quantum metrology systems.",
          "authors": [
            "Mahboob Ul Haq"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02065",
          "title": "Quantum Machine Learning for Secondary Frequency Control",
          "abstract": "Frequency control in power systems is critical to maintaining stability and preventing blackouts. Traditional methods like meta-heuristic algorithms and machine learning face limitations in real-time applicability and scalability. This paper introduces a novel approach using a pure variational quantum circuit (VQC) for real-time secondary frequency control in diesel generators. Unlike hybrid classical-quantum models, the proposed VQC operates independently during execution, eliminating latency from classical-quantum data exchange. The VQC is trained via supervised learning to map historical frequency deviations to optimal Proportional-Integral (PI) controller parameters using a pre-computed lookup table. Simulations demonstrate that the VQC achieves high prediction accuracy (over 90%) with sufficient quantum measurement shots and generalizes well across diverse test events. The quantum-optimized PI parameters significantly improve transient response, reducing frequency fluctuations and settling time.",
          "authors": [
            "Younes Ghazagh Jahed",
            "Alireza Khatiri"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02065",
          "title": "Quantum Machine Learning for Secondary Frequency Control",
          "abstract": "Frequency control in power systems is critical to maintaining stability and preventing blackouts. Traditional methods like meta-heuristic algorithms and machine learning face limitations in real-time applicability and scalability. This paper introduces a novel approach using a pure variational quantum circuit (VQC) for real-time secondary frequency control in diesel generators. Unlike hybrid classical-quantum models, the proposed VQC operates independently during execution, eliminating latency from classical-quantum data exchange. The VQC is trained via supervised learning to map historical frequency deviations to optimal Proportional-Integral (PI) controller parameters using a pre-computed lookup table. Simulations demonstrate that the VQC achieves high prediction accuracy (over 90%) with sufficient quantum measurement shots and generalizes well across diverse test events. The quantum-optimized PI parameters significantly improve transient response, reducing frequency fluctuations and settling time.",
          "authors": [
            "Younes Ghazagh Jahed",
            "Alireza Khatiri"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02066",
          "title": "Parallel Multi-Circuit Quantum Feature Fusion in Hybrid Quantum-Classical Convolutional Neural Networks for Breast Tumor Classification",
          "abstract": "Quantum machine learning has emerged as a promising approach to improve feature extraction and classification tasks in high-dimensional data domains such as medical imaging. In this work, we present a hybrid Quantum-Classical Convolutional Neural Network (QCNN) architecture designed for the binary classification of the BreastMNIST dataset, a standardized benchmark for distinguishing between benign and malignant breast tumors. Our architecture integrates classical convolutional feature extraction with two distinct quantum circuits: an amplitude-encoding variational quantum circuit (VQC) and an angle-encoding VQC circuit with circular entanglement, both implemented on four qubits. These circuits generate quantum feature embeddings that are fused with classical features to form a joint feature space, which is subsequently processed by a fully connected classifier. To ensure fairness, the hybrid QCNN is parameter-matched against a baseline classical CNN, allowing us to isolate the contribution of quantum layers. Both models are trained under identical conditions using the Adam optimizer and binary cross-entropy loss. Experimental evaluation in five independent runs demonstrates that the hybrid QCNN achieves statistically significant improvements in classification accuracy compared to the classical CNN, as validated by a one-sided Wilcoxon signed rank test (p = 0.03125) and supported by large effect size of Cohen's d = 2.14. Our results indicate that hybrid QCNN architectures can leverage entanglement and quantum feature fusion to enhance medical image classification tasks. This work establishes a statistical validation framework for assessing hybrid quantum models in biomedical applications and highlights pathways for scaling to larger datasets and deployment on near-term quantum hardware.",
          "authors": [
            "Ece Yurtseven"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02066",
          "title": "Parallel Multi-Circuit Quantum Feature Fusion in Hybrid Quantum-Classical Convolutional Neural Networks for Breast Tumor Classification",
          "abstract": "Quantum machine learning has emerged as a promising approach to improve feature extraction and classification tasks in high-dimensional data domains such as medical imaging. In this work, we present a hybrid Quantum-Classical Convolutional Neural Network (QCNN) architecture designed for the binary classification of the BreastMNIST dataset, a standardized benchmark for distinguishing between benign and malignant breast tumors. Our architecture integrates classical convolutional feature extraction with two distinct quantum circuits: an amplitude-encoding variational quantum circuit (VQC) and an angle-encoding VQC circuit with circular entanglement, both implemented on four qubits. These circuits generate quantum feature embeddings that are fused with classical features to form a joint feature space, which is subsequently processed by a fully connected classifier. To ensure fairness, the hybrid QCNN is parameter-matched against a baseline classical CNN, allowing us to isolate the contribution of quantum layers. Both models are trained under identical conditions using the Adam optimizer and binary cross-entropy loss. Experimental evaluation in five independent runs demonstrates that the hybrid QCNN achieves statistically significant improvements in classification accuracy compared to the classical CNN, as validated by a one-sided Wilcoxon signed rank test (p = 0.03125) and supported by large effect size of Cohen's d = 2.14. Our results indicate that hybrid QCNN architectures can leverage entanglement and quantum feature fusion to enhance medical image classification tasks. This work establishes a statistical validation framework for assessing hybrid quantum models in biomedical applications and highlights pathways for scaling to larger datasets and deployment on near-term quantum hardware.",
          "authors": [
            "Ece Yurtseven"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02066",
          "title": "Parallel Multi-Circuit Quantum Feature Fusion in Hybrid Quantum-Classical Convolutional Neural Networks for Breast Tumor Classification",
          "abstract": "Quantum machine learning has emerged as a promising approach to improve feature extraction and classification tasks in high-dimensional data domains such as medical imaging. In this work, we present a hybrid Quantum-Classical Convolutional Neural Network (QCNN) architecture designed for the binary classification of the BreastMNIST dataset, a standardized benchmark for distinguishing between benign and malignant breast tumors. Our architecture integrates classical convolutional feature extraction with two distinct quantum circuits: an amplitude-encoding variational quantum circuit (VQC) and an angle-encoding VQC circuit with circular entanglement, both implemented on four qubits. These circuits generate quantum feature embeddings that are fused with classical features to form a joint feature space, which is subsequently processed by a fully connected classifier. To ensure fairness, the hybrid QCNN is parameter-matched against a baseline classical CNN, allowing us to isolate the contribution of quantum layers. Both models are trained under identical conditions using the Adam optimizer and binary cross-entropy loss. Experimental evaluation in five independent runs demonstrates that the hybrid QCNN achieves statistically significant improvements in classification accuracy compared to the classical CNN, as validated by a one-sided Wilcoxon signed rank test (p = 0.03125) and supported by large effect size of Cohen's d = 2.14. Our results indicate that hybrid QCNN architectures can leverage entanglement and quantum feature fusion to enhance medical image classification tasks. This work establishes a statistical validation framework for assessing hybrid quantum models in biomedical applications and highlights pathways for scaling to larger datasets and deployment on near-term quantum hardware.",
          "authors": [
            "Ece Yurtseven"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02071",
          "title": "Numerical Solution to the Riemann Problem for a Liquid-Gas Two-phase Isentropic Flow Model",
          "abstract": "A recently introduced two-phase flow model by Chun Shen is studied in this work. The model is derived to describe the dynamics of immersed water bubbles in liquid water as carrier. Several assumptions are made to obtain a reduced form of the mathematical model. The established model consists of nonlinear coupled PDEs in which the unknowns are the densities of the liquid and gas phases and the velocity of the liquid phase; these depend on space and time. For numerical purposes a one-dimensional space--time coordinate system $(x,t)$ is considered. Using the Python programming framework, several Riemann-type initial value problems for the two-phase flow model are solved numerically. A comparison of three finite-difference schemes is presented in order to examine their performance: the Lax--Friedrichs scheme, the Lax--Wendroff scheme, and the FORCE scheme. The FORCE scheme is total-variation diminishing (TVD) and monotone and does not create oscillations. As expected, the numerical solution of the Riemann problems consists of combinations of smooth profiles, shock waves, and rarefaction waves.",
          "authors": [
            "Abdul Rab"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02078",
          "title": "Geometric Optimization on Lie Groups: A Lie-Theoretic Explanation of Barren Plateau Mitigation for Variational Quantum Algorithms",
          "abstract": "Barren plateaus, which means the training gradients become extremely small, pose a major challenge in optimizing parameterized quantum circuits, often making the learning process impractically slow or stall. This work shows why using neural networks to generate quantum circuit parameters helps overcome this difficulty. We introduce a geometric viewpoint that describes how the parameters produced by neural networks evolve during training. Our analysis shows that these parameters follow smooth and efficient paths that avoid the flat regions in the training that cause barren plateaus. This provides a computational explanation for the improved trainability observed in recent neural network-assisted quantum learning methods. Overall, our findings bridge ideas from quantum machine learning and computational optimization, offering new insight into the structure of quantum models and guiding future approaches for designing more trainable quantum circuits or parameter initialization.",
          "authors": [
            "Zhehao Yi",
            "Rahul Bhadani"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02081",
          "title": "From Betti Numbers to Persistence Diagrams: A Hybrid Quantum Algorithm for Topological Data Analysis",
          "abstract": "Persistence diagrams serve as a core tool in topological data analysis, playing a crucial role in pathological monitoring, drug discovery, and materials design. However, existing quantum topological algorithms, such as the LGZ algorithm, can only efficiently compute summary statistics like Betti numbers, failing to provide persistence diagram information that tracks the lifecycle of individual topological features, severely limiting their practical value. This paper proposes a novel quantum-classical hybrid algorithm that achieves, for the first time, the leap from \"quantum computation of Betti numbers\" to \"quantum acquisition of practical persistence diagrams.\" The algorithm leverages the LGZ quantum algorithm as an efficient feature extractor, mining the harmonic form eigenvectors of the combinatorial Laplacian as well as Betti numbers, constructing specialized topological kernel functions to train a quantum support vector machine (QSVM), and learning the mapping from quantum topological features to persistence diagrams. The core contributions of this algorithm are: (1) elevating quantum topological computation from statistical summaries to pattern recognition, greatly expanding its application value; (2) obtaining more practical topological information in the form of persistence diagrams for real-world applications while maintaining the exponential speedup advantage of quantum computation; (3) proposing a novel hybrid paradigm of \"classical precision guiding quantum efficiency.\" This method provides a feasible pathway for the practical implementation of quantum topological data analysis.",
          "authors": [
            "Dong Liu"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02081",
          "title": "From Betti Numbers to Persistence Diagrams: A Hybrid Quantum Algorithm for Topological Data Analysis",
          "abstract": "Persistence diagrams serve as a core tool in topological data analysis, playing a crucial role in pathological monitoring, drug discovery, and materials design. However, existing quantum topological algorithms, such as the LGZ algorithm, can only efficiently compute summary statistics like Betti numbers, failing to provide persistence diagram information that tracks the lifecycle of individual topological features, severely limiting their practical value. This paper proposes a novel quantum-classical hybrid algorithm that achieves, for the first time, the leap from \"quantum computation of Betti numbers\" to \"quantum acquisition of practical persistence diagrams.\" The algorithm leverages the LGZ quantum algorithm as an efficient feature extractor, mining the harmonic form eigenvectors of the combinatorial Laplacian as well as Betti numbers, constructing specialized topological kernel functions to train a quantum support vector machine (QSVM), and learning the mapping from quantum topological features to persistence diagrams. The core contributions of this algorithm are: (1) elevating quantum topological computation from statistical summaries to pattern recognition, greatly expanding its application value; (2) obtaining more practical topological information in the form of persistence diagrams for real-world applications while maintaining the exponential speedup advantage of quantum computation; (3) proposing a novel hybrid paradigm of \"classical precision guiding quantum efficiency.\" This method provides a feasible pathway for the practical implementation of quantum topological data analysis.",
          "authors": [
            "Dong Liu"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02083",
          "title": "On the Complexity of Signed Roman Domination",
          "abstract": "Given a graph $G = (V, E)$, a signed Roman dominating function is a function $f: V \\rightarrow \\{-1, 1, 2\\}$ such that for every vertex $u \\in V$: $\\sum_{v \\in N[u]} f(v) \\geq 1$ and for every vertex $u \\in V$ with $f(u) = -1$, there exists a vertex $v \\in N(u)$ with $f(v) = 2$. The weight of a signed Roman dominating function $f$ is $\\sum_{u \\in V} f(u)$. The objective of \\srd{} (SRD) problem is to compute a signed Roman dominating function with minimum weight. The problem is known to be NP-complete even when restricted to bipartite graphs and planar graphs. In this paper, we advance the complexity study by showing that the problem remains NP-complete on split graphs. In the realm of parameterized complexity, we prove that the problem is W[2]-hard parameterized by weight, even on bipartite graphs. We further show that the problem is W[1]-hard parameterized by feedback vertex set number (and hence also when parameterized by treewidth or clique-width). On the positive side, we present an FPT algorithm parameterized by neighbourhood diversity (and by vertex cover number). Finally, we complement this result by proving that the problem does not admit a polynomial kernel parameterized by vertex cover number unless coNP $\\subseteq$ NP/poly.",
          "authors": [
            "Sangam Balchandar Reddy"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02084",
          "title": "Modifications in clusterization procedures for heavy-ion collisions: minimum spanning tree, simulated annealing, coalescence",
          "abstract": "A new open-source cluster finding library ''Common Clusterization Library'' (CCL) is proposed to describe the clusters production when applied to the transport codes. The new library was applied to the Parton-Hadron-Quantum-Molecular Dynamics approach to be comparable with the established and well known MST and SACA implementations on the exactly same set of the events. The presented procedures were tested with rapidity density distributions and complex observables like $\\langle M_{imf} \\rangle$ and $\\langle Z_{\\text{max}} \\rangle$ vs $Z_{bound}2$ at the energies of ALADiN and NA49 experiments. An improvement to the simulated annealing chain is proposed to reduce the computational time. The new stable clusters tracking algorithm for the ''lost'' cluster recovering is presented. The results of the ''box-like'' coalescence procedure and a mixed method which incorporates the coalescence algorithm steps and the negative binding energy criteria are presented. The difference between the Helium-3 found by the MST-based cluster finding procedure and the coalescence algorithm applied on the exactly same set of events and baryons is shown for the first time.",
          "authors": [
            "Viktar Kireyeu"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02084",
          "title": "Modifications in clusterization procedures for heavy-ion collisions: minimum spanning tree, simulated annealing, coalescence",
          "abstract": "A new open-source cluster finding library ''Common Clusterization Library'' (CCL) is proposed to describe the clusters production when applied to the transport codes. The new library was applied to the Parton-Hadron-Quantum-Molecular Dynamics approach to be comparable with the established and well known MST and SACA implementations on the exactly same set of the events. The presented procedures were tested with rapidity density distributions and complex observables like $\\langle M_{imf} \\rangle$ and $\\langle Z_{\\text{max}} \\rangle$ vs $Z_{bound}2$ at the energies of ALADiN and NA49 experiments. An improvement to the simulated annealing chain is proposed to reduce the computational time. The new stable clusters tracking algorithm for the ''lost'' cluster recovering is presented. The results of the ''box-like'' coalescence procedure and a mixed method which incorporates the coalescence algorithm steps and the negative binding energy criteria are presented. The difference between the Helium-3 found by the MST-based cluster finding procedure and the coalescence algorithm applied on the exactly same set of events and baryons is shown for the first time.",
          "authors": [
            "Viktar Kireyeu"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02085",
          "title": "Effect of the avoided crossing on the rovibrational energy levels, resonances, and predissociation lifetimes within the ground and first excited electronic states of lithium fluoride",
          "abstract": "We investigate the LiF spectrum up to $7800$ cm$^{-1}$ above the first dissociation limit. The ab initio calculations of the adiabatic potentials and other molecular functions are performed in a wide range of interatomic separations, $r=1$-17 bohr. We consider the model of two interacting electronic states including both the bound states and the resonances of two kinds, the tunneling resonances and the predissociative ones. The Born-Oppenheimer potentials are modeled with use of two functions imitating the diabatic terms whereas the coupling between them was set constant equal to the half of the minimum separation between the adiabatic terms, and then we define the final diabatic terms and the final diabatic coupling via the adiabatic potentials and the angle of the adiabatic-to-diabatic basis rotation obtained by integration of the nonadiabatic coupling matrix element. The energies of the bound states, as well as the positions and widths of the resonances are calculated. The observed transition frequencies are reproduced with the standard deviation of 0.0009 cm$^{-1}$ for $^7$LiF, 0.0006 cm$^{-1}$ for $^6$LiF, and within the experimental uncertainties for the most of the lines. The line lists for the bound-bound $X$-$X$ rovibrational transitions are calculated for quantum numbers $v\\le50,\\Delta v\\le15,J\\le170$ ($J\\le200$ for the 0-0 and 1-0 bands).",
          "authors": [
            "V. G. Ushakov",
            "A. Yu. Ermilov",
            "E. S. Medvedev"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02085",
          "title": "Effect of the avoided crossing on the rovibrational energy levels, resonances, and predissociation lifetimes within the ground and first excited electronic states of lithium fluoride",
          "abstract": "We investigate the LiF spectrum up to $7800$ cm$^{-1}$ above the first dissociation limit. The ab initio calculations of the adiabatic potentials and other molecular functions are performed in a wide range of interatomic separations, $r=1$-17 bohr. We consider the model of two interacting electronic states including both the bound states and the resonances of two kinds, the tunneling resonances and the predissociative ones. The Born-Oppenheimer potentials are modeled with use of two functions imitating the diabatic terms whereas the coupling between them was set constant equal to the half of the minimum separation between the adiabatic terms, and then we define the final diabatic terms and the final diabatic coupling via the adiabatic potentials and the angle of the adiabatic-to-diabatic basis rotation obtained by integration of the nonadiabatic coupling matrix element. The energies of the bound states, as well as the positions and widths of the resonances are calculated. The observed transition frequencies are reproduced with the standard deviation of 0.0009 cm$^{-1}$ for $^7$LiF, 0.0006 cm$^{-1}$ for $^6$LiF, and within the experimental uncertainties for the most of the lines. The line lists for the bound-bound $X$-$X$ rovibrational transitions are calculated for quantum numbers $v\\le50,\\Delta v\\le15,J\\le170$ ($J\\le200$ for the 0-0 and 1-0 bands).",
          "authors": [
            "V. G. Ushakov",
            "A. Yu. Ermilov",
            "E. S. Medvedev"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02086",
          "title": "Disentangling Brillouin's negentropy law of information and Landauer's law on data erasure",
          "abstract": "The link between information and energy introduces the observer and his knowledge into the understanding of a fundamental quantity of physics. Two approaches compete to account for this link, Brillouin's negentropy law of information and Landauer's law on data erasure, which are often confused. The first, based on the Clausius' inequality and Shannon's mathematical results is very robust, while the second, based on the simple idea that information needs a material embodiment (data-bits) is today perceived as more physical and prevails. In this paper, we show that Landauer's idea results from a confusion between information (a global emergent concept) and data (a local material object). This confusion leads to many inconsistencies and is incompatible with thermodynamics and information theory. The reason it prevails is interpreted to be due to a frequent tendency of materialism towards reductionism, neglecting emergence and seeking to eliminate the role of the observer. A paradoxical trend given that it is often accompanied by the materialist idea that all scientific knowledge nevertheless originates from observation. Information and entropy are actually emergent quantities introduced in the theory by convention.",
          "authors": [
            "Didier Lairez"
          ],
          "primary_category": "physics.gen-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02087",
          "title": "A survey about Hidden Subgroup Problem from a mathematical and cryptographic perspective",
          "abstract": "We provide a survey on the Hidden Subgroup Problem (HSP), which plays an important role in studying the security of public-key cryptosystems. We first review the abelian case, where Kitaev's algorithm yields an efficient quantum solution to the HSP, recalling how classical problems (such as order finding, integer factorization, and discrete logarithm) can be formulated as abelian HSP instances. We then examine the current state of the art for non-abelian HSP, where no general efficient quantum solution is known, focusing on some relevant groups including dihedral group (connected to the shortest vector problem), symmetric groups (connected to the graph isomorphism problem), and semidirect product constructions (connected, in a special case, to the code equivalence problem). We also describe the main techniques for addressing the HSP in non-abelian cases, namely Fourier sampling and the black-box approach. Throughout the paper, we highlight the mathematical notions required and exploited in this context, providing a cryptography-oriented perspective.",
          "authors": [
            "Simone Dutto",
            "Pietro Mercuri",
            "Nadir Murru",
            "Lorenzo Romano"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02098",
          "title": "Baby Universes in AdS$_3$",
          "abstract": "We discuss Euclidean geometries in AdS$_3$ whose Lorentzian slicing gives rise to closed baby universes with a spatial geometry given by genus $g\\geq 2$ surfaces. Our setup only involves a two-dimensional holographic CFT defined on a higher genus Riemann surface and thus provides a well-posed alternative to shell states whose microscopic duals are less well understood. We find that geometries giving rise to baby universes are always subdominant. It follows that the baby universe does not provide a semi-classical description of the state since it is encoded in an exponentially suppressed part of the wave function. We then apply a prescription developed in \\cite{Belin:2025wju} to make the baby universe geometry the leading saddle. In the process, the CFT state becomes mixed, in agreement with the qualitative gravitational picture. We show that the fluctuations in the baby universe are small, even at fixed central charge, making the geometry reliable in the semi-classical limit. Finally, we discuss the interpretation of this mixed state in pure gravity from the perspective of the Virasoro TQFT.",
          "authors": [
            "Alexandre Belin",
            "Jan de Boer"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02098",
          "title": "Baby Universes in AdS$_3$",
          "abstract": "We discuss Euclidean geometries in AdS$_3$ whose Lorentzian slicing gives rise to closed baby universes with a spatial geometry given by genus $g\\geq 2$ surfaces. Our setup only involves a two-dimensional holographic CFT defined on a higher genus Riemann surface and thus provides a well-posed alternative to shell states whose microscopic duals are less well understood. We find that geometries giving rise to baby universes are always subdominant. It follows that the baby universe does not provide a semi-classical description of the state since it is encoded in an exponentially suppressed part of the wave function. We then apply a prescription developed in \\cite{Belin:2025wju} to make the baby universe geometry the leading saddle. In the process, the CFT state becomes mixed, in agreement with the qualitative gravitational picture. We show that the fluctuations in the baby universe are small, even at fixed central charge, making the geometry reliable in the semi-classical limit. Finally, we discuss the interpretation of this mixed state in pure gravity from the perspective of the Virasoro TQFT.",
          "authors": [
            "Alexandre Belin",
            "Jan de Boer"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02100",
          "title": "The measurement-induced phase transition in strongly disordered spin chains",
          "abstract": "We investigate the dynamics of strongly disordered spin chains in the presence of random local measurements. By studying the transverse-field Ising model with a site-dependent random longitudinal field and an effective $l$-bit many-body localized Hamiltonian, we show that the prethermal and MBL regimes are unstable to local measurements along any direction. Any non-zero measurement density induces a volume-law entangled phase with a subsequent phase transition into an area-law state as the measurement rate is further increased. The critical measurement rate $p_c$, where the transition occurs, is exponentially small in the strength of disorder $W$ and the average overlap between the measurement operator and the local integrals of motion $O$ as $p_c \\sim \\exp[-\\alpha W/(1-O^2)]$. In the measurement-induced volume-law phase, the saturation time scales as $t_s \\sim L $, contrasting the exponentially slow saturation $t_s \\sim e^{aL}$ in the prethermal and MBL regimes at $p = 0$.",
          "authors": [
            "Yicheng Tang",
            "Pradip Kattel",
            "Arijeet Pal",
            "Emil A. Yuzbashyan",
            "J. H. Pixley"
          ],
          "primary_category": "cond-mat.dis-nn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02100",
          "title": "The measurement-induced phase transition in strongly disordered spin chains",
          "abstract": "We investigate the dynamics of strongly disordered spin chains in the presence of random local measurements. By studying the transverse-field Ising model with a site-dependent random longitudinal field and an effective $l$-bit many-body localized Hamiltonian, we show that the prethermal and MBL regimes are unstable to local measurements along any direction. Any non-zero measurement density induces a volume-law entangled phase with a subsequent phase transition into an area-law state as the measurement rate is further increased. The critical measurement rate $p_c$, where the transition occurs, is exponentially small in the strength of disorder $W$ and the average overlap between the measurement operator and the local integrals of motion $O$ as $p_c \\sim \\exp[-\\alpha W/(1-O^2)]$. In the measurement-induced volume-law phase, the saturation time scales as $t_s \\sim L $, contrasting the exponentially slow saturation $t_s \\sim e^{aL}$ in the prethermal and MBL regimes at $p = 0$.",
          "authors": [
            "Yicheng Tang",
            "Pradip Kattel",
            "Arijeet Pal",
            "Emil A. Yuzbashyan",
            "J. H. Pixley"
          ],
          "primary_category": "cond-mat.dis-nn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02102",
          "title": "Generalized Schur limit, modular differential equations and quantum monodromy traces",
          "abstract": "We explore some aspects of the generalized Schur limit, defined in arXiv:2506.13764 . Based on several examples, we conjecture that the generalized Schur limit as a function of $\\alpha$ solves a modular linear differential equation of fixed order, with coefficients depending on $\\alpha$. We also observe in examples that for Argyres-Douglas theories of type $(A_1,G)$ with $G=A_n,D_n$, the generalized Schur limit for certain negative integer values of $\\alpha$, coincides with the trace of higher powers of the quantum monodromy operator. This hints at a more general correspondence between the wall-crossing invariant traces on the Coulomb branch and the generalized Schur limit, which is related to the Higgs branch.",
          "authors": [
            "Anirudh Deb"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02102",
          "title": "Generalized Schur limit, modular differential equations and quantum monodromy traces",
          "abstract": "We explore some aspects of the generalized Schur limit, defined in arXiv:2506.13764 . Based on several examples, we conjecture that the generalized Schur limit as a function of $\\alpha$ solves a modular linear differential equation of fixed order, with coefficients depending on $\\alpha$. We also observe in examples that for Argyres-Douglas theories of type $(A_1,G)$ with $G=A_n,D_n$, the generalized Schur limit for certain negative integer values of $\\alpha$, coincides with the trace of higher powers of the quantum monodromy operator. This hints at a more general correspondence between the wall-crossing invariant traces on the Coulomb branch and the generalized Schur limit, which is related to the Higgs branch.",
          "authors": [
            "Anirudh Deb"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02102",
          "title": "Generalized Schur limit, modular differential equations and quantum monodromy traces",
          "abstract": "We explore some aspects of the generalized Schur limit, defined in arXiv:2506.13764 . Based on several examples, we conjecture that the generalized Schur limit as a function of $\\alpha$ solves a modular linear differential equation of fixed order, with coefficients depending on $\\alpha$. We also observe in examples that for Argyres-Douglas theories of type $(A_1,G)$ with $G=A_n,D_n$, the generalized Schur limit for certain negative integer values of $\\alpha$, coincides with the trace of higher powers of the quantum monodromy operator. This hints at a more general correspondence between the wall-crossing invariant traces on the Coulomb branch and the generalized Schur limit, which is related to the Higgs branch.",
          "authors": [
            "Anirudh Deb"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02103",
          "title": "To gauge or to double gauge? Matrix models, global symmetry, and black hole cohomologies",
          "abstract": "We study the structure of the Hilbert space of gauged matrix models with a global symmetry. In the first part of the paper, we focus on bosonic matrix models with $U(2)$ gauge group and $SO(d)$ global symmetry, and consider singlets under both the gauge and global symmetry. We show how such \"double-gauged'' matrix models can be described in terms of a simpler $SO(3)$ single-matrix model. In the second part of the paper, we consider the so-called BMN subsector of the $\\mathcal{N}=4$ $SU(N)$ super Yang-Mills theory, which is closely related to the BMN matrix model. Among the 1/16 BPS operators in this sector, \"non-graviton'' operators were recently discovered, which are expected to relate to the microstates of supersymmetric $AdS_5$ black holes. We show that a double gauging of this model, where one projects onto $SU(3)_R$ $R$-symmetry singlets, considerably simplifies the analysis of the non-graviton spectrum. In particular, for low values of $N$, we show that (almost) all graviton operators project out of the spectrum, while important classes of non-graviton operators remain. In the $N=3$ case, we obtain a closed form expression for the superconformal index of singlet non-gravitons, which reveals structural features of their spectrum.",
          "authors": [
            "Adwait Gaikwad",
            "Tanay Kibe",
            "Sam van Leuven",
            "Kayleigh Mathieson"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02105",
          "title": "Anomalies on the Lattice, Homotopy of Quantum Cellular Automata, and a Spectrum of Invertible States",
          "abstract": "We develop a rigorous topological theory of anomalies on the lattice, which are obstructions to gauging global symmetries and the existence of trivial symmetric states. We also construct $\\Omega$-spectra of a class of invertible states and quantum cellular automata, which allows us to classify both anomalies and symmetry protected topological phases up to blend equivalence.",
          "authors": [
            "Alexander M. Czajka",
            "Roman Geiko",
            "Ryan Thorngren"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02105",
          "title": "Anomalies on the Lattice, Homotopy of Quantum Cellular Automata, and a Spectrum of Invertible States",
          "abstract": "We develop a rigorous topological theory of anomalies on the lattice, which are obstructions to gauging global symmetries and the existence of trivial symmetric states. We also construct $\\Omega$-spectra of a class of invertible states and quantum cellular automata, which allows us to classify both anomalies and symmetry protected topological phases up to blend equivalence.",
          "authors": [
            "Alexander M. Czajka",
            "Roman Geiko",
            "Ryan Thorngren"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02105",
          "title": "Anomalies on the Lattice, Homotopy of Quantum Cellular Automata, and a Spectrum of Invertible States",
          "abstract": "We develop a rigorous topological theory of anomalies on the lattice, which are obstructions to gauging global symmetries and the existence of trivial symmetric states. We also construct $\\Omega$-spectra of a class of invertible states and quantum cellular automata, which allows us to classify both anomalies and symmetry protected topological phases up to blend equivalence.",
          "authors": [
            "Alexander M. Czajka",
            "Roman Geiko",
            "Ryan Thorngren"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02105",
          "title": "Anomalies on the Lattice, Homotopy of Quantum Cellular Automata, and a Spectrum of Invertible States",
          "abstract": "We develop a rigorous topological theory of anomalies on the lattice, which are obstructions to gauging global symmetries and the existence of trivial symmetric states. We also construct $\\Omega$-spectra of a class of invertible states and quantum cellular automata, which allows us to classify both anomalies and symmetry protected topological phases up to blend equivalence.",
          "authors": [
            "Alexander M. Czajka",
            "Roman Geiko",
            "Ryan Thorngren"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02105",
          "title": "Anomalies on the Lattice, Homotopy of Quantum Cellular Automata, and a Spectrum of Invertible States",
          "abstract": "We develop a rigorous topological theory of anomalies on the lattice, which are obstructions to gauging global symmetries and the existence of trivial symmetric states. We also construct $\\Omega$-spectra of a class of invertible states and quantum cellular automata, which allows us to classify both anomalies and symmetry protected topological phases up to blend equivalence.",
          "authors": [
            "Alexander M. Czajka",
            "Roman Geiko",
            "Ryan Thorngren"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02107",
          "title": "Generalised 4d Partition Functions and Modular Differential Equations",
          "abstract": "We prove the equivalence of a class of generalised Schur partition functions $\\mathcal Z_G(q;\\alpha)$ of 4d $\\mathcal N=2$ superconformal gauge theories to contour integral representations of vector-valued modular forms of the type that arise in 2d rational conformal field theories (RCFT). Concretely, we consider the $USp(2N)$ theory with $2N+2$ fundamental hypermultiplets and analytically prove that $\\mathcal Z_{USp(2N)}(q;\\alpha)$ satisfies an order-$(N+1)$ modular linear differential equation (MLDE) with vanishing Wronskian index, explaining how the parameter $\\alpha$ of the former determines the parameters of the latter. Several connections are made to characters of RCFTs including unitary ones. We then propose a two-parameter extension $\\mathcal Z_{USp(2N)}(q;\\alpha,\\beta)$ of the generalised Schur partition function. Finally, we relate the $\\alpha=-k$ specialisation to quantum monodromy traces ${\\rm Tr}\\,M^k$ and formulate a conjecture linking their $k$-dependence to MLDEs.",
          "authors": [
            "A. Ramesh Chandra",
            "Sunil Mukhi",
            "Palash Singh"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02107",
          "title": "Generalised 4d Partition Functions and Modular Differential Equations",
          "abstract": "We prove the equivalence of a class of generalised Schur partition functions $\\mathcal Z_G(q;\\alpha)$ of 4d $\\mathcal N=2$ superconformal gauge theories to contour integral representations of vector-valued modular forms of the type that arise in 2d rational conformal field theories (RCFT). Concretely, we consider the $USp(2N)$ theory with $2N+2$ fundamental hypermultiplets and analytically prove that $\\mathcal Z_{USp(2N)}(q;\\alpha)$ satisfies an order-$(N+1)$ modular linear differential equation (MLDE) with vanishing Wronskian index, explaining how the parameter $\\alpha$ of the former determines the parameters of the latter. Several connections are made to characters of RCFTs including unitary ones. We then propose a two-parameter extension $\\mathcal Z_{USp(2N)}(q;\\alpha,\\beta)$ of the generalised Schur partition function. Finally, we relate the $\\alpha=-k$ specialisation to quantum monodromy traces ${\\rm Tr}\\,M^k$ and formulate a conjecture linking their $k$-dependence to MLDEs.",
          "authors": [
            "A. Ramesh Chandra",
            "Sunil Mukhi",
            "Palash Singh"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02107",
          "title": "Generalised 4d Partition Functions and Modular Differential Equations",
          "abstract": "We prove the equivalence of a class of generalised Schur partition functions $\\mathcal Z_G(q;\\alpha)$ of 4d $\\mathcal N=2$ superconformal gauge theories to contour integral representations of vector-valued modular forms of the type that arise in 2d rational conformal field theories (RCFT). Concretely, we consider the $USp(2N)$ theory with $2N+2$ fundamental hypermultiplets and analytically prove that $\\mathcal Z_{USp(2N)}(q;\\alpha)$ satisfies an order-$(N+1)$ modular linear differential equation (MLDE) with vanishing Wronskian index, explaining how the parameter $\\alpha$ of the former determines the parameters of the latter. Several connections are made to characters of RCFTs including unitary ones. We then propose a two-parameter extension $\\mathcal Z_{USp(2N)}(q;\\alpha,\\beta)$ of the generalised Schur partition function. Finally, we relate the $\\alpha=-k$ specialisation to quantum monodromy traces ${\\rm Tr}\\,M^k$ and formulate a conjecture linking their $k$-dependence to MLDEs.",
          "authors": [
            "A. Ramesh Chandra",
            "Sunil Mukhi",
            "Palash Singh"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02112",
          "title": "Observation of an anomaly in the statistics of Kibble-Zurek defects",
          "abstract": "The Kibble-Zurek mechanism quantifies defect formation during adiabatic passage across a continuous phase transition, providing key insights into universality in quantum many-body systems. We explore counting statistics of defects in adiabatic passage experiments on long 1D Rydberg atom chains. The experiments reveal an anomaly in the defect number distribution at long ramp times, challenging the hypothesis of defect formation through independent domain mergers. Numerical simulations confirm the anomaly and suggest its link to non-critical coarsening dynamics, which we suppress in prepare-and-hold experiments. Our results highlight the ability of quantum simulators to uncover unexpected correlated quantum phenomena.",
          "authors": [
            "Jan Balewski",
            "Alexey Khudorozhkov",
            "Siva Darbha",
            "Omar A. Ashour",
            "Fangli Liu",
            "Ermal Rrapaj",
            "Sheng-Tao Wang",
            "Pedro L. S. Lopes",
            "Katherine Klymko",
            "Milan Kornjača",
            "Daan Camps"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02112",
          "title": "Observation of an anomaly in the statistics of Kibble-Zurek defects",
          "abstract": "The Kibble-Zurek mechanism quantifies defect formation during adiabatic passage across a continuous phase transition, providing key insights into universality in quantum many-body systems. We explore counting statistics of defects in adiabatic passage experiments on long 1D Rydberg atom chains. The experiments reveal an anomaly in the defect number distribution at long ramp times, challenging the hypothesis of defect formation through independent domain mergers. Numerical simulations confirm the anomaly and suggest its link to non-critical coarsening dynamics, which we suppress in prepare-and-hold experiments. Our results highlight the ability of quantum simulators to uncover unexpected correlated quantum phenomena.",
          "authors": [
            "Jan Balewski",
            "Alexey Khudorozhkov",
            "Siva Darbha",
            "Omar A. Ashour",
            "Fangli Liu",
            "Ermal Rrapaj",
            "Sheng-Tao Wang",
            "Pedro L. S. Lopes",
            "Katherine Klymko",
            "Milan Kornjača",
            "Daan Camps"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02119",
          "title": "Wilson loops in ABJM theory reloaded",
          "abstract": "We present a new technique for computing supersymmetric Wilson loops in the ABJM theory via supersymmetric localization, valid for arbitrary values of the rank of the gauge group $N$ and the Chern-Simons level $k$. The approach relies on an operator representation of the Wilson loops within the Fermi gas formalism in terms of the resolvent of a certain integral operator previously encountered in the computation of the ABJM partition function on the round three-sphere. By deriving a set of nontrivial relations for this resolvent, we obtain exact expressions for the generating functions of Wilson loops in terms of the partition function. For large $k$, these expressions reproduce the weak-coupling expansion of the Wilson loops, and in the large-$N$ limit at fixed $k$ they match previously obtained high-precision numerical results. This analysis also resolves the longstanding discrepancy between numerical data and the semiclassical expression for the $1/6$ BPS Wilson loop.",
          "authors": [
            "Bercel Boldis",
            "Gregory P. Korchemsky",
            "Alessandro Testa"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02120",
          "title": "(Iso)spin from Isospin in Top-Down Holography",
          "abstract": "Motivated by the spin from isospin mechanism of Jackiw-Rebbi-Hasenfratz-'t Hooft, we study two SU(2) gauged supergravity solutions of the form $M_{d}\\times\\text{S}^{2}$ containing non-Abelian hedgehog monopole on the 2-sphere. Due to the presence of the monopole, the SO(3) isometry group of the 2-sphere is not a symmetry of the configuration. Instead, a diagonal combination of the SU(2) gauge and the SO(3) isometry of the 2-sphere is the true symmetry of the configuration. Uplifting the solutions to Type II, the gauge-isometry diagonal symmetry becomes a diagonal combination between the SO(3) symmetry of the 2-sphere and a SU(2) symmetry of a 3-sphere used to uplift the configuration. One of the uplifts is supersymmetric and corresponds to the I-brane theory on a 2-sphere. The second background is a deformation of $\\text{AdS}_{5}\\times\\text{S}^{5}$ and is not supersymmetric. We study dilaton fluctuations on the later geometry. Due to the diagonal symmetry, the fluctuations show angular momentum mixing between the SU(2) and SO(3) spins, mimicking the spin from isospin mechanism.",
          "authors": [
            "Marcelo Oyarzo",
            "Ricardo Stuardo"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02121",
          "title": "Network theory classification of quantum matter based on wave function snapshots",
          "abstract": "Quantum computers and simulators offer unparalleled capabilities of probing quantum many-body states, by obtaining snapshots of the many-body wave function via collective projective measurements. The probability distribution obtained by such snapshots (which are fundamentally limited to a negligible fraction of the Hilbert space) is of fundamental importance to determine the power of quantum computations. However, its relation to many-body collective properties is poorly understood. Here, we develop a theoretical framework to link quantum phases of matter to their snapshots, based on a combination of data complexity and network theory analyses. The first step in our scheme consists of applying Occam's razor principle to quantum sampling: given snapshots of a wave function, we identify a minimal-complexity measurement basis by analyzing the information compressibility of snapshots over different measurement bases. The second step consists of analyzing arbitrary correlations using network theory, building a wave-function network from the minimal-complexity basis data. This approach allows us to stochastically classify the output of quantum computers and simulations, with no assumptions on the underlying dynamics, and in a fully interpretable manner. We apply this method to quantum states of matter in one-dimensional translational invariant systems, where such classification is exhaustive, and where it reveals an interesting interplay between algorithmic and computational complexity for many-body states. Our framework is of immediate experimental relevance, and can be further extended both in terms of more advanced network mathematics, including discrete homology, as well as in terms of applications to physical phenomena, such as time-dependent dynamics and gauge theories.",
          "authors": [
            "Riccardo Andreoni",
            "Vittorio Vitale",
            "Cristiano Muzzi",
            "Guido Caldarelli",
            "Roberto Verdel",
            "Marcello Dalmonte"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02121",
          "title": "Network theory classification of quantum matter based on wave function snapshots",
          "abstract": "Quantum computers and simulators offer unparalleled capabilities of probing quantum many-body states, by obtaining snapshots of the many-body wave function via collective projective measurements. The probability distribution obtained by such snapshots (which are fundamentally limited to a negligible fraction of the Hilbert space) is of fundamental importance to determine the power of quantum computations. However, its relation to many-body collective properties is poorly understood. Here, we develop a theoretical framework to link quantum phases of matter to their snapshots, based on a combination of data complexity and network theory analyses. The first step in our scheme consists of applying Occam's razor principle to quantum sampling: given snapshots of a wave function, we identify a minimal-complexity measurement basis by analyzing the information compressibility of snapshots over different measurement bases. The second step consists of analyzing arbitrary correlations using network theory, building a wave-function network from the minimal-complexity basis data. This approach allows us to stochastically classify the output of quantum computers and simulations, with no assumptions on the underlying dynamics, and in a fully interpretable manner. We apply this method to quantum states of matter in one-dimensional translational invariant systems, where such classification is exhaustive, and where it reveals an interesting interplay between algorithmic and computational complexity for many-body states. Our framework is of immediate experimental relevance, and can be further extended both in terms of more advanced network mathematics, including discrete homology, as well as in terms of applications to physical phenomena, such as time-dependent dynamics and gauge theories.",
          "authors": [
            "Riccardo Andreoni",
            "Vittorio Vitale",
            "Cristiano Muzzi",
            "Guido Caldarelli",
            "Roberto Verdel",
            "Marcello Dalmonte"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02123",
          "title": "General Four-Loop Beta Function for Scalar-Fermion Theories in Three Dimensions",
          "abstract": "We present general four-loop template $\\beta$-functions and anomalous field dimensions for renormalisable scalar-fermion theories in three dimensions. By imposing $\\mathcal{N}=1$ and $\\mathcal{N}=2$ supersymmetry, we obtain relations between the template RGE coefficients, valid in any renormalisation scheme. Directly in $d=3$, we identify a new theory with a non-trivial IR fixed point that is under perturbative control in a large-$N$ limit. We provide up-to-date numerical results for all required massive tadpole master integrals up to four loops and complement them with analytic expressions where available.",
          "authors": [
            "York Schröder",
            "Emmanuel Stamou",
            "Tom Steudtner",
            "Max Uetrecht"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02123",
          "title": "General Four-Loop Beta Function for Scalar-Fermion Theories in Three Dimensions",
          "abstract": "We present general four-loop template $\\beta$-functions and anomalous field dimensions for renormalisable scalar-fermion theories in three dimensions. By imposing $\\mathcal{N}=1$ and $\\mathcal{N}=2$ supersymmetry, we obtain relations between the template RGE coefficients, valid in any renormalisation scheme. Directly in $d=3$, we identify a new theory with a non-trivial IR fixed point that is under perturbative control in a large-$N$ limit. We provide up-to-date numerical results for all required massive tadpole master integrals up to four loops and complement them with analytic expressions where available.",
          "authors": [
            "York Schröder",
            "Emmanuel Stamou",
            "Tom Steudtner",
            "Max Uetrecht"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02123",
          "title": "General Four-Loop Beta Function for Scalar-Fermion Theories in Three Dimensions",
          "abstract": "We present general four-loop template $\\beta$-functions and anomalous field dimensions for renormalisable scalar-fermion theories in three dimensions. By imposing $\\mathcal{N}=1$ and $\\mathcal{N}=2$ supersymmetry, we obtain relations between the template RGE coefficients, valid in any renormalisation scheme. Directly in $d=3$, we identify a new theory with a non-trivial IR fixed point that is under perturbative control in a large-$N$ limit. We provide up-to-date numerical results for all required massive tadpole master integrals up to four loops and complement them with analytic expressions where available.",
          "authors": [
            "York Schröder",
            "Emmanuel Stamou",
            "Tom Steudtner",
            "Max Uetrecht"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02131",
          "title": "Quantum Advantage in Resource Estimation",
          "abstract": "Quantum computing promises the ability to compute properties of quantum systems exponentially faster than classical computers. Quantum advantage is achieved when a practical problem is solved more efficiently on a quantum computer than on a classical computer. Demonstrating quantum advantage requires a powerful quantum computer with low error rates and an efficient quantum algorithm that has a useful application. Despite rapid progress in hardware development, we still lack useful applications that are feasible for the next generation of quantum computers. Here we argue that an exponential quantum advantage exists in producing numerical resource estimates of larger quantum algorithms by accurately measuring simulation errors. We provide a quantum algorithm for measuring simulation errors of Trotter-based algorithms. Our results indicate that this method will reduce runtimes of quantum algorithms by approximately three orders of magnitude for one-hundred qubit systems. We also predict that these reductions will increase with system size. The methods we propose require relatively few qubits and operations, meaning the next generation of quantum computers could compute simulation errors for classically intractable systems. Since the underlying computations that lead to reduced resource estimates are infeasible for classical computers, this task is a candidate for demonstrating practical quantum advantage.",
          "authors": [
            "William A. Simon",
            "Peter J. Love"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02132",
          "title": "Return point memory in knitted fabrics",
          "abstract": "The tunable mechanical response of knitted fabrics underpins applications ranging from soft robotics and artificial muscles to morphing electromagnetic field sensors. Elasticity in fabrics emerges from the bending of yarn in the knitted structure; however, properties beyond elasticity are relatively unexplored. Here, we demonstrate that knitted fabrics subjected to cyclic uniaxial stress exhibit significant hysteresis and the remarkable ability to \"remember\" their response to previous deformations -- reminiscent of classical return point memory in magnetic systems. The hysteretic behavior deviates from the two standard models of hysteresis that usually apply to solid-state materials, viscoelasticity and plasticity. Thus, we develop a phenomenological extension of the Preisach model of hysteresis which well replicates our data, and discuss implications of these results on the underlying mechanisms of memory in knitted fabrics.",
          "authors": [
            "Elizabeth J. Dresselhaus",
            "Sonja Hellebrand",
            "Rajyasri Roy",
            "Kranthi K. Mandadapu",
            "Sanjay Govindjee"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02133",
          "title": "Partially hyperbolic dynamics in the 3-body problem",
          "abstract": "We construct symplectic blenders for two classical Hamiltonian systems: the 3-body problem and its restricted version. We use these objects to show that both models exhibit a robust, strong form of topological instability. We do not assume any smallness conditions on the masses but require only that at least two of them are distinct. Our construction is based on two abstract results which might be of independent interest. The first one gives an explicit condition under which a given pair of twist maps of the cylinder generates a locally transitive iterated function system. The second one extends this result to certain cylinder skew-products.",
          "authors": [
            "Marcel Guardia",
            "Jaime Paradela"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02139",
          "title": "Generalizing fusion rules by shuffle: Symmetry-based classifications of nonlocal systems constructed from similarity transformations",
          "abstract": "We study fusion rings, or symmetry topological field theories (SymTFTs), which lie outside the non-negative integer matrix representation (NIM-rep), by combining knowledge from generalized symmetry and that from pseudo-Hermitian systems. By applying the Galois shuffle operation to the SymTFTs, we reconstruct fusion rings that correspond to nonlocal CFTs constructed from the corresponding local nonunitary CFTs by applying the similarity transformations. The resultant SymTFTs are outside of NIM-rep, whereas they are ring isomorphic to the NIM-rep of the corresponding local nonunitary CFTs. We study the consequences of this correspondence between the nonlocal unitary model and local nonunitary models. We demonstrate the correspondence between their classifications of massive or massless renormalization group flows and the discrepancies between their boundary or domain wall phenomena. Our work reveals a new connection between ring isomorphism and similarity transformations, providing the fundamental implications of ring-theoretic ideas in the context of symmetry in physics.",
          "authors": [
            "Yoshiki Fukusumi",
            "Taishi Kawamoto"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02139",
          "title": "Generalizing fusion rules by shuffle: Symmetry-based classifications of nonlocal systems constructed from similarity transformations",
          "abstract": "We study fusion rings, or symmetry topological field theories (SymTFTs), which lie outside the non-negative integer matrix representation (NIM-rep), by combining knowledge from generalized symmetry and that from pseudo-Hermitian systems. By applying the Galois shuffle operation to the SymTFTs, we reconstruct fusion rings that correspond to nonlocal CFTs constructed from the corresponding local nonunitary CFTs by applying the similarity transformations. The resultant SymTFTs are outside of NIM-rep, whereas they are ring isomorphic to the NIM-rep of the corresponding local nonunitary CFTs. We study the consequences of this correspondence between the nonlocal unitary model and local nonunitary models. We demonstrate the correspondence between their classifications of massive or massless renormalization group flows and the discrepancies between their boundary or domain wall phenomena. Our work reveals a new connection between ring isomorphism and similarity transformations, providing the fundamental implications of ring-theoretic ideas in the context of symmetry in physics.",
          "authors": [
            "Yoshiki Fukusumi",
            "Taishi Kawamoto"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02139",
          "title": "Generalizing fusion rules by shuffle: Symmetry-based classifications of nonlocal systems constructed from similarity transformations",
          "abstract": "We study fusion rings, or symmetry topological field theories (SymTFTs), which lie outside the non-negative integer matrix representation (NIM-rep), by combining knowledge from generalized symmetry and that from pseudo-Hermitian systems. By applying the Galois shuffle operation to the SymTFTs, we reconstruct fusion rings that correspond to nonlocal CFTs constructed from the corresponding local nonunitary CFTs by applying the similarity transformations. The resultant SymTFTs are outside of NIM-rep, whereas they are ring isomorphic to the NIM-rep of the corresponding local nonunitary CFTs. We study the consequences of this correspondence between the nonlocal unitary model and local nonunitary models. We demonstrate the correspondence between their classifications of massive or massless renormalization group flows and the discrepancies between their boundary or domain wall phenomena. Our work reveals a new connection between ring isomorphism and similarity transformations, providing the fundamental implications of ring-theoretic ideas in the context of symmetry in physics.",
          "authors": [
            "Yoshiki Fukusumi",
            "Taishi Kawamoto"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02139",
          "title": "Generalizing fusion rules by shuffle: Symmetry-based classifications of nonlocal systems constructed from similarity transformations",
          "abstract": "We study fusion rings, or symmetry topological field theories (SymTFTs), which lie outside the non-negative integer matrix representation (NIM-rep), by combining knowledge from generalized symmetry and that from pseudo-Hermitian systems. By applying the Galois shuffle operation to the SymTFTs, we reconstruct fusion rings that correspond to nonlocal CFTs constructed from the corresponding local nonunitary CFTs by applying the similarity transformations. The resultant SymTFTs are outside of NIM-rep, whereas they are ring isomorphic to the NIM-rep of the corresponding local nonunitary CFTs. We study the consequences of this correspondence between the nonlocal unitary model and local nonunitary models. We demonstrate the correspondence between their classifications of massive or massless renormalization group flows and the discrepancies between their boundary or domain wall phenomena. Our work reveals a new connection between ring isomorphism and similarity transformations, providing the fundamental implications of ring-theoretic ideas in the context of symmetry in physics.",
          "authors": [
            "Yoshiki Fukusumi",
            "Taishi Kawamoto"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02139",
          "title": "Generalizing fusion rules by shuffle: Symmetry-based classifications of nonlocal systems constructed from similarity transformations",
          "abstract": "We study fusion rings, or symmetry topological field theories (SymTFTs), which lie outside the non-negative integer matrix representation (NIM-rep), by combining knowledge from generalized symmetry and that from pseudo-Hermitian systems. By applying the Galois shuffle operation to the SymTFTs, we reconstruct fusion rings that correspond to nonlocal CFTs constructed from the corresponding local nonunitary CFTs by applying the similarity transformations. The resultant SymTFTs are outside of NIM-rep, whereas they are ring isomorphic to the NIM-rep of the corresponding local nonunitary CFTs. We study the consequences of this correspondence between the nonlocal unitary model and local nonunitary models. We demonstrate the correspondence between their classifications of massive or massless renormalization group flows and the discrepancies between their boundary or domain wall phenomena. Our work reveals a new connection between ring isomorphism and similarity transformations, providing the fundamental implications of ring-theoretic ideas in the context of symmetry in physics.",
          "authors": [
            "Yoshiki Fukusumi",
            "Taishi Kawamoto"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02142",
          "title": "The complete $10$-tetrahedra census of orientable cusped hyperbolic $3$-manifolds",
          "abstract": "We extend the complete census of orientable cusped hyperbolic $3$-manifolds to $10$ tetrahedra, giving the next $150730$ manifolds and their $496638$ minimal ideal triangulations. As applications, we find the precisely $439898$ exceptional Dehn fillings on them, revealing the next $1849$ simplest hyperbolic knot exteriors in $S^3$. We also give the simplest example of an orientable cusped hyperbolic $3$-manifold containing a closed totally geodesic surface.",
          "authors": [
            "Shana Yunsheng Li"
          ],
          "primary_category": "math.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02144",
          "title": "Splash-squeeze singularities and analytic breakdown in ideal incompressible MHD",
          "abstract": "We construct splash-squeeze singularities for the free boundary ideal incompressible plasma-vacuum system, in which two arcs of the plasma boundary come together to form a smooth, glancing self-intersection. As the interface self-intersects, Sobolev norms remain bounded, although analyticity is necessarily lost. This contrasts classical splash singularities, in which solutions remain analytic up to the time of self-intersection. The narrowing gap bounded by these arcs is not occupied by plasma, as squeezing the plasma itself would cause blow-up in Sobolev norms. Instead, the gap represents the region outside the plasma, a vacuum carrying a nontrivial magnetic field. The plasma on either side pinches the field as the gap closes, and, in response, the field flattens to infinite order at the intersection point (and nowhere else), thereby forming an analytic singularity. This gives the first example of analytic breakdown without Sobolev blow-up in a locally well-posed free-boundary incompressible fluid system, and can be viewed as the first rigorous construction of a squeeze-type singularity, in which we study and quantify the precise behavior of an active, incompressible vector field as it is completely pinched off by a free-boundary in finite time. The proof combines a magnetically-aligned Lagrangian formulation of ideal MHD together with weighted elliptic estimates in the vacuum that remain uniform as the width of the gap tends to zero. Our framework may provide a starting point for the analysis of squeeze-type singularities in other incompressible fluid models.",
          "authors": [
            "Diego Córdoba",
            "Alberto Enciso",
            "Matthew Hernandez"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02145",
          "title": "A Trefftz Continuous Galerkin method for Helmholtz problems",
          "abstract": "This work introduces a novel Trefftz Continuous Galerkin (TCG) method for 2D Helmholtz problems based on evanescent plane waves (EPWs). We construct a new globally-conforming discrete space, departing from standard discontinuous Trefftz formulations, and investigate its approximation properties, providing wavenumber-explicit best-approximation error estimates. The mesh is defined by intersecting the domain with a Cartesian grid, and the basis functions are continuous in the whole computational domain, compactly supported, and can be expressed as simple linear combinations of EPWs within each element. This ensures they remain local solutions to the Helmholtz equation and allows the system matrix to be assembled in closed form for polygonal domains. The discrete space provides stable approximations with bounded coefficients and spectral accuracy for analytic Helmholtz solutions. The approximation error is proved to decay exponentially both at a fixed frequency, with respect to the discretization parameters, and along suitable sequences of increasing wavenumbers, with the number of degrees of freedom scaling linearly with the frequency. Numerical results confirm these theoretical estimates for the full Galerkin error.",
          "authors": [
            "Nicola Galante",
            "Bruno Després",
            "Emile Parolin"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02145",
          "title": "A Trefftz Continuous Galerkin method for Helmholtz problems",
          "abstract": "This work introduces a novel Trefftz Continuous Galerkin (TCG) method for 2D Helmholtz problems based on evanescent plane waves (EPWs). We construct a new globally-conforming discrete space, departing from standard discontinuous Trefftz formulations, and investigate its approximation properties, providing wavenumber-explicit best-approximation error estimates. The mesh is defined by intersecting the domain with a Cartesian grid, and the basis functions are continuous in the whole computational domain, compactly supported, and can be expressed as simple linear combinations of EPWs within each element. This ensures they remain local solutions to the Helmholtz equation and allows the system matrix to be assembled in closed form for polygonal domains. The discrete space provides stable approximations with bounded coefficients and spectral accuracy for analytic Helmholtz solutions. The approximation error is proved to decay exponentially both at a fixed frequency, with respect to the discretization parameters, and along suitable sequences of increasing wavenumbers, with the number of degrees of freedom scaling linearly with the frequency. Numerical results confirm these theoretical estimates for the full Galerkin error.",
          "authors": [
            "Nicola Galante",
            "Bruno Després",
            "Emile Parolin"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02146",
          "title": "On the Eigen-Falconer theorem in $\\mathbb{R}^d$",
          "abstract": "In this paper, we study the analogous Erdős similarity conjecture in higher dimensions and generalize the Eigen-Falconer theorem. We show that if $A=\\{\\boldsymbol{x}_n\\}_{n=1}^\\infty \\subseteq \\mathbb{R}^d$ is a sequence of non-zero vectors satisfying \\[ \\lim_{n \\to \\infty} \\|\\boldsymbol{x}_n\\| =0 \\quad \\text{and} \\quad \\lim_{n \\to \\infty} \\frac{\\|\\boldsymbol{x}_{n+1}\\|}{\\|\\boldsymbol{x}_n\\|} = 1, \\] then there exists a measurable set $E \\subseteq \\mathbb{R}^d$ with positive Lebesgue measure such that $E$ contains no affine copies of $A$.",
          "authors": [
            "Wenxia Li",
            "Zhiqiang Wang",
            "Jiayi Xu"
          ],
          "primary_category": "math.CA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02149",
          "title": "Weight distributions of simplex codes over finite chain rings and their Gray map images",
          "abstract": "A linear code of length $n$ over a finite chain ring $R$ with residue field $\\F_q$ is a $R$-submodule of $R^n$. A $R$-linear code is a code over $\\F_q$ (not necessarily linear) which is the generalized Gray map image of a linear code over $R$. These codes can be seen as a generalization of the linear codes over $\\Z_{p^s}$ with $p$ prime and $s \\geq 1$. In this paper, we present the construction of linear simplex codes over $R$ and their corresponding $R$-linear simplex codes of type $\\alpha$ and $\\beta$. Moreover, we show the fundamental parameters of these codes, including their minimum Hamming distance, as well as their complete weight distributions. We also study whether these simplex codes are optimal with respect to the Griesmer-type bound.",
          "authors": [
            "Cristina Fernández-Córdoba",
            "Sergi Sánchez-Aragón",
            "Mercè Villanueva"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02149",
          "title": "Weight distributions of simplex codes over finite chain rings and their Gray map images",
          "abstract": "A linear code of length $n$ over a finite chain ring $R$ with residue field $\\F_q$ is a $R$-submodule of $R^n$. A $R$-linear code is a code over $\\F_q$ (not necessarily linear) which is the generalized Gray map image of a linear code over $R$. These codes can be seen as a generalization of the linear codes over $\\Z_{p^s}$ with $p$ prime and $s \\geq 1$. In this paper, we present the construction of linear simplex codes over $R$ and their corresponding $R$-linear simplex codes of type $\\alpha$ and $\\beta$. Moreover, we show the fundamental parameters of these codes, including their minimum Hamming distance, as well as their complete weight distributions. We also study whether these simplex codes are optimal with respect to the Griesmer-type bound.",
          "authors": [
            "Cristina Fernández-Córdoba",
            "Sergi Sánchez-Aragón",
            "Mercè Villanueva"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02150",
          "title": "$J_1-J_2$ Triangular Lattice Antiferromagnet in a Magnetic Field",
          "abstract": "We investigate the spin-1/2 $J_1-J_2$ triangular-lattice Heisenberg antiferromagnet in a magnetic field by combining large-scale density matrix renormalization group (DMRG) simulations with self-consistent spin-wave theory. The resulting field-coupling phase diagram reveals that quantum fluctuations stabilize coplanar order across the entire parameter range, giving rise to a characteristic sequence of magnetization plateaux. Near the quantum-spin-liquid window $0.06 \\lesssim J_2/J_1 \\lesssim 0.14$, which extends to magnetic field $B \\sim J_1$, we identify overlapping $m = 1/3$ and $m = 1/2$ plateaux - a distinctive hallmark of the system's proximity to the low-field spin-liquid regime. The excellent quantitative agreement between DMRG and self-consistent one-loop spin-wave calculations demonstrates that semiclassical approaches can reliably capture and parameterize the plateau phases of triangular quantum antiferromagnets.",
          "authors": [
            "Anna Keselman",
            "Xinyuan Xu",
            "Hao Zhang",
            "Cristian D. Batista",
            "Oleg A. Starykh"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02151",
          "title": "Repeated integrals of increasing functions",
          "abstract": "Motivated by a problem on comonotone approximation of $C^n$ functions by entire functions, for increasing functions $f\\colon[0,1]\\to[0,1]$, we characterize the possible values of $(a,b,c)$, where $a=I(f)(1)$, $b=I^2(f)(1)$, $c=I^3(f)(1)$ ($I$ is the integral operator $I(f)(x)=\\int_0^xf(t)\\,dt$), as those which satisfy the conditions $0\\leq a\\leq 1$, $a^2/2\\leq b\\leq a/2$, $2b^2\\leq 3ac$, $a^2 + 4b^2 + 6c\\leq 6ac +2ab+2b$, and $0\\leq c\\leq a/6$. Our main theorem states that if $a,b,c$ are real numbers for which the inequalities are strict, then there is a function $f$ satisfying $a=I(f)(1)$, $b=I^2(f)(1)$, $c=I^3(f)(1)$ which is $C^\\infty$ with $f(0)=0$, $f(1)=1$, $Df(x)>0$ for $0<x<1$, and whose derivatives $D^jf(0)$ and $D^jf(1)$, $j\\geq 1$, are arbitrary as long as they are consistent with the increasing nature of $f$. The construction of $f$ proceeds by starting with a continuous parametrization $s\\mapsto \\rho_s\\in C^\\infty([0,1])$ defined on an open subset of $\\mathbb{R}^4$, and composing with successive continuous transversals through the open set to fix the values of $I^j(\\rho_s)(1)$ for $j=0,1,2,3$. Addressing the aforementioned problem on comonotone approximation, we examine the set $V_n\\subseteq\\mathbb{R}^{2(n+1)}$ of possible values $D^jf(0)$, $D^jf(1)$, $j=0,\\dots,n$, of the derivatives of a $C^n$ function at the endpoints when $D^nf$ is increasing but not constant. We make a conjecture about the nature of this set and prove our conjecture for $n\\leq 3$ as a consequence of the theorem mentioned above.",
          "authors": [
            "Maxim R. Burke",
            "Maleeha Haris",
            "Madhavendra"
          ],
          "primary_category": "math.CA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02154",
          "title": "Accurate prediction of macroscopic transport from microscopic imaging via critical fractals at the Mott transition",
          "abstract": "Vanadium dioxide (VO$_2$) exhibits hysteresis in resistance while undergoing a thermally driven insulator-metal transition (IMT). Understanding the nonequilibrium effects in resistance is of great interest, as VO$_2$ is a strong candidate for brain-inspired computing, which is more energy efficient for AI tasks compared to traditional computing. Accurate models of the connection between microscopic and macroscopic transport properties and microscopic imaging of VO$_2$ will allow us to better utilize VO$_2$ in future applications. However, predictions of macroscopic resistance of VO$_2$ that quantitatively match observations using spatially resolved data have not yet been achieved. Here, we demonstrate an accurate prediction of the macroscopic resistance of VO$_2$ throughout the entire temperature range of interest, by developing a multiscale resistor network model incorporating the assumption of fractal sub-pixel structure of the optical data, where the configuration of insulating and metallic domains within each pixel are drawn from the random field Ising model near criticality. This strongly indicates that the observed fractal, power law structure of metallic and insulating domains extends down to much smaller length scales than the current record for experimental resolution of this system, and that the two-dimensional random field Ising model near criticality is a suitable model for describing the metal and insulator patches of VO$_2$ down to scales that approach the unit cell.",
          "authors": [
            "P.-Y. Chen",
            "A. R. Rajapurohita",
            "M. Alzate Banguero",
            "S. Basak",
            "F. Simmons",
            "P. Salev",
            "L. Aigouy",
            "Ivan. K. Schuller",
            "A. Zimmers",
            "E. W. Carlson"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02158",
          "title": "Out-of-equilibrium modeling of lyotropic liquid crystals: from binary simulations to multi-component theory",
          "abstract": "We present a thermodynamically consistent theoretical framework for lyotropic liquid crystals (LCs) based on the GENERIC (General Equation for the Non-Equilibrium Reversible-Irreversible Coupling) formalism. This formalism ensures conservation of energy and production of entropy, while coupling concentration, momentum balance, and liquid crystalline order. Starting from a binary nematic-isotropic mixture, we derive a theory for these key variables, which is then extended to multi-component systems. The binary equations are solved numerically using a Julia-based solver that relies on an upwind finite-difference scheme, enabling stable and efficient simulations capable of handling multiple time scales while satisfying fundamental mathematical constraints. The results of simulations are consistent with experimental observations of topological core defects in chromonic LCs, as well as flow-driven droplet shape transitions under Couette and Poiseuille flows. This work provides a platform for simulations of multi-component lyotropic LCs that can be extended to systems with multiple interfaces, active materials, and materials subject to external fields.",
          "authors": [
            "Jonathan Salmerón-Hernández",
            "Pablo Zubieta-Rico",
            "Juan de Pablo"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02158",
          "title": "Out-of-equilibrium modeling of lyotropic liquid crystals: from binary simulations to multi-component theory",
          "abstract": "We present a thermodynamically consistent theoretical framework for lyotropic liquid crystals (LCs) based on the GENERIC (General Equation for the Non-Equilibrium Reversible-Irreversible Coupling) formalism. This formalism ensures conservation of energy and production of entropy, while coupling concentration, momentum balance, and liquid crystalline order. Starting from a binary nematic-isotropic mixture, we derive a theory for these key variables, which is then extended to multi-component systems. The binary equations are solved numerically using a Julia-based solver that relies on an upwind finite-difference scheme, enabling stable and efficient simulations capable of handling multiple time scales while satisfying fundamental mathematical constraints. The results of simulations are consistent with experimental observations of topological core defects in chromonic LCs, as well as flow-driven droplet shape transitions under Couette and Poiseuille flows. This work provides a platform for simulations of multi-component lyotropic LCs that can be extended to systems with multiple interfaces, active materials, and materials subject to external fields.",
          "authors": [
            "Jonathan Salmerón-Hernández",
            "Pablo Zubieta-Rico",
            "Juan de Pablo"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02158",
          "title": "Out-of-equilibrium modeling of lyotropic liquid crystals: from binary simulations to multi-component theory",
          "abstract": "We present a thermodynamically consistent theoretical framework for lyotropic liquid crystals (LCs) based on the GENERIC (General Equation for the Non-Equilibrium Reversible-Irreversible Coupling) formalism. This formalism ensures conservation of energy and production of entropy, while coupling concentration, momentum balance, and liquid crystalline order. Starting from a binary nematic-isotropic mixture, we derive a theory for these key variables, which is then extended to multi-component systems. The binary equations are solved numerically using a Julia-based solver that relies on an upwind finite-difference scheme, enabling stable and efficient simulations capable of handling multiple time scales while satisfying fundamental mathematical constraints. The results of simulations are consistent with experimental observations of topological core defects in chromonic LCs, as well as flow-driven droplet shape transitions under Couette and Poiseuille flows. This work provides a platform for simulations of multi-component lyotropic LCs that can be extended to systems with multiple interfaces, active materials, and materials subject to external fields.",
          "authors": [
            "Jonathan Salmerón-Hernández",
            "Pablo Zubieta-Rico",
            "Juan de Pablo"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02158",
          "title": "Out-of-equilibrium modeling of lyotropic liquid crystals: from binary simulations to multi-component theory",
          "abstract": "We present a thermodynamically consistent theoretical framework for lyotropic liquid crystals (LCs) based on the GENERIC (General Equation for the Non-Equilibrium Reversible-Irreversible Coupling) formalism. This formalism ensures conservation of energy and production of entropy, while coupling concentration, momentum balance, and liquid crystalline order. Starting from a binary nematic-isotropic mixture, we derive a theory for these key variables, which is then extended to multi-component systems. The binary equations are solved numerically using a Julia-based solver that relies on an upwind finite-difference scheme, enabling stable and efficient simulations capable of handling multiple time scales while satisfying fundamental mathematical constraints. The results of simulations are consistent with experimental observations of topological core defects in chromonic LCs, as well as flow-driven droplet shape transitions under Couette and Poiseuille flows. This work provides a platform for simulations of multi-component lyotropic LCs that can be extended to systems with multiple interfaces, active materials, and materials subject to external fields.",
          "authors": [
            "Jonathan Salmerón-Hernández",
            "Pablo Zubieta-Rico",
            "Juan de Pablo"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02164",
          "title": "Universality of pseudoentropy for deformed spheres in dS/CFT",
          "abstract": "We determine the universal part of pseudoentropy for small shape deformations of spherical entangling surfaces in the context of de Sitter/conformal field theory (dS/CFT) correspondence. The leading correction at quadratic order in the deformation parameter is controlled by the coefficient of the two-point stress-energy tensor correlator, $C_T$, of the non-unitary dual CFT, and it retains the sign of the unperturbed result, thereby establishing the sphere as a local extremum. The same structure holds in higher-curvature theories, as we check explicitly for quadratic curvature gravity, suggesting a universal behavior across non-unitary holographic CFTs. Our findings extend the Mezei formula to the dS/CFT setting and indicate that the shape dependence of pseudoentropy in dS holography resembles that of entanglement entropy in AdS space.",
          "authors": [
            "Giorgos Anastasiou",
            "Ignacio J. Araya",
            "Avijit Das",
            "Javier Moreno"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02168",
          "title": "Evaluation of carbon incorporation in sulfide thin films grown by hybrid pulsed laser deposition",
          "abstract": "Vapor-pressure-mismatched materials, such as transition metal chalcogenides, have emerged as key electronic, photonic, and quantum materials. Hybrid pulsed laser deposition (hPLD) has become a preferred method for epitaxial or textured growth of these materials; however, unintentional carbon (C) incorporation remains a persistent concern, particularly when using organic chalcogen precursors as safer alternatives to toxic hydrides. The mechanisms governing C incorporation and its impact on film growth and properties in hPLD remain poorly understood. Here, we investigate the influence of C-containing side products generated from organosulfur precursor pyrolysis on ZnS, BaTiS$_3$, and TiS$_2$ thin films grown by hPLD using tert-butyl disulfide (TBDS). Structural characterization via X-ray diffraction and atomic force microscopy, combined with secondary ion mass spectrometry, is used to systematically examine the effects of growth temperature and TBDS partial pressure on film morphology, crystallinity, and C incorporation. Optimal growth temperatures of 400°C, 500°C, and 700°C are identified for ZnS, TiS$_2$, and BaTiS$_3$, respectively. Growth above or below these temperatures leads to increased C incorporation at both the interface and within the film, correlating with degraded texture. In contrast, highly textured films exhibit minimal C content, comparable to films grown without TBDS. For TiS$_2$, C incorporation depends strongly on TBDS pressure, with 10$^{-1}$ Pa identified as the optimal pressure for minimizing contamination. At higher pressures, loss of preferential texture is observed, likely due to C graphitization poisoning the interface and bulk. These results provide new insight into process-induced C impurities in hPLD-grown chalcogenide thin films and have important implications for sulfide-based thin film technologies.",
          "authors": [
            "Claire Wu",
            "Mythili Surendran",
            "Shin Muramoto",
            "Alexander Grutter",
            "Jayakanth Ravichandran"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02169",
          "title": "Methodological Realism and Quantum Mechanics",
          "abstract": "I distinguish two senses in which one can take a given physical theory to be `complete'. On the first, a complete physical theory is one that, in principle, completely describes physical reality. On the second, a complete physical theory is one that provides all of the conceptual resources one needs to describe any (in general probabilistic) physical phenomenon to any level of detail one likes, in principle. I argue that while the (neo-)Everettian approach to interpreting quantum mechanics aims to show that it is complete in the first sense, the (neo-)Bohrian approach begins from an understanding of quantum mechanics as being complete in the second sense. I then discuss some of the essential differences between how classical and quantum theory describe phenomena, and the way in which the quantum description can be thought of as a ``natural generalisation'' (to use Bohr's phrase) of the classical description. Finally, I elaborate upon the two visions of physics from which one can motivate the first and the second sense of completeness, respectively: \\emph{metaphysical realism}, on the one hand, and what I will call \\emph{methodological realism}, on the other -- and discuss what one can say about the significance of the differences between quantum and classical description from each of these points of view. I suggest that there is a sense in which the views of (neo-)Everett and the views of (neo-)Bohr can be understood to be mutually supporting positions, from their respective perspectives, even though they are diametrically opposed.",
          "authors": [
            "Michael E. Cuffaro"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02169",
          "title": "Methodological Realism and Quantum Mechanics",
          "abstract": "I distinguish two senses in which one can take a given physical theory to be `complete'. On the first, a complete physical theory is one that, in principle, completely describes physical reality. On the second, a complete physical theory is one that provides all of the conceptual resources one needs to describe any (in general probabilistic) physical phenomenon to any level of detail one likes, in principle. I argue that while the (neo-)Everettian approach to interpreting quantum mechanics aims to show that it is complete in the first sense, the (neo-)Bohrian approach begins from an understanding of quantum mechanics as being complete in the second sense. I then discuss some of the essential differences between how classical and quantum theory describe phenomena, and the way in which the quantum description can be thought of as a ``natural generalisation'' (to use Bohr's phrase) of the classical description. Finally, I elaborate upon the two visions of physics from which one can motivate the first and the second sense of completeness, respectively: \\emph{metaphysical realism}, on the one hand, and what I will call \\emph{methodological realism}, on the other -- and discuss what one can say about the significance of the differences between quantum and classical description from each of these points of view. I suggest that there is a sense in which the views of (neo-)Everett and the views of (neo-)Bohr can be understood to be mutually supporting positions, from their respective perspectives, even though they are diametrically opposed.",
          "authors": [
            "Michael E. Cuffaro"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02174",
          "title": "Diophantine approximation with primes from short intervals",
          "abstract": "In this paper, we establish hybrid results on Diophantine approximation with primes from short intervals. In particular, we prove the following result in a slightly modified form: If $\\alpha$ is an irrational number having a continued fraction expansion with bounded terms (in particular, if $\\alpha$ is a quadratic irrational), then the number of primes $p$ in the interval $(X-Y,X]$ satisfying $||p\\alpha||<\\delta$ is asymptotically equal to $2\\delta Y/\\log X$, provided that $X\\ge 10$, $X^{2/3+\\varepsilon}\\le Y\\le X/2$ and $X^{\\varepsilon}\\max\\left\\{X^{1/4}Y^{-1/2},X^{2/3}Y^{-1}\\right\\}\\le \\delta\\le 1/2$.",
          "authors": [
            "Stephan Baier",
            "Sayantan Roy"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02176",
          "title": "Emergent Spin-Singlet Pairing in the Frustrated Kagome Metal Sc$_3$Mn$_3$Al$_7$Si$_5$",
          "abstract": "The metallic kagome compound Sc$_3$Mn$_3$Al$_7$Si$_5$ has attracted attention as a candidate platform where geometric frustration and itinerant electrons may cooperate to stabilize a quantum-disordered magnetic ground state. Here, we combine bulk thermodynamic probes, low-noise FIB-device transport, and comprehensive $^{55}$Mn Nuclear Magnetic Resonance (NMR) measurements to elucidate the low-temperature spin dynamics of this system. The bulk data reveal strongly reduced magnetic entropy, a negative magnetoresistance arising from spin scattering, and field-dependent transport indicates the spin fluctuations, while showing no signatures of long-range magnetic order. NMR provides a direct local view of the correlated Mn moments: the nuclear spin-spin relaxation $T_2$ exhibits a pronounced low-temperature enhancement driven by an indirect internuclear coupling through electronic spin fluctuations, whose temperature and distance dependence point to partially gapped low-energy spin excitations. The spin-lattice relaxation rate $T_1^{-1}$ displays a Hebel-Slichter-like coherence peak near \\SI{10}{K}, coincident with the resistivity crossover and a subtle heat-capacity anomaly, indicating the formation of short-range spin-singlet correlations. Together, our results demonstrate that Sc$_3$Mn$_3$Al$_7$Si$_5$ hosts an unconventional correlated state dominated by frustrated, gapped spin dynamics, placing it among the rare metallic kagome systems proximate to a quantum spin liquid.",
          "authors": [
            "R. Guehne",
            "A. K. Sharma",
            "P. Yanda",
            "J. Noky",
            "J. Sichelschmidt",
            "R. Koban",
            "W. Schnelle",
            "C. Shekhar",
            "M. Baenitz",
            "C. Felser"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02181",
          "title": "The Lieb-Robinson condition and the Fréchet topology",
          "abstract": "We define various notions of locality for *-automorphisms of the algebra of observables for an infinitely extended quantum spin system and study their relationship. In particular, we show that the ubiquitous characterization which arises from the Lieb-Robinson bound implies but is not equivalent to continuity with respect to the natural Fréchet topology of almost local observables, which is a non-commutative analog of the Schwartz space.",
          "authors": [
            "Sven Bachmann",
            "Giuseppe De Nittis",
            "Julián Gómez"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02181",
          "title": "The Lieb-Robinson condition and the Fréchet topology",
          "abstract": "We define various notions of locality for *-automorphisms of the algebra of observables for an infinitely extended quantum spin system and study their relationship. In particular, we show that the ubiquitous characterization which arises from the Lieb-Robinson bound implies but is not equivalent to continuity with respect to the natural Fréchet topology of almost local observables, which is a non-commutative analog of the Schwartz space.",
          "authors": [
            "Sven Bachmann",
            "Giuseppe De Nittis",
            "Julián Gómez"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02183",
          "title": "Observation of Electromagnetic Transients in a Nb3Sn 4-layer Dipole Mirror Magnet",
          "abstract": "During testing of the Stress Managed Cosine-Theta dipole mirror magnet SMCTM1, magnet quenches were observed following large voltage spikes in the half-coil voltage taps which preceded normal quench initiation. Following some recent work at CERN measuring power current converter transients in relation to flux jumps, an additional differential current probe was added to the magnet instrumentation. Measurements of this probe, as well as the half coil voltage taps show a fast and substantial current change preceding the quench, hinting at coil motion. A simple model based on relative shift of the inner and outer layer coils was developed which suggests the magnitude of coil shift events is on the estimated relative coil shift from the magnet constraint conditions. The behavior is shown to be reversible and characteristic of stick-slip.",
          "authors": [
            "Steven Krave",
            "Maria Baldini",
            "Igor Novitski"
          ],
          "primary_category": "physics.acc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02184",
          "title": "Visible to Longwave-infrared imaging via an inverse-designed monolithic lens",
          "abstract": "Chromatic aberrations impose a fundamental barrier on optical design, confining most imaging systems to narrow spectral bands with fractional bandwidths typically limited to $\\Delta\\lambda/\\lambda < 1$. Here we report a monolithic, inverse-designed potassium bromide (KBr) lens that achieves broadband, near-achromatic focusing from 0.45 to 14 $\\mu$m, a continuous spectral span covering the visible, near-, mid-, and long-wave infrared. This corresponds to a fractional bandwidth of 1.9, approaching the theoretical limit of 2, while maintaining a nearly constant focal length across the entire range. The 19-mm-diameter, 22.5-mm-focal-length optic enables a single compact platform for hyperspectral imaging, mid-IR microscopy, super-resolution, imaging through scattering media, and simultaneous multi-band and long-range imaging. Coupling the KBr lens with a conventional refractive element further yields a hybrid telescope that extends these capabilities. By uniting inverse design with scalable manufacturing, this approach provides a route toward broadly deployable ultra-broadband imagers for biomedicine, climate and environmental monitoring, and space-based sensing.",
          "authors": [
            "Syed N. Qadri",
            "Apratim Majumder",
            "John D. Hodges",
            "Nicole Brimhall",
            "Freddie Santiago",
            "Rajesh Menon"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02186",
          "title": "Absorption-Based Qubit Estimation in Discrete-Time Quantum Walks",
          "abstract": "We investigate state estimation in discrete-time quantum walks with a single absorbing boundary. Using a spectral approach, we obtain closed expressions for the escape probability as a function of the coin state and the boundary position, and their corresponding classical Fisher information for a simple absorption readout. Comparing with the single-copy quantum Fisher information shows a clear complementarity: near boundaries carry broad information about the population angle of the coin, whereas moderate or distant boundaries reveal phase-sensitive regions. Because a single boundary probes only one information direction, combining two boundary placements yields a full-rank Fisher matrix and tight joint Cramér--Rao bounds, while retaining a binary, tomography-free measurement. We outline an integrated-photonics implementation in which an on-chip sink realizes the absorber and estimate a substantial reduction in configuration count compared to mode-resolved qubit tomography. These results identify absorption in quantum walks as a simple and scalable primitive for coin-state metrology.",
          "authors": [
            "Edgard P. M. Amorim",
            "Lorena R. Cerutti",
            "O. P. de Sá Neto",
            "M. C. de Oliveira"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02191",
          "title": "Josephson scanning tunneling spectroscopy in superconducting phases coexisting with pair-, charge- and spin-density-waves",
          "abstract": "We demonstrate that the recent observations of spatial oscillations in the energy position of the superconducting coherence peaks in the cuprate, transition metal dichalcogenide, iron-based and heavy-fermion superconductors are consistent with the possible presence of a pair-, charge- or spin-density-wave phase. We show that for all three cases, the spatial oscillations of the superconducting order parameter, $\\Delta({\\bf r})$ can be imaged via the critical Josephson current, $I_c({\\bf r})$ measured in Josephson scanning tunneling spectroscopy experiments. Finally, we show that the spatial oscillations of the density waves and of $\\Delta({\\bf r})$ exhibit relative phase shifts of $\\Delta \\phi = 0$ or $\\pi$ for a charge-density wave, and $\\Delta \\phi =\\pi/2$ for the spin-density wave.",
          "authors": [
            "Alyson Laskowski",
            "Jasmin Bedow",
            "Dirk K. Morr"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02196",
          "title": "Coupling between ferroelectric distortions and excitonic properties in PbTiO$_3$",
          "abstract": "PbTiO$_3$ is a ferroelectric perovskite semiconductor with favourable electronic and optical properties, making it suitable for a wide range of applications, including photo-catalysis and (opto)electronic devices. Despite its relevance, an accurate ab-initio description of the optical absorption spectrum and of the impact of ferroelectric distortion on the excitonic properties is still lacking. We combine $G_0W_0$ and Bethe-Salpeter Equation calculations to investigate the electronic and optical properties of PbTiO$_3$, tracking the evolution of its excitonic spectrum along the transition from the cubic paraelectric to the tetragonal ferroelectric phase. As the polar distortion increases, the first absorption peak of the cubic phase splits into two distinct features due to symmetry breaking, which partially lifts the degeneracy of the underlying excitonic state. Crucially, the distortion further introduces an in-plane/out-of-plane anisotropy in the spectra and controls the energy separation between the resulting excitonic branches. These findings highlight the potential for tuning the optical absorption properties of PbTiO$_3$ via the application of an external electric field.",
          "authors": [
            "Pietro Pacchioni",
            "Lorenzo Varrassi",
            "Cesare Franchini"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02199",
          "title": "Mamyshev oscillator based on gain-managed nonlinearity and chirped pulse amplification",
          "abstract": "We experimentally demonstrate a Mamyshev oscillator based on gain-managed nonlinearity and chirped pulse amplification. To the best of our knowledge, this configuration is first presented. Different from other Mamyshev oscillators, the gain-managed nonlinear regime serves as a seed provider instead of a power amplifier in one arm. The output pulse energy over 300nJ has been achieved from the chirped pulsed amplification in another arm. This configuration provided a new approach to design a high-energy ultrafast laser.",
          "authors": [
            "Baofu Zhang",
            "Sihua Lu",
            "Qiurun He",
            "Jing Guo",
            "Zhongxing Jiao",
            "Biao Wang"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02202",
          "title": "Progress in quantum metrology and applications for optical atomic clocks",
          "abstract": "Quantum entanglement offers powerful opportunities for enhancing measurement sensitivity beyond classical limits, with optical atomic clocks serving as a leading platform for such advances. This chapter introduces the principles of entanglement-enhanced quantum metrology and explores their applications to timekeeping. We review the theoretical framework of quantum phase estimation, comparing frequentist and Bayesian approaches, and discuss paradigmatic entangled states such as spin-squeezed and GHZ states. Particular emphasis is placed on the challenges posed by decoherence, which constrain the practical advantages that can be realized in large-scale devices. The discussion then turns to frequency estimation in atomic clocks, highlighting how experimental constraints shape the translation of abstract quantum limits into real performance gains. Finally, we outline emerging directions of contemporary quantum metrology. Together, these developments underscore the increasingly close interplay between quantum information processing and precision metrology.",
          "authors": [
            "Raphael Kaubruegger",
            "Adam M. Kaufman"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02205",
          "title": "Proton Dynamics Scenarios in the Integrable Optics Test Accelerator (IOTA) at Fermilab",
          "abstract": "The Integrable Optics Test Accelerator (IOTA) at Fermilab provides a versatile platform for studying the interplay of space-charge, impedance, and non-linear optics in high-intensity hadron beams within synchrotrons and storage rings. This report examines the parameters and dynamics of 2.5~MeV proton beam operations in two configurations of the bare IOTA lattice: one for demonstrating Non-linear Integrable Optics with the Danilov-Nagaitsev magnet, and the other for use with electron cooling. We offer order-of-magnitude estimates of the transverse emittance growth rate as a function of beam intensity, highlighting contributions from residual gas scattering, intra-beam scattering, and space-charge effects. Under nominal conditions, the beam lifetime is projected to be less than 7~minutes at low intensity with the current vacuum quality, and fewer than 100,000~turns at high intensity due to strong space-charge effects. The calculations presented here will guide strategies to mitigate emittance growth and inform future IOTA experiments.",
          "authors": [
            "N. Banerjee",
            "A. Romanov",
            "G. Stancari",
            "M. Wallbank"
          ],
          "primary_category": "physics.acc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02208",
          "title": "Projective limits of probabilistic symmetries and their applications to random graph limits",
          "abstract": "We couple projective limits of probability measures to direct limits of their symmetry groups. We show that the direct limit group is the group of symmetries of the projective limit probability measure. If projective systems of probability measures represent point processes in increasingly larger finite regions of the same infinite space, then we show that under some additional niceness and consistency assumptions, an extension of the direct limit group is the symmetry group of the projective limit point process in the whole infinite space. The application of these results to random graph limits provides ``shortest paths'' to graphons and graphexes as it recovers these random graph limits as trivial corollaries. Another application example encompasses a broad class of limits of random graphs with bounded average degrees. This class includes a representative collection of paradigmatic random graph models that have attracted significant research attention in diverse areas of science. Our approach thus provides a general unified framework to study limits of very different types of random graphs.",
          "authors": [
            "Pim van der Hoorn",
            "Huck Stepanyants",
            "Dmitri Krioukov"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02208",
          "title": "Projective limits of probabilistic symmetries and their applications to random graph limits",
          "abstract": "We couple projective limits of probability measures to direct limits of their symmetry groups. We show that the direct limit group is the group of symmetries of the projective limit probability measure. If projective systems of probability measures represent point processes in increasingly larger finite regions of the same infinite space, then we show that under some additional niceness and consistency assumptions, an extension of the direct limit group is the symmetry group of the projective limit point process in the whole infinite space. The application of these results to random graph limits provides ``shortest paths'' to graphons and graphexes as it recovers these random graph limits as trivial corollaries. Another application example encompasses a broad class of limits of random graphs with bounded average degrees. This class includes a representative collection of paradigmatic random graph models that have attracted significant research attention in diverse areas of science. Our approach thus provides a general unified framework to study limits of very different types of random graphs.",
          "authors": [
            "Pim van der Hoorn",
            "Huck Stepanyants",
            "Dmitri Krioukov"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02211",
          "title": "Covering by Centralizers",
          "abstract": "In this paper, we consider covers of finite groups by centralizers of elements. We show that the set of centralizers that are maximal under the partial ordering form a cover of the group. We also show that the set of centralizers that are minimal under the partial ordering form a cover of the group. We show for $F$-groups that are nonabelian $p$-groups that the number of distinct nontrivial centralizers is congruent to $1$ modulo $p$.",
          "authors": [
            "Mark L. Lewis",
            "Ryan McCulloch"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02212",
          "title": "Temperature-dependent refractive index of AlGaAs for quantum-photonic devices near the bandgap",
          "abstract": "We present an experimental method to determine the refractive index of $Al_{x}Ga_{1-x}As$ (x = 0.0 - 0.5) from 300 K to 4 K across the 500 - 1100 nm wavelength range. The values are extracted from spectroscopically observed microcavity resonances in thin $Al_{x}Ga_{1-x}As$ membranes embedded between fully and partially reflective gold mirrors. Refined Varshni and Paessler models are used to describe temperature-dependent bandgap shifts and material composition. By tracking resonance shifts and benchmarking against finite-difference time-domain simulations, we derive the dispersive optical response with high precision. This yields a quantitatively improved analytical expression for the refractive index of $Al_{x}Ga_{1-x}As$ matching the experimental results with a coefficient of determination as high as $R^2=0.993$, enabling accurate modeling near the band edge at cryogenic temperatures. The method is straightforward and broadly applicable to other semiconductor systems, offering a valuable tool for the design of micro photonic devices such as quantum light sources.",
          "authors": [
            "Moritz Langer",
            "Sai Abhishikth Dhurjati",
            "Martin Bauer",
            "Yared Getahun Zena",
            "Ahmad Rahimi",
            "Riccardo Bassoli",
            "Frank H. P. Fitzek",
            "Oliver G. Schmidt",
            "Caspar Hopfmann"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02212",
          "title": "Temperature-dependent refractive index of AlGaAs for quantum-photonic devices near the bandgap",
          "abstract": "We present an experimental method to determine the refractive index of $Al_{x}Ga_{1-x}As$ (x = 0.0 - 0.5) from 300 K to 4 K across the 500 - 1100 nm wavelength range. The values are extracted from spectroscopically observed microcavity resonances in thin $Al_{x}Ga_{1-x}As$ membranes embedded between fully and partially reflective gold mirrors. Refined Varshni and Paessler models are used to describe temperature-dependent bandgap shifts and material composition. By tracking resonance shifts and benchmarking against finite-difference time-domain simulations, we derive the dispersive optical response with high precision. This yields a quantitatively improved analytical expression for the refractive index of $Al_{x}Ga_{1-x}As$ matching the experimental results with a coefficient of determination as high as $R^2=0.993$, enabling accurate modeling near the band edge at cryogenic temperatures. The method is straightforward and broadly applicable to other semiconductor systems, offering a valuable tool for the design of micro photonic devices such as quantum light sources.",
          "authors": [
            "Moritz Langer",
            "Sai Abhishikth Dhurjati",
            "Martin Bauer",
            "Yared Getahun Zena",
            "Ahmad Rahimi",
            "Riccardo Bassoli",
            "Frank H. P. Fitzek",
            "Oliver G. Schmidt",
            "Caspar Hopfmann"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02215",
          "title": "Magnetoelectric effect in the mixed valence polyoxovanadate cage V$_{12}$",
          "abstract": "Development of spintronic and quantum computing devices increases demand for efficient, energy saving method of spin manipulation at molecular scale. Polyoxovanadate molecular magnets being susceptible to both electric and magnetic fields may serve here as a good base material. In this paper two isostructural anions [V$_{12}$As$_8$O$_{40}$(HCO$_2$)]$^{n-}$ (with $n=3,5$) featuring two different mixed-valence states with itinerant and localized valence electrons are studied. The impact of the electric field on their magnetic properties is investigated by means of two complementary methods informed by magnetic measurements: effective Hamiltonian calculations and density functional theory. It is demonstrated that the magnetoelectric effect in theses molecules is induced mostly by relocation of itinerant electrons, is highly anisotropic, depends on the valence state and can be detected even at room temperature. These findings can pave the way to practical applications in which an electric field control over spin state is required.",
          "authors": [
            "Piotr Kozłowski"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02215",
          "title": "Magnetoelectric effect in the mixed valence polyoxovanadate cage V$_{12}$",
          "abstract": "Development of spintronic and quantum computing devices increases demand for efficient, energy saving method of spin manipulation at molecular scale. Polyoxovanadate molecular magnets being susceptible to both electric and magnetic fields may serve here as a good base material. In this paper two isostructural anions [V$_{12}$As$_8$O$_{40}$(HCO$_2$)]$^{n-}$ (with $n=3,5$) featuring two different mixed-valence states with itinerant and localized valence electrons are studied. The impact of the electric field on their magnetic properties is investigated by means of two complementary methods informed by magnetic measurements: effective Hamiltonian calculations and density functional theory. It is demonstrated that the magnetoelectric effect in theses molecules is induced mostly by relocation of itinerant electrons, is highly anisotropic, depends on the valence state and can be detected even at room temperature. These findings can pave the way to practical applications in which an electric field control over spin state is required.",
          "authors": [
            "Piotr Kozłowski"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02215",
          "title": "Magnetoelectric effect in the mixed valence polyoxovanadate cage V$_{12}$",
          "abstract": "Development of spintronic and quantum computing devices increases demand for efficient, energy saving method of spin manipulation at molecular scale. Polyoxovanadate molecular magnets being susceptible to both electric and magnetic fields may serve here as a good base material. In this paper two isostructural anions [V$_{12}$As$_8$O$_{40}$(HCO$_2$)]$^{n-}$ (with $n=3,5$) featuring two different mixed-valence states with itinerant and localized valence electrons are studied. The impact of the electric field on their magnetic properties is investigated by means of two complementary methods informed by magnetic measurements: effective Hamiltonian calculations and density functional theory. It is demonstrated that the magnetoelectric effect in theses molecules is induced mostly by relocation of itinerant electrons, is highly anisotropic, depends on the valence state and can be detected even at room temperature. These findings can pave the way to practical applications in which an electric field control over spin state is required.",
          "authors": [
            "Piotr Kozłowski"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02218",
          "title": "Dominance regions for affine cluster algebras",
          "abstract": "We determine dominance regions associated to cluster algebras of affine type. In the most interesting cases, the dominance region is a line segment, which we describe explicitly. Motivations for this work include a project to determine all pointed bases for cluster algebras of affine type and a separate project to determine all theta functions in the affine case. The proofs draw on known results from the doubled Cambrian fan and almost-positive roots models, as well as a new tool that we develop: a detailed description of neighboring seeds of affine type (seeds that are, in some sense, as close as possible to the boundary of the g-vector fan).",
          "authors": [
            "Nathan Reading",
            "Dylan Rupel",
            "Salvatore Stella"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02220",
          "title": "Non-solitary wave response generated by \"soft\" striker impact on strongly nonlinear weakly dissipative granular chains",
          "abstract": "It is well known that striker impact on strongly nonlinear, non-dissipative or weakly dissipative granular chains assembled from spheres (or cylinders with flat ends and spheres) having similar masses results in strongly nonlinear Nesterenko solitary waves on a very short distance from the impacted end. This paper presents the first experimental results on the nature of the wave response excited by striker impact on strongly nonlinear weakly dissipative discrete chains assembled from cylinders with flat ends and spheres having similar masses depending on the ramp time of the incoming pulse. Variation of the pulse ramp time was accomplished using \"hard\" and \"soft\" striker impact. In the case of \"hard\" impact, the incoming pulse with relatively short ramp time was split into Nesterenko solitary waves after traveling about 20 particles as in previous publications. The \"soft\" impact by the same striker with the same velocity was achieved by placing a small mass PTFE spherical particle inside a PTFE O-ring at the top of the first cylinder resulting in significantly longer ramp time of incoming pulse. The incoming pulse generated by \"soft\" impact did not split into a train of solitary waves despite the initial steepening of the leading front due to strong nonlinearity. Instead, it traveled as a shock-like stress wave a long distance of 131 particles. Thus, the generation of a train of solitary waves or shock-like stress wave in a weakly dissipative, strongly nonlinear discrete chain depends on the duration of the incoming pulse ramp. Ramping incoming pulse resulted in dramatic decrease of shock-like stress wave amplitude in comparison with amplitude of the leading solitary wave in case of \"hard\" impact.",
          "authors": [
            "Po-Hsun Chiu",
            "Vitali F. Nesterenko"
          ],
          "primary_category": "nlin.PS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02221",
          "title": "Thermodynamic Entropy as Information -- A compression-based demonstration of the Shannon-Boltzmann equivalence in condensed matter",
          "abstract": "We demonstrate that Shannon's information entropy and the thermodynamic entropy of Boltzmann and Gibbs are quantitatively equivalent for real condensed-matter systems. By interpreting atomic configurations as information sources, we compute entropy directly from the compressibility of molecular-dynamics trajectories, without physical partitioning or empirical modeling. A custom lossy-compression algorithm measures the minimum number of bits required to describe a microstate at finite precision, and this bit count maps exactly to thermodynamic entropy through the Shannon-Boltzmann relation. The method reproduces benchmark entropies for metals, semiconductors, oxides, and refractory ceramics in both solid and liquid phases, establishing information as the fundamental quantity underlying thermodynamic disorder. This equivalence unifies information theory and statistical mechanics, providing a general and computationally efficient framework for determining entropies and free energies directly from atomic data.",
          "authors": [
            "Dallin Fisher",
            "Qi-Jun Hong"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02222",
          "title": "Chemical potential of magnon polarons",
          "abstract": "Using a rotationally invariant formulation of spin-lattice coupling, we derive a rigorous definition of the chemical potential for magnon-polaron quasiparticles in collinear ferromagnets (FMs) and antiferromagnets (AFMs), valid when magnetoelastic scattering equilibrates magnons and acoustic phonons on timescales much shorter than those associated with quasiparticle-nonconserving relaxation processes. While our microscopic framework applies to generic magnon-phonon interactions, here we focus on high-symmetry crystals where the two transverse acoustic modes form a degenerate doublet. This doublet can combine into circularly polarized phonons, making the chiral selectivity of the coupling manifest: the FM magnon mode hybridizes only with the co-rotating phonon, whereas in collinear AFMs each magnon branch of opposite handedness couples to the phonon of the same chirality. We show that, in both FM and AFM systems, the nonequilibrium magnon-polaron gas is governed by a single chemical potential conjugate to the conserved axial angular momentum. In FMs, the two hybrid branches in the co-rotating sector share this chemical potential, weighted by their magnonic fractions; in AFMs, the four magnon-polaron branches split into two chiral sectors that carry opposite angular momenta and couple with opposite sign to the same chemical potential. Building on this microscopic thermodynamic framework, we formulate a Boltzmann transport theory for magnon-polarons and derive compact expressions for angular-momentum and heat currents that interpolate continuously to the decoupled regime and reproduce the phenomenological magnon-polaron transport framework underlying previous spin Seebeck analyses.",
          "authors": [
            "Violet Williams",
            "Benedetta Flebus"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02225",
          "title": "Perfect impedance matching unlocks sensitive radio-frequency reflectometry in 2D material quantum dots",
          "abstract": "Two-dimensional (2D) materials are attractive platforms for realizing high-performance quantum bits (qubits). However, radio-frequency (RF) charge detection, which is a key technique for qubits readout, remains challenging in such systems. We demonstrate RF reflectometry with impedance matching for high-resistance quantum dot devices based on bilayer graphene and molybdenum disulfide. By integrating a tunable strontium titanate (SrTiO3) varactor into a resonant circuit, we achieve nearly perfect impedance matching, enabling sensitive charge detection. The demodulated RF signal clearly shows Coulomb oscillations, and the SrTiO3 varactor exhibits robustness against both magnetic fields and voltage noise on the varactor. Our results establish SrTiO3 varactors as effective tunable matching components for RF reflectometry in high-resistance 2D material quantum devices, providing a foundation for high-speed qubits readout.",
          "authors": [
            "Motoya Shinozaki",
            "Akitomi Shirachi",
            "Yuta Kera",
            "Tomoya Johmen",
            "Shunsuke Yashima",
            "Aruto Hosaka",
            "Tsuyoshi Yoshida",
            "Takeshi Kumasaka",
            "Yusuke Kozuka",
            "Tomohiro Otsuka"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02226",
          "title": "Representations of finite matrix monoids",
          "abstract": "Let $\\mathfrak{M}_n$ be the multiplicative monoid of $n \\times n$ matrices over a finite field. The monoid algebra $\\mathbf{C}[\\mathfrak{M}_n]$ has been studied for several decades. One of the important early results is Kovács' theorem that the two-sided ideal spanned by matrices of rank at most $r$ has a unit. Our most significant result is an explicit formula for this unit. Prior to our work, such a formula was only known in a few examples. We also study the module theory of $\\mathbf{C}[\\mathfrak{M}_n]$. We explicitly describe the simple modules, and establish induction and restriction rules. We show that the simple decomposition of an arbitrary module can be determined using character theory of finite general linear groups; this relies on a Pieri rule of Gurevich--Howe. We also establish a version of Schur--Weyl duality for $\\mathbf{C}[\\mathfrak{M}_n]$. Many of these results hold over more general coefficient fields.",
          "authors": [
            "Nate Harman",
            "Andrew Snowden",
            "Elad Zelingher"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02229",
          "title": "An infinite-dimensional mountain pass theorem with applications to nonlinear elliptic systems",
          "abstract": "The purpose of this paper is to establish a critical point theorem, which is an infinite-dimensional generalization of the classical generalized Mountain Pass Theorem of P. H. Rabinowitz \\cite[Theorem 5.3]{Ra}. As application, we obtain the existence of at least one solution to a semilinear elliptic systems with indefinite weights in $\\mathbb{R}^2$.",
          "authors": [
            "Ablanvi Songo",
            "Fabrice Colin"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02232",
          "title": "Lambert $W$-function and Gauss class number one conjecture",
          "abstract": "We study fixed points of a function arising in a representation theory of the Drinfeld modules by the bounded linear operators on a Hilbert space. We prove that such points correspond to number fields of the class number one. As an application, one gets a solution to the Gauss conjecture for the real quadratic fields of class number one.",
          "authors": [
            "Igor V. Nikolaev"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02234",
          "title": "The $O(N)$ Free-Scalar and Wilson-Fisher Conformal Field Theories on the Fuzzy Sphere",
          "abstract": "The fuzzy-sphere regularization is an emerging numerical and theoretical technique for studying conformal field theories (CFTs). In this paper, we apply it to the $O(N)$ vector model, one of the most prominent theories for critical behavior in three space-time dimensions. We construct a model that realizes the $O(N)$ Wilson-Fisher and free-scalar CFTs for general $N$. For $N=2,3,4$, we present numerical evidence including the operator spectra and correlation functions in agreement with conformal symmetry and conformal bootstrap results.",
          "authors": [
            "Wenhan Guo",
            "Zheng Zhou",
            "Tzu-Chieh Wei",
            "Yin-Chen He"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02234",
          "title": "The $O(N)$ Free-Scalar and Wilson-Fisher Conformal Field Theories on the Fuzzy Sphere",
          "abstract": "The fuzzy-sphere regularization is an emerging numerical and theoretical technique for studying conformal field theories (CFTs). In this paper, we apply it to the $O(N)$ vector model, one of the most prominent theories for critical behavior in three space-time dimensions. We construct a model that realizes the $O(N)$ Wilson-Fisher and free-scalar CFTs for general $N$. For $N=2,3,4$, we present numerical evidence including the operator spectra and correlation functions in agreement with conformal symmetry and conformal bootstrap results.",
          "authors": [
            "Wenhan Guo",
            "Zheng Zhou",
            "Tzu-Chieh Wei",
            "Yin-Chen He"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02235",
          "title": "Enhanced readout contrast of V2 ensembles in 4H-SiC through resonant optical excitation",
          "abstract": "The V2 silicon vacancy defect in 4H-SiC has emerged as a promising system for quantum technologies due to its favorable optical and spin properties and the advantages of the SiC host. However, the readout contrast - an important benchmark for quantum sensing - of V2 ensembles for optically-detected magnetic resonance (ODMR) is relatively low, usually <1$\\%$ at room temperature. To overcome this challenge, we resonantly excite the V2 ensembles at cryogenic temperatures and compare the results with the off-resonant case. We report a maximum ODMR contrast of 50$\\%$ with only 2 $\\mu$W of resonant laser power, almost 100 times improvement over off-resonant excitation. We attribute this high readout contrast to a subset of V2 centers that have one spin-selective optical transition resonant with the laser. The ODMR contrast decreases with temperature, approaching the non-resonant contrast by 60 K, likely due to broadening of the optical transition linewidths. We achieve a maximum sensitivity of 100 nT/$\\sqrt{Hz}$ with a resonant laser power of 300 $\\mu$W, while 100 times more non-resonant excitation power is needed to achieve comparable sensitivity.",
          "authors": [
            "Infiter Tathfif",
            "Samuel G. Carter"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02236",
          "title": "Snell meets Fagnano. Path optimization through an imperfect mirror",
          "abstract": "The renowned Fagnano problem asks for the inscribed triangle of minimal perimeter within a given reference triangle. Equivalently, it seeks a billiard trajectory inside the triangle that closes after three reflections. In this note, we consider a modification of this classical problem: finding the inscribed triangle of minimal weighted perimeter -- or, equivalently, the periodic trajectory of a Snell billiard.",
          "authors": [
            "Maxim Arnold",
            "Jaewoo Park"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02239",
          "title": "Evolution of the eigenvalues and eigenstates of the single-particle reduced density operator during two-particle scattering",
          "abstract": "A particle initially in a pure state but interacting with some environment evolves into a discrete ensemble of pure states, the eigenstates of its reduced density operator, with ensemble probabilities given by the corresponding eigenvalues. In this work, we use numerics to present explicit results for the time-dependence of these eigenvalues and eigenstates for simple scattering experiments in one and two dimensions. This provides a time-resolved picture of the scattering process, showing in detail how an initial state described entirely in terms of continuous parameters evolves into a discrete set of possible outcomes, each with an associated probability and time-evolving wavefunction. We find that for scattering of Gaussian wavepackets in one dimension, the late time spectrum is dominated by two large eigenvalues nearly equal to the transmission and reflection probabilities associated with the central value of momentum. The corresponding eigenstates appear as single-peaked reflected or transmitted wavepackets. The remaining smaller eigenvalues, which increase to a maximum during scattering and then decrease to small values, correspond to reflected or transmitted wavepackets with multiple spatially separated parts. In this case and also for two-dimensional scattering, we find that successively smaller eigenvalues correspond to probability distributions with successively more peaks. These multi-peaked states correspond to outcomes of the scattering experiment where a particle initially in a single wavepacket ends up in a superposition of separated wavepackets after scattering.",
          "authors": [
            "Arsam Najafian",
            "Mark Van Raamsdonk"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02239",
          "title": "Evolution of the eigenvalues and eigenstates of the single-particle reduced density operator during two-particle scattering",
          "abstract": "A particle initially in a pure state but interacting with some environment evolves into a discrete ensemble of pure states, the eigenstates of its reduced density operator, with ensemble probabilities given by the corresponding eigenvalues. In this work, we use numerics to present explicit results for the time-dependence of these eigenvalues and eigenstates for simple scattering experiments in one and two dimensions. This provides a time-resolved picture of the scattering process, showing in detail how an initial state described entirely in terms of continuous parameters evolves into a discrete set of possible outcomes, each with an associated probability and time-evolving wavefunction. We find that for scattering of Gaussian wavepackets in one dimension, the late time spectrum is dominated by two large eigenvalues nearly equal to the transmission and reflection probabilities associated with the central value of momentum. The corresponding eigenstates appear as single-peaked reflected or transmitted wavepackets. The remaining smaller eigenvalues, which increase to a maximum during scattering and then decrease to small values, correspond to reflected or transmitted wavepackets with multiple spatially separated parts. In this case and also for two-dimensional scattering, we find that successively smaller eigenvalues correspond to probability distributions with successively more peaks. These multi-peaked states correspond to outcomes of the scattering experiment where a particle initially in a single wavepacket ends up in a superposition of separated wavepackets after scattering.",
          "authors": [
            "Arsam Najafian",
            "Mark Van Raamsdonk"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02241",
          "title": "High-Precision Simulations of the Parity Conserving Directed Percolation Universality Class in 1+1 Dimensions",
          "abstract": "Next to the directed percolation (DP) universality class, parity conserving directed percolation (pcDP; also called parity conserving branching annihilating random walks, pcBARW) is the second-most important model with an absorbing state transition. Its distinction from ordinary DP is that particle number is conserved modulo 2, which means in 1 dimension of space that there are two degenerate vacuum (absorbing) states. Particles can be interpreted as domain walls between them, and there are two distinct sectors in systems with a finite initial number of particles: Realizations with even and odd particle numbers show different scaling behaviors. An intriguing feature of pcDP it is that some of its critical exponents seem to be very simple rational numbers. The most prominent is the one describing the average number of particles (or active sites) in the even sector, which is asymptotically constant. In contrast, the dynamical critical exponent (which is the same in both sectors) seems not close to any simple rational. Finally, the order parameter exponent (which is also the same in both sectors) is, according to the most precise previous simulations, $\\beta = 1.020(5)$, and thus very close but not really compatible with a simple rational. We present high statistics simulations which clarifies this situation, and which indicate several other intriguing properties of pcPD clusters. In particular, we find $\\beta = 1.000$ with the error in the next digit.",
          "authors": [
            "Peter Grassberger"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02242",
          "title": "Phase Transitions as Emergent Geometric Phenomena: A Deterministic Entropy Evolution Law",
          "abstract": "We show that thermodynamics can be formulated naturally from the intrinsic geometry of phase space alone-without postulating an ensemble, which instead emerges from the geometric structure itself. Within this formulation, phase transitions are encoded in the geometry of constant-energy manifold: entropy and its derivatives follow from a deterministic equation whose source is built from curvature invariants. As energy increases, geometric transformations in energy-manifold structure drive thermodynamic responses and characterize criticality. We validate this framework through explicit analysis of paradigmatic systems-the 1D XY mean-field model and 2D $\\phi^4$ theory-showing that geometric transformations in energy-manifold structure characterize criticality quantitatively. The framework applies universally to long-range interacting systems and in ensemble-inequivalence regimes.",
          "authors": [
            "Loris Di Cairano"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02244",
          "title": "A novel method for thermal noise reduction, enabling measurements of broadband, low-amplitude electron temperature fluctuations using individual radiometer channels",
          "abstract": "A new analysis method has been developed for measurements of broadband, low-amplitude turbulent electron temperature fluctuations in fusion plasmas using individual radiometer channels of a Correlation Electron Cyclotron Emission (CECE) diagnostic. This method takes advantage of differences in the correlation time of thermal noise compared to the correlation time of plasma fluctuations in fusion reactors. The validation of this single-channel method is demonstrated using comparisons with the standard dual-channel radiometer spectral decorrelation method for measurements of turbulent electron temperature fluctuations in the core and edge of low confinement (L), improved confinement (I), and high confinement (H)-mode plasmas at the ASDEX Upgrade tokamak.",
          "authors": [
            "Christian Yoo",
            "Garrard D. Conway",
            "Jacob Schellpfeffer",
            "Rachel Bielajew",
            "Klara Hoefler",
            "Diego J. Cruz-Zabala",
            "David Cusick",
            "William Burke",
            "Branka Vanovac",
            "Anne E. White",
            "ASDEX Upgrade Team"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02250",
          "title": "A New Proof of the Abstract Random Tensor Estimate by Deng, Nahmod, and Yue",
          "abstract": "We provide a new proof of the abstract random tensor estimate, which was established by Deng, Nahmod, and Yue (2022) using the moment method. The key new tool is the direct use of the non-commutative Khintchine inequality with the probabilistic decoupling of the product of Gaussians. We use Hermite and generalized Laguerre-type polynomials allow us to account for pairings in the real and complex-valued Gaussians, respectively, and remove the square-free (tetrahedral) requirement.",
          "authors": [
            "Claire Kaneshiro"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02253",
          "title": "Cancellation Identities and Renormalization",
          "abstract": "We construct a manifest gauge invariant renormalization framework by first introducing a perturbative BRST Feynman graph complex and then combining it with Connes--Kreimer renormalization theory: To this end, we first formalize the cancellation identities of 't Hooft (1971), which were used to prove the absence of gauge anomalies in Quantum Yang--Mills theories. Specifically, we start with some reasonable axioms of (generalized) gauge theories and then present the most general version of cancellation identities ensuring transversality. Then, we construct a perturbative BRST Feynman graph complex, whose cohomology groups consist of transversal invariant linear combinations of Feynman graphs. We prove that the cohomology groups are zero in odd degree and generated by connected combinatorial Green's functions in even degree, with a corresponding number of external ghost edges. Ultimately, we then formulate the renormalization Hopf algebra on these cohomology groups, which directly links to Hopf subalgebras for multiplicative renormalization. Finally, we exemplify the developed theory with Quantum Yang--Mills theory and (effective) Quantum General Relativity.",
          "authors": [
            "David Prinz"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02253",
          "title": "Cancellation Identities and Renormalization",
          "abstract": "We construct a manifest gauge invariant renormalization framework by first introducing a perturbative BRST Feynman graph complex and then combining it with Connes--Kreimer renormalization theory: To this end, we first formalize the cancellation identities of 't Hooft (1971), which were used to prove the absence of gauge anomalies in Quantum Yang--Mills theories. Specifically, we start with some reasonable axioms of (generalized) gauge theories and then present the most general version of cancellation identities ensuring transversality. Then, we construct a perturbative BRST Feynman graph complex, whose cohomology groups consist of transversal invariant linear combinations of Feynman graphs. We prove that the cohomology groups are zero in odd degree and generated by connected combinatorial Green's functions in even degree, with a corresponding number of external ghost edges. Ultimately, we then formulate the renormalization Hopf algebra on these cohomology groups, which directly links to Hopf subalgebras for multiplicative renormalization. Finally, we exemplify the developed theory with Quantum Yang--Mills theory and (effective) Quantum General Relativity.",
          "authors": [
            "David Prinz"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02253",
          "title": "Cancellation Identities and Renormalization",
          "abstract": "We construct a manifest gauge invariant renormalization framework by first introducing a perturbative BRST Feynman graph complex and then combining it with Connes--Kreimer renormalization theory: To this end, we first formalize the cancellation identities of 't Hooft (1971), which were used to prove the absence of gauge anomalies in Quantum Yang--Mills theories. Specifically, we start with some reasonable axioms of (generalized) gauge theories and then present the most general version of cancellation identities ensuring transversality. Then, we construct a perturbative BRST Feynman graph complex, whose cohomology groups consist of transversal invariant linear combinations of Feynman graphs. We prove that the cohomology groups are zero in odd degree and generated by connected combinatorial Green's functions in even degree, with a corresponding number of external ghost edges. Ultimately, we then formulate the renormalization Hopf algebra on these cohomology groups, which directly links to Hopf subalgebras for multiplicative renormalization. Finally, we exemplify the developed theory with Quantum Yang--Mills theory and (effective) Quantum General Relativity.",
          "authors": [
            "David Prinz"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02253",
          "title": "Cancellation Identities and Renormalization",
          "abstract": "We construct a manifest gauge invariant renormalization framework by first introducing a perturbative BRST Feynman graph complex and then combining it with Connes--Kreimer renormalization theory: To this end, we first formalize the cancellation identities of 't Hooft (1971), which were used to prove the absence of gauge anomalies in Quantum Yang--Mills theories. Specifically, we start with some reasonable axioms of (generalized) gauge theories and then present the most general version of cancellation identities ensuring transversality. Then, we construct a perturbative BRST Feynman graph complex, whose cohomology groups consist of transversal invariant linear combinations of Feynman graphs. We prove that the cohomology groups are zero in odd degree and generated by connected combinatorial Green's functions in even degree, with a corresponding number of external ghost edges. Ultimately, we then formulate the renormalization Hopf algebra on these cohomology groups, which directly links to Hopf subalgebras for multiplicative renormalization. Finally, we exemplify the developed theory with Quantum Yang--Mills theory and (effective) Quantum General Relativity.",
          "authors": [
            "David Prinz"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02254",
          "title": "Deterministic construction of typical networks in network models",
          "abstract": "It is often desirable to assess how well a given dataset is described by a given model. In network science, for instance, one often wants to say that a given real-world network appears to come from a particular network model. In statistical physics, the corresponding problem is about how typical a given state, representing real-world data, is in a particular statistical ensemble. One way to address this problem is to measure the distance between the data and the most typical state in the ensemble. Here, we identify the conditions that allow us to define this most typical state. These conditions hold in a wide class of grand canonical ensembles and their random mixtures. Our main contribution is a deterministic construction of a state that converges to this most typical state in the thermodynamic limit. This construction involves rounds of derandomization procedures, some of which deal with derandomizing point processes, an uncharted territory. We illustrate the construction on one particular network model, deterministic hyperbolic graphs, and its application to real-world networks, many of which we find are close to the most typical network in the model. While our main focus is on network models, our results are very general and apply to any grand canonical ensembles and their random mixtures satisfying certain niceness requirements.",
          "authors": [
            "Narayan G. Sabhahit",
            "Moritz Laber",
            "Harrison Hartle",
            "Jasper van der Kolk",
            "Samuel V. Scarpino",
            "Brennan Klein",
            "Dmitri Krioukov"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02254",
          "title": "Deterministic construction of typical networks in network models",
          "abstract": "It is often desirable to assess how well a given dataset is described by a given model. In network science, for instance, one often wants to say that a given real-world network appears to come from a particular network model. In statistical physics, the corresponding problem is about how typical a given state, representing real-world data, is in a particular statistical ensemble. One way to address this problem is to measure the distance between the data and the most typical state in the ensemble. Here, we identify the conditions that allow us to define this most typical state. These conditions hold in a wide class of grand canonical ensembles and their random mixtures. Our main contribution is a deterministic construction of a state that converges to this most typical state in the thermodynamic limit. This construction involves rounds of derandomization procedures, some of which deal with derandomizing point processes, an uncharted territory. We illustrate the construction on one particular network model, deterministic hyperbolic graphs, and its application to real-world networks, many of which we find are close to the most typical network in the model. While our main focus is on network models, our results are very general and apply to any grand canonical ensembles and their random mixtures satisfying certain niceness requirements.",
          "authors": [
            "Narayan G. Sabhahit",
            "Moritz Laber",
            "Harrison Hartle",
            "Jasper van der Kolk",
            "Samuel V. Scarpino",
            "Brennan Klein",
            "Dmitri Krioukov"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02254",
          "title": "Deterministic construction of typical networks in network models",
          "abstract": "It is often desirable to assess how well a given dataset is described by a given model. In network science, for instance, one often wants to say that a given real-world network appears to come from a particular network model. In statistical physics, the corresponding problem is about how typical a given state, representing real-world data, is in a particular statistical ensemble. One way to address this problem is to measure the distance between the data and the most typical state in the ensemble. Here, we identify the conditions that allow us to define this most typical state. These conditions hold in a wide class of grand canonical ensembles and their random mixtures. Our main contribution is a deterministic construction of a state that converges to this most typical state in the thermodynamic limit. This construction involves rounds of derandomization procedures, some of which deal with derandomizing point processes, an uncharted territory. We illustrate the construction on one particular network model, deterministic hyperbolic graphs, and its application to real-world networks, many of which we find are close to the most typical network in the model. While our main focus is on network models, our results are very general and apply to any grand canonical ensembles and their random mixtures satisfying certain niceness requirements.",
          "authors": [
            "Narayan G. Sabhahit",
            "Moritz Laber",
            "Harrison Hartle",
            "Jasper van der Kolk",
            "Samuel V. Scarpino",
            "Brennan Klein",
            "Dmitri Krioukov"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02257",
          "title": "Entropies associated with orbits of finite groups",
          "abstract": "For certain groups, parabolic subgroups appear as stabilizers of flags of sets or vector spaces. Quotients by these parabolic subgroups represent orbits of flags, and their cardinalities asymptotically reveal entropies (as rates of exponential or superexponential growth). The multiplicative \"chain rules\" that involve these cardinalities induce, asymptotically, additive analogues for entropies. Many traditional formulas in information theory correspond to quotients of symmetric groups, which are a particular kind of reflection group; in this case, the cardinalities of orbits are given by multinomial coefficients and are asymptotically related to Shannon entropy. One can treat similarly quotients of the general linear groups over a finite field; in this case, the cardinalities of orbits are given by $q$-multinomials and are asymptotically related to the Tsallis 2-entropy. In this contribution, we consider other finite reflection groups as well as the symplectic group as an example of a classical group over a finite field (groups of Lie type). In both cases, the groups are classified by Dynkin diagrams into infinite series of similar groups $A_n$, $B_n$, $C_n$, $D_n$ and a finite number of exceptional ones. The $A_n$ series consists of the symmetric groups (reflection case) and general linear groups (Lie case). Some of the other series, studied here from an information-theoretic perspective for the first time, are linked to new entropic functionals.",
          "authors": [
            "Ryan Leal",
            "Jingtong Sun",
            "Juan Pablo Vigneaux"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02257",
          "title": "Entropies associated with orbits of finite groups",
          "abstract": "For certain groups, parabolic subgroups appear as stabilizers of flags of sets or vector spaces. Quotients by these parabolic subgroups represent orbits of flags, and their cardinalities asymptotically reveal entropies (as rates of exponential or superexponential growth). The multiplicative \"chain rules\" that involve these cardinalities induce, asymptotically, additive analogues for entropies. Many traditional formulas in information theory correspond to quotients of symmetric groups, which are a particular kind of reflection group; in this case, the cardinalities of orbits are given by multinomial coefficients and are asymptotically related to Shannon entropy. One can treat similarly quotients of the general linear groups over a finite field; in this case, the cardinalities of orbits are given by $q$-multinomials and are asymptotically related to the Tsallis 2-entropy. In this contribution, we consider other finite reflection groups as well as the symplectic group as an example of a classical group over a finite field (groups of Lie type). In both cases, the groups are classified by Dynkin diagrams into infinite series of similar groups $A_n$, $B_n$, $C_n$, $D_n$ and a finite number of exceptional ones. The $A_n$ series consists of the symmetric groups (reflection case) and general linear groups (Lie case). Some of the other series, studied here from an information-theoretic perspective for the first time, are linked to new entropic functionals.",
          "authors": [
            "Ryan Leal",
            "Jingtong Sun",
            "Juan Pablo Vigneaux"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02264",
          "title": "Microwave Circulation in an Extended Josephson Junction Ring",
          "abstract": "Circulators are nonreciprocal devices that enable directional signal routing. Nonreciprocity, which requires time-reversal symmetry breaking, can be produced in waveguides in which the propagation medium moves relative to the waveguide at a moderate fraction of the wave speed. Motivated by this effect, here we propose a design for nonreciprocal microwave transmission based on an extended, annular Josephson junction, in which the propagation medium consists of a train of moving fluxons. We show how to harness this to build a high-quality resonant microwave circulator, and we theoretically evaluate the anticipated performance of such a device.",
          "authors": [
            "Dat Thanh Le",
            "Arkady Fedorov",
            "Thomas M. Stace"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02267",
          "title": "Free boundary q-Whittaker and Hall-Littlewood processes",
          "abstract": "We study the free boundary $q$-Whittaker and Hall--Littlewood processes, two probability measures on sequences of partitions. We prove that a certain observable of the free boundary $q$-Whittaker process exhibits a $(q,t)$ symmetry after a random shift, generalizing a previous result of Imamura, Mucciconi, and Sasamoto, and an extension of that result due to the first author. Our proof is completely different, and as part of our proof, we find contour integral formulas for the free boundary $q$-Whittaker process. We also show a matching between certain observables in the free boundary Hall--Littlewood process and a quasi-open six vertex model, and explain how work of Finn and Vanicat gives an evaluation of a bounded sum over skew Hall--Littlewood functions as a rectangular Koornwinder polynomial.",
          "authors": [
            "Jimmy He",
            "Michael Wheeler"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02267",
          "title": "Free boundary q-Whittaker and Hall-Littlewood processes",
          "abstract": "We study the free boundary $q$-Whittaker and Hall--Littlewood processes, two probability measures on sequences of partitions. We prove that a certain observable of the free boundary $q$-Whittaker process exhibits a $(q,t)$ symmetry after a random shift, generalizing a previous result of Imamura, Mucciconi, and Sasamoto, and an extension of that result due to the first author. Our proof is completely different, and as part of our proof, we find contour integral formulas for the free boundary $q$-Whittaker process. We also show a matching between certain observables in the free boundary Hall--Littlewood process and a quasi-open six vertex model, and explain how work of Finn and Vanicat gives an evaluation of a bounded sum over skew Hall--Littlewood functions as a rectangular Koornwinder polynomial.",
          "authors": [
            "Jimmy He",
            "Michael Wheeler"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02271",
          "title": "Three Dixon-Rosenfeld Planes",
          "abstract": "Rosenfeld postulated ``generalized'' projective planes, which exploit a correspondence between rank-one idempotents of Jordan algebras $\\mathfrak{J}_3(\\mathbb{A})$ and points of projective planes $\\mathbb{A}P^2$. The isometry groups of the generalized projective planes (which were later defined rigorously as homogeneous spaces) are entries of the Tits-Freudenthal magic square. Given recent interest in the Dixon algebra $\\mathbb{R}\\otimes\\mathbb{C}\\otimes\\mathbb{H}\\otimes\\mathbb{O}$, we extend Rosenfeld's approach and present three new coset manifolds. These \"Dixon-Rosenfeld planes\" have isometry algebras that are obtained from Tits' magic formula and involve all tensorial components of the Dixon algebra. We show that these are the only three planes obtainable with Tits' formula that preserve the analogy with Rosenfeld's planes. These non-simple Lie algebras generalize $\\mathfrak{f}_{4},\\mathfrak{e}_{6},\\mathfrak{e}_{7}$ and $\\mathfrak{e}_{8}$ for the octonionic plane $\\mathbb{O}P^{2}$ and in the octonionic Rosenfeld planes $\\left(\\mathbb{C}\\otimes\\mathbb{O}\\right)P^{2}$, $\\left(\\mathbb{H}\\otimes\\mathbb{O}\\right)P^{2}$ and $\\left(\\mathbb{O}\\otimes\\mathbb{O}\\right)P^{2}$. We finally investigate the relationships between the isometry algebras of the Dixon-Rosenfeld planes and the exceptional Lie algebras.",
          "authors": [
            "David Chester",
            "Alessio Marrani",
            "Daniele Corradetti",
            "Raymond Aschheim"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02271",
          "title": "Three Dixon-Rosenfeld Planes",
          "abstract": "Rosenfeld postulated ``generalized'' projective planes, which exploit a correspondence between rank-one idempotents of Jordan algebras $\\mathfrak{J}_3(\\mathbb{A})$ and points of projective planes $\\mathbb{A}P^2$. The isometry groups of the generalized projective planes (which were later defined rigorously as homogeneous spaces) are entries of the Tits-Freudenthal magic square. Given recent interest in the Dixon algebra $\\mathbb{R}\\otimes\\mathbb{C}\\otimes\\mathbb{H}\\otimes\\mathbb{O}$, we extend Rosenfeld's approach and present three new coset manifolds. These \"Dixon-Rosenfeld planes\" have isometry algebras that are obtained from Tits' magic formula and involve all tensorial components of the Dixon algebra. We show that these are the only three planes obtainable with Tits' formula that preserve the analogy with Rosenfeld's planes. These non-simple Lie algebras generalize $\\mathfrak{f}_{4},\\mathfrak{e}_{6},\\mathfrak{e}_{7}$ and $\\mathfrak{e}_{8}$ for the octonionic plane $\\mathbb{O}P^{2}$ and in the octonionic Rosenfeld planes $\\left(\\mathbb{C}\\otimes\\mathbb{O}\\right)P^{2}$, $\\left(\\mathbb{H}\\otimes\\mathbb{O}\\right)P^{2}$ and $\\left(\\mathbb{O}\\otimes\\mathbb{O}\\right)P^{2}$. We finally investigate the relationships between the isometry algebras of the Dixon-Rosenfeld planes and the exceptional Lie algebras.",
          "authors": [
            "David Chester",
            "Alessio Marrani",
            "Daniele Corradetti",
            "Raymond Aschheim"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02284",
          "title": "Quantum-Classical Separation in Bounded-Resource Tasks Arising from Measurement Contextuality",
          "abstract": "The prevailing view is that quantum phenomena can be harnessed to tackle certain problems beyond the reach of classical approaches. Quantifying this capability as a quantum-classical separation and demonstrating it on current quantum processors has remained elusive. Using a superconducting qubit processor, we show that quantum contextuality enables certain tasks to be performed with success probabilities beyond classical limits. With a few qubits, we illustrate quantum contextuality with the magic square game, as well as quantify it through a Kochen--Specker--Bell inequality violation. To examine many-body contextuality, we implement the N-player GHZ game and separately solve a 2D hidden linear function problem, exceeding classical success rate in both. Our work proposes novel ways to benchmark quantum processors using contextuality-based algorithms.",
          "authors": [
            "Shashwat Kumar",
            "Eliott Rosenberg",
            "Alejandro Grajales Dau",
            "Rodrigo Cortinas",
            "Dmitri Maslov",
            "Richard Oliver",
            "Adam Zalcman",
            "Matthew Neeley",
            "Alice Pagano",
            "Aaron Szasz",
            "Ilya Drozdov",
            "Zlatko Minev",
            "Craig Gidney",
            "Noureldin Yosri",
            "Stijn J. de Graaf",
            "Aniket Maiti",
            "Dmitry Abanin",
            "Rajeev Acharya",
            "Laleh Aghababaie Beni",
            "Georg Aigeldinger",
            "Ross Alcaraz",
            "Sayra Alcaraz",
            "Trond I. Andersen",
            "Markus Ansmann",
            "Frank Arute",
            "Kunal Arya",
            "Walt Askew",
            "Nikita Astrakhantsev",
            "Juan Atalaya",
            "Ryan Babbush",
            "Brian Ballard",
            "Joseph C. Bardin",
            "Hector Bates",
            "Andreas Bengtsson",
            "Martin Bigdeli",
            "Alexander Bilmes",
            "Simon Bilodeau",
            "Felix Borjans",
            "Alexandre Bourassa",
            "Jenna Bovaird",
            "Dylan Bowers",
            "Leon Brill",
            "Peter Brooks",
            "Michael Broughton",
            "David A. Browne",
            "Brett Buchea",
            "Bob B. Buckley",
            "Tim Burger",
            "Brian Burkett",
            "Nicholas Bushnell",
            "Jamal Busnaina",
            "Anthony Cabrera",
            "Juan Campero",
            "Hung-Shen Chang",
            "Silas Chen",
            "Zijun Chen",
            "Ben Chiaro",
            "Liang-Ying Chih",
            "Jahan Claes",
            "Agnetta Y. Cleland",
            "Bryan Cochrane",
            "Matt Cockrell",
            "Josh Cogan",
            "Roberto Collins",
            "Paul Conner",
            "Harold Cook",
            "William Courtney",
            "Alexander L. Crook",
            "Ben Curtin",
            "Sayan Das",
            "Laura De Lorenzo",
            "Sean Demura",
            "Agustin Di Paolo",
            "Paul Donohoe",
            "Andrew Dunsworth",
            "Valerie Ehimhen",
            "Alec Eickbusch",
            "Aviv Moshe Elbag",
            "Lior Ella",
            "Mahmoud Elzouka",
            "David Enriquez",
            "Catherine Erickson",
            "Vinicius S. Ferreira",
            "Marcos Flores",
            "Leslie Flores Burgos",
            "Ebrahim Forati",
            "Jeremiah Ford",
            "Austin G. Fowler",
            "Brooks Foxen",
            "Masaya Fukami",
            "Alan Wing Lun Fung",
            "Lenny Fuste",
            "Suhas Ganjam",
            "Gonzalo Garcia",
            "Christopher Garrick",
            "Robert Gasca",
            "Helge Gehring",
            "Élie Genois",
            "William Giang",
            "Dar Gilboa"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02284",
          "title": "Quantum-Classical Separation in Bounded-Resource Tasks Arising from Measurement Contextuality",
          "abstract": "The prevailing view is that quantum phenomena can be harnessed to tackle certain problems beyond the reach of classical approaches. Quantifying this capability as a quantum-classical separation and demonstrating it on current quantum processors has remained elusive. Using a superconducting qubit processor, we show that quantum contextuality enables certain tasks to be performed with success probabilities beyond classical limits. With a few qubits, we illustrate quantum contextuality with the magic square game, as well as quantify it through a Kochen--Specker--Bell inequality violation. To examine many-body contextuality, we implement the N-player GHZ game and separately solve a 2D hidden linear function problem, exceeding classical success rate in both. Our work proposes novel ways to benchmark quantum processors using contextuality-based algorithms.",
          "authors": [
            "Shashwat Kumar",
            "Eliott Rosenberg",
            "Alejandro Grajales Dau",
            "Rodrigo Cortinas",
            "Dmitri Maslov",
            "Richard Oliver",
            "Adam Zalcman",
            "Matthew Neeley",
            "Alice Pagano",
            "Aaron Szasz",
            "Ilya Drozdov",
            "Zlatko Minev",
            "Craig Gidney",
            "Noureldin Yosri",
            "Stijn J. de Graaf",
            "Aniket Maiti",
            "Dmitry Abanin",
            "Rajeev Acharya",
            "Laleh Aghababaie Beni",
            "Georg Aigeldinger",
            "Ross Alcaraz",
            "Sayra Alcaraz",
            "Trond I. Andersen",
            "Markus Ansmann",
            "Frank Arute",
            "Kunal Arya",
            "Walt Askew",
            "Nikita Astrakhantsev",
            "Juan Atalaya",
            "Ryan Babbush",
            "Brian Ballard",
            "Joseph C. Bardin",
            "Hector Bates",
            "Andreas Bengtsson",
            "Martin Bigdeli",
            "Alexander Bilmes",
            "Simon Bilodeau",
            "Felix Borjans",
            "Alexandre Bourassa",
            "Jenna Bovaird",
            "Dylan Bowers",
            "Leon Brill",
            "Peter Brooks",
            "Michael Broughton",
            "David A. Browne",
            "Brett Buchea",
            "Bob B. Buckley",
            "Tim Burger",
            "Brian Burkett",
            "Nicholas Bushnell",
            "Jamal Busnaina",
            "Anthony Cabrera",
            "Juan Campero",
            "Hung-Shen Chang",
            "Silas Chen",
            "Zijun Chen",
            "Ben Chiaro",
            "Liang-Ying Chih",
            "Jahan Claes",
            "Agnetta Y. Cleland",
            "Bryan Cochrane",
            "Matt Cockrell",
            "Josh Cogan",
            "Roberto Collins",
            "Paul Conner",
            "Harold Cook",
            "William Courtney",
            "Alexander L. Crook",
            "Ben Curtin",
            "Sayan Das",
            "Laura De Lorenzo",
            "Sean Demura",
            "Agustin Di Paolo",
            "Paul Donohoe",
            "Andrew Dunsworth",
            "Valerie Ehimhen",
            "Alec Eickbusch",
            "Aviv Moshe Elbag",
            "Lior Ella",
            "Mahmoud Elzouka",
            "David Enriquez",
            "Catherine Erickson",
            "Vinicius S. Ferreira",
            "Marcos Flores",
            "Leslie Flores Burgos",
            "Ebrahim Forati",
            "Jeremiah Ford",
            "Austin G. Fowler",
            "Brooks Foxen",
            "Masaya Fukami",
            "Alan Wing Lun Fung",
            "Lenny Fuste",
            "Suhas Ganjam",
            "Gonzalo Garcia",
            "Christopher Garrick",
            "Robert Gasca",
            "Helge Gehring",
            "Élie Genois",
            "William Giang",
            "Dar Gilboa"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02286",
          "title": "Pfaffian Transition Probability and Correlation Kernel of TASEP in Half-space",
          "abstract": "We present the transition probability for the asymmetric simple exclusion process on the half-space for general initial conditions and particle insertion at the boundary. In the limit of total asymmetry, where particles only jump to the right, we show that the transition probability reduces to a single Pfaffian for a large class of initial conditions. We further derive a Fredholm Pfaffian formula for the multipoint distribution of the totally asymmetric model conditioned on the number of particles in the system using a connection with a Pfaffian point process supported on Gelfand-Tsetlin patterns.",
          "authors": [
            "Jan de Gier",
            "William Mead",
            "Daniel Remenik",
            "Michael Wheeler"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02286",
          "title": "Pfaffian Transition Probability and Correlation Kernel of TASEP in Half-space",
          "abstract": "We present the transition probability for the asymmetric simple exclusion process on the half-space for general initial conditions and particle insertion at the boundary. In the limit of total asymmetry, where particles only jump to the right, we show that the transition probability reduces to a single Pfaffian for a large class of initial conditions. We further derive a Fredholm Pfaffian formula for the multipoint distribution of the totally asymmetric model conditioned on the number of particles in the system using a connection with a Pfaffian point process supported on Gelfand-Tsetlin patterns.",
          "authors": [
            "Jan de Gier",
            "William Mead",
            "Daniel Remenik",
            "Michael Wheeler"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02286",
          "title": "Pfaffian Transition Probability and Correlation Kernel of TASEP in Half-space",
          "abstract": "We present the transition probability for the asymmetric simple exclusion process on the half-space for general initial conditions and particle insertion at the boundary. In the limit of total asymmetry, where particles only jump to the right, we show that the transition probability reduces to a single Pfaffian for a large class of initial conditions. We further derive a Fredholm Pfaffian formula for the multipoint distribution of the totally asymmetric model conditioned on the number of particles in the system using a connection with a Pfaffian point process supported on Gelfand-Tsetlin patterns.",
          "authors": [
            "Jan de Gier",
            "William Mead",
            "Daniel Remenik",
            "Michael Wheeler"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02287",
          "title": "HOT Protocol",
          "abstract": "HOT Protocol provides the infrastructure that allows smart contracts to securely own and manage private keys. The Multi-Party Computation (MPC) Network manages signing keys. By running an MPC node inside a Trusted Execution Environment (TEE), the protocol achieves stronger security guarantees while lowering economic requirements for participants. The NEAR Protocol provides a decentralized and efficient state layer. Key management can be integrated with any smart contract across Stellar, TON, Solana, and EVM-compatible networks.",
          "authors": [
            "Peter Volnov",
            "Georgii Kuksa",
            "Andrey Zhevlakov"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02291",
          "title": "From two-dimensional continuous maps to one-dimensional discontinuous maps: a novel reduction explaining complex bifurcation structures in piecewise-linear families of maps",
          "abstract": "Piecewise-linear maps describe dynamical phenomena that switch between distinct states and readily generate complex bifurcation structures due to their strong nonlinearity. We show that two-dimensional continuous piecewise-linear maps near certain codimension-two homoclinic bifurcations are well approximated by a three-parameter family of one-dimensional maps. Each member of the one-dimensional family is discontinuous, because the family is constructed from the first return of iterates to a subset of phase space, and comprised of infinitely many linear pieces, where each piece corresponds to a fixed number of iterations near the saddle associated with the homoclinic bifurcation. The one-dimensional family exhibits period-incrementing, period-adding, bandcount-incrementing, and bandcount-adding structures (all typical for two-piece maps), as well as unique features caused by orbits repeatedly visiting more than two pieces of the map. These structures carry through to the two-dimensional maps with only minor differences in the arrangement of the bifurcations developing with the distance from the codimension-two bifurcations. This leads to a novel and vivid elucidation of the dynamics of the two-dimensional border-collision normal form.",
          "authors": [
            "D. J. W. Simpson",
            "V. Avrutin"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02291",
          "title": "From two-dimensional continuous maps to one-dimensional discontinuous maps: a novel reduction explaining complex bifurcation structures in piecewise-linear families of maps",
          "abstract": "Piecewise-linear maps describe dynamical phenomena that switch between distinct states and readily generate complex bifurcation structures due to their strong nonlinearity. We show that two-dimensional continuous piecewise-linear maps near certain codimension-two homoclinic bifurcations are well approximated by a three-parameter family of one-dimensional maps. Each member of the one-dimensional family is discontinuous, because the family is constructed from the first return of iterates to a subset of phase space, and comprised of infinitely many linear pieces, where each piece corresponds to a fixed number of iterations near the saddle associated with the homoclinic bifurcation. The one-dimensional family exhibits period-incrementing, period-adding, bandcount-incrementing, and bandcount-adding structures (all typical for two-piece maps), as well as unique features caused by orbits repeatedly visiting more than two pieces of the map. These structures carry through to the two-dimensional maps with only minor differences in the arrangement of the bifurcations developing with the distance from the codimension-two bifurcations. This leads to a novel and vivid elucidation of the dynamics of the two-dimensional border-collision normal form.",
          "authors": [
            "D. J. W. Simpson",
            "V. Avrutin"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02298",
          "title": "On Frequency-Weighted Extended Balanced Truncation",
          "abstract": "This paper addresses the problem of frequency-weighted extended balanced truncation for discrete and continuous-time linear time-invariant plants. We show that the frequency-weighted discrete-time plant admits block-diagonal solutions to both the Lyapunov inequality and its extended form. A recursive algorithm for extended balanced truncation is proposed, together with corresponding a-priori error bounds. Theoretical results are extended to continuous-time systems and validated through numerical examples.",
          "authors": [
            "Sribalaji C. Anand",
            "Henrik Sandberg"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02298",
          "title": "On Frequency-Weighted Extended Balanced Truncation",
          "abstract": "This paper addresses the problem of frequency-weighted extended balanced truncation for discrete and continuous-time linear time-invariant plants. We show that the frequency-weighted discrete-time plant admits block-diagonal solutions to both the Lyapunov inequality and its extended form. A recursive algorithm for extended balanced truncation is proposed, together with corresponding a-priori error bounds. Theoretical results are extended to continuous-time systems and validated through numerical examples.",
          "authors": [
            "Sribalaji C. Anand",
            "Henrik Sandberg"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02298",
          "title": "On Frequency-Weighted Extended Balanced Truncation",
          "abstract": "This paper addresses the problem of frequency-weighted extended balanced truncation for discrete and continuous-time linear time-invariant plants. We show that the frequency-weighted discrete-time plant admits block-diagonal solutions to both the Lyapunov inequality and its extended form. A recursive algorithm for extended balanced truncation is proposed, together with corresponding a-priori error bounds. Theoretical results are extended to continuous-time systems and validated through numerical examples.",
          "authors": [
            "Sribalaji C. Anand",
            "Henrik Sandberg"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02301",
          "title": "Quantum Vanguard: Server Optimized Privacy Fortified Federated Intelligence for Future Vehicles",
          "abstract": "This work presents vQFL (vehicular Quantum Federated Learning), a new framework that leverages quantum machine learning techniques to tackle key privacy and security issues in autonomous vehicular networks. Furthermore, we propose a server-side adapted fine-tuning method, ft-VQFL,to achieve enhanced and more resilient performance. By integrating quantum federated learning with differential privacy and quantum key distribution (QKD), our quantum vanguard approach creates a multi-layered defense against both classical and quantum threats while preserving model utility. Extensive experimentation with industry-standard datasets (KITTI, Waymo, and nuScenes) demonstrates that vQFL maintains accuracy comparable to standard QFL while significantly improving privacy guaranties and communication security. Our implementation using various quantum models (VQC, QCNN, and SamplerQNN) reveals minimal performance overhead despite the added security measures. This work establishes a crucial foundation for quantum-resistant autonomous vehicle systems that can operate securely in the post-quantum era while efficiently processing the massive data volumes (20-40TB/day per vehicle) generated by modern autonomous fleets. The modular design of the framework allows for seamless integration with existing vehicular networks, positioning vQFL as an essential component for future intelligent transportation infrastructure.",
          "authors": [
            "Dev Gurung",
            "Shiva Raj Pokhrel"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02307",
          "title": "Entropy rigidity of $u$-Gibbs measures",
          "abstract": "We obtain new entropy rigidity results for $u$-Gibbs measures by showing that whenever a $u$-Gibbs measure of a partially hyperbolic diffeomorphism admits an unstable Margulis family, the unstable Jacobian data of the system must to be constant. We apply our result to center isometries and flow type diffeomorphisms showing that if a measure of maximal entropy is also $u$-Gibbs then Jacobian periodic data along the unstable bundle are constant. In the case of smooth jointly integrable partially hyperbolic diffeomorphisms of $\\mathbb{T}^3$, assuming that there exists some $u$-Gibbs measure which is also a measure of maximal unstable entropy, we obtain smooth conjugacy along the center-unstable foliation and uniqueness of $u$-Gibbs measures in this case.",
          "authors": [
            "Vítor Gomes",
            "Bruno Santiago"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02313",
          "title": "Anharmonic interaction as random field for thermal transport in FPU-$β$ lattice",
          "abstract": "We present an open quantum theory for the thermal transport in the Fermi-Pasta-Ulam-$\\beta$(FPU-$\\beta$) lattice. In the theory, local bosons(LBs) are introduced as carriers for the transport. The LBs are stimulated by individual atoms in the lattice, which are different from the phonons that are collective motions of the atoms. The LBs move in the FPU chain and are governed by a set of stochastic differential equations(SDEs). The anharmonic interaction between the atoms in the lattice is transformed to a random field by the Hubbard-Stratonovich transformation, and has been implemented in the set of SDEs. By solving the set of SDEs at the steady state, we study the influence of the anharmonic interaction on the thermal transport. Results show that the anharmonic interaction decreases the thermal current by trapping the LBs on the lattice sites, as well as increase the thermal current by enhancing the amount of the LBs for the transport. The competition between these two mechanisms makes the thermal conductivity of the lattice dependent on the anharmonic interaction non-monotonically. The finite size effect of the thermal conductivity has also been captured by the theory.",
          "authors": [
            "Li Wan"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02314",
          "title": "A dimer view on Fox's trapezoidal conjecture",
          "abstract": "Fox's conjecture (1962) states that the sequence of absolute values of the coefficients of the Alexander polynomial of alternating links is trapezoidal. While the conjecture remains open in general, a number of special cases have been settled, some, quite recently: Fox's conjecture was shown to hold for special alternating links by Hafner, Mészáros, and Vidinas (2023) and for certain diagrammatic Murasugi sums of special alternating links by Azarpendar, Juhász, and Kálmán (2024). Any alternating link can be written as a diagrammatic Murasugi sums of special alternating links; thus, if one could remove the certain adjective in the previous result, it would settle Fox's conjecture. In this paper, we give an alternative proof of Azarpendar, Juhász, and Kálmán's aforementioned result via a dimer model for the Alexander polynomial. In doing so, we not only obtain a significantly shorter proof of Azarpendar, Juhász, and Kálmán's result than the original, but we also obtain several theorems of independent interest regarding the Alexander polynomial, which are readily visible from the dimer point of view. Moreover, we explain, backed with computational evidence, why our result is only for certain diagrammatic Murasugi sums of special alternating links as opposed to all. While the latter does not settle an open question, it strikes us as important to bring to attention, given the interest in finding a solution to Fox's conjecture.",
          "authors": [
            "Karola Mészáros",
            "Melissa Sherman-Bennett",
            "Alexander Vidinas"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02316",
          "title": "Two Variations on the XTrace Algorithm",
          "abstract": "This paper studies two potential modifications of XTrace (Epperly et al., SIMAX 45(1):1-23, 2024), a randomized algorithm for estimating the trace of a matrix. The first is a variance reduction step that averages the output of XTrace over right-multiplications of the test vectors by random orthogonal matrices. The second is to form a low-rank approximation to the matrix using the whole Krylov space produced by the test vectors, rather than the output of a single power iteration as is used by XTrace. Experiments on synthetic data show that the first modification offers only slight benefits in practice, while the second can lead to significant improvements depending on the spectrum of the matrix.",
          "authors": [
            "Eric Hallman"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02316",
          "title": "Two Variations on the XTrace Algorithm",
          "abstract": "This paper studies two potential modifications of XTrace (Epperly et al., SIMAX 45(1):1-23, 2024), a randomized algorithm for estimating the trace of a matrix. The first is a variance reduction step that averages the output of XTrace over right-multiplications of the test vectors by random orthogonal matrices. The second is to form a low-rank approximation to the matrix using the whole Krylov space produced by the test vectors, rather than the output of a single power iteration as is used by XTrace. Experiments on synthetic data show that the first modification offers only slight benefits in practice, while the second can lead to significant improvements depending on the spectrum of the matrix.",
          "authors": [
            "Eric Hallman"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02317",
          "title": "Rare Event Searches Using Cryogenic Detectors via Direct Detection Methods",
          "abstract": "Cryogenic detectors are at the forefront of rare-event search experiments, including direct detection of dark matter, coherent elastic neutrino-nucleus scattering, neutrinoless double-beta decay, and searches for fractionally charged particles. Their unique ability to achieve ultra-low energy thresholds, typically O(eV-100 eV), together with excellent energy resolution and effective background suppression, makes them sensitive to extremely faint signals from rare interactions. These rare particle interactions produce phonons, ionization, or scintillation, depending on the target medium, which are registered by specialized sensors and converted into measurable signals. This review summarizes the underlying detection principles, surveys major experiments and recent results, examines forthcoming initiatives, and outlines the evolving role of cryogenic detectors in advancing the frontiers of rare-event physics.",
          "authors": [
            "S. Das",
            "R. Dey",
            "V.K.S. Kashyap",
            "B. Mohanty",
            "D. Mondal",
            "S. Banik",
            "M. Chaudhuri",
            "V. Iyer"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02317",
          "title": "Rare Event Searches Using Cryogenic Detectors via Direct Detection Methods",
          "abstract": "Cryogenic detectors are at the forefront of rare-event search experiments, including direct detection of dark matter, coherent elastic neutrino-nucleus scattering, neutrinoless double-beta decay, and searches for fractionally charged particles. Their unique ability to achieve ultra-low energy thresholds, typically O(eV-100 eV), together with excellent energy resolution and effective background suppression, makes them sensitive to extremely faint signals from rare interactions. These rare particle interactions produce phonons, ionization, or scintillation, depending on the target medium, which are registered by specialized sensors and converted into measurable signals. This review summarizes the underlying detection principles, surveys major experiments and recent results, examines forthcoming initiatives, and outlines the evolving role of cryogenic detectors in advancing the frontiers of rare-event physics.",
          "authors": [
            "S. Das",
            "R. Dey",
            "V.K.S. Kashyap",
            "B. Mohanty",
            "D. Mondal",
            "S. Banik",
            "M. Chaudhuri",
            "V. Iyer"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02317",
          "title": "Rare Event Searches Using Cryogenic Detectors via Direct Detection Methods",
          "abstract": "Cryogenic detectors are at the forefront of rare-event search experiments, including direct detection of dark matter, coherent elastic neutrino-nucleus scattering, neutrinoless double-beta decay, and searches for fractionally charged particles. Their unique ability to achieve ultra-low energy thresholds, typically O(eV-100 eV), together with excellent energy resolution and effective background suppression, makes them sensitive to extremely faint signals from rare interactions. These rare particle interactions produce phonons, ionization, or scintillation, depending on the target medium, which are registered by specialized sensors and converted into measurable signals. This review summarizes the underlying detection principles, surveys major experiments and recent results, examines forthcoming initiatives, and outlines the evolving role of cryogenic detectors in advancing the frontiers of rare-event physics.",
          "authors": [
            "S. Das",
            "R. Dey",
            "V.K.S. Kashyap",
            "B. Mohanty",
            "D. Mondal",
            "S. Banik",
            "M. Chaudhuri",
            "V. Iyer"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02322",
          "title": "Ursell functions in lattice gauge theory",
          "abstract": "Ursell functions $U_n$ are higher-order generalizations of the covariance function, which capture the interactions between $n$ random variables. In the classical Ising model, as shown by Shlosman, when considering the spins at some locations, the sign of $U_{2n}$ alternates with $n$ and is independent of the locations of the spins considered. In this paper, we study the Ursell function in Ising lattice gauge theory. When the spins at the edges are used as random variables, we show that $U_n$ can be positive, negative, or zero depending on the configuration and the parameter $\\beta$. When considering Wilson loops observables as random variables, using the tool of cluster expansion adapted to this setting, we prove that at sufficiently low temperature, for any number $n$ of disjoint Wilson loops, there exists a configuration of loops such that the Ursell function $U_n$ is positive. These results contrast sharply with the behavior observed for the Ising model.",
          "authors": [
            "Adrien Malacan"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02324",
          "title": "Parity results for the reciprocals of false theta functions",
          "abstract": "Recently, Keith investigated arithmetic properties for the reciprocals of some false theta functions and posed several conjectures. In this paper, we prove some parity results for the reciprocals of some false theta functions by using some identities on Ramanujan's general theta function. In particular, our results imply some conjectures of Keith.",
          "authors": [
            "Jing Jin",
            "Huan Xu",
            "Olivia X.M. Yao"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02325",
          "title": "New Constructions of Non-GRS MDS Codes, Recovery and Determination Algorithms for GRS Codes",
          "abstract": "In this paper, we propose a new method for constructing a class of non-GRS MDS codes. The lengths of these codes can reach up to $\\frac{q+3}{2}$ (for finite fields of odd characteristic) and $\\frac{q+4}{2}$ (for even characteristic), respectively. Owing to their special structure, we can use the Cauchy matrix method to obtain the necessary and sufficient conditions for these codes to be MDS codes and non-GRS MDS codes. Additionally, the inequivalence between these codes and twisted GRS codes is analyzed. Furthermore, we analyze the relationships among several existing classes of codes used for constructing non-GRS MDS codes, propose explicit constructions, and discuss the lengths of non-GRS MDS codes based on these constructions. Finally, we design two efficient algorithms to address two main problems in GRS code research, i.e., determining whether an unknown code $C$ is a GRS code from its generator matrix $G$, and recovering the key vectors $\\bm{\\alpha}$ and $\\bm{v}$ such that $C = \\GRS_{n,k}(\\bm{\\alpha}, \\bm{v})$ if $C$ is indeed a GRS code. A computational complexity comparison of the proposed algorithms ($O(nk+n)$) with that of the Sidelnikov-Shestakov attack (exceeding $O(qk^2n+qk^3)$) shows that our methods offer superior computational efficiency.",
          "authors": [
            "Guodong Wang",
            "Hongwei Liu",
            "Jinquan Luo"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02325",
          "title": "New Constructions of Non-GRS MDS Codes, Recovery and Determination Algorithms for GRS Codes",
          "abstract": "In this paper, we propose a new method for constructing a class of non-GRS MDS codes. The lengths of these codes can reach up to $\\frac{q+3}{2}$ (for finite fields of odd characteristic) and $\\frac{q+4}{2}$ (for even characteristic), respectively. Owing to their special structure, we can use the Cauchy matrix method to obtain the necessary and sufficient conditions for these codes to be MDS codes and non-GRS MDS codes. Additionally, the inequivalence between these codes and twisted GRS codes is analyzed. Furthermore, we analyze the relationships among several existing classes of codes used for constructing non-GRS MDS codes, propose explicit constructions, and discuss the lengths of non-GRS MDS codes based on these constructions. Finally, we design two efficient algorithms to address two main problems in GRS code research, i.e., determining whether an unknown code $C$ is a GRS code from its generator matrix $G$, and recovering the key vectors $\\bm{\\alpha}$ and $\\bm{v}$ such that $C = \\GRS_{n,k}(\\bm{\\alpha}, \\bm{v})$ if $C$ is indeed a GRS code. A computational complexity comparison of the proposed algorithms ($O(nk+n)$) with that of the Sidelnikov-Shestakov attack (exceeding $O(qk^2n+qk^3)$) shows that our methods offer superior computational efficiency.",
          "authors": [
            "Guodong Wang",
            "Hongwei Liu",
            "Jinquan Luo"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02326",
          "title": "Chromatic derivatives, chromatic expansions and associated spaces II",
          "abstract": "We study differential operators associated with families of polynomials orthonormal with respect to certain measures. These operators, when applied to the Fourier transforms of such measures, produce basis functions for expansions of functions analytic on some complex domains. For many classical families of orthogonal polynomials these basis functions are the familiar special functions, such as the Bessel and the spherical Bessel functions. Many familiar identities involving such special functions turn out to be just special cases of such expansions. We also use these differential operators to introduce some new spaces of almost periodic functions. The notions we study here have been successfully applied to signal processing, for example to recovery of band-limited signals from their non-uniform samples as well as from their zero crossings and the locations of their extremal points.",
          "authors": [
            "Aleksandar Ignjatovic"
          ],
          "primary_category": "math.CA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02330",
          "title": "Unconventional superconductivity from crystal field fluctuations",
          "abstract": "We present a novel pairing mechanism for superconductivity in strongly correlated electron systems, which often have both localised and itinerant charge carriers. An effective anisotropic interaction between the itinerant particles originates from the fluctuations in the crystal field associated with virtual hopping of the localised particles, a process that is also responsible for the Kondo exchange. Interestingly, this interaction is \\emph{attractive} for charge transfer insulators such as cuprates. Considering a simple toy model for cuprates, without the antiferromagnetic exchange, this interaction leads to the correct d-wave superconducting gap, thus demonstrating its relevance.",
          "authors": [
            "M. A. Zeb"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02331",
          "title": "Instability triggered by mixed convection in a thin fluid layer",
          "abstract": "We investigate the convective stability of a thin, infinite fluid layer with a rectangular cross-section, subject to imposed heat fluxes at the top and bottom and fixed temperature along the vertical sides. The instability threshold depends on the Prandtl number as well as the normalized flux difference ($f$) and decreases with the aspect ratio ($\\epsilon$), following a $\\epsilon f^{-1}$ power law. Using 3D initial value and 2D eigenvalue calculations, we identify a dominant 3D mode characterized by two transverse standing waves attached to the domain edges. We characterize the dominant mode's frequency and transverse wave number as functions of the Rayleigh number and aspect ratio. An analytical asymptotic solution for the base state in the bulk is obtained, valid over most of the domain and increasingly accurate for lower aspect ratios. A local stability analysis, based on the analytical base state, reveals oscillatory transverse instabilities consistent with the global instability characteristics. The source term for this most unstable mode appears to be interactions between vertical shear and horizontal temperature gradients.",
          "authors": [
            "Florian Rein",
            "Keaton J. Burns",
            "Stefan G. Llewellyn Smith",
            "William R. Young",
            "Benjamin Favier",
            "Michael Le Bars"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02335",
          "title": "$SL_4$-Kloosterman sum via the Bruhat decomposition",
          "abstract": "We define the Kloosterman sum for $SL_4$ over the Kloosterman set via the Bruhat decomposition and stratify the Kloosterman set using the reduced word decomposition of the Weyl group element. The Kloosterman sum for an $SL_4$-long word is decomposed into finer parts (called the fine Kloosterman sum), and can be written as a finite sum of a product of two classical Kloosterman sums.",
          "authors": [
            "Suzuho Osonoe",
            "Maki Nakasuji"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02343",
          "title": "Lower Bounds for Galois Orbits of periodic points for polarized endomorphisms",
          "abstract": "Let $K$ be a number field, $X$ a smooth projective variety over $K$ and $f: X \\to X$ a polarized endomorphism of degree $d \\geq 2$. We prove an exponential lower bound on $[K(\\Per_n):K]$, where $\\Per_n$ is the set of $n$-periodic points, extending results of [Yap24] to higher dimensions. We also prove a quantitative rate of equidistribution for $\\Per_n$ to the equilibrium measure.",
          "authors": [
            "Jit Wu Yap",
            "Tien-Cuong Dinh"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02345",
          "title": "Ramanujan's function on small primes",
          "abstract": "We study matrices the determinants of which represent $\\tau(p_n)$, where $\\tau$ is Ramanujan's function and $p_n$ denotes the $n^{th} rational prime. We also look at certain ``deformations'' of these matrices that exhibit nice regularities within the limited range of our empirical observations. This is an application of methods from our previous article arXiv:math/0405083 .",
          "authors": [
            "Barry Brent"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02348",
          "title": "Adjoint motives of modular forms and the Tamagawa number conjecture",
          "abstract": "Let $f$ be a newform of weight $k\\geq 2$, level $N$ with coefficients in a number field $K$, and $A$ the adjoint motive of the motive $M$ associated to $f$. We carefully discuss the construction of the realisations of $M$ and $A$, as well as natural integral structures in these realisations. We then use the method of Taylor and Wiles to verify the $\\lambda$-part of the Tamagawa number conjecture of Bloch and Kato for $L(A,0)$ and $L(A,1)$. Here $\\lambda$ is any prime of $K$ not dividing $Nk!$, and so that the mod $\\lambda$ representation associated to $f$ is absolutely irreducible when restricted to the Galois group over $\\mathbb{Q}(\\sqrt{(-1)^{(\\ell-1)/2}\\ell})$ where $\\lambda\\mid \\ell$. The method also establishes modularity of all lifts of the mod $\\lambda$ representation which are crystalline of Hodge-Tate type $(0,k-1)$.",
          "authors": [
            "Fred Diamond",
            "Matthias Flach",
            "Li Guo"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02365",
          "title": "Singular value asymptotics on compact smooth Riemaniann manifolds",
          "abstract": "Let $(X,G)$ be a $d$-dimensional compact smooth Riemannian manifold equipped with Laplace-Beltrami operator $\\Delta_{G}$, and let $\\Pi_{X}$ be the $C^{\\ast}$-algebra obtained by locally transferring the $C^{\\ast}$-algebra generated by multiplication operators and Riesz transforms on $\\mathbb{R}^{d}$. Denote ${\\rm sym}_{X}$ the principal symbol mapping of $\\Pi_{X}$. For any $S\\in\\Pi_{X}$, we prove that, in the framework of $C^{\\ast}$-algebra, \\begin{align*} \\lim_{t\\rightarrow\\infty}t^{\\frac{1}{p}}\\mu(t,S(1+\\Delta_G)^{-\\frac{d}{2p}}) =(2\\pi\\sqrt[d]{d})^{-\\frac{1}{p}}\\Big\\|{\\rm sym}_{X}(S)\\Big\\|_{L_{p}(T^{\\ast}X,e^{-q_{G}}d\\lambda)}, \\end{align*} where $0<p<\\infty$, $e^{-q_{G}}$ is the canonical weight on $X$, and $d\\lambda$ is the Liouville measure on the cotangent bundle $T^{\\ast}X$.",
          "authors": [
            "Fedor Sukochev",
            "Fulin Yang",
            "Dmitriy Zanin"
          ],
          "primary_category": "math.FA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02366",
          "title": "Universal Sensitivity Bound for Thermal Quantum Dynamic Sensing",
          "abstract": "This work unifies the equilibrium and non-equilibrium frameworks of quantum metrology within the context of many-body systems. We investigate dynamic sensing schemes to derive an upper bound on the quantum Fisher information for probe states in thermal equilibrium with their environment. We establish that the dynamic quantum Fisher information for a thermal probe state is upper bounded by the degree of non-commutation between the transformed local generator and the Hamiltonian for the thermal state. Furthermore, we show that this upper bound scales as the square of the product of the inverse temperature and the evolution time. In the low-temperature limit, we establish an additional upper bound expressed as the seminorm of the commutator divided by the energy gap. We apply this thermal dynamic sensing scheme to various models, demonstrating that the dynamic quantum Fisher information satisfies the established upper bounds.",
          "authors": [
            "Rui Zhang",
            "Yang Yang",
            "Wenkui Ding",
            "Xiaoguang Wang"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02372",
          "title": "Effective Mass of a Migrating Interface",
          "abstract": "Interfaces in materials are often treated as massless geometric boundaries, and many kinetic models adopt an overdamped assumption. In this Letter, we show that grain boundaries exhibit inertial behavior under high-frequency oscillatory loading and introduce a quantitative method to determine their effective mass from the phase lag between the applied force and interface velocity. The measured effective mass correlates with the mass of atoms participating in interface migration. Using this advance, we reassess prevailing theories and identify regimes where the inertial term materially affects interfacial kinetics, particularly at high frequencies relevant to thermal fluctuations. These results motivate incorporating an effective mass into kinetic descriptions, providing a clearer basis for modeling and interpreting interface migration.",
          "authors": [
            "Xinyuan Song",
            "Chuang Deng"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02373",
          "title": "Methods in complete intersections in corank one",
          "abstract": "Let $A$ denote an affine algebra over an algebraically closed field $k$, with $\\dim A=d\\geq 3$. In the light of availability of cancellation theorems for stably free modules $P$ with $rank(P)=d-1$ (corank one), we try to implement the methods of complete intersections theory in corank zero, to the corank one case. Our conclusion is that cancellation theorems need to clean up some of the lack of minor generalities, for such an approach to work. However, we hypothesize and derive some of the consequences to complete intersections, of such hypotheses.",
          "authors": [
            "Satya Mandal"
          ],
          "primary_category": "math.AC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02374",
          "title": "Singular jets during droplet impact on superhydrophobic surfaces",
          "abstract": "Hypothesis: The impact of droplets is prevalent in numerous applications, and jetting during droplet impact is a critical process controlling the dispersal and transport of liquid. New jetting dynamics are expected in different conditions of droplet impact on super-hydrophobic surfaces, such as new jetting phenomena, mechanisms, and regimes. Experiments: In this experimental study of droplet impact on super-hydrophobic surfaces, the Weber number and the Ohnesorge number are varied in a wide range, and the impact process is analyzed theoretically. Findings: We identify a new type of singular jets, i.e., singular jets induced by horizontal inertia (HI singular jets), besides the previously studied singular jets induced by capillary deformation (CD singular jets). For CD singular jets, the formation of the cavity is due to the propagation of capillary waves on the droplet surface; while for HI singular jets, the cavity formation is due to the large horizontal inertia of the toroidal edge during the retraction of the droplet after the maximum spreading. Key steps of the impact process are analyzed quantitatively, including the spreading of the droplet, the formation and the collapse of the spire, the formation and retraction of the cavity, and finally the formation of singular jets. A regime map for the formation of singular jets is obtained, and scaling relationships for the transition conditions between different regimes are analyzed.",
          "authors": [
            "Xiaoyun Peng",
            "Tianyou Wang",
            "Feifei Jia",
            "Kai Sun",
            "Zhe Li",
            "Zhizhao Che"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02376",
          "title": "Efficient Quantum Simulation of Non-Adiabatic Molecular Dynamics with Precise Electronic Structure",
          "abstract": "In the study of non-adiabatic chemical processes such as photocatalysis and photosynthesis, non-adiabatic molecular dynamics (NAMD) is an indispensable theoretical tool, which requires precise potential energy surfaces (PESs) of ground and excited states. Quantum computing offers promising potential for calculating PESs that are intractable for classical computers. However, its realistic application poses significant challenges to the development of quantum algorithms that are sufficiently general to enable efficient and precise PES calculations across chemical systems with diverse properties, as well as to seamlessly adapt existing NAMD theories to quantum computing. In this work, we introduce a quantum-adapted extension to the Landau-Zener-Surface-Hopping (LZSH) NAMD. This extension incorporates curvature-driven hopping corrections that protect the population evolution while maintaining the efficiency gained from avoiding the computation of non-adiabatic couplings (NACs), as well as preserving the trajectory independence that enables parallelization. Furthermore, to ensure the high-precision PESs required for surface hopping dynamics, we develop a sub-microhartree-accurate PES calculation protocol. This protocol supports active space selection, enables parallel acceleration either on quantum or classical clusters, and demonstrates adaptability to diverse chemical systems - including the charged H3+ ion and the C2H4 molecule, a prototypical multi-reference benchmark. This work paves the way for practical application of quantum computing in NAMD, showcasing the potential of parallel simulation on quantum-classical heterogeneous clusters for ab-initio computational chemistry.",
          "authors": [
            "Tianyi Li",
            "Yumeng Zeng",
            "Qiming Ding",
            "Zixuan Huo",
            "Xiaosi Xu",
            "Jiajun Ren",
            "Diandong Tang",
            "Xiaoxia Cai",
            "Xiao Yuan"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02376",
          "title": "Efficient Quantum Simulation of Non-Adiabatic Molecular Dynamics with Precise Electronic Structure",
          "abstract": "In the study of non-adiabatic chemical processes such as photocatalysis and photosynthesis, non-adiabatic molecular dynamics (NAMD) is an indispensable theoretical tool, which requires precise potential energy surfaces (PESs) of ground and excited states. Quantum computing offers promising potential for calculating PESs that are intractable for classical computers. However, its realistic application poses significant challenges to the development of quantum algorithms that are sufficiently general to enable efficient and precise PES calculations across chemical systems with diverse properties, as well as to seamlessly adapt existing NAMD theories to quantum computing. In this work, we introduce a quantum-adapted extension to the Landau-Zener-Surface-Hopping (LZSH) NAMD. This extension incorporates curvature-driven hopping corrections that protect the population evolution while maintaining the efficiency gained from avoiding the computation of non-adiabatic couplings (NACs), as well as preserving the trajectory independence that enables parallelization. Furthermore, to ensure the high-precision PESs required for surface hopping dynamics, we develop a sub-microhartree-accurate PES calculation protocol. This protocol supports active space selection, enables parallel acceleration either on quantum or classical clusters, and demonstrates adaptability to diverse chemical systems - including the charged H3+ ion and the C2H4 molecule, a prototypical multi-reference benchmark. This work paves the way for practical application of quantum computing in NAMD, showcasing the potential of parallel simulation on quantum-classical heterogeneous clusters for ab-initio computational chemistry.",
          "authors": [
            "Tianyi Li",
            "Yumeng Zeng",
            "Qiming Ding",
            "Zixuan Huo",
            "Xiaosi Xu",
            "Jiajun Ren",
            "Diandong Tang",
            "Xiaoxia Cai",
            "Xiao Yuan"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02377",
          "title": "Estimating Local Observables via Cluster-Level Light-Cone Decomposition",
          "abstract": "Simulating large quantum circuits on hardware with limited qubit counts is often attempted through methods like circuit knitting, which typically incur sample costs that grow exponentially with the number of connections cut. In this work, we introduce a framework based on Cluster-level Light-cone analysis that leverages the natural locality of quantum workloads. We propose two complementary algorithms: the Causal Decoupling Algorithm, which exploits geometric disconnections in the light cone for sampling efficiency, and the Algebraic Decomposition Algorithm, which utilizes algebraic expansion to minimize hardware requirements. These methods allow simulation costs to depend on circuit depth and connectivity rather than system size. Together, our results generalize Lieb-Robinson-inspired locality to modular architectures and establish a quantitative framework for probing local physics on near-term quantum devices by decoupling the simulation cost from the global system size.",
          "authors": [
            "Junxiang Huang",
            "Yunxin Tang",
            "Xiao Yuan"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02378",
          "title": "Self-Consistent Random Phase Approximation from Projective Truncation Approximation Formalism",
          "abstract": "We derive the self-consistent random phase approximations (sc-RPA) from the projective truncation approximation (PTA) for the equation of motion of two-time Green's function. The obtained sc-RPA applies to arbitrary temperature and recovers the Rowe's formalism at zero temperature. The PTA formalism not only rationalize Rowe's formula, but also provides a general framework to extend sc-RPA. We implement the sc-RPA calculation for the one-dimensional spinless fermion model in the parameter regime of disordered ground state, with the N-representability constraints enforced. The obtained ground state energy, correlation function, and density spectral function agree well with existing results. The features of the Luttinger liquid ground state and the continuum/bound state in the spectral function are well captured. We discuss several issues concerning the approximations made in RPAs, difficulties of RPA for symmetric state, and the static component problem of PTA.",
          "authors": [
            "Yue-Hong Wu",
            "Xinguo Ren",
            "Ning-Hua Tong"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02379",
          "title": "Some topological properties of the intrinsic volume metric",
          "abstract": "We prove that for fixed $j\\in\\{2,\\ldots,d-1\\}$, the $j$th intrinsic volume metric $\\delta_j$ is not uniformly bounded, and the metric space $(\\mathcal{K}_j^d,\\delta_j)$ is incomplete. In particular, this proves that for $j\\in\\{2,\\ldots,d-1\\}$, the Hausdorff and $j$th intrinsic volume metrics do not induce the same topology on $\\mathcal{K}_j^d$.",
          "authors": [
            "Steven Hoehner"
          ],
          "primary_category": "math.MG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02380",
          "title": "Coupled plastic strain- and stress-induced phase transformations and microstructure evolution in Fe-7%Mn alloy in dynamic rotational diamond anvil cell",
          "abstract": "The first experiments in dynamic rotational diamond anvil cell (dRDAC) on severe plastic deformation (SPD) and BCC<->HCP phase transformation (PT) at pressure up to 27.6 GPa, rotation rates up to 1,500 RPM, and strain rates up to 2,094 /s are performed considering Fe-%7Mn alloy as an example. The BCC-HCP PT initiates at 11.4 GPa under hydrostatic loading while it is 3.2 GPa under plastic compression. Strong effect of plastic straining leads to unique kinetics with simultaneous direct and reverse PTs, not studied for any material. For quasi-static loading, parameters in the kinetics for the strain-induced direct-reverse PTs and stationary volume fraction versus pressure are found. During torsion with 1,000 and 1,500 RPM, volume fraction of the HCP phase does not change. After torsion stops, it increases by 30% within a few minutes after 1,000 RPM and HCP phase disappears after 1,500 RPM. These findings contradict general wisdom that strain-induced PTs occur only during straining, time is not a governing parameter, and kinetics is determined by plastic strain instead of time. Thus, nuclei of the HCP phase are generated during straining at high strain rate, but growth/disappearance occur under stresses at much longer time scales. Consequently, a new theory of combined strain- and stress-induced PTs is required. The following important rule is revealed: crystallite size of 30 nm, microstrain ~0.004, and dislocation density ~1.1 x $10^{15}$/$m^2$ in the HCP phase are steady during static compression and dynamic torsion, during and after the PT and after torsion. These parameters are independent of pressure, plastic strain tensor, its path, strain rates, and volume fraction of the HCP phase. Obtained results open fundamental research on combined strain- and stress-induced PTs and microstructure evolution under dynamic SPD and high pressure.",
          "authors": [
            "Sorb Yesudhas",
            "Mrinmay Sahu",
            "Valery I. Levitas",
            "Dean Smith",
            "Jeffrey T. Lloyd"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02382",
          "title": "Mass transfer and water management in proton exchange membrane fuel cells with a composite foam-rib flow field",
          "abstract": "Mass transfer capability of reactants and hydrothermal management is important for the performance and durability of proton exchange membrane fuel cells. In the conventional rib flow field, the oxygen transport is affected by the accumulation of under-rib liquid water which causes excessive concentration loss and limits cell performance. To improve the cell performance, a composite foam-rib flow field structure is proposed by combining the metal foam flow field and the conventional rib flow field. The proposed design is simulated by using a three-dimensional homogeneous non-isothermal numerical model. The results show that the composite foam-rib flow field, by improving the oxygen transfer and water removal capabilities under the ribs, can improve the oxygen concentration and current density without increasing the pumping power, thus improving the cell performance under different conditions. The key parameters of the composite foam-rib flow field are optimized. With the optimal metal foam filling ratio of 0.75 and porosity of 0.85, the peak power density and the limiting current density for the composite foam-rib flow field are higher than the conventional rib flow field by 5.20% and 22.68%.",
          "authors": [
            "Wei Gao",
            "Qifeng Li",
            "Kai Sun",
            "Rui Chen",
            "Zhizhao Che",
            "Tianyou Wang"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02385",
          "title": "On Topology of Three-dimensional Continua with Singular Points",
          "abstract": "We propose to model the topology of three-dimensional (3D) continua by Yin sets, regular open semianalytic sets with bounded boundary. Our model differs from manifold-based models in that singular points of a 3D continuum, i.e., boundary points where the tangent plane is not uniquely defined, are treated not as anomalies but as a central subject of our theoretical investigation. We characterize the local and global topology of Yin sets. Then we give a unique boundary representation of Yin sets based on the notion of a glued surface, a quotient space of an orientable compact 2-manifold along a one-dimensional CW complex. Our results apply to 3D continua with arbitrarily complex topology and may be useful in a number of scientific and engineering applications such as solid modeling, computer-aided design, and numerical simulations of multiphase flows with topological changes.",
          "authors": [
            "Hao Liang",
            "Yunhao Qiu",
            "Yan Tan",
            "Qinghai Zhang"
          ],
          "primary_category": "math.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02387",
          "title": "The Liouville theorem on H-type groups",
          "abstract": "In this paper we obtain a Liouville type theorem to the semilinear subcritical elliptic equation on H-type groups. The semilinear subcritical elliptic equation studied in this paper is a generalization of a classical semilinear subcritical elliptic equation on the Heisenberg group. The proofs are based on an {\\it a priori} integral estimate and a generalized differential identity which found by Jerison and Lee [J. Diff. Geom, 29 (1989)].",
          "authors": [
            "Chuanyang Li",
            "Juan Zhang",
            "Peibiao Zhao"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02388",
          "title": "Infinite symmetric power L-functions of the hyper-Kloosterman family",
          "abstract": "The infinity symmetric power $L$-functions play a fundamental role in Wan's groundbreaking work on Dwork's conjecture[16]. Building upon this foundation, Haessig[8] established the $p$-adic estimates for these $L$-functions in the case of the one-dimensional Kloosterman family. In this paper, we extend Haessig's results by deriving a uniform lower bound for the $q$-adic Newton polygon of the infinite symmetric power $L$-functions associated with the hyper-Kloosterman family. For the $1$-dimensional Kloosterman family, Haessig[8] showed that there is a $p$-adic cohomology theory for the infinity symmetric power $L$-function. In this paper, we prove there is also a cohomological description of the infinity symmetric power $L$-function for the hyper-Kloosterman family. By applying the Frobenius endomorphism to this cohomology, we derive a uniform lower bound for the corresponding $L$-function.",
          "authors": [
            "Bolun Wei",
            "Liping Yang"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02390",
          "title": "Error estimates for semi-Lagrangian schemes with higher-order interpolation for conservation laws with dispersive terms",
          "abstract": "We establish error estimates for semi-Lagrangian schemes for the initial value problem of one-dimensional conservation laws with a dispersive term, including the Korteweg--de Vries equation. The schemes considered in this paper are based on the semi-Lagrangian technique combined with spatial discretization by higher-order interpolation operators. For the semi-Lagrangian schemes equipped with the spline or Hermite interpolation operators of order $ 2 s - 1 $, we derive an $L^2$-error estimate of $ O (\\Delta t^r + h^{2s} / \\Delta t) $ and an $ H^s $-error estimate of $ O (\\Delta t^r + h^{s} / \\sqrt{\\Delta t}) $, where $ h $ and $ \\Delta t $ denote the spatial mesh size and the time step size, respectively, and $ r \\in \\lparen 0, 1\\rbrack $ is a parameter determined by the discretization of the dispersive term. A key step in the analysis is to establish the stability of the interpolation operators. Under suitable assumptions, interpolation operators of order $ 2s - 1 $ are stable with respect to the $ H^s $-norm as well as a weighted $ H^s $-norm. The weighted $H^s$-norm depends on $h$ and $\\Delta t$, and it reduces to the $L^2$-norm in the limit $ h \\to 0 $.",
          "authors": [
            "Haruki Takemura"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02390",
          "title": "Error estimates for semi-Lagrangian schemes with higher-order interpolation for conservation laws with dispersive terms",
          "abstract": "We establish error estimates for semi-Lagrangian schemes for the initial value problem of one-dimensional conservation laws with a dispersive term, including the Korteweg--de Vries equation. The schemes considered in this paper are based on the semi-Lagrangian technique combined with spatial discretization by higher-order interpolation operators. For the semi-Lagrangian schemes equipped with the spline or Hermite interpolation operators of order $ 2 s - 1 $, we derive an $L^2$-error estimate of $ O (\\Delta t^r + h^{2s} / \\Delta t) $ and an $ H^s $-error estimate of $ O (\\Delta t^r + h^{s} / \\sqrt{\\Delta t}) $, where $ h $ and $ \\Delta t $ denote the spatial mesh size and the time step size, respectively, and $ r \\in \\lparen 0, 1\\rbrack $ is a parameter determined by the discretization of the dispersive term. A key step in the analysis is to establish the stability of the interpolation operators. Under suitable assumptions, interpolation operators of order $ 2s - 1 $ are stable with respect to the $ H^s $-norm as well as a weighted $ H^s $-norm. The weighted $H^s$-norm depends on $h$ and $\\Delta t$, and it reduces to the $L^2$-norm in the limit $ h \\to 0 $.",
          "authors": [
            "Haruki Takemura"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02396",
          "title": "Two-phase flow in porous metal foam flow fields of PEM fuel cells",
          "abstract": "Porous metal foam (PMF) flow field is a potential option for proton exchange membrane fuel cells (PEMFCs) due to its excellent capabilities in gas distribution and water drainage. However, the gas-liquid two-phase flow in the PMF flow field on the pore scale is still unclear. In this study, we investigate the gas-liquid two-phase flow in the PMF flow field. Film, plug, and ligament flows are found in the hydrophilic PMF flow field, while slug and droplet flows are found in the hydrophobic PMF flow field. The results suggest that optimizing the pore size, increasing the metal foam surface hydrophobicity, and optimizing the operating condition are helpful for the water management of the PMF flow field. The frequency analysis of the pressure drop also shows that the dominant frequency can be used as an indicator to analyze the transition between different flow patterns.",
          "authors": [
            "Xingxiao Tao",
            "Kai Sun",
            "Rui Chen",
            "Mengshan Suo",
            "Huaiyu Liu",
            "Zhizhao Che",
            "Tianyou Wang"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02401",
          "title": "Quantum Coulomb drag signatures of Majorana bound states",
          "abstract": "Majorana bound states (MBSs), with their non-Abelian statistics and topological protection, are key candidates for fault-tolerant quantum computation. However, their unambiguous identification in solid-state systems remains a fundamental challenge. Here, we present a theoretical study demonstrating that drag transport in a capacitively coupled double quantum dot system offers a robust and nonlocal probe of weakly coupled MBSs. Using the master equation approach, we investigate both steady-state and transient dynamics and uncover a distinctive signature of MBSs, i.e., the emergence of pronounced split peaks in the drag transconductance, directly linked to inter-MBS coupling. We further show that the dynamics of quantum coherence exhibit an inverse correlation with the emergence and enhancement of MBS-induced split peaks in the drag transconductance as the inter-MBS coupling increases. A comparative analysis with Andreev bound states (ABSs) reveals key differences, that is, MBS-induced transconductance peaks are symmetric and robust, while ABS features are asymmetric and sensitive to perturbations. These findings establish clear experimental criteria for distinguishing MBSs and provide a practical framework for probing Majorana physics through nonlocal transport.",
          "authors": [
            "Zi-Wei Li",
            "Jiaojiao Chen",
            "Wei Xiong",
            "Xiao Xue",
            "Zeng-Zhao Li"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02401",
          "title": "Quantum Coulomb drag signatures of Majorana bound states",
          "abstract": "Majorana bound states (MBSs), with their non-Abelian statistics and topological protection, are key candidates for fault-tolerant quantum computation. However, their unambiguous identification in solid-state systems remains a fundamental challenge. Here, we present a theoretical study demonstrating that drag transport in a capacitively coupled double quantum dot system offers a robust and nonlocal probe of weakly coupled MBSs. Using the master equation approach, we investigate both steady-state and transient dynamics and uncover a distinctive signature of MBSs, i.e., the emergence of pronounced split peaks in the drag transconductance, directly linked to inter-MBS coupling. We further show that the dynamics of quantum coherence exhibit an inverse correlation with the emergence and enhancement of MBS-induced split peaks in the drag transconductance as the inter-MBS coupling increases. A comparative analysis with Andreev bound states (ABSs) reveals key differences, that is, MBS-induced transconductance peaks are symmetric and robust, while ABS features are asymmetric and sensitive to perturbations. These findings establish clear experimental criteria for distinguishing MBSs and provide a practical framework for probing Majorana physics through nonlocal transport.",
          "authors": [
            "Zi-Wei Li",
            "Jiaojiao Chen",
            "Wei Xiong",
            "Xiao Xue",
            "Zeng-Zhao Li"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02404",
          "title": "Signed Mahonian Polynomials on Colored Derangements",
          "abstract": "The polynomial $\\sum_{\\pi \\in W}q^{maj(\\pi)}$ of major index over a classical Weyl group $W$ with a generating set $S$ is called the Mahonian polynomial over $W$, and also the polynomial $\\sum_{\\pi \\in W}(-1)^{l(\\pi)}q^{maj(\\pi)}$ of major index together with sign over the group $W$ is called the signed Mahonian polynomial over the group $W$, where $l$ is the length function on $W$ defined in terms of the generating set $S$. We concern with the signed Mahonian polynomial $$\\sum_{\\pi \\in D_{n}^{(c)}}(-1)^{L(\\pi)}q^{fmaj(\\pi)}$$ on the set $D_{n}^{(c)}$ of colored derangements in the group $G_{c,n}$ of colored permutations, where $L$ denotes the length function defined by means of a complex root system described by Bremke and Malle in $G_{c,n}$ and $fmaj$ defined by Adin and Roichman in $G_{c,n}$ represents the \\textit{flag-major index}, which is a Mahonian statistic. As an application of the formula for signed Mahonian polynomials on the set of colored derangements, we will derive a formula to count colored derangements of even length in $G_{c,n}$ when $c$ is an even number. Finally, we conclude by providing a formula for the difference between the number of derangements of even and odd lengths in $G_{c,n}$ when $c$ is even.",
          "authors": [
            "Hasan Arslan",
            "Nazmiye Alemdar"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02412",
          "title": "New Bounds for Circular Trace Reconstruction",
          "abstract": "The ''trace reconstruction'' problem asks, given an unknown binary string $x$ and a channel that repeatedly returns ''traces'' of $x$ with each bit randomly deleted with some probability $p$, how many traces are needed to recover $x$? There is an exponential gap between the best known upper and lower bounds for this problem. Many variants of the model have been introduced in hopes of motivating or revealing new approaches to narrow this gap. We study the variant of circular trace reconstruction introduced by Narayanan and Ren (ITCS 2021), in which traces undergo a random cyclic shift in addition to random deletions. We show an improved lower bound of $\\tilde{\\Omega}(n^5)$ for circular trace reconstruction. This contrasts with the (previously) best known lower bounds of $\\tilde{\\Omega}(n^3)$ in the circular case and $\\tilde{\\Omega}(n^{3/2})$ in the linear case. Our bound shows the indistinguishability of traces from two sparse strings $x,y$ that each have a constant number of nonzeros. Can this technique be extended significantly? How hard is it to reconstruct a sparse string $x$ under a cyclic deletion channel? We resolve these questions by showing, using Fourier techniques, that $\\tilde{O}(n^6)$ traces suffice for reconstructing any constant-sparse string in a circular deletion channel, in contrast to the upper bound of $\\exp(\\tilde{O}(n^{1/3}))$ for general strings in the circular deletion channel. This shows that new algorithms or new lower bounds must focus on non-constant-sparse strings.",
          "authors": [
            "Arnav Burudgunte",
            "Paul Valiant",
            "Hongao Wang"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02415",
          "title": "Integrated Sliding-Short/Probe Tuner with Doorknob Transition for High-Q Cavities",
          "abstract": "We present an integrated three-knob tuner that internalizes impedance matching inside the launch adapter of a waveguide-fed, high-$Q$ cavity. The tuner combines a waveguide sliding short, a doorknob transition, and a micrometer-driven adjustable coaxial probe. A transmission-line/ABCD model is derived that maps the three mechanical degrees of freedom to the electrical objectives $\\Gamma \\rightarrow 0$, $\\beta$, and $Q_{\\rm L}$, explicitly including the fused-silica feedthrough capacitance. The model yields closed-form matching conditions and predicts the critical-coupling set. Full-wave FEM simulations and bench measurements validate the approach: with $h \\approx 0.55$~mm and backshort distance $\\approx 0.80$~mm, the return loss reaches $|S_{11}| \\approx -30$~dB near 17.8--18.1~GHz while sustaining peak electric fields of $\\sim 1.8 \\times 10^5$~V/m at the nozzle (normalized to 1~W). The measured through loss of the launch assembly is $|S_{21}| \\approx 0.7$--$0.8$~dB at resonance. A parametric study shows that backshort lengths $L_{\\rm {bs}} \\geq 0.5 \\lambda_{\\rm g}$ excite a parasitic stub resonance, introducing a second $S_{11}$ minimum and localizing energy behind the doorknob; keeping $L_{\\rm {bs}} \\leq 0.4 \\lambda_g$ avoids this. In helium plasma discharges at $P_{\\rm {in}} = 10$~W, \\textit{in-situ} retuning of the short and probe maintained a favorable match as the plasma impedance evolved, increasing absorbed power from $\\sim 43\\%$ to $\\sim 76\\%$ while increasing helium propellant flow rate from 25 to 351~sccm. The compact tuner eliminates external stub boxes and generalizes to other waveguide-coupled resonators and plasma sources.",
          "authors": [
            "Saptarshi Biswas",
            "Sven G. Bilén"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02420",
          "title": "Laser-driven electrodynamic implosion of fast ions in a thin shell",
          "abstract": "Collision of laser-driven subrelativistic high density ion flows provides a way to create extremely compressed ion conglomerates and study their properties. This paper presents a theoretical study of the electrodynamic implosion of ions inside a hollow spherical or cylindrical shell irradiated by femtosecond petawatt laser pulses. We propose to apply a very effective mechanism for ion acceleration in a selfconsistent field with strong charge separation, based on the oscillation of laser accelerated fast electrons in this field near the thin shell. Fast electrons are generated on the outer side of the shell under irradiation by the intense laser pulses. It is shown that ions, in particular protons, may be accelerated at the implosion stage to energies of tens and hundreds of MeV when a sub-micrometer shell is irradiated by femtosecond laser pulses with an intensity of 10^21 - 10^23 W cm^-2. .",
          "authors": [
            "S. Yu. Guskov",
            "Ph. Korneev",
            "M. Murakami"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02422",
          "title": "Quantum feature encoding optimization",
          "abstract": "Quantum Machine Learning (QML) holds the promise of enhancing machine learning modeling in terms of both complexity and accuracy. A key challenge in this domain is the encoding of input data, which plays a pivotal role in determining the performance of QML models. In this work, we tackle a largely unaddressed aspect of encoding that is unique to QML modeling -- rather than adjusting the ansatz used for encoding, we consider adjusting how data is conveyed to the ansatz. We specifically implement QML pipelines that leverage classical data manipulation (i.e., ordering, selecting, and weighting features) as a preprocessing step, and evaluate if these aspects of encoding can have a significant impact on QML model performance, and if they can be effectively optimized to improve performance. Our experimental results, applied across a wide variety of data sets, ansatz, and circuit sizes, with a representative QML approach, demonstrate that by optimizing how features are encoded in an ansatz we can substantially and consistently improve the performance of QML models, making a compelling case for integrating these techniques in future QML applications. Finally we demonstrate the practical feasibility of this approach by running it using real quantum hardware with 100 qubit circuits and successfully achieving improved QML modeling performance in this case as well.",
          "authors": [
            "Tommaso Fioravanti",
            "Brian Quanz",
            "Gabriele Agliardi",
            "Edgar Andres Ruiz Guzman",
            "Ginés Carrascal",
            "Jae-Eun Park"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02422",
          "title": "Quantum feature encoding optimization",
          "abstract": "Quantum Machine Learning (QML) holds the promise of enhancing machine learning modeling in terms of both complexity and accuracy. A key challenge in this domain is the encoding of input data, which plays a pivotal role in determining the performance of QML models. In this work, we tackle a largely unaddressed aspect of encoding that is unique to QML modeling -- rather than adjusting the ansatz used for encoding, we consider adjusting how data is conveyed to the ansatz. We specifically implement QML pipelines that leverage classical data manipulation (i.e., ordering, selecting, and weighting features) as a preprocessing step, and evaluate if these aspects of encoding can have a significant impact on QML model performance, and if they can be effectively optimized to improve performance. Our experimental results, applied across a wide variety of data sets, ansatz, and circuit sizes, with a representative QML approach, demonstrate that by optimizing how features are encoded in an ansatz we can substantially and consistently improve the performance of QML models, making a compelling case for integrating these techniques in future QML applications. Finally we demonstrate the practical feasibility of this approach by running it using real quantum hardware with 100 qubit circuits and successfully achieving improved QML modeling performance in this case as well.",
          "authors": [
            "Tommaso Fioravanti",
            "Brian Quanz",
            "Gabriele Agliardi",
            "Edgar Andres Ruiz Guzman",
            "Ginés Carrascal",
            "Jae-Eun Park"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02426",
          "title": "Progress in relativistic laser-plasma interaction with kilotesla-level applied magnetic fields",
          "abstract": "We report on progress in the understanding of the effects of kilotesla-level applied magnetic fields on relativistic laser-plasma interactions. Ongoing advances in magnetic-field-generation techniques enable new and highly desirable phenomena, including magnetic- field-amplification platforms with reversible sign, focusing ion acceleration, and bulk-relativistic plasma heating. Building on recent advance- ments in laser-plasma interactions with applied magnetic fields, we introduce simple models for evaluating the effects of applied magnetic fields in magnetic-field amplification, sheath-based ion acceleration, and direct laser acceleration. These models indicate the feasibility of observing beneficial magnetic-field effects under experimentally relevant conditions and offer a starting point for future experimental design.",
          "authors": [
            "K. Weichman",
            "A. P. L. Robinson",
            "M. Murakami",
            "J. J. Santos",
            "S. Fujioka",
            "T. Toncian",
            "J. P. Palastro",
            "A. V. Arefiev"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02428",
          "title": "Effective hybrid joint universality for Dirichlet $L$-functions and its application",
          "abstract": "In 2003, Garunkštis provided a lower bound for the lower density of the universality theorem for the Riemann zeta-function. In this paper, we generalize this result for the hybrid joint universality theorem for Dirichlet $L$-functions whose moduli are prime numbers. Furthermore, by its application, we estimate a lower bound of the lower density of the universality theorem for Hurwitz zeta-functions with rational parameters.",
          "authors": [
            "Keita Nakai"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02429",
          "title": "MMP on the generic fiber of log Calabi--Yau type fibration",
          "abstract": "We study the minimal model program on the geometric generic fiber of a fibration whose closed fibers are of $\\varepsilon$-lc log Calabi--Yau type. We prove that for a fibration $f:X\\to S$ of varieties, if the fibers are of $\\varepsilon$-lc log Calabi--Yau type, then the geometric generic fiber $X_{\\overline{\\eta}}$ is pklt. In particular, for any big divisor $D$ on $X_{\\overline{\\eta}}$, we can run the anticanonical MMP and $D$-MMP with scaling of an ample divisor on $X_{\\overline{\\eta}}$.",
          "authors": [
            "Donghyeon Kim",
            "Dae-Won Lee"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02430",
          "title": "Harnessing Multifractality to Enhance Thermal Stability in Mixed-Phase Vanadium Oxide Thin Films",
          "abstract": "Vanadium oxide thin films exhibit temperature-driven electronic transitions desirable for sensing and microelectronic applications, yet their performance is often limited by thermal hysteresis. This study demonstrates that electronic stability is governed not simply by roughness or crystallinity but by a unique combination of surface morphological complexity and thermal hysteresis, revealed across films deposited with varying working pressure using Direct Current/Radio Frequency magnetron sputtering. Specifically, the film grown at 15 mTorr shows a distinct convergence of highest morphological vertical complexity and lowest thermal hysteresis, exhibiting nearly reversible transport with activation energies ranging from 0.26 to 0.28 eV and negative temperature coefficients of resistance between -0.0337 and -0.035 K-1. While conventional roughness metrics and mono-fractal parameters do not capture this behavior, multifractal detrended fluctuation analysis uncovers a pronounced peak in multifractality strength, which correlates inversely with thermal hysteresis. This highlights multifractality strength as a predictive descriptor of electronic stability, identifying a multiscale structural signature that enhances stress accommodation during thermal cycling. These results define an optimal deposition window and provide a morphology-guided pathway for developing thermally robust mixed-phase vanadium oxide films.",
          "authors": [
            "Abhijeet Das",
            "Ram Pratap Yadav",
            "Rashmi Roy Karmakar",
            "Jyoti Jaiswal",
            "Sanjeev Kumar"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02433",
          "title": "Study of fully coupled 3D envelope instability using automatic differentiation",
          "abstract": "Auto-differentiation is a powerful tool for computing derivatives of simulation results with respect to given parameters. In this letter, we have applied this tool to investigate the instability of a dynamics system that is governed by 21 ordinary differential equations. This second-order instability (named envelope instability) is driven by space-charge effects and has significant impact on the operational regimes of particle accelerators. Our study delves into the three-dimensional envelope instability, incorporating both transverse and longitudinal coupling. Conventionally, analyzing this complex system would necessitate solving 441 ordinary differential equations, which is computationally intractable. However, by employing auto-differentiation, we were able to track only 21 equations. This approach allowed us to uncover an additional instability stopband, which arises from space-charge-induced coupling and has not been reported in previous studies. This research highlights the significant advantages of auto-differentiation in analyzing complicated dynamical systems involving a large number of ordinary differential equations.",
          "authors": [
            "Ji Qiang"
          ],
          "primary_category": "physics.acc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02443",
          "title": "Demonstration of magic dressing of $^3$He",
          "abstract": "A common concern in high-precision neutron electric dipole moment (nEDM) experiments is that of magnetic field stability. For static fields, this problem can be mitigated through the use of a superconducting holding field coil, which when operated in persistent current mode serves to stabilize the magnetic field. However, such a solution is not viable when time-varying magnetic fields are present, as is the case for the spin dressing mode of the proposed nEDMSF (nEDM super-fluid) experiment. This experiment features an oscillating magnetic field to dress the gyromagnetic ratios of $^3$He and neutrons to the same value, a condition known as critical dressing. Fluctuations in the dressing field amplitude have the potential to disrupt this condition. Here, we investigate a modification to spin dressing, termed ``magic dressing,'' which renders the system insensitive to small variations in dressing field amplitude. We further demonstrate the utility of this method for the single spin-species case using a sample of polarized $^3$He. We find a dramatic increase in transverse relaxation time in the presence of magnetic field gradients.",
          "authors": [
            "Raymond Tat"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02443",
          "title": "Demonstration of magic dressing of $^3$He",
          "abstract": "A common concern in high-precision neutron electric dipole moment (nEDM) experiments is that of magnetic field stability. For static fields, this problem can be mitigated through the use of a superconducting holding field coil, which when operated in persistent current mode serves to stabilize the magnetic field. However, such a solution is not viable when time-varying magnetic fields are present, as is the case for the spin dressing mode of the proposed nEDMSF (nEDM super-fluid) experiment. This experiment features an oscillating magnetic field to dress the gyromagnetic ratios of $^3$He and neutrons to the same value, a condition known as critical dressing. Fluctuations in the dressing field amplitude have the potential to disrupt this condition. Here, we investigate a modification to spin dressing, termed ``magic dressing,'' which renders the system insensitive to small variations in dressing field amplitude. We further demonstrate the utility of this method for the single spin-species case using a sample of polarized $^3$He. We find a dramatic increase in transverse relaxation time in the presence of magnetic field gradients.",
          "authors": [
            "Raymond Tat"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02443",
          "title": "Demonstration of magic dressing of $^3$He",
          "abstract": "A common concern in high-precision neutron electric dipole moment (nEDM) experiments is that of magnetic field stability. For static fields, this problem can be mitigated through the use of a superconducting holding field coil, which when operated in persistent current mode serves to stabilize the magnetic field. However, such a solution is not viable when time-varying magnetic fields are present, as is the case for the spin dressing mode of the proposed nEDMSF (nEDM super-fluid) experiment. This experiment features an oscillating magnetic field to dress the gyromagnetic ratios of $^3$He and neutrons to the same value, a condition known as critical dressing. Fluctuations in the dressing field amplitude have the potential to disrupt this condition. Here, we investigate a modification to spin dressing, termed ``magic dressing,'' which renders the system insensitive to small variations in dressing field amplitude. We further demonstrate the utility of this method for the single spin-species case using a sample of polarized $^3$He. We find a dramatic increase in transverse relaxation time in the presence of magnetic field gradients.",
          "authors": [
            "Raymond Tat"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02446",
          "title": "Obstructions of deforming complex structures and cohomology contractions",
          "abstract": "The Kodaira principle asserts that suitable cohomological contraction maps annihilate obstructions to deforming complex structures. In this paper, we revisit these phenomena from a purely analytic point of view, developing a refined power series method for the deformation of $(p,q)$-forms and complex structures. Working with the Frölicher spectral sequence, we show that under natural partial vanishing conditions on its differentials, all obstruction classes lie in the kernel of the corresponding contraction maps. This yields a refined Kodaira principle that recovers and strictly extends the known results. As a main application, we obtain new unobstructedness criteria for compact complex manifolds with trivial canonical bundle.",
          "authors": [
            "Xueyuan Wan",
            "Wei Xia"
          ],
          "primary_category": "math.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02451",
          "title": "Twisted Calabi functional and twisted Calabi flow",
          "abstract": "This paper investigates the twisted Calabi functional and the associated twisted Calabi flow on compact Kähler manifolds. Our main contributions are threefold: first, we establish the convexity of the twisted Calabi functional at its critical points; second, we prove the short-time existence of the twisted Calabi flow; and third, we demonstrate the stability of this flow in the neighborhood of twisted constant scalar curvature Kähler metrics. These results provide an analytic foundation for studying the twisted Calabi flow and resolve questions about its local behavior.",
          "authors": [
            "Jie He",
            "Haozhao Li"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02466",
          "title": "An expository review of the Chebyshev-Sylvester method in prime number theory",
          "abstract": "This paper provides a detailed expository and computational account of the elementary methods developed by P. L. Chebyshev and J. J. Sylvester to establish explicit bounds on the prime counting function. The core of the method involves replacing the Möbius function with a finitely supported arithmetic function in the convolution identities, relating the Chebyshev function psi(x) to the summatory logarithm function T(x) = log([x]!). We present a comprehensive analysis of the various schemes proposed by Chebyshev and Sylvester, with a central focus on Sylvester's innovative iterative refinement procedure. By implementing this procedure computationally, we replicate, verify, and optimize the historical results, providing a self-contained pedagogical resource for this pivotal technique in analytic number theory.",
          "authors": [
            "Tsogtgerel Gantumur"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02468",
          "title": "Quantum Optimization in Wireless Communication Systems: Principles and Applications",
          "abstract": "Quantum optimization is poised to play a transformative role in the design of next-generation wireless communication systems by addressing key computational and technological challenges. This paper provides an overview of the principles of adiabatic quantum computing, the foundation of quantum optimization, and explores its two primary computational models: quantum annealing and the gate-based quantum approximate optimization algorithm. By highlighting their core features, performance benefits, limitations, and distinctions, we position these methods as promising tools for advancing wireless communication system design. As a case study, we examine the design of passive reconfigurable intelligent surface beamforming with binary phase-shift resolution, supported by experimental results obtained from real-world quantum hardware.",
          "authors": [
            "Ioannis Krikidis",
            "Valentin Gilbert"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02468",
          "title": "Quantum Optimization in Wireless Communication Systems: Principles and Applications",
          "abstract": "Quantum optimization is poised to play a transformative role in the design of next-generation wireless communication systems by addressing key computational and technological challenges. This paper provides an overview of the principles of adiabatic quantum computing, the foundation of quantum optimization, and explores its two primary computational models: quantum annealing and the gate-based quantum approximate optimization algorithm. By highlighting their core features, performance benefits, limitations, and distinctions, we position these methods as promising tools for advancing wireless communication system design. As a case study, we examine the design of passive reconfigurable intelligent surface beamforming with binary phase-shift resolution, supported by experimental results obtained from real-world quantum hardware.",
          "authors": [
            "Ioannis Krikidis",
            "Valentin Gilbert"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02470",
          "title": "Su-Schrieffer-Heeger model driven by sequences of two unitaries: periodic, quasiperiodic and random protocols",
          "abstract": "We study the effect of driving the Su-Schrieffer-Heeger model using two unitary operators $U_1$ and $U_2$ in different combinations; the unitaries differ in the values of the inter-cell hopping amplitudes. Specifically, we study the cases where the unitaries are applied periodically, quasiperiodically and randomly. For a periodic protocol, when $U_1$ and $U_2$ are applied alternately, we find that end modes may appear, but the number of end modes does not always agree with the winding number which is a $Z$-valued topological invariant. We then study the Loschmidt echo ($LE$) starting with a random initial state. We find that the $LE$ exhibits pronounced oscillations whose Fourier transform has peaks at frequencies which agree with the most prominent gaps between pairs of quasienergies. Next, when $U_1$ and $U_2$ are applied in a quasiperiodic way (we consider Fibonacci and Thue-Morse protocols), we study the $LE$ starting with an initial state which is an end mode of one of the unitaries. When the inter-cell hoppings differ by a small amount denoted by $\\epsilon$, and the time period $T$ of each unitary is also small, the distance between the unitaries is found to be proportional to $\\epsilon T$. We then find that the $LE$ oscillates around a particular value for a very long time before decaying to zero. The deviation of the value of the $LE$ from 1 scales as $\\epsilon^2$ for a fixed value of $T$, while the time after which the $LE$ starts decaying to zero has an interesting dependence on $\\epsilon$ and $T$. Finally, when $U_1$ and $U_2$ are applied in a random order, the $LE$ rapidly decays to zero with increasing time. We have presented a qualitative understanding of the above results.",
          "authors": [
            "Maitri Ganguli",
            "Diptiman Sen"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02470",
          "title": "Su-Schrieffer-Heeger model driven by sequences of two unitaries: periodic, quasiperiodic and random protocols",
          "abstract": "We study the effect of driving the Su-Schrieffer-Heeger model using two unitary operators $U_1$ and $U_2$ in different combinations; the unitaries differ in the values of the inter-cell hopping amplitudes. Specifically, we study the cases where the unitaries are applied periodically, quasiperiodically and randomly. For a periodic protocol, when $U_1$ and $U_2$ are applied alternately, we find that end modes may appear, but the number of end modes does not always agree with the winding number which is a $Z$-valued topological invariant. We then study the Loschmidt echo ($LE$) starting with a random initial state. We find that the $LE$ exhibits pronounced oscillations whose Fourier transform has peaks at frequencies which agree with the most prominent gaps between pairs of quasienergies. Next, when $U_1$ and $U_2$ are applied in a quasiperiodic way (we consider Fibonacci and Thue-Morse protocols), we study the $LE$ starting with an initial state which is an end mode of one of the unitaries. When the inter-cell hoppings differ by a small amount denoted by $\\epsilon$, and the time period $T$ of each unitary is also small, the distance between the unitaries is found to be proportional to $\\epsilon T$. We then find that the $LE$ oscillates around a particular value for a very long time before decaying to zero. The deviation of the value of the $LE$ from 1 scales as $\\epsilon^2$ for a fixed value of $T$, while the time after which the $LE$ starts decaying to zero has an interesting dependence on $\\epsilon$ and $T$. Finally, when $U_1$ and $U_2$ are applied in a random order, the $LE$ rapidly decays to zero with increasing time. We have presented a qualitative understanding of the above results.",
          "authors": [
            "Maitri Ganguli",
            "Diptiman Sen"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02476",
          "title": "Quantum-Based Self-Attention Mechanism for Hardware-Aware Differentiable Quantum Architecture Search",
          "abstract": "The automated design of parameterized quantum circuits for variational algorithms in the NISQ era faces a fundamental limitation, as conventional differentiable architecture search relies on classical models that fail to adequately represent quantum gate interactions under hardware noise. We introduce the Quantum-Based Self-Attention for Differentiable Quantum Architecture Search (QBSA-DQAS), a meta-learning framework featuring quantum-based self-attention and hardware-aware multi-objective search. The framework employs a two-stage quantum self-attention module that computes contextual dependencies by mapping architectural parameters through parameterized quantum circuits, replacing classical similarity metrics with quantum-derived attention scores, then applies position-wise quantum transformations for feature enrichment. Architecture search is guided by a task-agnostic multi-objective function jointly optimizing noisy expressibility and Probability of Successful Trials (PST). A post-search optimization stage applies gate commutation, fusion, and elimination to reduce circuit complexity. Experimental validation demonstrates superior performance on VQE tasks and large-scale Wireless Sensor Networks. For VQE on H$_2$, QBSA-DQAS achieves 0.9 accuracy compared to 0.89 for standard DQAS. Post-search optimization reduces discovered circuit complexity by up to 44% in gate count and 47% in depth without accuracy degradation. The framework maintains robust performance across three molecules and five IBM quantum hardware noise models. For WSN routing, discovered circuits achieve 8.6% energy reduction versus QAOA and 40.7% versus classical greedy methods, establishing the effectiveness of quantum-native architecture search for NISQ applications.",
          "authors": [
            "Yuxiang Liu",
            "Sixuan Li",
            "Fanxu Meng",
            "Zaichen Zhang",
            "Xutao Yu"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02477",
          "title": "Qudits offer no advantages over dits for sending random messages",
          "abstract": "We consider the following simple scenario: Alice has one of many possible messages, drawn from a known distribution, and wants to maximize the probability that Bob guesses her message correctly. We prove that if Alice can send only a qudit to Bob, without preshared entanglement, there is never any advantage over sending him a classical dit. This result was previously known only for a uniform distribution. We also prove a mixed-state generalization of this result in the form of an upper bound on the success probability of discriminating between mixed quantum states with a single measurement. This bound is based solely on the dimension, probability distribution, and eigenvalues of the states and is sharp among such bounds.",
          "authors": [
            "Ronit Shah"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02477",
          "title": "Qudits offer no advantages over dits for sending random messages",
          "abstract": "We consider the following simple scenario: Alice has one of many possible messages, drawn from a known distribution, and wants to maximize the probability that Bob guesses her message correctly. We prove that if Alice can send only a qudit to Bob, without preshared entanglement, there is never any advantage over sending him a classical dit. This result was previously known only for a uniform distribution. We also prove a mixed-state generalization of this result in the form of an upper bound on the success probability of discriminating between mixed quantum states with a single measurement. This bound is based solely on the dimension, probability distribution, and eigenvalues of the states and is sharp among such bounds.",
          "authors": [
            "Ronit Shah"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02477",
          "title": "Qudits offer no advantages over dits for sending random messages",
          "abstract": "We consider the following simple scenario: Alice has one of many possible messages, drawn from a known distribution, and wants to maximize the probability that Bob guesses her message correctly. We prove that if Alice can send only a qudit to Bob, without preshared entanglement, there is never any advantage over sending him a classical dit. This result was previously known only for a uniform distribution. We also prove a mixed-state generalization of this result in the form of an upper bound on the success probability of discriminating between mixed quantum states with a single measurement. This bound is based solely on the dimension, probability distribution, and eigenvalues of the states and is sharp among such bounds.",
          "authors": [
            "Ronit Shah"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02479",
          "title": "Orbital-resolved three-body recombination across a p-wave Feshbach resonance in ultracold $^6$Li",
          "abstract": "We report precision, orbital-resolved measurements of three-body recombination near the 159~G $p$-wave Feshbach resonance in an ultracold gas of $^{6}$Li atoms prepared in their lowest hyperfine state. Using a radio-frequency gated protocol that suppresses magnetic-field transients below the milligauss level, we resolve loss features associated with the $|m_\\ell|=1$ and $m_\\ell=0$ orbital projections. The measured three-body loss coefficient $L_3$ is well captured by a thermally averaged cascade-recombination model, enabling extraction of the resonance splitting $\\delta B$ and effective-range parameter $k_e$. At the lowest temperature, we obtain $\\delta B = 7.6(3)$~mG and $k_e = 0.151(6)\\,a_0^{-1}$, both in quantitative agreement with coupled-channel theory. These results establish orbital-resolved three-body spectroscopy as a precision probe of $p$-wave scattering and provide a benchmark for microscopic models of resonant few-body loss.",
          "authors": [
            "Shaokun Liu",
            "Zhekang Xu",
            "Shuai Peng",
            "Sijia Peng",
            "Tangqian Shu",
            "Jiaming Li",
            "Le Luo"
          ],
          "primary_category": "cond-mat.quant-gas",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02488",
          "title": "Translational symmetry breaking in the electronic nematic phase of BaFe2As2",
          "abstract": "The microscopic origin of the nematicity, namely, four-fold rotational symmetry breaking in iron-based superconductors has been controversial since its discovery. In particular, its relationship with the stripe-type spin-density-wave order and the orthorhombic lattice distortion in the antiferromagnetic orthorhombic (AFO) phase, which exists at temperatures below the electronic nematic phase, has been highly debated. Here, we report on the temperature evolution of angle-resolved photoemission spectra of the parent compound BaFe2As2, ranging from the AFO to nematic to paramagnetic phases. The Dirac cone feature, which is formed in the AFO phase, is found to persist in the nematic phase, suggesting that an antiferroic order of the same periodicity as the AFO phase persists in the nematic phase. Considering the relatively shallow d_xy orbital in BaFe2As2, we propose that an antiferro-orbital order involving the d_xy and other orbitals takes place in the nematic phase.",
          "authors": [
            "K. Koshiishi",
            "L. Liu",
            "K. Okazaki",
            "H. Suzuki",
            "J. Xu",
            "M. Horio",
            "H. Kumigashira",
            "K. Ono",
            "M. Nakajima",
            "S. Ishida",
            "K. Kihou",
            "C. H. Lee",
            "A. Iyo",
            "H. Eisaki",
            "S. Uchida",
            "A. Fujimori"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02490",
          "title": "Quasi-steady electron-excitonic complexes coupling in a two-dimensional semiconductor",
          "abstract": "Excitons and their complexes govern optical-related behaviors in semiconductors. Here, using angle-resolved photoemission spectroscopy (ARPES), we have elucidated the light-matter interaction mediated by quasi-steady excitonic complexes within a monolayer of the prototypical two-dimensional (2D) semiconductor WSe2. Under continuous incident light, we have observed the generation of quasi-steady excitons and their complexes, encompassing ground and excited state excitons, trions, as well as their intricate interplay. We further show spectral evidence of electronic excitation states within the background of quasi-steady excitonic complexes, characterized by valence band (VB) effective mass renormalization, the enhanced spin-orbit coupling (SOC), the formation of an excitonic gap near the Fermi level (EF ) of the conduction band (CB), and intervalley excitonic band folding. Our findings not only unveil a quasi-steady excitonic complex background for the creation of diverse electronic excitations in 2D semiconductors but also offer new insights into the role of excitons in the charge density wave (CDW) formation mechanism and facilitate the advancement of correlated electronic state engineering based on the coupling between electrons and excitonic complexes in a quasi-equilibrium state.",
          "authors": [
            "Shangkun Mo",
            "Hao Zhong",
            "Keming Zhao",
            "Yunfei Bai",
            "Dingkun Qin",
            "Chunlong Wu",
            "Qiang Wan",
            "Renzhe Li",
            "Cao Peng",
            "Xingzhe Wang",
            "Enting Li",
            "Sheng Meng",
            "Nan Xu"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02493",
          "title": "Superchannel without Tears: A Generalized Occam's Razor for Quantum Processes",
          "abstract": "Quantum channels function as the operational primitives of quantum theory, while superchannels describe the most general transformations acting upon them. Yet the prevailing framework for superchannels is both internally inconsistent, owing to the coexistence of distinct Choi operator constructions, and structurally incomplete, lacking the analogue of representations that ground channel theory. We resolve these issues by combining tensor-network methods with a generalized Occam's razor introduced here, establishing a unified foundation for superchannels. Our framework establishes the connections between competing Choi formulations, develops the Kraus, Stinespring, and Liouville representations for superchannels, and provides a simplified derivation of the realization theorem that identifies the minimal memory required to implement a given transformation. These structural tools also enable characterizations of superchannels that destroy quantum correlations or causal structure, opening a systematic route to non-Markovian quantum dynamics.",
          "authors": [
            "Yunlong Xiao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02500",
          "title": "Plasmonic nanopore to monitor in-pore chemistry",
          "abstract": "In solid-state nanopores, achieving reliable control over pore aperture opening and closing (gating) remains a major challenge. Gating can be driven by the applied voltage involving electrically tunable chemical reactions, achieved by selecting appropriate compounds within the nanopore volume. In particular, cyclic precipitation and dissolution of metal phosphates can be triggered by regulating cation transport through an applied transmembrane voltage, thereby enabling reversible pore gating. Under negative bias, metal phosphate precipitates form inside the pore, obstructing ion flow and reducing current. Switching the polarity dissolves the precipitates, restoring ionic conductance. This process effectively produces a nanofluidic diode characterized by a remarkably high rectification ratio. To probe these localized chemical reactions more directly, we employed a plasmonic nanopore that generates strong confined fields, enabling surface-enhanced Raman scattering (SERS) measurements within the nanopore volume during cyclic gating. These measurements not only validate the proposed in-pore chemistry but also highlight the potential of plasmonic nanopores as powerful tools for monitoring nanoscale chemical processes with high spatial resolution.",
          "authors": [
            "Weihong Wang",
            "Shukun Weng",
            "Ali Douaki",
            "German Lanzavecchia",
            "Yanqiu Zou",
            "Qifei Ma",
            "Huaizhou Jin",
            "Roman Krahne",
            "Shangzhong Jin",
            "Makusu Tsutsui",
            "Denis Garoli"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02504",
          "title": "Emergent Chiral Spin Crystal Phase in (111) SrRuO3 Thin Films",
          "abstract": "Perovskite ruthenates are fascinating playgrounds for exploring topological spin textures, but generally rely on extrinsic mechanisms to trigger the noncoplanar states. Here we report the discovery of an emergent chiral spin crystal phase in (111) SrRuO3 epitaxial films, characterized by a significant topological Hall effect and noncoplanar spin arrangements with different propagation vectors along two orthogonal directions. Instead of driven by the enhanced Dzyaloshinskii-Moriya interaction due to broken inversion symmetry at heterointerfaces, this emergent state arises intrinsically from the interplay of dipolar interactions and magnetic frustration, leading to the stabilization of topological phases in much thicker films. These findings open a new pathway for creating and controlling the topological spin states in perovskites, with broad implications for spintronic device design.",
          "authors": [
            "Zhaoqing Ding",
            "Yongjie Xie",
            "Xuejiao Chen",
            "Sheng Wang",
            "Zhen Wang",
            "Zeguo Lin",
            "Enling Wang",
            "Xiaofeng Wu",
            "Mingyu Yang",
            "Yuelong Xiong",
            "Meng Meng",
            "Fang Yang",
            "Jiandi Zhang",
            "Xianggang Qiu",
            "XIaoran Liu",
            "Jiandong Guo"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02514",
          "title": "Low-temperature thermal conductivity of the substrate material YAlO3 and its unconventional sister compound YbAlO3",
          "abstract": "We present thermal conductivity data on single crystals of YAlO3 and YbAlO3 for temperatures between 2 K and 300 K and the heat current along b and c. Both materials are very good thermal conductors in the investigated temperature range. The thermal conductivity in these electrical insulators is due to phonons. The effect of Y-Yb exchange is found to be rather small despite the considerable difference in density and average atomic mass. For YAlO3 we find a moderate thermal conductivity anisotropy with weak temperature dependence and a ratio of c to b direction between at most 1 and 2.2. It is discussed with regard to the velocities of sound and relevant scattering processes. For YbAlO3 the small crystal size limits the precision of absolute thermal conductivity values and does not allow drawing conclusions on the anisotropy. Our results on YAlO3 confirm that the material is suitable for applications requiring a good thermal conductivity at temperatures down to liquid helium, such as lasers, substrates, and detectors.",
          "authors": [
            "Parisa Mokhtari",
            "Ulrike Stockert",
            "Stanislav E. Nikitin",
            "Leonid Vasylechko",
            "Manuel Brando",
            "Elena Hassinger"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02516",
          "title": "Improved Ising Meson Spectroscopy Simulation on a Noisy Digital Quantum Device",
          "abstract": "The transverse-field Ising model serves as a paradigm for studying confinement and excitation spectra, particularly the emergence of $E_8$ symmetry near criticality. However, experimentally resolving the Ising meson spectroscopy required to verify these symmetries is challenging on near-term quantum hardware due to the depth of circuits required for real-time evolution. Here, we demonstrate improved spectroscopy of confined excitations using two distinct error-resilient circuit construction techniques on the IBM Torino device: first-order Trotter decomposition utilizing native fractional gates, and a tensor-network-based circuit compression via Riemannian optimization. By analyzing the Fourier spectrum of error-mitigated time-series data, we successfully identify key signatures of $E_8$ symmetry despite hardware noise. These results validate the viability of both circuit compression and hardware-efficient compilation for probing complex topological phenomena on NISQ devices.",
          "authors": [
            "Hao-Ti Hung",
            "Isabel Nha Minh Le",
            "Johannes Knolle",
            "Ying-Jer Kao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02516",
          "title": "Improved Ising Meson Spectroscopy Simulation on a Noisy Digital Quantum Device",
          "abstract": "The transverse-field Ising model serves as a paradigm for studying confinement and excitation spectra, particularly the emergence of $E_8$ symmetry near criticality. However, experimentally resolving the Ising meson spectroscopy required to verify these symmetries is challenging on near-term quantum hardware due to the depth of circuits required for real-time evolution. Here, we demonstrate improved spectroscopy of confined excitations using two distinct error-resilient circuit construction techniques on the IBM Torino device: first-order Trotter decomposition utilizing native fractional gates, and a tensor-network-based circuit compression via Riemannian optimization. By analyzing the Fourier spectrum of error-mitigated time-series data, we successfully identify key signatures of $E_8$ symmetry despite hardware noise. These results validate the viability of both circuit compression and hardware-efficient compilation for probing complex topological phenomena on NISQ devices.",
          "authors": [
            "Hao-Ti Hung",
            "Isabel Nha Minh Le",
            "Johannes Knolle",
            "Ying-Jer Kao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02516",
          "title": "Improved Ising Meson Spectroscopy Simulation on a Noisy Digital Quantum Device",
          "abstract": "The transverse-field Ising model serves as a paradigm for studying confinement and excitation spectra, particularly the emergence of $E_8$ symmetry near criticality. However, experimentally resolving the Ising meson spectroscopy required to verify these symmetries is challenging on near-term quantum hardware due to the depth of circuits required for real-time evolution. Here, we demonstrate improved spectroscopy of confined excitations using two distinct error-resilient circuit construction techniques on the IBM Torino device: first-order Trotter decomposition utilizing native fractional gates, and a tensor-network-based circuit compression via Riemannian optimization. By analyzing the Fourier spectrum of error-mitigated time-series data, we successfully identify key signatures of $E_8$ symmetry despite hardware noise. These results validate the viability of both circuit compression and hardware-efficient compilation for probing complex topological phenomena on NISQ devices.",
          "authors": [
            "Hao-Ti Hung",
            "Isabel Nha Minh Le",
            "Johannes Knolle",
            "Ying-Jer Kao"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02518",
          "title": "Thouless pumps and universal geometry-induced drift velocity in multi-sliding quasi-periodic lattices",
          "abstract": "Quantized Thouless pumps in periodic systems, set by Chern numbers or Wannier-center winding, is by now fairly well established, whereas its quasi-periodic extensions still require further clarification. Here, we develop a general quantitative paradigm for bulk Thouless pumps in continuous models with spacetime quasi-periodicity, applicable to arbitrary spatial dimensions. Within this framework, the bulk pumping turns out to be governed by an emergent long wave-length effective potential. Based on this mechanism, we obtain our main result a universal relation between topological drifting and the geometry of quasi Brillouin zone. Reduced to periodic systems, our result gives an explicit and compact formula which enables us to directly calculate Chern numbers by microscopic data. These proposals are corroborated by simulations of one- and two-dimensional continuous moiré-type spacetime quasi-periodic lattices, which exhibit stable, localized, directional drift in excellent agreement with the theory.",
          "authors": [
            "Zixun Xu",
            "Yuan Yao"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02518",
          "title": "Thouless pumps and universal geometry-induced drift velocity in multi-sliding quasi-periodic lattices",
          "abstract": "Quantized Thouless pumps in periodic systems, set by Chern numbers or Wannier-center winding, is by now fairly well established, whereas its quasi-periodic extensions still require further clarification. Here, we develop a general quantitative paradigm for bulk Thouless pumps in continuous models with spacetime quasi-periodicity, applicable to arbitrary spatial dimensions. Within this framework, the bulk pumping turns out to be governed by an emergent long wave-length effective potential. Based on this mechanism, we obtain our main result a universal relation between topological drifting and the geometry of quasi Brillouin zone. Reduced to periodic systems, our result gives an explicit and compact formula which enables us to directly calculate Chern numbers by microscopic data. These proposals are corroborated by simulations of one- and two-dimensional continuous moiré-type spacetime quasi-periodic lattices, which exhibit stable, localized, directional drift in excellent agreement with the theory.",
          "authors": [
            "Zixun Xu",
            "Yuan Yao"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02518",
          "title": "Thouless pumps and universal geometry-induced drift velocity in multi-sliding quasi-periodic lattices",
          "abstract": "Quantized Thouless pumps in periodic systems, set by Chern numbers or Wannier-center winding, is by now fairly well established, whereas its quasi-periodic extensions still require further clarification. Here, we develop a general quantitative paradigm for bulk Thouless pumps in continuous models with spacetime quasi-periodicity, applicable to arbitrary spatial dimensions. Within this framework, the bulk pumping turns out to be governed by an emergent long wave-length effective potential. Based on this mechanism, we obtain our main result a universal relation between topological drifting and the geometry of quasi Brillouin zone. Reduced to periodic systems, our result gives an explicit and compact formula which enables us to directly calculate Chern numbers by microscopic data. These proposals are corroborated by simulations of one- and two-dimensional continuous moiré-type spacetime quasi-periodic lattices, which exhibit stable, localized, directional drift in excellent agreement with the theory.",
          "authors": [
            "Zixun Xu",
            "Yuan Yao"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02518",
          "title": "Thouless pumps and universal geometry-induced drift velocity in multi-sliding quasi-periodic lattices",
          "abstract": "Quantized Thouless pumps in periodic systems, set by Chern numbers or Wannier-center winding, is by now fairly well established, whereas its quasi-periodic extensions still require further clarification. Here, we develop a general quantitative paradigm for bulk Thouless pumps in continuous models with spacetime quasi-periodicity, applicable to arbitrary spatial dimensions. Within this framework, the bulk pumping turns out to be governed by an emergent long wave-length effective potential. Based on this mechanism, we obtain our main result a universal relation between topological drifting and the geometry of quasi Brillouin zone. Reduced to periodic systems, our result gives an explicit and compact formula which enables us to directly calculate Chern numbers by microscopic data. These proposals are corroborated by simulations of one- and two-dimensional continuous moiré-type spacetime quasi-periodic lattices, which exhibit stable, localized, directional drift in excellent agreement with the theory.",
          "authors": [
            "Zixun Xu",
            "Yuan Yao"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02519",
          "title": "Mean First Passage Time of the Symmetric Noisy Voter Model with Arbitrary Initial and Boundary Conditions",
          "abstract": "Models of imitation and herding behavior often underestimate the role of individualistic actions and assume symmetric boundary conditions. However, real-world systems (e.g., electoral processes) frequently involve asymmetric boundaries. In this study, we explore how arbitrarily placed boundary conditions influence the mean first passage time in the symmetric noisy voter model, and how individualistic behavior amplifies this asymmetry. We derive exact analytical expressions for mean first passage time that accommodate any initial condition and two types of boundary configurations: (i) both boundaries absorbing, and (ii) one absorbing and one reflective. In both scenarios, mean first passage time exhibits a clear asymmetry with respect to the initial condition, shaped by the boundary placement and the rate of independent transitions. Symmetry in mean first passage time emerges only when absorbing boundaries are equidistant from the midpoint. Additionally, we show that Kramers' law holds in both configurations when the rate of independent transitions is large. Our analytical results are in excellent agreement with numerical simulations, reinforcing the robustness of our findings.",
          "authors": [
            "Rytis Kazakevičius",
            "Aleksejus Kononovicius"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02519",
          "title": "Mean First Passage Time of the Symmetric Noisy Voter Model with Arbitrary Initial and Boundary Conditions",
          "abstract": "Models of imitation and herding behavior often underestimate the role of individualistic actions and assume symmetric boundary conditions. However, real-world systems (e.g., electoral processes) frequently involve asymmetric boundaries. In this study, we explore how arbitrarily placed boundary conditions influence the mean first passage time in the symmetric noisy voter model, and how individualistic behavior amplifies this asymmetry. We derive exact analytical expressions for mean first passage time that accommodate any initial condition and two types of boundary configurations: (i) both boundaries absorbing, and (ii) one absorbing and one reflective. In both scenarios, mean first passage time exhibits a clear asymmetry with respect to the initial condition, shaped by the boundary placement and the rate of independent transitions. Symmetry in mean first passage time emerges only when absorbing boundaries are equidistant from the midpoint. Additionally, we show that Kramers' law holds in both configurations when the rate of independent transitions is large. Our analytical results are in excellent agreement with numerical simulations, reinforcing the robustness of our findings.",
          "authors": [
            "Rytis Kazakevičius",
            "Aleksejus Kononovicius"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02519",
          "title": "Mean First Passage Time of the Symmetric Noisy Voter Model with Arbitrary Initial and Boundary Conditions",
          "abstract": "Models of imitation and herding behavior often underestimate the role of individualistic actions and assume symmetric boundary conditions. However, real-world systems (e.g., electoral processes) frequently involve asymmetric boundaries. In this study, we explore how arbitrarily placed boundary conditions influence the mean first passage time in the symmetric noisy voter model, and how individualistic behavior amplifies this asymmetry. We derive exact analytical expressions for mean first passage time that accommodate any initial condition and two types of boundary configurations: (i) both boundaries absorbing, and (ii) one absorbing and one reflective. In both scenarios, mean first passage time exhibits a clear asymmetry with respect to the initial condition, shaped by the boundary placement and the rate of independent transitions. Symmetry in mean first passage time emerges only when absorbing boundaries are equidistant from the midpoint. Additionally, we show that Kramers' law holds in both configurations when the rate of independent transitions is large. Our analytical results are in excellent agreement with numerical simulations, reinforcing the robustness of our findings.",
          "authors": [
            "Rytis Kazakevičius",
            "Aleksejus Kononovicius"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02519",
          "title": "Mean First Passage Time of the Symmetric Noisy Voter Model with Arbitrary Initial and Boundary Conditions",
          "abstract": "Models of imitation and herding behavior often underestimate the role of individualistic actions and assume symmetric boundary conditions. However, real-world systems (e.g., electoral processes) frequently involve asymmetric boundaries. In this study, we explore how arbitrarily placed boundary conditions influence the mean first passage time in the symmetric noisy voter model, and how individualistic behavior amplifies this asymmetry. We derive exact analytical expressions for mean first passage time that accommodate any initial condition and two types of boundary configurations: (i) both boundaries absorbing, and (ii) one absorbing and one reflective. In both scenarios, mean first passage time exhibits a clear asymmetry with respect to the initial condition, shaped by the boundary placement and the rate of independent transitions. Symmetry in mean first passage time emerges only when absorbing boundaries are equidistant from the midpoint. Additionally, we show that Kramers' law holds in both configurations when the rate of independent transitions is large. Our analytical results are in excellent agreement with numerical simulations, reinforcing the robustness of our findings.",
          "authors": [
            "Rytis Kazakevičius",
            "Aleksejus Kononovicius"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02521",
          "title": "Detection of photon-level signals embedded in sunlight with an atomic photodetector",
          "abstract": "The detection of few-photon signals in a broadband background is an extreme challenge for photon counting, requiring filtering that accepts a narrow range of optical frequencies while strongly rejecting all others. Recent work [Zarraoa et. al, Phys. Rev. Res. 6, 033338 (2024)] demonstrated that trapped single atoms can act as low dark-count narrow-band photodetectors. Here we show that this ``quantum jump photodetector'' (QJPD) approach can also detect photon-level signals embedded in strong sunlight. Using a single rubidium atom as a QJPD, we count arrivals of individual narrow-band laser photons embedded in sunlight powers of order $10^{10}$ photons/s. We derive a rate-equation model for the atom's internal-state dynamics in sunlight, and find quantitative agreement with experiment. Using this model, we calculate the channel capacity over a noisy communication channel when sending weak coherent states and detecting them in the presence of sunlight, achieving a representative rate of 0.5 bits per symbol when sending 150 probe photons per 10 ms time-bin, embedded in 1 nW of sunlight (of order $10^{10}$ photons/s in the visible and near-infrared bands). The demonstration may benefit background-limited applications such as daytime light detection and ranging (LIDAR), remote magnetometry, and free-space classical and quantum optical communications.",
          "authors": [
            "Laura Zarraoa",
            "Romain Veyron",
            "Tomas Lamich",
            "Sondos Elsehimy",
            "Morgan W. Mitchell"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02521",
          "title": "Detection of photon-level signals embedded in sunlight with an atomic photodetector",
          "abstract": "The detection of few-photon signals in a broadband background is an extreme challenge for photon counting, requiring filtering that accepts a narrow range of optical frequencies while strongly rejecting all others. Recent work [Zarraoa et. al, Phys. Rev. Res. 6, 033338 (2024)] demonstrated that trapped single atoms can act as low dark-count narrow-band photodetectors. Here we show that this ``quantum jump photodetector'' (QJPD) approach can also detect photon-level signals embedded in strong sunlight. Using a single rubidium atom as a QJPD, we count arrivals of individual narrow-band laser photons embedded in sunlight powers of order $10^{10}$ photons/s. We derive a rate-equation model for the atom's internal-state dynamics in sunlight, and find quantitative agreement with experiment. Using this model, we calculate the channel capacity over a noisy communication channel when sending weak coherent states and detecting them in the presence of sunlight, achieving a representative rate of 0.5 bits per symbol when sending 150 probe photons per 10 ms time-bin, embedded in 1 nW of sunlight (of order $10^{10}$ photons/s in the visible and near-infrared bands). The demonstration may benefit background-limited applications such as daytime light detection and ranging (LIDAR), remote magnetometry, and free-space classical and quantum optical communications.",
          "authors": [
            "Laura Zarraoa",
            "Romain Veyron",
            "Tomas Lamich",
            "Sondos Elsehimy",
            "Morgan W. Mitchell"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02522",
          "title": "Tuning proximity-induced spin-orbit coupling in graphene/WSe$_{2}$ heterostructures",
          "abstract": "Recently, proximity-induced spin-orbit coupling (SOC) has been observed in heterostructures consisting of monolayer graphene (ML-G) and transition metal dichalcogenides (TMDCs) such as WSe$_{2}$. Successful tuning of SOC in graphene/WSe$_{2}$ heterostructures by applying mechanical pressure and electric fields was also demonstrated in previous studies. In addition, theoretical calculations predicted a strong dependence of the proximity-induced SOC on the twist angle between graphene and TMDC. Here, we put these predictions to experimental test in ML-G/ML-WSe$_{2}$/hBN-heterostructures, where the twist angle is determined by aligning fractured edges, and by crystallographic etching of graphene. By performing weak anti-localization measurements, we determine the strength of the Rasbha-type SOC ($\\lambda_\\mathrm{R}$) and the valley-Zeeman-type SOC ($\\lambda_\\mathrm{VZ}$). Our experiments confirm a strong twist angle dependence of the proximity-induced SOC in agreement with theoretical predictions. Finally, we demonstrate the tunability of the SOC strength via mechanical pressure, which is in agreement with earlier findings.",
          "authors": [
            "Tobias Rockinger",
            "Bálint Szentpéteri",
            "Szabolcs Csonka",
            "Marina Marocko",
            "Julia Amann",
            "Ziyang Gan",
            "Antony George",
            "Andrey Turchanin",
            "Kenji Watanabe",
            "Takashi Taniguchi",
            "Dieter Weiss",
            "Péter Makk",
            "Jonathan Eroms"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02525",
          "title": "Inductive limits of partial crossed products",
          "abstract": "Let $\\big((A^{(i)}, G, \\alpha^{(i)}), \\phi_i\\big)_{i \\in \\mathbb{N}}$ be an inductive sequence of partial dynamical systems. We prove the existence of an induced partial action $\\alpha$ of $G$ on the inductive limit $A=\\varinjlim A^{(i)}$. We call $\\alpha$ the inductive limit partial action. Furthermore, we show the corresponding partial crossed product $A\\rtimes_{\\alpha}G$ is canonically isomorphic to $\\varinjlim A^{(i)}\\rtimes_{\\alpha^{(i)}}G$. We also study the globalization of the inductive limit partial action $\\alpha$, its finite Rokhlin dimension and tracial states on $A\\rtimes_{\\alpha}G$.",
          "authors": [
            "Md Amir Hossain"
          ],
          "primary_category": "math.OA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02529",
          "title": "Electromagnetic polarization matrix and its physical interpretation",
          "abstract": "Although electric and magnetic fields are intrinsically coupled in random stationary light, a complete and physically consistent second-order description of polarization requires a joint electromagnetic treatment. The 6x6 electromagnetic polarization matrix introduced here generalizes the conventional electric 3x3 matrix by incorporating both electric and magnetic contributions together with their mutual correlations. It consists of diagonal 3x3 blocks, representing the electric and magnetic polarization matrices, and off-diagonal 3x3 blocks that encode the full structure of electric-magnetic cross-correlations. The information contained in this matrix can be interpreted through physically meaningful quantities such as active and reactive energy fluxes, in-phase and quadrature alignment matrices, and global indices describing electric-magnetic coupling. The formalism is applied to a field composed of two orthogonally propagating plane waves sharing a common linear electric polarization (a simple yet physically realizable configuration) that demonstrates the need for a general combined electric-magnetic representation even in free space. This approach provides a comprehensive and unified framework for characterizing electromagnetic polarization beyond the electric-field description alone, bridging classical statistical optics with quantum-like density-matrix interpretations.",
          "authors": [
            "José J. Gil",
            "Andreas Norrman",
            "Ari T. Friberg",
            "Benhaz Fazlpour",
            "Tero Setälä"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02531",
          "title": "Full-counting statistics and quantum information of dispersive readout with a squeezed environment",
          "abstract": "Motivated by the importance of dispersive readout in quantum technology, we study a prototypical dispersive readout setup that is probed by a squeezed vacuum in a time-reversal-symmetric fashion. To this end, we develop a full-counting-statistics framework for dispersive readout and analyze its measurement information, accompanied by a generalized mean-field approach suitable to deal with non-unitary dynamics. Distinct from conventional input-output theory, our full-counting-statistics approach enables the direct calculation of arbitrary-order cumulants for the measured cumulative (i.e., time-integrated) photonic distribution while maintaining applicability to nonlinear systems. The corresponding Fisher information exhibits an exponential dependence on the squeezing parameter and a robustness against residual nonlinearity, which can even approach the quantum Fisher information, setting an upper limit. This work introduces a conceptually streamlined and computationally efficient framework for continuous quantum measurements, making it well suited for widespread adoption in quantum technologies.",
          "authors": [
            "Ming Li",
            "JunYan Luo",
            "Gloria Platero",
            "Georg Engelhardt"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02537",
          "title": "Numerical verification of PolyDG algebraic solvers for the pseudo-stress Stokes problem",
          "abstract": "This work focuses on the development of efficient solvers for the pseudo-stress formulation of the unsteady Stokes problem, discretised by means of a discontinuous Galerkin method on polytopal grids (PolyDG). The introduction of the pseudo-stress variable is motivated by the growing interest in non-Newtonian flow models and coupled interface problems, where the stress field plays a fundamental role in the physical description. The space-time discretisation of the problem is obtained by combining the PolyDG approach in space with the implicit Euler method for time integration. The resulting linear system, characterised by a symmetric, positive, definite matrix, exhibits deteriorating convergence with standard solvers as the time step decreases. To address this issue, we investigate two tailored strategies: deflated Conjugate Gradient, which mitigates the effect of the most problematic eigenmodes, and collective Block-Jacobi, which exploits the block structure of the system matrix. Numerical experiments show that both approaches yield iteration counts effectively independent of $\\Delta t$, ensuring robust performance with respect to the time step. Future work will focus on extending this robustness to the spatial discretisation parameter $h$ by integrating multigrid strategies with the time-robust solvers developed in this study.",
          "authors": [
            "Paola F. Antonietti",
            "Alessandra Cancrini",
            "Gabriele Ciaramella"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02537",
          "title": "Numerical verification of PolyDG algebraic solvers for the pseudo-stress Stokes problem",
          "abstract": "This work focuses on the development of efficient solvers for the pseudo-stress formulation of the unsteady Stokes problem, discretised by means of a discontinuous Galerkin method on polytopal grids (PolyDG). The introduction of the pseudo-stress variable is motivated by the growing interest in non-Newtonian flow models and coupled interface problems, where the stress field plays a fundamental role in the physical description. The space-time discretisation of the problem is obtained by combining the PolyDG approach in space with the implicit Euler method for time integration. The resulting linear system, characterised by a symmetric, positive, definite matrix, exhibits deteriorating convergence with standard solvers as the time step decreases. To address this issue, we investigate two tailored strategies: deflated Conjugate Gradient, which mitigates the effect of the most problematic eigenmodes, and collective Block-Jacobi, which exploits the block structure of the system matrix. Numerical experiments show that both approaches yield iteration counts effectively independent of $\\Delta t$, ensuring robust performance with respect to the time step. Future work will focus on extending this robustness to the spatial discretisation parameter $h$ by integrating multigrid strategies with the time-robust solvers developed in this study.",
          "authors": [
            "Paola F. Antonietti",
            "Alessandra Cancrini",
            "Gabriele Ciaramella"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02538",
          "title": "On the spectral geometry of Liouville quantum gravity",
          "abstract": "We give a concise presentation of the construction of the Liouville quantum gravity (LQG) eigenvalues and eigenfunctions, i.e., the spectrum associated to the infinitesimal generator of Liouville Brownian motion, the canonical diffusion in the geometry of LQG. We describe the recently obtained Weyl law in this context (giving a short summary of its proof) and report on some work in progress concerning the associated heat trace. Finally, we summarise and propose some new key open problems in this direction.",
          "authors": [
            "Nathanaël Berestycki"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02539",
          "title": "Constraint-Optimal Driven Allocation for Scalable QEC Decoder Scheduling",
          "abstract": "Fault-tolerant quantum computing (FTQC) requires fast and accurate decoding of Quantum Error Correction (QEC) syndromes. However, in large-scale systems, the number of available decoders is much smaller than the number of logical qubits, leading to a fundamental resource shortage. To address this limitation, Virtualized Quantum Decoder (VQD) architectures have been proposed to share a limited pool of decoders across multiple qubits. While the Minimize Longest Undecoded Sequence (MLS) heuristic has been introduced as an effective scheduling policy within the VQD framework, its locally greedy decision-making structure limits its ability to consider global circuit structure, causing inefficiencies in resource balancing and limited scalability. In this work, we propose Constraint-Optimal Driven Allocation (CODA), an optimization-based scheduling algorithm that leverages global circuit structure to minimize the longest undecoded sequence length. Across 19 benchmark circuits, CODA achieves an average 74\\% reduction in the longest undecoded sequence length. Crucially, while the theoretical search space scales exponentially with circuit size, CODA effectively bypasses this combinatorial explosion. Our evaluation confirms that the scheduling time scales linearly with the number of qubits, determined by physical resource constraints rather than the combinatorial search space, ensuring robust scalability for large-scale FTQC systems. These results demonstrate that CODA provides a global optimization-based, scalable scheduling solution that enables efficient decoder virtualization in large-scale FTQC systems.",
          "authors": [
            "Dongmin Kim",
            "Jeonggeun Seo",
            "Youngtae Kim",
            "Youngsun Han"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02540",
          "title": "Regime Maps for Sloshing in Horizontal Cylindrical Tanks Under Vertical Acceleration",
          "abstract": "Vertical sloshing in partially filled fuel tanks can significantly impact vehicle stability and structural integrity, particularly under harmonic accelerations near twice the sloshing natural frequency. In this regime, parametric resonance may arise, with nonlinear free-surface dynamics driving large-amplitude waves, interface break-up, and severe sloshing-induced mixing. In this work, we identify and characterize the distinct sloshing regimes associated with the lowest-frequency parametric instability, specifically when the external forcing frequency approaches twice the lowest natural frequency. Experiments were conducted in a transparent cylindrical tank with diameter D = 134.5 mm and length L = 336.3 mm. This work presents a data-driven approach for regime identification and classification that relies solely on high-speed video recordings and circumvents the need for interface tracking. The method combines prototype-based data labeling with dimensionality reduction via multiscale proper orthogonal decomposition (mPOD) and automatic kernel-based classification. The results are summarized in a dimensionless regime map across three fill ratios, where stable waves, longitudinal and transverse mode shapes, and mode-competition regimes are distinguished. The developed map provides a predictive tool for assessing sloshing-induced loads, supporting structural and operational optimization of fuel systems.",
          "authors": [
            "Francisco Monteiro",
            "Tommaso De Maria",
            "Samuel Ahizi",
            "Ramon Abarca",
            "Giuseppe C.A. Caridi",
            "Miguel A. Mendez"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02542",
          "title": "Size control guidelines for chemically active droplets",
          "abstract": "Biological cells and synthetic analogues use liquid-liquid phase separation to dynamically compartmentalize their environment for various applications. In many cases, multiple droplets need to coexist, and their size needs to be controlled, which is challenging because large droplets tend to grow at the expense of smaller ones. Chemical reactions can, in principle, control droplet sizes, but there are no clear guidelines on how to robustly achieve size control. To provide guidelines, we consider a binary fluid model driven out of equilibrium by chemical reactions. We reveal two different classes of size-controlled droplets, depending on the ratio of droplet radius to the reaction-diffusion length. Moreover, we determine parameter regimes in which droplets become small. Taken together, our theory allows us to separately predict the chemical reactions necessary for maintaining droplets of a given class or size.",
          "authors": [
            "Guido Kusters",
            "David Zwicker"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02542",
          "title": "Size control guidelines for chemically active droplets",
          "abstract": "Biological cells and synthetic analogues use liquid-liquid phase separation to dynamically compartmentalize their environment for various applications. In many cases, multiple droplets need to coexist, and their size needs to be controlled, which is challenging because large droplets tend to grow at the expense of smaller ones. Chemical reactions can, in principle, control droplet sizes, but there are no clear guidelines on how to robustly achieve size control. To provide guidelines, we consider a binary fluid model driven out of equilibrium by chemical reactions. We reveal two different classes of size-controlled droplets, depending on the ratio of droplet radius to the reaction-diffusion length. Moreover, we determine parameter regimes in which droplets become small. Taken together, our theory allows us to separately predict the chemical reactions necessary for maintaining droplets of a given class or size.",
          "authors": [
            "Guido Kusters",
            "David Zwicker"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02545",
          "title": "On the problem of stability of abstract elementary classes of modules",
          "abstract": "It is an open problem of Mazari-Armida whether every abstract elementary class of $R$-modules $(\\mathbf{K}, \\leq_{\\mathrm{pure}})$, with $\\leq_{\\mathrm{pure}}$ the pure submodule relation, is stable. We answer this question in the negative by constructing unstable abstract elementary classes $(\\mathbf{K}, \\leq_{\\mathrm{pure}})$ of torsion-free abelian groups. On the other hand, we prove (in $\\mathrm{ZFC}$) that if $R$ is any ring and $(\\mathbf{K}, \\preccurlyeq)$ is an abstract elementary class of $R$-modules which is $\\kappa$-local (also called $\\kappa$-tame) for some $\\kappa \\geq \\mathrm{LS}(\\mathbf{K}, \\preccurlyeq)$, then $(\\mathbf{K}, \\preccurlyeq)$ is almost stable, where almost stability is a new notion of independent interest that we introduce in this paper, and which is equivalent to the usual notion of stability under the assumption of amalgamation. As a consequence, assuming the existence of a strongly compact cardinal $\\kappa$, we have that every abstract elementary class $(\\mathbf{K}, \\preccurlyeq)$ of $R$-modules with amalgamation satisfying $\\kappa > \\mathrm{LS}(\\mathbf{K}, \\preccurlyeq)$ is stable.",
          "authors": [
            "Gianluca Paolini",
            "Saharon Shelah"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02553",
          "title": "A New Approach from Lattice of Subgroup Sets to Generalized Solvable Extension Formations",
          "abstract": "In this paper, we establish the decomposition of morphisms from lattice of subgroup sets to generalized solvable extension formations. To achieve this, we develop a unified framework involving maximal subgroup functors, generating formation morphism and contraction-extension functors. In particular, solvability-induced sets of maximal subgroups are determined and generating formation morphism gives rise to generalized solvable extension formations.",
          "authors": [
            "Ran Li",
            "Long Miao",
            "Wenxia Zhou",
            "Yinan Chen"
          ],
          "primary_category": "math.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02565",
          "title": "Lie and pre-Lie theory of Novikov algebras",
          "abstract": "Novikov algebras provide a simple but powerful algebraic axiomatization of important features of classical diferential calculus. We study their structure properties, modeling their relationships with commutative algebras with a derivation, featuring the role of their Lie and pre-Lie structures and analyzing the structure of their enveloping algebras. We focus on the combinatorial analysis of the Poincaré-Birkhoff-Witt Theorem (classical and pre-Lie), the pre-Lie exponential and logarithm. The topic is important for applications of the theory and has been treated intensively for pre-Lie algebras. However, specific formulas can be obtained in the Novikov case. We analyze their structure, as well as featuring various remarkable properties. Related statistical phenomena on trees, tableaux and permutations are investigated in this context.",
          "authors": [
            "Ruggero Bandiera",
            "Frédéric Patras"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02568",
          "title": "Anderson localization in high-contrast media with random spherical inclusions",
          "abstract": "We study spectral properties of partial differential operators modelling composite materials with highly contrasting constituents, comprised of soft spherical inclusions with random radii dispersed in a stiff matrix. Such operators have recently attracted significant interest from the research community, including in the context of stochastic homogenization. In particular, it has been proved that the spectrum of these operators may feature a band-gap structure in the regime where heterogeneities take place on a sufficiently small scale. However, the nature of the limiting (as the small scale tends to zero) spectrum in the above setting is non-classical and not completely understood. In this paper we prove for the first time that Anderson localization occurs near band edges, thus shedding light on the limiting spectral behaviour. Our results rely on recent nontrivial advancements in quantitative unique continuation for PDEs, in combination with assumptions on the model that are standard in the Anderson localization literature, and which we plan to relax in future works.",
          "authors": [
            "Matteo Capoferri",
            "Matthias Täufer"
          ],
          "primary_category": "math.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02568",
          "title": "Anderson localization in high-contrast media with random spherical inclusions",
          "abstract": "We study spectral properties of partial differential operators modelling composite materials with highly contrasting constituents, comprised of soft spherical inclusions with random radii dispersed in a stiff matrix. Such operators have recently attracted significant interest from the research community, including in the context of stochastic homogenization. In particular, it has been proved that the spectrum of these operators may feature a band-gap structure in the regime where heterogeneities take place on a sufficiently small scale. However, the nature of the limiting (as the small scale tends to zero) spectrum in the above setting is non-classical and not completely understood. In this paper we prove for the first time that Anderson localization occurs near band edges, thus shedding light on the limiting spectral behaviour. Our results rely on recent nontrivial advancements in quantitative unique continuation for PDEs, in combination with assumptions on the model that are standard in the Anderson localization literature, and which we plan to relax in future works.",
          "authors": [
            "Matteo Capoferri",
            "Matthias Täufer"
          ],
          "primary_category": "math.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02570",
          "title": "On Galois representations associated to mod $p$ Hilbert modular forms",
          "abstract": "We consider mod $p$ Hilbert modular forms for a totally real field $F$, viewed as sections of automorphic line bundles on Hilbert modular varieties in prime characteristic $p$. For a Hecke eigenform of arbitrary weight, we prove the existence of an associated two-dimensional representation of the absolute Galois group of $F$. Furthermore, for any such irreducible Galois representation, we formulate a conjecture predicting the set of weights of eigenforms from which it arises. This generalizes Edixhoven's variant of the weight part of Serre's Conjecture (in the case $F = \\mathbb{Q}$), and removes the restriction that $p$ be unramified in $F$ from prior work in this direction. We also establish one direction of a conjectural relation with the algebraic analogue of the weight part of Serre's Conjecture in this context. Finally, we prove results towards our conjecture in the case of partial weight one for real quadratic fields $F$ in which $p$ is ramified.",
          "authors": [
            "Fred Diamond",
            "Shu Sasaki"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02571",
          "title": "Approximation schemes for covering and packing mixed-integer programs with a fixed number of constraints",
          "abstract": "This paper presents an algorithmic study of a class of covering mixed-integer linear programming problems which encompasses classic cover problems, including multidimensional knapsack, facility location and supplier selection problems. We first show some properties of the vertices of the associated polytope, which are then used to decompose the problem into instances of the multidimensional knapsack cover problem with a single continuous variable per dimension. The proposed decomposition is used to design a polynomial-time approximation scheme for the problem with a fixed number of constraints. To the best of our knowledge, this is the first approximation scheme for such a general class of covering mixed-integer programs. Moreover, we design a fully polynomial-time approximation scheme and an approximate linear programming formulation for the case with a single constraint. These results improve upon the previously best-known 2-approximation algorithm for the knapsack cover problem with a single continuous variable. Finally, we show a perfect compact formulation for the case where all variables have the same lower and upper bounds. Analogous results are derived for the packing and assignment variants of the problem.",
          "authors": [
            "Kobe Grobben",
            "Phablo F.S. Moura",
            "Hande Yaman"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02575",
          "title": "Intrinsic and Tunable Superconducting Diode Effect in Quantum Spin Hall Systems",
          "abstract": "Nonreciprocal dissipationless transport has long been sought for applications in superconducting technologies. Recently, it has been implemented by the so called superconducting diode effect. Such effect arises from an imbalance in critical supercurrents flowing in opposite directions. In this work, we theoretically demonstrate how the superconducting diode effect emerges in the quantum spin Hall phase when brought into full proximity with a superconductor. We explore two regimes: large and narrow quantum wells. In the former geometry, we show that the superconducting diode effect can be externally controlled using both magnetic and electric fields, achieving unit efficiency. In the latter regime, where tunneling between opposite edges may occur, we propose a mechanism for an intrinsic superconducting diode effect driven by edge reconstruction, which does not require external magnetic fields.",
          "authors": [
            "Samuele Fracassi",
            "Simone Traverso",
            "Stefan Heun",
            "Maura Sassetti",
            "Matteo Carrega",
            "Niccolo Traverso Ziani"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02577",
          "title": "Multigrid p-Robustness at Jacobi Speeds: Efficient Matrix-Free Implementation of Local p-Multigrid Solvers",
          "abstract": "Vertex-patch smoothers are essential for the robust convergence of geometric multigrid methods in high-order finite element applications, yet their adoption is traditionally hindered by the prohibitive cost of solving local patch problems. This paper presents a high-performance, matrix-free implementation of a p-multigrid local solver that dismantles the trade-off between smoothing effectiveness and computational efficiency. We focus on the practical realization of this iterative approach, leveraging sum-factorization and explicit SIMD vectorization to minimize memory footprint and maximize arithmetic throughput. The performance analysis demonstrates that the solver effectively hides data-fetching latencies and maintains optimal $\\mathcal{O}(p^d)$ memory scaling, even when dominated by geometric data on distorted meshes. The result is a robust smoother that rivals the execution speed of simple pointwise smoothers while preserving the convergence benefits of patch-based methods.",
          "authors": [
            "Michał Wichrowski"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02577",
          "title": "Multigrid p-Robustness at Jacobi Speeds: Efficient Matrix-Free Implementation of Local p-Multigrid Solvers",
          "abstract": "Vertex-patch smoothers are essential for the robust convergence of geometric multigrid methods in high-order finite element applications, yet their adoption is traditionally hindered by the prohibitive cost of solving local patch problems. This paper presents a high-performance, matrix-free implementation of a p-multigrid local solver that dismantles the trade-off between smoothing effectiveness and computational efficiency. We focus on the practical realization of this iterative approach, leveraging sum-factorization and explicit SIMD vectorization to minimize memory footprint and maximize arithmetic throughput. The performance analysis demonstrates that the solver effectively hides data-fetching latencies and maintains optimal $\\mathcal{O}(p^d)$ memory scaling, even when dominated by geometric data on distorted meshes. The result is a robust smoother that rivals the execution speed of simple pointwise smoothers while preserving the convergence benefits of patch-based methods.",
          "authors": [
            "Michał Wichrowski"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02578",
          "title": "Self-Expanding Solutions to the Mean Curvature Flow for Multiphase Surfaces with Regular Junctions",
          "abstract": "We consider a multiphase surface $\\mathcal{C}_0$ in $\\mathbb{R}^3$ consisting of a finite number of surfaces passing through the origin , where all 1-dimensional junctions are regular triple junctions in which three planes meet at the same angle and each surface scales down homothetically to a limit curve of finite length. We prove the existence of self-similar expanding solutions of the mean curvature flow on the multiphase surface initially given by $\\mathcal{C}_0$. For this initial condition, there are multiple solutions that are combinations of the regular triple junctions and regular quadruple points, where four regular triple junctions meet at an angle of approximately $109.5^{\\circ}$.",
          "authors": [
            "Wei-Hung Liao"
          ],
          "primary_category": "math.DG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02583",
          "title": "Asymptotic behavior of solutions to a singular chemotaxis system in multi-dimensions",
          "abstract": "In this paper, we investigate the optimal large-time behavior of the global solution to a singular chemotaxis system in the whole space $\\mathbb{R}^d$ with $d=2,3$. Assuming that the initial data is sufficiently close to an equilibrium state, we first prove the $k$-th order spatial derivative of the global solution converges to its corresponding equilibrium at the optimal rate $(1+t)^{-(\\frac{d}{4}+\\frac{k}{2})}$, which improve upon the result in [37]. Then, for well-chosen initial data, we also establish lower bounds on the convergence rates, which match those of the heat equation. Our proof relies on a Cole-Hopf type transformation, delicate spectral analysis, the Fourier splitting technique, and energy methods.",
          "authors": [
            "Qiang Tao",
            "Dehua Wang",
            "Ying Yang",
            "Meifang Zhong"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02590",
          "title": "Hilbert Coefficients and Regularity of Binomial Edge Ideals",
          "abstract": "Let $G$ be a simple graph on $n$ vertices, and let $J_G$ denotes the corresponding binomial edge ideal in $S=\\mathbb{K}[x_1,\\ldots,x_n,y_1,\\ldots,y_n]$, where $\\mathbb{K}$ is a field. We show that if a vertex satisfies a certain degree condition, then some Hilbert coefficients remain unchanged upon its removal, thereby providing a reduction technique for computing Hilbert coefficients. As an application, for any $i\\geq 0$ and a pair $(r,s)$ with $r\\geq 2, s\\in \\mathbb{Z}$, we show that there always exists a graph $G$ such that $\\mathrm{reg}(S/J_G)=r$ and $e_i(S/J_G)=s$, where $\\mathrm{reg}(S/J_G)$ and $e_i(R/J_G)$ denote the Castelnuovo-Mumford regularity and the $i$-th Hilbert coefficient of $S/J_G$, respectively. In particular, this demonstrates that there is no inherent relationship between the regularity and the Hilbert coefficients for the class of binomial edge ideals.",
          "authors": [
            "Kanoy Kumar Das",
            "Rajiv Kumar",
            "Paramhans Kushwaha"
          ],
          "primary_category": "math.AC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02591",
          "title": "Finite Element Prediction of Sintering Deformation in 3D-Printed Porcelain Filament",
          "abstract": "Sintering of printed porcelain filaments can be strongly affected by overhang geometry, thin features, and printing-induced anisotropy. These effects are particularly difficult to simulate because they require accurately capturing the interplay between sintering kinetics, viscous deformation, and macroscopic anisotropy. In this study, a robust and predictive model is established experimentally using anisotropic sintering dilatometry combined with overhang-deformation calibration through finite element simulations (FEM).  The sintering behavior is identified using a porosity-temperature-independent minimization strategy applied to multi-rate dilatometry. Pellet anisotropy is incorporated via FEM by imposing directional sintering stresses. The deformation behavior is then calibrated by adjusting the shear viscosity to match overhang shapes deformation. The resulting model is finally validated on overhanging bar geometries. This step-by-step approach provides a comprehensive assessment of porcelain sintering while accurately capturing deformation mechanisms.",
          "authors": [
            "Fatima Hammoud",
            "Charles Manière"
          ],
          "primary_category": "physics.class-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02592",
          "title": "Strengthening and toughening mechanisms in heterostructured laminates revealed by a phase field-enhanced crystal plasticity simulation",
          "abstract": "Heterostructured (HS) materials exhibit excellent mechanical properties, combining high strength and significant ductility. Hetero-deformation-induced (HDI) hardening and strain de-localization are key to their strength-ductility synergy. However, existing models often fall short in addressing these aspects. In this work, a coupled framework integrating strain gradient crystal plasticity and phase field damage models is developed. The interface dominated HDI hardening in HS laminates is handled by introducing a heterogeneity coefficient into the back stress. The phase field model accounts for defect energy-driven damage and accurately represents the materials ductile damage behavior by accounting for effects of microstructure on crack initiation and propagation. Simulation results on HS laminates align well with experimental results and reflect the distribution of geometrically necessary dislocations and back stresses at interfaces between regions with dissimilar microstructure. Crack initiation and propagation are accurately described, providing valuable insights into fracture behavior. The model can predict how strength and ductility change upon variations of the HS laminate microstructure, thus providing an essential tool for microstructure optimization. This work enhances the understanding of deformation mechanisms in HS laminates and provides valuable insights for design and optimization of this class of materials.",
          "authors": [
            "Yukai Xiong",
            "Jianfeng Zhao",
            "Jinling Liu",
            "Jie Wang",
            "Michael Zaiser",
            "Xu Zhang"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02595",
          "title": "Ultrafast Stiffening of the Lattice Potential and Metastable State Formation in 1$T$-TiSe$_2$",
          "abstract": "We use ultrafast optical spectroscopy to investigate the electronic and lattice dynamics of the charge-density wave (CDW) material 1$T$-TiSe$_2$ across various temperatures and pump fluences. We reveal a close relationship between the observed ultrafast dynamical processes and two characteristic temperatures: $T_{\\rm CDW}$ ($\\sim$202 K) and $T^*$ ($\\sim$165 K). Two coherent phonon modes are identified: a high-frequency $A_{1g}$ mode ($\\omega_{1}$) and a lower-frequency $A_{1g}$ CDW amplitude mode ($\\omega_{2}$). In stark contrast to thermal melting, where phonons soften, the CDW amplitude mode exhibits anomalous hardening (frequency upshift) with increasing pump fluence. We establish this hardening as the direct signature of an ultrafast restoration of the bare lattice potential. The photoexcited carrier plasma screens the long-range electron-phonon interactions that drive the Peierls-like instability, effectively ``undressing\" the soft phonon and driving its frequency toward the stiffer value of the unrenormalized lattice. Furthermore, an abrupt increase in the excited state buildup time above a critical pump fluence marks a sharp boundary to a photoinduced metastable metallic state. These findings demonstrate that the CDW order in 1$T$-TiSe$_2$ is governed by a fragile, fluence-tunable competition between excitonic correlations and lattice dynamics.",
          "authors": [
            "Xue-Qing Ye",
            "Hao Liu",
            "Qi-Yi Wu",
            "Chen Zhang",
            "Xiao-Fang Tang",
            "Bo Chen",
            "Chuan-Cun Shu",
            "Hai-Yun Liu",
            "Yu-Xia Duan",
            "Peter M. Oppeneer",
            "Jian-Qiao Meng"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02596",
          "title": "Preservation of notion of large sets near zero over reals",
          "abstract": "The study of the size of subsets in a semigroup have shown that many of these subsets have strong combinatorial properties and contribute richly to the algebraic structure of the Stone-Cech compactification of a discrete semigroup. N. Hindman and D. Strauss have proved that if u, v $\\in \\mathbb{N}$, M is a u \\times v matrix satisfying restrictions that vary with the notion of largeness and if $\\Psi$ is a notion of large sets in $\\mathbb{N}$ then $\\{\\vec{x} \\in \\mathbb{N}^v: M\\vec{x} \\in \\Psi^u\\}$ is large set in $\\mathbb{N}^v$. In this article, we investigate the above result for various notions of largeness near zero in $\\mathbb{R}^+$.",
          "authors": [
            "Kilangbenla Imsong",
            "Ram Krishna Paul"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02597",
          "title": "Hilbert's Basis Theorem for generalized nonassociative Ore extensions",
          "abstract": "We introduce a broader class of nonassociative Ore extensions that unifies and generalizes several earlier constructions. We prove generalizations of Hilbert's Basis Theorem for this class, showing that they arise immediately from the existence of Euclidean division algorithms. These results extend Hilbert's Basis Theorem to new families of nonassociative, noncommutative polynomial rings and establish a novel and direct connection between Euclidean division algorithms and the left and right Noetherianity of such rings.",
          "authors": [
            "Per Bäck",
            "Masood Aryapoor"
          ],
          "primary_category": "math.RA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02598",
          "title": "Equilibrium SAT based PQC: New aegis against quantum computing",
          "abstract": "Public-key cryptography algorithms have evolved towards increasing computational complexity to hide desired messages, which is accelerating with the development of the Internet and quantum computing. This paper introduces a novel public-key cryptography algorithm that generates ciphertexts by counting the number of elements in randomly extracted subsets from a multiset. After explaining the novel cryptographic concept, the process of mathematically refining it using satisfiability problems is described. The advantages of the proposed algorithm are: first, it is significantly faster than other public-key algorithms; second, it does not require big numbers, making it executable on any devices; and third, it can be easily extended into a public-key cryptosystem using a single public key and multiple private keys while maintaining quantum resistance.",
          "authors": [
            "Keum-Bae Cho"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02599",
          "title": "CZT Detectors for kaonic atoms spectroscopy",
          "abstract": "Cadmium zinc telluride (CZT) detectors offer excellent room-temperature energy resolution, making them well suited for X- and $\\gamma$-ray spectroscopy in challenging environments. Within the SIDDHARTA-2 program at the DA$\\Phi$NE collider, a new CZT-based detection system has been developed to enable precision measurements of kaonic atom transitions in the intermediate mass range. In this work, we report the results of a calibration campaign performed with the collider operating, aimed at assessing the detector performance. A dedicated setup, including an array of quasi-hemispherical CZT sensors and a $^{152}$Eu source, was used to characterize the spectral response. The reconstructed emission lines were fitted with a model accounting for Gaussian response and incomplete charge recollection tails, and the detector linearity was evaluated by comparing the measured peak positions with their nominal energies. The results demonstrate that the CZT detector exhibits excellent linearity and stable operation with the collider on, confirming its suitability for future kaonic-atom spectroscopy at DA$\\Phi$NE.",
          "authors": [
            "Francesco Artibani",
            "Leonardo Abbene",
            "Antonino Buttacavoli",
            "Manuele Bettelli",
            "Gaetano Gerardi",
            "Fabio Principato",
            "Andrea Zappettini",
            "Massimiliano Bazzi",
            "Giacomo Borghi",
            "Damir Bosnar",
            "Mario Bragadireanu",
            "Marco Carminati",
            "Alberto Clozza",
            "Francesco Clozza",
            "Raffaele Del Grande",
            "Luca De Paolis",
            "Carlo Fiorini",
            "Ivica Friscic",
            "Carlo Guaraldo",
            "Mihail Iliescu",
            "Masahiko Iwasaki",
            "Aleksander Khreptak",
            "Simone Manti",
            "Johann Marton",
            "Pawel Moskal",
            "Fabrizio Napolitano",
            "Hiroaki Ohnishi",
            "Kristian Piscicchia",
            "Francesco Sgaramella",
            "Michal Silarski",
            "Diana Laura Sirghi",
            "Florin Sirghi",
            "Magdalena Skurzok",
            "Antonio Spallone",
            "Kairo Toho",
            "Oton Vazquez Doce",
            "Johann Zmeskal",
            "Catalina Curceanu",
            "Alessandro Scordo"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02602",
          "title": "Thermoelectric coefficients of two-flavor quark matter from the Kubo formalism",
          "abstract": "The hot quark matter created in heavy-ion collision experiments can exhibit strong temperature and chemical-potential gradients, which in turn can generate electric fields through thermoelectric effects. In this work, we investigate two relevant thermoelectric coefficients - the thermopower (Seebeck coefficient) and the Thomson coefficient - of two-flavor quark matter using the Kubo formalism and the Nambu--Jona-Lasinio model as an effective description of dense, finite-temperature QCD. The required two-point equilibrium correlation functions are evaluated using the Matsubara formalism of thermal field theory, applying a 1/Nc expansion to the relevant multi-loop Feynman diagrams. We employ previously derived quark spectral functions obtained from one--meson-exchange diagrams above the Mott transition temperature. Our numerical results show that both thermoelectric coefficients increase approximately linearly with temperature and decrease with increasing chemical potential. We also estimate the magnitude of the electric fields that can be generated in heavy-ion collisions by thermal gradients via the Seebeck effect.",
          "authors": [
            "Harutyun Gabuzyan",
            "Arus Harutyunyan",
            "Armen Sedrakian"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02602",
          "title": "Thermoelectric coefficients of two-flavor quark matter from the Kubo formalism",
          "abstract": "The hot quark matter created in heavy-ion collision experiments can exhibit strong temperature and chemical-potential gradients, which in turn can generate electric fields through thermoelectric effects. In this work, we investigate two relevant thermoelectric coefficients - the thermopower (Seebeck coefficient) and the Thomson coefficient - of two-flavor quark matter using the Kubo formalism and the Nambu--Jona-Lasinio model as an effective description of dense, finite-temperature QCD. The required two-point equilibrium correlation functions are evaluated using the Matsubara formalism of thermal field theory, applying a 1/Nc expansion to the relevant multi-loop Feynman diagrams. We employ previously derived quark spectral functions obtained from one--meson-exchange diagrams above the Mott transition temperature. Our numerical results show that both thermoelectric coefficients increase approximately linearly with temperature and decrease with increasing chemical potential. We also estimate the magnitude of the electric fields that can be generated in heavy-ion collisions by thermal gradients via the Seebeck effect.",
          "authors": [
            "Harutyun Gabuzyan",
            "Arus Harutyunyan",
            "Armen Sedrakian"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02602",
          "title": "Thermoelectric coefficients of two-flavor quark matter from the Kubo formalism",
          "abstract": "The hot quark matter created in heavy-ion collision experiments can exhibit strong temperature and chemical-potential gradients, which in turn can generate electric fields through thermoelectric effects. In this work, we investigate two relevant thermoelectric coefficients - the thermopower (Seebeck coefficient) and the Thomson coefficient - of two-flavor quark matter using the Kubo formalism and the Nambu--Jona-Lasinio model as an effective description of dense, finite-temperature QCD. The required two-point equilibrium correlation functions are evaluated using the Matsubara formalism of thermal field theory, applying a 1/Nc expansion to the relevant multi-loop Feynman diagrams. We employ previously derived quark spectral functions obtained from one--meson-exchange diagrams above the Mott transition temperature. Our numerical results show that both thermoelectric coefficients increase approximately linearly with temperature and decrease with increasing chemical potential. We also estimate the magnitude of the electric fields that can be generated in heavy-ion collisions by thermal gradients via the Seebeck effect.",
          "authors": [
            "Harutyun Gabuzyan",
            "Arus Harutyunyan",
            "Armen Sedrakian"
          ],
          "primary_category": "nucl-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02603",
          "title": "Semigroup action based on skew polynomial evaluation with applications to Cryptography",
          "abstract": "Through this work we introduce an action of the skew polynomial ring $\\mathbb{F}_{q}\\left[X; \\sigma, \\delta\\right]$ over $\\mathbb{F}_{q}$ based on its polynomial valuation and the concept of left skew product of functions. This lead us to explore the construction of a certain subset $\\mathcal{T}(X)\\subset\\mathbb{F}_{q}\\left[X; \\sigma, \\delta\\right]$ that allow us to control the non-commutativity of this ring, and exploit this fact in order to build a public key exchange protocol that is secure in Canetti and Krawczyk model.",
          "authors": [
            "Daniel Camazón-Portela",
            "Juan Antonio López-Ramos"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02603",
          "title": "Semigroup action based on skew polynomial evaluation with applications to Cryptography",
          "abstract": "Through this work we introduce an action of the skew polynomial ring $\\mathbb{F}_{q}\\left[X; \\sigma, \\delta\\right]$ over $\\mathbb{F}_{q}$ based on its polynomial valuation and the concept of left skew product of functions. This lead us to explore the construction of a certain subset $\\mathcal{T}(X)\\subset\\mathbb{F}_{q}\\left[X; \\sigma, \\delta\\right]$ that allow us to control the non-commutativity of this ring, and exploit this fact in order to build a public key exchange protocol that is secure in Canetti and Krawczyk model.",
          "authors": [
            "Daniel Camazón-Portela",
            "Juan Antonio López-Ramos"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02604",
          "title": "Accurate Modeling of Gate Leakage Currents in SiC Power MOSFETs",
          "abstract": "Silicon carbide (SiC) metal-oxide-semiconductor field-effect-transistors (MOSFETs) enable high-voltage and high-temperature power conversion. Compared to Si devices, they suffer from pronounced gate leakage due to the reduced electron tunneling barrier at the interface between SiC and amorphous silicon dioxide (a-SiO$_2$). We develop a self-consistent, physics-based simulation framework that couples electrostatics, quantum tunneling, carrier transport, impact ionization, and charge trapping for both electrons and holes. The model quantitatively reproduces measured gate-current-voltage characteristics of SiC MOS capacitors over a wide temperature (80-573 K) range and a wide bias range without empirical fitting. Simulations reveal that conduction electrons in a-SiO$_2$ can trigger impact ionization, which generates electron-hole pairs, and leads to capture of holes in the oxide bulk, thereby enhancing gate leakage current. The framework captures these coupled processes across multiple orders of magnitude in time and field, providing predictive capability for oxide reliability. Although demonstrated for SiC devices, the methodology also applies to Si technologies that uses the same gate dielectric.",
          "authors": [
            "Ang Feng",
            "Alexander Karl",
            "Dominic Waldhör",
            "Marina Avramenko",
            "Peter Moens",
            "Tibor Grasser"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02604",
          "title": "Accurate Modeling of Gate Leakage Currents in SiC Power MOSFETs",
          "abstract": "Silicon carbide (SiC) metal-oxide-semiconductor field-effect-transistors (MOSFETs) enable high-voltage and high-temperature power conversion. Compared to Si devices, they suffer from pronounced gate leakage due to the reduced electron tunneling barrier at the interface between SiC and amorphous silicon dioxide (a-SiO$_2$). We develop a self-consistent, physics-based simulation framework that couples electrostatics, quantum tunneling, carrier transport, impact ionization, and charge trapping for both electrons and holes. The model quantitatively reproduces measured gate-current-voltage characteristics of SiC MOS capacitors over a wide temperature (80-573 K) range and a wide bias range without empirical fitting. Simulations reveal that conduction electrons in a-SiO$_2$ can trigger impact ionization, which generates electron-hole pairs, and leads to capture of holes in the oxide bulk, thereby enhancing gate leakage current. The framework captures these coupled processes across multiple orders of magnitude in time and field, providing predictive capability for oxide reliability. Although demonstrated for SiC devices, the methodology also applies to Si technologies that uses the same gate dielectric.",
          "authors": [
            "Ang Feng",
            "Alexander Karl",
            "Dominic Waldhör",
            "Marina Avramenko",
            "Peter Moens",
            "Tibor Grasser"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02607",
          "title": "A unified optical platform for non-Gaussian and fault-tolerant Gottesman-Kitaev-Preskill states",
          "abstract": "Quantum technologies, encompassing communication, computation, and metrology, rely on the generation and control of non-Gaussian states of light. These states enable secure quantum communication, fault-tolerant quantum computation, and precision sensing beyond classical limits, yet their practical realisation remains a major challenge due to reliance on high-photon-number Fock states or strong non-linearities. Here we introduce a unified optical framework that removes this constraint, using only Gaussian inputs, optical parametric amplification, and heralded photon detection. Within a single architecture, we demonstrate the generation of photon-added squeezed states with near unit fidelity, cubic-phase-like states with strong non-linearities and fidelities above 98.5%, and squeezed-cat states exceeding 99% fidelity that can be iteratively bred into GKP grid states surpassing the 9.75 dB fault-tolerance threshold. Operating entirely below 3 dB of input squeezing, the approach provides a scalable, experimentally accessible platform that unites the state resources required for quantum communication, metrology, and computation within one coherent optical framework.",
          "authors": [
            "Ozlem Erkilic",
            "Aritra Das",
            "Biveen Shajilal",
            "Ping Koy Lam",
            "Timothy C. Ralph",
            "Syed M. Assad"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02611",
          "title": "Fundamentals of Theory of Continuous Gromov--Hausdorff distance",
          "abstract": "The Gromov--Hausdorff distance (hereinafter referred to as the GH-distance) is a measure of non-isometricity of metric spaces. In this paper, we study a modification of this distance that also takes topological differences into account. The resulting function of pairs of metric spaces is called the continuous GH-distance. We show that many basic properties of the classical GH-distance also hold in the continuous case. However, the continuous GH-distance, distinguishing between topologies, can differ significantly from the classical one. We will provide numerous examples of this distinction and demonstrate the role of topological dimension here. In particular, we will prove that the continuous GH-distance, like the classical one, is intrinsic, but, unlike the classical one, it is incomplete. Since we are dealing with all metric spaces, we will show, within the framework of the von Neumann-Bernays-Gödel set theory, how topological concepts can be transferred to proper classes.",
          "authors": [
            "Semeon A. Bogaty",
            "Alexey A. Tuzhilin"
          ],
          "primary_category": "math.MG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02612",
          "title": "Linear independence of values of Dirichlet $L$ functions",
          "abstract": "In this paper, for a given Dirichlet character mod $N$ with $4\\nmid N$, we give a lower bound of order $\\sqrt{s/\\log(s)}$ for the dimension of the $\\mathbb{Q}(e^{2i\\pi/N})$-vector space spanned by the values of its $L$-function at integers $\\leq s$ of a given parity. We thus generalize a result Fischler proved in 2021, corresponding to the principal character mod 1. To this end, we construct linear combinations of these values of $L$-function with a refined version of Siegel's lemma, and we apply to them a linear independence criterion generalizing the one used by Fischler. To check the assumptions of this criterion, we rely on a ``Shidlovskii's lemma''.",
          "authors": [
            "Ludovic Mistiaen"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02613",
          "title": "New 1mm thick Silicon Drift Detectors for future researches of Kaonic Atoms and the Pauli Exclusion principle",
          "abstract": "Kaonic atoms, formed when a negatively charged kaon replaces an electron, provide a sensitive probe of the low-energy strong interaction via precision X-ray spectroscopy. The SIDDHARTA-2 experiment at the DA$\\Phi$NE collider employs high-performance Silicon Drift Detectors (SDDs) optimized for the 4-12 keV range to study light kaonic systems. In preparation for the EXKALIBUR phase, which targets heavier kaonic atoms, new 1 mm-thick SDDs have been developed with Politecnico di Milano and Fondazione Bruno Kessler. Their increased thickness enhances the quantum efficiency by a factor of about two at 30 keV while preserving excellent energy resolution. These detectors are also intended for VIP-3, the next-generation test of the Pauli Exclusion Principle (PEP). Building on VIP-2, which set the most stringent limits on PEP-violating $K_{\\alpha}$ transitions in copper, VIP-3 will extend the search to heavier elements such as Ag, Sn, and Zr. Preliminary measurements demonstrate efficient detection up to 30 keV, supporting future high-precision studies of the kaon-nucleon interaction and PEP in heavier systems.",
          "authors": [
            "F. Clozza",
            "F. Sgaramella",
            "L. Abbene",
            "F. Artibani",
            "M. Bazzi",
            "G. Borghi",
            "D. Bosnar",
            "M. Bragadireanu",
            "A. Buttacavoli",
            "M. Carminati",
            "A. Clozza",
            "R. Del Grande",
            "L. De Paolis",
            "E. Demenev",
            "C. Fiorini",
            "I. Friščić",
            "C. Guaraldo",
            "M. Iliescu",
            "M. Iwasaki",
            "A. Khreptak",
            "S. Manti",
            "J. Marton",
            "P. Moskal",
            "H. Ohnishi",
            "K. Piscicchia",
            "F. Principato",
            "A. Samusenko",
            "A. Scordo",
            "D. Sirghi",
            "F. Sirghi",
            "M. Skurzok",
            "A. Spallone",
            "K. Toho",
            "J. Zmeskal",
            "N. Zorzi",
            "C. Curceanu"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02615",
          "title": "Precise Twist Angle Determination in twisted WSe2 via Optical Moiré Phonons",
          "abstract": "Twisted bilayers of transition metal dichalcogenides (TMDC) form moiré superlattices resulting in moiré minibands in momentum space and hosting localized excitons in real space. While moiré superlattices provide access to Mott-Hubbard physics, their energy potential landscape and electronic correlations are highly sensitive to fluctuations of the twist angle, disorder and lattice reconstructions. However, fast and non-invasive experimental access to local twist angle and its spatial variations is challenging. Here, we systematically correlate twist angle variations of twisted WSe2 bilayers across micrometer length scales using a combined lateral force microscopy (LFM) and a micro- Raman spectroscopy approach. These measurements uncover lateral variations in the twist angle by more than 1° across length scales relevant to optical and transport measurements. We demonstrate that twist angles in the range of 3° < $\\alpha$ < 12° show distinct Raman response from scattering on optical moiré phonons allowing twist angle determination with high precision and sub-micrometer spatial resolution under ambient conditions. These modes are particularly sensitive in the low-angle twist regime, predicted to host emergent quantum phases. Our results establish micro-Raman spectroscopy of optical moiré phonons as a rapid, non-invasive probe to determine twist angle and to screen local twist angle variations with a precision better than $\\pm$ 0.3° and a lateral resolution below one micrometer. This methodology is also applicable to fully hBN-encapsulated heterostructures.",
          "authors": [
            "Nicolai-Leonid Bathen",
            "Thorsten Deilmann",
            "Ana Senkić",
            "Hendrik Lambers",
            "Rami Dana",
            "Kenji Watanabe",
            "Takashi Taniguchi",
            "Frances M. Ross",
            "Julian Klein",
            "Ursula Wurstbauer"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02616",
          "title": "Interface Correlators in Symmetric Product Orbifolds",
          "abstract": "Symmetric product orbifolds provide a controlled environment to explore generic features of gauge theory and holography. The tractability of these theories lies in the complete characterisation of their gauge structure through holomorphic covering maps. In this paper, we introduce a novel class of generalised covering maps, which define a universal family of interfaces between symmetric product orbifolds. These interfaces coincide with the holographic interfaces that were recently proposed as duals to AdS$_2$ branes in pure NSNS AdS$_3$ backgrounds. The new covering-map description enables efficient evaluation of interface correlators via a generalisation of the Lunin-Mathur method. To organise these computations, we derive a generalised Riemann-Hurwitz formula for interface coverings and introduce novel diagrammatic rules that systematically classify these maps. The new framework allows us to define a concrete grand-canonical ensemble that has the correct properties to compute correlation functions dual to open string scattering amplitudes. Using the generalised Riemann-Hurwitz formula, we explicitly show that the correlators of the ensemble structurally match string perturbation theory to all orders in the string coupling.",
          "authors": [
            "Sebastian Harris",
            "Volker Schomerus",
            "Takashi Tsuda"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02617",
          "title": "The role of counting quantifiers in laminar set systems",
          "abstract": "Laminar set systems consist of non-crossing subsets of a universe with set inclusion essentially corresponding to the descendant relationship of a tree, the so-called laminar tree. Laminar set systems lie at the core of many graph decompositions such as modular decompositions, split decompositions, and bi-join decompositions. We show that from a laminar set system we can obtain the corresponding laminar tree by means of a monadic second order logic (MSO) transduction. This resolves an open question originally asked by Courcelle and is a satisfying resolution as MSO is the natural logic for set systems and is sufficient to define the property ``laminar''. Using results from Campbell et al. [STACS 2025], we can now obtain transductions for obtaining modular decompositions, co-trees, split decompositions and bi-join decompositions using MSO instead of CMSO. We further gain some insight into the expressive power of counting quantifiers and provide some results towards determining when counting quantifiers can be simulated in MSO in laminar set systems and when they cannot.",
          "authors": [
            "Rutger Campbell",
            "Noleen Köhler"
          ],
          "primary_category": "cs.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02620",
          "title": "Remarks on uniform recurrence properties for beta-transformation",
          "abstract": "We complement the recent paper of Zheng and Wu [Uniform recurrence properties for beta-transformation, Nonlinearity 33 (2020), 4590--4612], where the authors study, from the metrical point of view, the uniform recurrence properties of the orbit of a point under the $\\beta$-transformation to the point itself.",
          "authors": [
            "Yann Bugeaud"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02623",
          "title": "High-harmonic generation from two weakly coupled molecules: a simple tight-binding model",
          "abstract": "The generation of high harmonics is a strongly nonlinear effect that allows to probe properties of the target and to study electron dynamics in matter. It has been investigated in many different kinds of targets, including molecular gases, liquids and solids. Recently, high-harmonic generation was studied in organic molecular crystals by Wiechmann et al. [Nat. Commun. 16, 9890 (2025)]. It was found that the laser-polarization-dependent harmonic yield is sensitive to the weak couplings between nearest- and next-nearest-neighbor molecules. In this paper, the impact of the laser polarization angle and the intermolecular interaction on the harmonic yield is examined in detail using a simple but insightful two-dimensional tight-binding system that models a molecular dimer, i.e. two weakly coupled molecules. We find that the intensities of lower harmonic orders tend to maximize for a laser polarization direction aligning with the molecular axes, whereas higher harmonic orders rather show the strongest yield for a polarization direction along the intermolecular axis. We further demonstrate that the harmonic order at which the maximum flips from the molecular to the intermolecular direction strongly depends on the intermolecular coupling strength. To gain a deeper insight into the origins of the findings, we include a detailed adiabatic analysis, showing that the flipping of the maximum yield towards the intermolecular direction is already contained qualitatively in the adiabatically following states.",
          "authors": [
            "Lina Bielke",
            "Samuel Schöpa",
            "Falk-Erik Wiechmann",
            "Franziska Fennel",
            "Dieter Bauer"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02623",
          "title": "High-harmonic generation from two weakly coupled molecules: a simple tight-binding model",
          "abstract": "The generation of high harmonics is a strongly nonlinear effect that allows to probe properties of the target and to study electron dynamics in matter. It has been investigated in many different kinds of targets, including molecular gases, liquids and solids. Recently, high-harmonic generation was studied in organic molecular crystals by Wiechmann et al. [Nat. Commun. 16, 9890 (2025)]. It was found that the laser-polarization-dependent harmonic yield is sensitive to the weak couplings between nearest- and next-nearest-neighbor molecules. In this paper, the impact of the laser polarization angle and the intermolecular interaction on the harmonic yield is examined in detail using a simple but insightful two-dimensional tight-binding system that models a molecular dimer, i.e. two weakly coupled molecules. We find that the intensities of lower harmonic orders tend to maximize for a laser polarization direction aligning with the molecular axes, whereas higher harmonic orders rather show the strongest yield for a polarization direction along the intermolecular axis. We further demonstrate that the harmonic order at which the maximum flips from the molecular to the intermolecular direction strongly depends on the intermolecular coupling strength. To gain a deeper insight into the origins of the findings, we include a detailed adiabatic analysis, showing that the flipping of the maximum yield towards the intermolecular direction is already contained qualitatively in the adiabatically following states.",
          "authors": [
            "Lina Bielke",
            "Samuel Schöpa",
            "Falk-Erik Wiechmann",
            "Franziska Fennel",
            "Dieter Bauer"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02627",
          "title": "Harnessing swarms for directed migration of interacting active particles via optimal global control",
          "abstract": "This study investigates the use of global control strategies to enhance the directed migration of swarms of interacting self-propelled particles confined in a channel. Uncontrolled dynamics naturally leads to wall accumulation, clogging, and band formation due to the interplay between self-organization and confinement. This work explores whether a uniform global control, such as magnetic field acting on all particles, can optimize collective transport. Using a discrete Vicsek-like model, it is found that simple global alignment controls, optimized via reinforcement learning, efficiently suppress unfavorable configurations and significantly increase the net particle flux along a prescribed channel direction. These results highlight that coarse, system-level observations are sufficient to achieve near-optimal control, even in regimes with strong fluctuations or partial ordering.",
          "authors": [
            "Chiara Calascibetta",
            "Laëtitia Giraldi",
            "Jérémie Bec"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02632",
          "title": "GaN mid-IR plasmonics: low-loss epsilon-near-zero modes",
          "abstract": "Epsilon-near-zero (ENZ) materials, defined by $ | Re({\\epsilon}) | < 1$, enable unique light propagation characteristics, including confinement within sub-wavelength regions. To reduce losses in this regime, materials with both near-zero permittivity and $n<1$ refractive index, known as near-zero-index (NZI) materials, are desired. When both conditions are satisfied, the resulting region is classified as a low-loss ENZ medium combining strong light confinement with reduced optical losses. To achieve this behavior in the mid-IR, heavily doped semiconductors are required, and those compatible with current technologies are most desirable. This work provides the first in-depth study, supported by experimental demonstrations, of the plasmonic properties of highly doped GaN thin films on Si, exhibiting low optical losses and low-loss ENZ characteristics up to $3{\\mu}m$. From the extracted optical parameters, the ENZ and NZI regions are determined and compared with the existing literature. As a result of the large polar character of nitrides, a hybridization of the surface plasmon and phonon polaritons is observed, accompanied by a flat-dispersion of the high-energy mode (pinned near the plasma frequency) indicative of its ENZ character. Establishing GaN as a viable platform for mid-IR ENZ-based plasmonics paves the way for integration into future infrared photonic technologies.",
          "authors": [
            "Julia Inglés-Cerrillo",
            "Maria Villanueva-Blanco",
            "Benjamin Damilano",
            "Stéphane Vézian",
            "Miguel Montes Bajo",
            "Adrian Hierro"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02637",
          "title": "Higgs physics in superconductors",
          "abstract": "As pointed out by Nambu-Goldstone, continuous symmetry breaking gives rise to gapless bosonic excitation. In superconductors, continuous local U(1) gauge symmetry is broken. The gapless excitation thus created is the collective phase mode of a superconductor. In 1962, Anderson pointed out that Coulomb interaction lifts this gapless mode to the superconducting plasma frequency. Therefore, in a superconducting fluid there are no bosonic excitations below the Cooper pair binding energy. Anderson mechanism also implies that the massless photon becomes massive in a superconductor. It provides a microscopic theory for dissipationless charge transport (with Landau criterion for superfluidity) and the Meissner effect in a superconductor. Jumping to particle physics, to explain why the gauge bosons for electroweak interaction are massive, Higgs, Englert, Kibble et al. proposed the existence of the Higgs field. This matter field couples to the massless W, Z bosons and generates mass via the Higgs mechanism. Due to their conceptual similarities, these two mechanisms are referred to as the Anderson-Higgs mechanism. In 2013, the detection of the Higgs boson provided the final proof for the Higgs hypothesis decades after its conception. The amplitude mode of a superconductor, which corresponds to the Higgs boson in the above analogy, is referred to as the Higgs mode. Its spectroscopic detection has also remained elusive for decades. In recent years, the development of ultrafast techniques enabled an effective approach for studying the mode. Here, we introduce the Higgs mode from a perspective of why superconductors superconduct and review the recent development in Higgs spectroscopy, particularly in the field of nonlinear terahertz spectroscopy. We discuss the novel insights that may be learnt from these studies for future high-Tc superconductivity and correlated materials research in general.",
          "authors": [
            "Hao Chu",
            "Haotian Zhang",
            "Zhili Zhang"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02638",
          "title": "Electric-Field and Doping-Induced Non collinear Magnetic Interactions in Monolayer Ti$_2$Si",
          "abstract": "Two-dimensional (2D) silicides are an emerging class of materials whose magnetic and relativistic properties remain largely unexplored. Using first-principles calculations, we investigate how electric-field modulation and transition-metal doping influence the magnetic exchange, magnetocrystalline anisotropy, and antisymmetric Dzyaloshinskii-Moriya interaction (DMI) in monolayer Ti2Si. Pristine Ti2Si is a dynamically stable ferromagnetic metal with in-plane anisotropy and centrosymmetric bonding, which suppresses DMI even under strong perpendicular electric fields. To overcome this symmetry constraint, we introduce Pt and Co substitution at Ti sites. Co enhances the magnetic exchange, whereas Pt provides strong spin orbit coupling (SOC), and the combined chemical asymmetry breaks inversion symmetry sufficiently to induce a sizable DMI. A Wannier-based tight-binding model captures the orbital-resolved superexchange pathways and reveals a clear hierarchy between a weak Si-mediated channel and a dominant Pt-mediated interlayer channel. First-principles calculations confirm that the Pt-assisted pathway governs the magnitude and sign of the total DMI. Among all configurations, Pt0.5CoTi0.5Si exhibits the strongest chiral interaction, with its intralayer and interlayer contributions favoring opposite rotation senses, namely counterclockwise (CCW) and clockwise (CW). Our results establish chemically engineered Ti2Si monolayers as a promising platform for realizing and tuning chiral magnetic textures in 2D silicides.",
          "authors": [
            "Dimple Rani",
            "Gayatri Panda",
            "Subrata Jana",
            "Prasanjit Samal"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02639",
          "title": "Competing excitonic couplings as origin of mimicked phase transitions in zinc-phthalocyanine single crystals",
          "abstract": "The optical properties of molecular crystals are largely determined by the excitonic coupling of neighboring molecules. This coupling is extremely sensitive to the arrangement of adjacent molecular units, as their electronic interaction is defined by the relative orientation of the individual transition dipole moments and their wave function overlap. Hence, the optical properties, such as fluorescence, are usually highly anisotropic and good indicators of structural changes during the variation of intensive thermodynamic parameters like temperature or pressure. Here, we discuss the peculiar though archetypical case of $\\beta$-phase zinc-phthalocyanine: In single crystals, we report a sudden change of spectral emission with temperature from a broad, unpolarized Frenkel-exciton type luminescence to a narrow, highly polarized superradiance-like fluorescence below 80 K. Surprisingly, we find that there is no sign of a discrete structural phase transition in this temperature regime. To understand this apparent contradiction, we perform polarization-, temperature- and time-dependent photoluminescence measurements along different crystallographic directions to fully map the emission characteristics of the crystal-exciton. By means of ab-initio calculations on a density functional theory level we conclude that our observations are consistent with a dimer exciton model when considering thermalized electronic states. As such, our study presents a representative case study on a well-established molecular material class demonstrating that caution is advised when attributing discrete changes in electronic observables to a structural phase transition. As we show for zinc-phthalocyanine in its $\\beta$-phase modification, slowly varying excitonic couplings and thermal redistribution of excitations can mimic the same signatures attributed to a structural phase transition.",
          "authors": [
            "Lisa Schraut-May",
            "Sebastian Hammer",
            "Luca Nils Philipp",
            "Krzysztof Radacki",
            "Gabriele Tauscher",
            "Helena Hollstein",
            "Kilian Strauß",
            "Martin Kamp",
            "Heinrich Schwoerer",
            "Holger Braunschweig",
            "Roland Mitric",
            "Jens Pflaum"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02639",
          "title": "Competing excitonic couplings as origin of mimicked phase transitions in zinc-phthalocyanine single crystals",
          "abstract": "The optical properties of molecular crystals are largely determined by the excitonic coupling of neighboring molecules. This coupling is extremely sensitive to the arrangement of adjacent molecular units, as their electronic interaction is defined by the relative orientation of the individual transition dipole moments and their wave function overlap. Hence, the optical properties, such as fluorescence, are usually highly anisotropic and good indicators of structural changes during the variation of intensive thermodynamic parameters like temperature or pressure. Here, we discuss the peculiar though archetypical case of $\\beta$-phase zinc-phthalocyanine: In single crystals, we report a sudden change of spectral emission with temperature from a broad, unpolarized Frenkel-exciton type luminescence to a narrow, highly polarized superradiance-like fluorescence below 80 K. Surprisingly, we find that there is no sign of a discrete structural phase transition in this temperature regime. To understand this apparent contradiction, we perform polarization-, temperature- and time-dependent photoluminescence measurements along different crystallographic directions to fully map the emission characteristics of the crystal-exciton. By means of ab-initio calculations on a density functional theory level we conclude that our observations are consistent with a dimer exciton model when considering thermalized electronic states. As such, our study presents a representative case study on a well-established molecular material class demonstrating that caution is advised when attributing discrete changes in electronic observables to a structural phase transition. As we show for zinc-phthalocyanine in its $\\beta$-phase modification, slowly varying excitonic couplings and thermal redistribution of excitations can mimic the same signatures attributed to a structural phase transition.",
          "authors": [
            "Lisa Schraut-May",
            "Sebastian Hammer",
            "Luca Nils Philipp",
            "Krzysztof Radacki",
            "Gabriele Tauscher",
            "Helena Hollstein",
            "Kilian Strauß",
            "Martin Kamp",
            "Heinrich Schwoerer",
            "Holger Braunschweig",
            "Roland Mitric",
            "Jens Pflaum"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02641",
          "title": "Hausdorff dimension for the weighted products of multiple digits in d-decaying Gauss like systems",
          "abstract": "We compute the Hausdorff dimension of sets defined by the growth of weighted products of multiple digits at arbitrary positions in $d$-decaying Gauss-like iterated function systems. We provide the complete Hausdorff dimensional result for product of more than two digits, which was an open problem even for consecutive digits in the classical Gauss map and Lüroth map. In our approach we do not need to assume the Bounded Distortion Property (BDP).",
          "authors": [
            "Ayreena Bakhtawar",
            "Michał Rams"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02644",
          "title": "On the relationship between Heider links and Ising spins",
          "abstract": "We show that the Heider model with an external field is equivalent, in the limit of structural balance, to the Ising model with nearest-neighbor interactions without an external field. More precisely, we claim that the signs of the Heider relations that maintain structural equilibrium in the system can be represented as nearest neighbor Ising spin products. We demonstrate this explicitly for a complete graph and provide a general argument for an arbitrary graph. A consequence of the equivalence is that the system of balanced Heider states undergoes a phase transition, inherited from the Ising model, at a critical value of the social field at which the fluctuations of edge magnetization are maximal.",
          "authors": [
            "Zdzisław Burda",
            "Maciej Wołoszyn",
            "Krzysztof Malarz",
            "Krzysztof Kułakowski"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02645",
          "title": "Chiplet technology for large-scale trapped-ion quantum processors",
          "abstract": "Trapped ions are among the most promising platforms for realizing a large-scale quantum information processor. Current progress focuses on integrating optical and electronic components into microfabricated ion traps to allow scaling to large numbers of ion qubits. Most available fabrication strategies for such integrated processors employ monolithic integration of all processor components and rely heavily on CMOS-compatible semiconductor fabrication technologies that are not optimized for the requirements of a trapped-ion quantum processor. In this work, we present a modular approach in which the processor modules, called chiplets, have specific functions and are fabricated separately. The individual chiplets are then combined using heterogeneous integration techniques. This strategy opens up the possibility of choosing the optimal materials and fabrication technology for each of the chiplets, with a minimum amount of fabrication limitations compared to the monolithic approach. Chiplet technology furthermore enables novel processor functionalities to be added in a cost-effective, modular fashion by adding or modifying only a subset of the chiplets. We describe the design concept of a chiplet-based trapped-ion quantum processor and demonstrate the technology with an example of an integrated individual-ion addressing system for a ten-ion crystal. The addressing system emphasizes the modularity of the chiplet approach, combining a surface ion trap manufactured on a glass substrate with a silicon substrate carrying integrated waveguides and a stack of 3D-printed micro-optics, achieving diffraction-limited focal spots at the ion positions.",
          "authors": [
            "Bassem Badawi",
            "Philip C. Holz",
            "Michael Raffetseder",
            "Nicolas Jungwirth",
            "Juris Ulmanis",
            "Hans-Joachim Quenzer",
            "Dirk Kähler",
            "Thomas Monz",
            "Philipp Schindler"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02647",
          "title": "Using precision coefficients on recurrence times and integrated currents to lower bound the average dissipation rate",
          "abstract": "For continuous-time Markov jump processes on irreducible networks and time-independent rate constants, we employ a transition-based formalism to express the long-time precision of a single integrated current over an observable channel in terms of precisions of the recurrence times of the forward and backward jumps, and of an effective affinity that captures the thermodynamic driving on that channel. This leads to a general lower bound for the stationary entropy production rate that extends the well-known Thermodynamic Uncertainty Relation (TUR). Such an augmented TUR, which incorporates the statistics of the recurrences, proves to be tighter than the standard one far from equilibrium, and potentially offers new opportunities for the optimization and design of biological and chemical out-of-equilibrium systems at the nanoscale.",
          "authors": [
            "Alberto Garilli",
            "Diego Frezzato"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02658",
          "title": "Multimode interface between optical free-space- and waveguide modes",
          "abstract": "Free-space and on-chip photonic systems are key components in optical communication networks. While free-space beams allow for the flexible generation and manipulation of spatial modes, integrated waveguides provide compact and stable platforms for on-chip signal processing. Bridging these two domains is essential for scalable multi-mode communication networks. Here, we present an efficient, broadband interface capable of converting multiple higher-order free-space Laguerre-Gauss (LG) modes into corresponding waveguide modes using the multi-plane light conversion (MPLC) scheme. We experimentally demonstrate low-crosstalk mode conversion between various set of three LG modes, and the first three TE modes of a multimode silicon waveguide across the telecom C-band. The system operates passively without active switching and can be adapted to different spatial mode sets. This platform provides a pathway to increased data capacities and may enable more compact and efficient multi-mode optical communication and on-chip processing schemes.",
          "authors": [
            "Teresia Stranden",
            "Oussama Korichi",
            "Matias Eriksson",
            "Matteo Cherchi",
            "George Thomas",
            "Robert Fickler"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02659",
          "title": "Fully Integrated Perovskite Polaritonic Circuits with Tunable Lasing and Nonlinear Amplification",
          "abstract": "Photonic integrated circuits are emerging as a key technology for compact and energy-efficient optical information processing. Yet, their practical implementation remains limited by the intrinsically weak optical nonlinearities of conventional materials, which demand high power and large footprints to achieve significant nonlinear responses. Exciton-polaritons, hybrid light-matter excitations of semiconducting materials, offer a promising solution by combining strong optical nonlinearities with the high speed and large scalability typical of photonic devices. However, despite their potential, working on-chip polaritonic elements demonstrating room temperature coherent lasing, controllable nonlinear propagation, or amplification have remained elusive. Here we demonstrate a fully integrated perovskite polaritonic circuit that overcomes these limitations. Using a single-step microfluidic lithographic technique, we realize waveguide circuits with integrated gratings that simultaneously act as couplers and mirrors, forming in-plane Fabry-Pérot cavities. These structures support robust in-plane polariton lasing between gratings, yielding coherent emission along the waveguide. Furthermore, we observe clear signatures of strong nonlinear self-phase modulation and, for the first time, optical amplification of guided polaritons at room temperature. Our simple, scalable platform opens the way to low-power, highly nonlinear optical circuits for integrated photonics and neuromorphic architectures operating at room temperature.",
          "authors": [
            "Antonio Fieramosca",
            "Vincenzo Ardizzone",
            "Rosanna Mastria",
            "Laura Polimeno",
            "Lorenzo Dominici",
            "Umberto Dellasette",
            "Andrea Notargiacomo",
            "Marialilia Pea",
            "Raffaella Polito",
            "Eugenio Maggiolini",
            "Rughianah Gohar Ashfaq",
            "Fabio Bruni",
            "Elisa Fardelli",
            "Simona Sennato",
            "Francesco Todisco",
            "Dario Gerace",
            "Dario Ballarini",
            "Milena De Giorgi",
            "Ilenia Viola",
            "Daniele Sanvitto"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02661",
          "title": "Worst-case mixing estimates for Brownian motion with semipermeable barriers",
          "abstract": "We study the mixing properties of a Brownian motion whose movements are hindered by semipermeable barriers. Our setting assumes that the process takes values in a smooth planar domain and that the barriers are one-dimensional closed curves. We establish an upper bound on the mixing time and a lower bound on the stationary distribution in terms of geometric parameters. These worst-case bounds decay at an exponential rate as the domain grows large, and we give examples that show that exponential decay is necessary in our worst-case setting.",
          "authors": [
            "Alexander Van Werde",
            "Jaron Sanders"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02666",
          "title": "Efficient Simulation of the 2D Hubbard Model via Hilbert Space-Filling Curve Mapping",
          "abstract": "We investigate tensor network simulations of the two-dimensional Hubbard model by mapping the lattice onto a one-dimensional chain using space-filling curves. In particular, we focus on the Hilbert curve, whose locality-preserving structure minimizes the range of effective interactions in the mapped model. This enables a more compact matrix product state (MPS) representation compared to conventional snake mapping. Through systematic benchmarks, we show that the Hilbert curve consistently yields lower ground-state energies at fixed bond dimension, with the advantage increasing for larger system sizes and in physically relevant interaction regimes. Our implementation reaches clusters up to $32\\times32$ sites with open and periodic boundary conditions, delivering reliable ground-state energies and correlation functions in agreement with established results, but at significantly reduced computational cost. These findings establish space-filling curve mappings, particularly the Hilbert curve, as a powerful tool for extending tensor-network studies of strongly correlated two-dimensional quantum systems beyond the limits accessible with standard approaches.",
          "authors": [
            "Ashkan Abedi",
            "Vittorio Giovannetti",
            "Dario De Santis"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02666",
          "title": "Efficient Simulation of the 2D Hubbard Model via Hilbert Space-Filling Curve Mapping",
          "abstract": "We investigate tensor network simulations of the two-dimensional Hubbard model by mapping the lattice onto a one-dimensional chain using space-filling curves. In particular, we focus on the Hilbert curve, whose locality-preserving structure minimizes the range of effective interactions in the mapped model. This enables a more compact matrix product state (MPS) representation compared to conventional snake mapping. Through systematic benchmarks, we show that the Hilbert curve consistently yields lower ground-state energies at fixed bond dimension, with the advantage increasing for larger system sizes and in physically relevant interaction regimes. Our implementation reaches clusters up to $32\\times32$ sites with open and periodic boundary conditions, delivering reliable ground-state energies and correlation functions in agreement with established results, but at significantly reduced computational cost. These findings establish space-filling curve mappings, particularly the Hilbert curve, as a powerful tool for extending tensor-network studies of strongly correlated two-dimensional quantum systems beyond the limits accessible with standard approaches.",
          "authors": [
            "Ashkan Abedi",
            "Vittorio Giovannetti",
            "Dario De Santis"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02666",
          "title": "Efficient Simulation of the 2D Hubbard Model via Hilbert Space-Filling Curve Mapping",
          "abstract": "We investigate tensor network simulations of the two-dimensional Hubbard model by mapping the lattice onto a one-dimensional chain using space-filling curves. In particular, we focus on the Hilbert curve, whose locality-preserving structure minimizes the range of effective interactions in the mapped model. This enables a more compact matrix product state (MPS) representation compared to conventional snake mapping. Through systematic benchmarks, we show that the Hilbert curve consistently yields lower ground-state energies at fixed bond dimension, with the advantage increasing for larger system sizes and in physically relevant interaction regimes. Our implementation reaches clusters up to $32\\times32$ sites with open and periodic boundary conditions, delivering reliable ground-state energies and correlation functions in agreement with established results, but at significantly reduced computational cost. These findings establish space-filling curve mappings, particularly the Hilbert curve, as a powerful tool for extending tensor-network studies of strongly correlated two-dimensional quantum systems beyond the limits accessible with standard approaches.",
          "authors": [
            "Ashkan Abedi",
            "Vittorio Giovannetti",
            "Dario De Santis"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02670",
          "title": "Models of holomorphic functions on the symmetrized skew bidisc",
          "abstract": "The purpose of this paper is to develop the theory of holomorphic functions with modulus bounded by $1$ on the symmetrized skew bidisc \\[ \\mathbb{G}_{r} \\stackrel{\\rm def}{=} \\Big\\{( \\lambda_{1}+r\\lambda_{2} ,r\\lambda_{1}\\lambda_{2}): \\lambda_{1}\\in \\mathbb{D}, \\lambda_{2}\\in\\mathbb{D}\\Big\\}, \\] for a fixed $r \\in (0,1)$. We show the existence of a realization formula and a model formula for such holomorphic functions.",
          "authors": [
            "Connor Evans",
            "Zinaida A. Lykova",
            "N. J. Young"
          ],
          "primary_category": "math.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02673",
          "title": "Chen Ning Yang Retrospective",
          "abstract": "Chen-Ning Yang made important contributions to the theory of solvable models in statistical mechanics, including generalizations of the Bethe Ansatz, magnetization in the Ising model, the Lee-Yang circle theorem, and the Yang-Baxter equation. Most famously, Yang made transformative contributions to the current Standard Model of elementary particle interactions. The proposal of Yang and T. D. Lee, that left-right symetry (parity) is violated in weak particle decays, established that the primary currents involved in weak interactions are left handed. The work of Yang and R. L. Mills gave a framework for force carriers coupling to these currents that are non-Abelian generalizations of the electromagnetic photon, which unlike the electrically neutral photon, carry ``charges'' to which they self-couple . Two decades of work by others on quantization and mass-generation mechanisms then culminated in the Standard Model.",
          "authors": [
            "Stephen L. Adler"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02673",
          "title": "Chen Ning Yang Retrospective",
          "abstract": "Chen-Ning Yang made important contributions to the theory of solvable models in statistical mechanics, including generalizations of the Bethe Ansatz, magnetization in the Ising model, the Lee-Yang circle theorem, and the Yang-Baxter equation. Most famously, Yang made transformative contributions to the current Standard Model of elementary particle interactions. The proposal of Yang and T. D. Lee, that left-right symetry (parity) is violated in weak particle decays, established that the primary currents involved in weak interactions are left handed. The work of Yang and R. L. Mills gave a framework for force carriers coupling to these currents that are non-Abelian generalizations of the electromagnetic photon, which unlike the electrically neutral photon, carry ``charges'' to which they self-couple . Two decades of work by others on quantization and mass-generation mechanisms then culminated in the Standard Model.",
          "authors": [
            "Stephen L. Adler"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02673",
          "title": "Chen Ning Yang Retrospective",
          "abstract": "Chen-Ning Yang made important contributions to the theory of solvable models in statistical mechanics, including generalizations of the Bethe Ansatz, magnetization in the Ising model, the Lee-Yang circle theorem, and the Yang-Baxter equation. Most famously, Yang made transformative contributions to the current Standard Model of elementary particle interactions. The proposal of Yang and T. D. Lee, that left-right symetry (parity) is violated in weak particle decays, established that the primary currents involved in weak interactions are left handed. The work of Yang and R. L. Mills gave a framework for force carriers coupling to these currents that are non-Abelian generalizations of the electromagnetic photon, which unlike the electrically neutral photon, carry ``charges'' to which they self-couple . Two decades of work by others on quantization and mass-generation mechanisms then culminated in the Standard Model.",
          "authors": [
            "Stephen L. Adler"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02673",
          "title": "Chen Ning Yang Retrospective",
          "abstract": "Chen-Ning Yang made important contributions to the theory of solvable models in statistical mechanics, including generalizations of the Bethe Ansatz, magnetization in the Ising model, the Lee-Yang circle theorem, and the Yang-Baxter equation. Most famously, Yang made transformative contributions to the current Standard Model of elementary particle interactions. The proposal of Yang and T. D. Lee, that left-right symetry (parity) is violated in weak particle decays, established that the primary currents involved in weak interactions are left handed. The work of Yang and R. L. Mills gave a framework for force carriers coupling to these currents that are non-Abelian generalizations of the electromagnetic photon, which unlike the electrically neutral photon, carry ``charges'' to which they self-couple . Two decades of work by others on quantization and mass-generation mechanisms then culminated in the Standard Model.",
          "authors": [
            "Stephen L. Adler"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02673",
          "title": "Chen Ning Yang Retrospective",
          "abstract": "Chen-Ning Yang made important contributions to the theory of solvable models in statistical mechanics, including generalizations of the Bethe Ansatz, magnetization in the Ising model, the Lee-Yang circle theorem, and the Yang-Baxter equation. Most famously, Yang made transformative contributions to the current Standard Model of elementary particle interactions. The proposal of Yang and T. D. Lee, that left-right symetry (parity) is violated in weak particle decays, established that the primary currents involved in weak interactions are left handed. The work of Yang and R. L. Mills gave a framework for force carriers coupling to these currents that are non-Abelian generalizations of the electromagnetic photon, which unlike the electrically neutral photon, carry ``charges'' to which they self-couple . Two decades of work by others on quantization and mass-generation mechanisms then culminated in the Standard Model.",
          "authors": [
            "Stephen L. Adler"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02673",
          "title": "Chen Ning Yang Retrospective",
          "abstract": "Chen-Ning Yang made important contributions to the theory of solvable models in statistical mechanics, including generalizations of the Bethe Ansatz, magnetization in the Ising model, the Lee-Yang circle theorem, and the Yang-Baxter equation. Most famously, Yang made transformative contributions to the current Standard Model of elementary particle interactions. The proposal of Yang and T. D. Lee, that left-right symetry (parity) is violated in weak particle decays, established that the primary currents involved in weak interactions are left handed. The work of Yang and R. L. Mills gave a framework for force carriers coupling to these currents that are non-Abelian generalizations of the electromagnetic photon, which unlike the electrically neutral photon, carry ``charges'' to which they self-couple . Two decades of work by others on quantization and mass-generation mechanisms then culminated in the Standard Model.",
          "authors": [
            "Stephen L. Adler"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02674",
          "title": "Rational regulation strategies of interstitial localized electrons in electride: A density functional theory study",
          "abstract": "As a class of electron-rich materials, electrides demonstrate promising applications in many fields. However, the required high pressure restricts the practical applications to some extent. This study reveals that the unique feature of electride, i.e., the localization of interstitial electrons, can be greatly enhanced and tuned by self-defective doping, applying tensile/compressive stress, or shear stress. Moreover, the requirement of orbital orthogonality between the valence and core electron wave functions, as well as the Pauli exclusion principle, should be the driven force for the electron interstitial localization; and the exertion of external pressure modifies the available space to accommodate the electronic wave functions, thus enhances the interstitial localization. These discoveries lay down the ground for searching for promising electrides that are practicable at ambient conditions.",
          "authors": [
            "L. Zhang",
            "D. Wang",
            "H. Wang",
            "J. Li",
            "Y. F. Wang",
            "Q. Wu",
            "Hua Y. Geng"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02674",
          "title": "Rational regulation strategies of interstitial localized electrons in electride: A density functional theory study",
          "abstract": "As a class of electron-rich materials, electrides demonstrate promising applications in many fields. However, the required high pressure restricts the practical applications to some extent. This study reveals that the unique feature of electride, i.e., the localization of interstitial electrons, can be greatly enhanced and tuned by self-defective doping, applying tensile/compressive stress, or shear stress. Moreover, the requirement of orbital orthogonality between the valence and core electron wave functions, as well as the Pauli exclusion principle, should be the driven force for the electron interstitial localization; and the exertion of external pressure modifies the available space to accommodate the electronic wave functions, thus enhances the interstitial localization. These discoveries lay down the ground for searching for promising electrides that are practicable at ambient conditions.",
          "authors": [
            "L. Zhang",
            "D. Wang",
            "H. Wang",
            "J. Li",
            "Y. F. Wang",
            "Q. Wu",
            "Hua Y. Geng"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02674",
          "title": "Rational regulation strategies of interstitial localized electrons in electride: A density functional theory study",
          "abstract": "As a class of electron-rich materials, electrides demonstrate promising applications in many fields. However, the required high pressure restricts the practical applications to some extent. This study reveals that the unique feature of electride, i.e., the localization of interstitial electrons, can be greatly enhanced and tuned by self-defective doping, applying tensile/compressive stress, or shear stress. Moreover, the requirement of orbital orthogonality between the valence and core electron wave functions, as well as the Pauli exclusion principle, should be the driven force for the electron interstitial localization; and the exertion of external pressure modifies the available space to accommodate the electronic wave functions, thus enhances the interstitial localization. These discoveries lay down the ground for searching for promising electrides that are practicable at ambient conditions.",
          "authors": [
            "L. Zhang",
            "D. Wang",
            "H. Wang",
            "J. Li",
            "Y. F. Wang",
            "Q. Wu",
            "Hua Y. Geng"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02675",
          "title": "On the intersection of Cantor sets and products of random matrices",
          "abstract": "Kenyon and Peres (1991) showed that the Hausdorff dimension of intersections of randomly translated Cantor sets can be expressed in terms of the top Lyapunov exponent of a product of random matrices, and this exponent can be written as an integral with respect to stationary measures on the projective line. Although explicit computations are available when stationary measures are discrete, the continuous case has remained challenging. In this paper we introduce new combinatorial and analytic tools that allow us to compute the Lyapunov exponent, and hence the Hausdorff dimension, in a broad class of examples where stationary measures are continuous. As an application, we complete the dimension computation in the setting where a single digit is forbidden; for example, we determine the Hausdorff dimension of the intersection of the middle-seventh Cantor set with a random translate of itself.",
          "authors": [
            "Nima Alibabaei"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02678",
          "title": "The exchange coupling of a Wigner dimer",
          "abstract": "We study the exchange coupling in small Wigner crystals confined to one-dimensional space. In particular we concentrate on the simplest nontrivial case of two electrons in a box potential and calculate analytically the energy splitting between the lowest spatially symmetric and antisymmetric states, which is a relevant energy scale for the magnetic properties of the system. In the approximation of a fixed center of mass coordinate, the splitting decays exponentially with the square root of the distance between the electrons at the leading order. We show that the subleading exponential correction significantly increases the splitting and thus becomes crucial in order to describe correctly the exact numerical data for system sizes that are not astronomically large. Two methods of calculation of the energy splitting are developed. The first is based on the analysis of the exact solution that can be expressed in terms of the Whittaker functions. It applies at all values of the short-distance cutoff played by the width of one-dimensional wire that regularizes the Coulomb potential. The second method is based on the quasiclassical (or Wentzel-Kramers-Brillouin) approximation, which applies only for sufficiently large values of the cutoff. The two methods give identical result in the overlapping region. As a side result, our study gives the energy splitting in a triangular double well potential of inverse ``M'' shape.",
          "authors": [
            "Daniele Lagasco",
            "Zoran Ristivojevic"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02684",
          "title": "Kaganov-Lifshitz-Tanatarov theory for tilted Dirac-cone materials: anisotropic heating from uniform light",
          "abstract": "We point out that in the tilted Dirac cone materials the non-equilibrium (hot) electron relaxation with phonons is anisotropic in the Brillouin zone. It means that there is a preferential heating of the lattice degrees of freedom in the specific directions of the Brillouin zone, in particular, in the direction opposite to the tilt velocity in the model considered by us. This observation will have novel consequences: (1) With pump-probe spectroscopy applied to a given tilted Dirac cone material an anisotropic relaxation would lead to a transient anisotropic heating which can further lead to a transient Seebeck effect as transient thermal gradients would exist in the specific directions of the BZ, and (2) this direction of anisotropic heating can be controlled by controlling the direction of the tilt velocity which can be externally tuned by the application of an external pressure. We foresee novel applications of this effect in ultrafast sensor applications involving transient heating effects. This is equivalent to inducing a transient Seebeck effect by just shinning light on a tilted Dirac cone material!",
          "authors": [
            "Navinder Singh",
            "Bharathiganesh Devanarayanan",
            "Sruthi Sudhakaran",
            "Jalaja Pandya",
            "Saptarshi Mandal"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02688",
          "title": "Real-time imaging of slow noisy quasiparticle dynamics at a non-trivial metastable defect in an electronic crystal",
          "abstract": "Nonequilibrium self-assembly is the root of all emergent complexity, including life. In quantum materials emergent metastable states have become a very fashionable topic of research, but the study of resulting mesoscopic state dynamics is hindered by the absence of appropriate methods. Here we pioneer the use of fast-scanning tunnelling microscope (FSTM) techniques to investigate the internal dynamics of mesoscopic metastable topologically non-trivial defects in an electronic Wigner crystal superlattice created by a local electromagnetic perturbation. This allows us to record unprecedented individual electron motion trajectories in real-time on the millisecond timescale. Such dynamics is understood to arise from coupling of hybridised Goldstone-Higgs bound states localised at the Y junction with microscopic electronic degrees of freedom that lead to the formation of localised quasiparticles with slow internal dynamics. Their unprecedented robustness against external perturbations comes from non-local constraints and non-trivial broken symmetries. Two-level system telegraph noise maps at the junction show phase and amplitude that is correlated with the observed electron motion trajectories. Such observation of single-particle dynamics in real time fundamentally transforms our understanding of metastable quantum states in electronic crystals and paves the way for technological advancements that make use of engineered topologically non-trivial defects.",
          "authors": [
            "Yevhenii Vaskivskyi",
            "Jaka Vodeb",
            "Igor Vaskivskyi",
            "Dragan Mihailovic"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02691",
          "title": "A Tight Double-Exponentially Lower Bound for High-Multiplicity Bin Packing",
          "abstract": "Consider a high-multiplicity Bin Packing instance $I$ with $d$ distinct item types. In 2014, Goemans and Rothvoss gave an algorithm with runtime ${{|I|}^2}^{O(d)}$ for this problem~[SODA'14], where $|I|$ denotes the encoding length of the instance $I$. Although, Jansen and Klein~[SODA'17] later developed an algorithm that improves upon this runtime in a special case, it has remained a major open problem by Goemans and Rothvoss~[ this http URL '20] whether the doubly exponential dependency on $d$ is necessary. We solve this open problem by showing that unless the ETH fails, there is no algorithm solving the high-multiplicity Bin Packing problem in time ${{|I|}^2}^{o(d)}$. To prove this, we introduce a novel reduction from 3-SAT. The core of our construction is efficiently encoding the entire information from a 3-SAT instance with $n$ variables into an ILP with $O(\\log(n))$ variables. This result confirms that the Goemans and Rothvoss algorithm is best-possible for Bin Packing parameterized by the number $d$ of item sizes.",
          "authors": [
            "Klaus Jansen",
            "Felix Ohnesorge",
            "Lis Pirotton"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02698",
          "title": "Adaptive hydrogels with spatiotemporal stiffening using pH-modulating enzymes",
          "abstract": "Adaptive material systems that autonomously respond to external stimuli are crucial for advancing next-generation smart devices. Biological systems achieve autonomous behavior by utilizing chemical energy from out-of-equilibrium reactions to power life-like functions without requiring external energy inputs. Although responsive hydrogels with embedded enzymatic reactions offer a promising platform for implementing adaptive behavior in synthetic systems, previous studies have focused on controlling the supramolecular self-assembly of responsive building blocks rather than modulating network crosslinking. Here, we demonstrate direct enzymatic modulation of crosslinking density in a double-network hydrogel to achieve autonomous self-stiffening in response to a chemical stimulus. Our adaptive system embeds glucose oxidase within a polyacrylamide-alginate double-network hydrogel containing Ca(EDTA)2- complexes that render the crosslinked alginate network pH-responsive through a competitive calcium binding mechanism. Chemical waves emerging from enzymatic reaction activation propagate at speeds ranging from 15 to 44 um/min, driving spatiotemporal mechanical transitions that increase material stiffness by up to 2.1-fold. By integrating signal sensing and chemomechanical transduction within this responsive hydrogel, we realized adaptive behavior that autonomously converts localized chemical inputs into system-wide mechanical outputs. This positions our adaptive hydrogels as promising model systems to guide the design of intelligent materials for soft robotics and biomedical devices.",
          "authors": [
            "Natascha Gray",
            "Zoe Grämiger",
            "André R. Studart",
            "Rafael Libanori"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02701",
          "title": "Multi-node quantum key distribution network using existing underground optical fibre infrastructure",
          "abstract": "Quantum key distribution (QKD) offers unconditional information security by allowing two distant users to establish a common encryption key resilient to hacking. Resultingly, QKD networks interconnecting critical infrastructure and enabling the secure exchange of classified information, can provide a solution to the increasing number of successful cyberattacks. To efficiently deploy quantum networks, the technology must be integrated over existing communication infrastructure, such as optical fibre links. Yet, QKD poses stringent requirements on the conditions of the network over which it is deployed. This work demonstrates the first quantum communication network in Cyprus via the deployment of a multi-node quantum network, exploiting existing commercial underground optical fibre. The network employs bidirectional occupation of fibres and wavelength multiplexing in a ring architecture to achieve, with minimal use of dark fibres, high-rate QKD. Results obtained reveal consistent key generation rates across all nodes, confirming reliable operation in a real-world environment. This deployment highlights the feasibility of leveraging existing telecom infrastructure for quantum-secured communication, marking a significant step toward scalable and cost-effective quantum networks suited for critical applications.",
          "authors": [
            "Mariella Minder",
            "Andreas Siakolas",
            "Stephanos Yerolatsitis",
            "Konstantinos Katzis",
            "Kyriacos Kalli"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02706",
          "title": "Lectures on Quantum Field Theory on a Quantum Computer",
          "abstract": "The lecture notes cover the basics of quantum computing methods for quantum field theory applications. No detailed knowledge of either quantum computing or quantum field theory is assumed and we have attempted to keep the material at a pedagogical level. We review the anharmonic oscillator, using which we develop a hands-on treatment of certain interesting QFTs in $1+1D$: $\\phi^4$ theory, Ising field theory, and the Schwinger model. We review quantum computing essentials as well as tensor network techniques. The latter form an essential part for quantum computing benchmarking. Some error modelling on QISKIT is also done in the hope of anticipating runs on NISQ devices. These lecture notes are the expanded version of a one semester course taught by AS during August-November 2025 at the Indian Institute of Science and TA-ed by UB. The programs written for this course are available in a GitHub repository.",
          "authors": [
            "Aninda Sinha",
            "Ujjwal Basumatary"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02706",
          "title": "Lectures on Quantum Field Theory on a Quantum Computer",
          "abstract": "The lecture notes cover the basics of quantum computing methods for quantum field theory applications. No detailed knowledge of either quantum computing or quantum field theory is assumed and we have attempted to keep the material at a pedagogical level. We review the anharmonic oscillator, using which we develop a hands-on treatment of certain interesting QFTs in $1+1D$: $\\phi^4$ theory, Ising field theory, and the Schwinger model. We review quantum computing essentials as well as tensor network techniques. The latter form an essential part for quantum computing benchmarking. Some error modelling on QISKIT is also done in the hope of anticipating runs on NISQ devices. These lecture notes are the expanded version of a one semester course taught by AS during August-November 2025 at the Indian Institute of Science and TA-ed by UB. The programs written for this course are available in a GitHub repository.",
          "authors": [
            "Aninda Sinha",
            "Ujjwal Basumatary"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02709",
          "title": "Detection of Mpemba effect through good observables in open quantum systems",
          "abstract": "The Mpemba effect refers to the anomalous relaxation of a quantum state that, despite being initially farther from equilibrium, relaxes faster than a closer counterpart. Detecting such a quantum Mpemba effect typically requires full knowledge of the quantum state during its time evolution, which is an experimentally challenging task since state tomography becomes exponentially difficult as system size increases. This poses a significant obstacle in studying Mpemba effect in complex many-body systems. In this work, we demonstrate that this limitation can be overcome by identifying suitable observables that signal rapid relaxation. Moreover, as long as the system equilibrates to a known unique steady-state, it is possible to fully detect the occurrence of quantum Mpemba effect just by measuring the observable for known state preparations. Our approach thus significantly reduces experimental complexity and offers a practical route for observing the quantum Mpemba effect in complex and extended multi-qubit setups.",
          "authors": [
            "Pitambar Bagui",
            "Arijit Chatterjee",
            "Bijay Kumar Agarwalla"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02709",
          "title": "Detection of Mpemba effect through good observables in open quantum systems",
          "abstract": "The Mpemba effect refers to the anomalous relaxation of a quantum state that, despite being initially farther from equilibrium, relaxes faster than a closer counterpart. Detecting such a quantum Mpemba effect typically requires full knowledge of the quantum state during its time evolution, which is an experimentally challenging task since state tomography becomes exponentially difficult as system size increases. This poses a significant obstacle in studying Mpemba effect in complex many-body systems. In this work, we demonstrate that this limitation can be overcome by identifying suitable observables that signal rapid relaxation. Moreover, as long as the system equilibrates to a known unique steady-state, it is possible to fully detect the occurrence of quantum Mpemba effect just by measuring the observable for known state preparations. Our approach thus significantly reduces experimental complexity and offers a practical route for observing the quantum Mpemba effect in complex and extended multi-qubit setups.",
          "authors": [
            "Pitambar Bagui",
            "Arijit Chatterjee",
            "Bijay Kumar Agarwalla"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02718",
          "title": "Irreduciblity of certain $\\widehat{\\mathfrak sl}_2$-modules of Wakimoto type",
          "abstract": "We investigate the irreducible smooth $\\widehat{\\mathfrak{sl}}_{2}$-modules recently constructed in arXiv:2404.03855 , and demonstrate that these modules admit a Wakimoto-type realization at both critical and non-critical levels. In the critical level case, we identify simple quotients of these modules with the Wakimoto modules whose irreducibility was already established in arXiv:math/0602181 , arXiv:1402.6100 . We also generalize some Wakimoto modules constructed in arXiv:1409.5354 and identify them as generalized Whittaker modules.",
          "authors": [
            "Drazen Adamovic",
            "Veronika Pedic Tomic"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02718",
          "title": "Irreduciblity of certain $\\widehat{\\mathfrak sl}_2$-modules of Wakimoto type",
          "abstract": "We investigate the irreducible smooth $\\widehat{\\mathfrak{sl}}_{2}$-modules recently constructed in arXiv:2404.03855 , and demonstrate that these modules admit a Wakimoto-type realization at both critical and non-critical levels. In the critical level case, we identify simple quotients of these modules with the Wakimoto modules whose irreducibility was already established in arXiv:math/0602181 , arXiv:1402.6100 . We also generalize some Wakimoto modules constructed in arXiv:1409.5354 and identify them as generalized Whittaker modules.",
          "authors": [
            "Drazen Adamovic",
            "Veronika Pedic Tomic"
          ],
          "primary_category": "math.QA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02723",
          "title": "Emergent Quantum Valley Hall Insulator from Electron Interactions in Transition-Metal Dichalcogenide Heterobilayers",
          "abstract": "We explore the emergence of topological phases in moiré MoTe$_2$/WSe$_2$ bilayer, highlighting the crucial role of spin-orbit coupling and Coulomb interactions at two holes per moiré unit cell $v = 2$. Our analysis uncovers robust Quantum Valley Hall Insulating (QVHI) phase and reveals that long-range interactions alone can mediate the interlayer electron tunneling, generating topologically nontrivial bands even in the absence of the corresponding single-particle hopping. Additionally, we show that in the case of band mixing terms originating both from the interaction and single particle physics a competition between topological states realizing $s$-$wave$ and $p\\pm ip$-$wave$ symmetries can appear. Moreover, within the considered theoretical framework, we present that by introducing a small Zeeman field, one can lift the band inversion in one of the valleys. This leads to a Quantum Anomalous Hall Insulating (QAHI) state with the topological gap opening in a single valley and the other being topologically trivial.",
          "authors": [
            "Palash Saha",
            "Michał Zegrodnik"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02724",
          "title": "Sampling Permutations with Cell Probes is Hard",
          "abstract": "Suppose we are given an infinite sequence of input cells, each initialized with a uniform random symbol from $[n]$. How hard is it to output a sequence in $[n]^n$ that is close to a uniform random permutation? Viola (SICOMP 2020) conjectured that if each output cell is computed by making $d$ probes to input cells, then $d\\geq\\omega(1)$. Our main result shows that, in fact, $d\\geq (\\log n)^{\\Omega(1)}$, which is tight up to the constant in the exponent. Our techniques also show that if the probes are nonadaptive, then $d\\geq n^{\\Omega(1)}$, which is an exponential improvement over the previous nonadaptive lower bound due to Yu and Zhan (ITCS 2024). Our results also imply lower bounds against succinct data structures for storing permutations.",
          "authors": [
            "Yaroslav Alekseev",
            "Mika Göös",
            "Konstantin Myasnikov",
            "Artur Riazanov",
            "Dmitry Sokolov"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02725",
          "title": "Transcendence degrees over mutually generic extensions",
          "abstract": "Let $G_0$,..., $G_{n-1}$ be mutually generic over $V$, each $G_i$ adding at least one new real over $V$. We show that the transcendence degree of the reals of $V[G_0, \\dots, G_{n-1}]$ is maximal (of size continuum) over the field generated by reals coming from models $V[ G_i : i \\in a]$, for a proper subset $a$ of $n$. This answers a question of Fatalini and Schindler.",
          "authors": [
            "Jonathan Schilhan"
          ],
          "primary_category": "math.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02730",
          "title": "Invariance under Structure Translation as the Origin of Host Immune Capacity Conservation from Noether's Theorem",
          "abstract": "The capacity to resist pathogens is recognized as a fundamental property of the immune system, yet it remains a phenomenological concept and lacks a defined physical basis, leaving its fundamental entity, definition, and quantification unresolved. Here, we address these questions by introducing a theoretical framework based on Lagrangian analytical mechanics, which recasts immune recognition as a dynamical system in an immunological state space. Generalized coordinates are used to describe the conformational states of immune receptors, and their evolution is governed by Euler-Lagrange equations constructed from the antigen-receptor interaction. Central to our theory is the identification of a continuous symmetry: the action remains invariant under specific translations within the antigenic structure space. From this symmetry, Noether's theorem dictates a conserved quantity, I. We identify this conserved quantity as the physical embodiment of host immunity, a measurable quantity that encapsulates the system's protective capacity, encompassing both its breadth and intensity. This prediction is testable through statistically indistinguishable responses to antigen pairs related by the symmetry transformation. Furthermore, This theoretical model provides a unified framework for understanding key immunological phenomena, including vaccination, immune memory, tolerance, original antigenic sin, and T cell exhaustion. The conserved quantity I comprises a component quantifying protective breadth (with the dimension of action) and a component governing response intensity (with the dimension of energy), is thus established as a fundamental physical entity. This work transforms immune capacity from a phenomenological concept into a quantifiable entity, thereby establishing a foundational framework for predictive immunology and immunological intervention.",
          "authors": [
            "Yexing Chen",
            "Qingyun Wei",
            "Zhongxiang Dong",
            "Peng Cao"
          ],
          "primary_category": "physics.bio-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02732",
          "title": "Dynamic Modulation of Long Range Photon Magnon Coupling",
          "abstract": "Evidence of non-hermitian behavior has been recently demonstrated in cavity magnonics, including the emergence of mode level attraction and exceptional points in spectroscopic measurements. This work demonstrates experimental evidence of time-domain dynamics of magnon-photon systems that are coupled through a long-range interaction (i.e. remote coupling) exhibiting level attraction mediated by an auxiliary mode. We directly observe the temporal evolution of dissipatively coupled cavity-magnon modes, where heavily damped transmission line modes mediate the interaction. Our frequency-domain measurements confirm the predicted level attraction, while time-domain ring-down measurements reveal the characteristic signatures of dissipative coupling dynamics. Our approach offers in situ tunability over the dissipative coupling strength, including complete suppression, without requiring physical modifications to the experimental setup, providing a versatile platform for exploring tunable, non-Hermitian physics.",
          "authors": [
            "Alban Joseph",
            "Mawgan A. Smith",
            "Martin P. Weides",
            "Rair Macêdo"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02732",
          "title": "Dynamic Modulation of Long Range Photon Magnon Coupling",
          "abstract": "Evidence of non-hermitian behavior has been recently demonstrated in cavity magnonics, including the emergence of mode level attraction and exceptional points in spectroscopic measurements. This work demonstrates experimental evidence of time-domain dynamics of magnon-photon systems that are coupled through a long-range interaction (i.e. remote coupling) exhibiting level attraction mediated by an auxiliary mode. We directly observe the temporal evolution of dissipatively coupled cavity-magnon modes, where heavily damped transmission line modes mediate the interaction. Our frequency-domain measurements confirm the predicted level attraction, while time-domain ring-down measurements reveal the characteristic signatures of dissipative coupling dynamics. Our approach offers in situ tunability over the dissipative coupling strength, including complete suppression, without requiring physical modifications to the experimental setup, providing a versatile platform for exploring tunable, non-Hermitian physics.",
          "authors": [
            "Alban Joseph",
            "Mawgan A. Smith",
            "Martin P. Weides",
            "Rair Macêdo"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02734",
          "title": "Sum of Squares Decompositions for Structured Biquadratic Forms",
          "abstract": "This paper studies sum-of-squares (SOS) representations for structured biquadratic forms. We prove that diagonally dominated symmetric biquadratic tensors are always SOS. For the special case of symmetric biquadratic forms, we establish necessary and sufficient conditions for positive semi-definiteness of monic symmetric biquadratic forms, characterize the geometry of the corresponding psd cone, and prove that every such psd form is SOS. We also formulate conjectures regarding SOS representations for symmetric M-biquadratic tensors and symmetric B$_0$-biquadratic tensors, discussing their likelihood and potential proof strategies. Our results advance the understanding of when positive semi-definiteness implies sum-of-squares decompositions for structured biquadratic forms.",
          "authors": [
            "Yi Xu",
            "Chunfeng Cui",
            "Liqun Qi"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02739",
          "title": "Engineered mode coupling in high-Q microresonators enables deterministic low-repetition-rate soliton microcombs",
          "abstract": "Soliton optical frequency combs have become key enablers for a wide range of applications, including telecommunications, optical atomic clocks, ultrafast distance measurements, dual-comb spectroscopy, and astrophysical spectrometer calibration, many of which benefit from low repetition rates. However, achieving such low-repetition-rate soliton microcombs is nontrivial as long cavities require substantially higher pump power, which induces stronger thermal effects that, in turn, exacerbate thermal instability and complicate access to stable soliton states. The dual-mode pumping scheme, in which a continuous-wave pump couples to both the comb-generating mode and an auxiliary mode, has proven simple and effective for mitigating thermal instability and enabling thermally accessible soliton generation. Yet, in long-cavity devices, the standard bus-to-resonator coupling conditions for these two modes diverge substantially, resulting in insufficient pump coupling to the auxiliary mode, which makes dual-mode pumping particularly challenging for low-repetition-rate microcombs. In this work, we overcome this limitation by coupling the pump to the auxiliary mode via inter-modal coupling, which can be introduced in racetrack microresonators and engineered by tailoring the cavity bend design. We validate this approach in a high-Q (>$10^7$) silicon nitride microresonator and demonstrate thermally accessible, deterministic single-soliton generation at a repetition rate of 33 GHz. This work provides a simple and robust pathway for generating low-repetition-rate soliton microcombs.",
          "authors": [
            "Yi Zheng",
            "Yang Liu",
            "Haoyang Tan",
            "Yanjing Zhao",
            "Andreas Jacobsen",
            "Kresten Yvind",
            "Minhao Pu"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02741",
          "title": "Design and optimization of zone plates for flying focus applications",
          "abstract": "Flying focus laser pulse technology, characterized by programmable velocity profiles and the ability to break the traditional link between focal spot motion and group velocity constraints, holds significant potential for revolutionary advances in high-intensity laser related fields. However,the flying focus generated with conventional approaches suffers from a low maximum intensity, as the energy is spread over a long distance, and the size of the focusing optics is also limited. Here, we propose a zone-plate-based flying focus scheme in which the zone widths are modulated by a sinusoidal random distribution. Numerical simulations show that the high-order foci produced by the modulated zone plate can be suppressed by more than two orders of magnitude. Meanwhile, the scheme sustains a high-intensity focal region extending over more than 100 Rayleigh lengths. Furthermore, the focal speed can be tuned over a wide range, including values exceeding the speed of light in vacuum. Owing to these advantages, the proposed modulated zone-plate scheme offers new possibilities for high-intensity laser physics and holds promise for applications such as laser wakefield acceleration, photon acceleration, and more.",
          "authors": [
            "Zhengkun Li",
            "Yisong Zhou",
            "Changbo Fu",
            "Yugang Ma"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02742",
          "title": "Protein Diffusion and Stokes-Einstein Deviation in Supercooled Cryoprotectant Solutions",
          "abstract": "Vitrification during cryopreservation requires a detailed understanding of the dynamic behavior of biological solutions. We investigate ferritin diffusion in glycerol-water mixtures at supercooled temperatures using X-ray Photon Correlation Spectroscopy (XPCS). Diffusion coefficients were measured from ambient conditions to $T = 210$ K and analyzed using the Vogel-Fulcher-Tammann (VFT) relation, yielding an arrest temperature of $T_0 = 85 \\pm 11$ K for ferritin ($R_{\\rm h} = 7.3$ nm), markedly lower than $T_0 = 122 \\pm 4$ K for larger nanoparticles ($R_{\\rm h} = 50$ nm). Below $T \\approx 230$ K, ferritin diffusion exceeds the Stokes-Einstein prediction by up to a factor of 2.7, revealing nanoscale deviations from bulk viscosity. A fluctuating-friction model quantitatively links this enhancement to local friction heterogeneity, with fluctuations increasing upon cooling and reaching $\\sim 80\\%$ of the mean friction at $T=210$ K. These results establish a molecular-scale connection between protein diffusion and solvent dynamical heterogeneity in cryoprotected solutions.",
          "authors": [
            "Maddalena Bin",
            "Anita Girelli",
            "Mariia Filianina",
            "Mario Reiser",
            "Sharon Berkowicz",
            "Milla Åhlfeldt",
            "Michelle Dargasz",
            "Sonja Timmermann",
            "Jaqueline Savelkouls",
            "Takeshi Kawasaki",
            "Shinji Saito",
            "Federico Zontone",
            "Yuriy Chushkin",
            "Fajun Zhang",
            "Frank Schreiber",
            "Michael Paulus",
            "Christian Gutt",
            "Fivos Perakis"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02745",
          "title": "A Note on the Conditions for COS Convergence",
          "abstract": "We study the truncation error of the COS method and give simple, verifiable conditions that guarantee convergence. In one dimension, COS is admissible when the density belongs to both L1 and L2 and has a finite weighted L2 moment of order strictly greater than one. We extend the result to multiple dimensions by requiring the moment order to exceed the dimension. These conditions enlarge the class of densities covered by previous analyses and include heavy-tailed distributions such as Student t with small degrees of freedom.",
          "authors": [
            "Qinling Wang",
            "Xiaoyu Shen",
            "Fang Fang"
          ],
          "primary_category": "q-fin.CP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02745",
          "title": "A Note on the Conditions for COS Convergence",
          "abstract": "We study the truncation error of the COS method and give simple, verifiable conditions that guarantee convergence. In one dimension, COS is admissible when the density belongs to both L1 and L2 and has a finite weighted L2 moment of order strictly greater than one. We extend the result to multiple dimensions by requiring the moment order to exceed the dimension. These conditions enlarge the class of densities covered by previous analyses and include heavy-tailed distributions such as Student t with small degrees of freedom.",
          "authors": [
            "Qinling Wang",
            "Xiaoyu Shen",
            "Fang Fang"
          ],
          "primary_category": "q-fin.CP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02745",
          "title": "A Note on the Conditions for COS Convergence",
          "abstract": "We study the truncation error of the COS method and give simple, verifiable conditions that guarantee convergence. In one dimension, COS is admissible when the density belongs to both L1 and L2 and has a finite weighted L2 moment of order strictly greater than one. We extend the result to multiple dimensions by requiring the moment order to exceed the dimension. These conditions enlarge the class of densities covered by previous analyses and include heavy-tailed distributions such as Student t with small degrees of freedom.",
          "authors": [
            "Qinling Wang",
            "Xiaoyu Shen",
            "Fang Fang"
          ],
          "primary_category": "q-fin.CP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02746",
          "title": "Interplay of phonons, intertwined density waves, and induced spin density wave in trilayer nickelates Pr4-xLaxNi3O10",
          "abstract": "Lattice degrees of freedom (DoF) play a central role in correlated electron systems, strongly influencing the dynamics of the underlying charge carriers and spin excitations. In nickelates, understanding the role of lattice is essential to unravel the interplay between charge, orbital, and spin degree of freedom in giving rise to various emergent phenomena reported recently. Here, we investigate the phononic DoF in a series of trilayer nickelates, namely Pr4-xLaxNi3O10 (where x = 0, 0.4, 1, 2, 3.6, and 4) using temperature and polarization dependent Raman scattering measurements. Our in-depth analysis of the phonon evolution with temperature and doping, gives interesting insights into the behaviour of these materials. All these systems undergo a metal-to-metal transition (TMMT), characterized by the development of intertwined spin and charge density waves, with the spin density wave preceding the charge density wave. These transitions manifest as pronounced anomalies in phonon self-energy parameters i.e. peak frequency and linewidth in the vicinity of the metal-to-metal transition. Several phonon modes show dramatic change (nearly an order of magnitude for some modes) in their softening rates across the TMMT, highlighting the sensitivity of the lattice dynamics to spin and charge order. These findings emphasize the crucial role of lattice DoF in mediating correlated ground states in layered nickelates.",
          "authors": [
            "Sonia Deswal",
            "Dibyata Rout",
            "Nirmalya Jana",
            "Koushik Pal",
            "Surjeet Singh",
            "Pradeep Kumar"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02747",
          "title": "Digit-Indexed q-ary SEC-DED Codes with Near-Hamming Overhead",
          "abstract": "We present a simple $q$-ary family of single-error-correcting, double-error-detecting (SEC--DED) linear codes whose parity checks are tied directly to the base-$p$ ($q=p$ prime) digits of the coordinate index. For blocklength $n=p^r$ the construction uses only $r+1$ parity checks -- \\emph{near-Hamming} overhead -- and admits an index-based decoder that runs in a single pass with constant-time location and magnitude recovery from the syndromes. Based on the prototype, we develop two extensions: Code A1, which removes specific redundant trits to achieve higher information rate and support variable-length encoding; and Code A2, which incorporates two group-sum checks together with a 3-wise XOR linear independence condition on index subsets, yielding a ternary distance-4 (SEC--TED) variant. Furthermore, we demonstrate how the framework generalizes via $n$-wise XOR linearly independent sets to construct codes with distance $d = n + 1$, notably recovering the ternary Golay code for $n = 5$ -- showing both structural generality and a serendipitous link to optimal classical codes. Our contribution is not optimality but \\emph{implementational simplicity} and an \\emph{array-friendly} structure: the checks are digitwise and global sums, the mapping from syndromes to error location is explicit, and the SEC--TED upgrade is modular. We position the scheme against classical $q$-ary Hamming and SPC/product-code baselines and provide a small comparison of parity overhead, decoding work, and two-error behavior.",
          "authors": [
            "Jiaxu Hu",
            "Kenneth J. Roche"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02747",
          "title": "Digit-Indexed q-ary SEC-DED Codes with Near-Hamming Overhead",
          "abstract": "We present a simple $q$-ary family of single-error-correcting, double-error-detecting (SEC--DED) linear codes whose parity checks are tied directly to the base-$p$ ($q=p$ prime) digits of the coordinate index. For blocklength $n=p^r$ the construction uses only $r+1$ parity checks -- \\emph{near-Hamming} overhead -- and admits an index-based decoder that runs in a single pass with constant-time location and magnitude recovery from the syndromes. Based on the prototype, we develop two extensions: Code A1, which removes specific redundant trits to achieve higher information rate and support variable-length encoding; and Code A2, which incorporates two group-sum checks together with a 3-wise XOR linear independence condition on index subsets, yielding a ternary distance-4 (SEC--TED) variant. Furthermore, we demonstrate how the framework generalizes via $n$-wise XOR linearly independent sets to construct codes with distance $d = n + 1$, notably recovering the ternary Golay code for $n = 5$ -- showing both structural generality and a serendipitous link to optimal classical codes. Our contribution is not optimality but \\emph{implementational simplicity} and an \\emph{array-friendly} structure: the checks are digitwise and global sums, the mapping from syndromes to error location is explicit, and the SEC--TED upgrade is modular. We position the scheme against classical $q$-ary Hamming and SPC/product-code baselines and provide a small comparison of parity overhead, decoding work, and two-error behavior.",
          "authors": [
            "Jiaxu Hu",
            "Kenneth J. Roche"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02749",
          "title": "Minimal decomposition entropy and optimal representations of absolutely maximally entangled states",
          "abstract": "Understanding and classifying multipartite entanglement is fundamental to quantum information processing. A useful measure of multipartite entanglement is the minimal decomposition entropy, defined as the minimum of the Rényi entropy $ S_q $ associated with the state's decomposition over all local product bases. This quantity identifies the product bases in which the state is maximally localized, thereby yielding optimal representations for analyzing local-unitary equivalence and structural properties of multipartite states. We investigate the minimal decomposition entropy for absolutely maximally entangled (AME) states, a class of highly entangled states characterized by their maximal entanglement across any bipartitions. We present a numerical algorithm for computing the minimal decomposition entropy for finite $ q>1 $. Entropy distributions for AME and Haar random states are obtained for $ q=2 $ and $ q=\\infty $ in qubit, qutrit, and ququad systems. For $ q=2 $, AME states of four qutrits and four ququads exhibit smaller minimal decomposition entropy than Haar random states, indicating more localized optimal representations. For $ q=\\infty $, corresponding to the geometric measure of entanglement, AME states display higher entanglement than Haar random states. The algorithm additionally produces simpler and sparser decompositions of known AME states, aiding in distinguishing genuinely quantum AME states from those associated with classical combinatorial designs.",
          "authors": [
            "N Ramadas"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02752",
          "title": "Phase-sensitive non-reciprocal transport in high-temperature superconductor",
          "abstract": "We propose the superconducting diode effect (SDE) in a planar s-wave/d-wave/s-wave Josephson junction as a direct phase-sensitive probe of the d-wave pairing function in high-Tc superconductors. Asymmetric interface coupling breaks inversion symmetry and induces a spontaneous Pi/2 phase difference, thereby breaking time-reversal symmetry without a magnetic field. In this TRS-broken state, the SDE emerges when single-Cooper-pair tunneling is enabled at the s-d interfaces, with its polarity and efficiency controllable by rotating the d-wave crystallographic orientation or perturbing its intrinsic C4 symmetry. Our results reveal a robust link between nonreciprocal Josephson transport and pairing symmetry, establishing the SDE as a powerful diagnostic tool for high-Tc superconductors and a tunable element for superconducting electronics.",
          "authors": [
            "Guo-Liang Guo",
            "Xin Liu"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02753",
          "title": "Observation of non-Hermitian many-body phase transition in a Rydberg-atom array",
          "abstract": "Non-Hermitian quantum mechanics with parity-time (PT) symmetry offers a powerful framework for exploring the complex interplay of dissipation and coherent interactions in open quantum systems. While PT-symmetry breaking has been studied in various physical systems, its observation on a quantum many-body level remains elusive. Here, we experimentally realize a non-Hermitian XY model in a strongly-interacting Rydberg-atom array. By measuring the Loschmidt Echo of a fully polarized state, we observe distinct dynamical signatures of a PT-symmetry-breaking phase transition. Dipole interactions are found to play a crucial role, not only determining the transition point but also triggering a non-Hermitian many-body blockade effect that protects the Loschmidt Echo from decay with a non-monotonic dependence on the system size. Our results reveal intricate interaction-induced effects on PT-symmetry breaking and open the door for exploring non-Hermitian many-body dynamics beyond single-particle and mean-field paradigms.",
          "authors": [
            "Yao-Wen Zhang",
            "Biao Xu",
            "Yijia Zhou",
            "De-Sheng Xiang",
            "Hao-Xiang Liu",
            "Peng Zhou",
            "Kuan Zhang",
            "Ren Liao",
            "Thomas Pohl",
            "Weibin Li",
            "Lin Li"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02753",
          "title": "Observation of non-Hermitian many-body phase transition in a Rydberg-atom array",
          "abstract": "Non-Hermitian quantum mechanics with parity-time (PT) symmetry offers a powerful framework for exploring the complex interplay of dissipation and coherent interactions in open quantum systems. While PT-symmetry breaking has been studied in various physical systems, its observation on a quantum many-body level remains elusive. Here, we experimentally realize a non-Hermitian XY model in a strongly-interacting Rydberg-atom array. By measuring the Loschmidt Echo of a fully polarized state, we observe distinct dynamical signatures of a PT-symmetry-breaking phase transition. Dipole interactions are found to play a crucial role, not only determining the transition point but also triggering a non-Hermitian many-body blockade effect that protects the Loschmidt Echo from decay with a non-monotonic dependence on the system size. Our results reveal intricate interaction-induced effects on PT-symmetry breaking and open the door for exploring non-Hermitian many-body dynamics beyond single-particle and mean-field paradigms.",
          "authors": [
            "Yao-Wen Zhang",
            "Biao Xu",
            "Yijia Zhou",
            "De-Sheng Xiang",
            "Hao-Xiang Liu",
            "Peng Zhou",
            "Kuan Zhang",
            "Ren Liao",
            "Thomas Pohl",
            "Weibin Li",
            "Lin Li"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02754",
          "title": "Ultrasensitive Anti-Stokes Luminescence Thermometry in Transition Metal Dichalcogenide Monolayers",
          "abstract": "Accurate temperature mapping at the nanoscale is a critical challenge in modern science and technology, as conventional methods fail at these dimensions. To address this challenge, we demonstrate a highly sensitive nanothermometer using anti-Stokes photoluminescence, also known as photoluminescence upconversion (UPL), in monolayer tungsten disulfide ($\\mathrm{WS_2}$). Leveraging the direct band gap and strong exciton-phonon coupling in the two-dimensional monolayers, we achieve an exceptional relative sensitivity above $4\\%\\,\\mathrm{K}^{-1}$ across the 300 K to 425 K range, ranking it among the best-performing materials reported. A strong resonantly enhanced UPL is observed, confirming the central role of optical phonons in the upconversion mechanism. Furthermore, we introduce a new analytical model to quantitatively describe the UPL process, taking into account the interplay of phonon populations, bandgap narrowing, and substrate effects, which predicts resonant temperatures and provides a framework with broad applicability to any material exhibiting an anti-Stokes photoluminescence response. To demonstrate its use as a high-resolution optical thermometer, we map a $20\\,^{\\circ}\\mathrm{C}$ thermal gradient across a $20\\,\\mu\\mathrm{m}$ long monolayer with a spatial resolution of $1\\,\\mu\\mathrm{m}$. With its high sensitivity, strong signal, and excellent reproducibility, our work establishes monolayer transition metal dichalcogenide as a leading platform for non-invasive thermal sensing in advanced microelectronic and biological systems.",
          "authors": [
            "Sharada Nagarkar",
            "Fahrettin Sarcan",
            "Elanur Hut",
            "Emiliano R. Martins",
            "Stuart A Cavill",
            "Thomas F. Krauss",
            "Yue Wang"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02754",
          "title": "Ultrasensitive Anti-Stokes Luminescence Thermometry in Transition Metal Dichalcogenide Monolayers",
          "abstract": "Accurate temperature mapping at the nanoscale is a critical challenge in modern science and technology, as conventional methods fail at these dimensions. To address this challenge, we demonstrate a highly sensitive nanothermometer using anti-Stokes photoluminescence, also known as photoluminescence upconversion (UPL), in monolayer tungsten disulfide ($\\mathrm{WS_2}$). Leveraging the direct band gap and strong exciton-phonon coupling in the two-dimensional monolayers, we achieve an exceptional relative sensitivity above $4\\%\\,\\mathrm{K}^{-1}$ across the 300 K to 425 K range, ranking it among the best-performing materials reported. A strong resonantly enhanced UPL is observed, confirming the central role of optical phonons in the upconversion mechanism. Furthermore, we introduce a new analytical model to quantitatively describe the UPL process, taking into account the interplay of phonon populations, bandgap narrowing, and substrate effects, which predicts resonant temperatures and provides a framework with broad applicability to any material exhibiting an anti-Stokes photoluminescence response. To demonstrate its use as a high-resolution optical thermometer, we map a $20\\,^{\\circ}\\mathrm{C}$ thermal gradient across a $20\\,\\mu\\mathrm{m}$ long monolayer with a spatial resolution of $1\\,\\mu\\mathrm{m}$. With its high sensitivity, strong signal, and excellent reproducibility, our work establishes monolayer transition metal dichalcogenide as a leading platform for non-invasive thermal sensing in advanced microelectronic and biological systems.",
          "authors": [
            "Sharada Nagarkar",
            "Fahrettin Sarcan",
            "Elanur Hut",
            "Emiliano R. Martins",
            "Stuart A Cavill",
            "Thomas F. Krauss",
            "Yue Wang"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02755",
          "title": "Reaching Sachdev-Ye-Kitaev physics by shaking the Hubbard model",
          "abstract": "The Sachdev-Ye-Kitaev (SYK) model has attracted widespread attention due to its relevance to diverse areas of physics, such as high temperature superconductivity, black holes, and quantum chaos. The model is, however, extremely challenging to realize experimentally. In this work, we show how a particular form of Floquet engineering, termed ``kinetic driving'', effectively eliminates single-particle processes and creates quasi-random all-to-all interactions when applied to models of Hubbard type. For the specific case of the Bose-Hubbard model, we explicitly verify that the driven system indeed reproduces SYK physics by direct comparison of the spectral form factor and out-of-time ordered correlation functions (OTOCs). Our findings indicate that a cold-atom realization of kinetic driving -- achieved through modulation of hopping amplitudes in an optical lattice -- offers a practical and accurate platform for quantum simulation of the SYK model.",
          "authors": [
            "Charles Creffield",
            "Fernando Sols",
            "Marco Schirò",
            "Nathan Goldman"
          ],
          "primary_category": "cond-mat.quant-gas",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02755",
          "title": "Reaching Sachdev-Ye-Kitaev physics by shaking the Hubbard model",
          "abstract": "The Sachdev-Ye-Kitaev (SYK) model has attracted widespread attention due to its relevance to diverse areas of physics, such as high temperature superconductivity, black holes, and quantum chaos. The model is, however, extremely challenging to realize experimentally. In this work, we show how a particular form of Floquet engineering, termed ``kinetic driving'', effectively eliminates single-particle processes and creates quasi-random all-to-all interactions when applied to models of Hubbard type. For the specific case of the Bose-Hubbard model, we explicitly verify that the driven system indeed reproduces SYK physics by direct comparison of the spectral form factor and out-of-time ordered correlation functions (OTOCs). Our findings indicate that a cold-atom realization of kinetic driving -- achieved through modulation of hopping amplitudes in an optical lattice -- offers a practical and accurate platform for quantum simulation of the SYK model.",
          "authors": [
            "Charles Creffield",
            "Fernando Sols",
            "Marco Schirò",
            "Nathan Goldman"
          ],
          "primary_category": "cond-mat.quant-gas",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02756",
          "title": "X-ray photon correlation spectroscopy of hydrated lysozyme at elevated pressures",
          "abstract": "Pressure provides a powerful parameter to control the protein conformation state, which at sufficiently high values can lead to unfolding. Here, we investigate the effects of increasing pressure up to $0.4$ GPa on hydrated lysozyme proteins, by measuring the nanoscale stress relaxation induced and probed by X-rays. Structural and dynamical information at elevated pressures was obtained using X-ray photon correlation spectroscopy (XPCS) in combination with a diamond anvil cell (DAC). The dynamical analysis revealed a slowing down of the system up to $0.2$ GPa, followed by a re-acceleration at $0.4$ GPa. A similar non-monotonic behavior was observed both in the Porod and Kohlrausch-Williams-Watts (KWW) exponents, consistently indicating a crossover between $0.2$ and $0.4$ GPa. These findings suggest the presence of pressure-induced structural changes that impact protein collective stress-relaxation as the system transitions from a jammed state to an elastically driven regime. These results may be relevant for a deeper understanding of protein stability under compression as well as for practical high-pressure technologies, including food processing and pharmaceutical applications.",
          "authors": [
            "Milla Åhlfeldt",
            "Maddalena Bin",
            "Anita Girelli",
            "Iason Andronis",
            "Aigerim Karina",
            "Nimmi Das Anthuparambil",
            "Fiona Berner",
            "Tobias Eklund",
            "Louisa E. Kraft",
            "Aliaksandr Leonau",
            "Fabian Westermeier",
            "Michael Sprung",
            "Christian Gutt",
            "Katrin Amann-Winkel",
            "Fivos Perakis"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02758",
          "title": "The Support of Bin Packing is Exponential",
          "abstract": "Consider the classical Bin Packing problem with $d$ different item sizes $s_i$ and amounts of items $a_i.$ The support of a Bin Packing solution is the number of differently filled bins. In this work, we show that the lower bound on the support of this problem is $2^{\\Omega(d)}$. Our lower bound matches the upper bound of $2^d$ given by Eisenbrand and Shmonin [ this http URL Letters '06] up to a constant factor. This result has direct implications for the time complexity of several Bin Packing algorithms, such as Goemans and Rothvoss [SODA '14], Jansen and Klein [SODA '17] and Jansen and Solis-Oba [IPCO '10]. To achieve our main result, we develop a technique to aggregate equality constrained ILPs with many constraints into an equivalent ILP with one constraint. Our technique contrasts existing aggregation techniques as we manage to integrate upper bounds on variables into the resulting constraint. We believe this technique can be useful for solving general ILPs or the $d$-dimensional knapsack problem.",
          "authors": [
            "Klaus Jansen",
            "Lis Pirotton",
            "Malte Tutas"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02760",
          "title": "Fault-tolerant quantum computation with constant overhead for general noise",
          "abstract": "Fault-tolerant quantum computation traditionally incurs substantial resource overhead, with both qubit and time overheads scaling polylogarithmically with the size of the computation. While prior work by Gottesman showed that constant qubit overhead is achievable under stochastic noise using quantum low-density parity-check (QLDPC) codes, it has remained an open question whether similar guarantees hold under more general, non-stochastic noise models. In this work, we address this question by considering a general circuit-level noise model defined via the diamond norm, which captures both stochastic and non-stochastic noise, including coherent and amplitude damping noise. We prove that constant qubit overhead fault-tolerant quantum computation is achievable in this general setting, using QLDPC codes with constant rate and linear minimum distance. To establish our result, we develop a fault-tolerant error correction scheme and a method for implementing logic gates under general circuit noise. These results extend the theoretical foundations of fault-tolerant quantum computation and offer new directions for fault-tolerant architectures under realistic noise models.",
          "authors": [
            "Matthias Christandl",
            "Omar Fawzi",
            "Ashutosh Goswami"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02761",
          "title": "On local Liakopoulos-Meyer type inequalities and their functional counterparts",
          "abstract": "We provide a functional Rogers-Shephard type inequality for log-concave functions on $\\mathbb R^n$ and any $1$-reducible $s$-cover of $[n]$. As a consequence, we derive a sharp local Liakopoulos-Meyer type inequality for $n$-dimensional convex bodies and $1$-reducible $s$-covers of any $\\sigma\\subset[n]$, solving a question studied by Brazitikos, Giannopoulos, Liakopoulos in [14] as well as Alonso-Gutiérrez, Bernués, Brazitikos, Carbery in [3].",
          "authors": [
            "Luis J. Alías",
            "Bernardo González Merino",
            "Beatriz Marín Gimeno"
          ],
          "primary_category": "math.MG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02762",
          "title": "Topological Pseudospin Hall Effect and Multi-frequency Corner Modes in Kagome-based Lattices",
          "abstract": "Topological phases and modes, including pseudospin-Hall-selective edge transport and corner states, provide robust control of wave propagation and modal confinement in classical wave platforms. Under a tight-binding framework, we theoretically investigate two lattice designs derived from the kagome lattice. These extended kagome lattices support a series of localized modes, including pseudospin-Hall-like topological edge states and corner modes in different bandgaps and frequencies, which were not only achieved under lower lattice symmetries than Wu-Hu lattices, but also enable more degrees of freedom in topological and localized modes. By introducing two types of extended kagome lattices with different topological properties, multiple interesting phenomena, including newly emerged multiple groups of corner states, parametric tunable pseudospin Hall effect, and type-II corner states without long-range interactions, are found in theoretical models, which are possible and viable to achieve in artificial classical systems such as photonic, acoustic, or electrical circuits.",
          "authors": [
            "Shenglong Guo",
            "Qinhui Jiang",
            "Yuma Kawaguchi",
            "Bo Li",
            "Mengyao Li"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02762",
          "title": "Topological Pseudospin Hall Effect and Multi-frequency Corner Modes in Kagome-based Lattices",
          "abstract": "Topological phases and modes, including pseudospin-Hall-selective edge transport and corner states, provide robust control of wave propagation and modal confinement in classical wave platforms. Under a tight-binding framework, we theoretically investigate two lattice designs derived from the kagome lattice. These extended kagome lattices support a series of localized modes, including pseudospin-Hall-like topological edge states and corner modes in different bandgaps and frequencies, which were not only achieved under lower lattice symmetries than Wu-Hu lattices, but also enable more degrees of freedom in topological and localized modes. By introducing two types of extended kagome lattices with different topological properties, multiple interesting phenomena, including newly emerged multiple groups of corner states, parametric tunable pseudospin Hall effect, and type-II corner states without long-range interactions, are found in theoretical models, which are possible and viable to achieve in artificial classical systems such as photonic, acoustic, or electrical circuits.",
          "authors": [
            "Shenglong Guo",
            "Qinhui Jiang",
            "Yuma Kawaguchi",
            "Bo Li",
            "Mengyao Li"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02766",
          "title": "Fine-Graining and Continuous Space Scaling Limit of the $H^{2|2}$ Model on the Hierarchical Lattice",
          "abstract": "We extend the exact coarse-graining result of Disertori, Merkl and Rolles~\\cite{MR4517733} for the random field of $H^{2|2}$-model to the random Schrödinger operator representation of the $H^{2|2}$-model. We also introduce a fine-graining procedure as the reverse operation, and establish an associated exponential martingale property. Applying this fine-graining procedure to the $H^{2|2}$-model on the Dyson hierarchical lattice, we establish its continuous space scaling limit as a non-trivial random measure on $[0,1]$. This random measure is almost surely singular with respect to the Lebesgue measure if and only if the Vertex Reinforced Jump Process on the Dyson hierarchical lattice is recurrent. If the process is transient, the random measure almost surely has an absolutely continuous component. The density of this component is everywhere non-trivial and can be identified with the pointwise limit of an exponential martingale associated with the $H^{2|2}$-model on the Dyson hierarchical lattice.",
          "authors": [
            "Yichao Huang",
            "Jinglin Wang",
            "Xiaolin Zeng"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02766",
          "title": "Fine-Graining and Continuous Space Scaling Limit of the $H^{2|2}$ Model on the Hierarchical Lattice",
          "abstract": "We extend the exact coarse-graining result of Disertori, Merkl and Rolles~\\cite{MR4517733} for the random field of $H^{2|2}$-model to the random Schrödinger operator representation of the $H^{2|2}$-model. We also introduce a fine-graining procedure as the reverse operation, and establish an associated exponential martingale property. Applying this fine-graining procedure to the $H^{2|2}$-model on the Dyson hierarchical lattice, we establish its continuous space scaling limit as a non-trivial random measure on $[0,1]$. This random measure is almost surely singular with respect to the Lebesgue measure if and only if the Vertex Reinforced Jump Process on the Dyson hierarchical lattice is recurrent. If the process is transient, the random measure almost surely has an absolutely continuous component. The density of this component is everywhere non-trivial and can be identified with the pointwise limit of an exponential martingale associated with the $H^{2|2}$-model on the Dyson hierarchical lattice.",
          "authors": [
            "Yichao Huang",
            "Jinglin Wang",
            "Xiaolin Zeng"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02767",
          "title": "Structural Properties of Entropic Vectors and Stability of the Ingleton Inequality",
          "abstract": "We study constrained versions of the Ingleton inequality in the entropic setting and quantify its stability under small violations of conditional independence. Although the classical Ingleton inequality fails for general entropy profiles, it is known to hold under certain exact independence constraints. We focus on the regime where selected conditional mutual information terms are small (but not zero), and the inequality continues to hold up to controlled error terms. A central technical tool is a structural lemma that materializes part of the mutual information between two random variables, implicitly capturing the effect of infinitely many non-Shannon--type inequalities. This leads to conceptually transparent proofs without explicitly invoking such infinite families. Some of our bounds recover, in a unified way, what can also be deduced from the infinite families of inequalities of Matúš (2007) and of Dougherty--Freiling--Zeger (2011), while others appear to be new.",
          "authors": [
            "Rostislav Matveev",
            "Andrei Romashchenko"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02767",
          "title": "Structural Properties of Entropic Vectors and Stability of the Ingleton Inequality",
          "abstract": "We study constrained versions of the Ingleton inequality in the entropic setting and quantify its stability under small violations of conditional independence. Although the classical Ingleton inequality fails for general entropy profiles, it is known to hold under certain exact independence constraints. We focus on the regime where selected conditional mutual information terms are small (but not zero), and the inequality continues to hold up to controlled error terms. A central technical tool is a structural lemma that materializes part of the mutual information between two random variables, implicitly capturing the effect of infinitely many non-Shannon--type inequalities. This leads to conceptually transparent proofs without explicitly invoking such infinite families. Some of our bounds recover, in a unified way, what can also be deduced from the infinite families of inequalities of Matúš (2007) and of Dougherty--Freiling--Zeger (2011), while others appear to be new.",
          "authors": [
            "Rostislav Matveev",
            "Andrei Romashchenko"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02770",
          "title": "An efficient fully decoupled finite element method with second-order accuracy for the micropolar Rayleigh-Benard convection system",
          "abstract": "The micropolar Rayleigh-B{é}nard convection system, which consists of Navier-Stokes equations, the angular momentum equation, and the heat equation, is a strongly nonlinear, coupled, and saddle point structural multiphysics system. A second-order pressure projection finite element method, which is linear, fully decoupled, and second-order accurate in time, is proposed to simulate the system. Only a few decoupled linear elliptic problems with constant coefficients are solved at each time step, simplifying calculations significantly. The stability analysis of the method is established and the optimal error estimates are derived rigorously with the negative norm technique. Extensive numerical simulations, including 2D and 3D accuracy tests, the lid-driven cavity flow, and the passive-scalar mixing experiment, are carried out to illustrate the effectiveness of the method.",
          "authors": [
            "Ming Cui",
            "Akang Hou",
            "Xiaoyu Dong"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02770",
          "title": "An efficient fully decoupled finite element method with second-order accuracy for the micropolar Rayleigh-Benard convection system",
          "abstract": "The micropolar Rayleigh-B{é}nard convection system, which consists of Navier-Stokes equations, the angular momentum equation, and the heat equation, is a strongly nonlinear, coupled, and saddle point structural multiphysics system. A second-order pressure projection finite element method, which is linear, fully decoupled, and second-order accurate in time, is proposed to simulate the system. Only a few decoupled linear elliptic problems with constant coefficients are solved at each time step, simplifying calculations significantly. The stability analysis of the method is established and the optimal error estimates are derived rigorously with the negative norm technique. Extensive numerical simulations, including 2D and 3D accuracy tests, the lid-driven cavity flow, and the passive-scalar mixing experiment, are carried out to illustrate the effectiveness of the method.",
          "authors": [
            "Ming Cui",
            "Akang Hou",
            "Xiaoyu Dong"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02775",
          "title": "Intrinsic Second-Order Topological Superconductors with Tunable Majorana Zero Modes",
          "abstract": "Dirac semimetals, with their protected Dirac points, present an ideal platform for realizing intrinsic topological superconductivity. In this work, we investigate superconductivity in a two-dimensional, square-lattice nonsymmorphic Dirac semimetal. In the normal state near half-filling, the Fermi surface consists of two distinct pockets, each enclosing a Dirac point at a time-reversal invariant momentum ($\\textbf{X}=(\\pi,0)$ and $\\textbf{Y}=(0,\\pi)$). Considering an on-site repulsive and nearest-neighbor attractive interaction, we use self-consistent mean-field theory to determine the ground-state pairing symmetry. We find that an even-parity, spin-singlet $d_{x^{2}-y^{2}}$-wave pairing is favored as it gives rise to a fully gapped superconducting state. Since the pairing amplitude has opposite signs on the two Dirac Fermi pockets, the superconducting state is identified as a second-order topological superconductor. The hallmark of this topological phase is the emergence of Majorana zero modes at the system's boundaries. Notably, the positions of these Majorana modes are highly controllable and can be manipulated simply by tailoring the boundary sublattice terminations. Our results highlight the promise of nonsymmorphic Dirac semimetals for realizing and manipulating Majorana modes.",
          "authors": [
            "Xiao-Jiao Wang",
            "Yijie Mo",
            "Zhi Wang",
            "Zhigang Wu",
            "Zhongbo Yan"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02775",
          "title": "Intrinsic Second-Order Topological Superconductors with Tunable Majorana Zero Modes",
          "abstract": "Dirac semimetals, with their protected Dirac points, present an ideal platform for realizing intrinsic topological superconductivity. In this work, we investigate superconductivity in a two-dimensional, square-lattice nonsymmorphic Dirac semimetal. In the normal state near half-filling, the Fermi surface consists of two distinct pockets, each enclosing a Dirac point at a time-reversal invariant momentum ($\\textbf{X}=(\\pi,0)$ and $\\textbf{Y}=(0,\\pi)$). Considering an on-site repulsive and nearest-neighbor attractive interaction, we use self-consistent mean-field theory to determine the ground-state pairing symmetry. We find that an even-parity, spin-singlet $d_{x^{2}-y^{2}}$-wave pairing is favored as it gives rise to a fully gapped superconducting state. Since the pairing amplitude has opposite signs on the two Dirac Fermi pockets, the superconducting state is identified as a second-order topological superconductor. The hallmark of this topological phase is the emergence of Majorana zero modes at the system's boundaries. Notably, the positions of these Majorana modes are highly controllable and can be manipulated simply by tailoring the boundary sublattice terminations. Our results highlight the promise of nonsymmorphic Dirac semimetals for realizing and manipulating Majorana modes.",
          "authors": [
            "Xiao-Jiao Wang",
            "Yijie Mo",
            "Zhi Wang",
            "Zhigang Wu",
            "Zhongbo Yan"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02776",
          "title": "Enhanced particle diffusion in fluctuating binary environments",
          "abstract": "We investigate single-particle diffusion in a two-state Langevin model where the friction coefficient randomly switches between low-friction (liquid-like) and high-friction (glassy-like) states. The dynamics are governed by the ratio between the friction switching time $\\tau$ and the intrinsic velocity relaxation time $\\tau_0$. For fast switching ($\\tau/\\tau_0 \\lesssim 1$) the motion is homogeneous and Brownian, whereas for slow switching ($\\tau/\\tau_0 \\gg 1$) the particle exhibits intermittent dynamics and an enhanced diffusion coefficient. Analysis of the single-particle overlap function $Q(t)$ and the dynamic susceptibility $\\chi_4(t)$ reveals decoupling of the diffusion coefficient from the average friction upon cooling, which coincides with increasing temporal dynamic heterogeneity. This minimal model provides a transparent framework for understanding single-particle transport in media with fluctuating local mobility, including supercooled liquids and phase-separated soft materials.",
          "authors": [
            "Fivos Perakis",
            "Takeshi Kawasaki",
            "Shinji Saito"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02776",
          "title": "Enhanced particle diffusion in fluctuating binary environments",
          "abstract": "We investigate single-particle diffusion in a two-state Langevin model where the friction coefficient randomly switches between low-friction (liquid-like) and high-friction (glassy-like) states. The dynamics are governed by the ratio between the friction switching time $\\tau$ and the intrinsic velocity relaxation time $\\tau_0$. For fast switching ($\\tau/\\tau_0 \\lesssim 1$) the motion is homogeneous and Brownian, whereas for slow switching ($\\tau/\\tau_0 \\gg 1$) the particle exhibits intermittent dynamics and an enhanced diffusion coefficient. Analysis of the single-particle overlap function $Q(t)$ and the dynamic susceptibility $\\chi_4(t)$ reveals decoupling of the diffusion coefficient from the average friction upon cooling, which coincides with increasing temporal dynamic heterogeneity. This minimal model provides a transparent framework for understanding single-particle transport in media with fluctuating local mobility, including supercooled liquids and phase-separated soft materials.",
          "authors": [
            "Fivos Perakis",
            "Takeshi Kawasaki",
            "Shinji Saito"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02778",
          "title": "Realization of polytype heterostructures via delicate structural transitions from a doped-Mott insulator",
          "abstract": "Transition metal dichalcogenides (TMDs) host multiple competing structural and electronic phases, making them an ideal platform for constructing polytype heterostructures with emergent quantum properties. However, controlling phase transitions to form diverse heterostructures inside a single crystal remains challenging. Here, we realize vertical/lateral polytype heterostructures in a hole-doped Mott insulator via thermal-annealing-induced structural transitions. Raman spectroscopy, atomic force microscopy (AFM) and scanning Kelvin probe force microscopy (SKPM) confirm the coexistence of T-H polytype heterostructures. Atomic-scale scanning tunneling microscopy/spectroscopy (STM/STS) measurements reveal the transparent effect in 1H/1T vertical heterostructures, where the charge density wave (CDW) of the underlying 1T-layer superposes on the top 1H-layer under positive bias. By systematically comparing 1T/1H and 1T/1T interfaces, we demonstrate that the metallic 1H-layer imposes a Coulomb screening effect on the 1T-layer, suppressing the formation of CDW domain walls and forming more ordered electronic states. These results clarify the interfacial coupling between distinct quantum many-body phases and establish a controllable pathway for constructing two-dimensional polytype heterostructures with tunable electronic properties.",
          "authors": [
            "Yanyan Geng",
            "Manyu Wang",
            "Shumin Meng",
            "Shuo Mi",
            "Chang Li",
            "Huiji Hu",
            "Jianfeng Guo",
            "Rui Xu",
            "Fei Pang",
            "Wei Ji",
            "Weichang Zhou",
            "Zhihai Cheng"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02779",
          "title": "Devil's Games and $\\text{Q}\\mathbb{R}$: Continuous Games complete for the First-Order Theory of the Reals",
          "abstract": "We introduce the complexity class Quantified Reals ($\\text{Q}\\mathbb{R}$). Let FOTR be the set of true sentences in the first-order theory of the reals. A language $L$ is in $\\text{Q}\\mathbb{R}$, if there is a polynomial time reduction from $L$ to FOTR. This seems the first time this complexity class is studied. We show that $\\text{Q}\\mathbb{R}$ can also be defined using real Turing machines. It is known that deciding FOTR requires at least exponential time unconditionally [Berman, 1980]. We focus on devil's games with two defining properties: (1) Players (human and devil) alternate turns and (2) each turn has a continuum of options. First, we show that FOTRINV is $\\text{Q}\\mathbb{R}$-complete. FOTRINV has only inversion and addition constraints and all variables are in a compact interval. FOTRINV is a stepping stone for further reductions. Second, we show that the Packing Game is $\\text{Q}\\mathbb{R}$-complete. In the Packing Game we are given a container and two sets of pieces. One set of pieces for the human and one set for the devil. The human and the devil alternate by placing a piece into the container. Both rotations and translations are allowed. The first player that cannot place a piece loses. Third, we show that the Planar Extension Game is $\\text{Q}\\mathbb{R}$-complete. We are given a partially drawn plane graph and the human and the devil alternate by placing vertices and the corresponding edges in a straight-line manner. The vertices and edges to be placed are prescribed before hand. The first player that cannot place a vertex loses. Finally, we show that the Order Type Game is $\\text{Q}\\mathbb{R}$-complete. We are given an order-type together with a linear order. The human and the devil alternate in placing a point in the Euclidean plane following the linear order. The first player that cannot place a point correctly loses.",
          "authors": [
            "Lucas Meijer",
            "Arnaud de Mesmay",
            "Tillmann Miltzow",
            "Marcus Schaefer",
            "Jack Stade"
          ],
          "primary_category": "cs.CG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02784",
          "title": "Martingales, laminates and minimal Korn inequalities",
          "abstract": "Korn's inequalities show that the $L^2$-norm of $\\nabla u$ can be controlled by the $L^2$-norm of $\\mathrm{Sym}(\\nabla u)$, which only has $d(d+1)/2$ components. In [J. Math. Pures Appl. 148 (2021), pp. 199-220] Chipot posed the question of \\textit{how many scalar measurements are needed to have a Korn-type control on $\\nabla u$} when $u$ is in $H_0^1(\\Omega)$ and $H^1(\\Omega)$, introducing the minimal numbers $N(d,\\Omega)$ and $N'(d,\\Omega)$ respectively. He proved general bounds and calculated several low-dimensional values of $N,N'$. We reframe Chipot's problem in the language of rank-one convexity and quasiconvexity and obtain a purely algebraic characterisation of when such inequalities hold, which yields the sharp bounds \\begin{align*} N(d,\\Omega)&=2d(1-o(1))\\\\ N'(d,\\Omega)&=2d-1. \\end{align*} As a consequence, we recover and streamline several of Chipot's results, we obtain a dimension-optimal Korn inequality and several sharp estimates for the best constant for various Korn-type inequalities. Generalisations to the rectangular case and to general $L^p$ estimates are also considered.\\par The central new ingredient of our approach is a systematic connection between laminates and martingales which produces explicit families of laminates realising these bounds. This method is of independent interest in the calculus of variations: for instance, we use it to obtain a new quick and quantitative proof of Ornstein's non-inequality, valid for all first order homogeneous operators in $\\mathbb{R}^{2\\times 2}$ and for a large class of operators in general dimensions (including Korn's $\\frac{\\nabla u+\\nabla u^t}2$ and $\\frac{\\nabla u+\\nabla u^t}2-\\mathrm{div}(u)\\frac{\\mathrm{Id}}d$).",
          "authors": [
            "Gabriele Cassese"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02788",
          "title": "Stability and Hopf bifurcation analysis of an age-structured SVIRS epidemic model with temporary immunity",
          "abstract": "In this paper, we investigate an SVIRS epidemic model that incorporates both temporary immunity and an age-structured recovery process. By reformulating the system as a non-densely defined abstract Cauchy problem, we establish the existence and uniqueness of solutions and derive the basic reproduction number $ \\mathcal{R}_0 $. The stability of the equilibria is analyzed through the associated characteristic equations, and the occurrence of Hopf bifurcation near the endemic equilibrium is rigorously demonstrated. Our theoretical results reveal that temporary immunity plays a crucial role in shaping the stability of the endemic state. Finally, numerical simulations are carried out to verify and illustrate the analytical findings.",
          "authors": [
            "Songbo Hou",
            "Xinxin Tian"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02798",
          "title": "Theory of single-photon emission from neutral and charged excitons in a polarization-selective cavity",
          "abstract": "Single-photon sources based on neutral or charged excitons in a semiconductor quantum dot are attractive resources for photonic quantum computers and simulators. To obtain indistinguishable photons, the source is pumped on resonance with polarized laser pulses, and the output is collected in orthogonal polarization. However, for sources featuring vertical emission of light, 50% of the emitted photons are unavoidably lost in this way. Here, we theoretically study the quantum dynamics of an exciton embedded in an asymmetric vertical cavity that favors emission in a specific polarization. We identify the configuration for optimal state initialization and demonstrate a path toward near-unity polarized efficiency. We also derive simple analytical formulas for the photon output in each polarization as a function of the Purcell-enhanced emission rates, which shed light on the physical mechanism behind our results.",
          "authors": [
            "Luca Vannucci",
            "Niels Gregersen"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02798",
          "title": "Theory of single-photon emission from neutral and charged excitons in a polarization-selective cavity",
          "abstract": "Single-photon sources based on neutral or charged excitons in a semiconductor quantum dot are attractive resources for photonic quantum computers and simulators. To obtain indistinguishable photons, the source is pumped on resonance with polarized laser pulses, and the output is collected in orthogonal polarization. However, for sources featuring vertical emission of light, 50% of the emitted photons are unavoidably lost in this way. Here, we theoretically study the quantum dynamics of an exciton embedded in an asymmetric vertical cavity that favors emission in a specific polarization. We identify the configuration for optimal state initialization and demonstrate a path toward near-unity polarized efficiency. We also derive simple analytical formulas for the photon output in each polarization as a function of the Purcell-enhanced emission rates, which shed light on the physical mechanism behind our results.",
          "authors": [
            "Luca Vannucci",
            "Niels Gregersen"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02800",
          "title": "Swarming by curvature control in arbitrary dimension",
          "abstract": "We consider an interacting particle system proposed in the literature to model fish behavior. In this model, the agents move at constant speed and control the curvature of their trajectory (i.e. the time-derivative of their velocity) so as to align their velocity with that of their neighbors, up to some noise. We provide a novel $n$-dimensional formulation of this model for any $n \\geq 3$ and derive its mean-field kinetic formulation using bundle geometry concepts. The target of the paper is the derivation of a fluid model in the hydrodynamic limit. We show that this fluid model is the \"self-organized hydrodynamic\" (SOH) model already found in earlier work pertaining to the Vicsek model. The derivation is based on the introduction of appropriate \"generalized collision invariants\" (GCI). The action of the $n$-dimensional orthogonal group is used to reduce the expression of the GCI to a set of two functions satisfying a system of equations which is solved by means of a variational formulation. This leads to explicit formulas for the coefficients of the SOH model in terms of those of the original interacting particle system.",
          "authors": [
            "Pierre Degond",
            "Antoine Diez",
            "Amic Frouvelle"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02808",
          "title": "Search versus Decision for $\\mathsf{S}_2^\\mathsf{P}$",
          "abstract": "We compare the complexity of the search and decision problems for the complexity class S2P. While Cai (2007) showed that the decision problem is contained in ZPP^NP, we show that the search problem is equivalent to TFNP^NP, the class of total search problems verifiable in polynomial time with an NP oracle. This highlights a significant contrast: if search reduces to decision for S2P, then $\\Sigma_2^p \\cap \\Pi_2^p$ is contained in ZPP^NP.",
          "authors": [
            "Lance Fortnow"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02809",
          "title": "Effect of slowly decaying long-range interactions on topological qubits",
          "abstract": "We study the robustness of topological ground state degeneracy to long-range interactions in quantum many-body systems. We focus on slowly decaying two-body interactions that scale like a power-law $1/r^\\alpha$ where $\\alpha$ is smaller than the spatial dimension; such interactions are beyond the reach of known stability theorems which only apply to short-range or rapidly decaying long-range perturbations. Our main result is a computation of the ground state splitting of several toy models, which are variants of the 1D Ising model $H = -\\sum_i \\sigma^z_i \\sigma^z_{i+1} + \\lambda \\sum_{ij} |i-j|^{-\\alpha} \\sigma^x_i \\sigma^x_j$ with $\\lambda > 0$ and $\\alpha < 1$. These models are also closely connected to the Kitaev p-wave wire model with power-law density-density interactions. In these examples, we find that the splitting $\\delta$ scales like a stretched exponential $\\delta \\sim \\exp(-C L^{\\frac{1+\\alpha}{2}})$ where $L$ is the system size. Our computations are based on path integral techniques similar to the instanton method introduced by Coleman. We also study another toy model with long-range interactions that can be analyzed without path integral techniques and that shows similar behavior.",
          "authors": [
            "Etienne Granet",
            "Michael Levin"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02813",
          "title": "Implementation and Analysis of Quantum Majority Rules under Noisy Conditions",
          "abstract": "Quantum voting, inspired by quantum game theory, provides a framework in which the quantum majority rule (QMR) constitution of Bao and Yunger Halpern [Phys. Rev. A 95, 062306 (2017)] violates the quantum analogue of Arrow's impossibility theorem. We evaluate this QMR constitution analytically on classical profile data and implement its final measurement stage as a quantum circuit, running on both noiseless simulators and noisy IBM quantum hardware to map how realistic noise deforms the resulting societal ranking distribution. Moderate-high single-qubit noise does not change the qualitative behavior of QMR, whereas strong noise shifts the distribution toward other dominant winners than the classical one. We quantify this behavior using winner-agreement rates, Condorcet-winner flip rates, and Jensen-Shannon divergence between societal ranking distributions. In a second, exploratory component, we demonstrate an explicitly entanglement-based variant of the QMR constitution that serves as a testbed for multi-voter quantum correlations under noise, which we refer to as the QMR2-inspired variant. There, GHZ-type and separable superpositions over opposite rankings have the same expectation values but respond very differently to noise. Taken together, these two components connect the abstract QMR constitution to concrete implementations on noisy intermediate-scale quantum (NISQ) devices and highlight design considerations for future quantum voting protocols.",
          "authors": [
            "Gal Amit",
            "Yuval Idan",
            "Michael Suleymanov",
            "Luis Razo",
            "Eliahu Cohen"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02815",
          "title": "Phononic Casimir Effect in Planar Materials",
          "abstract": "The Phononic Casimir effect between planar objects is investigated by deriving a formalism from the quantum partition function of the system following multiscattering approach. This fluctuation-induced coupling is mediated by phonons modeled as an effective elastic medium. We find that excitations with three types of polarizations arise from the resolved boundary conditions, however the coupling is dominated by only one of these degrees of freedom due to exponential suppression effects in the other two. The obtained scaling laws and dependence on materials properties and temperature suggest effective pathways of interaction control. Scenarios of materials combinations are envisioned where the Phononic Casimir effect is of similar order as the standard Casimir interaction mediated by electromagnetic fluctuations.",
          "authors": [
            "Pablo Rodriguez-Lopez",
            "Dai-Nam Le",
            "Lilia M. Woods"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02815",
          "title": "Phononic Casimir Effect in Planar Materials",
          "abstract": "The Phononic Casimir effect between planar objects is investigated by deriving a formalism from the quantum partition function of the system following multiscattering approach. This fluctuation-induced coupling is mediated by phonons modeled as an effective elastic medium. We find that excitations with three types of polarizations arise from the resolved boundary conditions, however the coupling is dominated by only one of these degrees of freedom due to exponential suppression effects in the other two. The obtained scaling laws and dependence on materials properties and temperature suggest effective pathways of interaction control. Scenarios of materials combinations are envisioned where the Phononic Casimir effect is of similar order as the standard Casimir interaction mediated by electromagnetic fluctuations.",
          "authors": [
            "Pablo Rodriguez-Lopez",
            "Dai-Nam Le",
            "Lilia M. Woods"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02819",
          "title": "On the growth properties of interior transmission eigenfunctions near corners",
          "abstract": "We investigate the localization and vanishing of $L^2$ interior transmission eigenfunctions at corners. Past numerical computations suggest that these eigenfunctions localize at non-convex corners. This phenomenon has, however, not been proven theoretically. We show that localization does indeed occur for some eigenfunctions at a non-convex corner. We also investigate the vanishing of interior transmission eigenfunctions at a convex corner. We prove that these eigenfunctions vanish at convex corners with reduced smoothness assumptions compared to earlier results.",
          "authors": [
            "Emilia L.K. Blåsten",
            "Valter Pohjola"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02821",
          "title": "Quiver down-up algebras",
          "abstract": "We present a generalization of down-up algebras, originally defined by Benkart and Roby. These quiver down-up algebras arise as quotients of the double of the extended Dynkin quiver of type $A$. Under a certain non-degeneracy condition, we show that quiver down-up algebras are noetherian piecewise domains. The $\\NN$-graded members of the family are proved to be, generically, twisted Calabi--Yau. Finally, we consider the isomorphism problem for graded quiver down-up algebras.",
          "authors": [
            "Jason Gaddis",
            "Dennis Keeler"
          ],
          "primary_category": "math.RA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02822",
          "title": "Decryption thorough polynomial ambiguity: noise-enhanced high-memory convolutional codes for post-quantum cryptography",
          "abstract": "We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.",
          "authors": [
            "Meir Ariel"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02825",
          "title": "Memory Correlators and Ward Identities in the 'in-in' Formalism",
          "abstract": "The symmetries of asymptotically flat spacetimes impose constraints on observables at infinity. The consequences of this have been extensively explored for S-matrix elements, where soft theorems are known to be equivalent to Ward identities for asymptotic symmetries. However, recently there has been interest in broader classes of asymptotic observables. Here, we consider soft graviton insertions in the 'in-in' formalism. We derive a Ward identity for supertranslations and compute two point functions for the soft charges for 'in-in' correlators. We find that the connected memory correlators are non-trivial in this set up and can be straightforwardly inferred from the average null energy (ANEC) correlators using observations from celestial Conformal Field Theory (cCFT).",
          "authors": [
            "Ian Moult",
            "Sruthi A. Narayanan",
            "Sabrina Pasterski"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02827",
          "title": "There are no excess one digraphs",
          "abstract": "A digraph $G$ is \\emph{$k$-geodetic} if for any pair $u,v \\in V(G)$ there is at most one $u,v$-walk of length not exceeding $k$. The order of a $k$-geodetic digraph with minimum out-degree $d$ is bounded below by the directed Moore bound $M(d,k) = 1 + d + d^2+ \\cdots +d^k$. It is known that the Moore bound cannot be achieved for $d,k \\geq 2$. A $k$-geodetic digraph with minimum degree $d$ and order one greater than the Moore bound has \\emph{excess one}. In this paper we prove a conjecture that no excess one digraphs exist for $d,k \\geq 2$, thus complementing the result of Bannai and Ito on the non-existence of undirected graphs with excess one.",
          "authors": [
            "Slobodan Filipovski",
            "Arnau Messegué",
            "Josep M. Miret",
            "James Tuite"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02828",
          "title": "Anomalous metallic phase and reduced critical current in superconducting nanowires due to inverse proximity effect",
          "abstract": "Superconductor-to-metal transitions (SMTs) are key probes of mesoscopic superconductivity, but their interpretation can be complicated by device geometry and measurement conditions. Here, we study epitaxial InAs-Al nanowires and show that metallic contacts induce an inverse proximity effect (IPE), creating weak spots in the superconductor that strongly suppress the critical current and give rise to an anomalous metallic phase. Using transport measurements supported by Usadel theory, we demonstrate that this phase originates from the contact-induced weakening of superconductivity together with Joule heating, rather than intrinsic material properties. Our findings reveal an overlooked observer effect in mesoscopic superconductors and provide essential guidance for interpreting SMTs and for designing devices based on these systems.",
          "authors": [
            "G. M. Oliveira",
            "G. O. Steffensen",
            "I. Casal Iglesias",
            "M. Gomez",
            "A. Ibabe",
            "T. Kanne",
            "J. Nygard",
            "R. Aguado",
            "A. Levy Yeyati",
            "E. J. H. Lee"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02829",
          "title": "Divergence-type semigroups in Kleinian groups and Hausdorff dimension",
          "abstract": "Let $\\Gamma$ be a non-elementary, non-convex-cocompact Kleinian group acting on $\\mathbb{H}^{d}$. We show that the Hausdorff dimension of the sublinearly conical Myrberg limit set of $\\Gamma$ is equal to the critical exponent of $\\Gamma$. This gives a different proof of a theorem by M. Mj and W. Yang. Along the way, we construct subsemigroups of $\\Gamma$ of divergence type and develop the Patterson--Sullivan theory.",
          "authors": [
            "Inhyeok Choi"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02837",
          "title": "Characterizing Varieties Using Birational Transformations",
          "abstract": "Suppose $X$ is an irreducible complex variety. We show that when $X$ is ruled, the group of birational transformations $Bir(X)$, as a group, determines $X$ up to birational transformations and automorphisms of the base field. In contrast, we demonstrate that this same property never holds for non-uniruled varieties.",
          "authors": [
            "Nathan Chen",
            "Louis Esser",
            "Andriy Regeta",
            "Christian Urech",
            "Immanuel van Santen"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02838",
          "title": "Experimental Blueprint for Distinguishing Decoherence from Objective Collapse",
          "abstract": "The transition from the quantum to the classical realm remains one of the most profound open questions in physics. While quantum theory predicts the existence of macroscopic superpositions, their apparent absence in the everyday world is attributed either to environmental decoherence or to an intrinsic mechanism for wave-function collapse. This work presents a quantitative and experimentally grounded framework for distinguishing these possibilities. We propose a levitated optomechanical platform capable of generating controllable Schrodinger-cat states in the center of mass motion of a dielectric nanosphere. A comprehensive master equation incorporates gas collisions, black-body radiation, and photon-recoil noise, establishing a calibrated environmental baseline. The Continuous Spontaneous Localization (CSL) model is embedded within the same framework, predicting a characteristic saturation of the decoherence rate with superposition size and a quadratic scaling with mass. A Bayesian inference protocol is outlined to discriminate collapse induced excess decoherence from environmental noise. Together these elements provide a concrete experimental blueprint for a decisive test of quantum linearity, either revealing new physics beyond standard quantum mechanics or setting the most stringent bounds to date on objective-collapse parameters.",
          "authors": [
            "Ridha Horchani"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02853",
          "title": "The Obukhov--Corrsin spectrum of passive scalar turbulence through anomalous regularization",
          "abstract": "The Obukhov--Corrsin spectrum predicts the distribution of Fourier mass for a passive scalar field advected by a \"turbulent\" velocity field with spatial regularity $C^\\alpha_x$ for $\\alpha \\in (0,1)$ and subject to a time-stationary forcing. We prove the Obukhov--Corrsin spectrum holds after summing over geometric annuli in Fourier space -- up to logarithmic corrections -- as a consequence of a sharp anomalous regularization result. We then prove this anomalous regularization for a broad class of Kraichnan-type models. The proof of anomalous regularization relies on a Fourier space $\\ell^p$ energy equality and a weighted lattice Poincaré inequality.",
          "authors": [
            "Keefer Rowan"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02853",
          "title": "The Obukhov--Corrsin spectrum of passive scalar turbulence through anomalous regularization",
          "abstract": "The Obukhov--Corrsin spectrum predicts the distribution of Fourier mass for a passive scalar field advected by a \"turbulent\" velocity field with spatial regularity $C^\\alpha_x$ for $\\alpha \\in (0,1)$ and subject to a time-stationary forcing. We prove the Obukhov--Corrsin spectrum holds after summing over geometric annuli in Fourier space -- up to logarithmic corrections -- as a consequence of a sharp anomalous regularization result. We then prove this anomalous regularization for a broad class of Kraichnan-type models. The proof of anomalous regularization relies on a Fourier space $\\ell^p$ energy equality and a weighted lattice Poincaré inequality.",
          "authors": [
            "Keefer Rowan"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02855",
          "title": "Loewner--Kufarev entropy and large deviations of the Hastings--Levitov model",
          "abstract": "We consider the Hastings--Levitov HL(0) model in the small particle scaling limit and prove a large deviation principle. The rate function is given by the relative entropy of the driving measure $\\rho$ for the Loewner--Kufarev equation: \\[ H(\\rho) = \\frac{1}{2\\pi}\\iint \\bar{\\rho}_t(\\theta) \\log \\bar{\\rho}_t(\\theta) d\\theta dt, \\] whenever $\\rho = \\bar{\\rho}_t d\\theta dt/2\\pi$ with $\\int_{S^1} \\bar{\\rho}_t d\\theta/2\\pi = 1$. We investigate the class of shapes that can be generated by finite entropy Loewner evolution and show that it contains all Weil-Petersson quasicircles, all Becker quasicircles, a Jordan curve with a cusp, and a non-simple curve. We also consider the problem of finding a measure of minimal entropy generating a given shape as well as a simplified version of the problem for a related transport equation.",
          "authors": [
            "Nathanaël Berestycki",
            "Vladislav Guskov",
            "Fredrik Viklund"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02856",
          "title": "Qubit Lattice Algorithm Simulations of the Scattering of a Bounded Two Dimensional Electromagnetic Pulse from an Infinite Planar Dielectric Interface",
          "abstract": "Qubit lattice algorithm (QLA) simulations are performed for a two-dimensional (2D) spa- tially bounded pulse propagating onto a plane interface between two dielectric slabs. QLA is an initial value scheme that consists of a sequence of unitary collision and streaming operators, with appropriate potential operators, that recover Maxwell equations in inhomogeneous dielec- tric media to second order in the lattice discreteness. For the case of total internal reflection, there is transient energy transfer into the second medium due to the evanescent fields as the Poynting unit vector of the pulse is rotated from its incident to reflected direction. Because of the finite spatial extent of the pulse, a self- consistent Goos-Hanchen-type displacement along the interface is found without imposing any explicit interface boundary conditions on the fields. For normal incidence. the standard Fresnel coefficients are recovered for appropriately averaged QLA fields. Energy is conserved at all times to seven significant figures.",
          "authors": [
            "Min Soe",
            "George Vahala",
            "Linda Vahala",
            "Efstratios Koukoutsis",
            "Abhay K. Ram",
            "Kyriakos Hizanidis"
          ],
          "primary_category": "physics.plasm-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02864",
          "title": "Modulation of DNA rheology by a transcription factor that forms aging microgels",
          "abstract": "Proteins and nucleic acids form non-Newtonian liquids with complex rheological properties that contribute to their function in vivo. Here we investigate the rheology of the transcription factor NANOG, a key protein in sustaining embryonic stem cell self-renewal. We discover that at high concentrations NANOG forms macroscopic aging gels through its intrinsically disordered tryptophan-rich domain. By combining molecular dynamics simulations, mass photometry and Cryo-EM, we also discover that NANOG forms self-limiting micelle-like clusters which expose their DNA-binding domains. In dense solutions of DNA, NANOG micelle-like structures stabilize intermolecular entanglements and crosslinks, forming microgel-like structures. Our findings suggest that NANOG may contribute to regulate gene expression in a unconventional way: by restricting and stabilizing genome dynamics at key transcriptional sites through the formation of an aging microgel-like structure, potentially enabling mechanical memory in the gene network.",
          "authors": [
            "Amandine Hong-Minh",
            "Yair Augusto Gutiérrez Fosado",
            "Abbie Guild",
            "Nicholas Mullin",
            "Laura Spagnolo",
            "Ian Chambers",
            "Davide Michieletto"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02864",
          "title": "Modulation of DNA rheology by a transcription factor that forms aging microgels",
          "abstract": "Proteins and nucleic acids form non-Newtonian liquids with complex rheological properties that contribute to their function in vivo. Here we investigate the rheology of the transcription factor NANOG, a key protein in sustaining embryonic stem cell self-renewal. We discover that at high concentrations NANOG forms macroscopic aging gels through its intrinsically disordered tryptophan-rich domain. By combining molecular dynamics simulations, mass photometry and Cryo-EM, we also discover that NANOG forms self-limiting micelle-like clusters which expose their DNA-binding domains. In dense solutions of DNA, NANOG micelle-like structures stabilize intermolecular entanglements and crosslinks, forming microgel-like structures. Our findings suggest that NANOG may contribute to regulate gene expression in a unconventional way: by restricting and stabilizing genome dynamics at key transcriptional sites through the formation of an aging microgel-like structure, potentially enabling mechanical memory in the gene network.",
          "authors": [
            "Amandine Hong-Minh",
            "Yair Augusto Gutiérrez Fosado",
            "Abbie Guild",
            "Nicholas Mullin",
            "Laura Spagnolo",
            "Ian Chambers",
            "Davide Michieletto"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02864",
          "title": "Modulation of DNA rheology by a transcription factor that forms aging microgels",
          "abstract": "Proteins and nucleic acids form non-Newtonian liquids with complex rheological properties that contribute to their function in vivo. Here we investigate the rheology of the transcription factor NANOG, a key protein in sustaining embryonic stem cell self-renewal. We discover that at high concentrations NANOG forms macroscopic aging gels through its intrinsically disordered tryptophan-rich domain. By combining molecular dynamics simulations, mass photometry and Cryo-EM, we also discover that NANOG forms self-limiting micelle-like clusters which expose their DNA-binding domains. In dense solutions of DNA, NANOG micelle-like structures stabilize intermolecular entanglements and crosslinks, forming microgel-like structures. Our findings suggest that NANOG may contribute to regulate gene expression in a unconventional way: by restricting and stabilizing genome dynamics at key transcriptional sites through the formation of an aging microgel-like structure, potentially enabling mechanical memory in the gene network.",
          "authors": [
            "Amandine Hong-Minh",
            "Yair Augusto Gutiérrez Fosado",
            "Abbie Guild",
            "Nicholas Mullin",
            "Laura Spagnolo",
            "Ian Chambers",
            "Davide Michieletto"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02869",
          "title": "Detecting Symmetrizability in Physical Systems",
          "abstract": "We study the problem of data transmission under the influence of a jammer, which is typical for wireless systems and commonly modeled as an arbitrarily varying channel (AVC) in information theory. AVC fulfilling a certain set of linear equations are called symmetrizable and are known to be prone to denial of service attacks. Recent work has shown that deciding if a given AVC is symmetrizable or not is a non-Turing computable problem. By relaxing the formulation of symmetrizability, we show the existence of a polynomial-time algorithm that determines whether a given AVC is non-symmetrizable, but displays a critical dependence on the number of jammer input states. We then show how imposing an energy constraint on the jammer allows the same algorithm to efficiently identify large classes of AVCs which are non-symmetrizable.",
          "authors": [
            "Florian Seitz",
            "Janis Nötzel"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02873",
          "title": "Symbolic ω-automata with obligations",
          "abstract": "Extensions of {\\omega}-automata to infinite alphabets typically rely on symbolic guards to keep the transition relation finite, and on registers or memory cells to preserve information from past symbols. Symbolic transitions alone are ill-suited to act on this information, and register automata have intricate formal semantics and issues with tractability. We propose a slightly different approach based on obligations, i.e., assignment-like constructs attached to transitions. Whenever a transition with an obligation is taken, the obligation is evaluated against the current symbol and yields a constraint on the next symbol that the automaton will read. We formalize obligation automata with existential and universal branching and Emerson-Lei acceptance conditions, which subsume classic families such as Büchi, Rabin, Strett, and parity automata. We show that these automata recognise a strict superset of {\\omega}-regular languages. To illustrate the practicality of our proposal, we also introduce a machine-readable format to express obligation automata and describe a tool implementing several operations over them, including automata product and emptiness checking.",
          "authors": [
            "Luca Di Stefano"
          ],
          "primary_category": "cs.FL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02876",
          "title": "Communication-ready high-power soliton microcombs in highly-dispersive Fabry-Perot-microresonators",
          "abstract": "Microcombs generated in optical microresonators are widely regarded as promising light sources for next-generation communication systems, but the optical power available per comb line has so far fallen short of practical requirements. Here we introduce an integrated Fabry-Pérot microresonator platform that overcomes fundamental dispersion-engineering constraints and enables bright soliton microcombs with unprecedented power per line. The resonator is defined by chirped Bragg gratings that provide exceptionally large anomalous group-velocity dispersion, allowing more than ten comb lines to reach the milliwatt level. These combs can be used directly in coherent communication systems without additional amplification, achieving an aggregate data rate of 2 Tb/s. Once integrated, our high-power soliton microcombs could be instantly ready for communications as well as a broad range of practical comb-based applications.",
          "authors": [
            "Yinke Cheng",
            "Zhenyu Xie",
            "Yuanlei Wang",
            "Binbin Nie",
            "Xing Jin",
            "Haoyang Luo",
            "Junqi Wang",
            "Zixuan Zhou",
            "Qihuang Gong",
            "Lin Chang",
            "Yaowen Hu",
            "Qi-Fan Yang"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02877",
          "title": "Positional memory of skyrmions in magnetic bilayers",
          "abstract": "We numerically and analytically study the transient dynamics of magnetic skyrmions in synthetic antiferromagnets under a magnetic field gradient. We consider skyrmions in a bilayer with antiferromagnetic coupling between the layers. The skyrmions in the two layers move almost perpendicular to the field gradient and the motion is eventually halted with the two skyrmions at a distance from each other. We find that the skyrmion displacement is proportional to the field gradient, while the time it takes to reach their final position is almost independent of it. Below a critical magnetic field gradient strength, the system displays an unusual 'remembering' dynamics: when the magnetic field gradient is removed, the skyrmions return to their original positions to a high degree of accuracy. We explain this observation and other quantitative features using a moduli space dynamics approximation. We further provide an exact treatment of the dynamics that indicates that deviations from exact memory of the skyrmion position can arise.",
          "authors": [
            "Bruno Barton-Singer",
            "Anusree Navallur",
            "Stavros Komineas"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02877",
          "title": "Positional memory of skyrmions in magnetic bilayers",
          "abstract": "We numerically and analytically study the transient dynamics of magnetic skyrmions in synthetic antiferromagnets under a magnetic field gradient. We consider skyrmions in a bilayer with antiferromagnetic coupling between the layers. The skyrmions in the two layers move almost perpendicular to the field gradient and the motion is eventually halted with the two skyrmions at a distance from each other. We find that the skyrmion displacement is proportional to the field gradient, while the time it takes to reach their final position is almost independent of it. Below a critical magnetic field gradient strength, the system displays an unusual 'remembering' dynamics: when the magnetic field gradient is removed, the skyrmions return to their original positions to a high degree of accuracy. We explain this observation and other quantitative features using a moduli space dynamics approximation. We further provide an exact treatment of the dynamics that indicates that deviations from exact memory of the skyrmion position can arise.",
          "authors": [
            "Bruno Barton-Singer",
            "Anusree Navallur",
            "Stavros Komineas"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02877",
          "title": "Positional memory of skyrmions in magnetic bilayers",
          "abstract": "We numerically and analytically study the transient dynamics of magnetic skyrmions in synthetic antiferromagnets under a magnetic field gradient. We consider skyrmions in a bilayer with antiferromagnetic coupling between the layers. The skyrmions in the two layers move almost perpendicular to the field gradient and the motion is eventually halted with the two skyrmions at a distance from each other. We find that the skyrmion displacement is proportional to the field gradient, while the time it takes to reach their final position is almost independent of it. Below a critical magnetic field gradient strength, the system displays an unusual 'remembering' dynamics: when the magnetic field gradient is removed, the skyrmions return to their original positions to a high degree of accuracy. We explain this observation and other quantitative features using a moduli space dynamics approximation. We further provide an exact treatment of the dynamics that indicates that deviations from exact memory of the skyrmion position can arise.",
          "authors": [
            "Bruno Barton-Singer",
            "Anusree Navallur",
            "Stavros Komineas"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02883",
          "title": "Convergence to stationary points in the Weisbuch-Kirman-Herreiner model for buyers' preferences in fish markets",
          "abstract": "In a paper published in The Economic Journal in 2000, Weisbuch et al.\\ introduce a model for buyers' preferences to the various sellers in over-the-counter (OTC) fish markets. While this model has become an archetype of economic conceptualization that combines bounded rationality and myopic reasoning, the literature on its asymptotic behaviours has remained scarce. In this paper, we proceed to a mathematical analysis of the dynamics and its full characterization in the simplest case of homogeneous buyer populations. By using elements of the theory of cooperative dynamical systems, we prove that, independently of the number of sellers and parameters, for almost every initial condition, the subsequent trajectory must asymptotically approach a stationary state. Moreover, for simple enough distributions of the sellers' attractiveness, we determine all stationary states and their parameter-dependent stability. This analysis shows that in most cases, the asymptotic preferences are ordered as the attractiveness are. However, depending on the parameters, there also exist robust functioning modes in which those sellers with highest preference are not the ones that provide highest profit.",
          "authors": [
            "Ali Ellouze",
            "Bastien Fernandez"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02883",
          "title": "Convergence to stationary points in the Weisbuch-Kirman-Herreiner model for buyers' preferences in fish markets",
          "abstract": "In a paper published in The Economic Journal in 2000, Weisbuch et al.\\ introduce a model for buyers' preferences to the various sellers in over-the-counter (OTC) fish markets. While this model has become an archetype of economic conceptualization that combines bounded rationality and myopic reasoning, the literature on its asymptotic behaviours has remained scarce. In this paper, we proceed to a mathematical analysis of the dynamics and its full characterization in the simplest case of homogeneous buyer populations. By using elements of the theory of cooperative dynamical systems, we prove that, independently of the number of sellers and parameters, for almost every initial condition, the subsequent trajectory must asymptotically approach a stationary state. Moreover, for simple enough distributions of the sellers' attractiveness, we determine all stationary states and their parameter-dependent stability. This analysis shows that in most cases, the asymptotic preferences are ordered as the attractiveness are. However, depending on the parameters, there also exist robust functioning modes in which those sellers with highest preference are not the ones that provide highest profit.",
          "authors": [
            "Ali Ellouze",
            "Bastien Fernandez"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02883",
          "title": "Convergence to stationary points in the Weisbuch-Kirman-Herreiner model for buyers' preferences in fish markets",
          "abstract": "In a paper published in The Economic Journal in 2000, Weisbuch et al.\\ introduce a model for buyers' preferences to the various sellers in over-the-counter (OTC) fish markets. While this model has become an archetype of economic conceptualization that combines bounded rationality and myopic reasoning, the literature on its asymptotic behaviours has remained scarce. In this paper, we proceed to a mathematical analysis of the dynamics and its full characterization in the simplest case of homogeneous buyer populations. By using elements of the theory of cooperative dynamical systems, we prove that, independently of the number of sellers and parameters, for almost every initial condition, the subsequent trajectory must asymptotically approach a stationary state. Moreover, for simple enough distributions of the sellers' attractiveness, we determine all stationary states and their parameter-dependent stability. This analysis shows that in most cases, the asymptotic preferences are ordered as the attractiveness are. However, depending on the parameters, there also exist robust functioning modes in which those sellers with highest preference are not the ones that provide highest profit.",
          "authors": [
            "Ali Ellouze",
            "Bastien Fernandez"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02885",
          "title": "Exciton spin structure in lead halide perovskite semiconductors explored via the spin dynamics in magnetic field",
          "abstract": "We theoretically investigate the spin structure and spin dynamics of excitons in bulk lead halide perovskite semiconductors with cubic, tetragonal, and orthorhombic crystal symmetry. The exciton spin structure and its modification by an external magnetic field are modeled for different regimes defined by the relative magnitude of the electron-hole exchange interaction (splitting between dark and bright states) and the Zeeman spin splitting. The effects of crystal symmetry and magnetic field orientation with respect to the crystal axes are considered for lead halide perovskite crystals with band gaps in the range 1.4 - 3.5 eV, having different ratios of electron and hole g-factors. For cubic symmetry, in a longitudinal magnetic field, our theory predicts quantum beats between the bright exciton states under linearly polarized excitation and detection, while the dark exciton remains optically inactive. In a transverse magnetic field, all exciton spin states become optically active and can be excited by circularly polarized light. Reduction of the crystal symmetry leads to a zero-field offset of the exciton Larmor precession frequencies, modifying the Zeeman splitting energy dependence on magnetic field. This theoretical framework allows for the extraction of the strength of the exchange interaction and the crystal symmetry. Experimentally, we measure the exciton spin coherence via time-resolved photoluminescence at a temperature of 1.6 K in longitudinal and transverse magnetic fields in orthorhombic MAPbI3 crystals. Polarization beats at the frequency of the bright exciton are observed in both configurations. Comparison with theory indicates that the excitons are in the strong exchange interaction regime, and the reduction of symmetry does not lead to a significant splitting of the exciton spin levels.",
          "authors": [
            "Vladimir L. Zhiliakov",
            "Nataliia E. Kopteva",
            "Irina A. Yugova",
            "Dmitri R. Yakovlev",
            "Ilya A. Akimov",
            "Manfred Bayer"
          ],
          "primary_category": "cond-mat.other",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02885",
          "title": "Exciton spin structure in lead halide perovskite semiconductors explored via the spin dynamics in magnetic field",
          "abstract": "We theoretically investigate the spin structure and spin dynamics of excitons in bulk lead halide perovskite semiconductors with cubic, tetragonal, and orthorhombic crystal symmetry. The exciton spin structure and its modification by an external magnetic field are modeled for different regimes defined by the relative magnitude of the electron-hole exchange interaction (splitting between dark and bright states) and the Zeeman spin splitting. The effects of crystal symmetry and magnetic field orientation with respect to the crystal axes are considered for lead halide perovskite crystals with band gaps in the range 1.4 - 3.5 eV, having different ratios of electron and hole g-factors. For cubic symmetry, in a longitudinal magnetic field, our theory predicts quantum beats between the bright exciton states under linearly polarized excitation and detection, while the dark exciton remains optically inactive. In a transverse magnetic field, all exciton spin states become optically active and can be excited by circularly polarized light. Reduction of the crystal symmetry leads to a zero-field offset of the exciton Larmor precession frequencies, modifying the Zeeman splitting energy dependence on magnetic field. This theoretical framework allows for the extraction of the strength of the exchange interaction and the crystal symmetry. Experimentally, we measure the exciton spin coherence via time-resolved photoluminescence at a temperature of 1.6 K in longitudinal and transverse magnetic fields in orthorhombic MAPbI3 crystals. Polarization beats at the frequency of the bright exciton are observed in both configurations. Comparison with theory indicates that the excitons are in the strong exchange interaction regime, and the reduction of symmetry does not lead to a significant splitting of the exciton spin levels.",
          "authors": [
            "Vladimir L. Zhiliakov",
            "Nataliia E. Kopteva",
            "Irina A. Yugova",
            "Dmitri R. Yakovlev",
            "Ilya A. Akimov",
            "Manfred Bayer"
          ],
          "primary_category": "cond-mat.other",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02886",
          "title": "Log syntomic cohomology of truncated polynomials and coordinate axes",
          "abstract": "We study the logarithmic syntomic cohomology of fine and saturated log schemes and its realization in the logarithmic motivic stable homotopy category $\\mathrm{logSH}(\\mathrm{pt}_\\mathbb{N})$ of a log point. We prove that logarithmic prismatic and syntomic cohomology satisfy saturated descent under the sole assumption that the log structure is free, and that the presheaves $\\mathrm{logTHH}$, $\\mathrm{logTC}$, $\\widehat{\\mathbf{\\Delta}}$, and $\\mathbb{Z}_p^\\mathrm{syn}(i)$ are representable and $\\square$-invariant in $\\mathrm{logSH}_{\\mathrm{k\\acute{e}t}}^{\\mathrm{eff}}(\\mathrm{pt}_\\mathrm{N})$. As an application, we compute $\\mathbb{Z}_p^\\mathrm{syn}(i)$ for the projective log coordinate axes $D$ in $\\mathbb{P}^2$, obtaining \\[ \\mathbb{Z}_p^\\mathrm{syn}(i)(D) \\simeq \\mathbb{Z}_p^\\mathrm{syn}(i)(k,\\mathbb{N})\\oplus \\mathbb{Z}_p^\\mathrm{syn}(i-1)(k,\\mathbb{N})[-2] \\] Moreover, we determine logarithmic topological cyclic homology for truncated polynomial and semistable examples, directly from the syntomic calculations.",
          "authors": [
            "Doosung Park",
            "Paul Arne Østvær"
          ],
          "primary_category": "math.AG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02887",
          "title": "Discovery and rectification of an error in high resistance traceability at NPL: a case study in how metrology works",
          "abstract": "We broach a seldom-discussed topic in precision metrology; how subtle errors in calibration processes are discovered and remedied. We examine a case study at the National Physical Laboratory (NPL), UK, involving the calibration of DC standard resistors of value 100 MOhm and 1 GOhm. Results from the period 2001 to 2015 were in error by approximately 0.7 parts per million (ppm), with quoted uncertainties (k=2) of 0.4 ppm and 1.6 ppm respectively. Inter-comparisons did not detect the error, mainly because the uncertainty due to the transportation drift of the comparison standards was too large to resolve it. Likewise, research into single-electron current standards did not detect the error because at this resistance value it was on the borderline of statistical significance. The key event was a comparison between PTB (Germany) and NPL (UK) of a new small-current measuring instrument, the ultrastable low-noise current amplifier (ULCA). At that time, the transport stability of the ULCA was not well established. Nevertheless, calibrations of the ULCA at NPL using a 100 MOhm resistor were sufficiently discrepant with the PTB calibrations to motivate a thorough investigation into the NPL traceability chain, which uncovered the error. This instructive episode illustrates a positive interplay between calibration and research activities and shows that cutting-edge calibration uncertainties must be supported by a vigorous research programme. It is also important for NMIs to maintain a comfortable buffer (at least a factor of 10) between their claimed uncertainty and the uncertainty that their customers require, so that small errors can be resolved without significant impact on measurement stakeholders.",
          "authors": [
            "Stephen Giblin"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02888",
          "title": "A Novel Injection-Locked S-Band Oven Magnetron System Without Waveguide Isolators",
          "abstract": "A novel injection-locked S-band microwave oven magnetron system is proposed, analyzed, and experimented. The magnetron is considered as a two-port oscillator, and the filament structures of it are used as a port for injection locking. To our knowledge, it is the first time that microwaves have been injected through magnetron filaments. The microwave is injected into the magnetron filter box using a self-designed injection structure, entering the resonant cavity through filament leads. The intrinsic isolation between the magnetrons output and filament is utilized as an isolator. No waveguide circulators or couplers between the injection source and the magnetron were used in the system, resulting in low cost and compact injection locking. Two types of injection structures were performed. The maximum locking bandwidth of 0.7 MHz was achieved at an injection ratio of 0.2. The weight and volume of the proposed injection-locked magnetron system were reduced to 28% and 16%, respectively. The magnetron output is successfully locked by an external signal. The experiment results reveal that the proposed low-cost injection-locked oven magnetron system works reliably. It has significant potential applications for future microwave ovens with frequency-selective heating to improve both efficiency and uniformity.",
          "authors": [
            "S Wang",
            "Y Shen",
            "C Liao",
            "J Jing",
            "C Liu"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02889",
          "title": "Terahertz Emission from Spintronic Stack Nanodecorated with Drop-Cast Core-Shell Plasmonic Nanoparticles",
          "abstract": "Spintronic emitters promise to revolutionise terahertz (THz) sources by converting ultrafast optical pulses into broadband THz radiation without phase-matching constraints. Because the conversion relies on spin-current injection across a nanometre-thin magnetic layer, its efficiency is ordinarily limited by weak optical coupling. Here, we present a demonstration of a drop-casting based approach to introduce ultrafast plasmonic-mediated coupling: a sparse-layer of silica-gold core-shell nanoparticles is deposited directly onto a W/Fe/Pt spintronic trilayer. This sparse (six percent) decoration increases the wafer-averaged THz pulse energy, pointing to a very high local conversion enhancement for this low-coverage spintronic emitter compared with the bare stack. This demonstration points to a viable pathway toward highly efficient spintronic terahertz emitters with potential applications in spectroscopy, imaging, and ultrafast technologies.",
          "authors": [
            "Vittorio Cecconi",
            "Akash Dominic Thomas",
            "Ji Tong Wang",
            "Cheng-Han Lin",
            "Anoop Dhoot",
            "Antonio Cutrona",
            "Abhishek Paul",
            "Luke Peters",
            "Luana Olivieri",
            "Elchin Isgandarov",
            "Juan Sebastian Totero Gongora",
            "Alessia Pasquazi",
            "Marco Peccianti"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02890",
          "title": "SDQC: Distributed Quantum Computing Architecture Utilizing Entangled Ion Qubit Shuttling",
          "abstract": "We propose Shuttling-based Distributed Quantum Computing (SDQC), a hybrid architecture that combines the strengths of physical qubit shuttling and distributed quantum computing to enable scalable trapped-ion quantum computing. SDQC performs non-local quantum operations by distributing entangled ion qubits via deterministic shuttling, combining the high-fidelity and deterministic operations of shuttling-based architectures with the parallelism and pipelining advantages of distributed quantum computing. We present (1) a practical architecture incorporating quantum error correction (QEC), (2) pipelining strategies to exploit parallelism in entanglement distribution and measurement, and (3) a performance evaluation in terms of logical error rate and clock speed. For a 256-bit elliptic-curve discrete logarithm problem (ECDLP) instance, which requires 2,871 logical qubits at code distance 13, SDQC achieves a logical error rate which is $1.20^{+0.94}_{-0.45}\\times10^{-8}$ of Photonic DQC error rate and $3.79^{+5.09}_{-2.84}\\times10^{-3}$ of Quantum Charge-Coupled Device (QCCD) error rate, while providing 2.82 times faster logical clock speed than QCCD.",
          "authors": [
            "Seunghyun Baek",
            "Seok-Hyung Lee",
            "Dongmoon Min",
            "Junki Kim"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02890",
          "title": "SDQC: Distributed Quantum Computing Architecture Utilizing Entangled Ion Qubit Shuttling",
          "abstract": "We propose Shuttling-based Distributed Quantum Computing (SDQC), a hybrid architecture that combines the strengths of physical qubit shuttling and distributed quantum computing to enable scalable trapped-ion quantum computing. SDQC performs non-local quantum operations by distributing entangled ion qubits via deterministic shuttling, combining the high-fidelity and deterministic operations of shuttling-based architectures with the parallelism and pipelining advantages of distributed quantum computing. We present (1) a practical architecture incorporating quantum error correction (QEC), (2) pipelining strategies to exploit parallelism in entanglement distribution and measurement, and (3) a performance evaluation in terms of logical error rate and clock speed. For a 256-bit elliptic-curve discrete logarithm problem (ECDLP) instance, which requires 2,871 logical qubits at code distance 13, SDQC achieves a logical error rate which is $1.20^{+0.94}_{-0.45}\\times10^{-8}$ of Photonic DQC error rate and $3.79^{+5.09}_{-2.84}\\times10^{-3}$ of Quantum Charge-Coupled Device (QCCD) error rate, while providing 2.82 times faster logical clock speed than QCCD.",
          "authors": [
            "Seunghyun Baek",
            "Seok-Hyung Lee",
            "Dongmoon Min",
            "Junki Kim"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02894",
          "title": "Exploring the Electronic Nature of Spinel Oxides: A Review of Their Electron Interactions and Prospects",
          "abstract": "This review discusses the multifaceted electronic properties of spinel oxides with a particular focus on Lithium Vanadate (LiV2O4), Lithium Titanate (LiTi2O4), and Magnesium Titanate (MgTi2O4). We selected LiTi2O4, LiV2O4, and MgTi2O4 because they serve as quintessential examples of spinel oxides' diverse and intriguing electronic phenomena. LiV2O4 heavy fermion behaviour challenges traditional theories in d-electron systems, LiTi2O4 being the first oxide superconductor provides critical insights into unconventional superconductivity driven by strong electron-phonon interactions, and MgTi2O4 pronounced orbital ordering and metalinsulator transition offers a clear model for exploring electron-lattice coupling. This shows how the inherent structural versatility of the spinel lattice, characterised by its cubic close-packed oxygen network and variable cation distributions, enables a rich interplay of electron-electron correlations, electron-lattice coupling, and orbital degrees of freedom. In LiV2O4, the combination of mixed-valence vanadium ions and a geometrically frustrated pyrochlore lattice gives rise to heavy fermion behaviour, whereas LiTi2O4 exhibits unconventional superconductivity driven by a high density of states at the Fermi level and strong electronphonon interactions. MgTi2O4 undergoes a pronounced metal-insulator transition, where orbital ordering triggers a Peierls-like distortion that stabilises a low-temperature insulating state through Ti-Ti dimerization. How the composition of these compounds affects their properties, based on both theoretical research and experimental findings, is illustrated by this review. It illustrates the promise of Spinels in practical technologies such as energy storage, electrocatalysis, and high-temperature lubrication.",
          "authors": [
            "Jagadis Prasad Nayak",
            "Raju Saini",
            "Sourav Dash",
            "Gopi Nath Daptary"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02896",
          "title": "Ridged geometries induce axial flow vortices in Couette systems",
          "abstract": "A yield stress fluid has a critical stress above which the material starts to flow. Typically, the yield stress behaviour is captured in the Herschel-Bulkley (HB) model, which assumes a constant yield stress as material parameter. It is not clear whether the simultaneous superposition of a flow in an orthogonal direction to the main flow, that displays HB behaviour, affects the yield stress and will make the yield stress either flow rate- or field-dependent. Therefore, it is important to understand how the presence of flow in two orthogonal directions affects the yielding behaviour of the fluid in general. In this work, we showed that wall patterning can be used to generate flow in two orthogonal directions simultaneously. We find that these orthogonal flows measurably affected each other. We induced spatially varying secondary flows by shearing a standard Newtonian fluid and two common yield stress fluids in a rheometer using a concentric cylinder geometry with angled ridges. We measured the normal force as a function of rotation rates for different angled ridges from conventional rheological measurements. We also imaged the flow fields by employing rheo-MRI, to directly measure the penetration depth of the fluids into the rough boundary of the ridged geometry. Finally, we relate the penetration depth to the axial flow for different geometries, at different imposed rotation rates and the fluid type, to show that two flow directions in the yield stress fluids are indeed significantly related to each other.",
          "authors": [
            "Akankshya Majhi",
            "Maria Raquel Serial",
            "Lars Kool",
            "Jasper van der Gucht",
            "Joshua Albert Dijksman"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02903",
          "title": "Symmetry transformation group arising from the Laplace-Runge-Lenz vector",
          "abstract": "The Kepler problem in classical mechanics exhibits a rich structure of conserved quantities, highlighted by the Laplace--Runge--Lenz (LRL) vector. Through Noether's theorem in reverse, the LRL vector gives rise to a corresponding infinitesimal dynamical symmetry on the kinematical variables, which is well known in the literature. However, the physically relevant part of the LRL vector is its direction angle in the plane of motion (since its magnitude is just a function of energy and angular momentum). The present work derives the infinitesimal dynamical symmetry corresponding to the direction part of the LRL vector, and obtains the explicit form of the symmetry transformations that it generates. When combined with the rotation symmetries,the resulting symmetry group is shown to be the semi-direct product of $SO(3)$ and $R^3$. This stands in contrast to the $SO(4)$ symmetry group generated by the LRL symmetries and the rotations. As a by-product, the action of the new infinitesimal symmetries on all of the conserved quanties is obtained. The results are given in terms of the physical kinematical variables in the Kepler problem, rather than in an enlarged auxiliary space in which the LRL symmetries are usually stated.",
          "authors": [
            "Stephen C. Anco",
            "Mahdieh Gol Bashmani Moghadam"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02903",
          "title": "Symmetry transformation group arising from the Laplace-Runge-Lenz vector",
          "abstract": "The Kepler problem in classical mechanics exhibits a rich structure of conserved quantities, highlighted by the Laplace--Runge--Lenz (LRL) vector. Through Noether's theorem in reverse, the LRL vector gives rise to a corresponding infinitesimal dynamical symmetry on the kinematical variables, which is well known in the literature. However, the physically relevant part of the LRL vector is its direction angle in the plane of motion (since its magnitude is just a function of energy and angular momentum). The present work derives the infinitesimal dynamical symmetry corresponding to the direction part of the LRL vector, and obtains the explicit form of the symmetry transformations that it generates. When combined with the rotation symmetries,the resulting symmetry group is shown to be the semi-direct product of $SO(3)$ and $R^3$. This stands in contrast to the $SO(4)$ symmetry group generated by the LRL symmetries and the rotations. As a by-product, the action of the new infinitesimal symmetries on all of the conserved quanties is obtained. The results are given in terms of the physical kinematical variables in the Kepler problem, rather than in an enlarged auxiliary space in which the LRL symmetries are usually stated.",
          "authors": [
            "Stephen C. Anco",
            "Mahdieh Gol Bashmani Moghadam"
          ],
          "primary_category": "math-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02905",
          "title": "Syntomic formalism with coefficients",
          "abstract": "This paper provides the technical tools needed in ongoing work of the authors to compute p-adic étale Abel-Jacobi maps in order to obtain explicit reciprocity laws for GSp4. In particular, we define and study syntomic polynomial cohomology for filtered Frobenius log-isocrystals over proper and semistable schemes over the ring of integers of a local field, with smooth generic fiber, endowed with horizontal divisors. We introduce syntomic polynomial cohomology with support, we define Kunneth morphisms, trace maps and cup products, Gysin maps with respect to divisors and we study some of their properties. We establish the relation with Hyodo-Kato cohomology of the special fiber and de Rham cohomology of the generic fiber. We also introduce overconvergent variants with and without support by restricting to open smooth formal subschemes. Most of all, in case that the filtered log-isocrystal is associated to a p-adic local system on the generic fiber, we establish comparison morphisms between étale and syntomic cohomology and compatibilities with Hochschild-Serre morphisms and between Gysin morphisms.",
          "authors": [
            "Fabrizio Andreatta",
            "Massimo Bertolini",
            "Marco Adamo Seveso",
            "Rodolfo Venerucci"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02907",
          "title": "Tunable giant Purcell enhancement of quantum light emitters by means of acoustic graphene plasmons",
          "abstract": "Inspired by the remarkable ability of plasmons to boost radiative emission rates, we propose leveraging acoustic graphene plasmons (AGPs) to realize tunable, giant Purcell enhancements for single-photon, entangled-photon, and multipolar quantum emitters. These AGPs are localized inside a cavity defined by a graphene sheet and a metallic nanocube and filled with a dielectric of thickness of a few nanometers and consisting of stacked layers of 2D materials, containing impurities or defects that act as quantum light emitters. Through finite-difference time domain (FDTD) calculations, we show that this geometry can achieve giant Purcell enhancement factors over a large portion of the infrared (IR) spectrum, up to 6 orders of magnitude in the mid-IR and up to 4 orders of magnitude at telecommunications wavelengths, reaching quantum efficiencies of 95\\% and 89\\%, respectively, with high-mobility graphene. We obtain Purcell enhancement factors for single-photon electric dipole (E1), electric quadrupole (E2), and electric octupole (E3) transitions and two-photon spontaneous emission (2PSE) transitions, of the orders of $10^{4}$, $10^{7}$, $10^{9}$, and $10^9$, respectively, and a quantum efficiency of 79\\% for entangled-photon emission with high-mobility graphene at a wavelength of $\\lambda=1.55$ $\\mu$m. Importantly, AGP mode frequencies depend on the graphene Fermi energy, which can be tuned via electrostatic gating to modulate fluorescence enhancement in real time. As an example, we consider the Purcell enhancement of spontaneous single- and two-photon emissions from an erbium atom inside single-layer (SL) WS$_2$. Our results could be useful for electrically tunable quantum emitter devices with applications in quantum communication and quantum information processing.",
          "authors": [
            "Justin Gruber",
            "Mahtab A. Khan",
            "Dirk R. Englund",
            "Michael N. Leuenberger"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02907",
          "title": "Tunable giant Purcell enhancement of quantum light emitters by means of acoustic graphene plasmons",
          "abstract": "Inspired by the remarkable ability of plasmons to boost radiative emission rates, we propose leveraging acoustic graphene plasmons (AGPs) to realize tunable, giant Purcell enhancements for single-photon, entangled-photon, and multipolar quantum emitters. These AGPs are localized inside a cavity defined by a graphene sheet and a metallic nanocube and filled with a dielectric of thickness of a few nanometers and consisting of stacked layers of 2D materials, containing impurities or defects that act as quantum light emitters. Through finite-difference time domain (FDTD) calculations, we show that this geometry can achieve giant Purcell enhancement factors over a large portion of the infrared (IR) spectrum, up to 6 orders of magnitude in the mid-IR and up to 4 orders of magnitude at telecommunications wavelengths, reaching quantum efficiencies of 95\\% and 89\\%, respectively, with high-mobility graphene. We obtain Purcell enhancement factors for single-photon electric dipole (E1), electric quadrupole (E2), and electric octupole (E3) transitions and two-photon spontaneous emission (2PSE) transitions, of the orders of $10^{4}$, $10^{7}$, $10^{9}$, and $10^9$, respectively, and a quantum efficiency of 79\\% for entangled-photon emission with high-mobility graphene at a wavelength of $\\lambda=1.55$ $\\mu$m. Importantly, AGP mode frequencies depend on the graphene Fermi energy, which can be tuned via electrostatic gating to modulate fluorescence enhancement in real time. As an example, we consider the Purcell enhancement of spontaneous single- and two-photon emissions from an erbium atom inside single-layer (SL) WS$_2$. Our results could be useful for electrically tunable quantum emitter devices with applications in quantum communication and quantum information processing.",
          "authors": [
            "Justin Gruber",
            "Mahtab A. Khan",
            "Dirk R. Englund",
            "Michael N. Leuenberger"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02909",
          "title": "Electrically driven plasmon-polaritonic bistability in Dirac electron tunneling transistors",
          "abstract": "Bistability-two distinct stable states under identical parameter-is not only a fundamental physical concept but also of importance in practical applications. While plasmon-polaritonic bistability representing history-dependent stable states within plasmonic systems has been theoretically predicted, it has yet to be demonstrated experimentally due to challenges in realizing suitable nonlinearity at feasible electric-field strengths. Here, we report the experimental observation of electrically driven plasmon-polaritonic bistability in graphene/hexagonal-boron-nitride/graphene tunneling transistors, achieved through momentum-conserving resonant tunneling of Dirac electrons. Using a small twist angle between graphene layers, we engineered devices exhibiting both electronic and plasmon-polaritonic bistability. This bistable plasmonic behavior can be precisely tuned through load resistance and electrostatic gating. Our findings open new pathways for exploring nonlinear optical and electronic phenomena in van der Waals heterostructures and mark a significant advance in nanoplasmonics, with potential applications in optical memory, sensing, and optoelectronic switching.",
          "authors": [
            "Shuai Zhang",
            "Yang Xu",
            "Junhe Zhang",
            "Dihao Sun",
            "Yinan Dong",
            "Matthew Fu",
            "Takashi Taniguchi",
            "Kenji Watanabe",
            "Cory R. Dean",
            "Monica Allen",
            "Jeffery Allen",
            "F. Javier Garcia de Abajo",
            "Antti J. Moilanen",
            "Lukas Novotny",
            "D. N. Basov"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02909",
          "title": "Electrically driven plasmon-polaritonic bistability in Dirac electron tunneling transistors",
          "abstract": "Bistability-two distinct stable states under identical parameter-is not only a fundamental physical concept but also of importance in practical applications. While plasmon-polaritonic bistability representing history-dependent stable states within plasmonic systems has been theoretically predicted, it has yet to be demonstrated experimentally due to challenges in realizing suitable nonlinearity at feasible electric-field strengths. Here, we report the experimental observation of electrically driven plasmon-polaritonic bistability in graphene/hexagonal-boron-nitride/graphene tunneling transistors, achieved through momentum-conserving resonant tunneling of Dirac electrons. Using a small twist angle between graphene layers, we engineered devices exhibiting both electronic and plasmon-polaritonic bistability. This bistable plasmonic behavior can be precisely tuned through load resistance and electrostatic gating. Our findings open new pathways for exploring nonlinear optical and electronic phenomena in van der Waals heterostructures and mark a significant advance in nanoplasmonics, with potential applications in optical memory, sensing, and optoelectronic switching.",
          "authors": [
            "Shuai Zhang",
            "Yang Xu",
            "Junhe Zhang",
            "Dihao Sun",
            "Yinan Dong",
            "Matthew Fu",
            "Takashi Taniguchi",
            "Kenji Watanabe",
            "Cory R. Dean",
            "Monica Allen",
            "Jeffery Allen",
            "F. Javier Garcia de Abajo",
            "Antti J. Moilanen",
            "Lukas Novotny",
            "D. N. Basov"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02909",
          "title": "Electrically driven plasmon-polaritonic bistability in Dirac electron tunneling transistors",
          "abstract": "Bistability-two distinct stable states under identical parameter-is not only a fundamental physical concept but also of importance in practical applications. While plasmon-polaritonic bistability representing history-dependent stable states within plasmonic systems has been theoretically predicted, it has yet to be demonstrated experimentally due to challenges in realizing suitable nonlinearity at feasible electric-field strengths. Here, we report the experimental observation of electrically driven plasmon-polaritonic bistability in graphene/hexagonal-boron-nitride/graphene tunneling transistors, achieved through momentum-conserving resonant tunneling of Dirac electrons. Using a small twist angle between graphene layers, we engineered devices exhibiting both electronic and plasmon-polaritonic bistability. This bistable plasmonic behavior can be precisely tuned through load resistance and electrostatic gating. Our findings open new pathways for exploring nonlinear optical and electronic phenomena in van der Waals heterostructures and mark a significant advance in nanoplasmonics, with potential applications in optical memory, sensing, and optoelectronic switching.",
          "authors": [
            "Shuai Zhang",
            "Yang Xu",
            "Junhe Zhang",
            "Dihao Sun",
            "Yinan Dong",
            "Matthew Fu",
            "Takashi Taniguchi",
            "Kenji Watanabe",
            "Cory R. Dean",
            "Monica Allen",
            "Jeffery Allen",
            "F. Javier Garcia de Abajo",
            "Antti J. Moilanen",
            "Lukas Novotny",
            "D. N. Basov"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02911",
          "title": "FluxLab: Creating 3D Printable Shape-Changing Devices with Integrated Deformation Sensing",
          "abstract": "We present FluxLab, a system comprising interactive tools for creating custom 3D-printable shape-changing devices with integrated deformation sensing. To achieve this, we propose a 3D printable nesting structure, consisting of a central SMA channel for sensing and actuation, lattice-based padding in the middle for structural support and controllable elasticity, and parallel helix-based surface wires that preserve the overall form and provide anchoring struts for guided deformation. We developed a design editor to embed these structures into custom 3D models for printing with elastic silicone resin on a consumer-grade SLA 3D printer and minimal post-printing assembly. A deformation authoring tool was also developed for users to build a machine learning-based classifier that distinguishes desired deformation behaviors using inductive sensing. Finally, we demonstrate the potential of our system through example applications, including a self-deformable steamer bowl clip, a remotely controllable gripper, and an interactive desk lamp.",
          "authors": [
            "Hsuanling Lee",
            "Jiakun Yu",
            "Shurui Zheng",
            "Te-Yan Wu",
            "Liang He"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02915",
          "title": "On the distribution of very short character sums",
          "abstract": "We establish a central limit theorem of $(1/\\sqrt{h_p})\\sum_{X< n \\leq X+h_p}\\big(\\tfrac{n}{p}\\big)$ for almost all the primes $p$, with $X$ uniformly random in $[g(p)]$, $g(p)$ an arbitrary divergent function growing slower than any power of $p$, provided $(\\log h_p)/(\\log g(p))\\rightarrow 0, \\, h_p \\rightarrow \\infty$ as $p \\rightarrow \\infty$. This improves the recent results of Basak, Nath and Zaharescu, who established this for $g(p) = (\\log p)^A, A>1$. We also use the best currently available tools to expand the original central limit theorem of Davenport and Erdős for all the primes to a shorter interval of starting points. In this paper we exploit a Selberg's sieve argument, recently used by Harper, an intersection result due to Evertse and Silverman and some consequences of the Weil bound on general character sums.",
          "authors": [
            "Paweł Nosal"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02916",
          "title": "Intervention Strategies for Polarization Switching in Hybrid Improper Ferroelectrics",
          "abstract": "The potential of hybrid improper ferroelectrics (HIFs) in electronic and spintronic devices hinges on their ability to switch polarization. Although the coupling between octahedral rotation and tilt is well established, the factors that govern switching barriers remain elusive. In this study, we explore this area to demonstrate the critical role of causal reasoning in uncovering the mechanisms to control the ferroelectric switching barrier in HIFs. By combining causal discovery, causal interventions, and first-principles simulations, we identify tolerance factor, A-site cation radii mismatch, epitaxial strain, and octahedral rotation/tilt as key parameters and quantify how their interplay directly influences switching barrier. Three key insights emerge from our work: (a) the analysis identifies the structural descriptors controlling polarization reversal across a broad family of A-site-layered double perovskites and superlattices, (b) it uncovers non-trivial, material-specific rotation-tilt mechanisms, including a counterintuitive cooperative pathway where both rotation and tilt change while lowering the barrier, an effect mostly inaccessible to conventional Landau or first-principles-based approaches and (c) it maps these material-specific mechanisms to experimentally realizable parameters, showing that epitaxial strain from orthorhombic substrates (e.g., NdScO$_3$, NdGaO$_3$) selectively tunes octahedral distortions to achieve barrier reduction across varied compositions. These results establish actionable, materials-by-design principles linking composition, structure, and strain to polarization switching, while highlighting the potential of causal reasoning to guide intelligent, mechanism-driven strategies for engineering complex functional oxides.",
          "authors": [
            "Ayana Ghosh",
            "Palanichamy Gayathri",
            "Sathiyamoorthy Buvaneswaran",
            "Saurabh Ghosh"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02919",
          "title": "Congruences for the ratios of Rankin--Selberg $L$-functions",
          "abstract": "A well-known principle states that a congruence between objects should give rise to a corresponding congruence between the special values of $L$-functions attached to these objects. In this article we computationally investigate this principle for Rankin--Selberg $L$-functions attached to pairs of holomorphic cuspforms.",
          "authors": [
            "P. Narayanan",
            "A. Raghuram"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02922",
          "title": "Asymptotics for additive functionals of particle systems via Stein's method",
          "abstract": "We consider additive functionals of systems of random measures whose initial configuration is given by a Poisson point process, and whose individual components evolve according to arbitrary Markovian or non-Markovian measure valued dynamics, with no structural assumptions beyond basic moment bounds. In this setting and under adequate conditions, we establish a general third moment theorem for the normalized functionals. Building on this result, we obtain the first quantitative bounds in the Wasserstein distance for a variety of moving-measure models initialized by Poisson-driven clouds of points, turning qualitative central limit theorems into explicit rates of convergence. The scope of the approach is then demonstrated through several examples, including systems driven by fractional Brownian motion, $\\alpha$-stable processes, uniformly elliptic diffusions, and spectral empirical measures arising from Dyson Brownian motion, all under broad assumptions on the control measure of the initial Poisson configuration. The analysis relies on a combination of Stein's method with Mecke's formula, in the spirit of the Poisson Malliavin-Stein methodology.",
          "authors": [
            "Arturo Jaramillo",
            "Antonio Murillo-Salas"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02922",
          "title": "Asymptotics for additive functionals of particle systems via Stein's method",
          "abstract": "We consider additive functionals of systems of random measures whose initial configuration is given by a Poisson point process, and whose individual components evolve according to arbitrary Markovian or non-Markovian measure valued dynamics, with no structural assumptions beyond basic moment bounds. In this setting and under adequate conditions, we establish a general third moment theorem for the normalized functionals. Building on this result, we obtain the first quantitative bounds in the Wasserstein distance for a variety of moving-measure models initialized by Poisson-driven clouds of points, turning qualitative central limit theorems into explicit rates of convergence. The scope of the approach is then demonstrated through several examples, including systems driven by fractional Brownian motion, $\\alpha$-stable processes, uniformly elliptic diffusions, and spectral empirical measures arising from Dyson Brownian motion, all under broad assumptions on the control measure of the initial Poisson configuration. The analysis relies on a combination of Stein's method with Mecke's formula, in the spirit of the Poisson Malliavin-Stein methodology.",
          "authors": [
            "Arturo Jaramillo",
            "Antonio Murillo-Salas"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02926",
          "title": "Additive functionals of Harmonic samples: the conditioned Dickman regime",
          "abstract": "We study the distributional behavior of additive arithmetic functions evaluated at integers drawn from the harmonic distribution. Our main result shows that a broad family of such functions converges in law to conditioned Dickman-type limits. This contrasts with the Gaussian limits of the classical Erdös-Kac theorem for uniform samples. Our perspective combines the probabilistic representation of harmonic samples via independent geometric variables with analytic inputs such as Mertens' approximation, together with a Poissonization procedure",
          "authors": [
            "Victor Bernal Ramirez",
            "Arturo Jaramillo"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02927",
          "title": "Eisenstein cohomology and congruences for the ratios of Rankin--Selberg $L$-functions",
          "abstract": "A well-known principle states that a congruence between objects should give rise to a corresponding congruence between the special values of $L$-functions attached to these objects. In this article, using the machinery of Eisenstein cohomology after refining it for integral cohomology, we prove an instance of this principle for the ratios of critical values for Rankin--Selberg $L$-functions attached to pairs of holomorphic cuspforms.",
          "authors": [
            "P. Narayanan",
            "A. Raghuram"
          ],
          "primary_category": "math.NT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02928",
          "title": "Time-series forecasting with multiphoton quantum states and integrated photonics",
          "abstract": "Quantum machine learning algorithms have very recently attracted significant attention in photonic platforms. In particular, reconfigurable integrated photonic circuits offer a promising route, thanks to the possibility of implementing adaptive feedback loops, which is an essential ingredient for achieving the necessary nonlinear behavior characteristic of neural networks. Here, we implement a quantum reservoir computing protocol in which information is processed through a reconfigurable linear optical integrated photonic circuit and measured using single-photon detectors. We exploit a multiphoton-based setup for time-series forecasting tasks in a variety of scenarios, where the input signal is encoded in one of the circuit's optical phases, thus modulating the quantum reservoir state. The resulting output probabilities are used to set the feedback phases and, at the end of the computation, are fed to a classical digital layer trained via linear regression to perform predictions. We then focus on the investigation of the role of input photon indistinguishability in the reservoir's capabilities of predicting time-series. We experimentally demonstrate that two-photon indistinguishable input states lead to significantly better performance compared to distinguishable ones. This enhancement arises from the quantum correlations present in indistinguishable states, which enable the system to approximate higher-order nonlinear functions when using comparable physical resources, highlighting the importance of quantum interference and indistinguishability as a resource in photonic quantum reservoir computing.",
          "authors": [
            "Rosario Di Bartolo",
            "Simone Piacentini",
            "Francesco Ceccarelli",
            "Giacomo Corrielli",
            "Roberto Osellame",
            "Valeria Cimini",
            "Fabio Sciarrino"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02930",
          "title": "Phase diagram of the one-dimensional three-state Potts model with an additional mean-field interaction",
          "abstract": "We derive the phase diagram of the one-dimensional three-state Potts model with an additional mean-field interaction in the canonical ensemble. The free energy is obtained by mapping the model onto the spin-$1$ Blume-Emery-Griffiths model and solving it by using an Hubbard-Stratonovich transformation combined with the transfer matrix method. A complex structure with lines of first-order transitions, two triple points and a critical point appears at finite temperature. The phase diagram is two-dimensional, since there are two adjustable parameters, the nearest-neighbour coupling $K$ and the temperature $T$. We show that the phase diagram does not present second-order phase transition lines, due to the fact that the order parameter is not a symmetry-breaking one. Quite remarkably, we are able to determine analytically one of the first-order phase-transition lines. We also prove that, when the nearest-neighbour coupling $K$ is large and negative, the first-order transition temperature becomes asymptotically independent of $K$.",
          "authors": [
            "Alessandro Campa",
            "Vahan Hovhannisyan",
            "Stefano Ruffo",
            "Andrea Trombettoni"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02934",
          "title": "Stability of quantum chaos against weak non-unitarity",
          "abstract": "We study the quantum dynamics generated by the repeated action of a non-unitary evolution operator on a system of qubits. Breaking unitarity can lead to the purification of mixed initial states, which corresponds to the loss of sensitivity to initial conditions, and hence the absence of a key signature of dynamical chaos. However, the scrambling of quantum information can delay purification to times that are exponential in system size. Here we study purification in systems whose evolution operators are fixed in time, where all aspects of the dynamics are in principle encoded in spectral properties of the evolution operator for a single time step. The operators that we study consist of global Haar random unitary operators and non-unitary single-qubit operations. We show that exponentially slow purification arises from a distribution of eigenvalues in the complex plane that forms a ring with sharp edges at large radii, with the eigenvalue density exponentially large near these edges. We argue that the sharp edges of the eigenvalue distribution arise from level attraction along the radial direction in the complex plane. By calculating the spectral form factor we also show that there is level repulsion around the azimuthal direction, even close to the outer edge of the ring of eigenvalues. Our results connect this spectral signature of quantum chaos to the sensitivity of the system to its initial conditions.",
          "authors": [
            "Yi-Cheng Wang",
            "Ehud Altman",
            "Samuel J. Garratt"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02934",
          "title": "Stability of quantum chaos against weak non-unitarity",
          "abstract": "We study the quantum dynamics generated by the repeated action of a non-unitary evolution operator on a system of qubits. Breaking unitarity can lead to the purification of mixed initial states, which corresponds to the loss of sensitivity to initial conditions, and hence the absence of a key signature of dynamical chaos. However, the scrambling of quantum information can delay purification to times that are exponential in system size. Here we study purification in systems whose evolution operators are fixed in time, where all aspects of the dynamics are in principle encoded in spectral properties of the evolution operator for a single time step. The operators that we study consist of global Haar random unitary operators and non-unitary single-qubit operations. We show that exponentially slow purification arises from a distribution of eigenvalues in the complex plane that forms a ring with sharp edges at large radii, with the eigenvalue density exponentially large near these edges. We argue that the sharp edges of the eigenvalue distribution arise from level attraction along the radial direction in the complex plane. By calculating the spectral form factor we also show that there is level repulsion around the azimuthal direction, even close to the outer edge of the ring of eigenvalues. Our results connect this spectral signature of quantum chaos to the sensitivity of the system to its initial conditions.",
          "authors": [
            "Yi-Cheng Wang",
            "Ehud Altman",
            "Samuel J. Garratt"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02935",
          "title": "How Quorum Sensing Shapes Clustering in Active Matter",
          "abstract": "Self-propelled particles undergoing persistent motion can accumulate either through excluded-volume interactions or through quorum sensing, where self-propulsion decreases at high local density. Using kinetic balance theory and simulations, we show that the interplay of these two mechanisms produces a reentrant, non-monotonic behavior in which clustering passes through a pronounced minimum as quorum-sensing strength or persistence time varies. Beyond a threshold quorum-sensing strength, we find long-lived transient states that retain memory of initial conditions, including kinetically arrested active gels. Although quorum sensing can mimic attractive interactions, it also acts strongly in dilute regions, producing an effective cluster bistability that is captured by our theory. Our results explain collective states observed experimentally in synthetic and biological active systems.",
          "authors": [
            "L. de Souza",
            "E.F. Teixeira",
            "G.M. Viswanathan",
            "P. Sollich",
            "P. de Castro"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02937",
          "title": "Transient rebellions in the Kuramoto oscillator: Morse-Smale structural stability and connection graphs of finite 2-shift type",
          "abstract": "The celebrated 1975 Kuramoto model of $N$ identical oscillators with phase angle vector $\\boldsymbol{\\vartheta}=(\\vartheta_1,\\ldots,\\vartheta_N)$ and all-to-all coupling reads \\begin{equation} \\label{*} \\dot\\vartheta_j\\,=\\tfrac{1}{N}\\sum_{k=1}^N \\sin(\\vartheta_k-\\vartheta_j). \\tag{*} \\end{equation} Here we have passed to co-rotating coordinates in normalized time scale. The model is highly accessible to rigorous mathematical analysis, and has been studied as a paradigm for effects like total and partial synchronization. Most initial conditions $\\boldsymbol{\\vartheta}$ lead to total synchronization. The plethora of $2^N-1$ (circles of) partially synchronized states, however, is unstable. The precise behavior of transitions to synchrony seems to have eluded description. In the present paper, we address this gap. By the gradient structure of (*), the global dynamics decompose into equilibria and heteroclinic orbits between them. Except for the extremes of total instability and total synchrony, all equilibria are 2-cluster solutions: their phase angles $\\vartheta_j$ attain only two values, with a phase difference of $\\pi$ between them. Any heteroclinic orbit between 2-cluster equilibria, or towards synchrony, can be realized as a 3-cluster rebellion. Cluster rebellions split the smaller, \"slim\", minority cluster of the source equilibrium and send the rebellious part to join the bigger, \"fat\", majority cluster. Heteroclinic transversality identifies the Kuramoto model as a structurally stable Morse-Smale system. In particular, heteroclinic orbits can be concatenated in finite time. The options involved in successive cluster rebellions amount to finite symbol sequences of 2-shift type. The paper is dedicated to Professor Yoshiki Kuramoto, with admiration.",
          "authors": [
            "Jia-Yuan Dai",
            "Bernold Fiedler",
            "Alejandro López-Nieto"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02938",
          "title": "Magnetic field induced polarization enhancement in the photoluminescence of MBE-grown WSe$_2$ layers",
          "abstract": "We report an experimental study of the magnetic-field dependence of the optically pumped valley polarization in an epitaxial tungsten diselenide (WSe$_2$) monolayer grown by molecular-beam epitaxy (MBE) on a hexagonal boron nitride (hBN) substrate. Circularly polarized photoluminescence (PL) measurements reveal that applying a weak out-of-plane magnetic field, on the order of 0.1 T, dramatically increases the effectiveness of the optical orientation of the emission associated with defect-bound localized excitons. We compare the obtained results with the earlier studies on the reference exfoliated monolayers, discussing both qualitative similarity as well as quantitative differences. Our observations are further supplemented by the results of time-resolved PL measurements, which confirm the pseudospin relaxation time of approximately 25 ps, a value significantly shorter than the $\\approx$100 ps previously reported for mechanically exfoliated samples.",
          "authors": [
            "Maksymilian Kuna",
            "Mateusz Raczyński",
            "Julia Kucharek",
            "Takashi Taniguchi",
            "Kenji Watanabe",
            "Tomasz Kazimierczuk",
            "Wojciech Pacuski",
            "Piotr Kossacki"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02939",
          "title": "Combining Transport of Pendular Water with Wind-Assisted Interfacial Evaporation for Dewatering of Concentrated Slurry Waste",
          "abstract": "Drying concentrated slurry waste is slow, particularly due to the entrapment and limited accessibility of water entrained between the particles in the slurry. A sailboat evaporator with a root-like structure is a new system that enables wind-assisted interfacial evaporation of concentrated particle slurries. In this work, we create access to the disconnected water pockets in concentrated slurry waste, facilitating faster water conduction and efficient evaporation at extremely high solid concentration. The evaporator's long roots effectively extracted water beneath 150 cm deep supernatant water layer. Through replantation of the evaporator to a separate location, an impressive evaporation rate (ER) of 4 kg/(m^2*h) close to 80 wt% solid concentration, a 25% increase to a non-replanted sample. Furthermore, long periods of efficient of evaporation was achieved even at high solid concentration through hydrodynamic flushing of roots. Outdoor experiments achieved substantial volumetric reduction, yielding dried residues with over 75 wt% solid concentration. These results underscore the system's reliable performance against highly concentrated slurries, yet to be by conventional industrial methods, including flocculation and tail-lift drying. The integration of renewable energy coupled with efficient enhancement techniques makes the sailboat evaporator a scalable and sustainable pathway for industrial wastewater dewatering.",
          "authors": [
            "Tanay Kumar",
            "Hongying Zhao",
            "Xuehua Zhang"
          ],
          "primary_category": "physics.app-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02940",
          "title": "Scalable Quantum Walk-Based Heuristics for the Minimum Vertex Cover Problem",
          "abstract": "We propose a novel heuristic quantum algorithm for the Minimum Vertex Cover (MVC) problem based on continuous-time quantum walks (CTQWs). In this framework, the coherent propagation of a quantum walker over a graph encodes its structural properties into state amplitudes, enabling the identification of highly influential vertices through their transition probabilities. To enhance stability and solution quality, we introduce a dynamic decoupling (``freezing'') mechanism that isolates vertices already selected for the cover, preventing their interference in subsequent iterations of the algorithm. The method employs a compact binary encoding, requiring only $\\lceil \\log_2 (V)\\rceil$ qubits to represent a graph with $V$ vertices, resulting in an exponential reduction of quantum resources compared to conventional vertex-based encodings. We benchmark the proposed heuristic against exact solutions obtained via Mixed-Integer Linear Programming (MILP) and against established classical heuristics, including Simulated Annealing, FastVC, and the 2-Approximation algorithm, across Erdős--Rényi, Barabási--Albert and regular random graph ensembles. Our results demonstrate that the CTQW-based heuristic consistently achieves superior approximation ratios and exhibits remarkable robustness with respect to network topology, outperforming classical approaches in both heterogeneous and homogeneous structures. These findings indicate that continuous-time quantum walks, when combined with topology-independent decoupling strategies, provide a powerful paradigm for large-scale combinatorial optimization and complex network control, with potential applications spanning infrastructure resilience, epidemic containment, sensor network optimization, and biological systems analysis.",
          "authors": [
            "F. S. Luiz",
            "A. K. F. Iwakami",
            "D. H. Moraes",
            "M. C. de Oliveira"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02941",
          "title": "Pseudocodewords of quantum, quasi-cyclic, and spatially-coupled LDPC codes: a fundamental cone perspective",
          "abstract": "While low-density parity-check (LDPC) codes are near capacity-achieving when paired with iterative decoders, these decoders may not output a codeword due to the existence of pseudocodewords. Thus, pseudocodewords have been studied to give insight into the performance of modern decoders including iterative and linear programming decoders. These pseudocodewords are found to be dependent on the parity-check matrix of the code and the particular decoding algorithm used. In this paper, we consider LP decoding, which has been linked to graph cover decoding, providing functions which capture these pseudocodewords. In particular, we analyze the underlying structure of pseudocodewords from quantum stabilizer codes that arise from LP decoding, quasi-cyclic LDPC codes, and spatially-coupled LDPC codes.",
          "authors": [
            "Wittawat Kositwattanarerk",
            "Gretchen L. Matthews",
            "Emily McMillon",
            "Tunchanok Yutitumsatit"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02941",
          "title": "Pseudocodewords of quantum, quasi-cyclic, and spatially-coupled LDPC codes: a fundamental cone perspective",
          "abstract": "While low-density parity-check (LDPC) codes are near capacity-achieving when paired with iterative decoders, these decoders may not output a codeword due to the existence of pseudocodewords. Thus, pseudocodewords have been studied to give insight into the performance of modern decoders including iterative and linear programming decoders. These pseudocodewords are found to be dependent on the parity-check matrix of the code and the particular decoding algorithm used. In this paper, we consider LP decoding, which has been linked to graph cover decoding, providing functions which capture these pseudocodewords. In particular, we analyze the underlying structure of pseudocodewords from quantum stabilizer codes that arise from LP decoding, quasi-cyclic LDPC codes, and spatially-coupled LDPC codes.",
          "authors": [
            "Wittawat Kositwattanarerk",
            "Gretchen L. Matthews",
            "Emily McMillon",
            "Tunchanok Yutitumsatit"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02944",
          "title": "The Convex Matching Distance in Multiparameter Persistence",
          "abstract": "We introduce the convex matching distance, a novel metric for comparing functions with values in the real plane. This metric measures the maximal bottleneck distance between the persistence diagrams associated with the convex combinations of the two function components. Similarly to the traditional matching distance, the convex matching distance aggregates the information provided by two real-valued components. However, whereas the matching distance depends on two parameters, the convex matching distance depends on only one, offering improved computational efficiency. We further show that the convex matching distance can be more discriminative than the traditional matching distance in certain cases, although the two metrics are generally not comparable. Moreover, we prove that the convex matching distance is stable and characterize the coefficients of the convex combination at which it is attained. Finally, we demonstrate that this new aggregation framework benefits from the computational advantages provided by the Pareto grid, a collection of curves in the plane whose points lie in the image of the Pareto critical set associated with functions assuming values on the real plane.",
          "authors": [
            "Patrizio Frosini",
            "Ulderico Fugacci",
            "Eloy Mosig García",
            "Nicola Quercioli",
            "Sara Scaramuccia",
            "Francesca Tombari"
          ],
          "primary_category": "math.AT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02945",
          "title": "Exceptional Point Dynamics in Photonic Time Crystals for Enhanced Optical Sensing",
          "abstract": "Exceptional points (EPs) in non-Hermitian photonics offer singular sensitivity enhancements but have thus far been realized almost exclusively in spatially engineered platforms with fixed geometries and limited tunability. Here we extend EP physics into the temporal domain by introducing balanced gain--loss modulation in a photonic time crystal (PTC). A time-periodic refractive-index modulation $n(t)=n_{0}+\\delta n\\cos(\\Omega t)$ generates an effective non-Hermitian Floquet Hamiltonian that supports coalescence of quasi-eigenmodes in frequency space, constituting a genuine \\textit{temporal exceptional point}. Using a reduced two-mode model for the dominant frequency sidebands, we derive a non-Hermitian dimer Hamiltonian $H_{\\mathrm{PT}}(\\Delta,\\gamma,\\kappa)$ that is strictly $\\mathcal{PT}$-symmetric for $\\Delta=0$ and identify the exact EP condition. Numerical analysis reveals the associated Riemann-sheet topology, mode exchange and Berry-phase accumulation upon encirclement of the EP, and the characteristic $\\sqrt{\\varepsilon}$ perturbation response indicative of enhanced sensing. We further construct a non-Hermitian transmission model that is exact within the reduced two-mode description, compute the Cramér--Rao bound (CRB) for temperature estimation under an explicit noise model, and show that EP-enhanced sensitivity persists when compared to a linewidth-matched Hermitian reference under identical resource constraints. Monte Carlo simulations confirm that the CRB is saturable using spectral measurements. These results establish temporal non-Hermiticity as a new paradigm for dynamically reconfigurable, broadband, and geometry-independent exceptional-point photonics.",
          "authors": [
            "Saurabh Mani Tripathi",
            "Shalini Kumari",
            "Krishnan Kundan",
            "Neha Ahlawat"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02946",
          "title": "Unipotent quantum coordinate ring and minuscule prefundamental representations: twisted case",
          "abstract": "We study the prefundamental modules $L_{s,a}^{\\pm}$ over the Borel subalgebras of the twisted quantum loop algebras, which are introduced by Wang. A character formula for $L_{s,a}^{\\pm}$ is obtained from that for the prefundamental modules over the untwisted quantum loop algebras by applying a character folding map. This allows us to realize minuscule prefundamental modules $L_{s,a}^{\\pm}$ for types $A_{2n-1}^{(2)}$ and $D_{n+1}^{(2)}$ in terms of the unipotent quantum coordinate ring associated with the fundamental $s$-th coweight, where $s = 1$ for type $A_{2n-1}^{(2)}$ and $s = n$ for type $D_{n+1}^{(2)}$. This result is a continuation of the realization of (co)minuscule prefundamental modules established by earlier works [J-Kwon-Park, Int. Math. Res. Not., 2023] and [J-Kwon-Park, J. Algebra, 2025].",
          "authors": [
            "Il-Seung Jang"
          ],
          "primary_category": "math.RT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02948",
          "title": "Universality Diagram of Phase Transitions in Long-range Statistical Systems",
          "abstract": "The percolation, Ising, and O($n$) models constitute fundamental systems in statistical and condensed matter physics. For short-range-interacting cases, the nature of their phase transitions is well established by renormalization-group theory. However, the universality of the transitions in these models remains elusive when algebraically decaying long-range interactions $\\sim 1/r^{d+\\sigma}$ are introduced, where $d$ is the dimensionality and $\\sigma$ is the decay exponent. Building upon insights from Lévy flight, i.e., long-range simple random walk, we propose three universality diagrams in the $(d,\\sigma)$ plane for the percolation model, the O($n$) model, and the Fortuin-Kasteleyn Ising model, respectively. The conjectured universality diagrams are consistent with recent high-precision numerical studies and rigorous mathematical results, offering a unified perspective on critical phenomena in systems with long-range interactions.",
          "authors": [
            "Tianning Xiao",
            "Zhijie Fan",
            "Youjin Deng"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02949",
          "title": "Zero modes and geometric phase for 2D Weyl fermions on Lifshitz backgrounds",
          "abstract": "Here we investigate analytical properties of Weyl fermions in (2+1)-dimensional Lifshitz spacetimes. In particular, we are interested in obtaining geometric phases and verifying the existence of well-behaved fermionic zero modes. Using the Dirac phase method, we show how geometric phases naturally arise from the coupling between the fermionic fields and the Lifshitz geometry. We also present exact solutions of the zero modes by rewriting the Weyl equation as a system of supersymmetric equations.",
          "authors": [
            "G. Q. Garcia",
            "D. C. Moreira",
            "E. Cavalcante",
            "C. Furtado"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02950",
          "title": "Formation of bosonic $^{23}$Na$^{41}$K Feshbach molecules",
          "abstract": "Ultracold Feshbach molecules are a crucial intermediate step for the creation of quantum degenerate gases of strongly dipolar molecules. After coherent transfer to the rovibrational ground state, these dimers can realize stable dipolar gases with strong, tunable long-range interactions. Here, we report the creation of bosonic $^{23}$Na$^{41}$K Feshbach molecules by radio-frequency (RF) association. An RF pulse applied on the molecular side of an interspecies Feshbach resonance at 73.6(1)~G associates up to $1.1(1)\\times10^4$ molecules from a thermal mixture of $^{23}$Na and $^{41}$K atoms. Measurements of the binding energy reveal a broad resonance width of 5.1(2)~G, facilitating robust control over interspecies interactions. The molecule lifetime in the presence of background atoms exceeds 2~ms, extending to 7~ms after removal of $^{23}$Na. These results constitute a key step toward the production of ultracold $^{23}$Na$^{41}$K ground state molecules for the exploration of novel many-body phenomena in strongly dipolar Bose gases.",
          "authors": [
            "Sungjun Lee",
            "Younghoon Lim",
            "Jongyeol Kim",
            "Jaeryeong Chang",
            "Jee Woo Park"
          ],
          "primary_category": "cond-mat.quant-gas",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02950",
          "title": "Formation of bosonic $^{23}$Na$^{41}$K Feshbach molecules",
          "abstract": "Ultracold Feshbach molecules are a crucial intermediate step for the creation of quantum degenerate gases of strongly dipolar molecules. After coherent transfer to the rovibrational ground state, these dimers can realize stable dipolar gases with strong, tunable long-range interactions. Here, we report the creation of bosonic $^{23}$Na$^{41}$K Feshbach molecules by radio-frequency (RF) association. An RF pulse applied on the molecular side of an interspecies Feshbach resonance at 73.6(1)~G associates up to $1.1(1)\\times10^4$ molecules from a thermal mixture of $^{23}$Na and $^{41}$K atoms. Measurements of the binding energy reveal a broad resonance width of 5.1(2)~G, facilitating robust control over interspecies interactions. The molecule lifetime in the presence of background atoms exceeds 2~ms, extending to 7~ms after removal of $^{23}$Na. These results constitute a key step toward the production of ultracold $^{23}$Na$^{41}$K ground state molecules for the exploration of novel many-body phenomena in strongly dipolar Bose gases.",
          "authors": [
            "Sungjun Lee",
            "Younghoon Lim",
            "Jongyeol Kim",
            "Jaeryeong Chang",
            "Jee Woo Park"
          ],
          "primary_category": "cond-mat.quant-gas",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02955",
          "title": "Quantum hypergraph states: a concise review",
          "abstract": "Quantum hypergraph states emerged in the literature as a generalization of graph states, and since then, much has been developed in the direction of implementing this class of genuine multipartite entangled states for quantum information and computation. Here, we review the definition of hypergraph states and their main applications so far, both in discrete-variable and continuous-variable quantum information.",
          "authors": [
            "Vinícius Salem"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02956",
          "title": "Slices for reductive group actions in algebraic and holomorphic symplectic geometry",
          "abstract": "Symplectic slice theorems elucidate the local structure of symplectic manifolds carrying Hamiltonian actions of compact Lie groups. We generalize these theorems in two natural settings. The first is based on the idea that complex reductive algebraic groups are the natural complex-geometric counterparts of compact Lie groups. Using new definitions of Poisson and symplectic slices, we prove analogues of the classical symplectic slice theorems for Hamiltonian actions of complex reductive algebraic groups. These analogues have versions in the complex-algebraic and holomorphic categories, and make extensive use of Slodowy slices and decomposition classes in complex reductive Lie algebras. The starting point for our second setting is the fact that Hamiltonian Lie group actions are special cases of Hamiltonian symplectic groupoid actions. We generalize the classical symplectic slice theorems to the latter case.",
          "authors": [
            "Peter Crooks",
            "Rebecca Goldin",
            "Yiannis Loizides"
          ],
          "primary_category": "math.SG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02957",
          "title": "Systematic construction of ROCN Bell-inequalities",
          "abstract": "Self-testing constitutes one of the most powerful forms of device certification, enabling a complete and device-independent characterization of a quantum apparatus solely from the observed correlations. In recent work by the authors [23], a general framework was introduced for constructing Bell inequalities that self-test entire families of Clifford generators. In this manuscript, we develop an alternative and complementary self-testing criterion based on symmetric spanning sets. This formulation provides an explicit and constructive route to designing self-testing Bell inequalities in arbitrary dimensions.",
          "authors": [
            "Arturo Konderak",
            "Patryk Michalski"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02958",
          "title": "Generalized Zykov's Theorem",
          "abstract": "For a simple graph $G$, let $n$ denote its number of vertices, and let $N(G,K_t)$ denote the number of copies of $K_t$ in $G$. Zykov's theorem asserts that for any $K_{r+1}$-free graph and $t \\ge 2$, \\[ N(G,K_t) \\le {r \\choose t}\\left(\\frac{n}{r}\\right)^t \\] We generalize Zykov's bound within a vertex-based localization framework. For each vertex $v \\in V(G)$, let $c(v)$ denote the order of the largest clique containing $v$. In this paper, we show that \\[ N(G,K_t) \\le n^{t-1} \\sum_{v \\in V(G)} \\frac{1}{c(v)^t} {c(v) \\choose t} \\] We further show that equality holds if and only if $G$ is a regular complete multipartite graph. \\newline Note that if we impose the condition that, $G$ is $K_{r+1}$-free, then $c(v) \\leq r$ for all $v \\in V(G)$. Thus, plugging $c(v) = r$ for all $v \\in V(G)$, we retrieve Zykov's bound.",
          "authors": [
            "Rajat Adak",
            "L. Sunil Chandran"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02959",
          "title": "Bright and dark breathers on an elliptic wave in the defocusing mKdV equation",
          "abstract": "Breathers on an elliptic wave background consist of nonlinear superpositions of a soliton and a periodic wave, both traveling with different wave speeds and interacting periodically in the space-time. For the defocusing modified Korteweg-de Vries (mKdV) equation, the construction of general breathers has been an open problem since the elliptic wave is related to the elliptic degeneration of the hyperelliptic solutions of genus two. We have found the new representation of eigenfunctions of the Lax operator associated with the elliptic wave, which enables us to solve this open problem and to construct two families of breathers with bright (elevation) and dark (depression) profiles.",
          "authors": [
            "Dmitry E. Pelinovsky",
            "Rudi Weikard"
          ],
          "primary_category": "nlin.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02959",
          "title": "Bright and dark breathers on an elliptic wave in the defocusing mKdV equation",
          "abstract": "Breathers on an elliptic wave background consist of nonlinear superpositions of a soliton and a periodic wave, both traveling with different wave speeds and interacting periodically in the space-time. For the defocusing modified Korteweg-de Vries (mKdV) equation, the construction of general breathers has been an open problem since the elliptic wave is related to the elliptic degeneration of the hyperelliptic solutions of genus two. We have found the new representation of eigenfunctions of the Lax operator associated with the elliptic wave, which enables us to solve this open problem and to construct two families of breathers with bright (elevation) and dark (depression) profiles.",
          "authors": [
            "Dmitry E. Pelinovsky",
            "Rudi Weikard"
          ],
          "primary_category": "nlin.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02959",
          "title": "Bright and dark breathers on an elliptic wave in the defocusing mKdV equation",
          "abstract": "Breathers on an elliptic wave background consist of nonlinear superpositions of a soliton and a periodic wave, both traveling with different wave speeds and interacting periodically in the space-time. For the defocusing modified Korteweg-de Vries (mKdV) equation, the construction of general breathers has been an open problem since the elliptic wave is related to the elliptic degeneration of the hyperelliptic solutions of genus two. We have found the new representation of eigenfunctions of the Lax operator associated with the elliptic wave, which enables us to solve this open problem and to construct two families of breathers with bright (elevation) and dark (depression) profiles.",
          "authors": [
            "Dmitry E. Pelinovsky",
            "Rudi Weikard"
          ],
          "primary_category": "nlin.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02960",
          "title": "Conservation of Momentum and Energy in the Lorenz-Abraham-Dirac Equation of Motion",
          "abstract": "After a brief review of the modified causal Lorentz-Abraham classical equation of motion for an extended charged sphere and its limit to the mass-renormalized modified causal Lorentz-Abraham-Dirac equation of motion as the radius of the charged sphere approaches zero, a streamlined derivation is given for the conditions on the external force required for these modified equations of motion to satisfy conservation of momentum and energy.",
          "authors": [
            "Arthur D. Yaghjian"
          ],
          "primary_category": "physics.class-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02961",
          "title": "Reflective Metalenses for Near-Infrared Wavelengths Based on Silicon Nanorods",
          "abstract": "This paper presents the design and analysis of reflective metalenses optimized for a 900 nm wavelength, using silicon nanorods as the primary components. The metalens consists of unit cells, each containing a thin silicon rod. Lumerical FDTD software is used to create a detailed library that connects the dimensions of these nanorods with their respective phase shifts and reflectance properties. The nanorods are placed on a 70 nm thick silicon dioxide (SiO2) layer, with a 50 nm thick gold (Au) reflective layer underneath. In contrast to conventional transmissive metalenses, our design accomplishes complete 2{\\pi} phase control via geometry-optimized silicon nanorods, facilitating compact reflective optics. By carefully examining the impact of nanorod dimensions on optical performance, the main goal is to optimize the metalens design for enhanced light focusing and manipulation, which could benefit imaging systems, optical communications, and sensor technology.",
          "authors": [
            "Iftekhar Ahmed",
            "K. B. M. Sharif Mahmood",
            "Tanvin Tamanna"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02962",
          "title": "Spinons and Spin-Charge Separation at the Deconfined Quantum Critical Point",
          "abstract": "Using quantum Monte Carlo and numerical analytic continuation methods, we study the dynamic spin structure factor and the single-hole spectral function of a two-dimensional quantum magnet ($J$-$Q$ model) at its quantum phase transition separating Néel antiferromagnetic and spontaneously dimerized ground states. At this putative deconfined quantum-critical point, we find a broad continuum of spinon excitations that can be accounted for by the fermionic $\\pi$-flux state; a known mean-field model for deconfined quantum criticality. We find that the best description of the two-spinon continuum is with a version of the model with a $2\\times 2$ unit cell, reflecting non-trivial mutual statistics of spinons and anti-spinons. The single-hole spectral function can be described by the same spinon dispersion relation and an independently propagating holon. Thus, the system exhibits spin-charge separation and will likely evolve into an extended holon metal phase at finite doping.",
          "authors": [
            "Sibin Yang",
            "Anders W. Sandvik"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02963",
          "title": "Probing the Microscopic Origin of Toughness in Multiple Polymer Networks",
          "abstract": "Multiple polymer networks, such as double-network elastomers comprising a sacrificial and a matrix network, exhibit exceptional mechanical resilience, commonly attributed to the formation of an extended damage zone before a crack can grow. However, the microscopic mechanisms underlying their toughness remain poorly understood. Here, we combine advanced light scattering methods and molecular dynamics simulations to explore the microscopic relaxation dynamics and stress redistribution at the polymer strand scale of single-network and double-network elastomers under uni-axial loading. Dynamic light scattering experiments show that microscopic rearrangements and bond-breaking events are localized near the crack tip in single networks, readily causing the crack to advance. In contrast, double networks exhibit delocalized microscopic rearrangements well ahead of and not directly correlated with crack propagation, enabling the dissipation of energy over broader regions and timescales. Numerical simulations of the damage zone show that bond breaking in the matrix network of double networks leads to widespread stress redistribution, mitigating catastrophic damage localization. This enhanced ability to redistribute stress in a non-local manner allows a much larger extension before localized macroscopic failure occurs, explaining the superior toughness of double networks. Our findings identify early, delocalized bond-breaking events combined with more efficient dissipation pathways through enhanced microscopic rearrangements as the key microscopic mechanisms responsible for the outstanding toughness and extensibility of multiple elastomer networks.",
          "authors": [
            "Nicholas H. P. Orr",
            "Magali Le Goff",
            "Burebi Yiming",
            "Jean-Louis Barrat",
            "Mehdi Bouzid",
            "Laurence Ramos",
            "Costantino Creton",
            "Kirsten Martens",
            "Luca Cipelletti"
          ],
          "primary_category": "cond-mat.soft",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02964",
          "title": "Universal nondiffractive topological spin textures in vortex cores of light and sound",
          "abstract": "We report universal skyrmionic spin textures in the cores of optical and acoustic vortex beams, described within the framework of Laguerre-Gaussian modes. We analytically demonstrate nondiffractive propagating spin merons, independent of whether the field is transverse or longitudinal, with their sign controlled by the wavefront helicity. Experimental confirmation is provided in acoustics through full three-dimensional measurements of the velocity vector field. Although these phenomena are intrinsic to vortex cores, we also show that the claimed universality breaks down for higher-order topological charges, depending on the carrier mode, here exemplified using the Bessel framework.",
          "authors": [
            "Elena Annenkova",
            "Andrei Afanasev",
            "Etienne Brasselet"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02964",
          "title": "Universal nondiffractive topological spin textures in vortex cores of light and sound",
          "abstract": "We report universal skyrmionic spin textures in the cores of optical and acoustic vortex beams, described within the framework of Laguerre-Gaussian modes. We analytically demonstrate nondiffractive propagating spin merons, independent of whether the field is transverse or longitudinal, with their sign controlled by the wavefront helicity. Experimental confirmation is provided in acoustics through full three-dimensional measurements of the velocity vector field. Although these phenomena are intrinsic to vortex cores, we also show that the claimed universality breaks down for higher-order topological charges, depending on the carrier mode, here exemplified using the Bessel framework.",
          "authors": [
            "Elena Annenkova",
            "Andrei Afanasev",
            "Etienne Brasselet"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02971",
          "title": "Preconditioning a hybridizable discontinuous Galerkin method for Navier-Stokes at high Reynolds number",
          "abstract": "We introduce a preconditioner for a hybridizable discontinuous Galerkin discretization of the linearized Navier-Stokes equations at high Reynolds number. The preconditioner is based on an augmented Lagrangian approach of the full discretization. Unlike standard grad-div type augmentation, however, we consider augmentation based on divergence-conformity. With this augmentation we introduce two different, well-conditioned, and easy to solve matrices to approximate the trace pressure Schur complement. To introduce a completely algebraic solver, we propose to use multifrontal sparse LU solvers using butterfly compression to solve the trace velocity block. Numerical examples demonstrate that the trace pressure Schur complement is highly robust in mesh spacing and Reynolds number and that the multifrontal inexact LU performs well for a wide range of Reynolds numbers.",
          "authors": [
            "Alexander D. Lindsay",
            "Sander Rhebergen",
            "Ben S. Southworth"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02971",
          "title": "Preconditioning a hybridizable discontinuous Galerkin method for Navier-Stokes at high Reynolds number",
          "abstract": "We introduce a preconditioner for a hybridizable discontinuous Galerkin discretization of the linearized Navier-Stokes equations at high Reynolds number. The preconditioner is based on an augmented Lagrangian approach of the full discretization. Unlike standard grad-div type augmentation, however, we consider augmentation based on divergence-conformity. With this augmentation we introduce two different, well-conditioned, and easy to solve matrices to approximate the trace pressure Schur complement. To introduce a completely algebraic solver, we propose to use multifrontal sparse LU solvers using butterfly compression to solve the trace velocity block. Numerical examples demonstrate that the trace pressure Schur complement is highly robust in mesh spacing and Reynolds number and that the multifrontal inexact LU performs well for a wide range of Reynolds numbers.",
          "authors": [
            "Alexander D. Lindsay",
            "Sander Rhebergen",
            "Ben S. Southworth"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02971",
          "title": "Preconditioning a hybridizable discontinuous Galerkin method for Navier-Stokes at high Reynolds number",
          "abstract": "We introduce a preconditioner for a hybridizable discontinuous Galerkin discretization of the linearized Navier-Stokes equations at high Reynolds number. The preconditioner is based on an augmented Lagrangian approach of the full discretization. Unlike standard grad-div type augmentation, however, we consider augmentation based on divergence-conformity. With this augmentation we introduce two different, well-conditioned, and easy to solve matrices to approximate the trace pressure Schur complement. To introduce a completely algebraic solver, we propose to use multifrontal sparse LU solvers using butterfly compression to solve the trace velocity block. Numerical examples demonstrate that the trace pressure Schur complement is highly robust in mesh spacing and Reynolds number and that the multifrontal inexact LU performs well for a wide range of Reynolds numbers.",
          "authors": [
            "Alexander D. Lindsay",
            "Sander Rhebergen",
            "Ben S. Southworth"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02974",
          "title": "Altermagnetoelectric Spin Field Effect Transistor",
          "abstract": "Spin field-effect transistors (SFETs) are promising candidates for low-power spin-based electronics, yet existing realizations that rely on spin-orbit coupling are constrained by limited material choices and short spin-coherence lengths. Here we propose a different operating principle based on multiferroic altermagnets, in which spin splitting is tuned by an electric field through symmetry control rather than conventional spin-orbit physics. Using an effective model combined with quantum transport simulations, we show that the conductance is determined by the degree of matching between the electrically controlled spin texture of the channel and the fixed spin polarization of ferromagnetic contacts, enabling clear ON and OFF states. Remarkably, we also address a long-standing challenge in multiferroic device design: spintronic channels require metallic carriers, whereas ferroelectricity is usually suppressed in metals. We resolve this conflict by imprinting multiferroic altermagnetism into highly conductive materials via the proximity effect. First-principles calculations for graphene on multiferroic vanadium sulfide halides confirm that graphene acquires a ferroelectrically switchable spin splitting while retaining its metallic character. These results establish a practical route to SFET implementation and identify multiferroic altermagnets as a versatile platform for next-generation spintronic devices.",
          "authors": [
            "Ziye Zhu",
            "Xianzhang Chen",
            "Xunkai Duan",
            "Zhou Cui",
            "Jiayong Zhang",
            "Igor Zutic",
            "Tong Zhou"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02975",
          "title": "Stochastic parallel transport on the Wasserstein space and equivariant diffusions on the group of diffeomorphisms over a closed Riemannian manifold",
          "abstract": "In this work, we establish the existence of solutions to stochastic differential equations on the Wasserstein space over a closed Riemannian manifold, under suitable regularity assumptions on the driving vector fields. Interpreting the diffeomorphism group $\\mathscr{D}$ as a Riemannian submersion onto the smooth Wasserstein space $¶_\\infty$, we further prove the existence and uniqueness of the stochastic parallel parallel transport along diffusions on $¶_\\infty$. Finally, we show that equivariant diffusions on $\\mathscr{D}$ endowed with a principal bundle structure over $¶_\\infty$ admit a unique factorization into a horizontal diffusion and a vertical component expressed as a right exponential of a process taking values in the Lie algebra $\\mathfrak{g}$ of the group $G$ of volume preserving diffeomorphisms.",
          "authors": [
            "Aymeric Martin"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02976",
          "title": "Many-body $k$-local ground states as probes for unitary quantum metrology",
          "abstract": "Multipartite quantum states saturating the Heisenberg limit of sensitivity typically require full-body correlators to be prepared. On the other hand, experimentally practical Hamiltonians often involve few-body correlators only. Here, we study the metrological performances under this constraint, using tools derived from the quantum Fisher information. Our work applies to any encoding generator, also including a dependence on the parameter. We find that typical random symmetric ground states of $k$-body permutation-invariant Hamiltonians exhibit Heisenberg scaling. Finally, we establish a tradeoff between the Hamiltonian's gap, which quantifies preparation hardness, and the quantum Fisher information of the corresponding ground state.",
          "authors": [
            "Majid Hassani",
            "Mengyao Hu",
            "Guillem Müller-Rigat",
            "Matteo Fadel",
            "Jordi Tura"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02977",
          "title": "On the ellipticity of the higher rank numerical range",
          "abstract": "The higher rank numerical range is a concept that generalizes the classical numerical range, and it has application in quantum error correction. We investigate these sets for $2$-by-$2$ block matrices with associated Kippenhahn curves consisting of ellipses (and eventually points). As a consequence, elliptical higher rank numerical range results are derived in a unified way, using an approach developed by Spitkovsky {\\it et al}.",
          "authors": [
            "Natália Bebiano",
            "Rute Lemos",
            "Graça Soares"
          ],
          "primary_category": "math.FA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02979",
          "title": "New insights into hydrogen-assisted intergranular cracking in nickel",
          "abstract": "We characterize the grain boundary (GB) susceptibility to hydrogen-assisted intergranular cracking in pure nickel as a function of coincident site lattice value ($\\Sigma$-n), over a wide range of hydrogen concentrations (4 to 14 wppm). Cracks on the surface and within the bulk material were identified across the entire gauge region of the specimens. The susceptibility of GBs to crack initiation and propagation was evaluated by separating cracks containing single GB or multiple GBs. A larger loss in fracture strain, a smaller reduction in area, and an increase in the percentage of intergranular fracture indicated a higher degree of embrittlement at elevated hydrogen concentrations. The number of cracks was significantly higher on the surface than in the bulk for the most severe hydrogen charging conditions ($\\geq$ 8 wppm), while a similar number was observed for lower concentrations. The propensity for hydrogen-assisted intergranular cracking at different types of GBs on the surface and in the bulk material was consistent, indicating that while cathodic charging can promote surface cracks, it does not significantly impact the GBs relative susceptibility. The $\\Sigma$-3 boundaries were the most resistant to cracking, as evidenced by the considerably lower fraction of these GBs exhibiting intergranular cracking at all hydrogen concentrations considered. This contrasts literature findings for Ni alloys and can be explained by the segregation energies and reductions in the cohesive strength with hydrogen, with less favorable trapping at the $\\Sigma$-3 boundaries. No evidence of plasticity-mediated cracking initiation was observed.",
          "authors": [
            "S. Quan",
            "A. Zafra",
            "E. Martínez-Pañeda",
            "C. Wu",
            "Z.D. Harris",
            "L. Cupertino-Malheiros"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02979",
          "title": "New insights into hydrogen-assisted intergranular cracking in nickel",
          "abstract": "We characterize the grain boundary (GB) susceptibility to hydrogen-assisted intergranular cracking in pure nickel as a function of coincident site lattice value ($\\Sigma$-n), over a wide range of hydrogen concentrations (4 to 14 wppm). Cracks on the surface and within the bulk material were identified across the entire gauge region of the specimens. The susceptibility of GBs to crack initiation and propagation was evaluated by separating cracks containing single GB or multiple GBs. A larger loss in fracture strain, a smaller reduction in area, and an increase in the percentage of intergranular fracture indicated a higher degree of embrittlement at elevated hydrogen concentrations. The number of cracks was significantly higher on the surface than in the bulk for the most severe hydrogen charging conditions ($\\geq$ 8 wppm), while a similar number was observed for lower concentrations. The propensity for hydrogen-assisted intergranular cracking at different types of GBs on the surface and in the bulk material was consistent, indicating that while cathodic charging can promote surface cracks, it does not significantly impact the GBs relative susceptibility. The $\\Sigma$-3 boundaries were the most resistant to cracking, as evidenced by the considerably lower fraction of these GBs exhibiting intergranular cracking at all hydrogen concentrations considered. This contrasts literature findings for Ni alloys and can be explained by the segregation energies and reductions in the cohesive strength with hydrogen, with less favorable trapping at the $\\Sigma$-3 boundaries. No evidence of plasticity-mediated cracking initiation was observed.",
          "authors": [
            "S. Quan",
            "A. Zafra",
            "E. Martínez-Pañeda",
            "C. Wu",
            "Z.D. Harris",
            "L. Cupertino-Malheiros"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02980",
          "title": "Tunable polarization-entangled near-infrared photons from orthogonal GaAs nanowires",
          "abstract": "Quantum entanglement is a fundamental resource for emerging quantum technologies, enabling secure communication and enhanced sensing. For decades, generating polarization entangled states has been mainly achieved using bulk crystals with spontaneous parametric down conversion (SPDC), preventing scalability and on-chip integration. Miniaturizing the quantum source provides access to more versatility and tunability while enabling an easier integration to other devices, notably necessary for satellite-based quantum communication, and eventually reducing fabrication costs. This challenging task can be achieved with Zinc Blende GaAs nanowires. They already have shown an efficient photon pairs generation via SPDC at 1550 nm. Here we demonstrate that a pair of orthogonal GaAs nanowires constitutes a new nanoscale platform to control the quantum state at telecommunication wavelength, enabling a transition from polarization entangled to separable states as a function of the pump polarization, with fidelities reaching 90%",
          "authors": [
            "Elise Bailly-Rioufreyt",
            "Zoya Polshchykova",
            "Grégoire Saerens",
            "Wenhe Jia",
            "Thomas Dursap",
            "Andreas Maeder",
            "Philippe Regreny",
            "Robert J. Chapman",
            "Helena Weigand",
            "Alexandre Danescu",
            "Nicolas Chauvin",
            "José Penuelas",
            "Rachel Grange"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02980",
          "title": "Tunable polarization-entangled near-infrared photons from orthogonal GaAs nanowires",
          "abstract": "Quantum entanglement is a fundamental resource for emerging quantum technologies, enabling secure communication and enhanced sensing. For decades, generating polarization entangled states has been mainly achieved using bulk crystals with spontaneous parametric down conversion (SPDC), preventing scalability and on-chip integration. Miniaturizing the quantum source provides access to more versatility and tunability while enabling an easier integration to other devices, notably necessary for satellite-based quantum communication, and eventually reducing fabrication costs. This challenging task can be achieved with Zinc Blende GaAs nanowires. They already have shown an efficient photon pairs generation via SPDC at 1550 nm. Here we demonstrate that a pair of orthogonal GaAs nanowires constitutes a new nanoscale platform to control the quantum state at telecommunication wavelength, enabling a transition from polarization entangled to separable states as a function of the pump polarization, with fidelities reaching 90%",
          "authors": [
            "Elise Bailly-Rioufreyt",
            "Zoya Polshchykova",
            "Grégoire Saerens",
            "Wenhe Jia",
            "Thomas Dursap",
            "Andreas Maeder",
            "Philippe Regreny",
            "Robert J. Chapman",
            "Helena Weigand",
            "Alexandre Danescu",
            "Nicolas Chauvin",
            "José Penuelas",
            "Rachel Grange"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02984",
          "title": "Dualities and trialities in $\\mathcal{N}=2$ supersymmetric gauged quantum mechanics",
          "abstract": "We study new Seiberg-like dualities for 1d $\\mathcal{N}=2$ supersymmetric gauge theories -- that is, supersymmetric gauged quantum mechanics -- with unitary gauge group and (anti)fundamental matter in chiral and fermi multiplets, and with non-zero Fayet--Iliopoulos parameter. Similarly to its higher-dimensional analogues, this 1d Seiberg duality is an infrared duality: the supersymmetric ground states of the dual gauge theories match exactly. We provide strong evidence for the dualities, including the matching of the flavoured Witten indices, a Higgs-branch derivation in terms of dual Grassmannian manifolds, and a detailed study of the Coulomb-branch ground states in the abelian case. We study how the supersymmetric ground states, in either dual description, depend on the sign of the Fayet--Iliopoulos parameter, and we explore the corresponding wall-crossing phenomenon. For some special values of the discrete parameters defining the unitary gauge theory, the dualities, combined with trivial wall-crossing, enhances to a triality. This includes, as a special case, the dimensional reduction to 1d of the 2d $\\mathcal{N}=(0,2)$ Gadde--Gukov--Putrov triality.",
          "authors": [
            "Cyril Closset",
            "James Wynne"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02986",
          "title": "Equivalence of Synchronization States in the Hybrid Kuramoto Flow",
          "abstract": "We establish a unified synchronization framework for the all-to-all hybrid Kuramoto model that couples first- and second-order oscillators within a single dynamical system. Although the Kuramoto model has become one of the most widely used paradigms for describing synchronization phenomena-appearing in more than 100,000 scientific studies-the fundamental relationships among distinct synchronization states remain unresolved. In this work, we rigorously prove that full phase-locking, phase-locking, frequency synchronization, and order-parameter synchronization are equivalent for arbitrary hybrid ensembles. The proof combines dissipative energy methods, LaSalle-type compactness arguments, the Poincaré-Bendixson theorem, and Thieme's asymptotically autonomous theory to demonstrate that synchronization equivalence is topological, determined solely by the finite equilibrium structure of the all-to-all network. This result provides a mathematically complete characterization of synchronization in finite oscillator systems and clarifies its geometric invariance across first-, second-, and hybrid-order models.",
          "authors": [
            "Ting-Yang Hsiao",
            "Yun-Feng Lo",
            "Chengbin Zhu"
          ],
          "primary_category": "math.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02988",
          "title": "Alternative winding patterns for twisted solenoid coils with improved characteristics for TRASE MRI",
          "abstract": "Transmit Array Spatial Encoding (TRASE) is an MRI technique in which spatial encoding is achieved using phase gradients of the B1 field. This approach offers potential advantages such as hardware simplicity and reduced acoustic noise. In this study, we present an assessment of various winding patterns for twisted solenoid phase-gradient coils, including the simple twisted solenoid (with and without return wire), a double-wound twisted solenoid, and a discrete-loop twisted solenoid. We analyze the magnetic field uniformity and phase linearity of these configurations using Biot-Savart simulations. Our results show that both the double-wound and discrete loop designs offer similar improvements over the simple twisted solenoid with return wire. The discrete loop pattern requires less wire than the double-wound version, making it the preferred option for practical coil construction and operation in a TRASE MRI system.",
          "authors": [
            "Nahid Ghomimolkar",
            "Alexander E. Krosney",
            "Christopher P. Bidinosti"
          ],
          "primary_category": "physics.med-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02989",
          "title": "Relaxation Schemes for Flows in Networks: Application to Shallow Water and Blood Flow Equations",
          "abstract": "A numerical scheme of relaxation type is proposed to approximate hyperbolic conservation laws in canal networks. Physical conditions at the junction are given and a novel strategy based on [Briani, Natalini, Ribot, 2025] is introduced to approximate the solution, avoiding the use of approximate Riemann solvers. This general approach is applied to shallow water and blood flow equations, dealing both the subcritical and the supercritical case. The relaxation scheme is complemented with a well-balanced strategy to treat source terms. We investigate properties of the numerical scheme and we present many numerical tests in different settings.",
          "authors": [
            "Tommaso Tenna"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02989",
          "title": "Relaxation Schemes for Flows in Networks: Application to Shallow Water and Blood Flow Equations",
          "abstract": "A numerical scheme of relaxation type is proposed to approximate hyperbolic conservation laws in canal networks. Physical conditions at the junction are given and a novel strategy based on [Briani, Natalini, Ribot, 2025] is introduced to approximate the solution, avoiding the use of approximate Riemann solvers. This general approach is applied to shallow water and blood flow equations, dealing both the subcritical and the supercritical case. The relaxation scheme is complemented with a well-balanced strategy to treat source terms. We investigate properties of the numerical scheme and we present many numerical tests in different settings.",
          "authors": [
            "Tommaso Tenna"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02990",
          "title": "Characterisation of the LAPPD, a large area microchannel-plate PMT",
          "abstract": "We present a comprehensive characterization of the LAPPD Gen-II, a large-area microchannel-plate photomultiplier tube (MCP-PMT) equipped with a capacitively coupled sensing (readout) electrode. Two detector variants with different geometries and materials were investigated using a picosecond pulsed laser system. We measured the single-photon timing response and spatial charge distribution on segmented readout electrodes. The prompt timing peak exhibits a resolution of approximately 30 ps, with the overall timing structure explained by photoelectron propagation and back-scattering effects from the MCP input surface. We developed analytical models that describe the propagation of photoelectrons and the induced charge spread on the sensing electrodes, including secondary electron backscattering from the resistive anode. The model accurately reproduces the measured device properties and enables performance extrapolations for various detector geometries and dielectric properties. These results provide a predictive framework for optimizing MCP-PMTs for timing- and imaging-critical applications such as RICH detectors in high-energy physics and TOF-PET systems for medical imaging.",
          "authors": [
            "S. Korpar",
            "R. Dolenec",
            "F. Grijalva",
            "A. Lozar",
            "A. Kodrič",
            "P. Križan",
            "S. Parashari",
            "R. Pestotnik",
            "A. Seljak",
            "D. Žontar"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02995",
          "title": "Asymptotic enumeration via graph containers and entropy",
          "abstract": "The container methods are powerful tools to bound the number of independent sets of graphs and hypergraphs, and they have been extremely influential in the area of extremal and probabilistic combinatorics. We will focus on more specialized graph container methods due to Sapozhenko (1987) that deal with sets in expander graphs. Entropy, first introduced by Shannon (1948) in the area of information theory, is a measure of the expected amount of information contained in a random variable. Entropy has seen lots of fascinating applications in a wide range of enumeration problems. In this survey article, we will discuss recent developments that exploit a combination of the two methods on enumerating graph homomorphisms.",
          "authors": [
            "Jinyoung Park"
          ],
          "primary_category": "math.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02996",
          "title": "Structured Clifford+T Circuits for Efficient Generation of Quantum Chaos",
          "abstract": "We investigate the emergence of quantum chaos and unitary T-design behavior in derandomized Clifford+T circuits using causal cover architectures. Motivated by the need for deterministic constructions that can exhibit chaotic behavior across diverse quantum hardware platforms, we explore deterministic Clifford circuit architectures (random Clifford circuits with causal cover, bitonic sorting networks, and permutation-based routing circuits) to drive quantum circuits toward Wigner-Dyson (WD) entanglement spectrum statistics and OTOC this http URL experiments demonstrate that causal connectivity, not circuit depth or randomness, is a critical feature that drives circuits to chaos. We show that initializing with n T-states and adding a second T-layer after a causally covered Clifford evolution yields consistent OTOC decay and WD statistics. This also enables deeper understanding of the circuit structures that generate complex entanglement behavior. Notably, our work suggests polylogarithmic-depth deterministic circuits suffice to approximate chaotic behavior, highlighting that causal connectivity is sufficient for operator spreading to induce Wigner-Dyson entanglement statistics and OTOC decay.",
          "authors": [
            "Asim Sharma",
            "Avah Banerjee"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02998",
          "title": "Stability of knot equivalence at low regularity, and symmetric critical knots for the Möbius energy",
          "abstract": "We present sufficient criteria for the equivalence of tame knots at low regularity. To this end, we introduce a localized version of Gromov's distortion for any closed path-connected subset of $\\R^n$. If two such sets have local Gromov distortion below a universal dimension-dependent constant $g_n$ at some scale, and if their Hausdorff-distance is less than one quarter of that scale, we can show that the fundamental groups of their complements are isomorphic. In addition, we construct this isomorphism so that it restricts to the corresponding peripheral subgroups as an isomorphism as well. Applied to the images of one-dimensional knots it follows that two knots are equivalent if their Hausdorff-distance is bounded in terms of the scale under which their local Gromov distortion is controlled. From that we deduce novel stability results for knot equivalence in the Lipschitz category, and in the setting of fractional Sobolev regularity below $C^1$. Moreover, we prove a compactness theorem of knot equivalence classes with respect to weak $W^{3/2,2}$-convergence. As an application we show that the Möbius energy introduced by O'Hara~\\cite{ohara_1991a} can be minimized within arbitrary prime knot classes under a symmetry constraint, and that these minimizers are in fact critical points and therefore smooth and even real analytic. In particular, in every torus knot class there are at least two distinct critical knots for the Möbius energy.",
          "authors": [
            "Simon Blatt",
            "Alexandra Gilsbach",
            "Philipp Reiter",
            "Heiko von der Mosel"
          ],
          "primary_category": "math.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02999",
          "title": "All planar three-loop Feynman integrals for the production of two vector bosons at hadron colliders",
          "abstract": "We compute all the planar three-loop master integrals relevant for the leading colour N3LO QCD corrections to the production of two massive or off-shell vector bosons at hadron colliders. These integrals are organised into nine four-point integral families with massless internal propagators and two external massive legs. For each family, we construct a basis of pure master integrals and we reconstruct the corresponding canonical differential equations using finite field techniques. We evaluate the master integrals by solving the differential equations using generalised power series expansions.",
          "authors": [
            "Dhimiter Canko",
            "Mattia Pozzoli"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03002",
          "title": "IOTA Experiment for Proton Pulse Compression at Extreme Space-Charge",
          "abstract": "The longitudinal compression of high-intensity, space-charge-dominated proton bunches is a critical requirement for future proton-driven muon colliders. We propose a proton bunch compression experiment at the Integrable Optics Test Accelerator (IOTA) storage ring at Fermilab to investigate optimal radio-frequency (RF) cavity parameters and lattice configurations. IOTA is a compact, fixed-energy storage ring dedicated to beam physics Research and Development and capable of circulating a 2.5 MeV proton beam under extreme space-charge conditions. Using the ImpactX code with its 3D space-charge solver, simulations indicate that the bunch length can be rapidly reduced by at least a factor of two without appreciable degradation of transverse beam quality--even in the strong space-charge regime. However, longitudinal defocusing due to the space-charge remains a significant challenge in short-pulsed intense proton bunches, and the optimization of compression under these conditions is discussed.",
          "authors": [
            "Benjamin Simons",
            "Nilanjan Banerjee",
            "Jeffrey Eldred",
            "Vladimir Shiltsev"
          ],
          "primary_category": "physics.acc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03002",
          "title": "IOTA Experiment for Proton Pulse Compression at Extreme Space-Charge",
          "abstract": "The longitudinal compression of high-intensity, space-charge-dominated proton bunches is a critical requirement for future proton-driven muon colliders. We propose a proton bunch compression experiment at the Integrable Optics Test Accelerator (IOTA) storage ring at Fermilab to investigate optimal radio-frequency (RF) cavity parameters and lattice configurations. IOTA is a compact, fixed-energy storage ring dedicated to beam physics Research and Development and capable of circulating a 2.5 MeV proton beam under extreme space-charge conditions. Using the ImpactX code with its 3D space-charge solver, simulations indicate that the bunch length can be rapidly reduced by at least a factor of two without appreciable degradation of transverse beam quality--even in the strong space-charge regime. However, longitudinal defocusing due to the space-charge remains a significant challenge in short-pulsed intense proton bunches, and the optimization of compression under these conditions is discussed.",
          "authors": [
            "Benjamin Simons",
            "Nilanjan Banerjee",
            "Jeffrey Eldred",
            "Vladimir Shiltsev"
          ],
          "primary_category": "physics.acc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03007",
          "title": "Generation of strong ultralow-phase-noise microwave fields with tunable ellipticity for ultracold polar molecules",
          "abstract": "Microwave(MW) fields with strong field strength, ultralow phase-noise and tunable polarization are crucial for stabilizing and manipulating ultracold polar molecules, which have emerged as a promising platform for quantum sciences. In this letter, we present the design, characterization, and performance of a robust MW setup tailored for precise control of molecular states. This setup achieves a high electric field intensity of 6.9 kV/m in the near-field from a dual-feed waveguide antenna, enabling a Rabi frequency as high as 71 MHz for the rotational transition of sodium-potassium molecules. In addition, the low noise signal source and controlled electronics provide ultralow phase-noise and dynamically tunable polarization. Narrow-band filters within the MW circuitry further reduce phase-noise by more than 20 dB at 20 MHz offset frequency, ensuring prolonged one-body molecular lifetimes up to 10 seconds. We also show practical methods to measure the MW field strength and polarization using a simple homemade dipole probe, and to characterize phase-noise down to -170 dBc/Hz with a commercial spectrum analyser and a notch filter. Those capabilities allowed us to evaporatively cool our molecular sample to deep quantum degeneracy. Furthermore, the polarization tunability enabled the observation of field-linked resonances and facilitated the creation of field-linked this http URL techniques advance the study of ultracold polar molecules and broaden the potential applications of MW tools in other platforms of quantum sciences.",
          "authors": [
            "Shrestha Biswas",
            "Sebastian Eppelt",
            "Christian Buchberger",
            "Xing-Yan Chen",
            "Andreas Schindewolf",
            "Michael Hani",
            "Erwin Biebl",
            "Immanuel Bloch",
            "Xin-Yu Luo"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03007",
          "title": "Generation of strong ultralow-phase-noise microwave fields with tunable ellipticity for ultracold polar molecules",
          "abstract": "Microwave(MW) fields with strong field strength, ultralow phase-noise and tunable polarization are crucial for stabilizing and manipulating ultracold polar molecules, which have emerged as a promising platform for quantum sciences. In this letter, we present the design, characterization, and performance of a robust MW setup tailored for precise control of molecular states. This setup achieves a high electric field intensity of 6.9 kV/m in the near-field from a dual-feed waveguide antenna, enabling a Rabi frequency as high as 71 MHz for the rotational transition of sodium-potassium molecules. In addition, the low noise signal source and controlled electronics provide ultralow phase-noise and dynamically tunable polarization. Narrow-band filters within the MW circuitry further reduce phase-noise by more than 20 dB at 20 MHz offset frequency, ensuring prolonged one-body molecular lifetimes up to 10 seconds. We also show practical methods to measure the MW field strength and polarization using a simple homemade dipole probe, and to characterize phase-noise down to -170 dBc/Hz with a commercial spectrum analyser and a notch filter. Those capabilities allowed us to evaporatively cool our molecular sample to deep quantum degeneracy. Furthermore, the polarization tunability enabled the observation of field-linked resonances and facilitated the creation of field-linked this http URL techniques advance the study of ultracold polar molecules and broaden the potential applications of MW tools in other platforms of quantum sciences.",
          "authors": [
            "Shrestha Biswas",
            "Sebastian Eppelt",
            "Christian Buchberger",
            "Xing-Yan Chen",
            "Andreas Schindewolf",
            "Michael Hani",
            "Erwin Biebl",
            "Immanuel Bloch",
            "Xin-Yu Luo"
          ],
          "primary_category": "physics.atom-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03011",
          "title": "Microscopic evidence of dominant excitonic instability in Ta2NiSe5",
          "abstract": "An excitonic insulator (EI) is a charge-neutral bosonic condensate of spontaneously formed electron-hole pairs. Exotic quantum phenomena such as dissipationless charge neutral transport and huge potential for optoelectronic applications have led to an extensive search for intrinsic bulk materials that are EIs at ambient pressure without sophisticated device fabrication. The narrow gap semimetal Ta2NiSe5 has been proposed as a rare example of an intrinsic EI, but its ground state has remained controversial since the EI phase transition is accompanied by a structural distortion. Here, we use scanning tunneling microscopy and spectroscopy to present microscopic evidence that supports an excitonic origin of the insulating phase in Ta2NiSe5. First, we find that the insulating gap persists at structural domain boundaries where the bulk structural distortion is absent suggesting that the structural distortion is not the primary origin of insulating ground state. Second, the insulating gap is suppressed at localized charge puddles which indicates that charge correlations are important in producing the insulating gap. Finally, the decay length of the in-gap states at the puddles shows similar value to the estimated size of the exciton wavefunction from previous photoemission studies. Taken together, these findings suggest that Ta2NiSe5 is an EI and may be a versatile platform to study the physics of bosonic condensates in solid-state system at ambient conditions.",
          "authors": [
            "Seokjin Bae",
            "Arjun Raghavan",
            "Irena Feldman",
            "Amit Kanigel",
            "Vidya Madhavan"
          ],
          "primary_category": "cond-mat.str-el",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03012",
          "title": "Notes on Regularity theory for Nonlinear elliptic equations",
          "abstract": "In this note, we present several seminal developments in the regularity theory of nonlinear (uniformly) elliptic equations, including the De Giorgi--Nash--Moser theory concerning the Hilbert 19th problem and variational equations, as well as the Krylov--Safonov and Evans--Safonov theories for fully nonlinear equations.",
          "authors": [
            "Zhenye Qian"
          ],
          "primary_category": "math.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03015",
          "title": "The discrete wave equation with applications to scattering theory and quantum chaos",
          "abstract": "With a view towards studying the multitemporal wave equation on affine buildings recently introduced by Anker-Rémy-Trojan [ arXiv:2312.06860 ], we systematically develop the basic properties of the discrete wave equation on $\\mathbb{Z}$ and use this to explain existing results about the wave equation on regular graphs. Furthermore, we explicitly compute the incoming and outgoing translation representations and the scattering operator, in the sense of Lax-Phillips, for regular and biregular trees. Finally, we use the wave equation on biregular graphs to extend a result of Brooks-Lindenstrauss about delocalization of eigenfunctions on regular graphs to the setting of biregular graphs.",
          "authors": [
            "Carsten Peterson"
          ],
          "primary_category": "math.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03015",
          "title": "The discrete wave equation with applications to scattering theory and quantum chaos",
          "abstract": "With a view towards studying the multitemporal wave equation on affine buildings recently introduced by Anker-Rémy-Trojan [ arXiv:2312.06860 ], we systematically develop the basic properties of the discrete wave equation on $\\mathbb{Z}$ and use this to explain existing results about the wave equation on regular graphs. Furthermore, we explicitly compute the incoming and outgoing translation representations and the scattering operator, in the sense of Lax-Phillips, for regular and biregular trees. Finally, we use the wave equation on biregular graphs to extend a result of Brooks-Lindenstrauss about delocalization of eigenfunctions on regular graphs to the setting of biregular graphs.",
          "authors": [
            "Carsten Peterson"
          ],
          "primary_category": "math.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03017",
          "title": "On hyperbolic links associated to Eulerian cycles on ideal right-angled hyperbolic $3$-polytopes",
          "abstract": "We consider Eulerian cycles without transversal selfintersections in $4$-valent planar graphs. We prove that any cycle of this type in the graph of an ideal right-angled hyperbolic $3$-polytope corresponds to a hyperbolic link such that its complement consists of $4$-copies of this polytope glued according to its checkerboard coloring. Moreover, this link consists of trivially embedded circles bijectively corresponding to the vertices of the polytope. For such cycles we prove that the $3$-antiprism $A(3)$ (octahedron) has exactly $2$ combinatorially different cycles, the $4$-antiprism $A(4)$ has exactly $7$ combinatorially different cycles, and these cycles correspond to $7$ cycles (perhaps combinatorially equivalent) on any polytope different from antiprisms, and any antiprism $A(k)$ has at least $2$ combinatorially different cycles. The $2$-fold branched covering space corresponding to our link is a small cover over some simple $3$-polytope. This small cover is defined by a Hamiltonian cycle on it. We show that any compact hyperbolic $3$-polytope with a Hamiltonian cycle arises in this way.",
          "authors": [
            "Nikolai Erokhovets"
          ],
          "primary_category": "math.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03022",
          "title": "Topological marker in three dimensions based on kernel polynomial method",
          "abstract": "The atomic-scale influence of disorder on the topological order can be quantified by a universal topological marker, although the practical calculation of the marker becomes numerically very costly in higher dimensions. We propose that for any symmetry class in higher dimensions, the topological marker can be calculated in a very efficient way by adopting the kernel polynomial method. Using class AII in three dimensions as an example, which is relevant to realistic topological insulators like Bi2Se3 and Bi2Te3, this method reveals the criteria for the invariance of topological order in the presence of disorder, as well as the possibility of a smooth cross over between two topological phases caused by disorder. In addition, the significantly enlarged system size in the numerical calculation implies that this method is capable of capturing the quantum criticality much closer to topological phase transitions, as demonstrated by a nonlocal topological marker.",
          "authors": [
            "Ranadeep Roy",
            "Wei Chen"
          ],
          "primary_category": "cond-mat.dis-nn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03027",
          "title": "Consistent Truncations and Generalised Geometry: Scanning through Dimensions and Supersymmetry",
          "abstract": "We study consistent truncations in the framework of Exceptional Generalised Geometry. We classify the 4-dimensional gauged supergravities that can be obtained as a consistent truncation of 10/11-dimensional supergravity. Any truncation is associated to a (generalised) $G_S$-structure with singlet intrinsic torsion. We give the full classification for all truncations associated to continuous structure groups and we discuss a few examples with discrete ones. We recover gauged supergravities corresponding to known truncations as well as others for which explicit truncations are still to be constructed. We also summarise similar results obtained in the literature for truncations to $d=5,6,7$ dimensions and we complete them, when needed.",
          "authors": [
            "Gregoire Josse",
            "Michela Petrini",
            "Martin Pico"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03029",
          "title": "Combinatorial foundations for solvable chaotic local Euclidean quantum circuits in two dimensions",
          "abstract": "We investigate a graph-theoretic problem motivated by questions in quantum computing concerning the propagation of information in quantum circuits. A graph $G$ is said to be a bounded extension of its subgraph $L$ if they share the same vertex set, and the graph distance $d_L(u, v)$ is uniformly bounded for edges $uv\\in G$. Given vertices $u, v$ in $G$ and an integer $k$, the geodesic slice $S(u, v, k)$ denotes the subset of vertices $w$ lying on a geodesic in $G$ between $u$ and $v$ with $d_G(u, w) = k$. We say that $G$ has bounded geodesic slices if $|S(u, v, k)|$ is uniformly bounded over all $u, v, k$. We call a graph $L$ geodesically directable if it has a bounded extension $G$ with bounded geodesic slices. Contrary to previous expectations, we prove that $\\mathbb{Z}^2$ is geodesically directable. Physically, this provides a setting in which one could devise exactly-solvable chaotic local quantum circuits with non-trivial correlation patterns on 2D Euclidean lattices. In fact, we show that any bounded extension of $\\mathbb{Z}^2$ is geodesically directable. This further implies that all two-dimensional regular tilings are geodesically directable.",
          "authors": [
            "Fredy Yip"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03029",
          "title": "Combinatorial foundations for solvable chaotic local Euclidean quantum circuits in two dimensions",
          "abstract": "We investigate a graph-theoretic problem motivated by questions in quantum computing concerning the propagation of information in quantum circuits. A graph $G$ is said to be a bounded extension of its subgraph $L$ if they share the same vertex set, and the graph distance $d_L(u, v)$ is uniformly bounded for edges $uv\\in G$. Given vertices $u, v$ in $G$ and an integer $k$, the geodesic slice $S(u, v, k)$ denotes the subset of vertices $w$ lying on a geodesic in $G$ between $u$ and $v$ with $d_G(u, w) = k$. We say that $G$ has bounded geodesic slices if $|S(u, v, k)|$ is uniformly bounded over all $u, v, k$. We call a graph $L$ geodesically directable if it has a bounded extension $G$ with bounded geodesic slices. Contrary to previous expectations, we prove that $\\mathbb{Z}^2$ is geodesically directable. Physically, this provides a setting in which one could devise exactly-solvable chaotic local quantum circuits with non-trivial correlation patterns on 2D Euclidean lattices. In fact, we show that any bounded extension of $\\mathbb{Z}^2$ is geodesically directable. This further implies that all two-dimensional regular tilings are geodesically directable.",
          "authors": [
            "Fredy Yip"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03030",
          "title": "The Hilbert space of gauge theories: group averaging and the quantization of Jackiw-Teitelboim gravity",
          "abstract": "When the gauge group of a theory has infinite volume, defining the inner product on physical states becomes subtle. This is the case for gravity, even in exactly solvable models such as minisuperspace or low-dimensional theories: the physical states do not inherit an inner product in a straightforward manner, and different quantization procedures yield a priori inequivalent prescriptions. This is one of the main challenges when constructing gravitational Hilbert spaces. In this paper we study a quantization procedure known as group averaging, which is a special case of the BRST/BV formalism and has gained popularity as a promising connection between Dirac quantization and gravitational path integrals. We identify a large class of theories for which group averaging is ill-defined due to isometry groups with infinite volume, which includes Jackiw-Teitelboim gravity. We propose a modification of group averaging to renormalize these infinite volumes and use it to quantize Jackiw-Teitelboim gravity with a positive cosmological constant in closed universes. The resulting Hilbert space naturally splits into infinite-dimensional superselection sectors and has a positive-definite inner product. This is the first complete Dirac quantization of this theory, as we are able to capture all the physical states for the first time.",
          "authors": [
            "Elba Alonso-Monsalve"
          ],
          "primary_category": "hep-th",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03031",
          "title": "Information dynamics and symmetry breaking in generic monitored $\\mathbb{Z}_2$-symmetric open quantum systems",
          "abstract": "We investigate the steady-state phases of generic $\\mathbb{Z}_2$-symmetric monitored, open quantum dynamics. We describe the phases systematically in terms of both information-theoretic diagnostics and spontaneous breaking of strong and weak symmetries of the dynamics. We find a completely broken phase where information is retained by the quantum system, a strong-to-weak broken phase where information is leaked to the environment, and an unbroken phase where information is learned by the observer. We find that weak measurement and dephasing alone constitute a minimal model for generic open systems with $\\mathbb{Z}_2$ symmetry, but we also explore perturbations by unitary gates. For a 1d set of qubits, we examine information-theoretic and symmetry-breaking observables in the path integral of the doubled state. This path integral reduces to the standard classical 2d random-bond Ising model in certain limits but generically involves negative weights, enabling a special self-dual random-bond Ising model at the critical point when only measurements are present. We obtain numerical evidence for the steady-state phases using efficient tensor network simulations of the doubled state.",
          "authors": [
            "Jacob Hauser",
            "Ali Lavasani",
            "Sagar Vijay",
            "Matthew P. A. Fisher"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03031",
          "title": "Information dynamics and symmetry breaking in generic monitored $\\mathbb{Z}_2$-symmetric open quantum systems",
          "abstract": "We investigate the steady-state phases of generic $\\mathbb{Z}_2$-symmetric monitored, open quantum dynamics. We describe the phases systematically in terms of both information-theoretic diagnostics and spontaneous breaking of strong and weak symmetries of the dynamics. We find a completely broken phase where information is retained by the quantum system, a strong-to-weak broken phase where information is leaked to the environment, and an unbroken phase where information is learned by the observer. We find that weak measurement and dephasing alone constitute a minimal model for generic open systems with $\\mathbb{Z}_2$ symmetry, but we also explore perturbations by unitary gates. For a 1d set of qubits, we examine information-theoretic and symmetry-breaking observables in the path integral of the doubled state. This path integral reduces to the standard classical 2d random-bond Ising model in certain limits but generically involves negative weights, enabling a special self-dual random-bond Ising model at the critical point when only measurements are present. We obtain numerical evidence for the steady-state phases using efficient tensor network simulations of the doubled state.",
          "authors": [
            "Jacob Hauser",
            "Ali Lavasani",
            "Sagar Vijay",
            "Matthew P. A. Fisher"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03032",
          "title": "Entanglement evolution from entangled multipodal states",
          "abstract": "In a periodic lattice system an entangled antipodal pair state, otherwise known as a crosscap state, is a simple two site product state in which spins at antipodal sites are prepared in Bell pairs. Such states have maximal bipartite entanglement and serve as a useful platform for studying the quench dynamics of systems which have large initial entanglement. In this paper, we study a generalization of these states which we dub entangled mutipodal states. These states, which are defined for fermionic systems, generalize the crosscap states by having correlations among more than two sites, specifically, those which sit at the vertices of regular polygons. By construction, the states are Gaussian and translationally invariant allowing many of their properties to be understood. We study the bipartite entanglement entropy of these states both in and out of equilibrium. In equilibrium, the entanglement profile as a function of subsystem size exhibits two distinct regimes, a volume-law growth followed by a saturation to a constant value, thus generalizing the Page-curve profile of the crosscap state. In the non-equilibrium setting, we study quenches from these initial states to the free-fermion chain, whose ensuing dynamics displays a far richer structure compared to the crosscap case. We interpret our results in terms of the quasiparticle picture, which requires multiplets of quasiparticles to be excited non-locally around the system. This scenario is confirmed by the appearance of a post-quench, negative tripartite information.",
          "authors": [
            "Konstantinos Chalas",
            "Pasquale Calabrese",
            "Colin Rylands"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03032",
          "title": "Entanglement evolution from entangled multipodal states",
          "abstract": "In a periodic lattice system an entangled antipodal pair state, otherwise known as a crosscap state, is a simple two site product state in which spins at antipodal sites are prepared in Bell pairs. Such states have maximal bipartite entanglement and serve as a useful platform for studying the quench dynamics of systems which have large initial entanglement. In this paper, we study a generalization of these states which we dub entangled mutipodal states. These states, which are defined for fermionic systems, generalize the crosscap states by having correlations among more than two sites, specifically, those which sit at the vertices of regular polygons. By construction, the states are Gaussian and translationally invariant allowing many of their properties to be understood. We study the bipartite entanglement entropy of these states both in and out of equilibrium. In equilibrium, the entanglement profile as a function of subsystem size exhibits two distinct regimes, a volume-law growth followed by a saturation to a constant value, thus generalizing the Page-curve profile of the crosscap state. In the non-equilibrium setting, we study quenches from these initial states to the free-fermion chain, whose ensuing dynamics displays a far richer structure compared to the crosscap case. We interpret our results in terms of the quasiparticle picture, which requires multiplets of quasiparticles to be excited non-locally around the system. This scenario is confirmed by the appearance of a post-quench, negative tripartite information.",
          "authors": [
            "Konstantinos Chalas",
            "Pasquale Calabrese",
            "Colin Rylands"
          ],
          "primary_category": "cond-mat.stat-mech",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03033",
          "title": "The Gamma-disordered Aztec diamond",
          "abstract": "We introduce a multi-parameter family of random edge weights on the Aztec diamond graph, given by certain Gamma variables, and prove several results about the corresponding random dimer measures. Firstly, we show there is no phase transition at the level of the free energy. This provides rigorous backing for the physics predictions of Zeng-Leath-Hwa and later works that dimer models with random weights are in the glassy `super-rough' phase at all temperatures with no phase transition. Secondly, we show that the random dimer covers themselves enjoy exact distributional equalities of certain marginals with path locations in new `hybrid' integrable polymers. These reduce to the stationary log-Gamma, strict-weak, and Beta polymer in random environment in certain cases, allowing transfer of known results from integrable polymers to dimers with random weights. As an example application, we prove that the turning points at the boundaries of the Aztec diamond exhibit fluctuations of order $n^{2/3}$, in contrast to the $n^{1/2}$ fluctuations for deterministic weights. Underlying all these is a key integrability property of the weights: they are the unique family for which independence is preserved under the shuffling algorithm.",
          "authors": [
            "Maurice Duits",
            "Roger Van Peski"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03033",
          "title": "The Gamma-disordered Aztec diamond",
          "abstract": "We introduce a multi-parameter family of random edge weights on the Aztec diamond graph, given by certain Gamma variables, and prove several results about the corresponding random dimer measures. Firstly, we show there is no phase transition at the level of the free energy. This provides rigorous backing for the physics predictions of Zeng-Leath-Hwa and later works that dimer models with random weights are in the glassy `super-rough' phase at all temperatures with no phase transition. Secondly, we show that the random dimer covers themselves enjoy exact distributional equalities of certain marginals with path locations in new `hybrid' integrable polymers. These reduce to the stationary log-Gamma, strict-weak, and Beta polymer in random environment in certain cases, allowing transfer of known results from integrable polymers to dimers with random weights. As an example application, we prove that the turning points at the boundaries of the Aztec diamond exhibit fluctuations of order $n^{2/3}$, in contrast to the $n^{1/2}$ fluctuations for deterministic weights. Underlying all these is a key integrability property of the weights: they are the unique family for which independence is preserved under the shuffling algorithm.",
          "authors": [
            "Maurice Duits",
            "Roger Van Peski"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03039",
          "title": "On the Cutting Edge: Helical Liquids in Time-Reversal-Invariant Topological Materials",
          "abstract": "In this perspective, we discuss the unique electronic properties of helical liquids appearing at the boundaries of time-reversal-invariant topological materials and highlight the key challenges impeding progress in this field. We advocate for a deeper theoretical understanding of the many-body aspects of these systems to gain insights into helical liquids and the potential stabilization of topological zero modes. Such advancements are crucial for extensively exploring quantum phenomena and for the advancement of quantum science and engineering.",
          "authors": [
            "Chen-Hsuan Hsu",
            "Jelena Klinovaja",
            "Daniel Loss"
          ],
          "primary_category": "cond-mat.mes-hall",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 7,
      "size": 8,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2512.02048",
          "title": "The Impact of Artificial Intelligence on Enterprise Decision-Making Process",
          "abstract": "Artificial intelligence improves enterprise decision-making by accelerating data analysis, reducing human error, and supporting evidence-based choices. A quantitative survey of 92 companies across multiple industries examines how AI adoption influences managerial performance, decision efficiency, and organizational barriers. Results show that 93 percent of firms use AI, primarily in customer service, data forecasting, and decision support. AI systems increase the speed and clarity of managerial decisions, yet implementation faces challenges. The most frequent barriers include employee resistance, high costs, and regulatory ambiguity. Respondents indicate that organizational factors are more significant than technological limitations. Critical competencies for successful AI use include understanding algorithmic mechanisms and change management. Technical skills such as programming play a smaller role. Employees report difficulties in adapting to AI tools, especially when formulating prompts or accepting system outputs. The study highlights the importance of integrating AI with human judgment and communication practices. When supported by adaptive leadership and transparent processes, AI adoption enhances organizational agility and strengthens decision-making performance. These findings contribute to ongoing research on how digital technologies reshape management and the evolution of hybrid human-machine decision environments.",
          "primary_category": "cs.CY",
          "authors": [
            "Ernest Górka",
            "Dariusz Baran",
            "Gabriela Wojak",
            "Michał Ćwiąkała",
            "Sebastian Zupok",
            "Dariusz Starkowski",
            "Dariusz Reśko",
            "Oliwia Okrasa"
          ]
        },
        {
          "id": "arXiv:2512.02048",
          "title": "The Impact of Artificial Intelligence on Enterprise Decision-Making Process",
          "abstract": "Artificial intelligence improves enterprise decision-making by accelerating data analysis, reducing human error, and supporting evidence-based choices. A quantitative survey of 92 companies across multiple industries examines how AI adoption influences managerial performance, decision efficiency, and organizational barriers. Results show that 93 percent of firms use AI, primarily in customer service, data forecasting, and decision support. AI systems increase the speed and clarity of managerial decisions, yet implementation faces challenges. The most frequent barriers include employee resistance, high costs, and regulatory ambiguity. Respondents indicate that organizational factors are more significant than technological limitations. Critical competencies for successful AI use include understanding algorithmic mechanisms and change management. Technical skills such as programming play a smaller role. Employees report difficulties in adapting to AI tools, especially when formulating prompts or accepting system outputs. The study highlights the importance of integrating AI with human judgment and communication practices. When supported by adaptive leadership and transparent processes, AI adoption enhances organizational agility and strengthens decision-making performance. These findings contribute to ongoing research on how digital technologies reshape management and the evolution of hybrid human-machine decision environments.",
          "primary_category": "cs.CY",
          "authors": [
            "Ernest Górka",
            "Dariusz Baran",
            "Gabriela Wojak",
            "Michał Ćwiąkała",
            "Sebastian Zupok",
            "Dariusz Starkowski",
            "Dariusz Reśko",
            "Oliwia Okrasa"
          ]
        },
        {
          "id": "arXiv:2512.02480",
          "title": "How IFRS Affects Value Relevance and Key Financial Indicators? Evidence from the UK",
          "abstract": "This paper has two contributions to the International Financial Reporting Stands (IFRS) adoption literature. First is the scrutinizing impact of IFRS adoption on value relevance in the UK with TEST-A analysis under the H01 hypothesis. The second contribution is capturing the impact of IFRS adoption on key financial indicators of firms with the TEST-B analysis that hypothesizes this http URL statistical differences of items of two different reporting standards are examined with non-parametric tests as all input variables failed the Shapiro-Wilk and Lilliefors normality tests in TEST-A. The finding rejects the H01 hypothesis for BvMv, and agrees that IFRS has impact on value relevance. Besides, Ohlson's (1995) model documents that the coefficient of dummy variable (MODE) is positive. Therefore, the analysis concludes that IFRS has positive impact on value relevance. The aftermath of TEST-B rejects the H02 hypothesis for all profitability ratios (ROE, ROCE, ROA, PM) and gearing ratios (GR). It concludes that profitability and gearing ratios are affected by IFRS adoption, whereas efficiency-liquidity ratios are not. Also, in Forward Stepwise regression analysis only ROCE, ROA, and PM ratios show significant results. The analysis documents positive and significant impact of IFRS on these three ratios.",
          "primary_category": "econ.GN",
          "authors": [
            "Yhlas Sovbetov"
          ]
        },
        {
          "id": "arXiv:2512.02510",
          "title": "Does Firm-Level AI Adoption Improve Early-Warning of Corporate Financial Distress? Evidence from Chinese Non-Financial Firms",
          "abstract": "This study investigates whether firm-level artificial intelligence (AI) adoption improves the out-of-sample prediction of corporate financial distress models beyond traditional financial ratios. Using a sample of Chinese listed firms (2008-2023), we address sparse AI data with a novel pruned training window method, testing multiple machine learning models. We find that AI adoption consistently increases predictive accuracy, with the largest gains in recall rates for identifying distressed firms. Tree-based models and AI density metrics proved most effective. Crucially, models using longer histories outperformed those relying solely on recent \"AI-rich\" data. The analysis also identifies divergent adoption patterns, with healthy firms exhibiting earlier and higher AI uptake than distressed peers. These findings, while based on Chinese data, provide a framework for early-warning signals and demonstrate the broader potential of AI metrics as a stable, complementary risk indicator distinct from traditional accounting measures.",
          "primary_category": "econ.GN",
          "authors": [
            "Frederik Rech",
            "Fanchen Meng",
            "Hussam Musa",
            "Martin Šebeňa",
            "Siele Jean Tuo"
          ]
        },
        {
          "id": "arXiv:2512.02510",
          "title": "Does Firm-Level AI Adoption Improve Early-Warning of Corporate Financial Distress? Evidence from Chinese Non-Financial Firms",
          "abstract": "This study investigates whether firm-level artificial intelligence (AI) adoption improves the out-of-sample prediction of corporate financial distress models beyond traditional financial ratios. Using a sample of Chinese listed firms (2008-2023), we address sparse AI data with a novel pruned training window method, testing multiple machine learning models. We find that AI adoption consistently increases predictive accuracy, with the largest gains in recall rates for identifying distressed firms. Tree-based models and AI density metrics proved most effective. Crucially, models using longer histories outperformed those relying solely on recent \"AI-rich\" data. The analysis also identifies divergent adoption patterns, with healthy firms exhibiting earlier and higher AI uptake than distressed peers. These findings, while based on Chinese data, provide a framework for early-warning signals and demonstrate the broader potential of AI metrics as a stable, complementary risk indicator distinct from traditional accounting measures.",
          "primary_category": "econ.GN",
          "authors": [
            "Frederik Rech",
            "Fanchen Meng",
            "Hussam Musa",
            "Martin Šebeňa",
            "Siele Jean Tuo"
          ]
        },
        {
          "id": "arXiv:2512.02480",
          "title": "How IFRS Affects Value Relevance and Key Financial Indicators? Evidence from the UK",
          "abstract": "This paper has two contributions to the International Financial Reporting Stands (IFRS) adoption literature. First is the scrutinizing impact of IFRS adoption on value relevance in the UK with TEST-A analysis under the H01 hypothesis. The second contribution is capturing the impact of IFRS adoption on key financial indicators of firms with the TEST-B analysis that hypothesizes this http URL statistical differences of items of two different reporting standards are examined with non-parametric tests as all input variables failed the Shapiro-Wilk and Lilliefors normality tests in TEST-A. The finding rejects the H01 hypothesis for BvMv, and agrees that IFRS has impact on value relevance. Besides, Ohlson's (1995) model documents that the coefficient of dummy variable (MODE) is positive. Therefore, the analysis concludes that IFRS has positive impact on value relevance. The aftermath of TEST-B rejects the H02 hypothesis for all profitability ratios (ROE, ROCE, ROA, PM) and gearing ratios (GR). It concludes that profitability and gearing ratios are affected by IFRS adoption, whereas efficiency-liquidity ratios are not. Also, in Forward Stepwise regression analysis only ROCE, ROA, and PM ratios show significant results. The analysis documents positive and significant impact of IFRS on these three ratios.",
          "primary_category": "econ.GN",
          "authors": [
            "Yhlas Sovbetov"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2512.02048",
          "title": "The Impact of Artificial Intelligence on Enterprise Decision-Making Process",
          "abstract": "Artificial intelligence improves enterprise decision-making by accelerating data analysis, reducing human error, and supporting evidence-based choices. A quantitative survey of 92 companies across multiple industries examines how AI adoption influences managerial performance, decision efficiency, and organizational barriers. Results show that 93 percent of firms use AI, primarily in customer service, data forecasting, and decision support. AI systems increase the speed and clarity of managerial decisions, yet implementation faces challenges. The most frequent barriers include employee resistance, high costs, and regulatory ambiguity. Respondents indicate that organizational factors are more significant than technological limitations. Critical competencies for successful AI use include understanding algorithmic mechanisms and change management. Technical skills such as programming play a smaller role. Employees report difficulties in adapting to AI tools, especially when formulating prompts or accepting system outputs. The study highlights the importance of integrating AI with human judgment and communication practices. When supported by adaptive leadership and transparent processes, AI adoption enhances organizational agility and strengthens decision-making performance. These findings contribute to ongoing research on how digital technologies reshape management and the evolution of hybrid human-machine decision environments.",
          "authors": [
            "Ernest Górka",
            "Dariusz Baran",
            "Gabriela Wojak",
            "Michał Ćwiąkała",
            "Sebastian Zupok",
            "Dariusz Starkowski",
            "Dariusz Reśko",
            "Oliwia Okrasa"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02048",
          "title": "The Impact of Artificial Intelligence on Enterprise Decision-Making Process",
          "abstract": "Artificial intelligence improves enterprise decision-making by accelerating data analysis, reducing human error, and supporting evidence-based choices. A quantitative survey of 92 companies across multiple industries examines how AI adoption influences managerial performance, decision efficiency, and organizational barriers. Results show that 93 percent of firms use AI, primarily in customer service, data forecasting, and decision support. AI systems increase the speed and clarity of managerial decisions, yet implementation faces challenges. The most frequent barriers include employee resistance, high costs, and regulatory ambiguity. Respondents indicate that organizational factors are more significant than technological limitations. Critical competencies for successful AI use include understanding algorithmic mechanisms and change management. Technical skills such as programming play a smaller role. Employees report difficulties in adapting to AI tools, especially when formulating prompts or accepting system outputs. The study highlights the importance of integrating AI with human judgment and communication practices. When supported by adaptive leadership and transparent processes, AI adoption enhances organizational agility and strengthens decision-making performance. These findings contribute to ongoing research on how digital technologies reshape management and the evolution of hybrid human-machine decision environments.",
          "authors": [
            "Ernest Górka",
            "Dariusz Baran",
            "Gabriela Wojak",
            "Michał Ćwiąkała",
            "Sebastian Zupok",
            "Dariusz Starkowski",
            "Dariusz Reśko",
            "Oliwia Okrasa"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02048",
          "title": "The Impact of Artificial Intelligence on Enterprise Decision-Making Process",
          "abstract": "Artificial intelligence improves enterprise decision-making by accelerating data analysis, reducing human error, and supporting evidence-based choices. A quantitative survey of 92 companies across multiple industries examines how AI adoption influences managerial performance, decision efficiency, and organizational barriers. Results show that 93 percent of firms use AI, primarily in customer service, data forecasting, and decision support. AI systems increase the speed and clarity of managerial decisions, yet implementation faces challenges. The most frequent barriers include employee resistance, high costs, and regulatory ambiguity. Respondents indicate that organizational factors are more significant than technological limitations. Critical competencies for successful AI use include understanding algorithmic mechanisms and change management. Technical skills such as programming play a smaller role. Employees report difficulties in adapting to AI tools, especially when formulating prompts or accepting system outputs. The study highlights the importance of integrating AI with human judgment and communication practices. When supported by adaptive leadership and transparent processes, AI adoption enhances organizational agility and strengthens decision-making performance. These findings contribute to ongoing research on how digital technologies reshape management and the evolution of hybrid human-machine decision environments.",
          "authors": [
            "Ernest Górka",
            "Dariusz Baran",
            "Gabriela Wojak",
            "Michał Ćwiąkała",
            "Sebastian Zupok",
            "Dariusz Starkowski",
            "Dariusz Reśko",
            "Oliwia Okrasa"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02480",
          "title": "How IFRS Affects Value Relevance and Key Financial Indicators? Evidence from the UK",
          "abstract": "This paper has two contributions to the International Financial Reporting Stands (IFRS) adoption literature. First is the scrutinizing impact of IFRS adoption on value relevance in the UK with TEST-A analysis under the H01 hypothesis. The second contribution is capturing the impact of IFRS adoption on key financial indicators of firms with the TEST-B analysis that hypothesizes this http URL statistical differences of items of two different reporting standards are examined with non-parametric tests as all input variables failed the Shapiro-Wilk and Lilliefors normality tests in TEST-A. The finding rejects the H01 hypothesis for BvMv, and agrees that IFRS has impact on value relevance. Besides, Ohlson's (1995) model documents that the coefficient of dummy variable (MODE) is positive. Therefore, the analysis concludes that IFRS has positive impact on value relevance. The aftermath of TEST-B rejects the H02 hypothesis for all profitability ratios (ROE, ROCE, ROA, PM) and gearing ratios (GR). It concludes that profitability and gearing ratios are affected by IFRS adoption, whereas efficiency-liquidity ratios are not. Also, in Forward Stepwise regression analysis only ROCE, ROA, and PM ratios show significant results. The analysis documents positive and significant impact of IFRS on these three ratios.",
          "authors": [
            "Yhlas Sovbetov"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02480",
          "title": "How IFRS Affects Value Relevance and Key Financial Indicators? Evidence from the UK",
          "abstract": "This paper has two contributions to the International Financial Reporting Stands (IFRS) adoption literature. First is the scrutinizing impact of IFRS adoption on value relevance in the UK with TEST-A analysis under the H01 hypothesis. The second contribution is capturing the impact of IFRS adoption on key financial indicators of firms with the TEST-B analysis that hypothesizes this http URL statistical differences of items of two different reporting standards are examined with non-parametric tests as all input variables failed the Shapiro-Wilk and Lilliefors normality tests in TEST-A. The finding rejects the H01 hypothesis for BvMv, and agrees that IFRS has impact on value relevance. Besides, Ohlson's (1995) model documents that the coefficient of dummy variable (MODE) is positive. Therefore, the analysis concludes that IFRS has positive impact on value relevance. The aftermath of TEST-B rejects the H02 hypothesis for all profitability ratios (ROE, ROCE, ROA, PM) and gearing ratios (GR). It concludes that profitability and gearing ratios are affected by IFRS adoption, whereas efficiency-liquidity ratios are not. Also, in Forward Stepwise regression analysis only ROCE, ROA, and PM ratios show significant results. The analysis documents positive and significant impact of IFRS on these three ratios.",
          "authors": [
            "Yhlas Sovbetov"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02510",
          "title": "Does Firm-Level AI Adoption Improve Early-Warning of Corporate Financial Distress? Evidence from Chinese Non-Financial Firms",
          "abstract": "This study investigates whether firm-level artificial intelligence (AI) adoption improves the out-of-sample prediction of corporate financial distress models beyond traditional financial ratios. Using a sample of Chinese listed firms (2008-2023), we address sparse AI data with a novel pruned training window method, testing multiple machine learning models. We find that AI adoption consistently increases predictive accuracy, with the largest gains in recall rates for identifying distressed firms. Tree-based models and AI density metrics proved most effective. Crucially, models using longer histories outperformed those relying solely on recent \"AI-rich\" data. The analysis also identifies divergent adoption patterns, with healthy firms exhibiting earlier and higher AI uptake than distressed peers. These findings, while based on Chinese data, provide a framework for early-warning signals and demonstrate the broader potential of AI metrics as a stable, complementary risk indicator distinct from traditional accounting measures.",
          "authors": [
            "Frederik Rech",
            "Fanchen Meng",
            "Hussam Musa",
            "Martin Šebeňa",
            "Siele Jean Tuo"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02510",
          "title": "Does Firm-Level AI Adoption Improve Early-Warning of Corporate Financial Distress? Evidence from Chinese Non-Financial Firms",
          "abstract": "This study investigates whether firm-level artificial intelligence (AI) adoption improves the out-of-sample prediction of corporate financial distress models beyond traditional financial ratios. Using a sample of Chinese listed firms (2008-2023), we address sparse AI data with a novel pruned training window method, testing multiple machine learning models. We find that AI adoption consistently increases predictive accuracy, with the largest gains in recall rates for identifying distressed firms. Tree-based models and AI density metrics proved most effective. Crucially, models using longer histories outperformed those relying solely on recent \"AI-rich\" data. The analysis also identifies divergent adoption patterns, with healthy firms exhibiting earlier and higher AI uptake than distressed peers. These findings, while based on Chinese data, provide a framework for early-warning signals and demonstrate the broader potential of AI metrics as a stable, complementary risk indicator distinct from traditional accounting measures.",
          "authors": [
            "Frederik Rech",
            "Fanchen Meng",
            "Hussam Musa",
            "Martin Šebeňa",
            "Siele Jean Tuo"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02879",
          "title": "The future of AI in critical mineral exploration",
          "abstract": "The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage",
          "authors": [
            "Jef Caers"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 8,
      "size": 21,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:2408.12057",
          "title": "Optimised Annealed Sequential Monte Carlo Samplers",
          "abstract": "Annealed Sequential Monte Carlo (ASMC) samplers are special cases of SMC samplers where the sequence of distributions can be embedded in a smooth path of distributions. Using this underlying path and a performance model based on the variance of the normalising constant estimator, we systematically study dense-schedule limits. From our theory emerges a notion of global barrier, capturing the inherent complexity of normalising constant approximation under our performance model. We then turn the resulting approximations into surrogate objective functions of algorithm performance, using them to guide method development. This leads to novel adaptive methods, Optimised Annealed SMC (OASMC), which address practical difficulties inherent in previous adaptive SMC methods. First, our OASMC algorithms are predictable: they produce a sequence of increasingly precise estimates at deterministic, known times. Second, Optimised Annealed Importance Sampling (OAIS), a special case of OASMC, enables schedule adaptation at a memory cost constant in the number of particles, requiring significantly less communication. Finally, these characteristics make OAIS highly efficient on GPUs. We provide an open-source, high-performance GPU implementation of our method and demonstrate up to a hundred-fold speed improvement compared to state-of-the-art adaptive AIS methods.",
          "primary_category": "stat.CO",
          "authors": [
            "Saifuddin Syed",
            "Alexandre Bouchard-Côté",
            "Kevin Chern",
            "Arnaud Doucet"
          ]
        },
        {
          "id": "arXiv:2512.02925",
          "title": "Fast Gaussian Process Approximations for Autocorrelated Data",
          "abstract": "This paper is concerned with the problem of how to speed up computation for Gaussian process models trained on autocorrelated data. The Gaussian process model is a powerful tool commonly used in nonlinear regression applications. Standard regression modeling assumes random samples and an independently, identically distributed noise. Various fast approximations that speed up Gaussian process regression work under this standard setting. But for autocorrelated data, failing to account for autocorrelation leads to a phenomenon known as temporal overfitting that deteriorates model performance on new test instances. To handle autocorrelated data, existing fast Gaussian process approximations have to be modified; one such approach is to segment the originally correlated data points into blocks in which the blocked data are de-correlated. This work explains how to make some of the existing Gaussian process approximations work with blocked data. Numerical experiments across diverse application datasets demonstrate that the proposed approaches can remarkably accelerate computation for Gaussian process regression on autocorrelated data without compromising model prediction performance.",
          "primary_category": "cs.LG",
          "authors": [
            "Ahmadreza Chokhachian",
            "Matthias Katzfuss",
            "Yu Ding"
          ]
        },
        {
          "id": "arXiv:2512.02721",
          "title": "Generative modeling using evolved quantum Boltzmann machines",
          "abstract": "Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935 ]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367 ], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.",
          "primary_category": "quant-ph",
          "authors": [
            "Mark M. Wilde"
          ]
        },
        {
          "id": "arXiv:2512.02721",
          "title": "Generative modeling using evolved quantum Boltzmann machines",
          "abstract": "Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935 ]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367 ], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.",
          "primary_category": "quant-ph",
          "authors": [
            "Mark M. Wilde"
          ]
        },
        {
          "id": "arXiv:2512.02721",
          "title": "Generative modeling using evolved quantum Boltzmann machines",
          "abstract": "Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935 ]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367 ], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.",
          "primary_category": "quant-ph",
          "authors": [
            "Mark M. Wilde"
          ]
        },
        {
          "id": "arXiv:2512.02411",
          "title": "Simulation-Based Inference of Ginzburg--Landau Parameters in Type--1.5 Superconductors",
          "abstract": "Inferring microscopic couplings in multi-component superconductors directly from vortex configurations is a challenging inverse problem. In Type-1.5 systems, Time-Dependent Ginzburg-Landau (TDGL) dynamics generate complex, glassy vortex patterns with high metastability. We explicitly quantify this intractability by analyzing the Hessian spectrum of the energy landscape, revealing a proliferation of soft modes that hinders traditional sampling. We address this challenge by combining a differentiable TDGL solver with Simulation-Based Inference (SBI). Our approach treats the solver as a stochastic forward model mapping physical parameters ({\\theta} = ({\\eta}, B, {\\nu})) to vortex density fields. Using Neural Ratio Estimation (NRE), we train a classifier to approximate the likelihood-to-evidence ratio and perform Bayesian inference for the interband Josephson coupling from vortex density fields. On synthetic data, the proposed method reliably recovers the coupling with calibrated uncertainty.",
          "primary_category": "cond-mat.supr-con",
          "authors": [
            "Jung-Shen Kao"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:2408.12057",
          "title": "Optimised Annealed Sequential Monte Carlo Samplers",
          "abstract": "Annealed Sequential Monte Carlo (ASMC) samplers are special cases of SMC samplers where the sequence of distributions can be embedded in a smooth path of distributions. Using this underlying path and a performance model based on the variance of the normalising constant estimator, we systematically study dense-schedule limits. From our theory emerges a notion of global barrier, capturing the inherent complexity of normalising constant approximation under our performance model. We then turn the resulting approximations into surrogate objective functions of algorithm performance, using them to guide method development. This leads to novel adaptive methods, Optimised Annealed SMC (OASMC), which address practical difficulties inherent in previous adaptive SMC methods. First, our OASMC algorithms are predictable: they produce a sequence of increasingly precise estimates at deterministic, known times. Second, Optimised Annealed Importance Sampling (OAIS), a special case of OASMC, enables schedule adaptation at a memory cost constant in the number of particles, requiring significantly less communication. Finally, these characteristics make OAIS highly efficient on GPUs. We provide an open-source, high-performance GPU implementation of our method and demonstrate up to a hundred-fold speed improvement compared to state-of-the-art adaptive AIS methods.",
          "authors": [
            "Saifuddin Syed",
            "Alexandre Bouchard-Côté",
            "Kevin Chern",
            "Arnaud Doucet"
          ],
          "primary_category": "stat.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.18856",
          "title": "Relaxed and inertial nonlinear Forward-Backward algorithm",
          "abstract": "The Nonlinear Forward-Backward (NFB) algorithm, also known as warped resolvent iterations, is a splitting method for finding zeros of sums of monotone operators. In particular cases, NFB reduces to well-known algorithms such as Forward-Backward, Forward-Backward-Forward, Chambolle--Pock, and Condat--Vũ. Therefore, NFB can be used to solve monotone inclusions involving sums of maximally monotone, cocoercive, monotone and Lipschitz operators as well as linear compositions terms. In this article, we study the weak and strong (linear) convergence of NFB with inertial and relaxation steps. Our results recover known convergence guarantees for the aforementioned methods when extended with inertial and relaxation terms. Additionally, we establish the convergence of inertial and relaxed variants of the Forward-Backward-Half-Forward and Forward-Primal--Dual-Half-Forward algorithms, which, to the best of our knowledge, are new contributions. We consider both nondecreasing and decreasing sequences of inertial parameters, the latter being a novel approach in the context of inertial algorithms. To evaluate the performance of these strategies, we present numerical experiments on optimization problems with affine constraints and on image restoration tasks. Our results show that decreasing inertial sequences can accelerate the numerical convergence of the algorithms.",
          "authors": [
            "Juan José Maulén",
            "Fernando Roldán",
            "Cristian Vega"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.12513",
          "title": "Anderson Acceleration For Perturbed Newton Methods",
          "abstract": "We present a convergence theory for Anderson acceleration (AA) applied to perturbed Newton methods (pNMs) for computing roots of nonlinear problems. Two important special cases are the classical Newton method and the Levenberg-Marquardt method. We prove that if a problem is 2-regular, then Anderson accelerated pNMs coupled with a safeguarding scheme, known as $\\gamma$-safeguarding, converge locally linearly in a starlike domain of convergence, but with an improved rate of convergence compared to standard perturbed Newton methods. Since Levenberg-Marquardt methods are a special case of pNMs, we obtain a novel acceleration and local convergence result for Anderson accelerated Levenberg-Marquardt. We further show that $\\gamma$-safeguarding can detect if the underlying perturbed Newton method is converging superlinearly, and respond by tuning the Anderson step down. We demonstrate the methods on several benchmark problems in the literature.",
          "authors": [
            "Matt Dallas"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.12513",
          "title": "Anderson Acceleration For Perturbed Newton Methods",
          "abstract": "We present a convergence theory for Anderson acceleration (AA) applied to perturbed Newton methods (pNMs) for computing roots of nonlinear problems. Two important special cases are the classical Newton method and the Levenberg-Marquardt method. We prove that if a problem is 2-regular, then Anderson accelerated pNMs coupled with a safeguarding scheme, known as $\\gamma$-safeguarding, converge locally linearly in a starlike domain of convergence, but with an improved rate of convergence compared to standard perturbed Newton methods. Since Levenberg-Marquardt methods are a special case of pNMs, we obtain a novel acceleration and local convergence result for Anderson accelerated Levenberg-Marquardt. We further show that $\\gamma$-safeguarding can detect if the underlying perturbed Newton method is converging superlinearly, and respond by tuning the Anderson step down. We demonstrate the methods on several benchmark problems in the literature.",
          "authors": [
            "Matt Dallas"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.18413",
          "title": "Parallelizing MCMC Across the Sequence Length",
          "abstract": "Markov chain Monte Carlo (MCMC) methods are foundational algorithms for Bayesian inference and probabilistic modeling. However, most MCMC algorithms are inherently sequential and their time complexity scales linearly with the sequence length. Previous work on adapting MCMC to modern hardware has therefore focused on running many independent chains in parallel. Here, we take an alternative approach: we propose algorithms to evaluate MCMC samplers in parallel across the chain length. To do this, we build on recent methods for parallel evaluation of nonlinear recursions that formulate the state sequence as a solution to a fixed-point problem and solve for the fixed-point using a parallel form of Newton's method. We show how this approach can be used to parallelize Gibbs, Metropolis-adjusted Langevin, and Hamiltonian Monte Carlo sampling across the sequence length. In several examples, we demonstrate the simulation of up to hundreds of thousands of MCMC samples with only tens of parallel Newton iterations. Additionally, we develop two new parallel quasi-Newton methods to evaluate nonlinear recursions with lower memory costs and reduced runtime. We find that the proposed parallel algorithms accelerate MCMC sampling across multiple examples, in some cases by more than an order of magnitude compared to sequential evaluation.",
          "authors": [
            "David M. Zoltowski",
            "Skyler Wu",
            "Xavier Gonzalez",
            "Leo Kozachkov",
            "Scott W. Linderman"
          ],
          "primary_category": "stat.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.06030",
          "title": "Adaptive Pruning for Increased Robustness and Reduced Computational Overhead in Gaussian Process Accelerated Saddle Point Searches",
          "abstract": "Gaussian process (GP) regression provides a strategy for accelerating saddle point searches on high-dimensional energy surfaces by reducing the number of times the energy and its derivatives with respect to atomic coordinates need to be evaluated. The computational overhead in the hyperparameter optimization can, however, be large and make the approach inefficient. Failures can also occur if the search ventures too far into regions that are not represented well enough by the GP model. Here, these challenges are resolved by using geometry-aware optimal transport measures and an active pruning strategy using a summation over Wasserstein-1 distances for each atom-type in farthest-point sampling, selecting a fixed-size subset of geometrically diverse configurations to avoid rapidly increasing cost of GP updates as more observations are made. Stability is enhanced by permutation-invariant metric that provides a reliable trust radius for early-stopping and a logarithmic barrier penalty for the growth of the signal variance. These physically motivated algorithmic changes prove their efficacy by reducing to less than a half the mean computational time on a set of 238 challenging configurations from a previously published data set of chemical reactions. With these improvements, the GP approach is established as, a robust and scalable algorithm for accelerating saddle point searches when the evaluation of the energy and atomic forces requires significant computational effort.",
          "authors": [
            "Rohit Goswami",
            "Hannes Jónsson"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.06030",
          "title": "Adaptive Pruning for Increased Robustness and Reduced Computational Overhead in Gaussian Process Accelerated Saddle Point Searches",
          "abstract": "Gaussian process (GP) regression provides a strategy for accelerating saddle point searches on high-dimensional energy surfaces by reducing the number of times the energy and its derivatives with respect to atomic coordinates need to be evaluated. The computational overhead in the hyperparameter optimization can, however, be large and make the approach inefficient. Failures can also occur if the search ventures too far into regions that are not represented well enough by the GP model. Here, these challenges are resolved by using geometry-aware optimal transport measures and an active pruning strategy using a summation over Wasserstein-1 distances for each atom-type in farthest-point sampling, selecting a fixed-size subset of geometrically diverse configurations to avoid rapidly increasing cost of GP updates as more observations are made. Stability is enhanced by permutation-invariant metric that provides a reliable trust radius for early-stopping and a logarithmic barrier penalty for the growth of the signal variance. These physically motivated algorithmic changes prove their efficacy by reducing to less than a half the mean computational time on a set of 238 challenging configurations from a previously published data set of chemical reactions. With these improvements, the GP approach is established as, a robust and scalable algorithm for accelerating saddle point searches when the evaluation of the energy and atomic forces requires significant computational effort.",
          "authors": [
            "Rohit Goswami",
            "Hannes Jónsson"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.06030",
          "title": "Adaptive Pruning for Increased Robustness and Reduced Computational Overhead in Gaussian Process Accelerated Saddle Point Searches",
          "abstract": "Gaussian process (GP) regression provides a strategy for accelerating saddle point searches on high-dimensional energy surfaces by reducing the number of times the energy and its derivatives with respect to atomic coordinates need to be evaluated. The computational overhead in the hyperparameter optimization can, however, be large and make the approach inefficient. Failures can also occur if the search ventures too far into regions that are not represented well enough by the GP model. Here, these challenges are resolved by using geometry-aware optimal transport measures and an active pruning strategy using a summation over Wasserstein-1 distances for each atom-type in farthest-point sampling, selecting a fixed-size subset of geometrically diverse configurations to avoid rapidly increasing cost of GP updates as more observations are made. Stability is enhanced by permutation-invariant metric that provides a reliable trust radius for early-stopping and a logarithmic barrier penalty for the growth of the signal variance. These physically motivated algorithmic changes prove their efficacy by reducing to less than a half the mean computational time on a set of 238 challenging configurations from a previously published data set of chemical reactions. With these improvements, the GP approach is established as, a robust and scalable algorithm for accelerating saddle point searches when the evaluation of the energy and atomic forces requires significant computational effort.",
          "authors": [
            "Rohit Goswami",
            "Hannes Jónsson"
          ],
          "primary_category": "physics.chem-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02323",
          "title": "Unlocking the Power of Boltzmann Machines by Parallelizable Sampler and Efficient Temperature Estimation",
          "abstract": "Boltzmann machines (BMs) are powerful energy-based generative models, but their heavy training cost has largely confined practical use to Restricted BMs (RBMs) trained with an efficient learning method called contrastive divergence. More accurate learning typically requires Markov chain Monte Carlo (MCMC) Boltzmann sampling, but it is time-consuming due to the difficulty of parallelization for more expressive models. To address this limitation, we first propose a new Boltzmann sampler inspired by a quantum-inspired combinatorial optimization called simulated bifurcation (SB). This SB-inspired approach, which we name Langevin SB (LSB), enables parallelized sampling while maintaining accuracy comparable to MCMC. Furthermore, this is applicable not only to RBMs but also to BMs with general couplings. However, LSB cannot control the inverse temperature of the output Boltzmann distribution, which hinders learning and degrades performance. To overcome this limitation, we also developed an efficient method for estimating the inverse temperature during the learning process, which we call conditional expectation matching (CEM). By combining LSB and CEM, we establish an efficient learning framework for BMs with greater expressive power than RBMs. We refer to this framework as sampler-adaptive learning (SAL). SAL opens new avenues for energy-based generative modeling beyond RBMs.",
          "authors": [
            "Kentaro Kubo",
            "Hayato Goto"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02323",
          "title": "Unlocking the Power of Boltzmann Machines by Parallelizable Sampler and Efficient Temperature Estimation",
          "abstract": "Boltzmann machines (BMs) are powerful energy-based generative models, but their heavy training cost has largely confined practical use to Restricted BMs (RBMs) trained with an efficient learning method called contrastive divergence. More accurate learning typically requires Markov chain Monte Carlo (MCMC) Boltzmann sampling, but it is time-consuming due to the difficulty of parallelization for more expressive models. To address this limitation, we first propose a new Boltzmann sampler inspired by a quantum-inspired combinatorial optimization called simulated bifurcation (SB). This SB-inspired approach, which we name Langevin SB (LSB), enables parallelized sampling while maintaining accuracy comparable to MCMC. Furthermore, this is applicable not only to RBMs but also to BMs with general couplings. However, LSB cannot control the inverse temperature of the output Boltzmann distribution, which hinders learning and degrades performance. To overcome this limitation, we also developed an efficient method for estimating the inverse temperature during the learning process, which we call conditional expectation matching (CEM). By combining LSB and CEM, we establish an efficient learning framework for BMs with greater expressive power than RBMs. We refer to this framework as sampler-adaptive learning (SAL). SAL opens new avenues for energy-based generative modeling beyond RBMs.",
          "authors": [
            "Kentaro Kubo",
            "Hayato Goto"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02323",
          "title": "Unlocking the Power of Boltzmann Machines by Parallelizable Sampler and Efficient Temperature Estimation",
          "abstract": "Boltzmann machines (BMs) are powerful energy-based generative models, but their heavy training cost has largely confined practical use to Restricted BMs (RBMs) trained with an efficient learning method called contrastive divergence. More accurate learning typically requires Markov chain Monte Carlo (MCMC) Boltzmann sampling, but it is time-consuming due to the difficulty of parallelization for more expressive models. To address this limitation, we first propose a new Boltzmann sampler inspired by a quantum-inspired combinatorial optimization called simulated bifurcation (SB). This SB-inspired approach, which we name Langevin SB (LSB), enables parallelized sampling while maintaining accuracy comparable to MCMC. Furthermore, this is applicable not only to RBMs but also to BMs with general couplings. However, LSB cannot control the inverse temperature of the output Boltzmann distribution, which hinders learning and degrades performance. To overcome this limitation, we also developed an efficient method for estimating the inverse temperature during the learning process, which we call conditional expectation matching (CEM). By combining LSB and CEM, we establish an efficient learning framework for BMs with greater expressive power than RBMs. We refer to this framework as sampler-adaptive learning (SAL). SAL opens new avenues for energy-based generative modeling beyond RBMs.",
          "authors": [
            "Kentaro Kubo",
            "Hayato Goto"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02342",
          "title": "Safeguarded Stochastic Polyak Step Sizes for Non-smooth Optimization: Robust Performance Without Small (Sub)Gradients",
          "abstract": "The stochastic Polyak step size (SPS) has proven to be a promising choice for stochastic gradient descent (SGD), delivering competitive performance relative to state-of-the-art methods on smooth convex and non-convex optimization problems, including deep neural network training. However, extensions of this approach to non-smooth settings remain in their early stages, often relying on interpolation assumptions or requiring knowledge of the optimal solution. In this work, we propose a novel SPS variant, Safeguarded SPS (SPS$_{safe}$), for the stochastic subgradient method, and provide rigorous convergence guarantees for non-smooth convex optimization with no need for strong assumptions. We further incorporate momentum into the update rule, yielding equally tight theoretical results. Comprehensive experiments on convex benchmarks and deep neural networks corroborate our theory: the proposed step size accelerates convergence, reduces variance, and consistently outperforms existing adaptive baselines. Finally, in the context of deep neural network training, our method demonstrates robust performance by addressing the vanishing gradient problem.",
          "authors": [
            "Dimitris Oikonomou",
            "Nicolas Loizou"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02342",
          "title": "Safeguarded Stochastic Polyak Step Sizes for Non-smooth Optimization: Robust Performance Without Small (Sub)Gradients",
          "abstract": "The stochastic Polyak step size (SPS) has proven to be a promising choice for stochastic gradient descent (SGD), delivering competitive performance relative to state-of-the-art methods on smooth convex and non-convex optimization problems, including deep neural network training. However, extensions of this approach to non-smooth settings remain in their early stages, often relying on interpolation assumptions or requiring knowledge of the optimal solution. In this work, we propose a novel SPS variant, Safeguarded SPS (SPS$_{safe}$), for the stochastic subgradient method, and provide rigorous convergence guarantees for non-smooth convex optimization with no need for strong assumptions. We further incorporate momentum into the update rule, yielding equally tight theoretical results. Comprehensive experiments on convex benchmarks and deep neural networks corroborate our theory: the proposed step size accelerates convergence, reduces variance, and consistently outperforms existing adaptive baselines. Finally, in the context of deep neural network training, our method demonstrates robust performance by addressing the vanishing gradient problem.",
          "authors": [
            "Dimitris Oikonomou",
            "Nicolas Loizou"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02342",
          "title": "Safeguarded Stochastic Polyak Step Sizes for Non-smooth Optimization: Robust Performance Without Small (Sub)Gradients",
          "abstract": "The stochastic Polyak step size (SPS) has proven to be a promising choice for stochastic gradient descent (SGD), delivering competitive performance relative to state-of-the-art methods on smooth convex and non-convex optimization problems, including deep neural network training. However, extensions of this approach to non-smooth settings remain in their early stages, often relying on interpolation assumptions or requiring knowledge of the optimal solution. In this work, we propose a novel SPS variant, Safeguarded SPS (SPS$_{safe}$), for the stochastic subgradient method, and provide rigorous convergence guarantees for non-smooth convex optimization with no need for strong assumptions. We further incorporate momentum into the update rule, yielding equally tight theoretical results. Comprehensive experiments on convex benchmarks and deep neural networks corroborate our theory: the proposed step size accelerates convergence, reduces variance, and consistently outperforms existing adaptive baselines. Finally, in the context of deep neural network training, our method demonstrates robust performance by addressing the vanishing gradient problem.",
          "authors": [
            "Dimitris Oikonomou",
            "Nicolas Loizou"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02411",
          "title": "Simulation-Based Inference of Ginzburg--Landau Parameters in Type--1.5 Superconductors",
          "abstract": "Inferring microscopic couplings in multi-component superconductors directly from vortex configurations is a challenging inverse problem. In Type-1.5 systems, Time-Dependent Ginzburg-Landau (TDGL) dynamics generate complex, glassy vortex patterns with high metastability. We explicitly quantify this intractability by analyzing the Hessian spectrum of the energy landscape, revealing a proliferation of soft modes that hinders traditional sampling. We address this challenge by combining a differentiable TDGL solver with Simulation-Based Inference (SBI). Our approach treats the solver as a stochastic forward model mapping physical parameters ({\\theta} = ({\\eta}, B, {\\nu})) to vortex density fields. Using Neural Ratio Estimation (NRE), we train a classifier to approximate the likelihood-to-evidence ratio and perform Bayesian inference for the interband Josephson coupling from vortex density fields. On synthetic data, the proposed method reliably recovers the coupling with calibrated uncertainty.",
          "authors": [
            "Jung-Shen Kao"
          ],
          "primary_category": "cond-mat.supr-con",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02721",
          "title": "Generative modeling using evolved quantum Boltzmann machines",
          "abstract": "Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935 ]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367 ], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.",
          "authors": [
            "Mark M. Wilde"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02721",
          "title": "Generative modeling using evolved quantum Boltzmann machines",
          "abstract": "Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935 ]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367 ], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.",
          "authors": [
            "Mark M. Wilde"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02721",
          "title": "Generative modeling using evolved quantum Boltzmann machines",
          "abstract": "Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935 ]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367 ], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.",
          "authors": [
            "Mark M. Wilde"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02925",
          "title": "Fast Gaussian Process Approximations for Autocorrelated Data",
          "abstract": "This paper is concerned with the problem of how to speed up computation for Gaussian process models trained on autocorrelated data. The Gaussian process model is a powerful tool commonly used in nonlinear regression applications. Standard regression modeling assumes random samples and an independently, identically distributed noise. Various fast approximations that speed up Gaussian process regression work under this standard setting. But for autocorrelated data, failing to account for autocorrelation leads to a phenomenon known as temporal overfitting that deteriorates model performance on new test instances. To handle autocorrelated data, existing fast Gaussian process approximations have to be modified; one such approach is to segment the originally correlated data points into blocks in which the blocked data are de-correlated. This work explains how to make some of the existing Gaussian process approximations work with blocked data. Numerical experiments across diverse application datasets demonstrate that the proposed approaches can remarkably accelerate computation for Gaussian process regression on autocorrelated data without compromising model prediction performance.",
          "authors": [
            "Ahmadreza Chokhachian",
            "Matthias Katzfuss",
            "Yu Ding"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02925",
          "title": "Fast Gaussian Process Approximations for Autocorrelated Data",
          "abstract": "This paper is concerned with the problem of how to speed up computation for Gaussian process models trained on autocorrelated data. The Gaussian process model is a powerful tool commonly used in nonlinear regression applications. Standard regression modeling assumes random samples and an independently, identically distributed noise. Various fast approximations that speed up Gaussian process regression work under this standard setting. But for autocorrelated data, failing to account for autocorrelation leads to a phenomenon known as temporal overfitting that deteriorates model performance on new test instances. To handle autocorrelated data, existing fast Gaussian process approximations have to be modified; one such approach is to segment the originally correlated data points into blocks in which the blocked data are de-correlated. This work explains how to make some of the existing Gaussian process approximations work with blocked data. Numerical experiments across diverse application datasets demonstrate that the proposed approaches can remarkably accelerate computation for Gaussian process regression on autocorrelated data without compromising model prediction performance.",
          "authors": [
            "Ahmadreza Chokhachian",
            "Matthias Katzfuss",
            "Yu Ding"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03023",
          "title": "Asymptotic Analysis of Stochastic Splitting Methods for Multivariate Monotone Inclusions",
          "abstract": "We propose an abstract framework to establish the convergence of the iterates of stochastic versions of a broad range of monotone operator splitting methods in Hilbert spaces. This framework allows for the introduction of stochasticity at several levels: approximation of operators, selection of coordinates and operators in block-iterative implementations, and relaxation parameters. The proposed analysis involves a reduced inclusion model with two operators. At each iteration, stochastic approximations to points in the graphs of these two operators are used to form the update. The results are applied to derive the almost sure and $L^2$ convergence of stochastic versions of the proximal point algorithm, as well as of randomized block-iterative projective splitting methods for solving systems of coupled inclusions involving a mix of set-valued, cocoercive, and Lipschitzian monotone operators combined via various monotonicity-preserving operations.",
          "authors": [
            "Patrick L. Combettes",
            "Javier I. Madariaga"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    },
    {
      "cluster_id": 9,
      "size": 938,
      "rescued": false,
      "topic": "",
      "keywords": [],
      "description": "",
      "representatives": [
        {
          "id": "arXiv:1903.08485",
          "title": "A review of mechanistic and data-driven models of terrorism and radicalization",
          "abstract": "The rapid spread of radical ideologies in recent years has led to a worldwide string of terrorist attacks. Understanding how extremist tendencies germinate, develop, and drive individuals to action is important from a cultural standpoint, but also to help formulate response and prevention strategies. Demographic studies, interviews with radicalized subjects, analysis of terrorist databases, reveal that the path to radicalization occurs along progressive steps, where age, social context and peer-to-peer exchange of extremist ideas play major roles. Furthermore, the advent of social media has offered new channels of communication, facilitated recruitment, and hastened the leap from mild discontent to unbridled fanaticism. While a complete sociological understanding of the processes and circumstances that lead to full-fledged extremism is still lacking, quantitative approaches, using modeling and data analyses, can offer useful insight. We review some approaches from statistical mechanics, applied mathematics, data science, that can help describe and understand radicalization and terrorist activity. Specifically, we focus on compartment models of populations harboring extremist views, continuous time models for age-structured radical populations, radicalization as social contagion processes on lattices and social networks, adversarial evolutionary games coupling terrorists and counter-terrorism agents, and point processes to study the spatiotemporal clustering of terrorist events. We also present recent applications of machine learning methods on open-source terrorism databases. Finally, we discuss the role of institutional intervention and the stages at which de-radicalization strategies might be most effective.",
          "primary_category": "physics.soc-ph",
          "authors": [
            "Yao-li Chuang",
            "Maria R. D'Orsogna"
          ]
        },
        {
          "id": "arXiv:2512.02456",
          "title": "See, Think, Learn: A Self-Taught Multimodal Reasoner",
          "abstract": "Vision-Language Models (VLMs) have achieved remarkable progress in integrating visual perception with language understanding. However, effective multimodal reasoning requires both accurate perception and robust reasoning, and weakness in either limits the performance of VLMs. Prior efforts to enhance reasoning often depend on high-quality chain-of-thought (CoT) data, obtained via labor-intensive human annotations, costly proprietary models, or self-training methods that overlook perception. To address these limitations, we propose a simple yet effective self-training framework called See-Think-Learn (STL). At its core, STL introduces a structured reasoning template that encourages the model to see before thinking, first extracting visual attributes in textual form, then using them to guide reasoning. The framework jointly improves perception and reasoning by having the model generate and learn from its own structured rationales in a self-training loop. Furthermore, we augment the training data with negative rationales, i.e. explanations that justify why certain answer choices are incorrect, to enhance the model's ability to distinguish between correct and misleading responses. This fosters more discriminative and robust learning. Experiments across diverse domains show that STL consistently outperforms baselines trained directly only on answers or self-generated reasoning, while qualitative analysis confirms the high quality of its rationales. STL thus provides a cost-effective solution to enhance multimodal reasoning ability of VLMs.",
          "primary_category": "cs.CV",
          "authors": [
            "Sourabh Sharma",
            "Sonam Gupta",
            "Sadbhawna"
          ]
        },
        {
          "id": "arXiv:2512.02457",
          "title": "Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation",
          "abstract": "Recent audio-video generative systems suggest that coupling modalities benefits not only audio-video synchrony but also the video modality itself. We pose a fundamental question: Does audio-video joint denoising training improve video generation, even when we only care about video quality? To study this, we introduce a parameter-efficient Audio-Video Full DiT (AVFullDiT) architecture that leverages pre-trained text-to-video (T2V) and text-to-audio (T2A) modules for joint denoising. We train (i) a T2AV model with AVFullDiT and (ii) a T2V-only counterpart under identical settings. Our results provide the first systematic evidence that audio-video joint denoising can deliver more than synchrony. We observe consistent improvements on challenging subsets featuring large and object contact motions. We hypothesize that predicting audio acts as a privileged signal, encouraging the model to internalize causal relationships between visual events and their acoustic consequences (e.g., collision $\\times$ impact sound), which in turn regularizes video dynamics. Our findings suggest that cross-modal co-training is a promising approach to developing stronger, more physically grounded world models. Code and dataset will be made publicly available.",
          "primary_category": "cs.CV",
          "authors": [
            "Jianzong Wu",
            "Hao Lian",
            "Dachao Hao",
            "Ye Tian",
            "Qingyu Shi",
            "Biaolong Chen",
            "Hao Jiang"
          ]
        },
        {
          "id": "arXiv:2512.02458",
          "title": "Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration",
          "abstract": "Existing research on indoor embodied tasks typically requires agents to actively explore unknown environments and reason about the scene to achieve a specific goal. However, when deployed in real life, agents often face sequential tasks, where each new sub-task follows the completion of the previous one, and certain sub-tasks may be infeasible, such as searching for a non-existent object. Compared with the single-task setting, the core challenge lies in reusing spatial knowledge accumulated from previous explorations to support subsequent reasoning and exploration. In this work, we investigate this underexplored yet practically significant embodied AI challenge. To evaluate this challenge, we introduce SEER-Bench, a new Sequential Embodied Exploration and Reasoning Benchmark encompassing encompassing two classic embodied tasks: Embodied Question Answering (EQA) and Embodied Multi-modal Navigation (EMN). Building on SEER-Bench, we propose 3DSPMR, a 3D SPatial Memory Reasoning approach that exploits relational, visual, and geometric cues from explored regions to augment Multi-Modal Large Language Models (MLLMs) for reasoning and exploration in sequential embodied tasks. To the best of our knowledge, this is the first work to explicitly incorporate geometric information into MLLM-based spatial understanding and reasoning. Extensive experiments verify that 3DSPMR achieves substantial performance gains on both sequential EQA and EMN tasks.",
          "primary_category": "cs.CV",
          "authors": [
            "Zhongyi Cai",
            "Yi Du",
            "Chen Wang",
            "Yu Kong"
          ]
        },
        {
          "id": "arXiv:2512.02459",
          "title": "Efficient Eye-based Emotion Recognition via Neural Architecture Search of Time-to-First-Spike-Coded Spiking Neural Networks",
          "abstract": "Eye-based emotion recognition enables eyewear devices to perceive users' emotional states and support emotion-aware interaction, yet deploying such functionality on their resource-limited embedded hardware remains challenging. Time-to-first-spike (TTFS)-coded spiking neural networks (SNNs) offer a promising solution, as each neuron emits at most one binary spike, resulting in extremely sparse and energy-efficient computation. While prior works have primarily focused on improving TTFS SNN training algorithms, the impact of network architecture has been largely overlooked. In this paper, we propose TNAS-ER, the first neural architecture search (NAS) framework tailored to TTFS SNNs for eye-based emotion recognition. TNAS-ER presents a novel ANN-assisted search strategy that leverages a ReLU-based ANN counterpart sharing an identity mapping with the TTFS SNN to guide architecture optimization. TNAS-ER employs an evolutionary algorithm, with weighted and unweighted average recall jointly defined as fitness objectives for emotion recognition. Extensive experiments demonstrate that TNAS-ER achieves high recognition performance with significantly improved efficiency. Furthermore, when deployed on neuromorphic hardware, TNAS-ER attains a low latency of 48 ms and an energy consumption of 0.05 J, confirming its superior energy efficiency and strong potential for practical applications.",
          "primary_category": "cs.NE",
          "authors": [
            "Qianhui Liu",
            "Jing Yang",
            "Miao Yu",
            "Trevor E. Carlson",
            "Gang Pan",
            "Haizhou Li",
            "Zhumin Chen"
          ]
        },
        {
          "id": "arXiv:2512.02460",
          "title": "UniCom: Towards a Unified and Cohesiveness-aware Framework for Community Search and Detection",
          "abstract": "Searching and detecting communities in real-world graphs underpins a wide range of applications. Despite the success achieved, current learning-based solutions regard community search, i.e., locating the best community for a given query, and community detection, i.e., partitioning the whole graph, as separate problems, necessitating task- and dataset-specific retraining. Such a strategy limits the applicability and generalization ability of the existing models. Additionally, these methods rely heavily on information from the target dataset, leading to suboptimal performance when supervision is limited or unavailable. To mitigate this limitation, we propose UniCom, a unified framework to solve both community search and detection tasks through knowledge transfer across multiple domains, thus alleviating the limitations of single-dataset learning. UniCom centers on a Domain-aware Specialization (DAS) procedure that adapts on the fly to unseen graphs or tasks, eliminating costly retraining while maintaining framework compactness with a lightweight prompt-based paradigm. This is empowered by a Universal Graph Learning (UGL) backbone, which distills transferable semantic and topological knowledge from multiple source domains via comprehensive pre-training. Both DAS and UGL are informed by local neighborhood signals and cohesive subgraph structures, providing consistent guidance throughout the framework. Extensive experiments on both tasks across 16 benchmark datasets and 22 baselines have been conducted to ensure a comprehensive and fair evaluation. UniCom consistently outperforms all state-of-the-art baselines across all tasks under settings with scarce or no supervision, while maintaining runtime efficiency.",
          "primary_category": "cs.SI",
          "authors": [
            "Yifan Zhu",
            "Hanchen Wang",
            "Wenjie Zhang",
            "Alexander Zhou",
            "Ying Zhang"
          ]
        }
      ],
      "papers": [
        {
          "id": "arXiv:1903.08485",
          "title": "A review of mechanistic and data-driven models of terrorism and radicalization",
          "abstract": "The rapid spread of radical ideologies in recent years has led to a worldwide string of terrorist attacks. Understanding how extremist tendencies germinate, develop, and drive individuals to action is important from a cultural standpoint, but also to help formulate response and prevention strategies. Demographic studies, interviews with radicalized subjects, analysis of terrorist databases, reveal that the path to radicalization occurs along progressive steps, where age, social context and peer-to-peer exchange of extremist ideas play major roles. Furthermore, the advent of social media has offered new channels of communication, facilitated recruitment, and hastened the leap from mild discontent to unbridled fanaticism. While a complete sociological understanding of the processes and circumstances that lead to full-fledged extremism is still lacking, quantitative approaches, using modeling and data analyses, can offer useful insight. We review some approaches from statistical mechanics, applied mathematics, data science, that can help describe and understand radicalization and terrorist activity. Specifically, we focus on compartment models of populations harboring extremist views, continuous time models for age-structured radical populations, radicalization as social contagion processes on lattices and social networks, adversarial evolutionary games coupling terrorists and counter-terrorism agents, and point processes to study the spatiotemporal clustering of terrorist events. We also present recent applications of machine learning methods on open-source terrorism databases. Finally, we discuss the role of institutional intervention and the stages at which de-radicalization strategies might be most effective.",
          "authors": [
            "Yao-li Chuang",
            "Maria R. D'Orsogna"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:1903.08485",
          "title": "A review of mechanistic and data-driven models of terrorism and radicalization",
          "abstract": "The rapid spread of radical ideologies in recent years has led to a worldwide string of terrorist attacks. Understanding how extremist tendencies germinate, develop, and drive individuals to action is important from a cultural standpoint, but also to help formulate response and prevention strategies. Demographic studies, interviews with radicalized subjects, analysis of terrorist databases, reveal that the path to radicalization occurs along progressive steps, where age, social context and peer-to-peer exchange of extremist ideas play major roles. Furthermore, the advent of social media has offered new channels of communication, facilitated recruitment, and hastened the leap from mild discontent to unbridled fanaticism. While a complete sociological understanding of the processes and circumstances that lead to full-fledged extremism is still lacking, quantitative approaches, using modeling and data analyses, can offer useful insight. We review some approaches from statistical mechanics, applied mathematics, data science, that can help describe and understand radicalization and terrorist activity. Specifically, we focus on compartment models of populations harboring extremist views, continuous time models for age-structured radical populations, radicalization as social contagion processes on lattices and social networks, adversarial evolutionary games coupling terrorists and counter-terrorism agents, and point processes to study the spatiotemporal clustering of terrorist events. We also present recent applications of machine learning methods on open-source terrorism databases. Finally, we discuss the role of institutional intervention and the stages at which de-radicalization strategies might be most effective.",
          "authors": [
            "Yao-li Chuang",
            "Maria R. D'Orsogna"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:1911.04232",
          "title": "Statistical Analysis of weather variables of Antofagasta",
          "abstract": "The statistical behavior of weather variables of Antofagasta is described, especially the daily data of air as temperature, pressure and relative humidity measured at 08:00, 14:00 and 20:00. In this article, we use a time series deseasonalization technique, Q-Q plot, skewness, kurtosis and the Pearson correlation coefficient. We found that the distributions of the records are symmetrical and have positive kurtosis, so they have heavy tails. In addition, the variables are highly autocorrelated, extending up to one year in the case of pressure and temperature.",
          "authors": [
            "H. Farfan",
            "A. Castillo",
            "S. Curilef"
          ],
          "primary_category": "physics.ao-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2009.04413",
          "title": "On SkipGram Word Embedding Models with Negative Sampling: Unified Framework and Impact of Noise Distributions",
          "abstract": "SkipGram word embedding models with negative sampling, or SGN in short, is an elegant family of word embedding models. In this paper, we formulate a framework for word embedding, referred to as Word-Context Classification (WCC), that generalizes SGN to a wide family of models. The framework, which uses some ``noise examples'', is justified through theoretical analysis. The impact of noise distribution on the learning of the WCC embedding models is studied experimentally, suggesting that the best noise distribution is, in fact, the data distribution, in terms of both the embedding performance and the speed of convergence during training. Along our way, we discover several novel embedding models that outperform existing WCC models.",
          "authors": [
            "Dezhi Liu",
            "Richong Zhang",
            "Ziqiao Wang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2009.04413",
          "title": "On SkipGram Word Embedding Models with Negative Sampling: Unified Framework and Impact of Noise Distributions",
          "abstract": "SkipGram word embedding models with negative sampling, or SGN in short, is an elegant family of word embedding models. In this paper, we formulate a framework for word embedding, referred to as Word-Context Classification (WCC), that generalizes SGN to a wide family of models. The framework, which uses some ``noise examples'', is justified through theoretical analysis. The impact of noise distribution on the learning of the WCC embedding models is studied experimentally, suggesting that the best noise distribution is, in fact, the data distribution, in terms of both the embedding performance and the speed of convergence during training. Along our way, we discover several novel embedding models that outperform existing WCC models.",
          "authors": [
            "Dezhi Liu",
            "Richong Zhang",
            "Ziqiao Wang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2102.11766",
          "title": "Towers on the Peaks of Eternal Light: Quantifying the Available Solar Power",
          "abstract": "The Peaks of Eternal Light (PELs), that are largely unshaded regions mostly at the lunar south pole, have been suggested as a source of solar power for mining the water and other volatiles in the nearby permanently dark regions. As mining is a power-intensive activity, it is interesting to estimate the maximum solar power that could be generated at the PELs. Here we use average percentage illumination maps for a range of heights above the local topography from 2 m to 2 km to determine the total power available as a function of time of lunar day. Overshadowing of highly illuminated areas by towers placed in sunward locations (at a given time of day) limits the total power to much smaller values than the highly illuminated area would suggest. We find that for near-term realizable towers (up to 20 m), the upper limit to the time-averaged power available is ~55 MW at >70% illumination, and ~6 MW at >90% illumination. For the more distant future a maximum time-averaged power of order 21000 MW at >70% illumination could be realizable for towers up to 2 km in height, and ~5270 MW, respectively, at 90% illumination. Towers 1 km high provide about a factor 2.7 times less power. The variation with lunar time of day ranges from a factor of 1.1 to ~ 3.",
          "authors": [
            "Amia Ross",
            "Sephora Ruppert",
            "Philipp Gläser",
            "Martin Elvis"
          ],
          "primary_category": "astro-ph.EP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2112.08507",
          "title": "Algorithms for Adaptive Experiments that Trade-off Statistical Analysis with Reward: Combining Uniform Random Assignment and Reward Maximization",
          "abstract": "Traditional randomized A/B experiments assign arms with uniform random (UR) probability, such as 50/50 assignment to two versions of a website to discover whether one version engages users more. To more quickly and automatically use data to benefit users, multi-armed bandit algorithms such as Thompson Sampling (TS) have been advocated. While TS is interpretable and incorporates the randomization key to statistical inference, it can cause biased estimates and increase false positives and false negatives in detecting differences in arm means. We introduce a more Statistically Sensitive algorithm, TS-PostDiff (Posterior Probability of Small Difference), that mixes TS with traditional UR by using an additional adaptive step, where the probability of using UR (vs TS) is proportional to the posterior probability that the difference in arms is small. This allows an experimenter to define what counts as a small difference, below which a traditional UR experiment can obtain informative data for statistical inference at low cost, and above which using more TS to maximize user benefits is key. We evaluate TS-PostDiff against UR, TS, and two other TS variants designed to improve statistical inference. We consider results for the common two-armed experiment across a range of settings inspired by real-world applications. Our results provide insight into when and why TS-PostDiff or alternative approaches provide better tradeoffs between benefiting users (reward) and statistical inference (false positive rate and power). TS-PostDiff's adaptivity helps efficiently reduce false positives and increase statistical power when differences are small, while increasing reward more when differences are large. The work highlights important considerations for future Statistically Sensitive algorithm development that balances reward and statistical analysis in adaptive experimentation.",
          "authors": [
            "Tong Li",
            "Jacob Nogas",
            "Haochen Song",
            "Anna Rafferty",
            "Eric M. Schwartz",
            "Audrey Durand",
            "Harsh Kumar",
            "Nina Deliu",
            "Sofia S. Villar",
            "Dehan Kong",
            "Joseph J. Williams"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2112.08507",
          "title": "Algorithms for Adaptive Experiments that Trade-off Statistical Analysis with Reward: Combining Uniform Random Assignment and Reward Maximization",
          "abstract": "Traditional randomized A/B experiments assign arms with uniform random (UR) probability, such as 50/50 assignment to two versions of a website to discover whether one version engages users more. To more quickly and automatically use data to benefit users, multi-armed bandit algorithms such as Thompson Sampling (TS) have been advocated. While TS is interpretable and incorporates the randomization key to statistical inference, it can cause biased estimates and increase false positives and false negatives in detecting differences in arm means. We introduce a more Statistically Sensitive algorithm, TS-PostDiff (Posterior Probability of Small Difference), that mixes TS with traditional UR by using an additional adaptive step, where the probability of using UR (vs TS) is proportional to the posterior probability that the difference in arms is small. This allows an experimenter to define what counts as a small difference, below which a traditional UR experiment can obtain informative data for statistical inference at low cost, and above which using more TS to maximize user benefits is key. We evaluate TS-PostDiff against UR, TS, and two other TS variants designed to improve statistical inference. We consider results for the common two-armed experiment across a range of settings inspired by real-world applications. Our results provide insight into when and why TS-PostDiff or alternative approaches provide better tradeoffs between benefiting users (reward) and statistical inference (false positive rate and power). TS-PostDiff's adaptivity helps efficiently reduce false positives and increase statistical power when differences are small, while increasing reward more when differences are large. The work highlights important considerations for future Statistically Sensitive algorithm development that balances reward and statistical analysis in adaptive experimentation.",
          "authors": [
            "Tong Li",
            "Jacob Nogas",
            "Haochen Song",
            "Anna Rafferty",
            "Eric M. Schwartz",
            "Audrey Durand",
            "Harsh Kumar",
            "Nina Deliu",
            "Sofia S. Villar",
            "Dehan Kong",
            "Joseph J. Williams"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.09134",
          "title": "Gaussian and Non-Gaussian Universality of Data Augmentation",
          "abstract": "We provide universality results that quantify how data augmentation affects the variance and limiting distribution of estimates through simple surrogates, and analyze several specific models in detail. The results confirm some observations made in machine learning practice, but also lead to unexpected findings: Data augmentation may increase rather than decrease the uncertainty of estimates, such as the empirical prediction risk. It can act as a regularizer, but fails to do so in certain high-dimensional problems, and it may shift the double-descent peak of an empirical risk. Overall, the analysis shows that several properties data augmentation has been attributed with are not either true or false, but rather depend on a combination of factors -- notably the data distribution, the properties of the estimator, and the interplay of sample size, number of augmentations, and dimension. As our main theoretical tool, we develop an adaptation of Lindeberg's technique for block dependence. The resulting universality regime may be Gaussian or non-Gaussian.",
          "authors": [
            "Kevin Han Huang",
            "Peter Orbanz",
            "Morgane Austern"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.09134",
          "title": "Gaussian and Non-Gaussian Universality of Data Augmentation",
          "abstract": "We provide universality results that quantify how data augmentation affects the variance and limiting distribution of estimates through simple surrogates, and analyze several specific models in detail. The results confirm some observations made in machine learning practice, but also lead to unexpected findings: Data augmentation may increase rather than decrease the uncertainty of estimates, such as the empirical prediction risk. It can act as a regularizer, but fails to do so in certain high-dimensional problems, and it may shift the double-descent peak of an empirical risk. Overall, the analysis shows that several properties data augmentation has been attributed with are not either true or false, but rather depend on a combination of factors -- notably the data distribution, the properties of the estimator, and the interplay of sample size, number of augmentations, and dimension. As our main theoretical tool, we develop an adaptation of Lindeberg's technique for block dependence. The resulting universality regime may be Gaussian or non-Gaussian.",
          "authors": [
            "Kevin Han Huang",
            "Peter Orbanz",
            "Morgane Austern"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2202.09134",
          "title": "Gaussian and Non-Gaussian Universality of Data Augmentation",
          "abstract": "We provide universality results that quantify how data augmentation affects the variance and limiting distribution of estimates through simple surrogates, and analyze several specific models in detail. The results confirm some observations made in machine learning practice, but also lead to unexpected findings: Data augmentation may increase rather than decrease the uncertainty of estimates, such as the empirical prediction risk. It can act as a regularizer, but fails to do so in certain high-dimensional problems, and it may shift the double-descent peak of an empirical risk. Overall, the analysis shows that several properties data augmentation has been attributed with are not either true or false, but rather depend on a combination of factors -- notably the data distribution, the properties of the estimator, and the interplay of sample size, number of augmentations, and dimension. As our main theoretical tool, we develop an adaptation of Lindeberg's technique for block dependence. The resulting universality regime may be Gaussian or non-Gaussian.",
          "authors": [
            "Kevin Han Huang",
            "Peter Orbanz",
            "Morgane Austern"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2303.03397",
          "title": "Malaria detection using Deep Convolution Neural Network",
          "abstract": "The latest WHO report showed that the number of malaria cases climbed to 219 million last year, two million higher than last year. The global efforts to fight malaria have hit a plateau and the most significant underlying reason is international funding has declined. Malaria, which is spread to people through the bites of infected female mosquitoes, occurs in 91 countries but about 90% of the cases and deaths are in sub-Saharan Africa. The disease killed 4,35,000 people last year, the majority of them children under five in Africa. AI-backed technology has revolutionized malaria detection in some regions of Africa and the future impact of such work can be revolutionary. The malaria Cell Image Data-set is taken from the official NIH Website NIH data. The aim of the collection of the dataset was to reduce the burden for microscopists in resource-constrained regions and improve diagnostic accuracy using an AI-based algorithm to detect and segment the red blood cells. The goal of this work is to show that the state of the art accuracy can be obtained even by using 2 layer convolution network and show a new baseline in Malaria detection efforts using AI.",
          "authors": [
            "Sumit Kumar",
            "Harsh Vardhan",
            "Sneha Priya",
            "Ayush Kumar"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2305.19478",
          "title": "Permutation-Aware Action Segmentation via Unsupervised Frame-to-Segment Alignment",
          "abstract": "This paper presents an unsupervised transformer-based framework for temporal activity segmentation which leverages not only frame-level cues but also segment-level cues. This is in contrast with previous methods which often rely on frame-level information only. Our approach begins with a frame-level prediction module which estimates framewise action classes via a transformer encoder. The frame-level prediction module is trained in an unsupervised manner via temporal optimal transport. To exploit segment-level information, we utilize a segment-level prediction module and a frame-to-segment alignment module. The former includes a transformer decoder for estimating video transcripts, while the latter matches frame-level features with segment-level features, yielding permutation-aware segmentation results. Moreover, inspired by temporal optimal transport, we introduce simple-yet-effective pseudo labels for unsupervised training of the above modules. Our experiments on four public datasets, i.e., 50 Salads, YouTube Instructions, Breakfast, and Desktop Assembly show that our approach achieves comparable or better performance than previous methods in unsupervised activity segmentation. Our code and dataset are available on our research website: this https URL .",
          "authors": [
            "Quoc-Huy Tran",
            "Ahmed Mehmood",
            "Muhammad Ahmed",
            "Muhammad Naufil",
            "Anas Zafar",
            "Andrey Konin",
            "M. Zeeshan Zia"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2309.15039",
          "title": "Can-SAVE: Deploying Low-Cost and Population-Scale Cancer Screening via Survival Analysis Variables and EHR",
          "abstract": "Conventional medical cancer screening methods are costly, labor-intensive, and extremely difficult to scale. Although AI can improve cancer detection, most systems rely on complex or specialized medical data, making them impractical for large-scale screening. We introduce Can-SAVE, a lightweight AI system that ranks population-wide cancer risks solely based on medical history events. By integrating survival model outputs into a gradient-boosting framework, our approach detects subtle, long-term patient risk patterns - often well before clinical symptoms manifest. Can-SAVE was rigorously evaluated on a real-world dataset of 2.5 million adults spanning five Russian regions, marking the study as one of the largest and most comprehensive deployments of AI-driven cancer risk assessment. In a retrospective oncologist-supervised study over 1.9M patients, Can-SAVE achieves a 4-10x higher detection rate at identical screening volumes and an Average Precision (AP) of 0.228 vs. 0.193 for the best baseline (LoRA-tuned Qwen3-Embeddings via DeepSeek-R1 summarization). In a year-long prospective pilot (426K patients), our method almost doubled the cancer detection rate (+91%) and increased population coverage by 36% over the national screening protocol. The system demonstrates practical scalability: a city-wide population of 1 million patients can be processed in under three hours using standard hardware, enabling seamless clinical integration. This work proves that Can-SAVE achieves nationally significant cancer detection improvements while adhering to real-world public healthcare constraints, offering immediate clinical utility and a replicable framework for population-wide screening. Code for training and feature engineering is available at this https URL .",
          "authors": [
            "Petr Philonenko",
            "Vladimir Kokh",
            "Pavel Blinov"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2309.15039",
          "title": "Can-SAVE: Deploying Low-Cost and Population-Scale Cancer Screening via Survival Analysis Variables and EHR",
          "abstract": "Conventional medical cancer screening methods are costly, labor-intensive, and extremely difficult to scale. Although AI can improve cancer detection, most systems rely on complex or specialized medical data, making them impractical for large-scale screening. We introduce Can-SAVE, a lightweight AI system that ranks population-wide cancer risks solely based on medical history events. By integrating survival model outputs into a gradient-boosting framework, our approach detects subtle, long-term patient risk patterns - often well before clinical symptoms manifest. Can-SAVE was rigorously evaluated on a real-world dataset of 2.5 million adults spanning five Russian regions, marking the study as one of the largest and most comprehensive deployments of AI-driven cancer risk assessment. In a retrospective oncologist-supervised study over 1.9M patients, Can-SAVE achieves a 4-10x higher detection rate at identical screening volumes and an Average Precision (AP) of 0.228 vs. 0.193 for the best baseline (LoRA-tuned Qwen3-Embeddings via DeepSeek-R1 summarization). In a year-long prospective pilot (426K patients), our method almost doubled the cancer detection rate (+91%) and increased population coverage by 36% over the national screening protocol. The system demonstrates practical scalability: a city-wide population of 1 million patients can be processed in under three hours using standard hardware, enabling seamless clinical integration. This work proves that Can-SAVE achieves nationally significant cancer detection improvements while adhering to real-world public healthcare constraints, offering immediate clinical utility and a replicable framework for population-wide screening. Code for training and feature engineering is available at this https URL .",
          "authors": [
            "Petr Philonenko",
            "Vladimir Kokh",
            "Pavel Blinov"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2310.04660",
          "title": "Balancing Weights for Causal Inference in Observational Factorial Studies",
          "abstract": "Many scientific questions in biomedical, environmental, and psychological research involve understanding the effects of multiple factors on outcomes. While factorial experiments are ideal for this purpose, randomized controlled treatment assignment is generally infeasible in many empirical studies. Therefore, investigators must rely on observational data, where drawing reliable causal inferences for multiple factors remains challenging. As the number of treatment combinations grows exponentially with the number of factors, some treatment combinations can be rare or missing by chance in observed data, further complicating factorial effects estimation. To address these challenges, we propose a novel weighting method tailored to observational studies with multiple factors. Our approach uses weighted observational data to emulate a randomized factorial experiment, enabling simultaneous estimation of the effects of multiple factors and their interactions. Our investigations reveal a crucial nuance: achieving balance among covariates, as in single-factor scenarios, is necessary but insufficient for unbiasedly estimating factorial effects; balancing the factors is also essential in multi-factor settings. Moreover, we extend our weighting method to handle missing treatment combinations in observed data. Finally, we study the asymptotic behavior of the new weighting estimators and propose a consistent variance estimator, providing reliable inferences on factorial effects in observational studies.",
          "authors": [
            "Ruoqi Yu",
            "Peng Ding"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2310.11590",
          "title": "Predicting Human Perceptions of Robot Performance During Navigation Tasks",
          "abstract": "Understanding human perceptions of robot performance is crucial for designing socially intelligent robots that can adapt to human expectations. Current approaches often rely on surveys, which can disrupt ongoing human-robot interactions. As an alternative, we explore predicting people's perceptions of robot performance using non-verbal behavioral cues and machine learning techniques. We contribute the SEAN TOGETHER Dataset consisting of observations of an interaction between a person and a mobile robot in Virtual Reality, together with perceptions of robot performance provided by users on a 5-point scale. We then analyze how well humans and supervised learning techniques can predict perceived robot performance based on different observation types (like facial expression and spatial behavior features). Our results suggest that facial expressions alone provide useful information, but in the navigation scenarios that we considered, reasoning about spatial features in context is critical for the prediction task. Also, supervised learning techniques outperformed humans' predictions in most cases. Further, when predicting robot performance as a binary classification task on unseen users' data, the F1-Score of machine learning models more than doubled that of predictions on a 5-point scale. This suggested good generalization capabilities, particularly in identifying performance directionality over exact ratings. Based on these findings, we conducted a real-world demonstration where a mobile robot uses a machine learning model to predict how a human who follows it perceives it. Finally, we discuss the implications of our results for implementing these supervised learning models in real-world navigation. Our work paves the path to automatically enhancing robot behavior based on observations of users and inferences about their perceptions of a robot.",
          "authors": [
            "Qiping Zhang",
            "Nathan Tsoi",
            "Mofeed Nagib",
            "Booyeon Choi",
            "Jie Tan",
            "Hao-Tien Lewis Chiang",
            "Marynel Vázquez"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2311.07226",
          "title": "Large Language Models for Robotics: A Survey",
          "abstract": "The human ability to learn, generalize, and control complex manipulation tasks through multi-modality feedback suggests a unique capability, which we refer to as dexterity intelligence. Understanding and assessing this intelligence is a complex task. Amidst the swift progress and extensive proliferation of large language models (LLMs), their applications in the field of robotics have garnered increasing attention. LLMs possess the ability to process and generate natural language, facilitating efficient interaction and collaboration with robots. Researchers and engineers in the field of robotics have recognized the immense potential of LLMs in enhancing robot intelligence, human-robot interaction, and autonomy. Therefore, this comprehensive review aims to summarize the applications of LLMs in robotics, delving into their impact and contributions to key areas such as robot control, perception, decision-making, and planning. This survey first provides an overview of the background and development of LLMs for robotics, followed by a discussion of their benefits and recent advancements in LLM-based robotic models. It then explores various techniques, employed in perception, decision-making, control, and interaction, as well as cross-module coordination in practical tasks. Finally, we review current applications of LLMs in robotics and outline potential challenges they may face in the near future. Embodied intelligence represents the future of intelligent systems, and LLM-based robotics is one of the most promising yet challenging paths toward achieving it.",
          "authors": [
            "Fanlong Zeng",
            "Wensheng Gan",
            "Zezheng Huai",
            "Lichao Sun",
            "Hechang Chen",
            "Yongheng Wang",
            "Ning Liu",
            "Philip S. Yu"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.06646",
          "title": "Computational Copyright: Towards A Royalty Model for Music Generative AI",
          "abstract": "The rapid rise of generative AI has intensified copyright and economic tensions in creative industries, particularly in music. Current approaches addressing this challenge often focus on preventing infringement or establishing one-time licensing, which fail to provide the sustainable, recurring economic incentives necessary to maintain creative ecosystems. To address this gap, we propose Generative Content ID, a framework for scalable and faithful royalty attribution in music generative AI. Adapting the idea of YouTube's Content ID, it attributes the value of AI-generated music back to the specific training content that causally influenced its generation, a process we term as causal attribution. However, naively quantifying the causal influence requires counterfactually retraining the model on subsets of training data, which is infeasible. We address this challenge using efficient Training Data Attribution (TDA) methods to approximate causal attribution at scale. We further conduct empirical analysis of the framework on public and proprietary datasets. First, we demonstrate that the scalable TDA methods provide a faithful approximation of the \"gold-standard\" but costly retraining-based causal attribution, showing the feasibility of the proposed royalty framework. Second, we investigate the relationship between the perceived similarity employed by legal practices and our causal attribution reflecting the true AI training mechanics. We find that while perceived similarity can capture the most influential samples, it fails to account for the broader data contribution that drives model utility, suggesting similarity-based legal proxies are ill-suited for royalty distribution. Overall, this work provides a principled and operational foundation for royalty-based economic governance of music generative AI.",
          "authors": [
            "Junwei Deng",
            "Xirui Jiang",
            "Shiyuan Zhang",
            "Shichang Zhang",
            "Himabindu Lakkaraju",
            "Ruijiang Gao",
            "Chris Donahue",
            "Jiaqi W. Ma"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.11359",
          "title": "Using Game Design to Inform a Plastics Treaty: Fostering Collaboration between Science, Machine Learning, and Policymaking",
          "abstract": "Introduction: This multi-disciplinary case study details how an interactive decision support tool leverages game design to inform an international plastic pollution treaty. Design: Seeking to make our scientific findings more usable within the policy process, our interactive software supports manipulation of a mathematical model using techniques borrowed from games. These \"ludic\" approaches aim to enable user agency to find custom policy solutions, invite deep engagement with scientific results, serve audiences of diverse expertise, and accelerate scientific process to keep pace with intergovernmental negotiations. Implementation: Built in JavaScript and D3 with user-modifiable logic via an ANTLR domain specific language, this browser-based application offers adaptability and explorability for our machine learning results with privacy preserving architecture and offline capability. Demonstration: Policymakers and the supporting community engaged with this public simulation tool across multiple treaty-related events, investigating plastic waste outcomes under diverse and sometimes unexpected policy scenarios. Conclusion: Contextualizing our open source software within a broader lineage of digital media research, we reflect on this interactive modeling platform, considering how game design approaches may help facilitate collaboration at the science / policy nexus. Materials: Available on the public Internet, we host this browser-based decision support tool at this http URL , work also archived at this http URL in a Docker container.",
          "authors": [
            "A Samuel Pottinger",
            "Nivedita Biyani",
            "Roland Geyer",
            "Douglas J McCauley",
            "Magali de Bruyn",
            "Molly R Morse",
            "Neil Nathan",
            "Kevin Koy",
            "Ciera Martinez"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2312.15230",
          "title": "PERP: Rethinking the Prune-Retrain Paradigm in the Era of LLMs",
          "abstract": "Neural Networks can be effectively compressed through pruning, significantly reducing storage and compute demands while maintaining predictive performance. Simple yet effective methods like magnitude pruning remove less important parameters and typically require a costly retraining procedure to restore performance. However, with the rise of LLMs, full retraining has become infeasible due to memory and compute constraints. This study challenges the practice of retraining all parameters by showing that updating a small subset of highly expressive parameters can suffice to recover or even enhance performance after pruning. Surprisingly, retraining just 0.01%-0.05% of the parameters in GPT-architectures can match the performance of full retraining across various sparsity levels, significantly reducing compute and memory requirements, and enabling retraining of models with up to 30 billion parameters on a single GPU in minutes. To bridge the gap to full retraining in the high sparsity regime, we introduce two novel LoRA variants that, unlike standard LoRA, allow merging adapters back without compromising sparsity. Going a step further, we show that these methods can be applied for memory-efficient layer-wise reconstruction, significantly enhancing state-of-the-art retraining-free methods like Wanda (Sun et al., 2023) and SparseGPT (Frantar & Alistarh, 2023). Our findings present a promising alternative to avoiding retraining.",
          "authors": [
            "Max Zimmer",
            "Megi Andoni",
            "Christoph Spiegel",
            "Sebastian Pokutta"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.17512",
          "title": "Unifying Linear-Time Attention via Latent Probabilistic Modelling",
          "abstract": "Transformers have achieved state-of-the-art results across a range of domains, but their quadratic attention mechanism poses significant challenges for long-sequence modelling. Recent efforts to design linear-time attention mechanisms have yielded more scalable alternatives, yet often at the cost of performance, particularly on discrete data such as language. In this work, we revisit linear attention through the lens of probabilistic graphical models. We first show that standard linear attention can be interpreted as an undirected latent variable model, revealing a key limitation: the absence of directionality. To address this, we propose a novel directed parameterisation of linear attention that introduces an asymmetric structure, enabling an interpretation aligned with the causal and sequential nature of language. Our formulation integrates global latent-variable attention with local standard attention in a fully probabilistic framework. Additionally, we introduce a recurrent parameterisation of queries and keys that avoids reliance on relative positional encodings, often incompatible with linear attention. Experiments on language modelling benchmarks demonstrate that our model achieves competitive performance with standard attention and outperforms existing linear attention variants.",
          "authors": [
            "Rares Dolga",
            "Lucas Maystre",
            "Marius Cobzarenco",
            "David Barber"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2402.17512",
          "title": "Unifying Linear-Time Attention via Latent Probabilistic Modelling",
          "abstract": "Transformers have achieved state-of-the-art results across a range of domains, but their quadratic attention mechanism poses significant challenges for long-sequence modelling. Recent efforts to design linear-time attention mechanisms have yielded more scalable alternatives, yet often at the cost of performance, particularly on discrete data such as language. In this work, we revisit linear attention through the lens of probabilistic graphical models. We first show that standard linear attention can be interpreted as an undirected latent variable model, revealing a key limitation: the absence of directionality. To address this, we propose a novel directed parameterisation of linear attention that introduces an asymmetric structure, enabling an interpretation aligned with the causal and sequential nature of language. Our formulation integrates global latent-variable attention with local standard attention in a fully probabilistic framework. Additionally, we introduce a recurrent parameterisation of queries and keys that avoids reliance on relative positional encodings, often incompatible with linear attention. Experiments on language modelling benchmarks demonstrate that our model achieves competitive performance with standard attention and outperforms existing linear attention variants.",
          "authors": [
            "Rares Dolga",
            "Lucas Maystre",
            "Marius Cobzarenco",
            "David Barber"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2403.10711",
          "title": "Gaussian universality for approximately polynomial functions of high-dimensional data",
          "abstract": "Gaussian universality results assert that the properties of many estimators remain unchanged when the input data are replaced by Gaussians. Such results have gained popularity in high-dimensional statistics and machine learning, as Gaussianity often substantially simplifies downstream analyses. Yet, an open question remains on when universality may cease to hold. To address this, we establish nearly optimal upper and lower bounds for Gaussian universality approximation, measured in Kolmogorov distance, over the class of approximately polynomial functions of high-dimensional random vectors. The upper bounds adapt the invariance principle of Mossel, O'Donnell and Oleszkiewicz (2010) for high-dimensional vectors and functions beyond multilinear forms. As applications, we obtain a delta method for high-dimensional data with non-Gaussian limits, a necessary and sufficient condition for asymptotic normality, and simple estimators that are asymptotically normal but for which bootstrap fails to be consistent. We also extend recent results on the high-dimensional degeneracy of non-degenerate U-statistics, phase transition of MMD in two-sample tests with imbalanced data, and confidence spheres for high-dimensional averages. Our lower bound is constructive and shows that, for polynomials of even degree $m$, universality holds up to $m=o(\\log n)$. As a corollary, the Gaussian polynomial approximation error of $\\Omega(n^{-1/6m})$ is not improvable for even-degree U-statistics and V-statistics. Our results also explain how universality results for U-statistics and V-statistics differ significantly in their dependence on dimensions.",
          "authors": [
            "Kevin Han Huang",
            "Morgane Austern",
            "Peter Orbanz"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2403.10711",
          "title": "Gaussian universality for approximately polynomial functions of high-dimensional data",
          "abstract": "Gaussian universality results assert that the properties of many estimators remain unchanged when the input data are replaced by Gaussians. Such results have gained popularity in high-dimensional statistics and machine learning, as Gaussianity often substantially simplifies downstream analyses. Yet, an open question remains on when universality may cease to hold. To address this, we establish nearly optimal upper and lower bounds for Gaussian universality approximation, measured in Kolmogorov distance, over the class of approximately polynomial functions of high-dimensional random vectors. The upper bounds adapt the invariance principle of Mossel, O'Donnell and Oleszkiewicz (2010) for high-dimensional vectors and functions beyond multilinear forms. As applications, we obtain a delta method for high-dimensional data with non-Gaussian limits, a necessary and sufficient condition for asymptotic normality, and simple estimators that are asymptotically normal but for which bootstrap fails to be consistent. We also extend recent results on the high-dimensional degeneracy of non-degenerate U-statistics, phase transition of MMD in two-sample tests with imbalanced data, and confidence spheres for high-dimensional averages. Our lower bound is constructive and shows that, for polynomials of even degree $m$, universality holds up to $m=o(\\log n)$. As a corollary, the Gaussian polynomial approximation error of $\\Omega(n^{-1/6m})$ is not improvable for even-degree U-statistics and V-statistics. Our results also explain how universality results for U-statistics and V-statistics differ significantly in their dependence on dimensions.",
          "authors": [
            "Kevin Han Huang",
            "Morgane Austern",
            "Peter Orbanz"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2403.10786",
          "title": "ContourDiff: Unpaired Medical Image Translation with Structural Consistency",
          "abstract": "Accurately translating medical images between different modalities, such as Computed Tomography (CT) to Magnetic Resonance Imaging (MRI), has numerous downstream clinical and machine learning applications. While several methods have been proposed to achieve this, they often prioritize perceptual quality with respect to output domain features over preserving anatomical fidelity. However, maintaining anatomy during translation is essential for many tasks, e.g., when leveraging masks from the input domain to develop a segmentation model with images translated to the output domain. To address these challenges, we propose ContourDiff with Spatially Coherent Guided Diffusion (SCGD), a novel framework that leverages domain-invariant anatomical contour representations of images. These representations are simple to extract from images, yet form precise spatial constraints on their anatomical content. We introduce a diffusion model that converts contour representations of images from arbitrary input domains into images in the output domain of interest. By applying the contour as a constraint at every diffusion sampling step, we ensure the preservation of anatomical content. We evaluate our method on challenging lumbar spine and hip-and-thigh CT-to-MRI translation tasks, via (1) the performance of segmentation models trained on translated images applied to real MRIs, and (2) the foreground FID and KID of translated images with respect to real MRIs. Our method outperforms other unpaired image translation methods by a significant margin across almost all metrics and scenarios. Moreover, it achieves this without the need to access any input domain information during training and we further verify its zero-shot capability, showing that a model trained on one anatomical region can be directly applied to unseen regions without retraining (GitHub: this https URL ).",
          "authors": [
            "Yuwen Chen",
            "Nicholas Konz",
            "Hanxue Gu",
            "Haoyu Dong",
            "Yaqian Chen",
            "Lin Li",
            "Jisoo Lee",
            "Maciej A. Mazurowski"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2403.10786",
          "title": "ContourDiff: Unpaired Medical Image Translation with Structural Consistency",
          "abstract": "Accurately translating medical images between different modalities, such as Computed Tomography (CT) to Magnetic Resonance Imaging (MRI), has numerous downstream clinical and machine learning applications. While several methods have been proposed to achieve this, they often prioritize perceptual quality with respect to output domain features over preserving anatomical fidelity. However, maintaining anatomy during translation is essential for many tasks, e.g., when leveraging masks from the input domain to develop a segmentation model with images translated to the output domain. To address these challenges, we propose ContourDiff with Spatially Coherent Guided Diffusion (SCGD), a novel framework that leverages domain-invariant anatomical contour representations of images. These representations are simple to extract from images, yet form precise spatial constraints on their anatomical content. We introduce a diffusion model that converts contour representations of images from arbitrary input domains into images in the output domain of interest. By applying the contour as a constraint at every diffusion sampling step, we ensure the preservation of anatomical content. We evaluate our method on challenging lumbar spine and hip-and-thigh CT-to-MRI translation tasks, via (1) the performance of segmentation models trained on translated images applied to real MRIs, and (2) the foreground FID and KID of translated images with respect to real MRIs. Our method outperforms other unpaired image translation methods by a significant margin across almost all metrics and scenarios. Moreover, it achieves this without the need to access any input domain information during training and we further verify its zero-shot capability, showing that a model trained on one anatomical region can be directly applied to unseen regions without retraining (GitHub: this https URL ).",
          "authors": [
            "Yuwen Chen",
            "Nicholas Konz",
            "Hanxue Gu",
            "Haoyu Dong",
            "Yaqian Chen",
            "Lin Li",
            "Jisoo Lee",
            "Maciej A. Mazurowski"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2403.15176",
          "title": "Brain-aligning of semantic vectors improves neural decoding of visual stimuli",
          "abstract": "The development of algorithms to accurately decode neural information has long been a research focus in the field of neuroscience. Brain decoding typically involves training machine learning models to map neural data onto a preestablished vector representation of stimulus features. These vectors are usually derived from image- and/or text-based feature spaces. Nonetheless, the intrinsic characteristics of these vectors might fundamentally differ from those that are encoded by the brain, limiting the ability of decoders to accurately learn this mapping. To address this issue, we propose a framework, called brain-aligning of semantic vectors, that fine-tunes pretrained feature vectors to better align with the structure of neural representations of visual stimuli in the brain. We trained this model with functional magnetic resonance imaging (fMRI) and then performed zero-shot brain decoding on fMRI, magnetoencephalography (MEG), and electrocorticography (ECoG) data. fMRI-based brain-aligned vectors improved decoding performance across all three neuroimaging datasets when accuracy was determined by calculating the correlation coefficients between true and predicted vectors. Additionally, when decoding accuracy was determined via stimulus identification, this accuracy increased in specific category types; improvements varied depending on the original vector space that was used for brain-alignment, and consistent improvements were observed across all neuroimaging modalities.",
          "authors": [
            "Shirin Vafaei",
            "Ryohei Fukuma",
            "Takufumi Yanagisawa",
            "Huixiang Yang",
            "Satoru Oshino",
            "Naoki Tani",
            "Hui Ming Khoo",
            "Hidenori Sugano",
            "Yasushi Iimura",
            "Hiroharu Suzuki",
            "Madoka Nakajima",
            "Kentaro Tamura",
            "Haruhiko Kishima"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2403.15176",
          "title": "Brain-aligning of semantic vectors improves neural decoding of visual stimuli",
          "abstract": "The development of algorithms to accurately decode neural information has long been a research focus in the field of neuroscience. Brain decoding typically involves training machine learning models to map neural data onto a preestablished vector representation of stimulus features. These vectors are usually derived from image- and/or text-based feature spaces. Nonetheless, the intrinsic characteristics of these vectors might fundamentally differ from those that are encoded by the brain, limiting the ability of decoders to accurately learn this mapping. To address this issue, we propose a framework, called brain-aligning of semantic vectors, that fine-tunes pretrained feature vectors to better align with the structure of neural representations of visual stimuli in the brain. We trained this model with functional magnetic resonance imaging (fMRI) and then performed zero-shot brain decoding on fMRI, magnetoencephalography (MEG), and electrocorticography (ECoG) data. fMRI-based brain-aligned vectors improved decoding performance across all three neuroimaging datasets when accuracy was determined by calculating the correlation coefficients between true and predicted vectors. Additionally, when decoding accuracy was determined via stimulus identification, this accuracy increased in specific category types; improvements varied depending on the original vector space that was used for brain-alignment, and consistent improvements were observed across all neuroimaging modalities.",
          "authors": [
            "Shirin Vafaei",
            "Ryohei Fukuma",
            "Takufumi Yanagisawa",
            "Huixiang Yang",
            "Satoru Oshino",
            "Naoki Tani",
            "Hui Ming Khoo",
            "Hidenori Sugano",
            "Yasushi Iimura",
            "Hiroharu Suzuki",
            "Madoka Nakajima",
            "Kentaro Tamura",
            "Haruhiko Kishima"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.09101",
          "title": "Mixture of Experts Softens the Curse of Dimensionality in Operator Learning",
          "abstract": "We study the approximation-theoretic implications of mixture-of-experts architectures for operator learning, where the complexity of a single large neural operator is distributed across many small neural operators (NOs), and each input is routed to exactly one NO via a decision tree. We analyze how this tree-based routing and expert decomposition affect approximation power, sample complexity, and stability. Our main result is a distributed universal approximation theorem for mixture of neural operators (MoNOs): any Lipschitz nonlinear operator between $L^2([0,1]^d)$ spaces can be uniformly approximated over the Sobolev unit ball to arbitrary accuracy $\\varepsilon>0$ by an MoNO, where each expert NO has a depth, width, and rank scaling as $\\mathcal{O}(\\varepsilon^{-1})$. Although the number of experts may grow with accuracy, each NO remains small, enough to fit within active memory of standard hardware for reasonable accuracy levels. Our analysis also yields new quantitative approximation rates for classical NOs approximating uniformly continuous nonlinear operators uniformly on compact subsets of $L^2([0,1]^d)$.",
          "authors": [
            "Anastasis Kratsios",
            "Takashi Furuya",
            "Jose Antonio Lara Benitez",
            "Matti Lassas",
            "Maarten de Hoop"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.09101",
          "title": "Mixture of Experts Softens the Curse of Dimensionality in Operator Learning",
          "abstract": "We study the approximation-theoretic implications of mixture-of-experts architectures for operator learning, where the complexity of a single large neural operator is distributed across many small neural operators (NOs), and each input is routed to exactly one NO via a decision tree. We analyze how this tree-based routing and expert decomposition affect approximation power, sample complexity, and stability. Our main result is a distributed universal approximation theorem for mixture of neural operators (MoNOs): any Lipschitz nonlinear operator between $L^2([0,1]^d)$ spaces can be uniformly approximated over the Sobolev unit ball to arbitrary accuracy $\\varepsilon>0$ by an MoNO, where each expert NO has a depth, width, and rank scaling as $\\mathcal{O}(\\varepsilon^{-1})$. Although the number of experts may grow with accuracy, each NO remains small, enough to fit within active memory of standard hardware for reasonable accuracy levels. Our analysis also yields new quantitative approximation rates for classical NOs approximating uniformly continuous nonlinear operators uniformly on compact subsets of $L^2([0,1]^d)$.",
          "authors": [
            "Anastasis Kratsios",
            "Takashi Furuya",
            "Jose Antonio Lara Benitez",
            "Matti Lassas",
            "Maarten de Hoop"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.09101",
          "title": "Mixture of Experts Softens the Curse of Dimensionality in Operator Learning",
          "abstract": "We study the approximation-theoretic implications of mixture-of-experts architectures for operator learning, where the complexity of a single large neural operator is distributed across many small neural operators (NOs), and each input is routed to exactly one NO via a decision tree. We analyze how this tree-based routing and expert decomposition affect approximation power, sample complexity, and stability. Our main result is a distributed universal approximation theorem for mixture of neural operators (MoNOs): any Lipschitz nonlinear operator between $L^2([0,1]^d)$ spaces can be uniformly approximated over the Sobolev unit ball to arbitrary accuracy $\\varepsilon>0$ by an MoNO, where each expert NO has a depth, width, and rank scaling as $\\mathcal{O}(\\varepsilon^{-1})$. Although the number of experts may grow with accuracy, each NO remains small, enough to fit within active memory of standard hardware for reasonable accuracy levels. Our analysis also yields new quantitative approximation rates for classical NOs approximating uniformly continuous nonlinear operators uniformly on compact subsets of $L^2([0,1]^d)$.",
          "authors": [
            "Anastasis Kratsios",
            "Takashi Furuya",
            "Jose Antonio Lara Benitez",
            "Matti Lassas",
            "Maarten de Hoop"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.13182",
          "title": "Spectral Convolutional Conditional Neural Processes",
          "abstract": "Neural processes (NPs) are probabilistic meta-learning models that map sets of observations to posterior predictive distributions, enabling inference at arbitrary domain points. Their capacity to handle variable-sized collections of unstructured observations, combined with simple maximum-likelihood training and uncertainty-aware predictions, makes them well-suited for modeling data over continuous domains. Since their introduction, several variants have been proposed. Early approaches typically represented observed data using finite-dimensional summary embeddings obtained through aggregation schemes such as mean pooling. However, this strategy fundamentally mismatches the infinite-dimensional nature of the generative processes that NPs aim to capture. Convolutional conditional neural processes (ConvCNPs) address this limitation by constructing infinite-dimensional functional embeddings processed through convolutional neural networks (CNNs) to enforce translation equivariance. Yet CNNs with local spatial kernels struggle to capture long-range dependencies without resorting to large kernels, which impose significant computational costs. To overcome this limitation, we propose the Spectral ConvCNP (SConvCNP), which performs global convolution in the frequency domain. Inspired by Fourier neural operators (FNOs) for learning solution operators of partial differential equations (PDEs), our approach directly parameterizes convolution kernels in the frequency domain, leveraging the relatively compact yet global Fourier representation of many natural signals. We validate the effectiveness of SConvCNP on both synthetic and real-world datasets, demonstrating how ideas from operator learning can advance the capabilities of NPs.",
          "authors": [
            "Peiman Mohseni",
            "Nick Duffield"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.15272",
          "title": "CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios",
          "abstract": "3D medical vision-language (VL) pretraining has shown potential in radiology by leveraging large-scale multimodal datasets with CT-report pairs. However, existing methods primarily rely on a global VL alignment directly adapted from 2D scenarios. The entire 3D image is transformed into one global embedding, resulting in a loss of sparse but critical semantics essential for accurately aligning with the corresponding diagnosis. To address this limitation, we propose CT-GLIP, a 3D Grounded Language-Image Pretrained model that constructs fine-grained CT-report pairs to enhance \\textit{grounded} cross-modal contrastive learning, effectively aligning grounded visual features with precise textual descriptions. Leveraging the grounded cross-modal alignment, CT-GLIP improves performance across diverse downstream tasks and can even identify organs and abnormalities in a zero-shot manner using natural language. CT-GLIP is trained on a multimodal CT dataset comprising 44,011 organ-level CT-report pairs from 17,702 patients, covering 104 organs. Evaluation is conducted on four downstream tasks: zero-shot organ recognition (OR), zero-shot abnormality detection (AD), tumor detection (TD), and tumor segmentation (TS). Empirical results show that it outperforms its counterparts with global VL alignment. Compared to vanilla CLIP, CT-GLIP achieves average performance improvements of 15.1% of F1 score, 1.9% of AUC, and 3.2% of DSC for zero-shot AD, TD, and TS tasks, respectively. This study highlights the significance of grounded VL alignment in enabling 3D medical VL foundation models to understand sparse representations within CT scans.",
          "authors": [
            "Jingyang Lin",
            "Yingda Xia",
            "Jianpeng Zhang",
            "Ke Yan",
            "Kai Cao",
            "Le Lu",
            "Jiebo Luo",
            "Ling Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.15654",
          "title": "Autoregressive networks with dependent edges",
          "abstract": "We propose an autoregressive framework for modelling dynamic networks with dependent edges. It encompasses models that accommodate, for example, transitivity, degree heterogenenity, and other stylized features often observed in real network data. By assuming the edges of networks at each time are independent conditionally on their lagged values, the models, which exhibit a close connection with temporal ERGMs, facilitate both simulation and the maximum likelihood estimation in a straightforward manner. Due to the possibly large number of parameters in the models, the natural MLEs may suffer from slow convergence rates. An improved estimator for each component parameter is proposed based on an iteration employing projection, which mitigates the impact of the other parameters (Chang et al., 2021; Chang et al., 2023). Leveraging a martingale difference structure, the asymptotic distribution of the improved estimator is derived without the assumption of stationarity. The limiting distribution is not normal in general, although it reduces to normal when the underlying process satisfies some mixing conditions. Illustration with a transitivity model was carried out in both simulation and a real network data set.",
          "authors": [
            "Jinyuan Chang",
            "Qin Fang",
            "Eric D. Kolaczyk",
            "Peter W. MacDonald",
            "Qiwei Yao"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2404.15654",
          "title": "Autoregressive networks with dependent edges",
          "abstract": "We propose an autoregressive framework for modelling dynamic networks with dependent edges. It encompasses models that accommodate, for example, transitivity, degree heterogenenity, and other stylized features often observed in real network data. By assuming the edges of networks at each time are independent conditionally on their lagged values, the models, which exhibit a close connection with temporal ERGMs, facilitate both simulation and the maximum likelihood estimation in a straightforward manner. Due to the possibly large number of parameters in the models, the natural MLEs may suffer from slow convergence rates. An improved estimator for each component parameter is proposed based on an iteration employing projection, which mitigates the impact of the other parameters (Chang et al., 2021; Chang et al., 2023). Leveraging a martingale difference structure, the asymptotic distribution of the improved estimator is derived without the assumption of stationarity. The limiting distribution is not normal in general, although it reduces to normal when the underlying process satisfies some mixing conditions. Illustration with a transitivity model was carried out in both simulation and a real network data set.",
          "authors": [
            "Jinyuan Chang",
            "Qin Fang",
            "Eric D. Kolaczyk",
            "Peter W. MacDonald",
            "Qiwei Yao"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.13068",
          "title": "Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level Manipulation",
          "abstract": "Large language models (LLMs) have transformed the field of natural language processing, but they remain susceptible to jailbreaking attacks that exploit their capabilities to generate unintended and potentially harmful content. Existing token-level jailbreaking techniques, while effective, face scalability and efficiency challenges, especially as models undergo frequent updates and incorporate advanced defensive measures. In this paper, we introduce JailMine, an innovative token-level manipulation approach that addresses these limitations effectively. JailMine employs an automated \"mining\" process to elicit malicious responses from LLMs by strategically selecting affirmative outputs and iteratively reducing the likelihood of rejection. Through rigorous testing across multiple well-known LLMs and datasets, we demonstrate JailMine's effectiveness and efficiency, achieving a significant average reduction of 86% in time consumed while maintaining high success rates averaging 95%, even in the face of evolving defensive strategies. Our work contributes to the ongoing effort to assess and mitigate the vulnerability of LLMs to jailbreaking attacks, underscoring the importance of continued vigilance and proactive measures to enhance the security and reliability of these powerful language models.",
          "authors": [
            "Yuxi Li",
            "Yi Liu",
            "Yuekang Li",
            "Ling Shi",
            "Gelei Deng",
            "Shengquan Chen",
            "Kailong Wang"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.15727",
          "title": "Anomalous Change Point Detection Using Probabilistic Predictive Coding",
          "abstract": "Change point detection (CPD) and anomaly detection (AD) are essential techniques in various fields to identify abrupt changes or abnormal data instances. However, existing methods are often constrained to univariate data, face scalability challenges with large datasets due to computational demands, and experience reduced performance with high-dimensional or intricate data, as well as hidden anomalies. Furthermore, they often lack interpretability and adaptability to domain-specific knowledge, which limits their versatility across different fields. In this work, we propose a deep learning-based CPD/AD method called Probabilistic Predictive Coding (PPC) that jointly learns to encode sequential data to low-dimensional latent space representations and to predict the subsequent data representations as well as the corresponding prediction uncertainties. The model parameters are optimized with maximum likelihood estimation by comparing these predictions with the true encodings. At the time of application, the true and predicted encodings are used to determine the probability of conformance, an interpretable and meaningful anomaly score. Furthermore, our approach has linear time complexity, scalability issues are prevented, and the method can easily be adjusted to a wide range of data types and intricate applications. We demonstrate the effectiveness and adaptability of our proposed method across synthetic time series experiments, image data, and real-world magnetic resonance spectroscopic imaging data.",
          "authors": [
            "Roelof G. Hup",
            "Julian P. Merkofer",
            "Alex A. Bhogal",
            "Ruud J.G. van Sloun",
            "Reinder Haakma",
            "Rik Vullings"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2405.15727",
          "title": "Anomalous Change Point Detection Using Probabilistic Predictive Coding",
          "abstract": "Change point detection (CPD) and anomaly detection (AD) are essential techniques in various fields to identify abrupt changes or abnormal data instances. However, existing methods are often constrained to univariate data, face scalability challenges with large datasets due to computational demands, and experience reduced performance with high-dimensional or intricate data, as well as hidden anomalies. Furthermore, they often lack interpretability and adaptability to domain-specific knowledge, which limits their versatility across different fields. In this work, we propose a deep learning-based CPD/AD method called Probabilistic Predictive Coding (PPC) that jointly learns to encode sequential data to low-dimensional latent space representations and to predict the subsequent data representations as well as the corresponding prediction uncertainties. The model parameters are optimized with maximum likelihood estimation by comparing these predictions with the true encodings. At the time of application, the true and predicted encodings are used to determine the probability of conformance, an interpretable and meaningful anomaly score. Furthermore, our approach has linear time complexity, scalability issues are prevented, and the method can easily be adjusted to a wide range of data types and intricate applications. We demonstrate the effectiveness and adaptability of our proposed method across synthetic time series experiments, image data, and real-world magnetic resonance spectroscopic imaging data.",
          "authors": [
            "Roelof G. Hup",
            "Julian P. Merkofer",
            "Alex A. Bhogal",
            "Ruud J.G. van Sloun",
            "Reinder Haakma",
            "Rik Vullings"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.05811",
          "title": "Generalized Linear Spectral Statistics of High-dimensional Sample Covariance Matrices and Its Applications",
          "abstract": "In this paper, we introduce the \\textbf{G}eneralized \\textbf{L}inear \\textbf{S}pectral \\textbf{S}tatistics (GLSS) of a high-dimensional sample covariance matrix $\\bm{S}_n$, denoted as $\\operatorname{tr}f(\\bm{S}_n)\\bm{B}_n$, which effectively captures distinct spectral properties of $\\bm{S}_n$ by incorporating an ancillary matrix $\\bm{B}_n$ and a test function $f$. The joint asymptotic normality of GLSS associated with different test functions is established under mild assumptions on $\\bm{B}_n$ and the underlying distribution, when the dimension $n$ and sample size $N$ are comparable. The convergence rate of GLSS is determined by $\\sqrt{{N}/{\\operatorname{rank}(\\bm{B}_n)}}$. Subsequently, we propose a novel functional projection approach based on GLSS for hypothesis testing on eigenspaces of ``population-spiked'' covariance matrices, showcasing a universality phenomenon in the magnitude of the spikes. The theoretical accuracy of our results established for GLSS and the advantages of the newly suggested testing procedure are demonstrated through various numerical studies.",
          "authors": [
            "Yanlin Hu",
            "Qing Yang",
            "Xiao Han"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.05811",
          "title": "Generalized Linear Spectral Statistics of High-dimensional Sample Covariance Matrices and Its Applications",
          "abstract": "In this paper, we introduce the \\textbf{G}eneralized \\textbf{L}inear \\textbf{S}pectral \\textbf{S}tatistics (GLSS) of a high-dimensional sample covariance matrix $\\bm{S}_n$, denoted as $\\operatorname{tr}f(\\bm{S}_n)\\bm{B}_n$, which effectively captures distinct spectral properties of $\\bm{S}_n$ by incorporating an ancillary matrix $\\bm{B}_n$ and a test function $f$. The joint asymptotic normality of GLSS associated with different test functions is established under mild assumptions on $\\bm{B}_n$ and the underlying distribution, when the dimension $n$ and sample size $N$ are comparable. The convergence rate of GLSS is determined by $\\sqrt{{N}/{\\operatorname{rank}(\\bm{B}_n)}}$. Subsequently, we propose a novel functional projection approach based on GLSS for hypothesis testing on eigenspaces of ``population-spiked'' covariance matrices, showcasing a universality phenomenon in the magnitude of the spikes. The theoretical accuracy of our results established for GLSS and the advantages of the newly suggested testing procedure are demonstrated through various numerical studies.",
          "authors": [
            "Yanlin Hu",
            "Qing Yang",
            "Xiao Han"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.10360",
          "title": "Causal inference for N-of-1 trials",
          "abstract": "The aim of personalized medicine is to tailor treatment decisions to individuals' characteristics. N-of-1 trials are within-person crossover trials that hold the promise of targeting individual-specific effects. While the idea behind N-of-1 trials might seem simple, analyzing and interpreting N-of-1 trials is not straightforward. Here we ground N-of-1 trials in a formal causal inference framework and formalize intuitive claims from the N-of-1 trials literature. We focus on causal inference from a single N-of-1 trial and define a conditional average treatment effect (CATE) that represents a target in this setting, which we call the U-CATE. We discuss assumptions sufficient for identification and estimation of the U-CATE under different causal models where the treatment schedule is assigned at baseline. A simple mean difference is an unbiased, asymptotically normal estimator of the U-CATE in simple settings. We also consider settings where carryover effects, trends over time, time-varying common causes of the outcome, and outcome-outcome effects are present. In these more complex settings, we show that a time-varying g-formula identifies the U-CATE under explicit assumptions. Finally, we analyze data from N-of-1 trials about acne symptoms and show how different assumptions about the data generating process can lead to different analytical strategies.",
          "authors": [
            "Marco Piccininni",
            "Mats J. Stensrud",
            "Zachary Shahn",
            "Stefan Konigorski"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.12693",
          "title": "XXLTraffic: Expanding and Extremely Long Traffic forecasting beyond test adaptation",
          "abstract": "Traffic forecasting is crucial for smart cities and intelligent transportation initiatives, where deep learning has made significant progress in modeling complex spatio-temporal patterns in recent years. However, current public datasets have limitations in reflecting the distribution shift nature of real-world scenarios, characterized by continuously evolving infrastructures, varying temporal distributions, and long temporal gaps due to sensor downtimes or changes in traffic patterns. These limitations inevitably restrict the practical applicability of existing traffic forecasting datasets. To bridge this gap, we present XXLTraffic, largest available public traffic dataset with the longest timespan collected from Los Angeles, USA, and New South Wales, Australia, curated to support research in extremely long forecasting beyond test adaptation. Our benchmark includes both typical time-series forecasting settings with hourly and daily aggregated data and novel configurations that introduce gaps and down-sample the training size to better simulate practical constraints. We anticipate the new XXLTraffic will provide a fresh perspective for the time-series and traffic forecasting communities. It would also offer a robust platform for developing and evaluating models designed to tackle the extremely long forecasting problems beyond test adaptation. Our dataset supplements existing spatio-temporal data resources and leads to new research directions in this domain.",
          "authors": [
            "Du Yin",
            "Hao Xue",
            "Arian Prabowo",
            "Shuang Ao",
            "Flora Salim"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2406.17636",
          "title": "Aligning Diffusion Models with Noise-Conditioned Perception",
          "abstract": "Recent advancements in human preference optimization, initially developed for Language Models (LMs), have shown promise for text-to-image Diffusion Models, enhancing prompt alignment, visual appeal, and user preference. Unlike LMs, Diffusion Models typically optimize in pixel or VAE space, which does not align well with human perception, leading to slower and less efficient training during the preference alignment stage. We propose using a perceptual objective in the U-Net embedding space of the diffusion model to address these issues. Our approach involves fine-tuning Stable Diffusion 1.5 and XL using Direct Preference Optimization (DPO), Contrastive Preference Optimization (CPO), and supervised fine-tuning (SFT) within this embedding space. This method significantly outperforms standard latent-space implementations across various metrics, including quality and computational cost. For SDXL, our approach provides 60.8\\% general preference, 62.2\\% visual appeal, and 52.1\\% prompt following against original open-sourced SDXL-DPO on the PartiPrompts dataset, while significantly reducing compute. Our approach not only improves the efficiency and quality of human preference alignment for diffusion models but is also easily integrable with other optimization techniques. The training code and LoRA weights will be available here: this https URL \\_NCP-DPO\\_v0.1",
          "authors": [
            "Alexander Gambashidze",
            "Anton Kulikov",
            "Yuriy Sosnin",
            "Ilya Makarov"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2407.12687",
          "title": "Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach",
          "abstract": "A major challenge facing the world is the provision of equitable and universal access to quality education. Recent advances in generative AI (gen AI) have created excitement about the potential of new technologies to offer a personal tutor for every learner and a teaching assistant for every teacher. The full extent of this dream, however, has not yet materialised. We argue that this is primarily due to the difficulties with verbalising pedagogical intuitions into gen AI prompts and the lack of good evaluation practices, reinforced by the challenges in defining excellent pedagogy. Here we present our work collaborating with learners and educators to translate high level principles from learning science into a pragmatic set of seven diverse educational benchmarks, spanning quantitative, qualitative, automatic and human evaluations; and to develop a new set of fine-tuning datasets to improve the pedagogical capabilities of Gemini, introducing LearnLM-Tutor. Our evaluations show that LearnLM-Tutor is consistently preferred over a prompt tuned Gemini by educators and learners on a number of pedagogical dimensions. We hope that this work can serve as a first step towards developing a comprehensive educational evaluation framework, and that this can enable rapid progress within the AI and EdTech communities towards maximising the positive impact of gen AI in education.",
          "authors": [
            "Irina Jurenka",
            "Markus Kunesch",
            "Kevin R. McKee",
            "Daniel Gillick",
            "Shaojian Zhu",
            "Sara Wiltberger",
            "Shubham Milind Phal",
            "Katherine Hermann",
            "Daniel Kasenberg",
            "Avishkar Bhoopchand",
            "Ankit Anand",
            "Miruna Pîslar",
            "Stephanie Chan",
            "Lisa Wang",
            "Jennifer She",
            "Parsa Mahmoudieh",
            "Aliya Rysbek",
            "Wei-Jen Ko",
            "Andrea Huber",
            "Brett Wiltshire",
            "Gal Elidan",
            "Roni Rabin",
            "Jasmin Rubinovitz",
            "Amit Pitaru",
            "Mac McAllister",
            "Julia Wilkowski",
            "David Choi",
            "Roee Engelberg",
            "Lidan Hackmon",
            "Adva Levin",
            "Rachel Griffin",
            "Michael Sears",
            "Filip Bar",
            "Mia Mesar",
            "Mana Jabbour",
            "Arslan Chaudhry",
            "James Cohan",
            "Sridhar Thiagarajan",
            "Nir Levine",
            "Ben Brown",
            "Dilan Gorur",
            "Svetlana Grant",
            "Rachel Hashimshoni",
            "Laura Weidinger",
            "Jieru Hu",
            "Dawn Chen",
            "Kuba Dolecki",
            "Canfer Akbulut",
            "Maxwell Bileschi",
            "Laura Culp",
            "Wen-Xin Dong",
            "Nahema Marchal",
            "Kelsie Van Deman",
            "Hema Bajaj Misra",
            "Michael Duah",
            "Moran Ambar",
            "Avi Caciularu",
            "Sandra Lefdal",
            "Chris Summerfield",
            "James An",
            "Pierre-Alexandre Kamienny",
            "Abhinit Mohdi",
            "Theofilos Strinopoulous",
            "Annie Hale",
            "Wayne Anderson",
            "Luis C. Cobo",
            "Niv Efron",
            "Muktha Ananda",
            "Shakir Mohamed",
            "Maureen Heymans",
            "Zoubin Ghahramani",
            "Yossi Matias",
            "Ben Gomes",
            "Lila Ibrahim"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2407.17537",
          "title": "A process algebraic framework for multi-agent dynamic epistemic systems",
          "abstract": "This paper combines the classical model of labeled transition systems with the epistemic model for reasoning about knowledge. The result is a unifying framework for modeling and analyzing multi-agent, knowledge-based, dynamic systems. On the modeling side, we propose a process algebraic, agent-oriented specification language that makes such a framework easy to use for practical purposes. On the verification side, we define a modal logic encompassing temporal and epistemic operators.",
          "authors": [
            "Alessandro Aldini"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.01402",
          "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
          "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in offline reinforcement learning (RL) tasks, leveraging pre-collected datasets and Transformer's capability to model long sequences. Recent works have demonstrated that using parts of trajectories from training tasks as prompts in DT enhances its performance on unseen tasks, giving rise to Prompt-DT methods. However, collecting data from specific environments can be both costly and unsafe in many scenarios, leading to suboptimal performance and limited few-shot prompt abilities due to the data-hungry nature of Transformer-based models. Additionally, the limited datasets used in pre-training make it challenging for Prompt-DT type of methods to distinguish between various RL tasks through prompts alone. To address these challenges, we introduce the Language model-initialized Prompt Decision Transformer (LPDT) framework, which leverages pretrained language models providing rich prior knowledge for RL tasks and fine-tunes the sequence model using Low-rank Adaptation (LoRA) for meta-RL problems. We further incorporate prompt regularization to effectively differentiate between tasks based on prompt feature representations. Comprehensive empirical studies demonstrate that initializing with a pre-trained language model provides the prior knowledge and achieves a similar performance with Prompt-DT under only $10\\%$ data in some MuJoCo control tasks. We also provide a thorough ablation study to validate the effectiveness of each component, including sequence modeling, language models, prompt regularizations, and prompt strategies.",
          "authors": [
            "Yu Yang",
            "Pan Xu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.09734",
          "title": "Mutually-Aware Feature Learning for Few-Shot Object Counting",
          "abstract": "Few-shot object counting has garnered significant attention for its practicality as it aims to count target objects in a query image based on given exemplars without additional training. However, the prevailing extract-and-match approach has a shortcoming: query and exemplar features lack interaction during feature extraction since they are extracted independently and later correlated based on similarity. This can lead to insufficient target awareness and confusion in identifying the actual target when multiple class objects coexist. To address this, we propose a novel framework, Mutually-Aware FEAture learning (MAFEA), which encodes query and exemplar features with mutual awareness from the outset. By encouraging interaction throughout the pipeline, we obtain target-aware features robust to a multi-category scenario. Furthermore, we introduce background token to effectively associate the query's target region with exemplars and decouple its background region. Our extensive experiments demonstrate that our model achieves state-of-the-art performance on FSCD-LVIS and FSC-147 benchmarks with remarkably reduced target confusion.",
          "authors": [
            "Yerim Jeon",
            "Subeen Lee",
            "Jihwan Kim",
            "Jae-Pil Heo"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.14038",
          "title": "Jackknife Empirical Likelihood Method for U Statistics Based on Multivariate Samples and its Applications",
          "abstract": "We develop a jackknife empirical likelihood (JEL) framework for inference on parameters defined through multivariate three-sample U-statistic. From three independent multivariate samples, we construct JEL ratio statistic based on suitable jackknife pseudo-values and, under mild regularity conditions, establish a Wilks-type result showing that the log JEL ratio converges in distribution to a chi-square limit. This provides asymptotically valid confidence intervals for the parameter of interest without explicit variance estimation or heavy resampling. To illustrate the usefulness of the proposed method, we construct confidence intervals for differences in volume under the surface (VUS) measures, which are widely used in classification problems. Through Monte Carlo simulations, we compare the performance of JEL-based confidence intervals with those obtained from normal approximation of U-statistic and kernel-based methods. The findings indicate that the proposed JEL approach outperforms existing methods in terms of coverage probability and computational efficiency. Finally, we apply our methods to a recent real dataset.",
          "authors": [
            "Naresh Garg",
            "Litty Mathew",
            "Isha Dewan",
            "Sudheesh Kumar Kattumannil"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2408.14038",
          "title": "Jackknife Empirical Likelihood Method for U Statistics Based on Multivariate Samples and its Applications",
          "abstract": "We develop a jackknife empirical likelihood (JEL) framework for inference on parameters defined through multivariate three-sample U-statistic. From three independent multivariate samples, we construct JEL ratio statistic based on suitable jackknife pseudo-values and, under mild regularity conditions, establish a Wilks-type result showing that the log JEL ratio converges in distribution to a chi-square limit. This provides asymptotically valid confidence intervals for the parameter of interest without explicit variance estimation or heavy resampling. To illustrate the usefulness of the proposed method, we construct confidence intervals for differences in volume under the surface (VUS) measures, which are widely used in classification problems. Through Monte Carlo simulations, we compare the performance of JEL-based confidence intervals with those obtained from normal approximation of U-statistic and kernel-based methods. The findings indicate that the proposed JEL approach outperforms existing methods in terms of coverage probability and computational efficiency. Finally, we apply our methods to a recent real dataset.",
          "authors": [
            "Naresh Garg",
            "Litty Mathew",
            "Isha Dewan",
            "Sudheesh Kumar Kattumannil"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.00666",
          "title": "Support + Belief = Decision Trust",
          "abstract": "We present SBTrust, a logical framework designed to formalize decision trust. Our logic integrates a doxastic modality with a novel non-monotonic conditional operator that establishes a positive support relation between statements, and is closely related to a known dyadic deontic modality. For SBTrust, we provide semantics, proof theory and complexity results, as well as motivating examples. Compared to existing approaches, our framework seamlessly accommodates the integration of multiple factors in the emergence of trust.",
          "authors": [
            "Alessandro Aldini",
            "Agata Ciabattoni",
            "Dominik Pichler",
            "Mirko Tagliaferri"
          ],
          "primary_category": "cs.LO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2409.15272",
          "title": "OmniBench: Towards The Future of Universal Omni-Language Models",
          "abstract": "Recent advancements in multimodal large language models (MLLMs) have focused on integrating multiple modalities, yet their ability to simultaneously process and reason across different inputs remains underexplored. We introduce OmniBench, a novel benchmark designed to evaluate models' ability to recognize, interpret, and reason across visual, acoustic, and textual inputs simultaneously. We define language models capable of such tri-modal processing as omni-language models (OLMs). OmniBench features high-quality human annotations that require integrated understanding across all modalities. Our evaluation reveals that: i) open-source OLMs show significant limitations in instruction-following and reasoning in tri-modal contexts; and ii) most baseline models perform poorly (around 50% accuracy) even with textual alternatives to image/audio inputs. To address these limitations, we develop OmniInstruct, an 96K-sample instruction tuning dataset for training OLMs. We advocate for developing more robust tri-modal integration techniques and training strategies to enhance OLM performance. Codes and data could be found at our repo ( this https URL ).",
          "authors": [
            "Yizhi Li",
            "Ge Zhang",
            "Yinghao Ma",
            "Ruibin Yuan",
            "Kang Zhu",
            "Hangyu Guo",
            "Yiming Liang",
            "Jiaheng Liu",
            "Zekun Wang",
            "Jian Yang",
            "Siwei Wu",
            "Xingwei Qu",
            "Jinjie Shi",
            "Xinyue Zhang",
            "Zhenzhu Yang",
            "Xiangzhou Wang",
            "Zhaoxiang Zhang",
            "Zachary Liu",
            "Emmanouil Benetos",
            "Wenhao Huang",
            "Chenghua Lin"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.03768",
          "title": "Hidden in Plain Text: Emergence & Mitigation of Steganographic Collusion in LLMs",
          "abstract": "The rapid proliferation of frontier model agents promises significant societal advances but also raises concerns about systemic risks arising from unsafe interactions. Collusion to the disadvantage of others has been identified as a central form of undesirable agent cooperation. The use of information hiding (steganography) in agent communications could render such collusion practically undetectable. This underscores the need for investigations into the possibility of such behaviours emerging and the robustness corresponding countermeasures. To investigate this problem we design two approaches -- a gradient-based reinforcement learning (GBRL) method and an in-context reinforcement learning (ICRL) method -- for reliably eliciting sophisticated LLM-generated linguistic text steganography. We demonstrate, for the first time, that unintended steganographic collusion in LLMs can arise due to mispecified reward incentives during training. Additionally, we find that standard mitigations -- both passive oversight of model outputs and active mitigation through communication paraphrasing -- are not fully effective at preventing this steganographic communication. Our findings imply that (i) emergence of steganographic collusion is a plausible concern that should be monitored and researched, and (ii) preventing emergence may require innovation in mitigation techniques.",
          "authors": [
            "Yohan Mathew",
            "Ollie Matthews",
            "Robert McCarthy",
            "Joan Velja",
            "Christian Schroeder de Witt",
            "Dylan Cope",
            "Nandi Schoots"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.05814",
          "title": "Rank Matters: Understanding and Defending Model Inversion Attacks via Low-Rank Feature Filtering",
          "abstract": "Model Inversion Attacks (MIAs) pose a significant threat to data privacy by reconstructing sensitive training samples from the knowledge embedded in trained machine learning models. Despite recent progress in enhancing the effectiveness of MIAs across diverse settings, defense strategies have lagged behind, struggling to balance model utility with robustness against increasingly sophisticated attacks. In this work, we propose the ideal inversion error to measure the privacy leakage, and our theoretical and empirical investigations reveals that higher-rank features are inherently more prone to privacy leakage. Motivated by this insight, we propose a lightweight and effective defense strategy based on low-rank feature filtering, which explicitly reduces the attack surface by constraining the dimension of intermediate representations. Extensive experiments across various model architectures and datasets demonstrate that our method consistently outperforms existing defenses, achieving state-of-the-art performance against a wide range of MIAs. Notably, our approach remains effective even in challenging regimes involving high-resolution data and high-capacity models, where prior defenses fail to provide adequate protection. The code is available at this https URL .",
          "authors": [
            "Hongyao Yu",
            "Yixiang Qiu",
            "Hao Fang",
            "Tianqu Zhuang",
            "Bin Chen",
            "Sijin Yu",
            "Bin Wang",
            "Shu-Tao Xia",
            "Ke Xu"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.08360",
          "title": "Minimax Hypothesis Testing for the Bradley-Terry-Luce Model",
          "abstract": "The Bradley-Terry-Luce (BTL) model is one of the most widely used models for ranking a collection of items or agents based on pairwise comparisons among them. Given $n$ agents, the BTL model endows each agent $i$ with a latent skill score $\\alpha_i > 0$ and posits that the probability that agent $i$ is preferred over agent $j$ is $\\alpha_i/(\\alpha_i + \\alpha_j)$. In this work, our objective is to formulate a hypothesis test that determines whether a given pairwise comparison dataset, with $k$ comparisons per pair of agents, originates from an underlying BTL model. We formalize this testing problem in the minimax sense and define the critical threshold of the problem. We then establish upper bounds on the critical threshold for general induced observation graphs (satisfying mild assumptions) and develop lower bounds for complete induced graphs. Our bounds demonstrate that for complete induced graphs, the critical threshold scales as $\\Theta((nk)^{-1/2})$ in a minimax sense. In particular, our test statistic for the upper bounds is based on a new approximation we derive for the separation distance between general pairwise comparison models and the class of BTL models. To further assess the performance of our statistical test, we prove upper bounds on the type I and type II probabilities of error. Much of our analysis is conducted within the context of a fixed observation graph structure, where the graph possesses certain ``nice'' properties, such as expansion and bounded principal ratio. Additionally, we derive several auxiliary results, such as bounds on principal ratios of graphs, $\\ell^2$-bounds on BTL parameter estimation under model mismatch, stability of rankings under the BTL model, etc. We validate our theoretical results through experiments on synthetic and real-world datasets and propose a data-driven permutation testing approach to determine test thresholds.",
          "authors": [
            "Anuran Makur",
            "Japneet Singh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.08360",
          "title": "Minimax Hypothesis Testing for the Bradley-Terry-Luce Model",
          "abstract": "The Bradley-Terry-Luce (BTL) model is one of the most widely used models for ranking a collection of items or agents based on pairwise comparisons among them. Given $n$ agents, the BTL model endows each agent $i$ with a latent skill score $\\alpha_i > 0$ and posits that the probability that agent $i$ is preferred over agent $j$ is $\\alpha_i/(\\alpha_i + \\alpha_j)$. In this work, our objective is to formulate a hypothesis test that determines whether a given pairwise comparison dataset, with $k$ comparisons per pair of agents, originates from an underlying BTL model. We formalize this testing problem in the minimax sense and define the critical threshold of the problem. We then establish upper bounds on the critical threshold for general induced observation graphs (satisfying mild assumptions) and develop lower bounds for complete induced graphs. Our bounds demonstrate that for complete induced graphs, the critical threshold scales as $\\Theta((nk)^{-1/2})$ in a minimax sense. In particular, our test statistic for the upper bounds is based on a new approximation we derive for the separation distance between general pairwise comparison models and the class of BTL models. To further assess the performance of our statistical test, we prove upper bounds on the type I and type II probabilities of error. Much of our analysis is conducted within the context of a fixed observation graph structure, where the graph possesses certain ``nice'' properties, such as expansion and bounded principal ratio. Additionally, we derive several auxiliary results, such as bounds on principal ratios of graphs, $\\ell^2$-bounds on BTL parameter estimation under model mismatch, stability of rankings under the BTL model, etc. We validate our theoretical results through experiments on synthetic and real-world datasets and propose a data-driven permutation testing approach to determine test thresholds.",
          "authors": [
            "Anuran Makur",
            "Japneet Singh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.08360",
          "title": "Minimax Hypothesis Testing for the Bradley-Terry-Luce Model",
          "abstract": "The Bradley-Terry-Luce (BTL) model is one of the most widely used models for ranking a collection of items or agents based on pairwise comparisons among them. Given $n$ agents, the BTL model endows each agent $i$ with a latent skill score $\\alpha_i > 0$ and posits that the probability that agent $i$ is preferred over agent $j$ is $\\alpha_i/(\\alpha_i + \\alpha_j)$. In this work, our objective is to formulate a hypothesis test that determines whether a given pairwise comparison dataset, with $k$ comparisons per pair of agents, originates from an underlying BTL model. We formalize this testing problem in the minimax sense and define the critical threshold of the problem. We then establish upper bounds on the critical threshold for general induced observation graphs (satisfying mild assumptions) and develop lower bounds for complete induced graphs. Our bounds demonstrate that for complete induced graphs, the critical threshold scales as $\\Theta((nk)^{-1/2})$ in a minimax sense. In particular, our test statistic for the upper bounds is based on a new approximation we derive for the separation distance between general pairwise comparison models and the class of BTL models. To further assess the performance of our statistical test, we prove upper bounds on the type I and type II probabilities of error. Much of our analysis is conducted within the context of a fixed observation graph structure, where the graph possesses certain ``nice'' properties, such as expansion and bounded principal ratio. Additionally, we derive several auxiliary results, such as bounds on principal ratios of graphs, $\\ell^2$-bounds on BTL parameter estimation under model mismatch, stability of rankings under the BTL model, etc. We validate our theoretical results through experiments on synthetic and real-world datasets and propose a data-driven permutation testing approach to determine test thresholds.",
          "authors": [
            "Anuran Makur",
            "Japneet Singh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.12669",
          "title": "3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation",
          "abstract": "The increasing demand for controllable outputs in text-to-image generation has spurred advancements in multi-instance generation (MIG), allowing users to define both instance layouts and attributes. However, unlike image-conditional generation methods such as ControlNet, MIG techniques have not been widely adopted in state-of-the-art models like SD2 and SDXL, primarily due to the challenge of building robust renderers that simultaneously handle instance positioning and attribute rendering. In this paper, we introduce Depth-Driven Decoupled Instance Synthesis (3DIS), a novel framework that decouples the MIG process into two stages: (i) generating a coarse scene depth map for accurate instance positioning and scene composition, and (ii) rendering fine-grained attributes using pre-trained ControlNet on any foundational model, without additional training. Our 3DIS framework integrates a custom adapter into LDM3D for precise depth-based layouts and employs a finetuning-free method for enhanced instance-level attribute rendering. Extensive experiments on COCO-Position and COCO-MIG benchmarks demonstrate that 3DIS significantly outperforms existing methods in both layout precision and attribute rendering. Notably, 3DIS offers seamless compatibility with diverse foundational models, providing a robust, adaptable solution for advanced multi-instance generation. The code is available at: this https URL .",
          "authors": [
            "Dewei Zhou",
            "Ji Xie",
            "Zongxin Yang",
            "Yi Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.14040",
          "title": "WARPD: World model Assisted Reactive Policy Diffusion",
          "abstract": "With the increasing availability of open-source robotic data, imitation learning has become a promising approach for both manipulation and locomotion. Diffusion models are now widely used to train large, generalized policies that predict controls or trajectories, leveraging their ability to model multimodal action distributions. However, this generality comes at the cost of larger model sizes and slower inference, an acute limitation for robotic tasks requiring high control frequencies. Moreover, Diffusion Policy (DP), a popular trajectory-generation approach, suffers from a trade-off between performance and action horizon: fewer diffusion queries lead to larger trajectory chunks, which in turn accumulate tracking errors. To overcome these challenges, we introduce WARPD (World model Assisted Reactive Policy Diffusion), a method that generates closed-loop policies (weights for neural policies) directly, instead of open-loop trajectories. By learning behavioral distributions in parameter space rather than trajectory space, WARPD offers two major advantages: (1) extended action horizons with robustness to perturbations, while maintaining high task performance, and (2) significantly reduced inference costs. Empirically, WARPD outperforms DP in long-horizon and perturbed environments, and achieves multitask performance on par with DP while requiring only ~ 1/45th of the inference-time FLOPs per step.",
          "authors": [
            "Shashank Hegde",
            "Satyajeet Das",
            "Gautam Salhotra",
            "Gaurav S. Sukhatme"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2410.17498",
          "title": "Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks",
          "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in symbol processing through in-context learning (ICL). This success flies in the face of decades of critiques asserting that artificial neural networks cannot master abstract symbol manipulation. We seek to understand the mechanisms that can enable robust symbol processing in transformer networks, illuminating both the unanticipated success, and the significant limitations, of transformers in symbol processing. Borrowing insights from symbolic AI and cognitive science on the power of Production System architectures, we develop a high-level Production System Language, PSL, that allows us to write symbolic programs to do complex, abstract symbol processing, and create compilers that precisely implement PSL programs in transformer networks which are, by construction, 100% mechanistically interpretable. The work is driven by study of a purely abstract (semantics-free) symbolic task that we develop, Templatic Generation (TGT). Although developed through study of TGT, PSL is, we demonstrate, highly general: it is Turing Universal. The new type of transformer architecture that we compile from PSL programs suggests a number of paths for enhancing transformers' capabilities at symbol processing. We note, however, that the work we report addresses computability, and not learnability, by transformer networks. Note: The first section provides an extended synopsis of the entire paper.",
          "authors": [
            "Paul Smolensky",
            "Roland Fernandez",
            "Zhenghao Herbert Zhou",
            "Mattia Opper",
            "Adam Davies",
            "Jianfeng Gao"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.04257",
          "title": "LSHBloom: Memory-efficient, Extreme-scale Document Deduplication",
          "abstract": "Contemporary large language model (LLM) training pipelines require the assembly of internet-scale databases full of text data from a variety of sources (e.g., web, academic, and publishers). Preprocessing these datasets via deduplication -- detecting and eliminating additional instances of the same content -- is a major focus for assembling and curating training datasets for LLMs. Unrestrained, duplicates in the training dataset increase training costs and lead to undesirable properties such as memorization in trained models or cheating on evaluation. Unfortunately, contemporary approaches to document-level deduplication are either unreliable at accurately identifying duplicate documents or extremely expensive in terms of both runtime and memory. We propose LSHBloom, an extension to MinhashLSH, which replaces the expensive LSHIndex with lightweight Bloom filters. LSHBloom demonstrates the same state-of-the-art deduplication performance as MinhashLSH, with only a marginal increase in false positives (near zero in our experiments), while boasting competitive runtime (12$\\times$ faster than MinhashLSH on peS2o) and, crucially, using 18$\\times$ less disk space than MinhashLSH (as measured on peS2o). Based on extrapolation, we show that this advantage in space and runtime remains even at the extreme scale of several billion documents. LSHBloom allows practitioners to access the deduplication quality of MinHashLSH at scales that are normally only tractable for less sophisticated, heuristic solutions. As a result, LSHBloom promises to enable scaling high-quality document deduplication to internet-scale text datasets.",
          "authors": [
            "Arham Khan",
            "Robert Underwood",
            "Carlo Siebenschuh",
            "Yadu Babuji",
            "Aswathy Ajith",
            "Kyle Hippe",
            "Ozan Gokdemir",
            "Alexander Brace",
            "Kyle Chard",
            "Ian Foster"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.05036",
          "title": "From Word Vectors to Multimodal Embeddings: Techniques, Applications, and Future Directions For Large Language Models",
          "abstract": "Word embeddings and language models have transformed natural language processing (NLP) by facilitating the representation of linguistic elements in continuous vector spaces. This review visits foundational concepts such as the distributional hypothesis and contextual similarity, tracing the evolution from sparse representations like one-hot encoding to dense embeddings including Word2Vec, GloVe, and fastText. We examine both static and contextualized embeddings, underscoring advancements in models such as ELMo, BERT, and GPT and their adaptations for cross-lingual and personalized applications. The discussion extends to sentence and document embeddings, covering aggregation methods and generative topic models, along with the application of embeddings in multimodal domains, including vision, robotics, and cognitive science. Advanced topics such as model compression, interpretability, numerical encoding, and bias mitigation are analyzed, addressing both technical challenges and ethical implications. Additionally, we identify future research directions, emphasizing the need for scalable training techniques, enhanced interpretability, and robust grounding in non-textual modalities. By synthesizing current methodologies and emerging trends, this survey offers researchers and practitioners an in-depth resource to push the boundaries of embedding-based language models.",
          "authors": [
            "Charles Zhang",
            "Benji Peng",
            "Xintian Sun",
            "Qian Niu",
            "Junyu Liu",
            "Keyu Chen",
            "Ming Li",
            "Pohsun Feng",
            "Ziqian Bi",
            "Ming Liu",
            "Yichao Zhang",
            "Xinyuan Song",
            "Cheng Fei",
            "Caitlyn Heqi Yin",
            "Lawrence KQ Yan",
            "Hongyang He",
            "Tianyang Wang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2411.08699",
          "title": "FedSub: Introducing Class-aware Subnetworks Fusion to Enhance Personalized Federated Learning",
          "abstract": "Personalized Federated Learning aims at addressing the challenges of non-IID data in collaborative model training. However, existing methods struggle to balance personalization and generalization, often oversimplifying client similarities or relying too heavily on global models. In this paper, we propose FedSub, a novel approach that introduces class-aware model updates based on data prototypes and model subnetworks fusion to enhance personalization. Prototypes serve as compact representations of client data for each class, clustered on the server to capture label-specific similarities among the clients. Meanwhile, model subnetworks encapsulate the most relevant components to process each class and they are then fused on the server based on the identified clusters to generate fine-grained, class-specific, and highly personalized model updates for each client. Experimental results in three real-world scenarios with high data heterogeneity in human activity recognition and mobile health applications demonstrate the effectiveness of FedSub with respect to state-of-the-art methods to achieve fast convergence and high classification performance.",
          "authors": [
            "Mattia Giovanni Campana",
            "Franca Delmastro"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.01784",
          "title": "Noise Injection Reveals Hidden Capabilities of Sandbagging Language Models",
          "abstract": "Capability evaluations play a crucial role in assessing and regulating frontier AI systems. The effectiveness of these evaluations faces a significant challenge: strategic underperformance, or ``sandbagging'', where models deliberately underperform during evaluation. Sandbagging can manifest either through explicit developer intervention or through unintended model behavior, presenting a fundamental obstacle to accurate capability assessment. We introduce a novel sandbagging detection method based on injecting noise of varying magnitudes into model weights. While non-sandbagging models show predictable performance degradation with increasing noise, we demonstrate that sandbagging models exhibit anomalous performance improvements, likely due to disruption of underperformance mechanisms while core capabilities remain partially intact. Through experiments across various model architectures, sizes, and sandbagging techniques, we establish this distinctive response pattern as a reliable, model-agnostic signal for detecting sandbagging behavior. Importantly, we find noise-injection is capable of eliciting the full performance of Mistral Large 120B in a setting where the model underperforms without being instructed to do so. Our findings provide a practical tool for AI evaluation and oversight, addressing a challenge in ensuring accurate capability assessment of frontier AI systems.",
          "authors": [
            "Cameron Tice",
            "Philipp Alexander Kreer",
            "Nathan Helm-Burger",
            "Prithviraj Singh Shahani",
            "Fedor Ryzhenkov",
            "Fabien Roger",
            "Clement Neo",
            "Jacob Haimes",
            "Felix Hofstätter",
            "Teun van der Weij"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.03797",
          "title": "A Two-Stage Bayesian Approach for Variable Selection in Joint Modeling of Multiple Longitudinal Markers with Competing Risks",
          "abstract": "In many clinical and epidemiological studies, collecting longitudinal measurements together with time-to-event outcomes is essential. Accurately estimating the association between longitudinal markers and event risks, as well as identifying key markers for prediction, is especially important in the presence of competing risks. However, as the number of markers increases, fitting full joint models becomes computationally difficult and may lead to convergence issues. We propose a two-stage Bayesian approach for variable selection in joint models with multiple longitudinal markers and competing risks. The method efficiently identifies important longitudinal markers and covariates. In the first stage, a one-marker joint model is fitted for each marker with the competing risks outcome, and individual marker trajectories are predicted, reducing bias from informative dropout. In the second stage, a cause-specific hazards model is fitted, incorporating the predicted current values of all markers as time-dependent covariates. We consider both continuous and Dirac spike-and-slab priors for Bayesian variable selection, implemented through MCMC algorithms. Our approach enables risk prediction using a large number of longitudinal markers, which is often infeasible for standard joint models. We evaluate performance through simulation studies, examining both variable selection and predictive accuracy. Finally, we apply the method to predict dementia risk in the Three-City (3C) study, a French cohort with competing risks of death. To facilitate use, we provide an R package, VSJM, available at: https:/github.com/tbaghfalaki/VSJM .",
          "authors": [
            "Taban Baghfalaki",
            "Reza Hashemi",
            "Christophe Tzourio",
            "Catherine Helmer",
            "Helene Jacqmin-Gadda"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.05265",
          "title": "Reinforcement Learning: An Overview",
          "abstract": "This manuscript gives a big-picture, up-to-date overview of the field of (deep) reinforcement learning and sequential decision making, covering value-based methods, policy-based methods, model-based methods, multi-agent RL, LLMs and RL, and various other topics (e.g., offline RL, hierarchical RL, intrinsic reward). It also includes some code snippets for training LLMs with RL.",
          "authors": [
            "Kevin Murphy"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.06540",
          "title": "Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families",
          "abstract": "Scaling laws for large language models (LLMs) predict model performance based on parameters like size and training data. However, differences in training configurations and data processing across model families lead to significant variations in benchmark performance, making it difficult for a single scaling law to generalize across all LLMs. On the other hand, training family-specific scaling laws requires training models of varying sizes for every family. In this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a novel scaling law that leverages publicly available benchmark data and assumes LLM performance is driven by low-dimensional latent skills, such as reasoning and instruction following. These latent skills are influenced by computational resources like model size and training tokens, but with varying efficiencies across model families. Sloth exploits correlations across benchmarks to provide more accurate and interpretable predictions while alleviating the need to train multiple LLMs per family. We present both theoretical results on parameter identification and empirical evaluations on 12 prominent benchmarks, from Open LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance accurately and offers insights into scaling behaviors for complex downstream tasks, increased test-time compute, and compute-optimal scaling of skills.",
          "authors": [
            "Felipe Maia Polo",
            "Seamus Somerstep",
            "Leshem Choshen",
            "Yuekai Sun",
            "Mikhail Yurochkin"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.06540",
          "title": "Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families",
          "abstract": "Scaling laws for large language models (LLMs) predict model performance based on parameters like size and training data. However, differences in training configurations and data processing across model families lead to significant variations in benchmark performance, making it difficult for a single scaling law to generalize across all LLMs. On the other hand, training family-specific scaling laws requires training models of varying sizes for every family. In this work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a novel scaling law that leverages publicly available benchmark data and assumes LLM performance is driven by low-dimensional latent skills, such as reasoning and instruction following. These latent skills are influenced by computational resources like model size and training tokens, but with varying efficiencies across model families. Sloth exploits correlations across benchmarks to provide more accurate and interpretable predictions while alleviating the need to train multiple LLMs per family. We present both theoretical results on parameter identification and empirical evaluations on 12 prominent benchmarks, from Open LLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance accurately and offers insights into scaling behaviors for complex downstream tasks, increased test-time compute, and compute-optimal scaling of skills.",
          "authors": [
            "Felipe Maia Polo",
            "Seamus Somerstep",
            "Leshem Choshen",
            "Yuekai Sun",
            "Mikhail Yurochkin"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.06740",
          "title": "Convolution goes higher-order: a biologically inspired mechanism empowers image classification",
          "abstract": "We propose a novel approach to image classification inspired by complex nonlinear biological visual processing, whereby classical convolutional neural networks (CNNs) are equipped with learnable higher-order convolutions. Our model incorporates a Volterra-like expansion of the convolution operator, capturing multiplicative interactions akin to those observed in early and advanced stages of biological visual processing. We evaluated this approach on synthetic datasets by measuring sensitivity to testing higher-order correlations and performance in standard benchmarks (MNIST, FashionMNIST, CIFAR10, CIFAR100 and Imagenette). Our architecture outperforms traditional CNN baselines, and achieves optimal performance with expansions up to 3rd/4th order, aligning remarkably well with the distribution of pixel intensities in natural images. Through systematic perturbation analysis, we validate this alignment by isolating the contributions of specific image statistics to model performance, demonstrating how different orders of convolution process distinct aspects of visual information. Furthermore, Representational Similarity Analysis reveals distinct geometries across network layers, indicating qualitatively different modes of visual information processing. Our work bridges neuroscience and deep learning, offering a path towards more effective, biologically inspired computer vision models. It provides insights into visual information processing and lays the groundwork for neural networks that better capture complex visual patterns, particularly in resource-constrained scenarios.",
          "authors": [
            "Simone Azeglio",
            "Olivier Marre",
            "Peter Neri",
            "Ulisse Ferrari"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.06740",
          "title": "Convolution goes higher-order: a biologically inspired mechanism empowers image classification",
          "abstract": "We propose a novel approach to image classification inspired by complex nonlinear biological visual processing, whereby classical convolutional neural networks (CNNs) are equipped with learnable higher-order convolutions. Our model incorporates a Volterra-like expansion of the convolution operator, capturing multiplicative interactions akin to those observed in early and advanced stages of biological visual processing. We evaluated this approach on synthetic datasets by measuring sensitivity to testing higher-order correlations and performance in standard benchmarks (MNIST, FashionMNIST, CIFAR10, CIFAR100 and Imagenette). Our architecture outperforms traditional CNN baselines, and achieves optimal performance with expansions up to 3rd/4th order, aligning remarkably well with the distribution of pixel intensities in natural images. Through systematic perturbation analysis, we validate this alignment by isolating the contributions of specific image statistics to model performance, demonstrating how different orders of convolution process distinct aspects of visual information. Furthermore, Representational Similarity Analysis reveals distinct geometries across network layers, indicating qualitatively different modes of visual information processing. Our work bridges neuroscience and deep learning, offering a path towards more effective, biologically inspired computer vision models. It provides insights into visual information processing and lays the groundwork for neural networks that better capture complex visual patterns, particularly in resource-constrained scenarios.",
          "authors": [
            "Simone Azeglio",
            "Olivier Marre",
            "Peter Neri",
            "Ulisse Ferrari"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.16261",
          "title": "A reduced model for the long-term effects of physical activity on type 2 diabetes",
          "abstract": "Type 2 diabetes progresses slowly and may be reversed through lifestyle changes, but quantifying the long-term impact of regular physical activity remains challenging due to sparse longitudinal data. Mechanistic models offer a powerful tool by simulating metabolic processes over extended timescales. However, multi-scale formulations that capture both the short-term effects of exercise sessions and the slow evolution of disease tend to be computationally demanding, limiting their practical use in personalized decision support. To address this limitation, we derived a reduced version of a two-scale model that captures the short- and long-term effects of physical activity on blood glucose regulation. By analytically averaging the short-term effects induced by exercise, we developed a homogenized formulation that transmits the average contribution of physical activity to the slower glucose-insulin dynamics. This reduction preserves the key model dynamics while decreasing computational complexity by almost a factor 2000. We prove that the approximation error remains bounded and confirm the model's accuracy through a parameter-based simulation study. The resulting model provides a mathematically grounded reduction that retains key physiological mechanisms while enabling fast long-term simulations. This substantial computational gain makes it suitable for integration into medical decision support systems, where it can be used to design and evaluate personalized physical activity plans aimed at reducing the risk of type 2 diabetes.",
          "authors": [
            "Lea Multerer",
            "Pierluigi Francesco De Paola",
            "Marta Lenatti",
            "Alessia Paglialonga",
            "Laura Azzimonti"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2412.20555",
          "title": "Parameter-Specific Bias Diagnostics in Random-Effects Panel Data Models",
          "abstract": "The Hausman specification test detects inconsistency in random-effects estimators by comparing them with alternative fixed-effects estimators. This note shows how a recently proposed bias diagnostic for linear mixed models can complement this test in random-effects panel-data applications. The diagnostic delivers parameter-specific internal estimates of finite-sample bias, together with permutation-based $p$-values, from a single fitted random-effects model. We illustrate its use in a gasoline-demand panel and in a value-added model for teacher evaluation, using publicly available R packages, and we discuss how the resulting bias summaries can be incorporated into routine practice.",
          "authors": [
            "Andrew T. Karl"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.08033",
          "title": "Robust Semiparametric Graphical Models with Skew-Elliptical Distributions",
          "abstract": "We propose semiparametric estimators, called elliptical skew-(S)KEPTIC, for efficiently and robustly estimating non-Gaussian graphical models. Our approach extends the semiparametric elliptical framework to the meta skew-elliptical family, which accommodates skewness. Theoretically, we show that the elliptical skew-(S)KEPTIC estimators achieve robust convergence rates for both graph recovery and parameter estimation. Through numerical simulations, we illustrate the reliable graph recovery performance of the elliptical skew-(S)KEPTIC estimators. Finally, we apply the new method to the daily log-returns of the stocks in the S\\&P 500 index and obtain a sparser graph than with Gaussian copula graphical models.",
          "authors": [
            "Gabriele Di Luzio",
            "Giacomo Morelli"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.09270",
          "title": "Predicting the depth of the most recent common ancestor of a random sample of $k$ species: the impact of phylogenetic tree shape",
          "abstract": "We consider the following question: how close to the ancestral root of a phylogenetic tree is the most recent common ancestor of $k$ species randomly sampled from the tips of the tree? For trees having shapes predicted by the Yule-Harding model, it is known that the most recent common ancestor is likely to be close to (or equal to) the root of the full tree, even as $n$ becomes large (for $k$ fixed). However, this result does not extend to models of tree shape that more closely describe phylogenies encountered in evolutionary biology. We investigate the impact of tree shape (via the Aldous $\\beta-$splitting model) to predict the number of edges that separate the most recent common ancestor of a random sample of $k$ tip species and the root of the parent tree they are sampled from. Both exact and asymptotic results are presented. We also briefly consider a variation of the process in which a random number of tip species are sampled.",
          "authors": [
            "Michael Fuchs",
            "Mike Steel"
          ],
          "primary_category": "q-bio.PE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.09270",
          "title": "Predicting the depth of the most recent common ancestor of a random sample of $k$ species: the impact of phylogenetic tree shape",
          "abstract": "We consider the following question: how close to the ancestral root of a phylogenetic tree is the most recent common ancestor of $k$ species randomly sampled from the tips of the tree? For trees having shapes predicted by the Yule-Harding model, it is known that the most recent common ancestor is likely to be close to (or equal to) the root of the full tree, even as $n$ becomes large (for $k$ fixed). However, this result does not extend to models of tree shape that more closely describe phylogenies encountered in evolutionary biology. We investigate the impact of tree shape (via the Aldous $\\beta-$splitting model) to predict the number of edges that separate the most recent common ancestor of a random sample of $k$ tip species and the root of the parent tree they are sampled from. Both exact and asymptotic results are presented. We also briefly consider a variation of the process in which a random number of tip species are sampled.",
          "authors": [
            "Michael Fuchs",
            "Mike Steel"
          ],
          "primary_category": "q-bio.PE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.09557",
          "title": "Core Hours and Carbon Credits: Incentivizing Sustainability in HPC",
          "abstract": "Realizing a shared responsibility between providers and consumers is critical to manage the sustainability of HPC. However, while cost may motivate efficiency improvements by infrastructure operators, broader progress is impeded by a lack of user incentives. We conduct a survey of HPC users that reveals fewer than 30 percent are aware of their energy consumption, and that energy efficiency is among users' lowest priority concerns. One explanation is that existing pricing models may encourage users to prioritize performance over energy efficiency. We propose two transparent multi-resource pricing schemes, Energy- and Carbon-Based Accounting, that seek to change this paradigm by incentivizing more efficient user behavior. These two schemes charge for computations based on their energy consumption or carbon footprint, respectively, rewarding users who leverage efficient hardware and software. We evaluate these two pricing schemes via simulation, in a prototype, and a user study.",
          "authors": [
            "Alok Kamatar",
            "Maxime Gonthier",
            "Valerie Hayot-Sasson",
            "Andre Bauer",
            "Marcin Copik",
            "Torsten Hoefler",
            "Raul Castro Fernandez",
            "Kyle Chard",
            "Ian Foster"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.16165",
          "title": "A Survey of Operating System Kernel Fuzzing",
          "abstract": "The Operating System (OS) kernel is foundational in modern computing, especially with the proliferation of diverse computing devices. However, its development also comes with vulnerabilities that can lead to severe security breaches. Kernel fuzzing, a technique used to uncover these vulnerabilities, poses distinct challenges when compared to user-space fuzzing. These include the complexity of configuring the testing environment and addressing the statefulness inherent to both the kernel and the fuzzing process. Despite the significant interest from the community, a comprehensive understanding of kernel fuzzing remains lacking, hindering further progress in the field. In this paper, we present the first systematic study focused specifically on OS kernel fuzzing. We begin by outlining the unique challenges of kernel fuzzing, which distinguish it from those in user space. Following this, we summarize the progress of 107 academic studies from top-tier venues between 2017 and 2025. To structure this analysis, we introduce a stage-based fuzzing model and a novel fuzzing taxonomy that highlights nine core functionalities unique to kernel fuzzing. Each of these functionalities is examined in conjunction with the methodological approaches employed to address them. Finally, we identify remaining gaps in addressing challenges and outline promising directions to guide forthcoming research in kernel security.",
          "authors": [
            "Jiacheng Xu",
            "He Sun",
            "Shihao Jiang",
            "Qinying Wang",
            "Mingming Zhang",
            "Xiang Li",
            "Kaiwen Shen",
            "Peng Cheng",
            "Jiming Chen",
            "Charles Zhang",
            "Shouling Ji"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2501.16843",
          "title": "Bones of Contention: Exploring Query-Efficient Attacks against Skeleton Recognition Systems",
          "abstract": "Skeleton action recognition models have secured more attention than video-based ones in various applications due to privacy preservation and lower storage requirements. Skeleton data are typically transmitted to cloud servers for action recognition, with results returned to clients via Apps/APIs. However, the vulnerability of skeletal models against adversarial perturbations gradually reveals the unreliability of these systems. Existing black-box attacks all operate in a decision-based manner, resulting in numerous queries that hinder efficiency and feasibility in real-world applications. Moreover, all attacks off the shelf focus on only restricted perturbations, while ignoring model weaknesses when encountered with non-semantic perturbations. In this paper, we propose two query-effIcient Skeletal Adversarial AttaCks, ISAAC-K and ISAAC-N. As a black-box attack, ISAAC-K utilizes Grad-CAM in a surrogate model to extract key joints where minor sparse perturbations are then added to fool the classifier. To guarantee natural adversarial motions, we introduce constraints of both bone length and temporal consistency. ISAAC-K finds stronger adversarial examples on the $\\ell_\\infty$ norm, which can encompass those on other norms. Exhaustive experiments substantiate that ISAAC-K can uplift the attack efficiency of the perturbations under 10 skeletal models. Additionally, as a byproduct, ISAAC-N fools the classifier by replacing skeletons unrelated to the action. We surprisingly find that skeletal models are vulnerable to large perturbations where the part-wise non-semantic joints are just replaced, leading to a query-free no-box attack without any prior knowledge. Based on that, four adaptive defenses are eventually proposed to improve the robustness of skeleton recognition models.",
          "authors": [
            "Yuxin Cao",
            "Kai Ye",
            "Derui Wang",
            "Minhui Xue",
            "Hao Ge",
            "Chenxiong Qian",
            "Jin Song Dong"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.01846",
          "title": "UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping",
          "abstract": "3D Gaussian Splatting (3DGS) has demonstrated superior quality in modeling 3D objects and scenes. However, generating 3DGS remains challenging due to their discrete, unstructured, and permutation-invariant nature. In this work, we present a simple yet effective method to overcome these challenges. We utilize spherical mapping to transform 3DGS into a structured 2D representation, termed UVGS. UVGS can be viewed as multi-channel images, with feature dimensions as a concatenation of Gaussian attributes such as position, scale, color, opacity, and rotation. We further find that these heterogeneous features can be compressed into a lower-dimensional (e.g., 3-channel) shared feature space using a carefully designed multi-branch network. The compressed UVGS can be treated as typical RGB images. Remarkably, we discover that typical VAEs trained with latent diffusion models can directly generalize to this new representation without additional training. Our novel representation makes it effortless to leverage foundational 2D models, such as diffusion models, to directly model 3DGS. Additionally, one can simply increase the 2D UV resolution to accommodate more Gaussians, making UVGS a scalable solution compared to typical 3D backbones. This approach immediately unlocks various novel generation applications of 3DGS by inherently utilizing the already developed superior 2D generation capabilities. In our experiments, we demonstrate various unconditional, conditional generation, and inpainting applications of 3DGS based on diffusion models, which were previously non-trivial.",
          "authors": [
            "Aashish Rai",
            "Dilin Wang",
            "Mihir Jain",
            "Nikolaos Sarafianos",
            "Kefan Chen",
            "Srinath Sridhar",
            "Aayush Prakash"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.02877",
          "title": "Differentially-Private Multi-Tier Federated Learning: A Formal Analysis and Evaluation",
          "abstract": "While federated learning (FL) eliminates the transmission of raw data over a network, it is still vulnerable to privacy breaches from the communicated model parameters. Differential privacy (DP) is often employed to address such issues. However, the impact of DP on FL in multi-tier networks -- where hierarchical aggregations couple noise injection decisions at different tiers, and trust models are heterogeneous across subnetworks -- is not well understood. To fill this gap, we develop \\underline{M}ulti-Tier \\underline{F}ederated Learning with \\underline{M}ulti-Tier \\underline{D}ifferential \\underline{P}rivacy ({\\tt M$^2$FDP}), a DP-enhanced FL methodology for jointly optimizing privacy and performance over such networks. One of the key principles of {\\tt M$^2$FDP} is to adapt DP noise injection across the established edge/fog computing hierarchy (e.g., edge devices, intermediate nodes, and other tiers up to cloud servers) according to the trust models in different subnetworks. We conduct a comprehensive analysis of the convergence behavior of {\\tt M$^2$FDP} under non-convex problem settings, revealing conditions on parameter tuning under which the training process converges sublinearly to a finite stationarity gap that depends on the network hierarchy, trust model, and target privacy level. We show how these relationships can be employed to develop an adaptive control algorithm for {\\tt M$^2$FDP} that tunes properties of local model training to minimize energy, latency, and the stationarity gap while meeting desired convergence and privacy criterion. Subsequent numerical evaluations demonstrate that {\\tt M$^2$FDP} obtains substantial improvements in these metrics over baselines for different privacy budgets and system configurations.",
          "authors": [
            "Evan Chen",
            "Frank Po-Chen Lin",
            "Dong-Jun Han",
            "Christopher G. Brinton"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.03826",
          "title": "FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing",
          "abstract": "Text-to-image (T2I) models have advanced creative content generation, yet their reliance on large uncurated datasets often reproduces societal biases. We present FairT2I, a training-free and interactive framework grounded in a mathematically principled latent variable guidance formulation. This formulation decomposes the generative score function into attribute-conditioned components and reweights them according to a defined distribution, providing a unified and flexible mechanism for bias-aware generation that also subsumes many existing ad hoc debiasing approaches as special cases. Building upon this foundation, FairT2I incorporates (1) latent variable guidance as the core mechanism, (2) LLM-based bias detection to automatically infer bias-prone categories and attributes from text prompts as part of the latent structure, and (3) attribute resampling, which allows users to adjust or redefine the attribute distribution based on uniform, real-world, or user-specified statistics. The accompanying user interface supports this pipeline by enabling users to inspect detected biases, modify attributes or weights, and generate debiased images in real time. Experimental results show that LLMs outperform average human annotators in the number and granularity of detected bias categories and attributes. Moreover, FairT2I achieves superior performance to baseline models in both societal bias mitigation and image diversity, while preserving image quality and prompt fidelity.",
          "authors": [
            "Jinya Sakurai",
            "Yuki Koyama",
            "Issei Sato"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.04916",
          "title": "Classification or Prompting: A Case Study on Legal Requirements Traceability",
          "abstract": "New regulations are introduced to ensure software development aligns with ethical concerns and protects public safety. Showing compliance requires tracing requirements to legal provisions. Requirements traceability is a key task where engineers must analyze technical requirements against target artifacts, often within limited time. Manually analyzing complex systems with hundreds of requirements is infeasible. The legal dimension adds challenges that increase effort. In this paper, we investigate two automated solutions based on language models, including large ones (LLMs). The first solution, Kashif, is a classifier that leverages sentence transformers and semantic similarity. The second solution, RICE_LRT, prompts a recent LLM based on RICE, a prompt engineering framework. Using a publicly available benchmark dataset, we empirically evaluate Kashif and compare it against seven baseline classifiers from the literature (LSI, LDA, GloVe, TraceBERT, RoBERTa, and LLaMa). Kashif can identify trace links with F2 score of 63%, outperforming the best baseline by a substantial margin of 21 percentage points (pp) in F2 score. On a newly created and more complex requirements document traced to the European general data protection regulation (GDPR), RICE_LRT outperforms Kashif and baseline prompts in the literature by achieving an average recall of 84% and F2 score of 61%, improving the F2 score by 34 pp compared to the best baseline prompt. Our results indicate that requirements traceability in legal contexts cannot be adequately addressed by techniques proposed in the literature that are not specifically designed for legal artifacts. Furthermore, we demonstrate that our engineered prompt outperforms both classifier-based approaches and baseline prompts.",
          "authors": [
            "Romina Etezadi",
            "Sallam Abualhaija",
            "Chetan Arora",
            "Lionel Briand"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.05684",
          "title": "Machine Unlearning via Information Theoretic Regularization",
          "abstract": "How can we effectively remove or ''unlearn'' undesirable information, such as specific features or the influence of individual data points, from a learning outcome while minimizing utility loss and ensuring rigorous guarantees? We introduce a unified mathematical framework based on information-theoretic regularization to address both data point unlearning and feature unlearning. For data point unlearning, we introduce the $\\textit{Marginal Unlearning Principle}$, an auditable and provable framework inspired by memory suppression studies in neuroscience. Moreover, we provide formal information-theoretic unlearning definition based on the proposed principle, named marginal unlearning, and provable guarantees on sufficiency and necessity of marginal unlearning to the existing approximate unlearning definitions. We then show the proposed framework provide natural solution to the marginal unlearning problems. For feature unlearning, the framework applies to deep learning with arbitrary training objectives. By combining flexibility in learning objectives with simplicity in regularization design, our approach is highly adaptable and practical for a wide range of machine learning and AI applications. From a mathematical perspective, we provide an unified analytic solution to the optimal feature unlearning problem with a variety of information-theoretic training objectives. Our theoretical analysis reveals intriguing connections between machine unlearning, information theory, optimal transport, and extremal sigma algebras. Numerical simulations support our theoretical finding.",
          "authors": [
            "Shizhou Xu",
            "Thomas Strohmer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.05684",
          "title": "Machine Unlearning via Information Theoretic Regularization",
          "abstract": "How can we effectively remove or ''unlearn'' undesirable information, such as specific features or the influence of individual data points, from a learning outcome while minimizing utility loss and ensuring rigorous guarantees? We introduce a unified mathematical framework based on information-theoretic regularization to address both data point unlearning and feature unlearning. For data point unlearning, we introduce the $\\textit{Marginal Unlearning Principle}$, an auditable and provable framework inspired by memory suppression studies in neuroscience. Moreover, we provide formal information-theoretic unlearning definition based on the proposed principle, named marginal unlearning, and provable guarantees on sufficiency and necessity of marginal unlearning to the existing approximate unlearning definitions. We then show the proposed framework provide natural solution to the marginal unlearning problems. For feature unlearning, the framework applies to deep learning with arbitrary training objectives. By combining flexibility in learning objectives with simplicity in regularization design, our approach is highly adaptable and practical for a wide range of machine learning and AI applications. From a mathematical perspective, we provide an unified analytic solution to the optimal feature unlearning problem with a variety of information-theoretic training objectives. Our theoretical analysis reveals intriguing connections between machine unlearning, information theory, optimal transport, and extremal sigma algebras. Numerical simulations support our theoretical finding.",
          "authors": [
            "Shizhou Xu",
            "Thomas Strohmer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.05684",
          "title": "Machine Unlearning via Information Theoretic Regularization",
          "abstract": "How can we effectively remove or ''unlearn'' undesirable information, such as specific features or the influence of individual data points, from a learning outcome while minimizing utility loss and ensuring rigorous guarantees? We introduce a unified mathematical framework based on information-theoretic regularization to address both data point unlearning and feature unlearning. For data point unlearning, we introduce the $\\textit{Marginal Unlearning Principle}$, an auditable and provable framework inspired by memory suppression studies in neuroscience. Moreover, we provide formal information-theoretic unlearning definition based on the proposed principle, named marginal unlearning, and provable guarantees on sufficiency and necessity of marginal unlearning to the existing approximate unlearning definitions. We then show the proposed framework provide natural solution to the marginal unlearning problems. For feature unlearning, the framework applies to deep learning with arbitrary training objectives. By combining flexibility in learning objectives with simplicity in regularization design, our approach is highly adaptable and practical for a wide range of machine learning and AI applications. From a mathematical perspective, we provide an unified analytic solution to the optimal feature unlearning problem with a variety of information-theoretic training objectives. Our theoretical analysis reveals intriguing connections between machine unlearning, information theory, optimal transport, and extremal sigma algebras. Numerical simulations support our theoretical finding.",
          "authors": [
            "Shizhou Xu",
            "Thomas Strohmer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.06684",
          "title": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks",
          "abstract": "Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives rise to an irreducible \"equivariance gap\", an error term that introduces instability in predictions. We eliminate this gap by designing a fully target-equivariant architecture-ensuring permutation invariance via equivariant encoders, decoders, and a bi-attention mechanism. Empirical evaluation on standard classification benchmarks shows that, on datasets with more classes than those seen during pre-training, our model matches or surpasses existing methods while incurring lower computational overhead.",
          "authors": [
            "Michael Arbel",
            "David Salinas",
            "Frank Hutter"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.12397",
          "title": "Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone",
          "abstract": "Only 37% of sub-Saharan Africans use the internet, and those who do seldom rely on traditional web search. A major reason is that bandwidth is scarce and costly. We study whether an AI-powered WhatsApp chatbot can bridge this gap by analyzing 40,350 queries submitted by 529 Sierra Leonean teachers over 17 months. Each month, more teachers relied on AI than web search for teaching assistance. We compare the AI responses to the top results from this http URL , which mostly returns web pages formatted for foreign users: just 2% of pages originate in-country. Also, each web page consumes 3,107 times more bandwidth than an AI response on average. As a result, querying AI through WhatsApp is 98% less expensive than loading a web page, even including AI compute costs. In blinded evaluations, an independent sample of teachers rate AI responses as more relevant, helpful, and correct answers to queries than web search results. These findings suggest that AI can provide cost-effective access to information in low-connectivity environments.",
          "authors": [
            "Daniel Björkegren",
            "Jun Ho Choi",
            "Divya Budihal",
            "Dominic Sobhani",
            "Oliver Garrod",
            "Paul Atherton"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.12397",
          "title": "Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone",
          "abstract": "Only 37% of sub-Saharan Africans use the internet, and those who do seldom rely on traditional web search. A major reason is that bandwidth is scarce and costly. We study whether an AI-powered WhatsApp chatbot can bridge this gap by analyzing 40,350 queries submitted by 529 Sierra Leonean teachers over 17 months. Each month, more teachers relied on AI than web search for teaching assistance. We compare the AI responses to the top results from this http URL , which mostly returns web pages formatted for foreign users: just 2% of pages originate in-country. Also, each web page consumes 3,107 times more bandwidth than an AI response on average. As a result, querying AI through WhatsApp is 98% less expensive than loading a web page, even including AI compute costs. In blinded evaluations, an independent sample of teachers rate AI responses as more relevant, helpful, and correct answers to queries than web search results. These findings suggest that AI can provide cost-effective access to information in low-connectivity environments.",
          "authors": [
            "Daniel Björkegren",
            "Jun Ho Choi",
            "Divya Budihal",
            "Dominic Sobhani",
            "Oliver Garrod",
            "Paul Atherton"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.12397",
          "title": "Could AI Leapfrog the Web? Evidence from Teachers in Sierra Leone",
          "abstract": "Only 37% of sub-Saharan Africans use the internet, and those who do seldom rely on traditional web search. A major reason is that bandwidth is scarce and costly. We study whether an AI-powered WhatsApp chatbot can bridge this gap by analyzing 40,350 queries submitted by 529 Sierra Leonean teachers over 17 months. Each month, more teachers relied on AI than web search for teaching assistance. We compare the AI responses to the top results from this http URL , which mostly returns web pages formatted for foreign users: just 2% of pages originate in-country. Also, each web page consumes 3,107 times more bandwidth than an AI response on average. As a result, querying AI through WhatsApp is 98% less expensive than loading a web page, even including AI compute costs. In blinded evaluations, an independent sample of teachers rate AI responses as more relevant, helpful, and correct answers to queries than web search results. These findings suggest that AI can provide cost-effective access to information in low-connectivity environments.",
          "authors": [
            "Daniel Björkegren",
            "Jun Ho Choi",
            "Divya Budihal",
            "Dominic Sobhani",
            "Oliver Garrod",
            "Paul Atherton"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.13127",
          "title": "Facilitating Long Context Understanding via Supervised Chain-of-Thought Reasoning",
          "abstract": "Recent advances in Large Language Models (LLMs) have enabled them to process increasingly longer sequences, ranging from 2K to 2M tokens and even beyond. However, simply extending the input sequence length does not necessarily lead to effective long-context understanding. In this study, we integrate Chain-of-Thought (CoT) reasoning into LLMs in a supervised manner to facilitate effective long-context understanding. To achieve this, we introduce LongFinanceQA, a synthetic dataset in the financial domain designed to improve long-context reasoning. Unlike existing long-context synthetic data, LongFinanceQA includes intermediate CoT reasoning before the final conclusion, which encourages LLMs to perform explicit reasoning, improving accuracy and interpretability in long-context understanding. To generate synthetic CoT reasoning, we propose Property-based Agentic Inference (PAI), an agentic framework that simulates human-like reasoning steps, including property extraction, retrieval, and summarization. We evaluate PAI's reasoning capabilities by assessing GPT-4o-mini w/ PAI on the Loong benchmark, outperforming standard GPT-4o-mini by 20.0%. Furthermore, we fine-tune LLaMA-3.1-8B-Instruct on LongFinanceQA, achieving a 28.0% gain on Loong's financial subset.",
          "authors": [
            "Jingyang Lin",
            "Andy Wong",
            "Tian Xia",
            "Shenghua He",
            "Hui Wei",
            "Mei Han",
            "Jiebo Luo"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.15798",
          "title": "MaxSup: Overcoming Representation Collapse in Label Smoothing",
          "abstract": "Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature representations into overly tight clusters, diluting intra-class diversity, although the precise cause of this phenomenon remained elusive. In this paper, we analytically decompose the LS-induced loss, exposing two key terms: (i) a regularization term that dampens overconfidence only when the prediction is correct, and (ii) an error-amplification term that arises under misclassifications. This latter term compels the network to reinforce incorrect predictions with undue certainty, exacerbating representation collapse. To address these shortcomings, we propose Max Suppression (MaxSup), which applies uniform regularization to both correct and incorrect predictions by penalizing the top-1 logit rather than the ground-truth logit. Through extensive feature-space analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Experiments on large-scale image classification and multiple downstream tasks confirm that MaxSup is a more robust alternative to LS. Code is available at: this https URL",
          "authors": [
            "Yuxuan Zhou",
            "Heng Li",
            "Zhi-Qi Cheng",
            "Xudong Yan",
            "Yifei Dong",
            "Mario Fritz",
            "Margret Keuper"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.15926",
          "title": "Anomaly preserving contrastive neural embeddings for end-to-end model-independent searches at the LHC",
          "abstract": "Anomaly detection - identifying deviations from Standard Model predictions - is a key challenge at the Large Hadron Collider due to the size and complexity of its datasets. This is typically addressed by transforming high-dimensional detector data into lower-dimensional, physically meaningful features. We tackle feature extraction for anomaly detection by learning powerful low-dimensional representations via contrastive neural embeddings. This approach preserves potential anomalies indicative of new physics and enables rare signal extraction using novel machine learning-based statistical methods for signal-independent hypothesis testing. We compare supervised and self-supervised contrastive learning methods, for both MLP- and Transformer-based neural embeddings, trained on the kinematic observables of physics objects in LHC collision events. The learned embeddings serve as input representations for signal-agnostic statistical detection methods in inclusive final states. We achieve significant improvement in discovery power for both rare new physics signals and rare Standard Model processes across diverse final states, demonstrating its applicability for efficiently searching for diverse signals simultaneously. We study the impact of architectural choices, contrastive loss formulations, supervision levels, and embedding dimensionality on anomaly detection performance. We show that the optimal representation for background classification does not always maximize sensitivity to new physics signals, revealing an inherent trade-off between background structure preservation and anomaly enhancement. We demonstrate that combining compression with domain knowledge for label encoding produces the most effective data representation for statistical discovery of anomalies.",
          "authors": [
            "Kyle Metzger",
            "Lana Xu",
            "Mia Sodini",
            "Thea K. Arrestad",
            "Katya Govorkova",
            "Gaia Grosso",
            "Philip Harris"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2502.17721",
          "title": "Aligning Compound AI Systems via System-level DPO",
          "abstract": "Compound AI systems, comprising multiple interacting components such as LLMs, foundation models, and external tools, have demonstrated remarkable improvements compared to single models in various tasks. To ensure their effective deployment in real-world applications, aligning these systems with human preferences is crucial. However, aligning the compound system via policy optimization, unlike the alignment of a single model, is challenging for two main reasons: (i) non-differentiable interactions between components make end-to-end gradient-based optimization method inapplicable, and (ii) system-level preferences cannot be directly transformed into component-level preferences. To address these challenges, we first formulate compound AI systems as Directed Acyclic Graphs (DAGs), explicitly modeling both component interactions and the associated data flows. Building on this formulation, we introduce $\\textbf{SysDPO}$, a framework that extends Direct Preference Optimization (DPO) to enable joint system-level alignment. We propose two variants, SysDPO-Direct and SysDPO-Sampling, tailored for scenarios depending on whether we construct a system-specific preference dataset. We empirically demonstrate the effectiveness of our approach across two applications: the joint alignment of a language model and a diffusion model, and the joint alignment of an LLM collaboration system.",
          "authors": [
            "Xiangwen Wang",
            "Yibo Jacky Zhang",
            "Zhoujie Ding",
            "Katherine Tsai",
            "Haolun Wu",
            "Sanmi Koyejo"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.01822",
          "title": "Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry",
          "abstract": "Sparse Autoencoders (SAEs) are widely used to interpret neural networks by identifying meaningful concepts from their representations. However, do SAEs truly uncover all concepts a model relies on, or are they inherently biased toward certain kinds of concepts? We introduce a unified framework that recasts SAEs as solutions to a bilevel optimization problem, revealing a fundamental challenge: each SAE imposes structural assumptions about how concepts are encoded in model representations, which in turn shapes what it can and cannot detect. This means different SAEs are not interchangeable -- switching architectures can expose entirely new concepts or obscure existing ones. To systematically probe this effect, we evaluate SAEs across a spectrum of settings: from controlled toy models that isolate key variables, to semi-synthetic experiments on real model activations and finally to large-scale, naturalistic datasets. Across this progression, we examine two fundamental properties that real-world concepts often exhibit: heterogeneity in intrinsic dimensionality (some concepts are inherently low-dimensional, others are not) and nonlinear separability. We show that SAEs fail to recover concepts when these properties are ignored, and we design a new SAE that explicitly incorporates both, enabling the discovery of previously hidden concepts and reinforcing our theoretical insights. Our findings challenge the idea of a universal SAE and underscores the need for architecture-specific choices in model interpretability. Overall, we argue an SAE does not just reveal concepts -- it determines what can be seen at all.",
          "authors": [
            "Sai Sumedh R. Hindupur",
            "Ekdeep Singh Lubana",
            "Thomas Fel",
            "Demba Ba"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.02050",
          "title": "DYNEMO-SLAM: Dynamic Entity and Motion-Aware 3D Scene Graph SLAM",
          "abstract": "Robots operating in dynamic environments face significant challenges due to the presence of moving agents and displaced objects. Traditional SLAM systems typically assume a static world or treat dynamic as outliers, discarding their information to preserve map consistency. As a result, they cannot exploit dynamic entities as persistent landmarks, do not model and exploit their motion over time, and therefore quickly degrade in highly cluttered environments with few reliable static features. This paper presents a novel 3D scene graph-based SLAM framework that addresses the challenge of modeling and estimating the pose of dynamic entities into the SLAM backend. Our framework incorporates semantic motion priors and dynamic entity-aware constraints to jointly optimize the robot trajectory, dynamic entity poses, and the surrounding environment structure within a unified graph formulation. In parallel, a dynamic keyframe selection policy and a semantic loop-closure prefiltering step enable the system to remain robust and effective in highly dynamic environments by continuously adapting to scene changes and filtering inconsistent observations. The simulation and real-world experimental results show a 49.97% reduction in ATE compared to the baseline method employed, demonstrating the effectiveness of incorporating dynamic entities and estimating their poses for improved robustness and richer scene representation in complex scenarios while maintaining real-time performance.",
          "authors": [
            "Marco Giberna",
            "Muhammad Shaheer",
            "Miguel Fernandez-Cortizas",
            "Jose Andres Millan-Romera",
            "Jose Luis Sanchez-Lopez",
            "Holger Voos"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.03306",
          "title": "Modeling portfolio loss distribution under infectious defaults and immunization",
          "abstract": "We introduce a model for the loss distribution of a credit portfolio considering a contagion mechanism for the default of names which is the result of two independent components: an infection attempt generated by defaulting entities and a failed defence from healthy ones. We then propose an efficient recursive algorithm for the loss distribution. Then we extend the framework with more flexible distributions that integrate a contagion component and a systematic factor to better fit real-world data. Finally, we propose an empirical application in which we price synthetic CDO tranches of the iTraxx index, finding a good fit for multiple tranches.",
          "authors": [
            "Gabriele Torri",
            "Rosella Giacometti",
            "Gianluca Farina"
          ],
          "primary_category": "q-fin.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.04096",
          "title": "Image-Based Relocalization and Alignment for Long-Term Monitoring of Dynamic Underwater Environments",
          "abstract": "Effective monitoring of underwater ecosystems is crucial for tracking environmental changes, guiding conservation efforts, and ensuring long-term ecosystem health. However, automating underwater ecosystem management with robotic platforms remains challenging due to the complexities of underwater imagery, which pose significant difficulties for traditional visual localization methods. We propose an integrated pipeline that combines Visual Place Recognition (VPR), feature matching, and image segmentation on video-derived images. This method enables robust identification of revisited areas, estimation of rigid transformations, and downstream analysis of ecosystem changes. Furthermore, we introduce the SQUIDLE+ VPR Benchmark-the first large-scale underwater VPR benchmark designed to leverage an extensive collection of unstructured data from multiple robotic platforms, spanning time intervals from days to years. The dataset encompasses diverse trajectories, arbitrary overlap and diverse seafloor types captured under varying environmental conditions, including differences in depth, lighting, and turbidity. Our code is available at: this https URL",
          "authors": [
            "Beverley Gorry",
            "Tobias Fischer",
            "Michael Milford",
            "Alejandro Fontan"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.07561",
          "title": "Alligat0R: Pre-Training Through Co-Visibility Segmentation for Relative Camera Pose Regression",
          "abstract": "Pre-training techniques have greatly advanced computer vision, with CroCo's cross-view completion approach yielding impressive results in tasks like 3D reconstruction and pose regression. However, cross-view completion is ill-posed in non-covisible regions, limiting its effectiveness. We introduce Alligat0R, a novel pre-training approach that replaces cross-view learning with a covisibility segmentation task. Our method predicts whether each pixel in one image is covisible in the second image, occluded, or outside the field of view, making the pre-training effective in both covisible and non-covisible regions, and provides interpretable predictions. To support this, we present Cub3, a large-scale dataset with 5M image pairs and dense covisibility annotations derived from the nuScenes and ScanNet datasets. Cub3 includes diverse scenarios with varying degrees of overlap. The experiments show that our novel pre-training method Alligat0R significantly outperforms CroCo in relative pose regression. Code is available at this https URL .",
          "authors": [
            "Thibaut Loiseau",
            "Guillaume Bourmaud",
            "Vincent Lepetit"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.07675",
          "title": "DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems",
          "abstract": "The emergence of Large Language Models (LLMs) in Multi-Agent Systems (MAS) has opened new possibilities for artificial intelligence, yet current implementations face significant challenges in resource management, task coordination, and system efficiency. While existing frameworks demonstrate the potential of LLM-based agents in collaborative problem-solving, they often lack sophisticated mechanisms for parallel execution and dynamic task management. This paper introduces DynTaskMAS, a novel framework that orchestrates asynchronous and parallel operations in LLM-based MAS through dynamic task graphs. The framework features four key innovations: (1) a Dynamic Task Graph Generator that intelligently decomposes complex tasks while maintaining logical dependencies, (2) an Asynchronous Parallel Execution Engine that optimizes resource utilization through efficient task scheduling, (3) a Semantic-Aware Context Management System that enables efficient information sharing among agents, and (4) an Adaptive Workflow Manager that dynamically optimizes system performance. Experimental evaluations demonstrate that DynTaskMAS achieves significant improvements over traditional approaches: a 21-33% reduction in execution time across task complexities (with higher gains for more complex tasks), a 35.4% improvement in resource utilization (from 65% to 88%), and near-linear throughput scaling up to 16 concurrent agents (3.47X improvement for 4X agents). Our framework establishes a foundation for building scalable, high-performance LLM-based multi-agent systems capable of handling complex, dynamic tasks efficiently.",
          "authors": [
            "Junwei Yu",
            "Yepeng Ding",
            "Hiroyuki Sato"
          ],
          "primary_category": "cs.MA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.08096",
          "title": "MegaSR: Mining Customized Semantics and Expressive Guidance for Real-World Image Super-Resolution",
          "abstract": "Text-to-image (T2I) models have ushered in a new era of real-world image super-resolution (Real-ISR) due to their rich internal implicit knowledge for multimodal learning. Although bringing high-level semantic priors and dense pixel guidance have led to advances in reconstruction, we identified several critical phenomena by analyzing the behavior of existing T2I-based Real-ISR methods: (1) Fine detail deficiency, which ultimately leads to incorrect reconstruction in local regions. (2) Block-wise semantic inconsistency, which results in distracted semantic interpretations across U-Net blocks. (3) Edge ambiguity, which causes noticeable structural degradation. Building upon these observations, we first introduce MegaSR, which enhances the T2I-based Real-ISR models with fine-grained customized semantics and expressive guidance to unlock semantically rich and structurally consistent reconstruction. Then, we propose the Customized Semantics Module (CSM) to supplement fine-grained semantics from the image modality and regulate the semantic fusion between multi-level knowledge to realize customization for different U-Net blocks. Besides the semantic adaptation, we identify expressive multimodal signals through pair-wise comparisons and introduce the Multimodal Signal Fusion Module (MSFM) to aggregate them for structurally consistent reconstruction. Extensive experiments on real-world and synthetic datasets demonstrate the superiority of the method. Notably, it not only achieves state-of-the-art performance on quality-driven metrics but also remains competitive on fidelity-focused metrics, striking a balance between perceptual realism and faithful content reconstruction.",
          "authors": [
            "Xinrui Li",
            "Jinrong Zhang",
            "Jianlong Wu",
            "Chong Chen",
            "Liqiang Nie",
            "Zhouchen Lin"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.14537",
          "title": "Learning-based 3D Reconstruction in Autonomous Driving: A Comprehensive Survey",
          "abstract": "Learning-based 3D reconstruction has emerged as a transformative technique in autonomous driving, enabling precise modeling of environments through advanced neural representations. It has inspired pioneering solutions for vital tasks in autonomous driving, such as dense mapping and closed-loop simulation, as well as comprehensive scene feature for driving scene understanding and reasoning. Given the rapid growth in related research, this survey provides a comprehensive review of both technical evolutions and practical applications in autonomous driving. We begin with an introduction to the preliminaries of learning-based 3D reconstruction to provide a solid technical background foundation, then progress to a rigorous, multi-dimensional examination of cutting-edge methodologies, systematically organized according to the distinctive technical requirements and fundamental challenges of autonomous driving. Through analyzing and summarizing development trends and cutting-edge research, we identify existing technical challenges, along with insufficient disclosure of on-board validation and safety verification details in the current literature, and ultimately suggest potential directions to guide future studies.",
          "authors": [
            "Liewen Liao",
            "Weihao Yan",
            "Wang Xu",
            "Ming Yang",
            "Songan Zhang",
            "H. Eric Tseng"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.15450",
          "title": "SkyLadder: Better and Faster Pretraining via Context Window Scheduling",
          "abstract": "Recent advancements in LLM pretraining have featured ever-expanding context windows to process longer sequences. However, our pilot study reveals that models pretrained with shorter context windows consistently outperform their long-context counterparts under a fixed token budget. This finding motivates us to explore an optimal context window scheduling strategy to better balance long-context capability with pretraining efficiency. To this end, we propose SkyLadder, a simple yet effective approach that implements a short-to-long context window transition. SkyLadder preserves strong standard benchmark performance, while matching or exceeding baseline results on long context tasks. Through extensive experiments, we pre-train 1B-parameter models (up to 32K context) and 3B-parameter models (8K context) on 100B tokens, demonstrating that SkyLadder yields consistent gains of up to 3.7% on common benchmarks, while achieving up to 22% faster training speeds compared to baselines. The code is at this https URL .",
          "authors": [
            "Tongyao Zhu",
            "Qian Liu",
            "Haonan Wang",
            "Shiqi Chen",
            "Xiangming Gu",
            "Tianyu Pang",
            "Min-Yen Kan"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.15568",
          "title": "Mixed precision accumulation for neural network inference guided by componentwise forward error analysis",
          "abstract": "This work proposes a mathematically founded mixed precision accumulation strategy for the inference of neural networks. Our strategy is based on a new componentwise forward error analysis that explains the propagation of errors in the forward pass of neural networks. Specifically, our analysis shows that the error in each component of the output of a linear layer is proportional to the condition number of the inner product between the weights and the input, multiplied by the condition number of the activation function. These condition numbers can vary widely from one component to the other, thus creating a significant opportunity to introduce mixed precision: each component should be accumulated in a precision inversely proportional to the product of these condition numbers. We propose a numerical algorithm that exploits this observation: it first computes all components in low precision, uses this output to estimate the condition numbers, and recomputes in higher precision only the components associated with large condition numbers. We test our algorithm on various networks and datasets and confirm experimentally that it can significantly improve the cost--accuracy tradeoff compared with uniform precision accumulation baselines.",
          "authors": [
            "El-Mehdi El Arar",
            "Silviu-Ioan Filip",
            "Theo Mary",
            "Elisa Riccietti"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.15568",
          "title": "Mixed precision accumulation for neural network inference guided by componentwise forward error analysis",
          "abstract": "This work proposes a mathematically founded mixed precision accumulation strategy for the inference of neural networks. Our strategy is based on a new componentwise forward error analysis that explains the propagation of errors in the forward pass of neural networks. Specifically, our analysis shows that the error in each component of the output of a linear layer is proportional to the condition number of the inner product between the weights and the input, multiplied by the condition number of the activation function. These condition numbers can vary widely from one component to the other, thus creating a significant opportunity to introduce mixed precision: each component should be accumulated in a precision inversely proportional to the product of these condition numbers. We propose a numerical algorithm that exploits this observation: it first computes all components in low precision, uses this output to estimate the condition numbers, and recomputes in higher precision only the components associated with large condition numbers. We test our algorithm on various networks and datasets and confirm experimentally that it can significantly improve the cost--accuracy tradeoff compared with uniform precision accumulation baselines.",
          "authors": [
            "El-Mehdi El Arar",
            "Silviu-Ioan Filip",
            "Theo Mary",
            "Elisa Riccietti"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.18259",
          "title": "Rough Heston model as the scaling limit of bivariate cumulative heavy-tailed INAR processes: Weak-error bounds and option pricing",
          "abstract": "This paper links nearly unstable, heavy-tailed \\emph{bivariate cumulative} INAR($\\infty$) processes to the rough Heston model via a discrete scaling limit, extending scaling-limit techniques beyond Hawkes processes and providing a microstructural mechanism for rough volatility and leverage effect. Computationally, we simulate the \\emph{approximating INAR($\\infty$)} sequence rather than discretizing the Volterra SDE, and implement the long-memory convolution with a \\emph{divide-and-conquer FFT} (CDQ) that reuses past transforms, yielding an efficient Monte Carlo engine for \\emph{European options} and \\emph{path-dependent options} (Asian, lookback, barrier). We further derive finite-horizon \\emph{weak-error bounds} for option pricing under our microstructural approximation. Numerical experiments show tight confidence intervals with improved efficiency; as $\\alpha \\to 1$, results align with the classical Heston benchmark, where $\\alpha$ is the roughness specification. Using the simulator, we also study the \\emph{implied-volatility surface}: the roughness specification ($\\alpha<1$) reproduces key empirical features -- most notably the steep short-maturity ATM skew with power-law decay -- whereas the classical model produces a much flatter skew.",
          "authors": [
            "Yingli Wang",
            "Zhenyu Cui",
            "Lingjiong Zhu"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2503.18259",
          "title": "Rough Heston model as the scaling limit of bivariate cumulative heavy-tailed INAR processes: Weak-error bounds and option pricing",
          "abstract": "This paper links nearly unstable, heavy-tailed \\emph{bivariate cumulative} INAR($\\infty$) processes to the rough Heston model via a discrete scaling limit, extending scaling-limit techniques beyond Hawkes processes and providing a microstructural mechanism for rough volatility and leverage effect. Computationally, we simulate the \\emph{approximating INAR($\\infty$)} sequence rather than discretizing the Volterra SDE, and implement the long-memory convolution with a \\emph{divide-and-conquer FFT} (CDQ) that reuses past transforms, yielding an efficient Monte Carlo engine for \\emph{European options} and \\emph{path-dependent options} (Asian, lookback, barrier). We further derive finite-horizon \\emph{weak-error bounds} for option pricing under our microstructural approximation. Numerical experiments show tight confidence intervals with improved efficiency; as $\\alpha \\to 1$, results align with the classical Heston benchmark, where $\\alpha$ is the roughness specification. Using the simulator, we also study the \\emph{implied-volatility surface}: the roughness specification ($\\alpha<1$) reproduces key empirical features -- most notably the steep short-maturity ATM skew with power-law decay -- whereas the classical model produces a much flatter skew.",
          "authors": [
            "Yingli Wang",
            "Zhenyu Cui",
            "Lingjiong Zhu"
          ],
          "primary_category": "math.PR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.01407",
          "title": "TimeSearch: Hierarchical Video Search with Spotlight and Reflection for Human-like Long Video Understanding",
          "abstract": "Large video-language models (LVLMs) have shown remarkable performance across various video-language tasks. However, they encounter significant challenges when processing long videos because of the large number of video frames involved. Downsampling long videos in either space or time can lead to visual hallucinations, making it difficult to accurately interpret long videos. Motivated by human hierarchical temporal search strategies, we propose \\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videos in a human-like manner. TimeSearch integrates two human-like primitives into a unified autoregressive LVLM: 1) \\textbf{Spotlight} efficiently identifies relevant temporal events through a Temporal-Augmented Frame Representation (TAFR), explicitly binding visual features with timestamps; 2) \\textbf{Reflection} evaluates the correctness of the identified events, leveraging the inherent temporal self-reflection capabilities of LVLMs. TimeSearch progressively explores key events and prioritizes temporal search based on reflection confidence. Extensive experiments on challenging long-video benchmarks confirm that TimeSearch substantially surpasses previous state-of-the-art, improving the accuracy from 41.8\\% to 51.5\\% on the LVBench. Additionally, experiments on temporal grounding demonstrate that appropriate TAFR is adequate to effectively stimulate the surprising temporal grounding ability of LVLMs in a simpler yet versatile manner, which improves mIoU on Charades-STA by 11.8\\%. The code will be released.",
          "authors": [
            "Junwen Pan",
            "Rui Zhang",
            "Xin Wan",
            "Yuan Zhang",
            "Ming Lu",
            "Qi She"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.04634",
          "title": "Walk Before You Dance: High-fidelity and Editable Dance Synthesis via Generative Masked Motion Prior",
          "abstract": "Recent advances in dance generation have enabled the automatic synthesis of 3D dance motions. However, existing methods still face significant challenges in simultaneously achieving high realism, precise dance-music synchronization, diverse motion expression, and physical plausibility. To address these limitations, we propose a novel approach that leverages a generative masked text-to-motion model as a distribution prior to learn a probabilistic mapping from diverse guidance signals, including music, genre, and pose, into high-quality dance motion sequences. Our framework also supports semantic motion editing, such as motion inpainting and body part modification. Specifically, we introduce a multi-tower masked motion model that integrates a text-conditioned masked motion backbone with two parallel, modality-specific branches: a music-guidance tower and a pose-guidance tower. The model is trained using synchronized and progressive masked training, which allows effective infusion of the pretrained text-to-motion prior into the dance synthesis process while enabling each guidance branch to optimize independently through its own loss function, mitigating gradient interference. During inference, we introduce classifier-free logits guidance and pose-guided token optimization to strengthen the influence of music, genre, and pose signals. Extensive experiments demonstrate that our method sets a new state of the art in dance generation, significantly advancing both the quality and editability over existing approaches. Project Page available at this https URL",
          "authors": [
            "Foram N Shah",
            "Parshwa Shah",
            "Muhammad Usama Saleem",
            "Ekkasit Pinyoanuntapong",
            "Pu Wang",
            "Hongfei Xue",
            "Ahmed Helmy"
          ],
          "primary_category": "cs.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.05627",
          "title": "Maternal and Fetal Health Status Assessment by Using Machine Learning on Optical 3D Body Scans",
          "abstract": "Monitoring maternal and fetal health during pregnancy is crucial for preventing adverse outcomes. While tests such as ultrasound scans offer high accuracy, they can be costly and inconvenient. Telehealth and more accessible body shape information provide pregnant women with a convenient way to monitor their health. This study explores the potential of 3D body scan data, captured during the 18-24 gestational weeks, to predict adverse pregnancy outcomes and estimate clinical parameters. We developed a novel algorithm with two parallel streams which are used for extract body shape features: one for supervised learning to extract sequential abdominal circumference information, and another for unsupervised learning to extract global shape descriptors, alongside a branch for demographic data. Our results indicate that 3D body shape can assist in predicting preterm labor, gestational diabetes mellitus (GDM), gestational hypertension (GH), and in estimating fetal weight. Compared to other machine learning models, our algorithm achieved the best performance, with prediction accuracies exceeding 88% and fetal weight estimation accuracy of 76.74% within a 10% error margin, outperforming conventional anthropometric methods by 22.22%.",
          "authors": [
            "Ruting Cheng",
            "Yijiang Zheng",
            "Boyuan Feng",
            "Chuhui Qiu",
            "Zhuoxin Long",
            "Joaquin A. Calderon",
            "Xiaoke Zhang",
            "Jaclyn M.Phillips",
            "James K. Hahn"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.07646",
          "title": "On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data",
          "abstract": "The applicability of Large Language Models (LLMs) in temporal reasoning tasks over data that is not present during training is still a field that remains to be explored. In this paper we work on this topic, focusing on structured and semi-structured anonymized data. We not only develop a direct LLM pipeline, but also compare various methodologies and conduct an in-depth analysis. We identified and examined seventeen common temporal reasoning tasks in natural language, focusing on their algorithmic components. To assess LLM performance, we created the \\textit{Reasoning and Answering Temporal Ability} dataset (RATA), featuring semi-structured anonymized data to ensure reliance on reasoning rather than on prior knowledge. We compared several methodologies, involving SoTA techniques such as Tree-of-Thought, self-reflexion and code execution, tuned specifically for this scenario. Our results suggest that achieving scalable and reliable solutions requires more than just standalone LLMs, highlighting the need for integrated approaches.",
          "authors": [
            "Alfredo Garrachón Ruiz",
            "Tomás de la Rosa",
            "Daniel Borrajo"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.07958",
          "title": "Detect Anything 3D in the Wild",
          "abstract": "Despite the success of deep learning in close-set 3D object detection, existing approaches struggle with zero-shot generalization to novel objects and camera configurations. We introduce DetAny3D, a promptable 3D detection foundation model capable of detecting any novel object under arbitrary camera configurations using only monocular inputs. Training a foundation model for 3D detection is fundamentally constrained by the limited availability of annotated 3D data, which motivates DetAny3D to leverage the rich prior knowledge embedded in extensively pre-trained 2D foundation models to compensate for this scarcity. To effectively transfer 2D knowledge to 3D, DetAny3D incorporates two core modules: the 2D Aggregator, which aligns features from different 2D foundation models, and the 3D Interpreter with Zero-Embedding Mapping, which stabilizes early training in 2D-to-3D knowledge transfer. Experimental results validate the strong generalization of our DetAny3D, which not only achieves state-of-the-art performance on unseen categories and novel camera configurations, but also surpasses most competitors on in-domain data. DetAny3D sheds light on the potential of the 3D foundation model for diverse applications in real-world scenarios, e.g., rare object detection in autonomous driving, and demonstrates promise for further exploration of 3D-centric tasks in open-world settings. More visualization results can be found at our code repository.",
          "authors": [
            "Hanxue Zhang",
            "Haoran Jiang",
            "Qingsong Yao",
            "Yanan Sun",
            "Renrui Zhang",
            "Hao Zhao",
            "Hongyang Li",
            "Hongzi Zhu",
            "Zetong Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.09843",
          "title": "ST-Booster: An Iterative SpatioTemporal Perception Booster for Vision-and-Language Navigation in Continuous Environments",
          "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires agents to navigate unknown, continuous spaces based on natural language instructions. Compared to discrete settings, VLN-CE poses two core perception challenges. First, the absence of predefined observation points leads to heterogeneous visual memories and weakened global spatial correlations. Second, cumulative reconstruction errors in three-dimensional scenes introduce structural noise, impairing local feature perception. To address these challenges, this paper proposes ST-Booster, an iterative spatiotemporal booster that enhances navigation performance through multi-granularity perception and instruction-aware reasoning. ST-Booster consists of three key modules -- Hierarchical SpatioTemporal Encoding (HSTE), Multi-Granularity Aligned Fusion (MGAF), and ValueGuided Waypoint Generation (VGWG). HSTE encodes long-term global memory using topological graphs and captures shortterm local details via grid maps. MGAF aligns these dualmap representations with instructions through geometry-aware knowledge fusion. The resulting representations are iteratively refined through pretraining tasks. During reasoning, VGWG generates Guided Attention Heatmaps (GAHs) to explicitly model environment-instruction relevance and optimize waypoint selection. Extensive comparative experiments and performance analyses are conducted, demonstrating that ST-Booster outperforms existing state-of-the-art methods, particularly in complex, disturbance-prone environments.",
          "authors": [
            "Lu Yue",
            "Dongliang Zhou",
            "Liang Xie",
            "Erwei Yin",
            "Feitian Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.12369",
          "title": "WorldMem: Long-term Consistent World Simulation with Memory",
          "abstract": "World simulation has gained increasing popularity due to its ability to model virtual environments and predict the consequences of actions. However, the limited temporal context window often leads to failures in maintaining long-term consistency, particularly in preserving 3D spatial consistency. In this work, we present WorldMem, a framework that enhances scene generation with a memory bank consisting of memory units that store memory frames and states (e.g., poses and timestamps). By employing a memory attention mechanism that effectively extracts relevant information from these memory frames based on their states, our method is capable of accurately reconstructing previously observed scenes, even under significant viewpoint or temporal gaps. Furthermore, by incorporating timestamps into the states, our framework not only models a static world but also captures its dynamic evolution over time, enabling both perception and interaction within the simulated world. Extensive experiments in both virtual and real scenarios validate the effectiveness of our approach.",
          "authors": [
            "Zeqi Xiao",
            "Yushi Lan",
            "Yifan Zhou",
            "Wenqi Ouyang",
            "Shuai Yang",
            "Yanhong Zeng",
            "Xingang Pan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.13375",
          "title": "Pricing AI Model Accuracy",
          "abstract": "This paper examines the market for AI models in which firms compete to provide accurate model predictions and consumers exhibit heterogeneous preferences for model accuracy. We develop a consumer-firm duopoly model to analyze how competition affects firms' incentives to improve model accuracy. Each firm aims to minimize its model's error, but this choice can often be suboptimal. Counterintuitively, we find that in a competitive market, firms that improve overall accuracy do not necessarily improve their profits. Rather, each firm's optimal decision is to invest further on the error dimension where it has a competitive advantage. By decomposing model errors into false positive and false negative rates, firms can reduce errors in each dimension through investments. Firms are strictly better off investing on their superior dimension and strictly worse off with investments on their inferior dimension. Profitable investments adversely affect consumers but increase overall welfare.",
          "authors": [
            "Nikhil Kumar"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.13375",
          "title": "Pricing AI Model Accuracy",
          "abstract": "This paper examines the market for AI models in which firms compete to provide accurate model predictions and consumers exhibit heterogeneous preferences for model accuracy. We develop a consumer-firm duopoly model to analyze how competition affects firms' incentives to improve model accuracy. Each firm aims to minimize its model's error, but this choice can often be suboptimal. Counterintuitively, we find that in a competitive market, firms that improve overall accuracy do not necessarily improve their profits. Rather, each firm's optimal decision is to invest further on the error dimension where it has a competitive advantage. By decomposing model errors into false positive and false negative rates, firms can reduce errors in each dimension through investments. Firms are strictly better off investing on their superior dimension and strictly worse off with investments on their inferior dimension. Profitable investments adversely affect consumers but increase overall welfare.",
          "authors": [
            "Nikhil Kumar"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.15051",
          "title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks",
          "abstract": "Activation functions play a critical role in deep neural networks by shaping gradient flow, optimization stability, and generalization. While ReLU remains widely used due to its simplicity, it suffers from gradient sparsity and dead-neuron issues and offers no adaptivity to input statistics. Smooth alternatives such as Swish and GELU improve gradient propagation but still apply a fixed transformation regardless of the activation distribution. In this paper, we propose VeLU, a Variance-enhanced Learning Unit that introduces variance-aware and distributionally aligned nonlinearity through a principled combination of ArcTan-ArcSin transformations, adaptive scaling, and Wasserstein-2 regularization (Optimal Transport). This design enables VeLU to modulate its response based on local activation variance, mitigate internal covariate shift at the activation level, and improve training stability without adding learnable parameters or architectural overhead. Extensive experiments across six deep neural networks show that VeLU outperforms ReLU, ReLU6, Swish, and GELU on 12 vision benchmarks. The implementation of VeLU is publicly available in GitHub.",
          "authors": [
            "Ashkan Shakarami",
            "Yousef Yeganeh",
            "Azade Farshad",
            "Lorenzo Nicolè",
            "Stefano Ghidoni",
            "Nassir Navab"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.19602",
          "title": "Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation",
          "abstract": "Federated Learning (FL) enables collaborative model training across decentralized clients, enhancing privacy by keeping data local. Yet conventional FL, relying on frequent parameter-sharing, suffers from high communication overhead and limited model heterogeneity. Distillation-based FL approaches address these issues by sharing predictions (soft-labels, i.e., normalized probability distributions) instead, but they often involve redundant transmissions across communication rounds, reducing efficiency. We propose SCARLET, a novel framework integrating synchronized soft-label caching and an enhanced Entropy Reduction Aggregation (Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing cached soft-labels, achieving up to 50% reduction in communication costs compared to existing methods while maintaining competitive accuracy. Enhanced ERA resolves the fundamental instability of conventional temperature-based aggregation, ensuring robust control and high performance in diverse client scenarios. Experimental evaluations demonstrate that SCARLET consistently outperforms state-of-the-art distillation-based FL methods in terms of accuracy and communication efficiency. The implementation of SCARLET is publicly available at this https URL .",
          "authors": [
            "Kitsuya Azuma",
            "Takayuki Nishio",
            "Yuichi Kitagawa",
            "Wakako Nakano",
            "Takahito Tanimura"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2504.21370",
          "title": "ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning",
          "abstract": "Recent models such as OpenAI o1 and DeepSeek-R1 have demonstrated strong performance on reasoning-intensive tasks by generating extended Chain-of-Thought (CoT) traces. While longer reasoning helps with thorough exploration of solution paths for complex problems, it also often leads to inefficient and redundant outputs--a phenomenon commonly described as overthinking. In this paper, we propose ShorterBetter, a simple yet effective reinforcement learning method that enables reasoning models to learn their own optimal CoT lengths without manual supervision. We define the Sample Optimal Length (SOL) as the length of the shortest correct response among multiple generations, which serves as a dynamic reward signal to guide the model toward efficient reasoning. Applied to DeepSeek-Distill-Qwen-1.5B/7B as base models, ShorterBetter achieves 50%-80% reduction in output lengths in both in-domain and out-of-domain reasoning tasks while maintaining accuracy. Our reasoning trace analysis shows that ShorterBetter refines the structure of the reasoning traces by reducing unnecessary repetition, excessive self-verification, and over-exploration of alternatives.",
          "authors": [
            "Jingyang Yi",
            "Jiazheng Wang",
            "Sida Li"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.01346",
          "title": "How to Learn a Star: Binary Classification with Starshaped Polyhedral Sets",
          "abstract": "We consider binary classification restricted to a class of continuous piecewise linear functions whose decision boundaries are (possibly nonconvex) starshaped polyhedral sets, supported on a fixed polyhedral simplicial fan. We investigate the expressivity of these function classes and describe the combinatorial and geometric structure of the loss landscape, most prominently the sublevel sets, for two loss-functions: the 0/1-loss (discrete loss) and a log-likelihood loss function. In particular, we give explicit bounds on the VC dimension of this model, and concretely describe the sublevel sets of the discrete loss as chambers in a hyperplane arrangement. For the log-likelihood loss, we give sufficient conditions for the optimum to be unique, and describe the geometry of the optimum when varying the rate parameter of the underlying exponential probability distribution.",
          "authors": [
            "Marie-Charlotte Brandenburg",
            "Katharina Jochemko"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.01346",
          "title": "How to Learn a Star: Binary Classification with Starshaped Polyhedral Sets",
          "abstract": "We consider binary classification restricted to a class of continuous piecewise linear functions whose decision boundaries are (possibly nonconvex) starshaped polyhedral sets, supported on a fixed polyhedral simplicial fan. We investigate the expressivity of these function classes and describe the combinatorial and geometric structure of the loss landscape, most prominently the sublevel sets, for two loss-functions: the 0/1-loss (discrete loss) and a log-likelihood loss function. In particular, we give explicit bounds on the VC dimension of this model, and concretely describe the sublevel sets of the discrete loss as chambers in a hyperplane arrangement. For the log-likelihood loss, we give sufficient conditions for the optimum to be unique, and describe the geometry of the optimum when varying the rate parameter of the underlying exponential probability distribution.",
          "authors": [
            "Marie-Charlotte Brandenburg",
            "Katharina Jochemko"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.05767",
          "title": "Model-based calibration of gear-specific fish abundance survey data as a change-of-support problem",
          "abstract": "For commercial and recreational fisheries of a wide-ranging species to be sustainable, abundance studies from neighboring regions should be unified. For the first time in the USA, a single research project to estimate the abundance of the Greater Amberjack {Seriola dumerili) is being undertaken at the continental scale. A major methodological challenge lies in 1) the difference in fish detection gears deployed by regional survey teams that produce gear-specific relative abundance indices, and 2) the unknown relationship between actual abundance and these indices. In this paper, we develop a conversion tool that is operationalized from a Bayesian hierarchical model in an inferential context akin to the change-of-support problem often encountered in large-scale spatial studies; though, the context here is to reconcile abundance data observed at various gear-specific scales. To this end, we consider a small calibration experiment in which 2 to 4 different underwater video camera types were simultaneously deployed on each of 21 boat trips. Alongside the suite of deployed cameras was also an acoustic echosounder that recorded fish signals along surrounding transects. Our modeling framework is used to derive calibration formulae for translating camera-specific relative indices to the actual abundance scale in surveys that deploy a single camera. Cross-validation is conducted using mark-recapture abundance estimates (only available for 10 trips, all observed at a single habitat type) and through a separate simulation study. We also briefly discuss the case when surveys pair one camera with the echosounder.",
          "authors": [
            "Grace S. Chiu",
            "Anton H. Westveld",
            "Mark A. Albins",
            "Kevin M. Boswell",
            "John M. Hoenig",
            "Sean P. Powers",
            "S. Lynne Stokes",
            "Allison L. White"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.05767",
          "title": "Model-based calibration of gear-specific fish abundance survey data as a change-of-support problem",
          "abstract": "For commercial and recreational fisheries of a wide-ranging species to be sustainable, abundance studies from neighboring regions should be unified. For the first time in the USA, a single research project to estimate the abundance of the Greater Amberjack {Seriola dumerili) is being undertaken at the continental scale. A major methodological challenge lies in 1) the difference in fish detection gears deployed by regional survey teams that produce gear-specific relative abundance indices, and 2) the unknown relationship between actual abundance and these indices. In this paper, we develop a conversion tool that is operationalized from a Bayesian hierarchical model in an inferential context akin to the change-of-support problem often encountered in large-scale spatial studies; though, the context here is to reconcile abundance data observed at various gear-specific scales. To this end, we consider a small calibration experiment in which 2 to 4 different underwater video camera types were simultaneously deployed on each of 21 boat trips. Alongside the suite of deployed cameras was also an acoustic echosounder that recorded fish signals along surrounding transects. Our modeling framework is used to derive calibration formulae for translating camera-specific relative indices to the actual abundance scale in surveys that deploy a single camera. Cross-validation is conducted using mark-recapture abundance estimates (only available for 10 trips, all observed at a single habitat type) and through a separate simulation study. We also briefly discuss the case when surveys pair one camera with the echosounder.",
          "authors": [
            "Grace S. Chiu",
            "Anton H. Westveld",
            "Mark A. Albins",
            "Kevin M. Boswell",
            "John M. Hoenig",
            "Sean P. Powers",
            "S. Lynne Stokes",
            "Allison L. White"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.07409",
          "title": "Computational Fact-Checking of Online Discourse: Scoring scientific accuracy in climate change related news articles",
          "abstract": "Democratic societies need reliable information. Misinformation in popular media, such as news articles or videos, threatens to impair civic discourse. Citizens are, unfortunately, not equipped to verify the flood of content consumed daily at increasing rates. This work aims to quantify the scientific accuracy of online media semi-automatically. We investigate the state of the art of climate-related ground truth knowledge representation. By semantifying media content of unknown veracity, their statements can be compared against these ground truth knowledge graphs. We implemented a workflow using LLM-based statement extraction and knowledge graph analysis. Our implementation can streamline content processing towards state-of-the-art knowledge representation and veracity quantification. Developed and evaluated with the help of 27 experts and detailed interviews with 10, the tool evidently provides a beneficial veracity indication. These findings are supported by 43 anonymous participants from a parallel user survey. This initial step, however, is unable to annotate public media at the required granularity and scale. Additionally, the identified state of climate change knowledge graphs is vastly insufficient to support this neurosymbolic fact-checking approach. Further work towards a FAIR (Findable, Accessible, Interoperable, Reusable) ground truth and complementary metrics is required to support civic discourse scientifically.",
          "authors": [
            "Tim Wittenborg",
            "Constantin Sebastian Tremel",
            "Markus Stocker",
            "Sören Auer"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.11275",
          "title": "TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs",
          "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) have significantly enhanced the ability of artificial intelligence systems to understand and generate multimodal content. However, these models often exhibit limited effectiveness when applied to non-Western cultural contexts, which raises concerns about their wider applicability. To address this limitation, we propose the Traditional Chinese Culture understanding Benchmark (TCC-Bench), a bilingual (i.e., Chinese and English) Visual Question Answering (VQA) benchmark specifically designed for assessing the understanding of traditional Chinese culture by MLLMs. TCC-Bench comprises culturally rich and visually diverse data, incorporating images from museum artifacts, everyday life scenes, comics, and other culturally significant contexts. We adopt a semi-automated pipeline that utilizes GPT-4o in text-only mode to generate candidate questions, followed by human curation to ensure data quality and avoid potential data leakage. The benchmark also avoids language bias by preventing direct disclosure of cultural concepts within question texts. Experimental evaluations across a wide range of MLLMs demonstrate that current models still face significant challenges when reasoning about culturally grounded visual content. The results highlight the need for further research in developing culturally inclusive and context-aware multimodal systems. The code and data can be found at: this https URL .",
          "authors": [
            "Pengju Xu",
            "Yan Wang",
            "Shuyuan Zhang",
            "Xuan Zhou",
            "Xin Li",
            "Yue Yuan",
            "Fengzhao Li",
            "Shunyuan Zhou",
            "Xingyu Wang",
            "Yi Zhang",
            "Haiying Zhao"
          ],
          "primary_category": "cs.MM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.11856",
          "title": "Telco-oRAG: Optimizing Retrieval-augmented Generation for Telecom Queries via Hybrid Retrieval and Neural Routing",
          "abstract": "Artificial intelligence will be one of the key pillars of the next generation of mobile networks (6G), as it is expected to provide novel added-value services and improve network performance. In this context, large language models have the potential to revolutionize the telecom landscape through intent comprehension, intelligent knowledge retrieval, coding proficiency, and cross-domain orchestration capabilities. This paper presents Telco-oRAG, an open-source Retrieval-Augmented Generation (RAG) framework optimized for answering technical questions in the telecommunications domain, with a particular focus on 3GPP standards. Telco-oRAG introduces a hybrid retrieval strategy that combines 3GPP domain-specific retrieval with web search, supported by glossary-enhanced query refinement and a neural router for memory-efficient retrieval. Our results show that Telco-oRAG improves the accuracy in answering 3GPP-related questions by up to 17.6% and achieves a 10.6% improvement in lexicon queries compared to baselines. Furthermore, Telco-oRAG reduces memory usage by 45% through targeted retrieval of relevant 3GPP series compared to baseline RAG, and enables open-source LLMs to reach GPT-4-level accuracy on telecom benchmarks.",
          "authors": [
            "Andrei-Laurentiu Bornea",
            "Fadhel Ayed",
            "Antonio De Domenico",
            "Nicola Piovesan",
            "Tareq Si Salem",
            "Ali Maatouk"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.12653",
          "title": "High-dimensional structure underlying individual differences in naturalistic visual experience",
          "abstract": "How do different brains create unique visual experiences from identical sensory input? While neural representations vary across individuals, the fundamental architecture underlying these differences remains poorly understood. Here, we reveal that individual visual experience emerges from a high-dimensional neural geometry across the visual cortical hierarchy. Using spectral decomposition of fMRI responses during naturalistic movie viewing, we find that idiosyncratic neural patterns persist across multiple orders of magnitude of latent dimensions. Remarkably, each dimensional range encodes qualitatively distinct aspects of individual processing, and this multidimensional neural geometry predicts subsequent behavioral differences in memory recall. These fine-grained patterns of inter-individual variability cannot be reduced to those detected by conventional intersubject correlation measures. Our findings demonstrate that subjective visual experience arises from information integrated across an expansive multidimensional manifold. This geometric framework offers a powerful new lens for understanding how diverse brains construct unique perceptual worlds from shared experiences.",
          "authors": [
            "Chihye Han",
            "Michael F. Bonner"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.13431",
          "title": "A Practical Guide for Incorporating Symmetry in Diffusion Policy",
          "abstract": "Recently, equivariant neural networks for policy learning have shown promising improvements in sample efficiency and generalization, however, their wide adoption faces substantial barriers due to implementation complexity. Equivariant architectures typically require specialized mathematical formulations and custom network design, posing significant challenges when integrating with modern policy frameworks like diffusion-based models. In this paper, we explore a number of straightforward and practical approaches to incorporate symmetry benefits into diffusion policies without the overhead of full equivariant designs. Specifically, we investigate (i) invariant representations via relative trajectory actions and eye-in-hand perception, (ii) integrating equivariant vision encoders, and (iii) symmetric feature extraction with pretrained encoders using Frame Averaging. We first prove that combining eye-in-hand perception with relative or delta action parameterization yields inherent SE(3)-invariance, thus improving policy generalization. We then perform a systematic experimental study on those design choices for integrating symmetry in diffusion policies, and conclude that an invariant representation with equivariant feature extraction significantly improves the policy performance. Our method achieves performance on par with or exceeding fully equivariant architectures while greatly simplifying implementation.",
          "authors": [
            "Dian Wang",
            "Boce Hu",
            "Shuran Song",
            "Robin Walters",
            "Robert Platt"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.13514",
          "title": "Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models",
          "abstract": "Repetition curse is a phenomenon where Large Language Models (LLMs) generate repetitive sequences of tokens or cyclic sequences. While the repetition curse has been widely observed, its underlying mechanisms remain poorly understood. In this work, we investigate the role of induction heads--a specific type of attention head known for their ability to perform in-context learning--in driving this repetitive behavior. Specifically, we focus on the \"toxicity\" of induction heads, which we define as their tendency to dominate the model's output logits during repetition, effectively excluding other attention heads from contributing to the generation process. Our findings have important implications for the design and training of LLMs. By identifying induction heads as a key driver of the repetition curse, we provide a mechanistic explanation for this phenomenon and suggest potential avenues for mitigation. We also propose a technique with attention head regularization that could be employed to reduce the dominance of induction heads during generation, thereby promoting more diverse and coherent outputs.",
          "authors": [
            "Shuxun Wang",
            "Qingyu Yin",
            "Chak Tou Leong",
            "Qiang Zhang",
            "Linyi Yang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.14502",
          "title": "Learning to Integrate Diffusion ODEs by Averaging the Derivatives",
          "abstract": "To accelerate diffusion model inference, numerical solvers perform poorly at extremely small steps, while distillation techniques often introduce complexity and instability. This work presents an intermediate strategy, balancing performance and cost, by learning ODE integration using loss functions derived from the derivative-integral relationship, inspired by Monte Carlo integration and Picard iteration. From a geometric perspective, the losses operate by gradually extending the tangent to the secant, thus are named as secant losses. The target of secant losses is the same as that of diffusion models, or the diffusion model itself, leading to great training stability. By fine-tuning or distillation, the secant version of EDM achieves a $10$-step FID of $2.14$ on CIFAR-10, while the secant version of SiT-XL/2 attains a $4$-step FID of $2.27$ and an $8$-step FID of $1.96$ on ImageNet-$256\\times256$. Code is available at this https URL .",
          "authors": [
            "Wenze Liu",
            "Xiangyu Yue"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.14996",
          "title": "MAS-ZERO: Designing Multi-Agent Systems with Zero Supervision",
          "abstract": "Multi-agent systems (MAS) leveraging the impressive capabilities of Large Language Models (LLMs) hold significant potential for tackling complex tasks. However, most current MAS depend on manually designed agent roles and communication protocols. These manual designs often fail to align with the underlying LLMs' strengths and struggle to adapt to novel tasks. Recent automatic MAS approaches attempt to mitigate these limitations but typically necessitate a validation set for tuning and yield static MAS designs lacking adaptability during inference, while also removing the flexibility to reduce to simpler systems. We introduce MAS-ZERO, the first self-evolved, inference-time framework for automatic MAS design. MAS-ZERO employs meta-level design to iteratively design, critique, and refine MAS configurations tailored to each problem instance, without requiring a validation set. Critically, it enables dynamic problem decomposition and agent composition through meta-feedback on solvability and completeness, and reduction to simpler systems when appropriate. Experiments across reasoning (math and graduate-level QA), coding, and agentic (search-based) benchmarks, using both closed-source and open-source LLM backbones of varying sizes, demonstrate that MAS-ZERO outperforms strong manual and automatic MAS baselines. It achieves substantial average accuracy improvements of up to 16.69% on reasoning, 16.66% on coding, and 5.45% on agentic tasks, while maintaining cost efficiency.",
          "authors": [
            "Zixuan Ke",
            "Austin Xu",
            "Yifei Ming",
            "Xuan-Phi Nguyen",
            "Ryan Chin",
            "Caiming Xiong",
            "Shafiq Joty"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.15216",
          "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems",
          "abstract": "AI agents have the potential to significantly alter the cybersecurity landscape. Here, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a given vulnerability), and Patch (patching a given vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards from \\$10 to \\$30,485, covering 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a given vulnerability. We evaluate 10 agents: Claude Code, OpenAI Codex CLI with o3-high and o4-mini, and custom agents with o3-high, GPT-4.1, Gemini 2.5 Pro Preview, Claude 3.7 Sonnet Thinking, Qwen3 235B A22B, Llama 4 Maverick, and DeepSeek-R1. Given up to three attempts, the top-performing agents are Codex CLI: o3-high (12.5% on Detect, mapping to \\$3,720; 90% on Patch, mapping to \\$14,152), Custom Agent: Claude 3.7 Sonnet Thinking (67.5% on Exploit), and Codex CLI: o4-mini (90% on Patch, mapping to \\$14,422). Codex CLI: o3-high, Codex CLI: o4-mini, and Claude Code are more capable at defense, achieving higher Patch scores of 90%, 90%, and 87.5%, compared to Exploit scores of 47.5%, 32.5%, and 57.5% respectively; while the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 17.5-67.5% and Patch scores of 25-60%.",
          "authors": [
            "Andy K. Zhang",
            "Joey Ji",
            "Celeste Menders",
            "Riya Dulepet",
            "Thomas Qin",
            "Ron Y. Wang",
            "Junrong Wu",
            "Kyleen Liao",
            "Jiliang Li",
            "Jinghan Hu",
            "Sara Hong",
            "Nardos Demilew",
            "Shivatmica Murgai",
            "Jason Tran",
            "Nishka Kacheria",
            "Ethan Ho",
            "Denis Liu",
            "Lauren McLane",
            "Olivia Bruvik",
            "Dai-Rong Han",
            "Seungwoo Kim",
            "Akhil Vyas",
            "Cuiyuanxiu Chen",
            "Ryan Li",
            "Weiran Xu",
            "Jonathan Z. Ye",
            "Prerit Choudhary",
            "Siddharth M. Bhatia",
            "Vikram Sivashankar",
            "Yuxuan Bao",
            "Dawn Song",
            "Dan Boneh",
            "Daniel E. Ho",
            "Percy Liang"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.16791",
          "title": "Cohort-Based Active Modality Acquisition",
          "abstract": "Real-world machine learning applications often involve data from multiple modalities that must be integrated effectively to make robust predictions. However, in many practical settings, not all modalities are available for every sample, and acquiring additional modalities can be costly. This raises the question: which samples should be prioritized for additional modality acquisition when resources are limited? While prior work has explored individual-level acquisition strategies and training-time active learning paradigms, test-time and cohort-based acquisition remain underexplored. We introduce Cohort-based Active Modality Acquisition (CAMA), a novel test-time setting to formalize the challenge of selecting which samples should receive additional modalities. We derive acquisition strategies that leverage a combination of generative imputation and discriminative modeling to estimate the expected benefit of acquiring missing modalities based on common evaluation metrics. We also introduce upper-bound heuristics that provide performance ceilings to benchmark acquisition strategies. Experiments on multimodal datasets with up to 15 modalities demonstrate that our proposed imputation-based strategies can more effectively guide the acquisition of additional modalities for selected samples compared with methods relying solely on unimodal information, entropy-based guidance, or random selection. We showcase the real-world relevance and scalability of our method by demonstrating its ability to effectively guide the costly acquisition of proteomics data for disease prediction in a large prospective cohort, the UK Biobank (UKBB). Our work provides an effective approach for optimizing modality acquisition at the cohort level, enabling more effective use of resources in constrained settings.",
          "authors": [
            "Tillmann Rheude",
            "Roland Eils",
            "Benjamin Wild"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.17691",
          "title": "ELSPR: Evaluator LLM Training Data Self-Purification on Non-Transitive Preferences via Tournament Graph Reconstruction",
          "abstract": "Pairwise evaluation of large language models (LLMs) has become the dominant paradigm for benchmarking open-ended tasks, yet non-transitive preferences, where evaluators prefer A over B, B over C, but C over A, fundamentally undermine ranking reliability. We show that this critical issue stems largely from low-quality data that contains inherently ambiguous preference pairs. To address this challenge, we propose ELSPR, a principled graph-theoretic framework that models pairwise preferences as tournament graphs and systematically identifies problematic training data. ELSPR quantifies non-transitivity through strongly connected components (SCCs) analysis and measures overall preference clarity using a novel normalized directed graph structural entropy metric. Our filtering methodology selectively removes preference data that induce non-transitivity while preserving transitive preferences. Extensive experiments on the AlpacaEval benchmark demonstrate that models fine-tuned on ELSPR-filtered data achieve substantial improvements: a 13.8% reduction in non-transitivity, a 0.088 decrease in structural entropy, and significantly enhanced discriminative power in real-world evaluation systems. Human validation confirms that discarded data exhibit dramatically lower inter-annotator agreement (34.4% vs. 52.6%) and model-human consistency (51.2% vs. 80.6%) compared to cleaned data. These findings establish ELSPR as an effective data self-purification approach for developing more robust, consistent, and human-aligned LLM evaluation systems.",
          "authors": [
            "Yan Yu",
            "Yilun Liu",
            "Minggui He",
            "Shimin Tao",
            "Weibin Meng",
            "Xinhua Yang",
            "Li Zhang",
            "Hongxia Ma",
            "Dengye Li",
            "Daimeng Wei",
            "Boxing Chen",
            "Fuliang Li"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.18659",
          "title": "Adaptive Prediction-Powered AutoEval with Reliability and Efficiency Guarantees",
          "abstract": "Selecting artificial intelligence (AI) models, such as large language models (LLMs), from multiple candidates requires accurate performance estimation. This is ideally achieved through empirical evaluations involving abundant real-world data. However, such evaluations are costly and impractical at scale. To address this challenge, autoevaluation methods leverage synthetic data produced by automated evaluators, such as LLMs-as-judges, reducing variance but potentially introducing bias. Recent approaches have employed semi-supervised prediction-powered inference (PPI) to correct for the bias of autoevaluators. However, the use of autoevaluators may lead in practice to a degradation in sample efficiency compared to conventional methods using only real-world data. In this paper, we propose R-AutoEval+, a novel framework that provides finite-sample reliability guarantees on the model evaluation, while also ensuring an enhanced (or at least no worse) sample efficiency compared to conventional methods. The key innovation of R-AutoEval+ is an adaptive construction of the model evaluation variable, which dynamically tunes its reliance on synthetic data, reverting to conventional methods when the autoevaluator is insufficiently accurate. Experiments on the use of LLMs-as-judges for the optimization of quantization settings for the weights of an LLM, for prompt design in LLMs, and for test-time reasoning budget allocation in LLMs confirm the reliability and efficiency of R-AutoEval+.",
          "authors": [
            "Sangwoo Park",
            "Matteo Zecchin",
            "Osvaldo Simeone"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.18659",
          "title": "Adaptive Prediction-Powered AutoEval with Reliability and Efficiency Guarantees",
          "abstract": "Selecting artificial intelligence (AI) models, such as large language models (LLMs), from multiple candidates requires accurate performance estimation. This is ideally achieved through empirical evaluations involving abundant real-world data. However, such evaluations are costly and impractical at scale. To address this challenge, autoevaluation methods leverage synthetic data produced by automated evaluators, such as LLMs-as-judges, reducing variance but potentially introducing bias. Recent approaches have employed semi-supervised prediction-powered inference (PPI) to correct for the bias of autoevaluators. However, the use of autoevaluators may lead in practice to a degradation in sample efficiency compared to conventional methods using only real-world data. In this paper, we propose R-AutoEval+, a novel framework that provides finite-sample reliability guarantees on the model evaluation, while also ensuring an enhanced (or at least no worse) sample efficiency compared to conventional methods. The key innovation of R-AutoEval+ is an adaptive construction of the model evaluation variable, which dynamically tunes its reliance on synthetic data, reverting to conventional methods when the autoevaluator is insufficiently accurate. Experiments on the use of LLMs-as-judges for the optimization of quantization settings for the weights of an LLM, for prompt design in LLMs, and for test-time reasoning budget allocation in LLMs confirm the reliability and efficiency of R-AutoEval+.",
          "authors": [
            "Sangwoo Park",
            "Matteo Zecchin",
            "Osvaldo Simeone"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.18738",
          "title": "AuroRA: Breaking Low-Rank Bottleneck of LoRA with Nonlinear Mapping",
          "abstract": "Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method validated across NLP and CV domains. However, LoRA faces an inherent low-rank bottleneck: narrowing its performance gap with full finetuning requires increasing the rank of its parameter matrix, resulting in significant parameter overhead. Recent linear LoRA variants have attempted to enhance expressiveness by introducing additional linear mappings; however, their composition remains inherently linear and fails to fundamentally improve LoRA's representational capacity. To address this limitation, we propose AuroRA, which incorporates an Adaptive Nonlinear Layer (ANL) between two linear projectors to capture fixed and learnable nonlinearities. This combination forms an MLP-like structure with a compressed rank, enabling flexible and precise approximation of diverse target functions while theoretically guaranteeing lower approximation errors and bounded gradients. Extensive experiments on 22 datasets and 6 pretrained models demonstrate that AuroRA: (I) not only matches or surpasses full fine-tuning performance with only 6.18% ~ 25% of LoRA's parameters but also (II) outperforms competitive PEFT methods by up to 10.88% in both NLP and CV tasks, and (III) exhibits robust performance across various rank configurations.",
          "authors": [
            "Haonan Dong",
            "Wenhao Zhu",
            "Guojie Song",
            "Liang Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.19785",
          "title": "medDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support",
          "abstract": "Timely and personalized treatment decisions are essential across a wide range of healthcare settings where patient responses can vary significantly and evolve over time. Clinical data used to support these treatment decisions are often irregularly sampled, where missing data frequencies may implicitly convey information about the patient's condition. Existing Reinforcement Learning (RL) based clinical decision support systems often ignore the missing patterns and distort them with coarse discretization and simple imputation. They are also predominantly model-free and largely depend on retrospective data, which could lead to insufficient exploration and bias by historical behaviors. To address these limitations, we propose medDreamer, a novel model-based reinforcement learning framework for personalized treatment recommendation. medDreamer contains a world model with an Adaptive Feature Integration module that simulates latent patient states from irregular data and a two-phase policy trained on a hybrid of real and imagined trajectories. This enables learning optimal policies that go beyond the sub-optimality of historical clinical decisions, while remaining close to real clinical data. We evaluate medDreamer on both sepsis and mechanical ventilation treatment tasks using two large-scale Electronic Health Records (EHRs) datasets. Comprehensive evaluations show that medDreamer significantly outperforms model-free and model-based baselines in both clinical outcomes and off-policy metrics.",
          "authors": [
            "Qianyi Xu",
            "Gousia Habib",
            "Feng Wu",
            "Dilruk Perera",
            "Mengling Feng"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.19969",
          "title": "Differential Privacy Analysis of Decentralized Gossip Averaging under Varying Threat Models",
          "abstract": "Fully decentralized training of machine learning models offers significant advantages in scalability, robustness, and fault tolerance. However, achieving differential privacy (DP) guarantees in such settings is challenging due to the absence of a central aggregator and varying trust assumptions among nodes. We present a novel privacy analysis of decentralized gossip-based averaging algorithms with additive node-level noise, from arbitrary views of nodes in a graph and especially consider the averaging over nearest neighbors with secure summation and individual node-wise views. Our main contribution is a an analytical framework based on a linear systems formulation that accurately characterizes privacy leakage between nodes across different scenarios. In case the gossip averaging happens via secure summation, we show that the Rényi DP parameter growth is asymptotically $O(T)$, where $T$ is the number of training rounds, similarly as in the case of central aggregation.",
          "authors": [
            "Antti Koskela",
            "Tejas Kulkarni"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.21025",
          "title": "Text-Queried Audio Source Separation via Hierarchical Modeling",
          "abstract": "Target audio source separation with natural language queries presents a promising paradigm for extracting arbitrary audio events through arbitrary text descriptions. Existing methods mainly face two challenges, the difficulty in jointly modeling acoustic-textual alignment and semantic-aware separation within a blindly-learned single-stage architecture, and the reliance on large-scale accurately-labeled training data to compensate for inefficient cross-modal learning and separation. To address these challenges, we propose a hierarchical decomposition framework, HSM-TSS, that decouples the task into global-local semantic-guided feature separation and structure-preserving acoustic reconstruction. Our approach introduces a dual-stage mechanism for semantic separation, operating on distinct global and local semantic feature spaces. We first perform global-semantic separation through a global semantic feature space aligned with text queries. A Q-Audio architecture is employed to align audio and text modalities, serving as pretrained global-semantic encoders. Conditioned on the predicted global feature, we then perform the second-stage local-semantic separation on AudioMAE features that preserve time-frequency structures, followed by acoustic reconstruction. We also propose an instruction processing pipeline to parse arbitrary text queries into structured operations, extraction or removal, coupled with audio descriptions, enabling flexible sound manipulation. Our method achieves state-of-the-art separation performance with data-efficient training while maintaining superior semantic consistency with queries in complex auditory scenes.",
          "authors": [
            "Xinlei Yin",
            "Xiulian Peng",
            "Xue Jiang",
            "Zhiwei Xiong",
            "Yan Lu"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.21025",
          "title": "Text-Queried Audio Source Separation via Hierarchical Modeling",
          "abstract": "Target audio source separation with natural language queries presents a promising paradigm for extracting arbitrary audio events through arbitrary text descriptions. Existing methods mainly face two challenges, the difficulty in jointly modeling acoustic-textual alignment and semantic-aware separation within a blindly-learned single-stage architecture, and the reliance on large-scale accurately-labeled training data to compensate for inefficient cross-modal learning and separation. To address these challenges, we propose a hierarchical decomposition framework, HSM-TSS, that decouples the task into global-local semantic-guided feature separation and structure-preserving acoustic reconstruction. Our approach introduces a dual-stage mechanism for semantic separation, operating on distinct global and local semantic feature spaces. We first perform global-semantic separation through a global semantic feature space aligned with text queries. A Q-Audio architecture is employed to align audio and text modalities, serving as pretrained global-semantic encoders. Conditioned on the predicted global feature, we then perform the second-stage local-semantic separation on AudioMAE features that preserve time-frequency structures, followed by acoustic reconstruction. We also propose an instruction processing pipeline to parse arbitrary text queries into structured operations, extraction or removal, coupled with audio descriptions, enabling flexible sound manipulation. Our method achieves state-of-the-art separation performance with data-efficient training while maintaining superior semantic consistency with queries in complex auditory scenes.",
          "authors": [
            "Xinlei Yin",
            "Xiulian Peng",
            "Xue Jiang",
            "Zhiwei Xiong",
            "Yan Lu"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.21265",
          "title": "Multilingual Pretraining for Pixel Language Models",
          "abstract": "Pixel language models operate directly on images of rendered text, eliminating the need for a fixed vocabulary. While these models have demonstrated strong capabilities for downstream cross-lingual transfer, multilingual pretraining remains underexplored. We introduce PIXEL-M4, a model pretrained on four visually and linguistically diverse languages: English, Hindi, Ukrainian, and Simplified Chinese. Multilingual evaluations on semantic and syntactic tasks show that PIXEL-M4 outperforms an English-only counterpart on non-Latin scripts. Word-level probing analyses confirm that PIXEL-M4 captures rich linguistic features, even in languages not seen during pretraining. Furthermore, an analysis of its hidden representations shows that multilingual pretraining yields a semantic embedding space closely aligned across the languages used for pretraining. This work demonstrates that multilingual pretraining substantially enhances the capability of pixel language models to effectively support a diverse set of languages.",
          "authors": [
            "Ilker Kesen",
            "Jonas F. Lotz",
            "Ingo Ziegler",
            "Phillip Rust",
            "Desmond Elliott"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22563",
          "title": "Do Large Language Models Think Like the Brain? Sentence-Level Evidences from Layer-Wise Embeddings and fMRI",
          "abstract": "Understanding whether large language models (LLMs) and the human brain converge on similar computational principles remains a fundamental and important question in cognitive neuroscience and AI. Do the brain-like patterns observed in LLMs emerge simply from scaling, or do they reflect deeper alignment with the architecture of human language processing? This study focuses on the sentence-level neural mechanisms of language models, systematically investigating how layer-wise representations in LLMs align with the dynamic neural responses during human sentence comprehension. By comparing hierarchical embeddings from 14 publicly available LLMs with fMRI data collected from participants, who were exposed to a naturalistic narrative story, we constructed sentence-level neural prediction models to identify the model layers most significantly correlated with brain region activations. Results show that improvements in model performance drive the evolution of representational architectures toward brain-like hierarchies, particularly achieving stronger functional and anatomical correspondence at higher semantic abstraction levels. These findings advance our understanding of the computational parallels between LLMs and the human brain, highlighting the potential of LLMs as models for human language processing.",
          "authors": [
            "Yu Lei",
            "Xingyang Ge",
            "Yi Zhang",
            "Yiming Yang",
            "Bolei Ma"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.22563",
          "title": "Do Large Language Models Think Like the Brain? Sentence-Level Evidences from Layer-Wise Embeddings and fMRI",
          "abstract": "Understanding whether large language models (LLMs) and the human brain converge on similar computational principles remains a fundamental and important question in cognitive neuroscience and AI. Do the brain-like patterns observed in LLMs emerge simply from scaling, or do they reflect deeper alignment with the architecture of human language processing? This study focuses on the sentence-level neural mechanisms of language models, systematically investigating how layer-wise representations in LLMs align with the dynamic neural responses during human sentence comprehension. By comparing hierarchical embeddings from 14 publicly available LLMs with fMRI data collected from participants, who were exposed to a naturalistic narrative story, we constructed sentence-level neural prediction models to identify the model layers most significantly correlated with brain region activations. Results show that improvements in model performance drive the evolution of representational architectures toward brain-like hierarchies, particularly achieving stronger functional and anatomical correspondence at higher semantic abstraction levels. These findings advance our understanding of the computational parallels between LLMs and the human brain, highlighting the potential of LLMs as models for human language processing.",
          "authors": [
            "Yu Lei",
            "Xingyang Ge",
            "Yi Zhang",
            "Yiming Yang",
            "Bolei Ma"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.23337",
          "title": "Matryoshka Model Learning for Improved Elastic Student Models",
          "abstract": "Industry-grade ML models are carefully designed to meet rapidly evolving serving constraints, which requires significant resources for model development. In this paper, we propose MatTA, a framework for training multiple accurate Student models using a novel Teacher-TA-Student recipe. TA models are larger versions of the Student models with higher capacity, and thus allow Student models to better relate to the Teacher model and also bring in more domain-specific expertise. Furthermore, multiple accurate Student models can be extracted from the TA model. Therefore, despite only one training run, our methodology provides multiple servable options to trade off accuracy for lower serving cost. We demonstrate the proposed method, MatTA, on proprietary datasets and models. Its practical efficacy is underscored by live A/B tests within a production ML system, demonstrating 20% improvement on a key metric. We also demonstrate our method on GPT-2 Medium, a public model, and achieve relative improvements of over 24% on SAT Math and over 10% on the LAMBADA benchmark.",
          "authors": [
            "Chetan Verma",
            "Aditya Srinivas Timmaraju",
            "Cho-Jui Hsieh",
            "Suyash Damle",
            "Ngot Bui",
            "Yang Zhang",
            "Wen Chen",
            "Xin Liu",
            "Prateek Jain",
            "Inderjit S Dhillon"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.23393",
          "title": "Ordinal regression for meta-analysis of test accuracy: a flexible approach for utilising all threshold data",
          "abstract": "Standard (network) meta-analysis methods for medical test accuracy evaluation analyse the data separately for each test threshold - wasting data - unless every study reports all thresholds. Previously proposed \"multiple threshold\" models either fail to provide threshold-specific summary estimates, or they assume that ordinal tests (e.g., questionnaires) are continuous. We propose two ordinal regression models - ordinal-bivariate and ordinal-HSROC - using an induced-Dirichlet framework for cutpoint parameters, enabling intuitive priors and both fixed-effects and random-effects cutpoints. We conducted a simulation study to evaluate the performance of our proposed models, with the simulated data being based on real anxiety screening data spanning 7, 22, and 64 ordinal categories, with 15%, 40% and 55% missing threshold data. Our proposed ordinal-bivariate model with fixed-effect cutpoints tended to obtain the best RMSE and bias, including when data was generated from a recently proposed continuous-assumption model. For instance - even with 64 categories - continuous models performed 10%-30% worse than our models, contradicting the common assumption that many categories justify treating ordinal tests as continuous. Furthermore, the standard stratified-bivariate approach showed worse performance, especially for tests with higher missingness. We implemented the models in the MetaOrdDTA R package ( this https URL ), which provides features such as: Stan estimation, K-fold cross-validation for model selection, meta-regression, network meta-analysis extensions, and visualisation tools including sROC plots with credible/prediction regions. Overall, our simulation study suggests that our proposed models may obtain better accuracy estimates than previous approaches for ordinal tests, even when the number of ordinal categories is very high.",
          "authors": [
            "Enzo Cerullo",
            "Klaus Linde",
            "Haley E. Jones",
            "Efthymia Derezea",
            "Tim Lucas",
            "Nicola J. Cooper",
            "Alex J. Sutton"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2505.24265",
          "title": "R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning",
          "abstract": "Multi-agent reinforcement learning (MARL) has achieved significant progress in large-scale traffic control, autonomous vehicles, and robotics. Drawing inspiration from biological systems where roles naturally emerge to enable coordination, role-based MARL methods have been proposed to enhance cooperation learning for complex tasks. However, existing methods exclusively derive roles from an agent's past experience during training, neglecting their influence on its future trajectories. This paper introduces a key insight: an agent's role should shape its future behavior to enable effective coordination. Hence, we propose Role Discovery and Diversity through Dynamics Models (R3DM), a novel role-based MARL framework that learns emergent roles by maximizing the mutual information between agents' roles, observed trajectories, and expected future behaviors. R3DM optimizes the proposed objective through contrastive learning on past trajectories to first derive intermediate roles that shape intrinsic rewards to promote diversity in future behaviors across different roles through a learned dynamics model. Benchmarking on SMAC and SMACv2 environments demonstrates that R3DM outperforms state-of-the-art MARL approaches, improving multi-agent coordination to increase win rates by up to 20%. The code is available at this https URL .",
          "authors": [
            "Harsh Goel",
            "Mohammad Omama",
            "Behdad Chalaki",
            "Vaishnav Tadiparthi",
            "Ehsan Moradi Pari",
            "Sandeep Chinchali"
          ],
          "primary_category": "cs.MA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.02459",
          "title": "ReSpace: Text-Driven 3D Indoor Scene Synthesis and Editing with Preference Alignment",
          "abstract": "Scene synthesis and editing has emerged as a promising direction in computer graphics. Current trained approaches for 3D indoor scenes either oversimplify object semantics through one-hot class encodings (e.g., 'chair' or 'table'), require masked diffusion for editing, ignore room boundaries, or rely on floor plan renderings that fail to capture complex layouts. LLM-based methods enable richer semantics via natural language (e.g., 'modern studio with light wood furniture'), but lack editing functionality, are limited to rectangular layouts, or rely on weak spatial reasoning from implicit world models. We introduce ReSpace, a generative framework for text-driven 3D indoor scene synthesis and editing using autoregressive language models. Our approach features a compact structured scene representation with explicit room boundaries that enables asset-agnostic deployment and frames scene editing as a next-token prediction task. We leverage a dual-stage training approach combining supervised fine-tuning and preference alignment, enabling a specially trained language model for object addition that accounts for user instructions, spatial geometry, object semantics, and scene-level composition. For scene editing, we employ a zero-shot LLM to handle object removal and prompts for addition. We further introduce a voxelization-based evaluation capturing fine-grained geometry beyond 3D bounding boxes. Experimental results surpass state-of-the-art on addition and achieve superior human-perceived quality on full scene synthesis.",
          "authors": [
            "Martin JJ. Bucher",
            "Iro Armeni"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.03719",
          "title": "On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity",
          "abstract": "Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching. First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",
          "authors": [
            "Quentin Bertrand",
            "Anne Gagneux",
            "Mathurin Massias",
            "Rémi Emonet"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.03719",
          "title": "On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity",
          "abstract": "Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching. First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",
          "authors": [
            "Quentin Bertrand",
            "Anne Gagneux",
            "Mathurin Massias",
            "Rémi Emonet"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.05197",
          "title": "Overlap Gap and Computational Thresholds in the Square Wave Perceptron",
          "abstract": "Square Wave Perceptrons (SWPs) form a class of neural network models with oscillating activation function that exhibit intriguing ``hardness'' properties in the high-dimensional limit at a fixed constraint density $\\alpha = O(1)$. In this work, we examine two key aspects of these models. The first is related to the so-called \\emph{overlap-gap property}, that is a disconnectivity feature of the geometry of the solution space of combinatorial optimization problems proven to cause the failure of a large family of solvers, and conjectured to be a symptom of algorithmic hardness. We identify, both in the storage and in the teacher-student settings, the emergence of an overlap gap at a threshold $\\alpha_{\\mathrm{OGP}}(\\delta)$, which can be made arbitrarily small by suitably increasing the frequency of oscillations $1/\\delta$ of the activation. This suggests that in this small-$\\delta$ regime, typical instances of the problem are hard to solve even for small values of $\\alpha$. Second, in the teacher-student setup, we show that the recovery threshold of the planted signal for message-passing algorithms can be made arbitrarily large by reducing $\\delta$. These properties make SWPs both a challenging benchmark for algorithms and an interesting candidate for cryptographic applications.",
          "authors": [
            "Marco Benedetti",
            "Andrej Bogdanov",
            "Enrico M. Malatesta",
            "Marc Mézard",
            "Gianmarco Perrupato",
            "Alon Rosen",
            "Nikolaj I. Schwartzbach",
            "Riccardo Zecchina"
          ],
          "primary_category": "cond-mat.dis-nn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.05332",
          "title": "Unleashing Hour-Scale Video Training for Long Video-Language Understanding",
          "abstract": "Recent long-form video-language understanding benchmarks have driven progress in video large multimodal models (Video-LMMs). However, the scarcity of well-annotated long videos has left the training of hour-long Video-LMMs underexplored. To close this gap, we present VideoMarathon, a large-scale hour-long video instruction-following dataset. This dataset includes around 9,700 hours of long videos sourced from diverse domains, ranging from 3 to 60 minutes per video. Specifically, it contains 3.3M high-quality QA pairs, spanning six fundamental topics: temporality, spatiality, object, action, scene, and event. Compared to existing video instruction datasets, VideoMarathon significantly extends training video durations up to 1 hour, and supports 22 diverse tasks requiring both short- and long-term video comprehension. Building on VideoMarathon, we propose Hour-LLaVA, a powerful and efficient Video-LMM for hour-scale video-language modeling. It enables hour-long video training and inference at 1-FPS sampling by leveraging a memory augmentation module, which adaptively integrates question-relevant and spatiotemporally informative semantics from the cached full video context. In our experiments, Hour-LLaVA achieves the best performance on multiple representative long video-language benchmarks, demonstrating the high quality of the VideoMarathon dataset and the superiority of the Hour-LLaVA model.",
          "authors": [
            "Jingyang Lin",
            "Jialian Wu",
            "Ximeng Sun",
            "Ze Wang",
            "Jiang Liu",
            "Yusheng Su",
            "Xiaodong Yu",
            "Hao Chen",
            "Jiebo Luo",
            "Zicheng Liu",
            "Emad Barsoum"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.06409",
          "title": "HeavyWater and SimplexWater: Distortion-Free LLM Watermarks for Low-Entropy Next-Token Predictions",
          "abstract": "Large language model (LLM) watermarks enable authentication of text provenance, curb misuse of machine-generated text, and promote trust in AI systems. Current watermarks operate by changing the next-token predictions output by an LLM. The updated (i.e., watermarked) predictions depend on random side information produced, for example, by hashing previously generated tokens. LLM watermarking is particularly challenging in low-entropy generation tasks -- such as coding -- where next-token predictions are near-deterministic. In this paper, we propose an optimization framework for watermark design. Our goal is to understand how to most effectively use random side information in order to maximize the likelihood of watermark detection and minimize the distortion of generated text. Our analysis informs the design of two new watermarks: HeavyWater and SimplexWater. Both watermarks are tunable, gracefully trading-off between detection accuracy and text distortion. They can also be applied to any LLM and are agnostic to side information generation. We examine the performance of HeavyWater and SimplexWater through several benchmarks, demonstrating that they can achieve high watermark detection accuracy with minimal compromise of text generation quality, particularly in the low-entropy regime. Our theoretical analysis also reveals surprising new connections between LLM watermarking and coding theory. The code implementation can be found in this https URL",
          "authors": [
            "Dor Tsur",
            "Carol Xuan Long",
            "Claudio Mayrink Verdun",
            "Hsiang Hsu",
            "Chen-Fu Chen",
            "Haim Permuter",
            "Sajani Vithana",
            "Flavio P. Calmon"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.06409",
          "title": "HeavyWater and SimplexWater: Distortion-Free LLM Watermarks for Low-Entropy Next-Token Predictions",
          "abstract": "Large language model (LLM) watermarks enable authentication of text provenance, curb misuse of machine-generated text, and promote trust in AI systems. Current watermarks operate by changing the next-token predictions output by an LLM. The updated (i.e., watermarked) predictions depend on random side information produced, for example, by hashing previously generated tokens. LLM watermarking is particularly challenging in low-entropy generation tasks -- such as coding -- where next-token predictions are near-deterministic. In this paper, we propose an optimization framework for watermark design. Our goal is to understand how to most effectively use random side information in order to maximize the likelihood of watermark detection and minimize the distortion of generated text. Our analysis informs the design of two new watermarks: HeavyWater and SimplexWater. Both watermarks are tunable, gracefully trading-off between detection accuracy and text distortion. They can also be applied to any LLM and are agnostic to side information generation. We examine the performance of HeavyWater and SimplexWater through several benchmarks, demonstrating that they can achieve high watermark detection accuracy with minimal compromise of text generation quality, particularly in the low-entropy regime. Our theoretical analysis also reveals surprising new connections between LLM watermarking and coding theory. The code implementation can be found in this https URL",
          "authors": [
            "Dor Tsur",
            "Carol Xuan Long",
            "Claudio Mayrink Verdun",
            "Hsiang Hsu",
            "Chen-Fu Chen",
            "Haim Permuter",
            "Sajani Vithana",
            "Flavio P. Calmon"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.07255",
          "title": "Subgoal-Guided Policy Heuristic Search with Learned Subgoals",
          "abstract": "Policy tree search is a family of tree search algorithms that use a policy to guide the search. These algorithms provide guarantees on the number of expansions required to solve a given problem that are based on the quality of the policy. While these algorithms have shown promising results, the process in which they are trained requires complete solution trajectories to train the policy. Search trajectories are obtained during a trial-and-error search process. When the training problem instances are hard, learning can be prohibitively costly, especially when starting from a randomly initialized policy. As a result, search samples are wasted in failed attempts to solve these hard instances. This paper introduces a novel method for learning subgoal-based policies for policy tree search algorithms. The subgoals and policies conditioned on subgoals are learned from the trees that the search expands while attempting to solve problems, including the search trees of failed attempts. We empirically show that our policy formulation and training method improve the sample efficiency of learning a policy and heuristic function in this online setting.",
          "authors": [
            "Jake Tuero",
            "Michael Buro",
            "Levi H. S. Lelis"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.11151",
          "title": "Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels",
          "abstract": "We consider the problem of recovering a mental target (e.g., an image of a face) that a participant has in mind from paired EEG (i.e., brain responses) and image (i.e., perceived faces) data collected during interactive sessions without access to labeled information. The problem has been previously explored with labeled data but not via self-calibration, where labeled data is unavailable. Here, we present the first framework and an algorithm, CURSOR, that learns to recover unknown mental targets without access to labeled data or pre-trained decoders. Our experiments on naturalistic images of faces demonstrate that CURSOR can (1) predict image similarity scores that correlate with human perceptual judgments without any label information, (2) use these scores to rank stimuli against an unknown mental target, and (3) generate new stimuli indistinguishable from the unknown mental target (validated via a user study, N=53).",
          "authors": [
            "Jonathan Grizou",
            "Carlos de la Torre-Ortiz",
            "Tuukka Ruotsalo"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.11452",
          "title": "Leveraging Reference Documents for Zero-Shot Ranking via Large Language Models",
          "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in the task of text ranking for information retrieval. While Pointwise ranking approaches offer computational efficiency by scoring documents independently, they often yield biased relevance estimates due to the lack of inter-document comparisons. In contrast, Pairwise methods improve ranking accuracy by explicitly comparing document pairs, but suffer from substantial computational overhead with quadratic complexity ($O(n^2)$). To address this tradeoff, we propose \\textbf{RefRank}, a simple and effective comparative ranking method based on a fixed reference document. Instead of comparing all document pairs, RefRank prompts the LLM to evaluate each candidate relative to a shared reference anchor. By selecting the reference anchor that encapsulates the core query intent, RefRank implicitly captures relevance cues, enabling indirect comparison between documents via this common anchor. This reduces computational cost to linear time ($O(n)$) while importantly, preserving the advantages of comparative evaluation. To further enhance robustness, we aggregate multiple RefRank outputs using a weighted averaging scheme across different reference choices. Experiments on several benchmark datasets and with various LLMs show that RefRank significantly outperforms Pointwise baselines and could achieve performance at least on par with Pairwise approaches with a significantly lower computational cost.",
          "authors": [
            "Jieran Li",
            "Xiuyuan Hu",
            "Yang Zhao",
            "Shengyao Zhuang",
            "Hao Zhang"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12389",
          "title": "Revisiting Clustering of Neural Bandits: Selective Reinitialization for Mitigating Loss of Plasticity",
          "abstract": "Clustering of Bandits (CB) methods enhance sequential decision-making by grouping bandits into clusters based on similarity and incorporating cluster-level contextual information, demonstrating effectiveness and adaptability in applications like personalized streaming recommendations. However, when extending CB algorithms to their neural version (commonly referred to as Clustering of Neural Bandits, or CNB), they suffer from loss of plasticity, where neural network parameters become rigid and less adaptable over time, limiting their ability to adapt to non-stationary environments (e.g., dynamic user preferences in recommendation). To address this challenge, we propose Selective Reinitialization (SeRe), a novel bandit learning framework that dynamically preserves the adaptability of CNB algorithms in evolving environments. SeRe leverages a contribution utility metric to identify and selectively reset underutilized units, mitigating loss of plasticity while maintaining stable knowledge retention. Furthermore, when combining SeRe with CNB algorithms, the adaptive change detection mechanism adjusts the reinitialization frequency according to the degree of non-stationarity, ensuring effective adaptation without unnecessary resets. Theoretically, we prove that SeRe enables sublinear cumulative regret in piecewise-stationary environments, outperforming traditional CNB approaches in long-term performances. Extensive experiments on six real-world recommendation datasets demonstrate that SeRe-enhanced CNB algorithms can effectively mitigate the loss of plasticity with lower regrets, improving adaptability and robustness in dynamic settings.",
          "authors": [
            "Zhiyuan Su",
            "Sunhao Dai",
            "Xiao Zhang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12389",
          "title": "Revisiting Clustering of Neural Bandits: Selective Reinitialization for Mitigating Loss of Plasticity",
          "abstract": "Clustering of Bandits (CB) methods enhance sequential decision-making by grouping bandits into clusters based on similarity and incorporating cluster-level contextual information, demonstrating effectiveness and adaptability in applications like personalized streaming recommendations. However, when extending CB algorithms to their neural version (commonly referred to as Clustering of Neural Bandits, or CNB), they suffer from loss of plasticity, where neural network parameters become rigid and less adaptable over time, limiting their ability to adapt to non-stationary environments (e.g., dynamic user preferences in recommendation). To address this challenge, we propose Selective Reinitialization (SeRe), a novel bandit learning framework that dynamically preserves the adaptability of CNB algorithms in evolving environments. SeRe leverages a contribution utility metric to identify and selectively reset underutilized units, mitigating loss of plasticity while maintaining stable knowledge retention. Furthermore, when combining SeRe with CNB algorithms, the adaptive change detection mechanism adjusts the reinitialization frequency according to the degree of non-stationarity, ensuring effective adaptation without unnecessary resets. Theoretically, we prove that SeRe enables sublinear cumulative regret in piecewise-stationary environments, outperforming traditional CNB approaches in long-term performances. Extensive experiments on six real-world recommendation datasets demonstrate that SeRe-enhanced CNB algorithms can effectively mitigate the loss of plasticity with lower regrets, improving adaptability and robustness in dynamic settings.",
          "authors": [
            "Zhiyuan Su",
            "Sunhao Dai",
            "Xiao Zhang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.12523",
          "title": "Privacy-preserving and reward-based mechanisms of proof of engagement",
          "abstract": "Proof-of-Attendance (PoA) mechanisms are typically employed to demonstrate a specific user's participation in an event, whether virtual or in-person. The goal of this study is to extend such mechanisms to broader contexts where the user wishes to digitally demonstrate her involvement in a specific activity (Proof-of-Engagement, PoE). This work explores different solutions, including DLTs as well as established technologies based on centralized systems. The main aspects we consider include the level of privacy guaranteed to users, the scope of PoA/PoE (both temporal and spatial), the transferability of the proof, and the integration with incentive mechanisms.",
          "authors": [
            "Matteo Marco Montanari",
            "Alessandro Aldini"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.14262",
          "title": "Knowledge Adaptation as Posterior Correction",
          "abstract": "Adaptation is the holy grail of intelligence, but even the best AI models lack the adaptability of toddlers. In spite of great progress, little is known about the mechanisms by which machines can learn to adapt as fast as humans and animals. Here, we cast adaptation as `correction' of old posteriors and show that a wide-variety of existing adaptation methods follow this very principle, including those used for continual learning, federated learning, unlearning, and model merging. In all these settings, more accurate posteriors often lead to smaller corrections and can enable faster adaptation. Posterior correction is derived by using the dual representation of the Bayesian Learning Rule of Khan and Rue (2023), where the interference between the old representation and new information is quantified by using the natural-gradient mismatch. We present many examples demonstrating how machines can learn to adapt quickly by using posterior correction.",
          "authors": [
            "Mohammad Emtiyaz Khan"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.14262",
          "title": "Knowledge Adaptation as Posterior Correction",
          "abstract": "Adaptation is the holy grail of intelligence, but even the best AI models lack the adaptability of toddlers. In spite of great progress, little is known about the mechanisms by which machines can learn to adapt as fast as humans and animals. Here, we cast adaptation as `correction' of old posteriors and show that a wide-variety of existing adaptation methods follow this very principle, including those used for continual learning, federated learning, unlearning, and model merging. In all these settings, more accurate posteriors often lead to smaller corrections and can enable faster adaptation. Posterior correction is derived by using the dual representation of the Bayesian Learning Rule of Khan and Rue (2023), where the interference between the old representation and new information is quantified by using the natural-gradient mismatch. We present many examples demonstrating how machines can learn to adapt quickly by using posterior correction.",
          "authors": [
            "Mohammad Emtiyaz Khan"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.15746",
          "title": "Neural Cellular Automata for ARC-AGI",
          "abstract": "Cellular automata and their differentiable counterparts, Neural Cellular Automata (NCA), are highly expressive and capable of surprisingly complex behaviors. This paper explores how NCAs perform when applied to tasks requiring precise transformations and few-shot generalization, using the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) as a domain that challenges their capabilities in ways not previously explored. Specifically, this paper uses gradient-based training to learn iterative update rules that transform input grids into their outputs from the training examples and apply them to the test inputs. Results suggest that gradient-trained NCA models are a promising and efficient approach to a range of abstract grid-based tasks from ARC. Along with discussing the impacts of various design modifications and training constraints, this work examines the behavior and properties of NCAs applied to ARC to give insights for broader applications of self-organizing systems.",
          "authors": [
            "Kevin Xu",
            "Risto Miikkulainen"
          ],
          "primary_category": "cs.NE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.16038",
          "title": "Autocratic strategies in Cournot oligopoly game",
          "abstract": "An oligopoly is a market in which the price of goods is controlled by a few firms. Cournot introduced the simplest game-theoretic model of oligopoly, where profit-maximizing behavior of each firm results in market failure. Furthermore, when the Cournot oligopoly game is infinitely repeated, firms can tacitly collude to monopolize the market. Such tacit collusion is realized by the same mechanism as direct reciprocity in the repeated prisoner's dilemma game, where mutual cooperation can be realized whereas defection is favorable for both prisoners in a one-shot game. Recently, in the repeated prisoner's dilemma game, a class of strategies called zero-determinant strategies attracts much attention in the context of direct reciprocity. Zero-determinant strategies are autocratic strategies which unilaterally control payoffs of players by enforcing linear relationships between payoffs. There were many attempts to find zero-determinant strategies in other games and to extend them so as to apply them to broader situations. In this paper, first, we show that zero-determinant strategies exist even in the repeated Cournot oligopoly game, and that they are quite different from those in the repeated prisoner's dilemma game. Especially, we prove that a fair zero-determinant strategy exists, which is guaranteed to obtain the average payoff of the opponents. Second, we numerically show that the fair zero-determinant strategy can be used to promote collusion when it is used against an adaptively learning player, whereas it cannot promote collusion when it is used against two adaptively learning players. Our findings elucidate some negative impact of zero-determinant strategies in the oligopoly market.",
          "authors": [
            "Masahiko Ueda",
            "Shoma Yagi",
            "Genki Ichinose"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.16038",
          "title": "Autocratic strategies in Cournot oligopoly game",
          "abstract": "An oligopoly is a market in which the price of goods is controlled by a few firms. Cournot introduced the simplest game-theoretic model of oligopoly, where profit-maximizing behavior of each firm results in market failure. Furthermore, when the Cournot oligopoly game is infinitely repeated, firms can tacitly collude to monopolize the market. Such tacit collusion is realized by the same mechanism as direct reciprocity in the repeated prisoner's dilemma game, where mutual cooperation can be realized whereas defection is favorable for both prisoners in a one-shot game. Recently, in the repeated prisoner's dilemma game, a class of strategies called zero-determinant strategies attracts much attention in the context of direct reciprocity. Zero-determinant strategies are autocratic strategies which unilaterally control payoffs of players by enforcing linear relationships between payoffs. There were many attempts to find zero-determinant strategies in other games and to extend them so as to apply them to broader situations. In this paper, first, we show that zero-determinant strategies exist even in the repeated Cournot oligopoly game, and that they are quite different from those in the repeated prisoner's dilemma game. Especially, we prove that a fair zero-determinant strategy exists, which is guaranteed to obtain the average payoff of the opponents. Second, we numerically show that the fair zero-determinant strategy can be used to promote collusion when it is used against an adaptively learning player, whereas it cannot promote collusion when it is used against two adaptively learning players. Our findings elucidate some negative impact of zero-determinant strategies in the oligopoly market.",
          "authors": [
            "Masahiko Ueda",
            "Shoma Yagi",
            "Genki Ichinose"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.16038",
          "title": "Autocratic strategies in Cournot oligopoly game",
          "abstract": "An oligopoly is a market in which the price of goods is controlled by a few firms. Cournot introduced the simplest game-theoretic model of oligopoly, where profit-maximizing behavior of each firm results in market failure. Furthermore, when the Cournot oligopoly game is infinitely repeated, firms can tacitly collude to monopolize the market. Such tacit collusion is realized by the same mechanism as direct reciprocity in the repeated prisoner's dilemma game, where mutual cooperation can be realized whereas defection is favorable for both prisoners in a one-shot game. Recently, in the repeated prisoner's dilemma game, a class of strategies called zero-determinant strategies attracts much attention in the context of direct reciprocity. Zero-determinant strategies are autocratic strategies which unilaterally control payoffs of players by enforcing linear relationships between payoffs. There were many attempts to find zero-determinant strategies in other games and to extend them so as to apply them to broader situations. In this paper, first, we show that zero-determinant strategies exist even in the repeated Cournot oligopoly game, and that they are quite different from those in the repeated prisoner's dilemma game. Especially, we prove that a fair zero-determinant strategy exists, which is guaranteed to obtain the average payoff of the opponents. Second, we numerically show that the fair zero-determinant strategy can be used to promote collusion when it is used against an adaptively learning player, whereas it cannot promote collusion when it is used against two adaptively learning players. Our findings elucidate some negative impact of zero-determinant strategies in the oligopoly market.",
          "authors": [
            "Masahiko Ueda",
            "Shoma Yagi",
            "Genki Ichinose"
          ],
          "primary_category": "physics.soc-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.17238",
          "title": "Training a Scientific Reasoning Model for Chemistry",
          "abstract": "Reasoning models are large language models that emit a long chain-of-thought before answering, providing both higher accuracy and explicit reasoning for their response. A major question has been whether language model reasoning generalizes beyond mathematics, programming, and logic, where most previous work has focused. We demonstrate that reasoning models can be post-trained for chemistry without additional domain pretraining, and require substantially less data compared to contemporary domain-specific models. We report ether0, a 24B parameter LLM (based on Mistral-Small-24B) that can reason in natural language and respond with chemical structures. This reasoning model was trained with reinforcement learning on 640,730 experimentally-grounded chemistry problems across 375 tasks ranging from synthesizability, to blood-brain barrier permeability, to human receptor activity, to scent. Our model exceeds general-purpose chemistry models, frontier models, and human experts on molecular design tasks. It is also more data efficient relative to specialized models. We anticipate that this method can be applied to train data-efficient language models specialized for tasks across a wide variety of scientific domains.",
          "authors": [
            "Siddharth M. Narayanan",
            "James D. Braza",
            "Ryan-Rhys Griffiths",
            "Albert Bou",
            "Geemi Wellawatte",
            "Mayk Caldas Ramos",
            "Ludovico Mitchener",
            "Samuel G. Rodriques",
            "Andrew D. White"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.17442",
          "title": "Keeping Medical AI Healthy and Trustworthy: A Review of Detection and Correction Methods for System Degradation",
          "abstract": "Artificial intelligence (AI) is increasingly integrated into modern healthcare, offering powerful support for clinical decision-making. However, in real-world settings, AI systems may experience performance degradation over time, due to factors such as shifting data distributions, changes in patient characteristics, evolving clinical protocols, and variations in data quality. These factors can compromise model reliability, posing safety concerns and increasing the likelihood of inaccurate predictions or adverse outcomes. This review presents a forward-looking perspective on monitoring and maintaining the \"health\" of AI systems in healthcare. We highlight the urgent need for continuous performance monitoring, early degradation detection, and effective self-correction mechanisms. The paper begins by reviewing common causes of performance degradation at both data and model levels. We then summarize key techniques for detecting data and model drift, followed by an in-depth look at root cause analysis. Correction strategies are further reviewed, ranging from model retraining to test-time adaptation. Our survey spans both traditional machine learning models and state-of-the-art large language models (LLMs), offering insights into their strengths and limitations. Finally, we discuss ongoing technical challenges and propose future research directions. This work aims to guide the development of reliable, robust medical AI systems capable of sustaining safe, long-term deployment in dynamic clinical settings.",
          "authors": [
            "Hao Guan",
            "David Bates",
            "Li Zhou"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.19117",
          "title": "PrITTI: Primitive-based Generation of Controllable and Editable 3D Semantic Urban Scenes",
          "abstract": "Existing approaches to 3D semantic urban scene generation predominantly rely on voxel-based representations, which are bound by fixed resolution, challenging to edit, and memory-intensive in their dense form. In contrast, we advocate for a primitive-based paradigm where urban scenes are represented using compact, semantically meaningful 3D elements that are easy to manipulate and compose. To this end, we introduce PrITTI, a latent diffusion model that leverages vectorized object primitives and rasterized ground surfaces for generating diverse, controllable, and editable 3D semantic urban scenes. This hybrid representation yields a structured latent space that facilitates object- and ground-level manipulation. Experiments on KITTI-360 show that primitive-based representations unlock the full capabilities of diffusion transformers, achieving state-of-the-art 3D scene generation quality with lower memory requirements, faster inference, and greater editability than voxel-based methods. Beyond generation, PrITTI supports a range of downstream applications, including scene editing, inpainting, outpainting, and photo-realistic street-view synthesis. Code and models are publicly available at $\\href{ this https URL }{ this https URL }$.",
          "authors": [
            "Christina Ourania Tze",
            "Daniel Dauner",
            "Yiyi Liao",
            "Dzmitry Tsishkou",
            "Andreas Geiger"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2506.19686",
          "title": "From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers",
          "abstract": "Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory-- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.",
          "authors": [
            "Ching Fang",
            "Kanaka Rajan"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.01463",
          "title": "NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation",
          "abstract": "Instance segmentation of novel objects instances in RGB images, given some example images for each object, is a well known problem in computer vision. Designing a model general enough to be employed for all kinds of novel objects without (re-) training has proven to be a difficult task. To handle this, we present a new training-free framework, called: Novel Object Cyclic Threshold based Instance Segmentation (NOCTIS). NOCTIS integrates two pre-trained models: Grounded-SAM 2 for object proposals with precise bounding boxes and corresponding segmentation masks; and DINOv2 for robust class and patch embeddings, due to its zero-shot capabilities. Internally, the proposal-object matching is realized by determining an object matching score based on the similarity of the class embeddings and the average maximum similarity of the patch embeddings with a new cyclic thresholding (CT) mechanism that mitigates unstable matches caused by repetitive textures or visually similar patterns. Beyond CT, NOCTIS introduces: (i) an appearance score that is unaffected by object selection bias; (ii) the usage of the average confidence of the proposals' bounding box and mask as a scoring component; and (iii) an RGB-only pipeline that performs even better than RGB-D ones. We empirically show that NOCTIS, without further training/fine tuning, outperforms the best RGB and RGB-D methods regarding the mean AP score on the seven core datasets of the BOP 2023 challenge for the \"Model-based 2D segmentation of unseen objects\" task.",
          "authors": [
            "Max Gandyra",
            "Alessandro Santonicola",
            "Michael Beetz"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.01853",
          "title": "Eka-Eval: An Evaluation Framework for Low-Resource Multilingual Large Language Models",
          "abstract": "The rapid evolution of Large Language Models' has underscored the need for evaluation frameworks that are globally applicable, flexible, and modular, and that support a wide range of tasks, model types, and linguistic settings. We introduce EKA-EVAL, a unified, end- to-end framework that combines a zero-code web interface and an interactive CLI to ensure broad accessibility. It integrates 50+ multilingual benchmarks across nine evaluation categories, supports local and proprietary models, and provides 11 core capabilities through a modular, plug-and-play architecture. Designed for scalable, multilingual evaluation with support for low-resource multilingual languages, EKA-EVAL is, to the best of our knowledge, the first suite to offer comprehensive coverage in a single platform. Comparisons against five existing baselines indicate improvements of at least 2x better on key usability measures, with the highest user satisfaction, faster setup times, and consistent benchmark reproducibility. The framework is open-source and publicly available at this https URL .",
          "authors": [
            "Samridhi Raj Sinha",
            "Rajvee Sheth",
            "Abhishek Upperwal",
            "Mayank Singh"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.02027",
          "title": "Arbitrage with bounded Liquidity",
          "abstract": "We derive the arbitrage gains or, equivalently, Loss Versus Rebalancing (LVR) for arbitrage between \\textit{two imperfectly liquid} markets, extending prior work that assumes the existence of an infinitely liquid reference market. Our result highlights that the LVR depends on the relative liquidity and relative trading volume of the two markets between which arbitrage gains are extracted. Our model assumes that trading costs on at least one of the markets is quadratic. This assumption holds well in practice, with the exception of highly liquid major pairs on centralized exchanges, for which we discuss extensions to other cost functions.",
          "authors": [
            "Christoph Schlegel",
            "Quintus Kilbourn"
          ],
          "primary_category": "q-fin.MF",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.02179",
          "title": "A general polynomial emulator for cosmology via moment projection",
          "abstract": "We present MomentEmu, a general-purpose polynomial emulator for fast and interpretable mappings between theoretical parameters and observational features. The method constructs moment matrices to project simulation data onto polynomial bases, yielding symbolic expressions that approximate the target mapping. Compared to neural-network-based emulators, MomentEmu offers negligible training cost, millisecond-level evaluation, and transparent functional forms. As a proof-of-concept demonstration, we develop two emulators: PolyCAMB-$D_\\ell$, which maps six cosmological parameters to the CMB power spectra (TT, EE, BB, TE), and PolyCAMB-peak, which enables a bidirectional mapping between the cosmological parameters and the acoustic peak features of $D_\\ell^{\\rm TT}$. PolyCAMB-$D_\\ell$ achieves sub-percent accuracy over multipoles $\\ell \\leq 4050$, while PolyCAMB-peak also attains comparable precision and produces symbolic forms consistent with known analytical approximations. The method is well suited for forward modelling, parameter inference, and uncertainty propagation, particularly when the parameter space is moderate in dimensionality and the mapping is smooth. MomentEmu offers a lightweight and portable alternative to regression-based or black-box emulators in cosmological analysis.",
          "authors": [
            "Zheng Zhang"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.02179",
          "title": "A general polynomial emulator for cosmology via moment projection",
          "abstract": "We present MomentEmu, a general-purpose polynomial emulator for fast and interpretable mappings between theoretical parameters and observational features. The method constructs moment matrices to project simulation data onto polynomial bases, yielding symbolic expressions that approximate the target mapping. Compared to neural-network-based emulators, MomentEmu offers negligible training cost, millisecond-level evaluation, and transparent functional forms. As a proof-of-concept demonstration, we develop two emulators: PolyCAMB-$D_\\ell$, which maps six cosmological parameters to the CMB power spectra (TT, EE, BB, TE), and PolyCAMB-peak, which enables a bidirectional mapping between the cosmological parameters and the acoustic peak features of $D_\\ell^{\\rm TT}$. PolyCAMB-$D_\\ell$ achieves sub-percent accuracy over multipoles $\\ell \\leq 4050$, while PolyCAMB-peak also attains comparable precision and produces symbolic forms consistent with known analytical approximations. The method is well suited for forward modelling, parameter inference, and uncertainty propagation, particularly when the parameter space is moderate in dimensionality and the mapping is smooth. MomentEmu offers a lightweight and portable alternative to regression-based or black-box emulators in cosmological analysis.",
          "authors": [
            "Zheng Zhang"
          ],
          "primary_category": "astro-ph.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.04070",
          "title": "XISM: an eXploratory and Interactive Graph Tool to Visualize and Evaluate Semantic Map Models",
          "abstract": "Semantic map models visualize systematic relations among semantic functions through graph structures and are widely used in linguistic typology. However, existing construction methods either depend on labor-intensive expert reasoning or on fully automated systems lacking expert involvement, creating a tension between scalability and interpretability. We introduce \\textbf{XISM}, an interactive system that combines data-driven inference with expert knowledge. XISM generates candidate maps via a top-down procedure and allows users to iteratively refine edges in a visual interface, with real-time metric feedback. Experiments in three semantic domains and expert interviews show that XISM improves linguistic decision transparency and controllability in semantic-map construction while maintaining computational efficiency. XISM provides a collaborative approach for scalable and interpretable semantic-map building. The system\\footnote{ this https URL } , source code\\footnote{ this https URL } , and demonstration video\\footnote{ this https URL } are publicly available.",
          "authors": [
            "Zhu Liu",
            "Zhen Hu",
            "Lei Dai",
            "Yu Xuan",
            "Ying Liu"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.05749",
          "title": "Event-Time Anchor Selection for Multi-Contract Quoting",
          "abstract": "When quoting across multiple contracts, the sequence of execution can be a key driver of implementation shortfall relative to the target spread~\\cite{bergault2022multi}. We model the short-horizon execution risk from such quoting as variations in transaction prices between the initiation of the first leg and the completion of the position. Our quoting policy anchors the spread by designating one contract ex ante as a \\emph{reference contract}. Reducing execution risk requires a predictive criterion for selecting that contract whose price is most stable over the execution interval. This paper develops a diagnostic framework for reference-contract selection that evaluates this stability by contrasting order-flow Hawkes forecasts with a Composite Liquidity Factor (CLF) of instantaneous limit order book (LOB) shape. We illustrate the framework on tick-by-tick data for a pair of NIFTY futures contracts. The results suggest that event-history and LOB-state signals offer complementary views of short-horizon execution risk for reference-contract selection.",
          "authors": [
            "Aditya Nittur Anantha",
            "Shashi Jain",
            "Shivam Goyal",
            "Dhruv Misra"
          ],
          "primary_category": "q-fin.TR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06171",
          "title": "Data-Semantics-Aware Recommendation of Diverse Pivot Tables",
          "abstract": "Data summarization is essential to discover insights from large datasets. In a spreadsheets, pivot tables offer a convenient way to summarize tabular data by computing aggregates over some attributes, grouped by others. However, identifying attribute combinations that will result in useful pivot tables remains a challenge, especially for high-dimensional datasets. We formalize the problem of automatically recommending insightful and interpretable pivot tables, eliminating the tedious manual process. A crucial aspect of recommending a set of pivot tables is to diversify them. Traditional works inadequately address the table-diversification problem, which leads us to consider the problem of pivot table diversification. We present SAGE, a data-semantics-aware system for recommending k-budgeted diverse pivot tables, overcoming the shortcomings of prior work for top-k recommendations that cause redundancy. SAGE ensures that each pivot table is insightful, interpretable, and adaptive to the user's actions and preferences, while also guaranteeing that the set of pivot tables are different from each other, offering a diverse recommendation. We make two key technical contributions: (1) a data-semantics-aware model to measure the utility of a single pivot table and the diversity of a set of pivot tables, and (2) a scalable greedy algorithm that can efficiently select a set of diverse pivot tables of high utility, by leveraging data semantics to significantly reduce the combinatorial search space. Our extensive experiments on three real-world datasets show that SAGE outperforms alternative approaches, and efficiently scales to accommodate high-dimensional datasets. Additionally, we present several case studies to highlight SAGE's qualitative effectiveness over commercial software and Large Language Models (LLMs).",
          "authors": [
            "Whanhee Cho",
            "Anna Fariha"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06192",
          "title": "SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads",
          "abstract": "Database research and development often require a large number of SQL queries for benchmarking purposes. However, acquiring real-world SQL queries is challenging due to privacy concerns, and existing SQL generation methods are limited in customization and in satisfying realistic constraints. To address this issue, we present SQLBarber, a system based on Large Language Models (LLMs) to generate customized and realistic SQL workloads. SQLBarber (i) eliminates the need for users to manually craft SQL templates in advance, while providing the flexibility to accept natural language specifications to constrain SQL templates, (ii) scales efficiently to generate large volumes of queries matching any user-defined cost distribution (e.g., cardinality and execution plan cost), and (iii) uses execution statistics from Amazon Redshift and Snowflake to derive SQL template specifications and query cost distributions that reflect real-world query characteristics. SQLBarber introduces (i) a declarative interface for users to effortlessly generate customized SQL templates, (ii) an LLM-powered pipeline augmented with a self-correction module that profiles, refines, and prunes SQL templates based on query costs, and (iii) a Bayesian Optimizer to efficiently explore different predicate values and identify a set of queries that satisfy the target cost distribution. We construct and open-source ten benchmarks of varying difficulty levels and target query cost distributions based on real-world statistics from Snowflake and Amazon Redshift. Extensive experiments on these benchmarks show that SQLBarber is the only system that can generate customized SQL templates. It reduces query generation time by one to three orders of magnitude, and significantly improves alignment with the target cost distribution, compared with existing methods.",
          "authors": [
            "Jiale Lao",
            "Immanuel Trummer"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06483",
          "title": "Animating Language Practice: Engagement with Stylized Conversational Agents in Japanese Learning",
          "abstract": "We explore Jouzu, a Japanese language learning application that integrates large language models with anime-inspired conversational agents. Designed to address challenges learners face in practicing natural and expressive dialogue, Jouzu combines stylized character personas with expressive text-to-speech to create engaging conversational scenarios. We conducted a two-week in-the-wild deployment with 52 Japanese learners to examine how such stylized agents influence engagement and learner experience. Our findings show that participants interacted frequently and creatively, with advanced learners demonstrating greater use of expressive forms. Participants reported that the anime-inspired style made practice more enjoyable and encouraged experimenting with different registers. We discuss how stylization shapes willingness to engage, the role of affect in sustaining practice, and design opportunities for culturally grounded conversational AI in computer-assisted language learning (CALL). By framing our findings as an exploration of design and engagement, we highlight opportunities for generalization beyond Japanese contexts and contribute to international HCI scholarship.",
          "authors": [
            "Zackary Rackauckas",
            "Julia Hirschberg"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.06968",
          "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report",
          "abstract": "Instruction tuning has become a foundation for unlocking the capabilities of large-scale pretrained models and improving their performance on complex tasks. Thus, the construction of high-quality instruction datasets is crucial for enhancing model performance and generalizability. Although current instruction datasets have reached tens of millions of samples, models finetuned on them may still struggle with complex instruction following and tasks in rare domains. This is primarily due to limited expansion in both ``coverage'' (coverage of task types and knowledge areas) and ``depth'' (instruction complexity) of the instruction set. To address this issue, we propose a systematic instruction data construction framework, which integrates a hierarchical labeling system, an informative seed selection algorithm, an evolutionary data synthesis process, and a model deficiency diagnosis with targeted data generation. These components form an iterative closed-loop to continuously enhance the coverage and depth of instruction data. Based on this framework, we construct InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million instructions. Experiments on multiple foundation models and benchmark tasks demonstrate its effectiveness in improving instruction-following capabilities. Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage and depth compared to comparable synthesized instruction datasets. Our work lays a theoretical and practical foundation for the efficient, continuous evolution of instruction datasets, moving from data quantity expansion to qualitative improvement.",
          "authors": [
            "Li Du",
            "Hanyu Zhao",
            "Yiming Ju",
            "Tengfei Pan"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.08355",
          "title": "scE2TM improves single-cell embedding interpretability and reveals cellular perturbation signatures",
          "abstract": "Single-cell RNA sequencing technologies have revolutionized our understanding of cellular heterogeneity, yet computational methods often struggle to balance performance with biological interpretability. Embedded topic models have been widely used for interpretable single-cell embedding learning. However, these models suffer from the potential problem of interpretation collapse, where topics semantically collapse towards each other, resulting in redundant topics and incomplete capture of biological variation. Furthermore, the rise of single-cell foundation models creates opportunities to harness external biological knowledge for guiding model embeddings. Here, we present scE2TM, an external knowledge-guided embedded topic model that provides a high-quality cell embedding and interpretation for scRNA-seq analysis. Through embedding clustering regularization method, each topic is constrained to be the center of a separately aggregated gene cluster, enabling it to capture unique biological information. Across 20 scRNA-seq datasets, scE2TM achieves superior clustering performance compared with seven state-of-the-art methods. A comprehensive interpretability benchmark further shows that scE2TM-learned topics exhibit higher diversity and stronger consistency with underlying biological pathways. Modeling interferon-stimulated PBMCs, scE2TM simulates topic perturbations that drive control cells toward stimulated-like transcriptional states, faithfully mirroring experimental interferon responses. In melanoma, scE2TM identifies malignant-specific topics and extrapolates them to unseen patient data, revealing gene programs associated with patient survival.",
          "authors": [
            "Hegang Chen",
            "Yuyin Lu",
            "Yifan Zhao",
            "Zhiming Dai",
            "Fu Lee Wang",
            "Qing Li",
            "Yanghui Rao",
            "Yue Li"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.09481",
          "title": "Evaluating LLMs on Sequential API Call Through Automated Test Generation",
          "abstract": "By integrating tools from external APIs, Large Language Models (LLMs) have expanded their promising capabilities in a diverse spectrum of complex real-world tasks. However, testing, evaluation, and analysis of LLM tool use remain in their early stages. Most existing benchmarks rely on manually collected test cases, many of which cannot be automatically checked for semantic correctness and instead depend on static methods such as string matching. Additionally, these benchmarks often overlook the complex interactions that occur between sequential API calls, which are common in real-world applications. To fill the gap, in this paper, we introduce StateGen, an automated framework designed to generate diverse coding tasks involving sequential API interactions. StateGen combines state-machine-based API constraint solving and validation, energy-based sampling, and control-flow injection to generate executable programs. These programs are then translated into human-like natural language task descriptions through a collaboration of two LLM agents. Utilizing StateGen, we construct StateEval, a benchmark encompassing 120 verified test cases spanning across three representative scenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental results confirm that StateGen can effectively generate challenging and realistic API-oriented tasks, highlighting areas for improvement in current LLMs incorporating this http URL make our framework and benchmark publicly available to support future research.",
          "authors": [
            "Yuheng Huang",
            "Jiayang Song",
            "Da Song",
            "Zhenlan Ji",
            "Wenhan Wang",
            "Shuai Wang",
            "Lei Ma"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.14270",
          "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation",
          "abstract": "We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both optimization-efficient and elegant. The proposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i + \\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters $\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to $96.69\\%$ test accuracy within 11 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and training efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it. Source code is available at this https URL .",
          "authors": [
            "Ravin Kumar"
          ],
          "primary_category": "cs.NE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.15530",
          "title": "Bayesian Separation Logic",
          "abstract": "Bayesian probabilistic programming languages (BPPLs) let users denote statistical models as code while the interpreter infers the posterior distribution. The semantics of BPPLs are usually mathematically complex and unable to reason about desirable properties such as expected values and independence of random variables. To reason about these properties in a non-Bayesian setting, probabilistic separation logics such as PSL and Lilac interpret separating conjunction as probabilistic independence of random variables. However, no existing separation logic can handle Bayesian updating, which is the key distinguishing feature of BPPLs. To close this gap, we introduce Bayesian separation logic (BaSL), a probabilistic separation logic that gives semantics to BPPL. We prove an internal version of Bayes' theorem using a result in measure theory known as the Rokhlin-Simmons disintegration theorem. Consequently, BaSL can model probabilistic programming concepts such as Bayesian updating, unnormalised distribution, conditional distribution, soft constraint, conjugate prior and improper prior while maintaining modularity via the frame rule. The model of BaSL is based on a novel instantiation of Kripke resource monoid via $\\sigma$-finite measure spaces over the Hilbert cube, and the semantics of Hoare triple is compatible with an existing denotational semantics of BPPL based on the category of $s$-finite kernels. Using BaSL, we then prove properties of statistical models such as the expected value of Bayesian coin flip, correlation of random variables in the collider Bayesian network, the posterior distributions of the burglar alarm model, a parameter estimation algorithm, and the Gaussian mixture model.",
          "authors": [
            "Shing Hin Ho",
            "Nicolas Wu",
            "Azalea Raad"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.15810",
          "title": "Empirical Likelihood Based Inference for a Divergence Measure Based on Survival Extropy",
          "abstract": "Survival extropy, which quantifies the uncertainty associated with the remaining lifetime distribution, provides an information-theoretic perspective on survival behavior. We consider a divergence measure based on survival extropy and derive its nonparametric estimators based on U-statistics, empirical distribution functions, and kernel density. Further, we construct confidence intervals for the divergence measure using the jackknife empirical likelihood (JEL) method and the normal approximation method with a jackknife pseudo-value-based variance estimator. A comprehensive Monte Carlo simulation study is conducted to compare the performance of the measure with existing divergence measures. Additionally, we evaluate the finite-sample performance of various estimators for the proposed measure. The findings highlight the effectiveness of the divergence measure and its estimators in practical applications. Finally, we show how the proposed divergence measure is used to detect the small differences between images in image datasets.",
          "authors": [
            "Naresh Garg",
            "Isha Dewan",
            "Sudheesh Kumar Kattumannil"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.15810",
          "title": "Empirical Likelihood Based Inference for a Divergence Measure Based on Survival Extropy",
          "abstract": "Survival extropy, which quantifies the uncertainty associated with the remaining lifetime distribution, provides an information-theoretic perspective on survival behavior. We consider a divergence measure based on survival extropy and derive its nonparametric estimators based on U-statistics, empirical distribution functions, and kernel density. Further, we construct confidence intervals for the divergence measure using the jackknife empirical likelihood (JEL) method and the normal approximation method with a jackknife pseudo-value-based variance estimator. A comprehensive Monte Carlo simulation study is conducted to compare the performance of the measure with existing divergence measures. Additionally, we evaluate the finite-sample performance of various estimators for the proposed measure. The findings highlight the effectiveness of the divergence measure and its estimators in practical applications. Finally, we show how the proposed divergence measure is used to detect the small differences between images in image datasets.",
          "authors": [
            "Naresh Garg",
            "Isha Dewan",
            "Sudheesh Kumar Kattumannil"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.19551",
          "title": "Rainbow Noise: Stress-Testing Multimodal Harmful-Meme Detectors on LGBTQ Content",
          "abstract": "Hateful memes aimed at LGBTQ\\,+ communities often evade detection by tweaking either the caption, the image, or both. We build the first robustness benchmark for this setting, pairing four realistic caption attacks with three canonical image corruptions and testing all combinations on the PrideMM dataset. Two state-of-the-art detectors, MemeCLIP and MemeBLIP2, serve as case studies, and we introduce a lightweight \\textbf{Text Denoising Adapter (TDA)} to enhance the latter's resilience. Across the grid, MemeCLIP degrades more gently, while MemeBLIP2 is particularly sensitive to the caption edits that disrupt its language processing. However, the addition of the TDA not only remedies this weakness but makes MemeBLIP2 the most robust model overall. Ablations reveal that all systems lean heavily on text, but architectural choices and pre-training data significantly impact robustness. Our benchmark exposes where current multimodal safety models crack and demonstrates that targeted, lightweight modules like the TDA offer a powerful path towards stronger defences.",
          "authors": [
            "Ran Tong",
            "Songtao Wei",
            "Jiaqi Liu",
            "Lanruo Wang"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2507.22052",
          "title": "Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos",
          "abstract": "We present Ov3R, a novel framework for open-vocabulary semantic 3D reconstruction from RGB video streams, designed to advance Spatial AI. The system features two key components: CLIP3R, a CLIP-informed 3D reconstruction module that predicts dense point maps from overlapping clips while embedding object-level semantics; and 2D-3D OVS, a 2D-3D open-vocabulary semantic module that lifts 2D features into 3D by learning fused descriptors integrating spatial, geometric, and semantic cues. Unlike prior methods, Ov3R incorporates CLIP semantics directly into the reconstruction process, enabling globally consistent geometry and fine-grained semantic alignment. Our framework achieves state-of-the-art performance in both dense 3D reconstruction and open-vocabulary 3D segmentation, marking a step forward toward real-time, semantics-aware Spatial AI.",
          "authors": [
            "Ziren Gong",
            "Xiaohan Li",
            "Fabio Tosi",
            "Jiawei Han",
            "Stefano Mattoccia",
            "Jianfei Cai",
            "Matteo Poggi"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.01504",
          "title": "Instruction-based Time Series Editing",
          "abstract": "In time series editing, we aim to modify some properties of a given time series without altering others. For example, when analyzing a hospital patient's blood pressure, we may add a sudden early drop and observe how it impacts their future while preserving other conditions. Existing diffusion-based editors rely on rigid, predefined attribute vectors as conditions and produce all-or-nothing edits through sampling. This attribute- and sampling-based approach limits flexibility in condition format and lacks customizable control over editing strength. To overcome these limitations, we introduce Instruction-based Time Series Editing, where users specify intended edits using natural language. This allows users to express a wider range of edits in a more accessible format. We then introduce InstructTime, the first instruction-based time series editor. InstructTime takes in time series and instructions, embeds them into a shared multi-modal representation space, then decodes their embeddings to generate edited time series. By learning a structured multi-modal representation space, we can easily interpolate between embeddings to achieve varying degrees of edit. To handle local and global edits together, we propose multi-resolution encoders. In our experiments, we use synthetic and real datasets and find that InstructTime is a state-of-the-art time series editor: InstructTime achieves high-quality edits with controllable strength, can generalize to unseen instructions, and can be easily adapted to unseen conditions through few-shot learning.",
          "authors": [
            "Jiaxing Qiu",
            "Dongliang Guo",
            "Brynne Sullivan",
            "Teague R. Henry",
            "Tom Hartvigsen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.02443",
          "title": "PRIMU: Uncertainty Estimation for Novel Views in Gaussian Splatting from Primitive-Based Representations of Error and Coverage",
          "abstract": "We introduce Primitive-based Representations of Uncertainty (PRIMU), a post-hoc uncertainty estimation (UE) framework for Gaussian Splatting (GS). Reliable UE is essential for deploying GS in safety-critical domains such as robotics and medicine. Existing approaches typically estimate Gaussian-primitive variances and rely on the rendering process to obtain pixel-wise uncertainties. In contrast, we construct primitive-level representations of error and visibility/coverage from training views, capturing interpretable uncertainty information. These representations are obtained by projecting view-dependent training errors and coverage statistics onto the primitives. Uncertainties for novel views are inferred by rendering these primitive-level representations, producing uncertainty feature maps, which are aggregate through pixel-wise regression on holdout data. We analyze combinations of uncertainty feature maps and regression models to understand how their interactions affect prediction accuracy and generalization. PRIMU also enables an effective active view selection strategy by directly leveraging these uncertainty feature maps. Additionally, we study the effect of separating splatting into foreground and background regions. Our estimates show strong correlations with true errors, outperforming state-of-the-art methods, especially for depth UE and foreground objects. Finally, our regression models show generalization capabilities to unseen scenes, enabling UE without additional holdout data.",
          "authors": [
            "Thomas Gottwald",
            "Edgar Heinert",
            "Peter Stehr",
            "Chamuditha Jayanga Galappaththige",
            "Matthias Rottmann"
          ],
          "primary_category": "cs.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.02566",
          "title": "Dynamic Feature Selection based on Rule-based Learning for Explainable Classification with Uncertainty Quantification",
          "abstract": "Dynamic feature selection (DFS) offers a compelling alternative to traditional, static feature selection by adapting the selected features to each individual sample. This provides insights into the decision-making process for each case, which makes DFS especially significant in settings where decision transparency is key, i.e., clinical decisions. However, existing DFS methods use opaque models, which hinder their applicability in real-life scenarios. DFS also introduces new own sources of uncertainty compared to the static setting, which is also not considered in the existing literature. In this paper, we formalize the additional sources of uncertainty in DFS, and give formulas to estimate them. We also propose novel approach by leveraging a rule-based system as a base classifier for the DFS process, which enhances decision interpretability compared to neural estimators. Finally, we demonstrate the competitive performance of our rule-based DFS approach against established and state-of-the-art greedy and reinforcement learning methods, which are mostly considered opaque, compared to our explainable rulebased system.",
          "authors": [
            "Javier Fumanal-Idocin",
            "Raquel Fernandez-Peralta",
            "Javier Andreu-Perez"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.03079",
          "title": "Bias Beyond Demographics: Probing Decision Boundaries in Black-Box LVLMs via Counterfactual VQA",
          "abstract": "Recent advances in large vision-language models (LVLMs) have amplified concerns about fairness, yet existing evaluations remain confined to demographic attributes and often conflate fairness with refusal behavior. This paper broadens the scope of fairness by introducing a counterfactual VQA benchmark that probes the decision boundaries of closed-source LVLMs under controlled context shifts. Each image pair differs in a single visual attribute that has been validated as irrelevant to the question, enabling ground-truth-free and refusal-aware analysis of reasoning stability. Comprehensive experiments reveal that non-demographic attributes, such as environmental context or social behavior, distort LVLM decision-making more strongly than demographic ones. Moreover, instruction-based debiasing shows limited effectiveness and can even amplify these asymmetries, whereas exposure to a small number of human norm validated examples from our benchmark encourages more consistent and balanced responses, highlighting its potential not only as an evaluative framework but also as a means for understanding and improving model behavior. Together, these results provide a practial basis for auditing contextual biases even in black-box LVLMs and contribute to more transparent and equitable multimodal reasoning.",
          "authors": [
            "Zaiying Zhao",
            "Toshihiko Yamasaki"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.03692",
          "title": "LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences",
          "abstract": "Generative world models have become essential data engines for autonomous driving, yet most existing efforts focus on videos or occupancy grids, overlooking the unique LiDAR properties. Extending LiDAR generation to dynamic 4D world modeling presents challenges in controllability, temporal coherence, and evaluation standardization. To this end, we present LiDARCrafter, a unified framework for 4D LiDAR generation and editing. Given free-form natural language inputs, we parse instructions into ego-centric scene graphs, which condition a tri-branch diffusion network to generate object structures, motion trajectories, and geometry. These structured conditions enable diverse and fine-grained scene editing. Additionally, an autoregressive module generates temporally coherent 4D LiDAR sequences with smooth transitions. To support standardized evaluation, we establish a comprehensive benchmark with diverse metrics spanning scene-, object-, and sequence-level aspects. Experiments on the nuScenes dataset using this benchmark demonstrate that LiDARCrafter achieves state-of-the-art performance in fidelity, controllability, and temporal consistency across all levels, paving the way for data augmentation and simulation. The code and benchmark are released to the community.",
          "authors": [
            "Ao Liang",
            "Youquan Liu",
            "Yu Yang",
            "Dongyue Lu",
            "Linfeng Li",
            "Lingdong Kong",
            "Huaici Zhao",
            "Wei Tsang Ooi"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.04295",
          "title": "EvoC2Rust: A Skeleton-guided Framework for Project-Level C-to-Rust Translation",
          "abstract": "Translating legacy C codebases to Rust is increasingly demanded for building safety-critical systems. While various approaches have emerged for this task, they face inherent trade-offs: rule-based methods often struggle to satisfy code safety and idiomaticity requirements, while LLM-based methods frequently fail to generate semantically equivalent Rust code, due to the heavy dependencies of modules across the entire codebase. Recent studies have revealed that both solutions are limited to small-scale programs. In this paper, we propose EvoC2Rust, an automated framework for converting complete C projects to equivalent Rust ones. EvoC2Rust employs a skeleton-guided translation strategy for project-level translation. The pipeline consists of three stages: 1) it first decomposes the C project into functional modules, employs a feature-mapping-enhanced LLM to transform definitions and macros, and generates type-checked function stubs, which form a compilable Rust skeleton; 2) it then incrementally translates functions, replacing the corresponding stub placeholders; 3) finally, it repairs compilation errors by integrating LLM and static analysis. Through evolutionary augmentation, EvoC2Rust combines the advantages of both rule-based and LLM-based solutions. Our evaluation on open-source benchmarks and six industrial projects demonstrates the superior performance of EvoC2Rust in project-level C-to-Rust translation. The results show that our approach outperforms the strongest LLM-based baseline by 17.24% in syntax accuracy and 14.32% in semantic accuracy, while also achieving a 43.59% higher code safety rate than the best rule-based tool.",
          "authors": [
            "Chaofan Wang",
            "Tingrui Yu",
            "Chen Xie",
            "Jie Wang",
            "Dong Chen",
            "Wenrui Zhang",
            "Yuling Shi",
            "Xiaodong Gu",
            "Beijun Shen"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.04979",
          "title": "Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression",
          "abstract": "Diffusion-based image compression has demonstrated impressive perceptual performance. However, it suffers from two critical drawbacks: (1) excessive decoding latency due to multi-step sampling, and (2) poor fidelity resulting from over-reliance on generative priors. To address these issues, we propose SODEC, a novel single-step diffusion image compression model. We argue that in image compression, a sufficiently informative latent renders multi-step refinement unnecessary. Based on this insight, we leverage a pre-trained VAE-based model to produce latents with rich information, and replace the iterative denoising process with a single-step decoding. Meanwhile, to improve fidelity, we introduce the fidelity guidance module, encouraging output that is faithful to the original image. Furthermore, we design the rate annealing training strategy to enable effective training under extremely low bitrates. Extensive experiments show that SODEC significantly outperforms existing methods, achieving superior rate-distortion-perception performance. Moreover, compared to previous diffusion-based compression models, SODEC improves decoding speed by more than 20$\\times$. Code is released at: this https URL .",
          "authors": [
            "Zheng Chen",
            "Mingde Zhou",
            "Jinpei Guo",
            "Jiale Yuan",
            "Yifei Ji",
            "Yulun Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.05452",
          "title": "LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models",
          "abstract": "Existing evaluation of Large Language Models (LLMs) on static benchmarks is vulnerable to data contamination and leaderboard overfitting, critical issues that obscure true model capabilities. To address this, we introduce LLMEval-3, a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary bank of 220k graduate-level questions, from which it dynamically samples unseen test sets for each evaluation run. Its automated pipeline ensures integrity via contamination-resistant data curation, a novel anti-cheating architecture, and a calibrated LLM-as-a-judge process achieving 90% agreement with human experts, complemented by a relative ranking system for fair comparison. An 20-month longitudinal study of nearly 50 leading models reveals a performance ceiling on knowledge memorization and exposes data contamination vulnerabilities undetectable by static benchmarks. The framework demonstrates exceptional robustness in ranking stability and consistency, providing strong empirical validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and credible methodology for assessing the true capabilities of LLMs beyond leaderboard scores, promoting the development of more trustworthy evaluation standards.",
          "authors": [
            "Ming Zhang",
            "Yujiong Shen",
            "Jingyi Deng",
            "Yuhui Wang",
            "Yue Zhang",
            "Junzhe Wang",
            "Shichun Liu",
            "Shihan Dou",
            "Huayu Sha",
            "Qiyuan Peng",
            "Changhao Jiang",
            "Jingqi Tong",
            "Yilong Wu",
            "Zhihao Zhang",
            "Mingqi Wu",
            "Zhiheng Xi",
            "Mingxu Chai",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.07114",
          "title": "Increasing Information Extraction in Low-Signal Regimes via Multiple Instance Learning",
          "abstract": "In this work, we introduce a new information-theoretic perspective on Multiple Instance Learning (MIL) for parameter estimation with i.i.d. data, and show that MIL can outperform single-instance learners in low-signal regimes. Prior work [Nachman and Thaler, 2021] argued that single-instance methods are often sufficient, but this conclusion presumes enough single-instance signal to train near-optimal classifiers. We demonstrate that even state-of-the-art single-instance models can fail to reach optimal classifier performance in challenging low-signal regimes, whereas MIL can mitigate this sub-optimality. As a concrete application, we constrain Wilson coefficients of the Standard Model Effective Field Theory (SMEFT) using kinematic information from subatomic particle collision events at the Large Hadron Collider (LHC). In experiments, we observe that under specific modeling and weak signal conditions, pooling instances can increase the effective Fisher information compared to single-instance approaches.",
          "authors": [
            "Atakan Azakli",
            "Bernd Stelzer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.07114",
          "title": "Increasing Information Extraction in Low-Signal Regimes via Multiple Instance Learning",
          "abstract": "In this work, we introduce a new information-theoretic perspective on Multiple Instance Learning (MIL) for parameter estimation with i.i.d. data, and show that MIL can outperform single-instance learners in low-signal regimes. Prior work [Nachman and Thaler, 2021] argued that single-instance methods are often sufficient, but this conclusion presumes enough single-instance signal to train near-optimal classifiers. We demonstrate that even state-of-the-art single-instance models can fail to reach optimal classifier performance in challenging low-signal regimes, whereas MIL can mitigate this sub-optimality. As a concrete application, we constrain Wilson coefficients of the Standard Model Effective Field Theory (SMEFT) using kinematic information from subatomic particle collision events at the Large Hadron Collider (LHC). In experiments, we observe that under specific modeling and weak signal conditions, pooling instances can increase the effective Fisher information compared to single-instance approaches.",
          "authors": [
            "Atakan Azakli",
            "Bernd Stelzer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.08864",
          "title": "Autonomous thermodynamically informed database generation for machine-learned interatomic potentials and application to magnesium",
          "abstract": "We propose a novel approach for constructing training databases for Machine-Learned Interatomic Potential (MLIP) models, specifically designed to capture phase properties across a wide range of conditions. The framework is uniquely appealing due to its ease of automation, its suitability for iterative learning, and its independence from prior knowledge of stable phases, avoiding bias towards pre-existing structural data. The approach uses Nested Sampling (NS) to explore the configuration space and generate thermodynamically relevant configurations, forming the database which undergoes ab initio Density Functional Theory (DFT) evaluation. We use the Atomic Cluster Expansion (ACE) architecture to fit a model on the resulting database. To demonstrate the efficiency of the framework, we apply it to magnesium, developing a model capable of accurately describing behaviour across pressure and temperature ranges of 0-600 GPa and 0-8000 K, respectively. We benchmark the model's performance by calculating phonon spectra and elastic constants, as well as the pressure-temperature phase diagram within this region. The results showcase the power of the framework to produce robust MLIPs while maintaining transferability and generality, for reduced computational cost.",
          "authors": [
            "Vincent G. Fletcher",
            "Albert P. Bartók",
            "Livia B. Pártay"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09042",
          "title": "LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback",
          "abstract": "Although large language models (LLMs) hold significant promise in psychotherapy, their direct application in patient-facing scenarios raises ethical and safety concerns. Therefore, this work shifts towards developing an LLM as a supervisor to train real therapists. In addition to the privacy of clinical therapist training data, a fundamental contradiction complicates the training of therapeutic behaviors: clear feedback standards are necessary to ensure a controlled training system, yet there is no absolute \"gold standard\" for appropriate therapeutic behaviors in practice. In contrast, many common therapeutic mistakes are universal and identifiable, making them effective triggers for targeted feedback that can serve as clearer evidence. Motivated by this, we create a novel therapist-training paradigm: (1) guidelines for mistaken behaviors and targeted correction strategies are first established as standards; (2) a human-in-the-loop dialogue-feedback dataset is then constructed, where a mistake-prone agent intentionally makes standard mistakes during interviews naturally, and a supervisor agent locates and identifies mistakes and provides targeted feedback; (3) after fine-tuning on this dataset, the final supervisor model is provided for real therapist training. The detailed experimental results of automated, human and downstream assessments demonstrate that models fine-tuned on our dataset MATE, can provide high-quality feedback according to the clinical guideline, showing significant potential for the therapist training scenario.",
          "authors": [
            "Chen Xu",
            "Zhenyu Lv",
            "Tian Lan",
            "Xianyang Wang",
            "Luyao Ji",
            "Leyang Cui",
            "Minqiang Yang",
            "Jian Shen",
            "Qunxi Dong",
            "Xiuling Liu",
            "Juan Wang",
            "Bin Hu"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09200",
          "title": "Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction",
          "abstract": "To investigate the feasibility of zero-shot self-supervised learning reconstruction for reducing breath-hold times in magnetic resonance cholangiopancreatography (MRCP). Breath-hold MRCP was acquired from 11 healthy volunteers on 3T scanners using an incoherent k-space sampling pattern, leading to 14-second acquisition time and an acceleration factor of R=25. Zero-shot reconstruction was compared with parallel imaging of respiratory-triggered MRCP (338s, R=3) and compressed sensing reconstruction. For two volunteers, breath-hold scans (40s, R=6) were additionally acquired and retrospectively undersampled to R=25 to compute peak signal-to-noise ratio (PSNR). To address long zero-shot training time, the n+m full stages of the zero-shot learning were divided into two parts to reduce backpropagation depth during training: 1) n frozen stages initialized with n-stage pretrained network and 2) m trainable stages initialized either randomly or m-stage pretrained network. Efficiency of our approach was assessed by varying initialization strategies and the number of trainable stages using the retrospectively undersampled data. Zero-shot reconstruction significantly improved visual image quality over compressed sensing, particularly in SNR and ductal delineation, and achieved image quality comparable to that of successful respiratory-triggered acquisitions with regular breathing patterns. Improved initializations enhanced PSNR and reduced reconstruction time. Adjusting frozen/trainable configurations demonstrated that PSNR decreased only slightly from 38.25 dB (0/13) to 37.67 dB (12/1), while training time decreased up to 6.7-fold. Zero-shot learning delivers high-fidelity MRCP reconstructions with reduced breath-hold times, and the proposed partially trainable approach offers a practical solution for translation into time-constrained clinical workflows.",
          "authors": [
            "Jinho Kim",
            "Marcel Dominik Nickel",
            "Florian Knoll"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.09200",
          "title": "Zero-shot self-supervised learning of single breath-hold magnetic resonance cholangiopancreatography (MRCP) reconstruction",
          "abstract": "To investigate the feasibility of zero-shot self-supervised learning reconstruction for reducing breath-hold times in magnetic resonance cholangiopancreatography (MRCP). Breath-hold MRCP was acquired from 11 healthy volunteers on 3T scanners using an incoherent k-space sampling pattern, leading to 14-second acquisition time and an acceleration factor of R=25. Zero-shot reconstruction was compared with parallel imaging of respiratory-triggered MRCP (338s, R=3) and compressed sensing reconstruction. For two volunteers, breath-hold scans (40s, R=6) were additionally acquired and retrospectively undersampled to R=25 to compute peak signal-to-noise ratio (PSNR). To address long zero-shot training time, the n+m full stages of the zero-shot learning were divided into two parts to reduce backpropagation depth during training: 1) n frozen stages initialized with n-stage pretrained network and 2) m trainable stages initialized either randomly or m-stage pretrained network. Efficiency of our approach was assessed by varying initialization strategies and the number of trainable stages using the retrospectively undersampled data. Zero-shot reconstruction significantly improved visual image quality over compressed sensing, particularly in SNR and ductal delineation, and achieved image quality comparable to that of successful respiratory-triggered acquisitions with regular breathing patterns. Improved initializations enhanced PSNR and reduced reconstruction time. Adjusting frozen/trainable configurations demonstrated that PSNR decreased only slightly from 38.25 dB (0/13) to 37.67 dB (12/1), while training time decreased up to 6.7-fold. Zero-shot learning delivers high-fidelity MRCP reconstructions with reduced breath-hold times, and the proposed partially trainable approach offers a practical solution for translation into time-constrained clinical workflows.",
          "authors": [
            "Jinho Kim",
            "Marcel Dominik Nickel",
            "Florian Knoll"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.10201",
          "title": "B-repLer: Language-guided Editing of CAD Models",
          "abstract": "Computer-Aided Design (CAD) models, given their compactness and precision, remain the industry standard for designing and fabricating engineering objects. However, language-guided CAD editing is still in its infancy, largely due to missing semantic connection between user commands and underlying shape geometry, a problem exacerbated by the shortage of paired text-and-edit CAD datasets. While recent Multimodal Large Language Models (mLLMs) have attempted to bridge this gap, their reliance on CAD construction history --often an expensive and hard to obtain input-- severely limits their expressiveness and restricts their usage. We present B-repLer, a novel framework that directly connects natural language with editing CAD models by operating in a learned latent space. Importantly, our approach bypasses the need for construction history, enabling semantic edits on a wide range of geometries, from simple prismatic parts to complex freeform shapes defined by B-Spline surfaces. To facilitate this research, we introduce BrepEDIT-240K, the first large-scale dataset for this task. We demonstrate how this paired dataset can be automatically generated, (user) validated, and scaled by leveraging existing CAD tools, in conjunction with mLLMs, to create the required paired data without relying on any external annotations. Our results demonstrate that B-repLer can accurately perform complex edits on complex CAD shapes, even when the input edit specifications are high-level and ambiguous to interpret, consistently producing valid, high-quality CAD outputs enabling a class of text-guided edits not previously possible.",
          "authors": [
            "Yilin Liu",
            "Niladri Shekhar Dutt",
            "Changjian Li",
            "Niloy J. Mitra"
          ],
          "primary_category": "cs.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.12726",
          "title": "DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning",
          "abstract": "Large language models (LLMs) have achieved remarkable success in many natural language tasks but still struggle with complex, multi-step reasoning, particularly across diverse disciplines. Existing reasoning datasets often lack disciplinary breadth, reasoning depth, and diversity, as well as guiding principles for question synthesis. We propose DESIGNER: a DESIGN-logic-guidEd Reasoning data synthesis pipeline that leverages naturally available, extensive raw documents (e.g., book corpus and web corpus) to generate multidisciplinary challenging questions. We introduce the concept of \"design logic\" and instruct LLMs to mimic human educators' question-creation process, enabling the automated synthesis of large-scale, high-difficulty questions. We use LLMs to reverse-engineer and abstract over 120,000 design logics from existing questions across various disciplines. By matching these design logics with source documents, we are able to generate reasoning questions with controllable question types and difficulty levels. Using this pipeline, we synthesized two large-scale reasoning datasets that span 75 disciplines: DLR-Book (3.04 million questions from the book corpus) and DLR-Web (1.66 million questions from the web corpus). Data analysis indicates that the questions synthesized by our method exhibit greater difficulty and diversity compared to those in the baseline datasets. We validate our synthesized data through supervised fine-tuning (SFT) on the Qwen3 and Llama3 model families. Our data substantially enhances their multidisciplinary reasoning capabilities, outperforming existing datasets. Notably, by applying SFT on the base versions of these models using only our data, we even surpass their official final models that have undergone the full post-training process.",
          "authors": [
            "Weize Liu",
            "Yongchi Zhao",
            "Yijia Luo",
            "Mingyu Xu",
            "Jiaheng Liu",
            "Yanan Li",
            "Xiguo Hu",
            "Zhiqi Bai",
            "Yuchi Xu",
            "Wenbo Su",
            "Bo Zheng"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.12792",
          "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap",
          "abstract": "Large language models are increasingly used as judges (LLM-as-a-judge) to evaluate model outputs at scale, but their assessments often diverge systematically from human judgments. We present Bridge, a unified statistical framework that explicitly bridges human and LLM evaluations under both absolute scoring and pairwise comparison paradigms. Bridge posits a latent human preference score for each prompt-response pair and models LLM deviations as linear transformations of covariates that capture sources of discrepancies. This offers a simple and principled framework for refining LLM ratings and characterizing systematic discrepancies between humans and LLMs. We provide an efficient fitting algorithm with asymptotic guarantees for statistical inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot Arena), Bridge achieves higher agreement with human ratings (accuracy, calibration, and KL divergence) and exposes systematic human-LLM gaps.",
          "authors": [
            "Felipe Maia Polo",
            "Xinhe Wang",
            "Mikhail Yurochkin",
            "Gongjun Xu",
            "Moulinath Banerjee",
            "Yuekai Sun"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.12792",
          "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap",
          "abstract": "Large language models are increasingly used as judges (LLM-as-a-judge) to evaluate model outputs at scale, but their assessments often diverge systematically from human judgments. We present Bridge, a unified statistical framework that explicitly bridges human and LLM evaluations under both absolute scoring and pairwise comparison paradigms. Bridge posits a latent human preference score for each prompt-response pair and models LLM deviations as linear transformations of covariates that capture sources of discrepancies. This offers a simple and principled framework for refining LLM ratings and characterizing systematic discrepancies between humans and LLMs. We provide an efficient fitting algorithm with asymptotic guarantees for statistical inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot Arena), Bridge achieves higher agreement with human ratings (accuracy, calibration, and KL divergence) and exposes systematic human-LLM gaps.",
          "authors": [
            "Felipe Maia Polo",
            "Xinhe Wang",
            "Mikhail Yurochkin",
            "Gongjun Xu",
            "Moulinath Banerjee",
            "Yuekai Sun"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.13024",
          "title": "WebMall - A Multi-Shop Benchmark for Evaluating Web Agents [Technical Report]",
          "abstract": "LLM-based web agents have the potential to automate long-running web tasks, such as searching for products in multiple e-shops and subsequently ordering the cheapest products that meet the users needs. Benchmarks for evaluating web agents either require agents to perform tasks online using the live Web or offline using simulated environments, which allow for the exact reproduction of the experimental setup. While DeepShop provides an online benchmark that requires agents to perform challenging shopping tasks, existing offline benchmarks such as WebShop, WebArena, or Mind2Web cover only comparatively simple e-commerce tasks that need to be performed against a single shop containing product data from a single source. What is missing is an e-commerce benchmark that simulates multiple shops containing heterogeneous product data and requires agents to perform complex tasks. We fill this gap by introducing WebMall, the first offline multi-shop benchmark for evaluating web agents on challenging comparison shopping tasks. WebMall consists of four simulated shops populated with product data extracted from the Common Crawl. The WebMall tasks range from specific product searches and price comparisons to advanced queries for complementary or substitute products, as well as checkout processes. We validate WebMall using eight agents that differ in observation space, availability of short-term memory, and the employed LLM. The validation highlights the difficulty of the benchmark, with even the best-performing agents achieving task completion rates below 55% in the task categories cheapest product search and vague product search.",
          "authors": [
            "Ralph Peeters",
            "Aaron Steiner",
            "Luca Schwarz",
            "Julian Yuya Caspary",
            "Christian Bizer"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.13377",
          "title": "MaxWave: Rapid maximum likelihood wavelet reconstruction of non-Gaussian features in gravitational wave data",
          "abstract": "Advancements in the sensitivity of gravitational wave detectors have increased the detection rate of transient astrophysical signals. We improve the existing BayesWave initialization algorithm and present a rapid, low latency approximate maximum likelihood solution for reconstructing non-Gaussian features. We include three enhancements: (1) using a modified wavelet basis to eliminate redundant inner product calculations; (2) shifting from traditional time-frequency-quality factor wavelet transforms to time-frequency-time extent transforms to optimize wavelet subtractions; and (3) implementing a downsampled heterodyned wavelet transform to accelerate initial calculations. Our model can be used to denoise long-duration signals, which include the stochastic gravitational wave background from numerous unresolved sources and continuous wave signals from isolated sources such as rotating neutron stars. Through our model, we can also supplement machine learning applications that use spectrographic training data to classify and understand glitches by providing nonwhitened, time and frequency domain reconstructions of any glitch.",
          "authors": [
            "Sudhi Mathur",
            "Neil J. Cornish"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.13377",
          "title": "MaxWave: Rapid maximum likelihood wavelet reconstruction of non-Gaussian features in gravitational wave data",
          "abstract": "Advancements in the sensitivity of gravitational wave detectors have increased the detection rate of transient astrophysical signals. We improve the existing BayesWave initialization algorithm and present a rapid, low latency approximate maximum likelihood solution for reconstructing non-Gaussian features. We include three enhancements: (1) using a modified wavelet basis to eliminate redundant inner product calculations; (2) shifting from traditional time-frequency-quality factor wavelet transforms to time-frequency-time extent transforms to optimize wavelet subtractions; and (3) implementing a downsampled heterodyned wavelet transform to accelerate initial calculations. Our model can be used to denoise long-duration signals, which include the stochastic gravitational wave background from numerous unresolved sources and continuous wave signals from isolated sources such as rotating neutron stars. Through our model, we can also supplement machine learning applications that use spectrographic training data to classify and understand glitches by providing nonwhitened, time and frequency domain reconstructions of any glitch.",
          "authors": [
            "Sudhi Mathur",
            "Neil J. Cornish"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.13482",
          "title": "Cross-Cancer Knowledge Transfer in WSI-based Prognosis Prediction",
          "abstract": "Whole-Slide Image (WSI) is an important tool for estimating cancer prognosis. Current studies generally follow a conventional cancer-specific paradigm in which each cancer corresponds to a single model. However, this paradigm naturally struggles to scale to rare tumors and cannot leverage knowledge from other cancers. While multi-task learning frameworks have been explored recently, they often place high demands on computational resources and require extensive training on ultra-large, multi-cancer WSI datasets. To this end, this paper shifts the paradigm to knowledge transfer and presents the first preliminary yet systematic study on cross-cancer prognosis knowledge transfer in WSIs, called CROPKT. It comprises three major parts. (1) We curate a large dataset (UNI2-h-DSS) with 26 cancers and use it to measure the transferability of WSI-based prognostic knowledge across different cancers (including rare tumors). (2) Beyond a simple evaluation merely for benchmarking, we design a range of experiments to gain deeper insights into the underlying mechanism behind transferability. (3) We further show the utility of cross-cancer knowledge transfer, by proposing a routing-based baseline approach (ROUPKT) that could often efficiently utilize the knowledge transferred from off-the-shelf models of other cancers. CROPKT could serve as an inception that lays the foundation for this nascent paradigm, i.e., WSI-based prognosis prediction with cross-cancer knowledge transfer. Our source code is available at this https URL .",
          "authors": [
            "Pei Liu",
            "Luping Ji",
            "Jiaxiang Gou",
            "Xiangxiang Zeng"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.13482",
          "title": "Cross-Cancer Knowledge Transfer in WSI-based Prognosis Prediction",
          "abstract": "Whole-Slide Image (WSI) is an important tool for estimating cancer prognosis. Current studies generally follow a conventional cancer-specific paradigm in which each cancer corresponds to a single model. However, this paradigm naturally struggles to scale to rare tumors and cannot leverage knowledge from other cancers. While multi-task learning frameworks have been explored recently, they often place high demands on computational resources and require extensive training on ultra-large, multi-cancer WSI datasets. To this end, this paper shifts the paradigm to knowledge transfer and presents the first preliminary yet systematic study on cross-cancer prognosis knowledge transfer in WSIs, called CROPKT. It comprises three major parts. (1) We curate a large dataset (UNI2-h-DSS) with 26 cancers and use it to measure the transferability of WSI-based prognostic knowledge across different cancers (including rare tumors). (2) Beyond a simple evaluation merely for benchmarking, we design a range of experiments to gain deeper insights into the underlying mechanism behind transferability. (3) We further show the utility of cross-cancer knowledge transfer, by proposing a routing-based baseline approach (ROUPKT) that could often efficiently utilize the knowledge transferred from off-the-shelf models of other cancers. CROPKT could serve as an inception that lays the foundation for this nascent paradigm, i.e., WSI-based prognosis prediction with cross-cancer knowledge transfer. Our source code is available at this https URL .",
          "authors": [
            "Pei Liu",
            "Luping Ji",
            "Jiaxiang Gou",
            "Xiangxiang Zeng"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.14083",
          "title": "GeoMAE: Masking Representation Learning for Spatio-Temporal Graph Forecasting with Missing Values",
          "abstract": "The ubiquity of missing data in urban intelligence systems, attributable to adverse environmental conditions and equipment failures, poses a significant challenge to the efficacy of downstream applications, notably in the realms of traffic forecasting and energy consumption prediction. Therefore, it is imperative to develop a robust spatio-temporal learning methodology capable of extracting meaningful insights from incomplete datasets. Despite the existence of methodologies for spatio-temporal graph forecasting in the presence of missing values, unresolved issues persist. Primarily, the majority of extant research is predicated on time-series analysis, thereby neglecting the dynamic spatial correlations inherent in sensor networks. Additionally, the complexity of missing data patterns compounds the intricacy of the problem. Furthermore, the variability in maintenance conditions results in a significant fluctuation in the ratio and pattern of missing values, thereby challenging the generalizability of predictive models. In response to these challenges, this study introduces GeoMAE, a self-supervised spatio-temporal representation learning model. The model is comprised of three principal components: an input preprocessing module, an attention-based spatio-temporal forecasting network (STAFN), and an auxiliary learning task, which draws inspiration from Masking AutoEncoders to enhance the robustness of spatio-temporal representation learning. Empirical evaluations on real-world datasets demonstrate that GeoMAE significantly outperforms existing benchmarks, achieving up to 13.20\\% relative improvement over the best baseline models.",
          "authors": [
            "Songyu Ke",
            "Chenyu Wu",
            "Yuxuan Liang",
            "Huiling Qin",
            "Junbo Zhang",
            "Yu Zheng"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.14101",
          "title": "Implicit Hypergraph Neural Network",
          "abstract": "Hypergraphs offer a generalized framework for capturing high-order relationships between entities and have been widely applied in various domains, including healthcare, social networks, and bioinformatics. Hypergraph neural networks, which rely on message-passing between nodes over hyperedges to learn latent representations, have emerged as the method of choice for predictive tasks in many of these domains. These approaches typically perform only a small number of message-passing rounds to learn the representations, which they then utilize for predictions. The small number of message-passing rounds comes at a cost, as the representations only capture local information and forego long-range high-order dependencies. However, as we demonstrate, blindly increasing the message-passing rounds to capture long-range dependency also degrades the performance of hyper-graph neural networks. Recent works have demonstrated that implicit graph neural networks capture long-range dependencies in standard graphs while maintaining performance. Despite their popularity, prior work has not studied long-range dependency issues on hypergraph neural networks. Here, we first demonstrate that existing hypergraph neural networks lose predictive power when aggregating more information to capture long-range dependency. We then propose Implicit Hypergraph Neural Network (IHNN), a novel framework that jointly learns fixed-point representations for both nodes and hyperedges in an end-to-end manner to alleviate this issue. Leveraging implicit differentiation, we introduce a tractable projected gradient descent approach to train the model efficiently. Extensive experiments on real-world hypergraphs for node classification demonstrate that IHNN outperforms the closest prior works in most settings, establishing a new state-of-the-art in hypergraph learning.",
          "authors": [
            "Akash Choudhuri",
            "Yongjian Zhong",
            "Bijaya Adhikari"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.15690",
          "title": "GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning",
          "abstract": "GRAFT is a structured multimodal benchmark designed to probe how well LLMs handle instruction following, visual reasoning, and tasks requiring tight visual textual alignment. The dataset is built around programmatically generated charts and synthetically rendered tables, each paired with a carefully constructed, multi step analytical question that depends solely on what can be inferred from the image itself. Responses are formatted in structured outputs such as JSON or YAML, enabling consistent and fine grained evaluation of both reasoning processes and adherence to output specifications. The benchmark further introduces a taxonomy of reasoning operations ranging from comparison and trend identification to ranking, aggregation, proportional estimation, and anomaly detection to support a comprehensive assessment of model capabilities. Taken together, GRAFT provides a unified and scalable framework for evaluating multimodal LLMs on visually grounded, structured reasoning tasks, offering a more rigorous standard for future benchmarking efforts.",
          "authors": [
            "Abhigya Verma",
            "Sriram Puttagunta",
            "Seganrasan Subramanian",
            "Sravan Ramachandran"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.16873",
          "title": "Multimodal LLMs See Sentiment",
          "abstract": "Understanding how visual content communicates sentiment is critical in an era where online interaction is increasingly dominated by this kind of media on social platforms. However, this remains a challenging problem, as sentiment perception is closely tied to complex, scene-level semantics. In this paper, we propose an original framework, MLLMsent, to investigate the sentiment reasoning capabilities of Multimodal Large Language Models (MLLMs) through three perspectives: (1) using those MLLMs for direct sentiment classification from images; (2) associating them with pre-trained LLMs for sentiment analysis on automatically generated image descriptions; and (3) fine-tuning the LLMs on sentiment-labeled image descriptions. Experiments on a recent and established benchmark demonstrate that our proposal, particularly the fine-tuned approach, achieves state-of-the-art results outperforming Lexicon-, CNN-, and Transformer-based baselines by up to 30.9%, 64.8%, and 42.4%, respectively, across different levels of evaluators' agreement and sentiment polarity categories. Remarkably, in a cross-dataset test, without any training on these new data, our model still outperforms, by up to 8.26%, the best runner-up, which has been trained directly on them. These results highlight the potential of the proposed visual reasoning scheme for advancing affective computing, while also establishing new benchmarks for future research.",
          "authors": [
            "Neemias B. da Silva",
            "John Harrison",
            "Rodrigo Minetto",
            "Myriam R. Delgado",
            "Bogdan T. Nassu",
            "Thiago H. Silva"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.18175",
          "title": "Amortized Sampling with Transferable Normalizing Flows",
          "abstract": "Efficient equilibrium sampling of molecular conformations remains a core challenge in computational chemistry and statistical inference. Classical approaches such as molecular dynamics or Markov chain Monte Carlo inherently lack amortization; the computational cost of sampling must be paid in full for each system of interest. The widespread success of generative models has inspired interest towards overcoming this limitation through learning sampling algorithms. Despite performing competitively with conventional methods when trained on a single system, learned samplers have so far demonstrated limited ability to transfer across systems. We demonstrate that deep learning enables the design of scalable and transferable samplers by introducing Prose, a 285 million parameter all-atom transferable normalizing flow trained on a corpus of peptide molecular dynamics trajectories up to 8 residues in length. Prose draws zero-shot uncorrelated proposal samples for arbitrary peptide systems, achieving the previously intractable transferability across sequence length, whilst retaining the efficient likelihood evaluation of normalizing flows. Through extensive empirical evaluation we demonstrate the efficacy of Prose as a proposal for a variety of sampling algorithms, finding a simple importance sampling-based finetuning procedure to achieve competitive performance to established methods such as sequential Monte Carlo. We open-source the Prose codebase, model weights, and training dataset, to further stimulate research into amortized sampling methods and finetuning objectives.",
          "authors": [
            "Charlie B. Tan",
            "Majdi Hassan",
            "Leon Klein",
            "Saifuddin Syed",
            "Dominique Beaini",
            "Michael M. Bronstein",
            "Alexander Tong",
            "Kirill Neklyudov"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.19112",
          "title": "Random forest-based out-of-distribution detection for robust lung cancer segmentation",
          "abstract": "Accurate detection and segmentation of cancerous lesions from computed tomography (CT) scans is essential for automated treatment planning and cancer treatment response assessment. Transformer-based models with self-supervised pretraining have achieved strong performance on in-distribution (ID) data but often generalize poorly on out-of-distribution (OOD) inputs. We investigate this behavior for lung cancer segmentation using an encoder-decoder model. Our encoder is a Swin Transformer pretrained with masked image modeling (SimMIM) on 10,432 unlabeled 3D CT scans spanning cancerous and non-cancerous conditions, and the decoder was randomly initialized. This model was evaluated on an independent ID test set and four OOD scenarios, including chest CT cohorts (pulmonary embolism and negative COVID-19) and abdomen CT cohorts (kidney cancers and non-cancerous pancreas). OOD detection was performed at the scan level using RF-Deep, a random forest classifier applied to contextual tumor-anchored feature representations. We evaluated 920 3D CTs (172,650 images) and observed that RF-Deep achieved FPR95 values of 18.26% and 27.66% on the chest CT cohorts, and near-perfect detection (less than 0.1% FPR95) on the abdomen CT cohorts, consistently outperforming established OOD methods. These results demonstrate that our RF-Deep classifier provides a simple, lightweight, and effective approach for enhancing the reliability of segmentation models in clinical deployment.",
          "authors": [
            "Aneesh Rangnekar",
            "Harini Veeraraghavan"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.19112",
          "title": "Random forest-based out-of-distribution detection for robust lung cancer segmentation",
          "abstract": "Accurate detection and segmentation of cancerous lesions from computed tomography (CT) scans is essential for automated treatment planning and cancer treatment response assessment. Transformer-based models with self-supervised pretraining have achieved strong performance on in-distribution (ID) data but often generalize poorly on out-of-distribution (OOD) inputs. We investigate this behavior for lung cancer segmentation using an encoder-decoder model. Our encoder is a Swin Transformer pretrained with masked image modeling (SimMIM) on 10,432 unlabeled 3D CT scans spanning cancerous and non-cancerous conditions, and the decoder was randomly initialized. This model was evaluated on an independent ID test set and four OOD scenarios, including chest CT cohorts (pulmonary embolism and negative COVID-19) and abdomen CT cohorts (kidney cancers and non-cancerous pancreas). OOD detection was performed at the scan level using RF-Deep, a random forest classifier applied to contextual tumor-anchored feature representations. We evaluated 920 3D CTs (172,650 images) and observed that RF-Deep achieved FPR95 values of 18.26% and 27.66% on the chest CT cohorts, and near-perfect detection (less than 0.1% FPR95) on the abdomen CT cohorts, consistently outperforming established OOD methods. These results demonstrate that our RF-Deep classifier provides a simple, lightweight, and effective approach for enhancing the reliability of segmentation models in clinical deployment.",
          "authors": [
            "Aneesh Rangnekar",
            "Harini Veeraraghavan"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2508.21393",
          "title": "VeriLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs",
          "abstract": "Fine-tuning large language models (LLMs) is crucial for adapting them to specific tasks, yet it remains computationally demanding and raises concerns about correctness and privacy, particularly in untrusted environments. Although parameter-efficient methods like Low-Rank Adaptation (LoRA) significantly reduce resource requirements, ensuring the security and verifiability of fine-tuning under zero-knowledge constraints remains an unresolved challenge. To address this, we introduce VeriLoRA, the first framework to integrate LoRA fine-tuning with zero-knowledge proofs (ZKPs), achieving provable security and correctness. VeriLoRA employs advanced cryptographic techniques -- such as lookup arguments, sumcheck protocols, and polynomial commitments -- to verify both arithmetic and non-arithmetic operations in Transformer-based architectures. The framework provides end-to-end verifiability for forward propagation, backward propagation, and parameter updates during LoRA fine-tuning, while safeguarding the privacy of model parameters and training data. Leveraging GPU-based implementations, VeriLoRA demonstrates practicality and efficiency through experimental validation on open-source LLMs like LLaMA, scaling up to 13 billion parameters. By combining parameter-efficient fine-tuning with ZKPs, VeriLoRA bridges a critical gap, enabling secure and trustworthy deployment of LLMs in sensitive or untrusted environments.",
          "authors": [
            "Guofu Liao",
            "Taotao Wang",
            "Shengli Zhang",
            "Jiqun Zhang",
            "Shi Long",
            "Dacheng Tao"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.00360",
          "title": "ChopChop: a Programmable Framework for Semantically Constraining the Output of Language Models",
          "abstract": "Language models (LMs) can generate code but cannot guarantee its correctness$\\unicode{x2014}$often producing outputs that violate type safety, program invariants, or other semantic properties. Constrained decoding offers a solution by restricting generation to only produce programs that satisfy user-defined properties. However, existing methods are either limited to syntactic constraints or rely on brittle, ad hoc encodings of semantic properties over token sequences rather than program structure. We present ChopChop, the first programmable framework for constraining the output of LMs with respect to semantic properties. ChopChop introduces a principled way to construct constrained decoders based on analyzing the space of programs a prefix represents. It formulates this analysis as a realizability problem which is solved via coinduction, connecting token-level generation with structural reasoning over programs. We demonstrate ChopChop's generality by using it to enforce (1) equivalence to a reference program and (2) type safety. Across a range of models and tasks, ChopChop improves success rates while maintaining practical decoding latency.",
          "authors": [
            "Shaan Nagy",
            "Timothy Zhou",
            "Nadia Polikarpova",
            "Loris D'Antoni"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.02191",
          "title": "Simulating classification models to evaluate Predict-Then-Optimize methods",
          "abstract": "Uncertainty in optimization is often represented as stochastic parameters in the optimization model. In Predict-Then-Optimize approaches, predictions of a machine learning model are used as values for such parameters, effectively transforming the stochastic optimization problem into a deterministic one. This two-stage framework is built on the assumption that more accurate predictions result in solutions that are closer to the actual optimal solution. However, providing evidence for this assumption in the context of complex, constrained optimization problems is challenging and often overlooked in the literature. Simulating predictions of machine learning models offers a way to (experimentally) analyze how prediction error impacts solution quality without the need to train real models. Complementing an algorithm from the literature for simulating binary classification, we introduce a new algorithm for simulating predictions of multiclass classifiers. We conduct a computational study to evaluate the performance of these algorithms, and show that classifier performance can be simulated with reasonable accuracy, although some variability is observed. Additionally, we apply these algorithms to assess the performance of a Predict-Then-Optimize algorithm for a machine scheduling problem. The experiments demonstrate that the relationship between prediction error and how close solutions are to the actual optimum is non-trivial, highlighting important considerations for the design and evaluation of decision-making systems based on machine learning predictions.",
          "authors": [
            "Pieter Smet"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.04443",
          "title": "EMMA: Scaling Mobile Manipulation via Egocentric Human Data",
          "abstract": "Scaling mobile manipulation imitation learning is bottlenecked by expensive mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA), an end-to-end framework training mobile manipulation policies from human mobile manipulation data with static robot data, sidestepping mobile teleoperation. To accomplish this, we co-train human full-body motion data with static robot data. In our experiments across three real-world tasks, EMMA demonstrates comparable performance to baselines trained on teleoperated mobile robot data (Mobile ALOHA), achieving higher or equivalent task performance in full task success. We find that EMMA is able to generalize to new spatial configurations and scenes, and we observe positive performance scaling as we increase the hours of human data, opening new avenues for scalable robotic learning in real-world environments. Details of this project can be found at this https URL .",
          "authors": [
            "Lawrence Y. Zhu",
            "Pranav Kuppili",
            "Ryan Punamiya",
            "Patcharapong Aphiwetsa",
            "Dhruv Patel",
            "Simar Kareer",
            "Sehoon Ha",
            "Danfei Xu"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.04466",
          "title": "Just-in-time and distributed task representations in language models",
          "abstract": "Many of language models' impressive capabilities originate from their in-context learning: based on instructions or examples, they can infer and perform new tasks without weight updates. In this work, we investigate when representations for new tasks are formed in language models, and how these representations change over the course of context. We study two different task representations: those that are ''transferrable'' -- vector representations that can transfer task contexts to another model instance, even without the full prompt -- and simpler representations of high-level task categories. We show that transferrable task representations evolve in non-monotonic and sporadic ways, while task identity representations persist throughout the context. Specifically, transferrable task representations exhibit a two-fold locality. They successfully condense evidence when more examples are provided in the context. But this evidence accrual process exhibits strong temporal locality along the sequence dimension, coming online only at certain tokens -- despite task identity being reliably decodable throughout the context. In some cases, transferrable task representations also show semantic locality, capturing a small task ''scope'' such as an independent subtask. Language models thus represent new tasks on the fly through both an inert, sustained sensitivity to the task and an active, just-in-time representation to support inference.",
          "authors": [
            "Yuxuan Li",
            "Declan Campbell",
            "Stephanie C. Y. Chan",
            "Andrew Kyle Lampinen"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.04699",
          "title": "CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals",
          "abstract": "Hand gesture classification using high-quality structured data such as videos, images, and hand skeletons is a well-explored problem in computer vision. Leveraging low-power, cost-effective biosignals, e.g. surface electromyography (sEMG), allows for continuous gesture prediction on wearables. In this paper, we demonstrate that learning representations from weak-modality data that are aligned with those from structured, high-quality data can improve representation quality and enables zero-shot classification. Specifically, we propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and pose representations, where we learn an EMG encoder that produces high-quality and pose-informative representations. We assess the gesture classification performance of our model through linear probing and zero-shot setups. Our model outperforms emg2pose benchmark models by up to 21% on in-distribution gesture classification and 72% on unseen (out-of-distribution) gesture classification.",
          "authors": [
            "Wenhui Cui",
            "Christopher Sandino",
            "Hadi Pouransari",
            "Ran Liu",
            "Juri Minxha",
            "Ellen Zippi",
            "Aman Verma",
            "Anna Sedlackova",
            "Erdrin Azemi",
            "Behrooz Mahasseni"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.04699",
          "title": "CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals",
          "abstract": "Hand gesture classification using high-quality structured data such as videos, images, and hand skeletons is a well-explored problem in computer vision. Leveraging low-power, cost-effective biosignals, e.g. surface electromyography (sEMG), allows for continuous gesture prediction on wearables. In this paper, we demonstrate that learning representations from weak-modality data that are aligned with those from structured, high-quality data can improve representation quality and enables zero-shot classification. Specifically, we propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and pose representations, where we learn an EMG encoder that produces high-quality and pose-informative representations. We assess the gesture classification performance of our model through linear probing and zero-shot setups. Our model outperforms emg2pose benchmark models by up to 21% on in-distribution gesture classification and 72% on unseen (out-of-distribution) gesture classification.",
          "authors": [
            "Wenhui Cui",
            "Christopher Sandino",
            "Hadi Pouransari",
            "Ran Liu",
            "Juri Minxha",
            "Ellen Zippi",
            "Aman Verma",
            "Anna Sedlackova",
            "Erdrin Azemi",
            "Behrooz Mahasseni"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.06996",
          "title": "Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems",
          "abstract": "Writing is a universal cultural technology that reuses vision for symbolic communication. Humans display striking resilience: we readily recognize words even when characters are fragmented, fused, or partially occluded. This paper investigates whether advanced vision language models (VLMs) share this resilience. We construct two psychophysics inspired benchmarks across distinct writing systems, Chinese logographs and English alphabetic words, by splicing, recombining, and overlaying glyphs to yield ''visible but unreadable'' stimuli for models while remaining legible to humans. Despite strong performance on clean text, contemporary VLMs show a severe drop under these perturbations, frequently producing unrelated or incoherent outputs. The pattern suggests a structural limitation: models heavily leverage generic visual invariances but under rely on compositional priors needed for robust literacy. We release stimuli generation code, prompts, and evaluation protocols to facilitate transparent replication and follow up work. Our findings motivate architectures and training strategies that encode symbol segmentation, composition, and binding across scripts, and they delineate concrete challenges for deploying multimodal systems in education, accessibility, cultural heritage, and security.",
          "authors": [
            "Jie Zhang",
            "Ting Xu",
            "Gelei Deng",
            "Runyi Hu",
            "Han Qiu",
            "Tianwei Zhang",
            "Qing Guo",
            "Ivor Tsang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.07424",
          "title": "Feed-O-Meter: Investigating AI-Generated Mentee Personas as Interactive Agents for Scaffolding Design Feedback Practice",
          "abstract": "Effective feedback, including critique and evaluation, helps designers develop design concepts and refine their ideas, supporting informed decision-making throughout the iterative design process. However, in studio-based design courses, students often struggle to provide feedback due to a lack of confidence and fear of being judged, which limits their ability to develop essential feedback-giving skills. Recent advances in large language models (LLMs) suggest that role-playing with AI agents can let learners engage in multi-turn feedback without the anxiety of external judgment or the time constraints of real-world settings. Yet prior studies have raised concerns that LLMs struggle to behave like real people in role-play scenarios, diminishing the educational benefits of these interactions. Therefore, designing AI-based agents that effectively support learners in practicing and developing intellectual reasoning skills requires more than merely assigning the target persona's personality and role to the agent. By addressing these issues, we present Feed-O-Meter, a novel system that employs carefully designed LLM-based agents to create an environment in which students can practice giving design feedback. The system enables users to role-play as mentors, providing feedback to an AI mentee and allowing them to reflect on how that feedback impacts the AI mentee's idea development process. A user study (N=24) indicated that Feed-O-Meter increased participants' engagement and motivation through role-switching and helped them adjust feedback to be more comprehensible for an AI mentee. Based on these findings, we discuss future directions for designing systems to foster feedback skills in design education.",
          "authors": [
            "Hyunseung Lim",
            "Dasom Choi",
            "DaEun Choi",
            "Sooyohn Nam",
            "Hwajung Hong"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.07451",
          "title": "Synthetic Data Generation with Lorenzetti for Time Series Anomaly Detection in High-Energy Physics Calorimeters",
          "abstract": "Anomaly detection in multivariate time series is crucial to ensure the quality of data coming from a physics experiment. Accurately identifying the moments when unexpected errors or defects occur is essential, yet challenging due to scarce labels, unknown anomaly types, and complex correlations across dimensions. To address the scarcity and unreliability of labelled data, we use the Lorenzetti Simulator to generate synthetic events with injected calorimeter anomalies. We then assess the sensitivity of several time series anomaly detection methods, including transformer-based and other deep learning models. The approach employed here is generic and applicable to different detector designs and defects.",
          "authors": [
            "Laura Boggia",
            "Bogdan Malaescu"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.07451",
          "title": "Synthetic Data Generation with Lorenzetti for Time Series Anomaly Detection in High-Energy Physics Calorimeters",
          "abstract": "Anomaly detection in multivariate time series is crucial to ensure the quality of data coming from a physics experiment. Accurately identifying the moments when unexpected errors or defects occur is essential, yet challenging due to scarce labels, unknown anomaly types, and complex correlations across dimensions. To address the scarcity and unreliability of labelled data, we use the Lorenzetti Simulator to generate synthetic events with injected calorimeter anomalies. We then assess the sensitivity of several time series anomaly detection methods, including transformer-based and other deep learning models. The approach employed here is generic and applicable to different detector designs and defects.",
          "authors": [
            "Laura Boggia",
            "Bogdan Malaescu"
          ],
          "primary_category": "hep-ex",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.08093",
          "title": "Evolution and compression in LLMs: On the emergence of human-aligned categorization",
          "abstract": "Converging evidence suggests that human systems of semantic categories achieve near-optimal compression via the Information Bottleneck (IB) complexity-accuracy tradeoff. Large language models (LLMs) are not trained for this objective, which raises the question: are LLMs capable of evolving efficient human-aligned semantic systems? To address this question, we focus on color categorization -- a key testbed of cognitive theories of categorization with uniquely rich human data -- and replicate with LLMs two influential human studies. First, we conduct an English color-naming study, showing that LLMs vary widely in their complexity and English-alignment, with larger instruction-tuned models achieving better alignment and IB-efficiency. Second, to test whether these LLMs simply mimic patterns in their training data or actually exhibit a human-like inductive bias toward IB-efficiency, we simulate cultural evolution of pseudo color-naming systems in LLMs via a method we refer to as Iterated in-Context Language Learning (IICLL). We find that akin to humans, LLMs iteratively restructure initially random systems towards greater IB-efficiency. However, only a model with strongest in-context capabilities (Gemini 2.0) is able to recapitulate the wide range of near-optimal IB-tradeoffs observed in humans, while other state-of-the-art models converge to low-complexity solutions. These findings demonstrate how human-aligned semantic categories can emerge in LLMs via the same fundamental principle that underlies semantic efficiency in humans.",
          "authors": [
            "Nathaniel Imel",
            "Noga Zaslavsky"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.11614",
          "title": "Vessel Detection and Localization Using Distributed Acoustic Sensing in Submarine Optical Fiber Cables",
          "abstract": "Submarine cables play a critical role in global internet connectivity, energy transmission, and communication but remain vulnerable to accidental damage and sabotage. Recent incidents in the Baltic Sea highlighted the need for enhanced monitoring to protect this vital infrastructure. Traditional vessel detection methods, such as synthetic aperture radar, video surveillance, and multispectral satellite imagery, face limitations in real-time processing, adverse weather conditions, and coverage range. This paper explores Distributed Acoustic Sensing (DAS) as an alternative by repurposing submarine telecommunication cables as large-scale acoustic sensor arrays. DAS offers continuous real-time monitoring, operates independently of cooperative systems like the \"Automatic Identification System\" (AIS), being largely unaffected by lighting or weather conditions. However, existing research on DAS for vessel tracking is limited in scale and lacks validation under real-world conditions. To address these gaps, a general and systematic methodology is presented for vessel detection and distance estimation using DAS. Advanced machine learning models are applied to improve detection and localization accuracy in dynamic maritime environments. The approach is evaluated over a continuous ten-day period, covering diverse ship and operational conditions, representing one of the largest-scale DAS-based vessel monitoring studies to date, and for which we release the full evaluation dataset. Results demonstrate DAS as a practical tool for maritime surveillance, with an overall F1-score of over 90% in vessel detection, and a mean average error of 141 m for vessel distance estimation, bridging the gap between experimental research and real-world deployment.",
          "authors": [
            "Erick Eduardo Ramirez-Torres",
            "Javier Macias-Guarasa",
            "Daniel Pizarro-Perez",
            "Javier Tejedor",
            "Sira Elena Palazuelos-Cagigas",
            "Pedro J. Vidal-Moreno",
            "Sonia Martin-Lopez",
            "Miguel Gonzalez-Herraez",
            "Roel Vanthillo"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.12326",
          "title": "Spontaneous Kolmogorov-Arnold Geometry in Shallow MLPs",
          "abstract": "The Kolmogorov-Arnold (KA) representation theorem constructs universal, but highly non-smooth inner functions (the first layer map) in a single (non-linear) hidden layer neural network. Such universal functions have a distinctive local geometry, a \"texture,\" which can be characterized by the inner function's Jacobian $J({\\mathbf{x}})$, as $\\mathbf{x}$ varies over the data. It is natural to ask if this distinctive KA geometry emerges through conventional neural network optimization. We find that indeed KA geometry often is produced when training vanilla single hidden layer neural networks. We quantify KA geometry through the statistical properties of the exterior powers of $J(\\mathbf{x})$: number of zero rows and various observables for the minor statistics of $J(\\mathbf{x})$, which measure the scale and axis alignment of $J(\\mathbf{x})$. This leads to a rough understanding for where KA geometry occurs in the space of function complexity and model hyperparameters. The motivation is first to understand how neural networks organically learn to prepare input data for later downstream processing and, second, to learn enough about the emergence of KA geometry to accelerate learning through a timely intervention in network hyperparameters. This research is the \"flip side\" of KA-Networks (KANs). We do not engineer KA into the neural network, but rather watch KA emerge in shallow MLPs.",
          "authors": [
            "Michael H. Freedman",
            "Michael Mulligan"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.12326",
          "title": "Spontaneous Kolmogorov-Arnold Geometry in Shallow MLPs",
          "abstract": "The Kolmogorov-Arnold (KA) representation theorem constructs universal, but highly non-smooth inner functions (the first layer map) in a single (non-linear) hidden layer neural network. Such universal functions have a distinctive local geometry, a \"texture,\" which can be characterized by the inner function's Jacobian $J({\\mathbf{x}})$, as $\\mathbf{x}$ varies over the data. It is natural to ask if this distinctive KA geometry emerges through conventional neural network optimization. We find that indeed KA geometry often is produced when training vanilla single hidden layer neural networks. We quantify KA geometry through the statistical properties of the exterior powers of $J(\\mathbf{x})$: number of zero rows and various observables for the minor statistics of $J(\\mathbf{x})$, which measure the scale and axis alignment of $J(\\mathbf{x})$. This leads to a rough understanding for where KA geometry occurs in the space of function complexity and model hyperparameters. The motivation is first to understand how neural networks organically learn to prepare input data for later downstream processing and, second, to learn enough about the emergence of KA geometry to accelerate learning through a timely intervention in network hyperparameters. This research is the \"flip side\" of KA-Networks (KANs). We do not engineer KA into the neural network, but rather watch KA emerge in shallow MLPs.",
          "authors": [
            "Michael H. Freedman",
            "Michael Mulligan"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.12326",
          "title": "Spontaneous Kolmogorov-Arnold Geometry in Shallow MLPs",
          "abstract": "The Kolmogorov-Arnold (KA) representation theorem constructs universal, but highly non-smooth inner functions (the first layer map) in a single (non-linear) hidden layer neural network. Such universal functions have a distinctive local geometry, a \"texture,\" which can be characterized by the inner function's Jacobian $J({\\mathbf{x}})$, as $\\mathbf{x}$ varies over the data. It is natural to ask if this distinctive KA geometry emerges through conventional neural network optimization. We find that indeed KA geometry often is produced when training vanilla single hidden layer neural networks. We quantify KA geometry through the statistical properties of the exterior powers of $J(\\mathbf{x})$: number of zero rows and various observables for the minor statistics of $J(\\mathbf{x})$, which measure the scale and axis alignment of $J(\\mathbf{x})$. This leads to a rough understanding for where KA geometry occurs in the space of function complexity and model hyperparameters. The motivation is first to understand how neural networks organically learn to prepare input data for later downstream processing and, second, to learn enough about the emergence of KA geometry to accelerate learning through a timely intervention in network hyperparameters. This research is the \"flip side\" of KA-Networks (KANs). We do not engineer KA into the neural network, but rather watch KA emerge in shallow MLPs.",
          "authors": [
            "Michael H. Freedman",
            "Michael Mulligan"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.13352",
          "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning",
          "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly used in defense, surveillance, and disaster response, yet most systems still operate at SAE Level 2 to 3 autonomy. Their dependence on rule-based control and narrow AI limits adaptability in dynamic and uncertain missions. Current UAV architectures lack context-aware reasoning, autonomous decision-making, and integration with external systems. Importantly, none make use of Large Language Model (LLM) agents with tool-calling for real-time knowledge access. This paper introduces the Agentic UAVs framework, a five-layer architecture consisting of Perception, Reasoning, Action, Integration, and Learning. The framework enhances UAV autonomy through LLM-driven reasoning, database querying, and interaction with third-party systems. A prototype built with ROS 2 and Gazebo combines YOLOv11 for object detection with GPT-4 for reasoning and a locally deployed Gemma 3 model. In simulated search-and-rescue scenarios, agentic UAVs achieved higher detection confidence (0.79 compared to 0.72), improved person detection rates (91% compared to 75%), and a major increase in correct action recommendations (92% compared to 4.5%). These results show that modest computational overhead can enable significantly higher levels of autonomy and system-level integration.",
          "authors": [
            "Anis Koubaa",
            "Khaled Gabr"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.13813",
          "title": "Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs",
          "abstract": "Large language models demonstrate impressive results across diverse tasks but are still known to hallucinate, generating linguistically plausible but incorrect answers to questions. Uncertainty quantification has been proposed as a strategy for hallucination detection, requiring estimates for both global uncertainty (attributed to a batch of responses) and local uncertainty (attributed to individual responses). While recent black-box approaches have shown some success, they often rely on disjoint heuristics or graph-theoretic approximations that lack a unified geometric interpretation. We introduce a geometric framework to address this, based on archetypal analysis of batches of responses sampled with only black-box model access. At the global level, we propose Geometric Volume, which measures the convex hull volume of archetypes derived from response embeddings. At the local level, we propose Geometric Suspicion, which leverages the spatial relationship between responses and these archetypes to rank reliability, enabling hallucination reduction through preferential response selection. Unlike prior methods that rely on discrete pairwise comparisons, our approach provides continuous semantic boundary points which have utility for attributing reliability to individual responses. Experiments show that our framework performs comparably to or better than prior methods on short form question-answering datasets, and achieves superior results on medical datasets where hallucinations carry particularly critical risks. We also provide theoretical justification by proving a link between convex hull volume and entropy.",
          "authors": [
            "Edward Phillips",
            "Sean Wu",
            "Soheila Molaei",
            "Danielle Belgrave",
            "Anshul Thakur",
            "David Clifton"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.14233",
          "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments",
          "abstract": "We present Apertus, a fully open suite of large language models (LLMs) designed to address two systemic shortcomings in today's open model ecosystem: data compliance and multilingual representation. Unlike many prior models that release weights without reproducible data pipelines or regard for content-owner rights, Apertus models are pretrained exclusively on openly available data, retroactively respecting ` this http URL ` exclusions and filtering for non-permissive, toxic, and personally identifiable content. To mitigate risks of memorization, we adopt the Goldfish objective during pretraining, strongly suppressing verbatim recall of data while retaining downstream task performance. The Apertus models also expand multilingual coverage, training on 15T tokens from over 1800 languages, with ~40% of pretraining data allocated to non-English content. Released at 8B and 70B scales, Apertus approaches state-of-the-art results among fully open models on multilingual benchmarks, rivalling or surpassing open-weight counterparts. Beyond model weights, we release all scientific artifacts from our development cycle with a permissive license, including data preparation scripts, checkpoints, evaluation suites, and training code, enabling transparent audit and extension.",
          "authors": [
            "Project Apertus",
            "Alejandro Hernández-Cano",
            "Alexander Hägele",
            "Allen Hao Huang",
            "Angelika Romanou",
            "Antoni-Joan Solergibert",
            "Barna Pasztor",
            "Bettina Messmer",
            "Dhia Garbaya",
            "Eduard Frank Ďurech",
            "Ido Hakimi",
            "Juan García Giraldo",
            "Mete Ismayilzada",
            "Negar Foroutan",
            "Skander Moalla",
            "Tiancheng Chen",
            "Vinko Sabolčec",
            "Yixuan Xu",
            "Michael Aerni",
            "Badr AlKhamissi",
            "Inés Altemir Mariñas",
            "Mohammad Hossein Amani",
            "Matin Ansaripour",
            "Ilia Badanin",
            "Harold Benoit",
            "Emanuela Boros",
            "Nicholas Browning",
            "Fabian Bösch",
            "Maximilian Böther",
            "Niklas Canova",
            "Camille Challier",
            "Clement Charmillot",
            "Jonathan Coles",
            "Jan Deriu",
            "Arnout Devos",
            "Lukas Drescher",
            "Daniil Dzenhaliou",
            "Maud Ehrmann",
            "Dongyang Fan",
            "Simin Fan",
            "Silin Gao",
            "Miguel Gila",
            "María Grandury",
            "Diba Hashemi",
            "Alexander Hoyle",
            "Jiaming Jiang",
            "Mark Klein",
            "Andrei Kucharavy",
            "Anastasiia Kucherenko",
            "Frederike Lübeck",
            "Roman Machacek",
            "Theofilos Manitaras",
            "Andreas Marfurt",
            "Kyle Matoba",
            "Simon Matrenok",
            "Henrique Mendonça",
            "Fawzi Roberto Mohamed",
            "Syrielle Montariol",
            "Luca Mouchel",
            "Sven Najem-Meyer",
            "Jingwei Ni",
            "Gennaro Oliva",
            "Matteo Pagliardini",
            "Elia Palme",
            "Andrei Panferov",
            "Léo Paoletti",
            "Marco Passerini",
            "Ivan Pavlov",
            "Auguste Poiroux",
            "Kaustubh Ponkshe",
            "Nathan Ranchin",
            "Javi Rando",
            "Mathieu Sauser",
            "Jakhongir Saydaliev",
            "Muhammad Ali Sayfiddinov",
            "Marian Schneider",
            "Stefano Schuppli",
            "Marco Scialanga",
            "Andrei Semenov",
            "Kumar Shridhar",
            "Raghav Singhal",
            "Anna Sotnikova",
            "Alexander Sternfeld",
            "Ayush Kumar Tarun",
            "Paul Teiletche",
            "Jannis Vamvas",
            "Xiaozhe Yao",
            "Hao Zhao",
            "Alexander Ilic",
            "Ana Klimovic",
            "Andreas Krause",
            "Caglar Gulcehre",
            "David Rosenthal",
            "Elliott Ash",
            "Florian Tramèr",
            "Joost VandeVondele",
            "Livio Veraldi",
            "Martin Rajman",
            "Thomas Schulthess",
            "Torsten Hoefler"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.16264",
          "title": "ParlAI Vote: A Web Platform for Analyzing Gender and Political Bias in Large Language Models",
          "abstract": "We present ParlAI Vote, an interactive web platform for exploring European Parliament debates and votes, and for testing LLMs on vote prediction and bias analysis. This web system connects debate topics, speeches, and roll-call outcomes, and includes rich demographic data such as gender, age, country, and political group. Users can browse debates, inspect linked speeches, compare real voting outcomes with predictions from frontier LLMs, and view error breakdowns by demographic group. Visualizing the EuroParlVote benchmark and its core tasks of gender classification and vote prediction, ParlAI Vote highlights systematic performance bias in state-of-the-art LLMs. It unifies data, models, and visual analytics in a single interface, lowering the barrier for reproducing findings, auditing behavior, and running counterfactual scenarios. This web platform also shows model reasoning, helping users see why errors occur and what cues the models rely on. It supports research, education, and public engagement with legislative decision-making, while making clear both the strengths and the limitations of current LLMs in political analysis.",
          "authors": [
            "Wenjie Lin",
            "Hange Liu",
            "Yingying Zhuang",
            "Xutao Mao",
            "Jingwei Shi",
            "Xudong Han",
            "Tianyu Shi",
            "Jinrui Yang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.17321",
          "title": "OpenGVL -- Benchmarking Visual Temporal Progress for Data Curation",
          "abstract": "Data scarcity remains one of the most limiting factors in driving progress in robotics. However, the amount of available robotics data in the wild is growing exponentially, creating new opportunities for large-scale data utilization. Reliable temporal task completion prediction could help automatically annotate and curate this data at scale. The Generative Value Learning (GVL) approach was recently proposed, leveraging the knowledge embedded in vision-language models (VLMs) to predict task progress from visual observations. Building upon GVL, we propose OpenGVL, a comprehensive benchmark for estimating task progress across diverse challenging manipulation tasks involving both robotic and human embodiments. We evaluate the capabilities of publicly available open-source foundation models, showing that open-source model families significantly underperform closed-source counterparts, achieving only approximately $70\\%$ of their performance on temporal progress prediction tasks. Furthermore, we demonstrate how OpenGVL can serve as a practical tool for automated data curation and filtering, enabling efficient quality assessment of large-scale robotics datasets. We release the benchmark along with the complete codebase at \\href{ this http URL }{OpenGVL}.",
          "authors": [
            "Paweł Budzianowski",
            "Emilia Wiśnios",
            "Gracjan Góral",
            "Igor Kulakov",
            "Viktor Petrenko",
            "Krzysztof Walas"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18228",
          "title": "Forest tree species classification and entropy-derived uncertainty mapping using extreme gradient boosting and Sentinel-1/2 satellite data",
          "abstract": "We present a new 10-meter map of dominant tree species in Swedish forests accompanied by pixel-level uncertainty estimates. The tree species classification is based on spatiotemporal metrics derived from Sentinel-1 and Sentinel-2 satellite data, combined with field observations from the Swedish National Forest Inventory. We apply an extreme gradient boosting model with Bayesian optimization to relate field observations to satellite-derived features and generate the final species map. Classification uncertainty is quantified using Shannon's entropy of the predicted class probabilities, which provide a spatially explicit measure of model confidence. The final model achieved an overall accuracy of 85% (F1 score = 0.82, Matthews correlation coefficient = 0.81), and mapped species distributions showed strong agreement with official forest statistics (Spearman's rho = 0.94).",
          "authors": [
            "Abdulhakim M. Abdi",
            "Fan Wang"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18228",
          "title": "Forest tree species classification and entropy-derived uncertainty mapping using extreme gradient boosting and Sentinel-1/2 satellite data",
          "abstract": "We present a new 10-meter map of dominant tree species in Swedish forests accompanied by pixel-level uncertainty estimates. The tree species classification is based on spatiotemporal metrics derived from Sentinel-1 and Sentinel-2 satellite data, combined with field observations from the Swedish National Forest Inventory. We apply an extreme gradient boosting model with Bayesian optimization to relate field observations to satellite-derived features and generate the final species map. Classification uncertainty is quantified using Shannon's entropy of the predicted class probabilities, which provide a spatially explicit measure of model confidence. The final model achieved an overall accuracy of 85% (F1 score = 0.82, Matthews correlation coefficient = 0.81), and mapped species distributions showed strong agreement with official forest statistics (Spearman's rho = 0.94).",
          "authors": [
            "Abdulhakim M. Abdi",
            "Fan Wang"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18406",
          "title": "Estimation and inference in generalised linear models with constrained iteratively-reweighted least squares",
          "abstract": "We propose a simple and flexible framework for generalised linear models (GLM) with linear constraints on the coefficients. Linear constraints are useful in a wide range of applications, allowing the fitting of model with high-dimensional or highly collinear predictors, as well as encoding assumptions on the association between some or all predictors and the response. We propose the constrained iteratively-reweighted least squares (CIRLS) to fit the model, iterating quadratic programs to ensure the coefficient vector remains feasible according to the constraints. Inference for constrained coefficients can be obtained by simulating from a truncated multivariate normal distribution and computing empirical confidence intervals or variance-covariance matrix from the simulated coefficient vectors. We additionally discuss the complexity of a constrained GLM, proposing a measure of expected degrees of freedom which accounts for the stringency of constraints in the reduction of the model degrees of freedom. An extensive simulations study shows that constraining the coefficients introduces some bias to the estimation, but also decreases the estimator variance. This trade-off results in an improved estimator when constraints are chosen appropriately. The simulations also show that our proposed inference results in error in variance estimation and coverage. The proposed framework is illustrated on two case studies, showing its usefulness as well as some of its weaknesses.",
          "authors": [
            "Pierre Masselot",
            "Devon Nenon",
            "Jacopo Vanoli",
            "Zaid Chalabi",
            "Antonio Gasparrini"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18480",
          "title": "SimpleFold: Folding Proteins is Simpler than You Think",
          "abstract": "Protein folding models have achieved groundbreaking results typically via a combination of integrating domain knowledge into the architectural blocks and training pipelines. Nonetheless, given the success of generative models across different but related problems, it is natural to question whether these architectural designs are a necessary condition to build performant models. In this paper, we introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer blocks. Protein folding models typically employ computationally expensive modules involving triangular updates, explicit pair representations or multiple training objectives curated for this specific domain. Instead, SimpleFold employs standard transformer blocks with adaptive layers and is trained via a generative flow-matching objective with an additional structural term. We scale SimpleFold to 3B parameters and train it on approximately 9M distilled protein structures together with experimental PDB data. On standard folding benchmarks, SimpleFold-3B achieves competitive performance compared to state-of-the-art baselines, in addition SimpleFold demonstrates strong performance in ensemble prediction which is typically difficult for models trained via deterministic reconstruction objectives. Due to its general-purpose architecture, SimpleFold shows efficiency in deployment and inference on consumer-level hardware. SimpleFold challenges the reliance on complex domain-specific architectures designs in protein folding, opening up an alternative design space for future progress.",
          "authors": [
            "Yuyang Wang",
            "Jiarui Lu",
            "Navdeep Jaitly",
            "Josh Susskind",
            "Miguel Angel Bautista"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.18480",
          "title": "SimpleFold: Folding Proteins is Simpler than You Think",
          "abstract": "Protein folding models have achieved groundbreaking results typically via a combination of integrating domain knowledge into the architectural blocks and training pipelines. Nonetheless, given the success of generative models across different but related problems, it is natural to question whether these architectural designs are a necessary condition to build performant models. In this paper, we introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer blocks. Protein folding models typically employ computationally expensive modules involving triangular updates, explicit pair representations or multiple training objectives curated for this specific domain. Instead, SimpleFold employs standard transformer blocks with adaptive layers and is trained via a generative flow-matching objective with an additional structural term. We scale SimpleFold to 3B parameters and train it on approximately 9M distilled protein structures together with experimental PDB data. On standard folding benchmarks, SimpleFold-3B achieves competitive performance compared to state-of-the-art baselines, in addition SimpleFold demonstrates strong performance in ensemble prediction which is typically difficult for models trained via deterministic reconstruction objectives. Due to its general-purpose architecture, SimpleFold shows efficiency in deployment and inference on consumer-level hardware. SimpleFold challenges the reliance on complex domain-specific architectures designs in protein folding, opening up an alternative design space for future progress.",
          "authors": [
            "Yuyang Wang",
            "Jiarui Lu",
            "Navdeep Jaitly",
            "Josh Susskind",
            "Miguel Angel Bautista"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.19846",
          "title": "BoreaRL: A Multi-Objective Reinforcement Learning Environment for Climate-Adaptive Boreal Forest Management",
          "abstract": "Boreal forests store 30-40\\% of terrestrial carbon, much in climate-vulnerable permafrost soils, making their management critical for climate mitigation. However, optimizing forest management for both carbon sequestration and permafrost preservation presents complex trade-offs that current tools cannot adequately address. We introduce BoreaRL, the first multi-objective reinforcement learning environment for climate-adaptive boreal forest management, featuring a physically-grounded simulator of coupled energy, carbon, and water fluxes. BoreaRL supports two training paradigms: site-specific mode for controlled studies and generalist mode for learning robust policies under environmental stochasticity. Through evaluation of multi-objective RL algorithms, we reveal a fundamental asymmetry in learning difficulty: carbon objectives are significantly easier to optimize than thaw (permafrost preservation) objectives, with thaw-focused policies showing minimal learning progress across both paradigms. In generalist settings, standard gradient-descent based preference-conditioned approaches fail, while a naive site selection approach achieves superior performance by strategically selecting training episodes. Analysis of learned strategies reveals distinct management philosophies, where carbon-focused policies favor aggressive high-density coniferous stands, while effective multi-objective policies balance species composition and density to protect permafrost while maintaining carbon gains. Our results demonstrate that robust climate-adaptive forest management remains challenging for current MORL methods, establishing BoreaRL as a valuable benchmark for developing more effective approaches. We open-source BoreaRL to accelerate research in multi-objective RL for climate applications.",
          "authors": [
            "Kevin Bradley Dsouza",
            "Enoch Ofosu",
            "Daniel Chukwuemeka Amaogu",
            "Jérôme Pigeon",
            "Richard Boudreault",
            "Pooneh Maghoul",
            "Juan Moreno-Cruz",
            "Yuri Leonenko"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.20478",
          "title": "Offline Goal-conditioned Reinforcement Learning with Quasimetric Representations",
          "abstract": "Approaches for goal-conditioned reinforcement learning (GCRL) often use learned state representations to extract goal-reaching policies. Two frameworks for representation structure have yielded particularly effective GCRL algorithms: (1) *contrastive representations*, in which methods learn \"successor features\" with a contrastive objective that performs inference over future outcomes, and (2) *temporal distances*, which link the (quasimetric) distance in representation space to the transit time from states to goals. We propose an approach that unifies these two frameworks, using the structure of a quasimetric representation space (triangle inequality) with the right additional constraints to learn successor representations that enable optimal goal-reaching. Unlike past work, our approach is able to exploit a **quasimetric** distance parameterization to learn **optimal** goal-reaching distances, even with **suboptimal** data and in **stochastic** environments. This gives us the best of both worlds: we retain the stability and long-horizon capabilities of Monte Carlo contrastive RL methods, while getting the free stitching capabilities of quasimetric network parameterizations. On existing offline GCRL benchmarks, our representation learning objective improves performance on stitching tasks where methods based on contrastive learning struggle, and on noisy, high-dimensional environments where methods based on quasimetric networks struggle.",
          "authors": [
            "Vivek Myers",
            "Bill Chunyuan Zheng",
            "Benjamin Eysenbach",
            "Sergey Levine"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.20645",
          "title": "Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions",
          "abstract": "Progress in large language models is constrained by an evaluation bottleneck: build a benchmark, run models, then iterate. We ask a question: can we forecast outcomes before running any experiments to inform earlier study design? For example, a team building an AI assistant for a certain task can estimate whether expected performance is around 50 or closer to 80, evidence that supports whether to proceed to a pilot study, how to scope it, and how to allocate resources. We study text-only performance forecasting, where a model predicts a score from a redacted task description and intended configuration, with no access to dataset instances. To support systematic study, we curate PRECOG, a corpus of redacted description-performance pairs spanning diverse tasks, domains, and metrics. We scrape task and configuration descriptions from arXiv, yielding 2,290 instances covering 1,519 papers, and construct a leakage free test split using papers published after the knowledge cutoff of the evaluated models. Experiments show the task is challenging but feasible: reasoning models achieve moderate prediction performance with well calibrated uncertainty, reaching mean absolute error as low as 9.9 at high confidence thresholds. We further test a zero-leakage setting, forecasting on newly released datasets or experiments before their papers are indexed, where GPT5 with built in web search still attains nontrivial prediction accuracy. Overall, our corpus and analyses offer an initial step toward open ended anticipatory evaluation, supporting difficulty estimation and smarter experiment prioritization.",
          "authors": [
            "Jungsoo Park",
            "Ethan Mendes",
            "Gabriel Stanovsky",
            "Alan Ritter"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.21519",
          "title": "Provable Scaling Laws of Feature Emergence from Learning Dynamics of Grokking",
          "abstract": "While the phenomenon of grokking, i.e., delayed generalization, has been studied extensively, it remains an open problem whether there is a mathematical framework that characterizes what kind of features will emerge, how and in which conditions it happens, and is closely related to the gradient dynamics of the training, for complex structured inputs. We propose a novel framework, named $\\mathbf{Li}_2$, that captures three key stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy learning, (II) independent feature learning and (III) interactive feature learning. At the lazy learning stage, top layer overfits to random hidden representation and the model appears to memorize, and at the same time, the backpropagated gradient $G_F$ from the top layer now carries information about the target label, with a specific structure that enables each hidden node to learn their representation independently. Interestingly, the independent dynamics follows exactly the gradient ascent of an energy function $E$, and its local maxima are precisely the emerging features. We study whether these local-optima induced features are generalizable, their representation power, and how they change on sample size, in group arithmetic tasks. When hidden nodes start to interact in the later stage of learning, we provably show how $G_F$ changes to focus on missing features that need to be learned. Our study sheds lights on roles played by key hyperparameters such as weight decay, learning rate and sample sizes in grokking, leads to provable scaling laws of feature emergence, memorization and generalization, and reveals why recent optimizers such as Muon can be effective, from the first principles of gradient dynamics. Our analysis can be extended to multi-layers. The code is available at this https URL .",
          "authors": [
            "Yuandong Tian"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.23846",
          "title": "Adversarial Diffusion for Robust Reinforcement Learning",
          "abstract": "Robustness to modeling errors and uncertainties remains a central challenge in reinforcement learning (RL). In this work, we address this challenge by leveraging diffusion models to train robust RL policies. Diffusion models have recently gained popularity in model-based RL due to their ability to generate full trajectories \"all at once\", mitigating the compounding errors typical of step-by-step transition models. Moreover, they can be conditioned to sample from specific distributions, making them highly flexible. We leverage conditional sampling to learn policies that are robust to uncertainty in environment dynamics. Building on the established connection between Conditional Value at Risk (CVaR) optimization and robust RL, we introduce Adversarial Diffusion for Robust Reinforcement Learning (AD-RRL). AD-RRL guides the diffusion process to generate worst-case trajectories during training, effectively optimizing the CVaR of the cumulative return. Empirical results across standard benchmarks show that AD-RRL achieves superior robustness and performance compared to existing robust RL methods.",
          "authors": [
            "Daniele Foffano",
            "Alessio Russo",
            "Alexandre Proutiere"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.24239",
          "title": "ChessArena: A Chess Testbed for Evaluating Strategic Reasoning Capabilities of Large Language Models",
          "abstract": "Recent large language models (LLMs) have shown strong reasoning capabilities. However, a critical question remains: do these models possess genuine reasoning skills particularly complex strategic reasoning or are they primarily excelling at sophisticated pattern recognition within their training data? To address this question, this paper presents a chess testbed, ChessArena, to evaluate the strategic reasoning capabilities of LLMs. Chess requires complex strategic reasoning capabilities including long-term planning, strict rule comprehension, and multi-turn conversation memorization. Specifically, ChessArena is a competitive framework where LLMs play against each other, under four different play modes. The testbed is equipped with a ranking algorithm and a leaderboard. The testbed can also evaluate fine-grained capabilities including basic understanding, move selection, and puzzle solving. Over 13 LLMs with different modes are evaluated in ChessArena, playing over 800 games. The results reveal significant shortcomings in current LLMs: no model can beat Maia-1100 (a chess engine at human amateur level), while some even failed to defeat a random player that selects moves arbitrarily. We also present a strong baseline to the testbed: our fine-tuned Qwen3-8B substantially improved performance, approaching much larger state-of-the-art reasoning models.",
          "authors": [
            "Jincheng Liu",
            "Sijun He",
            "Jingjing Wu",
            "Xiangsen Wang",
            "Yang Chen",
            "Zhaoqi Kuang",
            "Siqi Bao",
            "Yuan Yao"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.24857",
          "title": "Between Help and Harm: An Evaluation of Mental Health Crisis Handling by LLMs",
          "abstract": "Large language model-powered chatbots have transformed how people seek information, especially in high-stakes contexts like mental health. Despite their support capabilities, safe detection and response to crises such as suicidal ideation and self-harm are still unclear, hindered by the lack of unified crisis taxonomies and clinical evaluation standards. We address this by creating: (1) a taxonomy of six crisis categories; (2) a dataset of over 2,000 inputs from 12 mental health datasets, classified into these categories; and (3) a clinical response assessment protocol. We also use LLMs to identify crisis inputs and audit five models for response safety and appropriateness. First, we built a clinical-informed crisis taxonomy and evaluation protocol. Next, we curated 2,252 relevant examples from over 239,000 user inputs, then tested three LLMs for automatic classification. In addition, we evaluated five models for the appropriateness of their responses to a user's crisis, graded on a 5-point Likert scale from harmful (1) to appropriate (5). While some models respond reliably to explicit crises, risks still exist. Many outputs, especially in self-harm and suicidal categories, are inappropriate or unsafe. Different models perform variably; some, like gpt-5-nano and deepseek-v3.2-exp, have low harm rates, but others, such as gpt-4o-mini and grok-4-fast, generate more unsafe responses. All models struggle with indirect signals, default replies, and context misalignment. These results highlight the urgent need for better safeguards, crisis detection, and context-aware responses in LLMs. They also show that alignment and safety practices, beyond scale, are crucial for reliable crisis support. Our taxonomy, datasets, and evaluation methods support ongoing AI mental health research, aiming to reduce harm and protect vulnerable users.",
          "authors": [
            "Adrian Arnaiz-Rodriguez",
            "Miguel Baidal",
            "Erik Derner",
            "Jenn Layton Annable",
            "Mark Ball",
            "Mark Ince",
            "Elvira Perez Vallejos",
            "Nuria Oliver"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.25045",
          "title": "Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures",
          "abstract": "Despite their capabilities, Large Language Models (LLMs) remain opaque with limited understanding of their internal representations. Current interpretability methods either focus on input-oriented feature extraction, such as supervised probes and Sparse Autoencoders (SAEs), or on output distribution inspection, such as logit-oriented approaches. A full understanding of LLM vector spaces, however, requires integrating both perspectives, something existing approaches struggle with due to constraints on latent feature definitions. We introduce the Hyperdimensional Probe, a hybrid supervised probe that combines symbolic representations with neural probing. Leveraging Vector Symbolic Architectures (VSAs) and hypervector algebra, it unifies prior methods: the top-down interpretability of supervised probes, SAE's sparsity-driven proxy space, and output-oriented logit investigation. This allows deeper input-focused feature extraction while supporting output-oriented investigation. Our experiments show that our method consistently extracts meaningful concepts across LLMs, embedding sizes, and setups, uncovering concept-driven patterns in analogy-oriented inference and QA-focused text generation. By supporting joint input-output analysis, this work advances semantic understanding of neural representations while unifying the complementary perspectives of prior methods.",
          "authors": [
            "Marco Bronzini",
            "Carlo Nicolini",
            "Bruno Lepri",
            "Jacopo Staiano",
            "Andrea Passerini"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.25170",
          "title": "GLASS Flows: Transition Sampling for Alignment of Flow and Diffusion Models",
          "abstract": "The performance of flow matching and diffusion models can be greatly improved at inference time using reward alignment algorithms, yet efficiency remains a major limitation. While several algorithms were proposed, we demonstrate that a common bottleneck is the sampling method these algorithms rely on: many algorithms require to sample Markov transitions via SDE sampling, which is significantly less efficient and often less performant than ODE sampling. To remove this bottleneck, we introduce GLASS Flows, a new sampling paradigm that simulates a \"flow matching model within a flow matching model\" to sample Markov transitions. As we show in this work, this \"inner\" flow matching model can be retrieved from a pre-trained model without any re-training, combining the efficiency of ODEs with the stochastic evolution of SDEs. On large-scale text-to-image models, we show that GLASS Flows eliminate the trade-off between stochastic evolution and efficiency. Combined with Feynman-Kac Steering, GLASS Flows improve state-of-the-art performance in text-to-image generation, making it a simple, drop-in solution for inference-time scaling of flow and diffusion models.",
          "authors": [
            "Peter Holderrieth",
            "Uriel Singer",
            "Tommi Jaakkola",
            "Ricky T. Q. Chen",
            "Yaron Lipman",
            "Brian Karrer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.25170",
          "title": "GLASS Flows: Transition Sampling for Alignment of Flow and Diffusion Models",
          "abstract": "The performance of flow matching and diffusion models can be greatly improved at inference time using reward alignment algorithms, yet efficiency remains a major limitation. While several algorithms were proposed, we demonstrate that a common bottleneck is the sampling method these algorithms rely on: many algorithms require to sample Markov transitions via SDE sampling, which is significantly less efficient and often less performant than ODE sampling. To remove this bottleneck, we introduce GLASS Flows, a new sampling paradigm that simulates a \"flow matching model within a flow matching model\" to sample Markov transitions. As we show in this work, this \"inner\" flow matching model can be retrieved from a pre-trained model without any re-training, combining the efficiency of ODEs with the stochastic evolution of SDEs. On large-scale text-to-image models, we show that GLASS Flows eliminate the trade-off between stochastic evolution and efficiency. Combined with Feynman-Kac Steering, GLASS Flows improve state-of-the-art performance in text-to-image generation, making it a simple, drop-in solution for inference-time scaling of flow and diffusion models.",
          "authors": [
            "Peter Holderrieth",
            "Uriel Singer",
            "Tommi Jaakkola",
            "Ricky T. Q. Chen",
            "Yaron Lipman",
            "Brian Karrer"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.26004",
          "title": "Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations",
          "abstract": "Pixel-level recognition of objects manipulated by the user from egocentric images enables key applications spanning assistive technologies, industrial safety, and activity monitoring. However, progress in this area is currently hindered by the scarcity of annotated datasets, as existing approaches rely on costly manual labels. In this paper, we propose to learn human-object interaction detection leveraging narrations $\\unicode{x2013}$ natural language descriptions of the actions performed by the camera wearer which contain clues about manipulated objects. We introduce Narration-Supervised in-Hand Object Segmentation (NS-iHOS), a novel task where models have to learn to segment in-hand objects by learning from natural-language narrations in a weakly-supervised regime. Narrations are then not employed at inference time. We showcase the potential of the task by proposing Weakly-Supervised In-hand Object Segmentation from Human Narrations (WISH), an end-to-end model distilling knowledge from narrations to learn plausible hand-object associations and enable in-hand object segmentation without using narrations at test time. We benchmark WISH against different baselines based on open-vocabulary object detectors and vision-language models. Experiments on EPIC-Kitchens and Ego4D show that WISH surpasses all baselines, recovering more than 50% of the performance of fully supervised methods, without employing fine-grained pixel-wise annotations. Code and data can be found at this https URL .",
          "authors": [
            "Nicola Messina",
            "Rosario Leonardi",
            "Luca Ciampi",
            "Fabio Carrara",
            "Giovanni Maria Farinella",
            "Fabrizio Falchi",
            "Antonino Furnari"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2509.26219",
          "title": "Beyond Pixels: Efficient Dataset Distillation via Sparse Gaussian Representation",
          "abstract": "Dataset distillation has emerged as a promising paradigm that synthesizes compact, informative datasets capable of retaining the knowledge of large-scale counterparts, thereby addressing the substantial computational and storage burdens of modern model training. Conventional approaches typically rely on dense pixel-level representations, which introduce redundancy and are difficult to scale up. In this work, we propose GSDD, a novel and efficient sparse representation for dataset distillation based on 2D Gaussians. Instead of representing all pixels equally, GSDD encodes critical discriminative information in a distilled image using only a small number of Gaussian primitives. This sparse representation could improve dataset diversity under the same storage budget, enhancing coverage of difficult samples and boosting distillation performance. To ensure both efficiency and scalability, we adapt CUDA-based splatting operators for parallel inference and training, enabling high-quality rendering with minimal computational and memory overhead. Our method is simple yet effective, broadly applicable to different distillation pipelines, and highly scalable. Experiments show that GSDD achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet subsets, while remaining highly efficient encoding and decoding cost. Our code is available at this https URL .",
          "authors": [
            "Chenyang Jiang",
            "Zhengcen Li",
            "Hang Zhao",
            "Qiben Shan",
            "Shaocong Wu",
            "Jingyong Su"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.01472",
          "title": "LLM-NAS: LLM-driven Hardware-Aware Neural Architecture Search",
          "abstract": "Hardware-Aware Neural Architecture Search (HW-NAS) requires joint optimization of accuracy and latency under device constraints. Traditional supernet-based methods require multiple GPU days per dataset. Large Language Model (LLM)-driven approaches avoid training a large supernet and can provide quick feedback, but we observe an exploration bias: the LLM repeatedly proposes neural network designs within limited search space and fails to discover architectures across different latency ranges in the entire search space. To address this issue, we propose LLM-NAS: an LLM-driven Neural Architecture Search that can generate neural networks with high accuracy and low latency with reduced search cost. Our proposed LLM-NAS has three key components: 1) a complexity-driven partitioning engine that divides the search space by complexity to enforce diversity and mitigate exploration bias; 2) an LLM-powered architecture prompt co-evolution operator, in which the LLM first updates a knowledge base of design heuristics based on results from the previous round, then performs a guided evolution algorithm on architectures with prompts that incorporate this knowledge base. Prompts and designs improve together across rounds which avoids random guesswork and improve efficiency; 3) a zero-cost predictor to avoid training a large number of candidates from scratch. Experimental results show that on HW-NAS-Bench, LLM-NAS can achieve overall higher HV, lower IGD, and up to 54% lower latency than baselines at similar accuracy. Meanwhile, the search cost drops from days to minutes compared with traditional supernet baselines.",
          "authors": [
            "Hengyi Zhu",
            "Grace Li Zhang",
            "Shaoyi Huang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.02977",
          "title": "Multi-faceted light pollution modelling and its application to the decline of artificial illuminance in France",
          "abstract": "Artificial Light At Night (ALAN) has been increasing steadily over the past century, particularly during the last decade. This leads to rising light pollution, which is known to have adverse effects on living organisms, including humans. We present a new software package to model light pollution from ground radiance measurements. The software is called Otus 3 and incorporates innovative ALAN diffusion models with different atmospheric profiles, cloud covers and urban emission functions. To date, light pollution modelling typically focused on calculating the zenith luminance of the skyglow produced by city lights. In Otus 3 we extend this and additionally model the horizontal illuminance on the ground, including the contributions from skyglow and the direct illumination. We applied Otus 3 to France using ground radiance data from the Visible Infrared Imaging Radiometer Suite (VIIRS). We calibrated our models using precise sky brightness measurements we obtained over 6 years at 139 different locations and make this dataset publicly available. We produced the first artificial illuminance map for France for the periods of 2013-2018 and 2019-2024. We found that the artificial ground illuminance in the middle of the night decreased by 23 % between these two periods, in stark contrast to the global trend.",
          "authors": [
            "Rolf Buhler",
            "Philippe Deverchère",
            "Christophe Plotard",
            "Sébastien Vauclair"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.02977",
          "title": "Multi-faceted light pollution modelling and its application to the decline of artificial illuminance in France",
          "abstract": "Artificial Light At Night (ALAN) has been increasing steadily over the past century, particularly during the last decade. This leads to rising light pollution, which is known to have adverse effects on living organisms, including humans. We present a new software package to model light pollution from ground radiance measurements. The software is called Otus 3 and incorporates innovative ALAN diffusion models with different atmospheric profiles, cloud covers and urban emission functions. To date, light pollution modelling typically focused on calculating the zenith luminance of the skyglow produced by city lights. In Otus 3 we extend this and additionally model the horizontal illuminance on the ground, including the contributions from skyglow and the direct illumination. We applied Otus 3 to France using ground radiance data from the Visible Infrared Imaging Radiometer Suite (VIIRS). We calibrated our models using precise sky brightness measurements we obtained over 6 years at 139 different locations and make this dataset publicly available. We produced the first artificial illuminance map for France for the periods of 2013-2018 and 2019-2024. We found that the artificial ground illuminance in the middle of the night decreased by 23 % between these two periods, in stark contrast to the global trend.",
          "authors": [
            "Rolf Buhler",
            "Philippe Deverchère",
            "Christophe Plotard",
            "Sébastien Vauclair"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.03163",
          "title": "ROGR: Relightable 3D Objects using Generative Relighting",
          "abstract": "We introduce ROGR, a novel approach that reconstructs a relightable 3D model of an object captured from multiple views, driven by a generative relighting model that simulates the effects of placing the object under novel environment illuminations. Our method samples the appearance of the object under multiple lighting environments, creating a dataset that is used to train a lighting-conditioned Neural Radiance Field (NeRF) that outputs the object's appearance under any input environmental lighting. The lighting-conditioned NeRF uses a novel dual-branch architecture to encode the general lighting effects and specularities separately. The optimized lighting-conditioned NeRF enables efficient feed-forward relighting under arbitrary environment maps without requiring per-illumination optimization or light transport simulation. We evaluate our approach on the established TensoIR and Stanford-ORB datasets, where it improves upon the state-of-the-art on most metrics, and showcase our approach on real-world object captures.",
          "authors": [
            "Jiapeng Tang",
            "Matthew Lavine",
            "Dor Verbin",
            "Stephan J. Garbin",
            "Matthias Nießner",
            "Ricardo Martin Brualla",
            "Pratul P. Srinivasan",
            "Philipp Henzler"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05013",
          "title": "Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration",
          "abstract": "Human infants acquire language and action gradually through development, achieving strong generalization from minimal experience, whereas large language models require exposure to billions of training tokens. What mechanisms underlie such efficient developmental learning in humans? This study investigates this question through robot simulation experiments in which agents learn to perform actions associated with imperative sentences (e.g., \\textit{push red cube}) via curiosity-driven self-exploration. Our approach integrates the active inference framework with reinforcement learning, enabling intrinsically motivated developmental learning. The simulations reveal several key findings: i) Generalization improves markedly as the scale of compositional elements increases. ii) Curiosity combined with motor noise yields substantially better learning than exploration without curiosity. iii) Rote pairing of sentences and actions precedes the emergence of compositional generalization. iv) Simpler, prerequisite-like actions develop earlier than more complex actions that depend on them. v) When exception-handling rules were introduced -- where certain imperative sentences required executing inconsistent actions -- the robots successfully acquired these exceptions through exploration and displayed a U-shaped performance curve characteristic of representational redescription in child language learning. Together, these results suggest that curiosity-driven exploration and active inference provide a powerful account of how intrinsic motivation and hierarchical sensorimotor learning can jointly support scalable compositional generalization and exception handling in both humans and artificial agents.",
          "authors": [
            "Theodore Jerome Tinker",
            "Kenji Doya",
            "Jun Tani"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05013",
          "title": "Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration",
          "abstract": "Human infants acquire language and action gradually through development, achieving strong generalization from minimal experience, whereas large language models require exposure to billions of training tokens. What mechanisms underlie such efficient developmental learning in humans? This study investigates this question through robot simulation experiments in which agents learn to perform actions associated with imperative sentences (e.g., \\textit{push red cube}) via curiosity-driven self-exploration. Our approach integrates the active inference framework with reinforcement learning, enabling intrinsically motivated developmental learning. The simulations reveal several key findings: i) Generalization improves markedly as the scale of compositional elements increases. ii) Curiosity combined with motor noise yields substantially better learning than exploration without curiosity. iii) Rote pairing of sentences and actions precedes the emergence of compositional generalization. iv) Simpler, prerequisite-like actions develop earlier than more complex actions that depend on them. v) When exception-handling rules were introduced -- where certain imperative sentences required executing inconsistent actions -- the robots successfully acquired these exceptions through exploration and displayed a U-shaped performance curve characteristic of representational redescription in child language learning. Together, these results suggest that curiosity-driven exploration and active inference provide a powerful account of how intrinsic motivation and hierarchical sensorimotor learning can jointly support scalable compositional generalization and exception handling in both humans and artificial agents.",
          "authors": [
            "Theodore Jerome Tinker",
            "Kenji Doya",
            "Jun Tani"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05109",
          "title": "Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices",
          "abstract": "Large Multimodal Models (LMMs) are inherently modular, consisting of vision and audio encoders, projectors, and large language models. Yet, they are almost always executed monolithically, which underutilizes the heterogeneous accelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end latency. In this paper, we present NANOMIND, a hardware--software co-design inference framework for Large Multimodal Models (LMMs) that breaks large models into modular ``bricks'' (vision, language, audio, etc.) and maps each to its ideal accelerator. The key insight is that large models can be broken into modular components and scheduled to run on the most appropriate compute units. It performs module-level dynamic offloading across accelerators on unified-memory SoCs. By combining customized hardware design, system-level scheduling, and optimized low-bit computation kernels, we demonstrate our framework with a compact, battery-powered device capable of running LMMs entirely on device. This prototype functions as a self-contained intelligent assistant that requires no network connectivity, while achieving higher throughput and superior power efficiency under strict resource constraints. The design further bypasses CPU bottlenecks and reduces redundant memory usage through token-aware buffer management and module-level coordination. Our system outperforms existing implementations in resource efficiency, cutting energy consumption by 42.3\\% and GPU memory usage by 11.2\\%. This enables a battery-powered device to run LLaVA-OneVision with a camera for nearly 20.8 hours.",
          "authors": [
            "Yilong Li",
            "Shuai Zhang",
            "Yijing Zeng",
            "Hao Zhang",
            "Xinmiao Xiong",
            "Jingyu Liu",
            "Pan Hu",
            "Suman Banerjee"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.05109",
          "title": "Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices",
          "abstract": "Large Multimodal Models (LMMs) are inherently modular, consisting of vision and audio encoders, projectors, and large language models. Yet, they are almost always executed monolithically, which underutilizes the heterogeneous accelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end latency. In this paper, we present NANOMIND, a hardware--software co-design inference framework for Large Multimodal Models (LMMs) that breaks large models into modular ``bricks'' (vision, language, audio, etc.) and maps each to its ideal accelerator. The key insight is that large models can be broken into modular components and scheduled to run on the most appropriate compute units. It performs module-level dynamic offloading across accelerators on unified-memory SoCs. By combining customized hardware design, system-level scheduling, and optimized low-bit computation kernels, we demonstrate our framework with a compact, battery-powered device capable of running LMMs entirely on device. This prototype functions as a self-contained intelligent assistant that requires no network connectivity, while achieving higher throughput and superior power efficiency under strict resource constraints. The design further bypasses CPU bottlenecks and reduces redundant memory usage through token-aware buffer management and module-level coordination. Our system outperforms existing implementations in resource efficiency, cutting energy consumption by 42.3\\% and GPU memory usage by 11.2\\%. This enables a battery-powered device to run LLaVA-OneVision with a camera for nearly 20.8 hours.",
          "authors": [
            "Yilong Li",
            "Shuai Zhang",
            "Yijing Zeng",
            "Hao Zhang",
            "Xinmiao Xiong",
            "Jingyu Liu",
            "Pan Hu",
            "Suman Banerjee"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.06203",
          "title": "Reference Grounded Skill Discovery",
          "abstract": "Scaling unsupervised skill discovery algorithms to high-DoF agents remains challenging. As dimensionality increases, the exploration space grows exponentially, while the manifold of meaningful skills remains limited. Therefore, semantic meaningfulness becomes essential to effectively guide exploration in high-dimensional spaces. In this work, we present **Reference-Grounded Skill Discovery (RGSD)**, a novel algorithm that grounds skill discovery in a semantically meaningful latent space using reference data. RGSD first performs contrastive pretraining to embed motions on a unit hypersphere, clustering each reference trajectory into a distinct direction. This grounding enables skill discovery to simultaneously involve both imitation of reference behaviors and the discovery of semantically related diverse behaviors. On a simulated SMPL humanoid with $359$-D observations and $69$-D actions, RGSD successfully imitates skills such as walking, running, punching, and sidestepping, while also discover variations of these behaviors. In downstream locomotion tasks, RGSD leverages the discovered skills to faithfully satisfy user-specified style commands and outperforms imitation-learning baselines, which often fail to maintain the commanded style. Overall, our results suggest that lightweight reference-grounding offers a practical path to discovering semantically rich and structured skills in high-DoF systems.",
          "authors": [
            "Seungeun Rho",
            "Aaron Trinh",
            "Danfei Xu",
            "Sehoon Ha"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.09330",
          "title": "Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers",
          "abstract": "Ensuring that large language models (LLMs) comply with safety requirements is a central challenge in AI deployment. Existing alignment approaches primarily operate during training, such as through fine-tuning or reinforcement learning from human feedback, but these methods are costly and inflexible, requiring retraining whenever new requirements arise. Recent efforts toward inference-time alignment mitigate some of these limitations but still assume access to model internals, which is impractical, and not suitable for third party stakeholders who do not have access to the models. In this work, we propose a model-independent, black-box framework for safety alignment that does not require retraining or access to the underlying LLM architecture. As a proof of concept, we address the problem of trading off between generating safe but uninformative answers versus helpful yet potentially risky ones. We formulate this dilemma as a two-player zero-sum game whose minimax equilibrium captures the optimal balance between safety and helpfulness. LLM agents operationalize this framework by leveraging a linear programming solver at inference time to compute equilibrium strategies. Our results demonstrate the feasibility of black-box safety alignment, offering a scalable and accessible pathway for stakeholders, including smaller organizations and entities in resource-constrained settings, to enforce safety across rapidly evolving LLM ecosystems.",
          "authors": [
            "Tuan Nguyen",
            "Long Tran-Thanh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.10341",
          "title": "Multi-View Graph Learning with Graph-Tuple",
          "abstract": "Graph Neural Networks (GNNs) typically scale with the number of graph edges, making them well suited for sparse graphs but less efficient on dense graphs, such as point clouds or molecular interactions. A common remedy is to sparsify the graph via similarity thresholding or distance pruning, but this forces an arbitrary choice of a single interaction scale and discards crucial information from other scales. To overcome this limitation, we introduce a multi-view graph-tuple framework. Instead of a single graph, our graph-tuple framework partitions the graph into disjoint subgraphs, capturing primary local interactions and weaker, long-range connections. We then learn multi-view representations from the graph-tuple via a heterogeneous message-passing architecture inspired by the theory of non-commuting operators, which we formally prove is strictly more expressive and guarantees a lower oracle risk compared to single-graph message-passing models. We instantiate our framework on two scientific domains: molecular property prediction from feature-scarce Coulomb matrices and cosmological parameter inference from geometric point clouds. On both applications, our multi-view graph-tuple models demonstrate better performance than single-graph baselines, highlighting the power and versatility of our multi-view approach.",
          "authors": [
            "Shiyu Chen",
            "Ningyuan Huang",
            "Soledad Villar"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.11059",
          "title": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
          "abstract": "Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to the lack of high-quality, open-source benchmarks tailored for C/C++. To address this issue, we introduce Defects4C, a comprehensive and executable benchmark specifically designed for C/C++ program repair. Our dataset is constructed from real-world C/C++ repositories and includes a large collection of bug-relevant commits (9M in total), 248 high-quality buggy functions, and 102 vulnerable functions, all paired with test cases for reproduction. These resources enable rigorous evaluation of repair techniques and support the retraining of learning-based approaches for enhanced performance. Using Defects4C, we conduct a comprehensive empirical study evaluating the effectiveness of 24 state-of-the-art large language models (LLMs) in repairing C/C++ faults. Our findings offer valuable insights into the strengths and limitations of current LLM-based APR techniques in this domain, highlighting both the need for more robust methods and the critical role of Defects4C in advancing future research",
          "authors": [
            "Jian Wang",
            "Xiaofei Xie",
            "Qiang Hu",
            "Shangqing Liu",
            "Jiongchi Yu",
            "Jiaolong Kong",
            "Yi Li"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12416",
          "title": "Geopolitics, Geoeconomics and Risk: A Machine Learning Approach",
          "abstract": "We introduce a novel high-frequency daily panel dataset of both markets and news-based indicators -- including Geopolitical Risk, Economic Policy Uncertainty, Trade Policy Uncertainty, and Political Sentiment -- for 42 countries across both emerging and developed markets. Using this dataset, we study how sentiment dynamics shape sovereign risk, measured by Credit Default Swap (CDS) spreads, and evaluate their forecasting value relative to traditional drivers such as global monetary policy and market volatility. Our horse-race analysis of forecasting models demonstrates that incorporating news-based indicators significantly enhances predictive accuracy and enriches the analysis, with non-linear machine learning methods -- particularly Random Forests -- delivering the largest gains. Our analysis reveals that while global financial variables remain the dominant drivers of sovereign risk, geopolitical risk and economic policy uncertainty also play a meaningful role. Crucially, their effects are amplified through non-linear interactions with global financial conditions. Finally, we document pronounced regional heterogeneity, as certain asset classes and emerging markets exhibit heightened sensitivity to shocks in policy rates, global financial volatility, and geopolitical risk.",
          "authors": [
            "Alvaro Ortiz",
            "Tomasa Rodrigo"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12416",
          "title": "Geopolitics, Geoeconomics and Risk: A Machine Learning Approach",
          "abstract": "We introduce a novel high-frequency daily panel dataset of both markets and news-based indicators -- including Geopolitical Risk, Economic Policy Uncertainty, Trade Policy Uncertainty, and Political Sentiment -- for 42 countries across both emerging and developed markets. Using this dataset, we study how sentiment dynamics shape sovereign risk, measured by Credit Default Swap (CDS) spreads, and evaluate their forecasting value relative to traditional drivers such as global monetary policy and market volatility. Our horse-race analysis of forecasting models demonstrates that incorporating news-based indicators significantly enhances predictive accuracy and enriches the analysis, with non-linear machine learning methods -- particularly Random Forests -- delivering the largest gains. Our analysis reveals that while global financial variables remain the dominant drivers of sovereign risk, geopolitical risk and economic policy uncertainty also play a meaningful role. Crucially, their effects are amplified through non-linear interactions with global financial conditions. Finally, we document pronounced regional heterogeneity, as certain asset classes and emerging markets exhibit heightened sensitivity to shocks in policy rates, global financial volatility, and geopolitical risk.",
          "authors": [
            "Alvaro Ortiz",
            "Tomasa Rodrigo"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.12498",
          "title": "Artificial Intelligence Virtual Cells: From Measurements to Decisions across Modality, Scale, Dynamics, and Evaluation",
          "abstract": "Artificial Intelligence Virtual Cells (AIVCs) aim to learn executable, decision-relevant models of cell state from multimodal, multiscale measurements. Recent studies have introduced single-cell and spatial foundation models, improved cross-modality alignment, scaled perturbation atlases, and explored pathway-level readouts. Nevertheless, although held-out validation is standard practice, evaluations remain predominantly within single datasets and settings; evidence indicates that transport across laboratories and platforms is often limited, that some data splits are vulnerable to leakage and coverage bias, and that dose, time and combination effects are not yet systematically handled. Cross-scale coupling also remains constrained, as anchors linking molecular, cellular and tissue levels are sparse, and alignment to scientific or clinical readouts varies across studies. We propose a model-agnostic Cell-State Latent (CSL) perspective that organizes learning via an operator grammar: measurement, lift/project for cross-scale coupling, and intervention for dosing and scheduling. This view motivates a decision-aligned evaluation blueprint across modality, scale, context and intervention, and emphasizes function-space readouts such as pathway activity, spatial neighborhoods and clinically relevant endpoints. We recommend operator-aware data design, leakage-resistant partitions, and transparent calibration and reporting to enable reproducible, like-for-like comparisons.",
          "authors": [
            "Chengpeng Hu",
            "Calvin Yu-Chian Chen"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.13506",
          "title": "Design of an Imaging Air Cherenkov Telescope array layout with differential programming",
          "abstract": "Current optimization of ground-based Cherenkov telescopes arrays, also called Imaging Air Cherenkov Telescope (IACT) arrays, relies on brute-force human-driven approaches based on large simulations requiring both high amount of storage and long computation time. To explore the full phase space of telescope positioning of a given array even more simulations would be required. To optimize any array layout, we explore the possibility of developing a differential program with surrogate models of IACT arrays based on high-level instrument response functions (IRFs). The simulation time of a single telescope to a cosmic-ray event can be significantly reduced with its instrument response function or with generative models. However, it is not straight forward to model the array of telescopes from a set of single telescope surrogate models as the array is a stereoscopic imaging system. The complexity increases as well if the telescopes in the array are of different types. Additionally, the optimum of the array layout depends on the scientific use case. Current array layout optimization are obtained by minimizing the sensitivity of the array, a metric that depends on several high-level parameters such as the trigger efficiency, the energy and angular resolution, as well as the background rejection capability. The variety of telescopes types in IACT arrays, such as in the Cherenkov Telescope Array Observatory (CTAO), not only extends the sensitive energy range but also allows for cross-calibration of the instruments. Therefore, the optimal array layout is not only which minimizes sensitivity but also which reduces the systematic uncertainties. We focus on the optimization of a telescope array based on the SST-1M IACTs in Hanle, Ladakh India aiming at building a generic optimization pipeline for future ground-based cosmic-ray observatories",
          "authors": [
            "Cyril Alispach",
            "Matthieu Heller",
            "Teresa Montaruli"
          ],
          "primary_category": "astro-ph.IM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.13583",
          "title": "On the identifiability of causal graphs with multiple environments",
          "abstract": "Causal discovery from i.i.d. observational data is known to be generally ill-posed. We demonstrate that if we have access to the distribution of a structural causal model, and additional data from only two environments that sufficiently differ in the noise statistics, the unique causal graph is identifiable. Notably, this is the first result in the literature that guarantees the entire causal graph recovery with a constant number of environments and arbitrary nonlinear mechanisms. Our only constraint is the Gaussianity of the noise terms; however, we propose potential ways to relax this requirement. Of interest on its own, we expand on the well-known duality between independent component analysis (ICA) and causal discovery; recent advancements have shown that nonlinear ICA can be solved from multiple environments, at least as many as the number of sources: we show that the same can be achieved for causal discovery while having access to much less auxiliary information.",
          "authors": [
            "Francesco Montagna"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.13583",
          "title": "On the identifiability of causal graphs with multiple environments",
          "abstract": "Causal discovery from i.i.d. observational data is known to be generally ill-posed. We demonstrate that if we have access to the distribution of a structural causal model, and additional data from only two environments that sufficiently differ in the noise statistics, the unique causal graph is identifiable. Notably, this is the first result in the literature that guarantees the entire causal graph recovery with a constant number of environments and arbitrary nonlinear mechanisms. Our only constraint is the Gaussianity of the noise terms; however, we propose potential ways to relax this requirement. Of interest on its own, we expand on the well-known duality between independent component analysis (ICA) and causal discovery; recent advancements have shown that nonlinear ICA can be solved from multiple environments, at least as many as the number of sources: we show that the same can be achieved for causal discovery while having access to much less auxiliary information.",
          "authors": [
            "Francesco Montagna"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.15414",
          "title": "MARSHAL: Incentivizing Multi-Agent Reasoning via Self-Play with Strategic LLMs",
          "abstract": "Developing large language models (LLMs) to cooperate and compete effectively within multi-agent systems (MASs) is a critical step towards more advanced intelligence. While reinforcement learning (RL) has proven effective for enhancing reasoning in single-agent tasks, its extension to multi-turn, multi-agent scenarios remains underexplored due to the challenges of long-horizon credit assignment and agent-specific advantage estimation. To address these challenges, we introduce MARSHAL, an end-to-end RL framework that incentivizes Multi-Agent Reasoning through Self-play witH strAtegic LLMs in both cooperative and competitive games. MARSHAL features a turn-level advantage estimator that aligns learning signals with each interaction for credit assignment, and an agent-specific advantage normalization to stabilize multi-agent training. By learning with self-play across cooperative and competitive games, MARSHAL agent trained from Qwen3-4B develops strong strategic abilities that generalize to held-out games with up to 28.7% performance improvements. More importantly, the capability acquired through self-play generalizes beyond games, yielding consistent performance gains of MASs in reasoning benchmarks. When integrated into leading MASs, our MARSHAL agent achieves significant performance gains of up to 10.0% on AIME, 6.6% on GPQA-Diamond, and 3.5% on average across all benchmarks. These results establish end-to-end RL training with self-play in strategic games as a powerful approach for developing generalizable multi-agent reasoning capabilities in LLMs.",
          "authors": [
            "Huining Yuan",
            "Zelai Xu",
            "Zheyue Tan",
            "Xiangmin Yi",
            "Mo Guang",
            "Kaiwen Long",
            "Haojia Hui",
            "Boxun Li",
            "Xinlei Chen",
            "Bo Zhao",
            "Xiao-Ping Zhang",
            "Chao Yu",
            "Yu Wang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.16295",
          "title": "OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models",
          "abstract": "OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in evaluating membership inference attacks (MIA) against large vision-language models (LVLMs). While prior work has reported high attack success rates, our analysis suggests that these results often arise from detecting distributional bias introduced during dataset construction rather than from identifying true membership status. To address this issue, we introduce a controlled benchmark of 6{,}000 images where the distributions of member and non-member samples are carefully balanced, and ground-truth membership labels are provided across three distinct training stages. Experiments using OpenLVLM-MIA demonstrated that the performance of state-of-the-art MIA methods approached chance-level. OpenLVLM-MIA, designed to be transparent and unbiased benchmark, clarifies certain limitations of MIA research on LVLMs and provides a solid foundation for developing stronger privacy-preserving techniques.",
          "authors": [
            "Ryoto Miyamoto",
            "Xin Fan",
            "Fuyuko Kido",
            "Tsuneo Matsumoto",
            "Hayato Yamana"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.17923",
          "title": "Rewarding the Journey, Not Just the Destination: A Composite Path and Answer Self-Scoring Reward Mechanism for Test-Time Reinforcement Learning",
          "abstract": "Reinforcement Learning (RL) has emerged as a powerful paradigm for advancing Large Language Models (LLMs), achieving remarkable performance in complex reasoning domains such as mathematics and code generation. However, current RL methods face a fundamental scalability bottleneck due to their heavy reliance on human-curated preference data or labeled datasets for reward modeling. To overcome this limitation, we explore RL on unlabeled data where models learn autonomously from continuous experience streams. The core challenge in this setting lies in reliable reward estimation without ground-truth supervision. Existing approaches like Test-Time RL address this through self-consistent consensus, but risk reinforcing incorrect pseudo-labels derived from majority voting. We introduce COMPASS (Composite Path and Answer Self-Scoring), a novel test-time reward mechanism that operates without external supervision. COMPASS integrates two complementary components: the Dual-Calibration Answer Reward (DCAR), which stabilizes training by establishing trustworthy pseudo-labels through confidence and credibility calibration, and the Decisive Path Reward (DPR), which directly optimizes the reasoning process quality beyond mere outcome supervision. By jointly reinforcing trustworthy consensus answers and highly decisive reasoning chains, the COMPASS systematically enhances the model's analytical capabilities. Extensive experiments show that COMPASS achieves significant and consistent performance gains across diverse reasoning tasks and model architectures, advancing a more scalable direction for LLMs to learn from continuous experience.",
          "authors": [
            "Chenwei Tang",
            "Jingyu Xing",
            "Lin Long",
            "Xinyu Liu",
            "Deng Xiong",
            "Wei Ju",
            "Shudong Huang",
            "Jiancheng Lv",
            "Ziyue Qiao"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.21830",
          "title": "GAPO: Robust Advantage Estimation for Real-World Code LLMs",
          "abstract": "Reinforcement learning (RL) is widely used for post-training large language models (LLMs) in code editing, where group-relative methods like GRPO are popular for their critic-free, normalized advantage estimation. However, in real-world code-editing scenarios, reward distributions are often skewed with unpredictable outliers, leading to distorted advantage computation and increased noise. To address this issue, we propose Group Adaptive Policy Optimization (GAPO), which adaptively finds an outlier-free highest-density interval (HDI) per prompt and then uses the median of that interval as an adaptive Q to replace the group mean in advantage calculation. This adaptive Q robustly handles skewed distributions while remaining plug-and-play and efficient. We validate GAPO on nine instruction-tuned LLMs (3B-14B) using a large internal dataset of 51,844 real-world, history-aware code-editing tasks across 10 languages, demonstrating consistent improvements in exact match accuracy over GRPO and its variant DAPO. Code is publicly available.",
          "authors": [
            "Jianqing Zhang",
            "Zhezheng Hao",
            "Wei Xia",
            "Hande Dong",
            "Hong Wang",
            "Chenxing Wei",
            "Yuyan Zhou",
            "Yubin Qi",
            "Qiang Lin",
            "Jian Cao"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23166",
          "title": "Common Task Framework For a Critical Evaluation of Scientific Machine Learning Algorithms",
          "abstract": "Machine learning (ML) is transforming modeling and control in the physical, engineering, and biological sciences. However, rapid development has outpaced the creation of standardized, objective benchmarks - leading to weak baselines, reporting bias, and inconsistent evaluations across methods. This undermines reproducibility, misguides resource allocation, and obscures scientific progress. To address this, we propose a Common Task Framework (CTF) for scientific machine learning. The CTF features a curated set of datasets and task-specific metrics spanning forecasting, state reconstruction, and generalization under realistic constraints, including noise and limited data. Inspired by the success of CTFs in fields like natural language processing and computer vision, our framework provides a structured, rigorous foundation for head-to-head evaluation of diverse algorithms. As a first step, we benchmark methods on two canonical nonlinear systems: Kuramoto-Sivashinsky and Lorenz. These results illustrate the utility of the CTF in revealing method strengths, limitations, and suitability for specific classes of problems and diverse objectives. Next, we are launching a competition around a global real world sea surface temperature dataset with a true holdout dataset to foster community engagement. Our long-term vision is to replace ad hoc comparisons with standardized evaluations on hidden test sets that raise the bar for rigor and reproducibility in scientific ML.",
          "authors": [
            "Philippe Martin Wyder",
            "Judah Goldfeder",
            "Alexey Yermakov",
            "Yue Zhao",
            "Stefano Riva",
            "Jan P. Williams",
            "David Zoro",
            "Amy Sara Rude",
            "Matteo Tomasetto",
            "Joe Germany",
            "Joseph Bakarji",
            "Georg Maierhofer",
            "Miles Cranmer",
            "J. Nathan Kutz"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23166",
          "title": "Common Task Framework For a Critical Evaluation of Scientific Machine Learning Algorithms",
          "abstract": "Machine learning (ML) is transforming modeling and control in the physical, engineering, and biological sciences. However, rapid development has outpaced the creation of standardized, objective benchmarks - leading to weak baselines, reporting bias, and inconsistent evaluations across methods. This undermines reproducibility, misguides resource allocation, and obscures scientific progress. To address this, we propose a Common Task Framework (CTF) for scientific machine learning. The CTF features a curated set of datasets and task-specific metrics spanning forecasting, state reconstruction, and generalization under realistic constraints, including noise and limited data. Inspired by the success of CTFs in fields like natural language processing and computer vision, our framework provides a structured, rigorous foundation for head-to-head evaluation of diverse algorithms. As a first step, we benchmark methods on two canonical nonlinear systems: Kuramoto-Sivashinsky and Lorenz. These results illustrate the utility of the CTF in revealing method strengths, limitations, and suitability for specific classes of problems and diverse objectives. Next, we are launching a competition around a global real world sea surface temperature dataset with a true holdout dataset to foster community engagement. Our long-term vision is to replace ad hoc comparisons with standardized evaluations on hidden test sets that raise the bar for rigor and reproducibility in scientific ML.",
          "authors": [
            "Philippe Martin Wyder",
            "Judah Goldfeder",
            "Alexey Yermakov",
            "Yue Zhao",
            "Stefano Riva",
            "Jan P. Williams",
            "David Zoro",
            "Amy Sara Rude",
            "Matteo Tomasetto",
            "Joe Germany",
            "Joseph Bakarji",
            "Georg Maierhofer",
            "Miles Cranmer",
            "J. Nathan Kutz"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23909",
          "title": "Two Shades of Quark Color: Parallel Canons across the Cold War Divide",
          "abstract": "The introduction of the color quantum number is conventionally narrated as a linear progression from the quark-model statistics paradox to quantum chromodynamics (QCD). This paper challenges that teleology by arguing that \"color\" emerged as two conceptually distinct constructs during the Cold War. The first, originating with Han and Nambu and culminating in QCD, conceived of color as a local gauge charge, the source of a fundamental force mediated by gluons. The second, developed at the Joint Institute for Nuclear Research (JINR) in Dubna, treated color as a hidden, three-valued label--a statistical and structural property within a composite, S-matrix-inflected hadron model. We trace these parallel narratives, linking the Dubna approach to a holist epistemology that prioritizes observable amplitudes and global constraints, and the QCD approach to a reductionist program grounded in micro-dynamics. A case study of Fermilab's E-36 experimental chain (1970--78) shows how an observables-first design-tuned to S-matrix and Regge constraints on forward elastic scattering--performed robustly within its natural domain but was ultimately discontinued amid declining theoretical interest and involvement. The subsequent hegemony of QCD retroactively projected its gauge-theoretic conception of color onto history, erasing this epistemic diversity. We conclude that the marginalization of Dubna's structural color was not merely a political outcome of the Cold War but a result of deep ontological and philosophical divergences, advocating for a domain-sensitive pluralism in the historiography of particle physics.",
          "authors": [
            "Vitaly Pronskikh"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23909",
          "title": "Two Shades of Quark Color: Parallel Canons across the Cold War Divide",
          "abstract": "The introduction of the color quantum number is conventionally narrated as a linear progression from the quark-model statistics paradox to quantum chromodynamics (QCD). This paper challenges that teleology by arguing that \"color\" emerged as two conceptually distinct constructs during the Cold War. The first, originating with Han and Nambu and culminating in QCD, conceived of color as a local gauge charge, the source of a fundamental force mediated by gluons. The second, developed at the Joint Institute for Nuclear Research (JINR) in Dubna, treated color as a hidden, three-valued label--a statistical and structural property within a composite, S-matrix-inflected hadron model. We trace these parallel narratives, linking the Dubna approach to a holist epistemology that prioritizes observable amplitudes and global constraints, and the QCD approach to a reductionist program grounded in micro-dynamics. A case study of Fermilab's E-36 experimental chain (1970--78) shows how an observables-first design-tuned to S-matrix and Regge constraints on forward elastic scattering--performed robustly within its natural domain but was ultimately discontinued amid declining theoretical interest and involvement. The subsequent hegemony of QCD retroactively projected its gauge-theoretic conception of color onto history, erasing this epistemic diversity. We conclude that the marginalization of Dubna's structural color was not merely a political outcome of the Cold War but a result of deep ontological and philosophical divergences, advocating for a domain-sensitive pluralism in the historiography of particle physics.",
          "authors": [
            "Vitaly Pronskikh"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23909",
          "title": "Two Shades of Quark Color: Parallel Canons across the Cold War Divide",
          "abstract": "The introduction of the color quantum number is conventionally narrated as a linear progression from the quark-model statistics paradox to quantum chromodynamics (QCD). This paper challenges that teleology by arguing that \"color\" emerged as two conceptually distinct constructs during the Cold War. The first, originating with Han and Nambu and culminating in QCD, conceived of color as a local gauge charge, the source of a fundamental force mediated by gluons. The second, developed at the Joint Institute for Nuclear Research (JINR) in Dubna, treated color as a hidden, three-valued label--a statistical and structural property within a composite, S-matrix-inflected hadron model. We trace these parallel narratives, linking the Dubna approach to a holist epistemology that prioritizes observable amplitudes and global constraints, and the QCD approach to a reductionist program grounded in micro-dynamics. A case study of Fermilab's E-36 experimental chain (1970--78) shows how an observables-first design-tuned to S-matrix and Regge constraints on forward elastic scattering--performed robustly within its natural domain but was ultimately discontinued amid declining theoretical interest and involvement. The subsequent hegemony of QCD retroactively projected its gauge-theoretic conception of color onto history, erasing this epistemic diversity. We conclude that the marginalization of Dubna's structural color was not merely a political outcome of the Cold War but a result of deep ontological and philosophical divergences, advocating for a domain-sensitive pluralism in the historiography of particle physics.",
          "authors": [
            "Vitaly Pronskikh"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.23909",
          "title": "Two Shades of Quark Color: Parallel Canons across the Cold War Divide",
          "abstract": "The introduction of the color quantum number is conventionally narrated as a linear progression from the quark-model statistics paradox to quantum chromodynamics (QCD). This paper challenges that teleology by arguing that \"color\" emerged as two conceptually distinct constructs during the Cold War. The first, originating with Han and Nambu and culminating in QCD, conceived of color as a local gauge charge, the source of a fundamental force mediated by gluons. The second, developed at the Joint Institute for Nuclear Research (JINR) in Dubna, treated color as a hidden, three-valued label--a statistical and structural property within a composite, S-matrix-inflected hadron model. We trace these parallel narratives, linking the Dubna approach to a holist epistemology that prioritizes observable amplitudes and global constraints, and the QCD approach to a reductionist program grounded in micro-dynamics. A case study of Fermilab's E-36 experimental chain (1970--78) shows how an observables-first design-tuned to S-matrix and Regge constraints on forward elastic scattering--performed robustly within its natural domain but was ultimately discontinued amid declining theoretical interest and involvement. The subsequent hegemony of QCD retroactively projected its gauge-theoretic conception of color onto history, erasing this epistemic diversity. We conclude that the marginalization of Dubna's structural color was not merely a political outcome of the Cold War but a result of deep ontological and philosophical divergences, advocating for a domain-sensitive pluralism in the historiography of particle physics.",
          "authors": [
            "Vitaly Pronskikh"
          ],
          "primary_category": "physics.hist-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.24974",
          "title": "Conformational Rank Conditioned Committees for Machine Learning-Assisted Directed Evolution",
          "abstract": "Machine Learning-assisted directed evolution (MLDE) is a powerful tool for efficiently navigating antibody fitness landscapes. Many structure-aware MLDE pipelines rely on a single conformation or a single committee across all conformations, limiting their ability to separate conformational uncertainty from epistemic uncertainty. Here, we introduce a rank -conditioned committee (RCC) framework that leverages ranked conformations to assign a deep neural network committee per rank. This design enables a principled separation between epistemic uncertainty and conformational uncertainty. We validate our RCC-MLDE approach on SARS-CoV-2 antibody docking, demonstrating significant improvements over baseline strategies. Our results offer a scalable route for therapeutic antibody discovery while directly addressing the challenge of modeling conformational uncertainty.",
          "authors": [
            "Mia Adler",
            "Carrie Liang",
            "Brian Peng",
            "Oleg Presnyakov",
            "Justin M. Baker",
            "Jannelle Lauffer",
            "Himani Sharma",
            "Barry Merriman"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.26012",
          "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys",
          "abstract": "The rapid growth of research literature, particularly in large language models (LLMs), has made producing comprehensive and current survey papers increasingly difficult. This paper introduces autosurvey2, a multi-stage pipeline that automates survey generation through retrieval-augmented synthesis and structured evaluation. The system integrates parallel section generation, iterative refinement, and real-time retrieval of recent publications to ensure both topical completeness and factual accuracy. Quality is assessed using a multi-LLM evaluation framework that measures coverage, structure, and relevance in alignment with expert review standards. Experimental results demonstrate that autosurvey2 consistently outperforms existing retrieval-based and automated baselines, achieving higher scores in structural coherence and topical relevance while maintaining strong citation fidelity. By combining retrieval, reasoning, and automated evaluation into a unified framework, autosurvey2 provides a scalable and reproducible solution for generating long-form academic surveys and contributes a solid foundation for future research on automated scholarly writing. All code and resources are available at this https URL .",
          "authors": [
            "Siyi Wu",
            "Chiaxin Liang",
            "Ziqian Bi",
            "Leyi Zhao",
            "Tianyang Wang",
            "Junhao Song",
            "Yichao Zhang",
            "Keyu Chen",
            "Benji Peng",
            "Xinyuan Song"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2510.26643",
          "title": "MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection",
          "abstract": "Anomaly detection is a fundamental task for time series analytics with important implications for the downstream performance of many applications. Despite increasing academic interest and the large number of methods proposed in the literature, recent benchmarks and evaluation studies demonstrated that no overall best anomaly detection methods exist when applied to very heterogeneous time series datasets. Therefore, the only scalable and viable solution to solve anomaly detection over very different time series collected from diverse domains is to propose a model selection method that will select, based on time series characteristics, the best anomaly detection methods to run. Existing AutoML solutions are, unfortunately, not directly applicable to time series anomaly detection, and no evaluation of time series-based approaches for model selection exists. Towards that direction, this paper studies the performance of time series classification methods used as model selection for anomaly detection. In total, we evaluate 234 model configurations derived from 16 base classifiers across more than 1980 time series, and we propose the first extensive experimental evaluation of time series classification as model selection for anomaly detection. Our results demonstrate that model selection methods outperform every single anomaly detection method while being in the same order of magnitude regarding execution time. This evaluation is the first step to demonstrate the accuracy and efficiency of time series classification algorithms for anomaly detection, and represents a strong baseline that can then be used to guide the model selection step in general AutoML pipelines. Preprint version of an article accepted at the VLDB Journal.",
          "authors": [
            "Emmanouil Sylligardos",
            "John Paparrizos",
            "Themis Palpanas",
            "Pierre Senellart",
            "Paul Boniol"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.01732",
          "title": "Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection",
          "abstract": "We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET.",
          "authors": [
            "Liangkang Wang",
            "Akhil Ambekar",
            "Ani Eloyan"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.01732",
          "title": "Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection",
          "abstract": "We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET.",
          "authors": [
            "Liangkang Wang",
            "Akhil Ambekar",
            "Ani Eloyan"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.02802",
          "title": "TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models",
          "abstract": "Tabular foundation models represent a growing paradigm in structured data learning, extending the benefits of large-scale pretraining to tabular domains. However, their adoption remains limited due to heterogeneous preprocessing pipelines, fragmented APIs, inconsistent fine-tuning procedures, and the absence of standardized evaluation for deployment-oriented metrics such as calibration and fairness. We present TabTune, a unified library that standardizes the complete workflow for tabular foundation models through a single interface. TabTune provides consistent access to seven state-of-the-art models supporting multiple adaptation strategies, including zero-shot inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient fine-tuning (PEFT). The framework automates model-aware preprocessing, manages architectural heterogeneity internally, and integrates evaluation modules for performance, calibration, and fairness. Designed for extensibility and reproducibility, TabTune enables consistent benchmarking of adaptation strategies of tabular foundation models.",
          "authors": [
            "Aditya Tanna",
            "Pratinav Seth",
            "Mohamed Bouadi",
            "Utsav Avaiya",
            "Vinay Kumar Sankarapu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.03317",
          "title": "Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models",
          "abstract": "Text-to-image diffusion models deliver high-quality images, yet aligning them with human preferences remains challenging. We revisit diffusion-based Direct Preference Optimization (DPO) for these models and identify a critical pathology: enlarging the preference margin does not necessarily improve generation quality. In particular, the standard Diffusion-DPO objective can increase the reconstruction error of both winner and loser branches. Consequently, degradation of the less-preferred outputs can become sufficiently severe that the preferred branch is also adversely affected even as the margin grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule that preserves the winner by adaptively scaling the loser gradient according to its alignment with the winner gradient. A first-order analysis yields a closed-form scaling coefficient that guarantees the error of the preferred output is non-increasing at each optimization step. Our method is simple, model-agnostic, broadly compatible with existing DPO-style alignment frameworks and adds only marginal computational overhead. Across standard text-to-image benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning baselines on automated preference, aesthetic, and prompt alignment metrics. Code is publicly available at this https URL .",
          "authors": [
            "Minghao Fu",
            "Guo-Hua Wang",
            "Tianyu Cui",
            "Qing-Guo Chen",
            "Zhao Xu",
            "Weihua Luo",
            "Kaifu Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.03576",
          "title": "Multi-User Personalisation in Human-Robot Interaction: Resolving Preference Conflicts Using Gradual Argumentation",
          "abstract": "While personalisation in Human-Robot Interaction (HRI) has advanced significantly, most existing approaches focus on single-user adaptation, overlooking scenarios involving multiple stakeholders with potentially conflicting preferences. To address this, we propose the Multi-User Preferences Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user personalisation framework based on Quantitative Bipolar Argumentation Frameworks (QBAFs) that explicitly models and resolves multi-user preference conflicts. Unlike prior work in Argumentation Frameworks, which typically assumes static inputs, our approach is tailored to robotics: it incorporates both users' arguments and the robot's dynamic observations of the environment, allowing the system to adapt over time and respond to changing contexts. Preferences, both positive and negative, are represented as arguments whose strength is recalculated iteratively based on new information. The framework's properties and capabilities are presented and validated through a realistic case study, where an assistive robot mediates between the conflicting preferences of a caregiver and a care recipient during a frailty assessment task. This evaluation further includes a sensitivity analysis of argument base scores, demonstrating how preference outcomes can be shaped by user input and contextual observations. By offering a transparent, structured, and context-sensitive approach to resolving competing user preferences, this work advances the field of multi-user HRI. It provides a principled alternative to data-driven methods, enabling robots to navigate conflicts in real-world environments.",
          "authors": [
            "Aniol Civit",
            "Antonio Andriella",
            "Carles Sierra",
            "Guillem Alenyà"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.04694",
          "title": "Reasoning Up the Instruction Ladder for Controllable Language Models",
          "abstract": "As large language model (LLM) based systems take on high-stakes roles in real-world decision-making, they must reconcile competing instructions from multiple sources (e.g., model developers, users, and tools) within a single prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where higher-level directives override lower-priority requests, is critical for the reliability and controllability of LLMs. In this work, we reframe instruction hierarchy resolution as a reasoning task. Specifically, the model must first \"think\" about the relationship between a given user prompt and higher-priority (system) instructions before generating a response. To enable this capability via training, we construct VerIH, an instruction hierarchy dataset of constraint-following tasks with verifiable answers. This dataset comprises ~7K aligned and conflicting system-user instructions. We show that lightweight reinforcement learning with VerIH effectively transfers general reasoning capabilities of models to instruction prioritization. Our finetuned models achieve consistent improvements on instruction following and instruction hierarchy benchmarks, achieving roughly a 20% improvement on the IHEval conflict setup. This reasoning ability also generalizes to safety-critical settings beyond the training distribution. By treating safety issues as resolving conflicts between adversarial user inputs and predefined higher-priority policies, our trained model enhances robustness against jailbreak and prompt injection attacks, providing up to a 20% reduction in attack success rate (ASR). These results demonstrate that reasoning over instruction hierarchies provides a practical path to reliable LLMs, where updates to system prompts yield controllable and robust changes in model behavior.",
          "authors": [
            "Zishuo Zheng",
            "Vidhisha Balachandran",
            "Chan Young Park",
            "Faeze Brahman",
            "Sachin Kumar"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05706",
          "title": "AdvisingWise: Supporting Academic Advising in Higher Education Settings Through a Human-in-the-Loop Multi-Agent Framework",
          "abstract": "Academic advising is critical to student success in higher education, yet high student-to-advisor ratios limit advisors' capacity to provide timely support, particularly during peak periods. Recent advances in Large Language Models (LLMs) present opportunities to enhance the advising process. We present AdvisingWise, a multi-agent system that automates time-consuming tasks, such as information retrieval and response drafting, while preserving human oversight. AdvisingWise leverages authoritative institutional resources and adaptively prompts students about their academic backgrounds to generate reliable, personalized responses. All system responses undergo human advisor validation before delivery to students. We evaluate AdvisingWise through a mixed-methods approach: (1) expert evaluation on responses of 20 sample queries, (2) LLM-as-a-judge evaluation of the information retrieval strategy, and (3) a user study with 8 academic advisors to assess the system's practical utility. Our evaluation shows that AdvisingWise produces accurate, personalized responses. Advisors reported increasingly positive perceptions after using AdvisingWise, as their initial concerns about reliability and personalization diminished. We conclude by discussing the implications of human-AI synergy on the practice of academic advising.",
          "authors": [
            "Wendan Jiang",
            "Shiyuan Wang",
            "Hiba Eltigani",
            "Rukhshan Haroon",
            "Abdullah Bin Faisal",
            "Fahad Dogar"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05747",
          "title": "CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization",
          "abstract": "Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of large language models (LLMs) but leads to substantial inference overhead, limiting deployment in resource-constrained settings. This paper investigates efficient CoT transfer across models of different scales and architectures through an adaptive reasoning summarization framework. The proposed method compresses reasoning traces via semantic segmentation with importance scoring, budget-aware dynamic compression, and coherence reconstruction, preserving critical reasoning steps while significantly reducing token usage. Experiments on 7{,}501 medical examination questions across 10 specialties show up to 40% higher accuracy than truncation under the same token budgets. Evaluations on 64 model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian Process-based Bayesian optimization module reduces evaluation cost by 84% and reveals a power-law relationship between model size and cross-domain robustness. These results demonstrate that reasoning summarization provides a practical path toward efficient CoT transfer, enabling advanced reasoning under tight computational constraints. Code will be released upon publication.",
          "authors": [
            "Ziqian Bi",
            "Kaijie Chen",
            "Tianyang Wang",
            "Junfeng Hao",
            "Benji Peng",
            "Xinyuan Song"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.05858",
          "title": "ViTaMIn-B: A Reliable and Efficient Visuo-Tactile Bimanual Manipulation Interface",
          "abstract": "Handheld devices have opened up unprecedented opportunities to collect large-scale, high-quality demonstrations efficiently. However, existing systems often lack robust tactile sensing or reliable pose tracking to handle complex interaction scenarios, especially for bimanual and contact-rich tasks. In this work, we propose ViTaMIn-B, a more capable and efficient handheld data collection system for such tasks. We first design DuoTact, a novel compliant visuo-tactile sensor built with a flexible frame to withstand large contact forces during manipulation while capturing high-resolution contact geometry. To enhance the cross-sensor generalizability, we propose reconstructing the sensor's global deformation as a 3D point cloud and using it as the policy input. We further develop a robust, unified 6-DoF bimanual pose acquisition process using Meta Quest controllers, which eliminates the trajectory drift issue in common SLAM-based methods. Comprehensive user studies confirm the efficiency and high usability of ViTaMIn-B among novice and expert operators. Furthermore, experiments on four bimanual manipulation tasks demonstrate its superior task performance relative to existing systems. Project page: this https URL",
          "authors": [
            "Chuanyu Li",
            "Chaoyi Liu",
            "Daotan Wang",
            "Shuyu Zhang",
            "Lusong Li",
            "Zecui Zeng",
            "Fangchen Liu",
            "Jing Xu",
            "Rui Chen"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06080",
          "title": "AIDEN: Design and Pilot Study of an AI Assistant for the Visually Impaired",
          "abstract": "This paper presents AIDEN, an artificial intelligence-based assistant designed to enhance the autonomy and daily quality of life of visually impaired individuals, who often struggle with object identification, text reading, and navigation in unfamiliar environments. Existing solutions such as screen readers or audio-based assistants facilitate access to information but frequently lead to auditory overload and raise privacy concerns in open environments. AIDEN addresses these limitations with a hybrid architecture that integrates You Only Look Once (YOLO) for real-time object detection and a Large Language and Vision Assistant (LLaVA) for scene description and Optical Character Recognition (OCR). A key novelty of the system is a continuous haptic guidance mechanism based on a Geiger-counter metaphor, which supports object centering without occupying the auditory channel, while privacy is preserved by ensuring that no personal data are stored. Empirical evaluations with visually impaired participants assessed perceived ease of use and acceptance using the Technology Acceptance Model (TAM). Results indicate high user satisfaction, particularly regarding intuitiveness and perceived autonomy. Moreover, the ``Find an Object'' achieved effective real-time performance. These findings provide promising evidence that multimodal haptic-visual feedback can improve daily usability and independence compared to traditional audio-centric methods, motivating larger-scale clinical validations.",
          "authors": [
            "Luis Marquez-Carpintero",
            "Francisco Gomez-Donoso",
            "Zuria Bauer",
            "Bessie Dominguez-Dager",
            "Alvaro Belmonte-Baeza",
            "Mónica Pina-Navarro",
            "Francisco Morillas-Espejo",
            "Felix Escalona",
            "Miguel Cazorla"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06246",
          "title": "IDMap: A Pseudo-Speaker Generator Framework Based on Speaker Identity Index to Vector Mapping",
          "abstract": "Facilitated by the speech generation framework that disentangles speech into content, speaker, and prosody, voice anonymization is accomplished by substituting the original speaker embedding vector with that of a pseudo-speaker. In this framework, the pseudo-speaker generation forms a fundamental challenge. Current pseudo-speaker generation methods demonstrate limitations in the uniqueness of pseudo-speakers, consequently restricting their effectiveness in voice privacy protection. Besides, existing model-based methods suffer from heavy computation costs. Especially, in the large-scale scenario where a huge number of pseudo-speakers are generated, the limitations of uniqueness and computational inefficiency become more significant. To this end, this paper proposes a framework for pseudo-speaker generation, which establishes a mapping from speaker identity index to speaker vector in the feedforward architecture, termed IDMap. Specifically, the framework is specified into two models: IDMap-MLP and IDMap-Diff. Experiments were conducted on both small- and large-scale evaluation datasets. Small-scale evaluations on the LibriSpeech dataset validated the effectiveness of the proposed IDMap framework in enhancing the uniqueness of pseudo-speakers, thereby improving voice privacy protection, while at a reduced computational cost. Large-scale evaluations on the MLS and Common Voice datasets further justified the superiority of the IDMap framework regarding the stability of the voice privacy protection capability as the number of pseudo-speakers increased. Audio samples and open-source code can be found in this https URL .",
          "authors": [
            "Zeyan Liu",
            "Liping Chen",
            "Kong Aik Lee",
            "Zhenhua Ling"
          ],
          "primary_category": "eess.AS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06741",
          "title": "Otter: Mitigating Background Distractions of Wide-Angle Few-Shot Action Recognition with Enhanced RWKV",
          "abstract": "Wide-angle videos in few-shot action recognition (FSAR) effectively express actions within specific scenarios. However, without a global understanding of both subjects and background, recognizing actions in such samples remains challenging because of the background distractions. Receptance Weighted Key Value (RWKV), which learns interaction between various dimensions, shows promise for global modeling. While directly applying RWKV to wide-angle FSAR may fail to highlight subjects due to excessive background information. Additionally, temporal relation degraded by frames with similar backgrounds is difficult to reconstruct, further impacting performance. Therefore, we design the CompOund SegmenTation and Temporal REconstructing RWKV (Otter). Specifically, the Compound Segmentation Module~(CSM) is devised to segment and emphasize key patches in each frame, effectively highlighting subjects against background information. The Temporal Reconstruction Module (TRM) is incorporated into the temporal-enhanced prototype construction to enable bidirectional scanning, allowing better reconstruct temporal relation. Furthermore, a regular prototype is combined with the temporal-enhanced prototype to simultaneously enhance subject emphasis and temporal modeling, improving wide-angle FSAR performance. Extensive experiments on benchmarks such as SSv2, Kinetics, UCF101, and HMDB51 demonstrate that Otter achieves state-of-the-art performance. Extra evaluation on the VideoBadminton dataset further validates the superiority of Otter in wide-angle FSAR.",
          "authors": [
            "Wenbo Huang",
            "Jinghui Zhang",
            "Zhenghao Chen",
            "Guang Li",
            "Lei Zhang",
            "Yang Cao",
            "Fang Dong",
            "Takahiro Ogawa",
            "Miki Haseyama"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.06942",
          "title": "HLPD: Aligning LLMs to Human Language Preference for Machine-Revised Text Detection",
          "abstract": "To prevent misinformation and social issues arising from trustworthy-looking content generated by LLMs, it is crucial to develop efficient and reliable methods for identifying the source of texts. Previous approaches have demonstrated exceptional performance in detecting texts fully generated by LLMs. However, these methods struggle when confronting more advanced LLM output or text with adversarial multi-task machine revision, especially in the black-box setting, where the generating model is unknown. To address this challenge, grounded in the hypothesis that human writing possesses distinctive stylistic patterns, we propose Human Language Preference Detection (HLPD). HLPD employs a reward-based alignment process, Human Language Preference Optimization (HLPO), to shift the scoring model's token distribution toward human-like writing, making the model more sensitive to human writing, therefore enhancing the identification of machine-revised text. We test HLPD in an adversarial multi-task evaluation framework that leverages a five-dimensional prompt generator and multiple advanced LLMs to create diverse revision scenarios. When detecting texts revised by GPT-series models, HLPD achieves a 15.11% relative improvement in AUROC over ImBD, surpassing Fast-DetectGPT by 45.56%. When evaluated on texts generated by advanced LLMs, HLPD achieves the highest average AUROC, exceeding ImBD by 5.53% and Fast-DetectGPT by 34.14%. Code will be made available at this https URL .",
          "authors": [
            "Fangqi Dai",
            "Xingjian Jiang",
            "Zizhuang Deng"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.08294",
          "title": "SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering",
          "abstract": "Accurate 3D human pose estimation is fundamental for applications such as augmented reality and human-robot interaction. State-of-the-art multi-view methods learn to fuse predictions across views by training on large annotated datasets, leading to poor generalization when the test scenario differs. To overcome these limitations, we propose SkelSplat, a novel framework for multi-view 3D human pose estimation based on differentiable Gaussian rendering. Human pose is modeled as a skeleton of 3D Gaussians, one per joint, optimized via differentiable rendering to enable seamless fusion of arbitrary camera views without 3D ground-truth supervision. Since Gaussian Splatting was originally designed for dense scene reconstruction, we propose a novel one-hot encoding scheme that enables independent optimization of human joints. SkelSplat outperforms approaches that do not rely on 3D ground truth in Human3.6M and CMU, while reducing the cross-dataset error up to 47.8% compared to learning-based methods. Experiments on Human3.6M-Occ and Occlusion-Person demonstrate robustness to occlusions, without scenario-specific fine-tuning. Our project page is available here: this https URL .",
          "authors": [
            "Laura Bragagnolo",
            "Leonardo Barcellona",
            "Stefano Ghidoni"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.09809",
          "title": "Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models",
          "abstract": "Vision-Language Models (VLMs) excel at zero-shot inference but often degrade under test-time domain shifts. For this reason, episodic test-time adaptation strategies have recently emerged as powerful techniques for adapting VLMs to a single unlabeled image. However, existing adaptation strategies, such as test-time prompt tuning, typically require backpropagating through large encoder weights or altering core model components. In this work, we introduce Spectrum-Aware Test-Time Steering (STS), a lightweight adaptation framework that extracts a spectral subspace from the textual embeddings to define principal semantic directions and learns to steer latent representations in a spectrum-aware manner by adapting a small number of per-sample shift parameters to minimize entropy across augmented views. STS operates entirely at inference in the latent space, without backpropagation through or modification of the frozen encoders. Building on standard evaluation protocols, our comprehensive experiments demonstrate that STS largely surpasses or compares favorably against state-of-the-art test-time adaptation methods, while introducing only a handful of additional parameters and achieving inference speeds up to 8x faster with a 12x smaller memory footprint than conventional test-time prompt tuning. The code is available at this https URL .",
          "authors": [
            "Konstantinos M. Dafnis",
            "Dimitris N. Metaxas"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.09956",
          "title": "Optimizing CPU Cache Utilization in Cloud VMs with Accurate Cache Abstraction",
          "abstract": "This paper shows that cache-based optimizations are often ineffective in cloud virtual machines (VMs) due to limited visibility into and control over provisioned caches. In public clouds, CPU caches can be partitioned or shared among VMs, but a VM is unaware of cache provisioning details. Moreover, a VM cannot influence cache usage via page placement policies, as memory-to-cache mappings are hidden. The paper proposes a novel solution, CacheX, which probes accurate and fine-grained cache abstraction within VMs using eviction sets without requiring hardware or hypervisor support, and showcases the utility of the probed information with two new techniques: LLC contention-aware task scheduling and virtual color-aware page cache management. Our evaluation of CacheX's implementation in x86 Linux kernel demonstrates that it can effectively improve cache utilization for various workloads in public cloud VMs.",
          "authors": [
            "Mani Tofigh",
            "Edward Guo",
            "Weiwei Jia",
            "Xiaoning Ding",
            "Zirui Neil Zhao",
            "Jianchen Shan"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11306",
          "title": "iMAD: Intelligent Multi-Agent Debate for Efficient and Accurate LLM Inference",
          "abstract": "Large Language Model (LLM) agent systems have advanced rapidly, driven by their strong generalization in zero-shot settings. To further enhance reasoning and accuracy on complex tasks, Multi-Agent Debate (MAD) has emerged as a promising framework that engages multiple LLM agents in structured debates to encourage diverse reasoning. However, triggering MAD for every query is inefficient, as it incurs substantial computational (token) cost and may even degrade accuracy by overturning correct single-agent answers. To address these limitations, we propose intelligent Multi-Agent Debate (iMAD), a token-efficient framework that selectively triggers MAD only when it is likely to be beneficial (i.e., correcting an initially wrong answer). To achieve this goal, iMAD learns generalizable model behaviors to make accurate debate decisions. Specifically, iMAD first prompts a single agent to produce a structured self-critique response, from which we extract 41 interpretable linguistic and semantic features capturing hesitation cues. Then, iMAD uses a lightweight debate-decision classifier, trained using our proposed FocusCal loss, to determine whether to trigger MAD, enabling robust debate decisions without test dataset-specific tuning. Through extensive experiments using six (visual) question answering datasets against five competitive baselines, we have shown that iMAD significantly reduces token usage (by up to 92%) while also improving final answer accuracy (by up to 13.5%).",
          "authors": [
            "Wei Fan",
            "JinYi Yoon",
            "Bo Ji"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11722",
          "title": "Fast 3D Surrogate Modeling for Data Center Thermal Management",
          "abstract": "Reducing energy consumption and carbon emissions in data centers by enabling real-time temperature prediction is critical for sustainability and operational efficiency. Achieving this requires accurate modeling of the 3D temperature field to capture airflow dynamics and thermal interactions under varying operating conditions. Traditional thermal CFD solvers, while accurate, are computationally expensive and require expert-crafted meshes and boundary conditions, making them impractical for real-time use. To address these limitations, we develop a vision-based surrogate modeling framework that operates directly on a 3D voxelized representation of the data center, incorporating server workloads, fan speeds, and HVAC temperature set points. We evaluate multiple architectures, including 3D CNN U-Net variants, a 3D Fourier Neural Operator, and 3D vision transformers, to map these thermal inputs to high-fidelity heat maps. Our results show that the surrogate models generalize across data center configurations and significantly speed up computations (20,000x), from hundreds of milliseconds to hours. This fast and accurate estimation of hot spots and temperature distribution enables real-time cooling control and workload redistribution, leading to substantial energy savings (7\\%) and reduced carbon footprint.",
          "authors": [
            "Soumyendu Sarkar",
            "Antonio Guillen-Perez",
            "Zachariah J Carmichael",
            "Avisek Naug",
            "Refik Mert Cam",
            "Vineet Gundecha",
            "Ashwin Ramesh Babu",
            "Sahand Ghorbanpour",
            "Ricardo Luna Gutierrez"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.11722",
          "title": "Fast 3D Surrogate Modeling for Data Center Thermal Management",
          "abstract": "Reducing energy consumption and carbon emissions in data centers by enabling real-time temperature prediction is critical for sustainability and operational efficiency. Achieving this requires accurate modeling of the 3D temperature field to capture airflow dynamics and thermal interactions under varying operating conditions. Traditional thermal CFD solvers, while accurate, are computationally expensive and require expert-crafted meshes and boundary conditions, making them impractical for real-time use. To address these limitations, we develop a vision-based surrogate modeling framework that operates directly on a 3D voxelized representation of the data center, incorporating server workloads, fan speeds, and HVAC temperature set points. We evaluate multiple architectures, including 3D CNN U-Net variants, a 3D Fourier Neural Operator, and 3D vision transformers, to map these thermal inputs to high-fidelity heat maps. Our results show that the surrogate models generalize across data center configurations and significantly speed up computations (20,000x), from hundreds of milliseconds to hours. This fast and accurate estimation of hot spots and temperature distribution enables real-time cooling control and workload redistribution, leading to substantial energy savings (7\\%) and reduced carbon footprint.",
          "authors": [
            "Soumyendu Sarkar",
            "Antonio Guillen-Perez",
            "Zachariah J Carmichael",
            "Avisek Naug",
            "Refik Mert Cam",
            "Vineet Gundecha",
            "Ashwin Ramesh Babu",
            "Sahand Ghorbanpour",
            "Ricardo Luna Gutierrez"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.12578",
          "title": "TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction",
          "abstract": "We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.",
          "authors": [
            "Yukuo Ma",
            "Cong Liu",
            "Junke Wang",
            "Junqi Liu",
            "Haibin Huang",
            "Zuxuan Wu",
            "Chi Zhang",
            "Xuelong Li"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.13208",
          "title": "End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer",
          "abstract": "Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames. Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation. Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a 6.0 mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video based approaches, while offering significant gains in efficiency. Project page: this https URL .",
          "authors": [
            "Yonghui Yu",
            "Jiahang Cai",
            "Xun Wang",
            "Wenwu Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.13922",
          "title": "Self-Supervised Compression and Artifact Correction for Streaming Underwater Imaging Sonar",
          "abstract": "Real-time imaging sonar is crucial for underwater monitoring where optical sensing fails, but its use is limited by low uplink bandwidth and severe sonar-specific artifacts (speckle, motion blur, reverberation, acoustic shadows) affecting up to 98% of frames. We present SCOPE, a self-supervised framework that jointly performs compression and artifact correction without clean-noise pairs or synthetic assumptions. SCOPE combines (i) Adaptive Codebook Compression (ACC), which learns frequency-encoded latent representations tailored to sonar, with (ii) Frequency-Aware Multiscale Segmentation (FAMS), which decomposes frames into low-frequency structure and sparse high-frequency dynamics while suppressing rapidly fluctuating artifacts. A hedging training strategy further guides frequency-aware learning using low-pass proxy pairs generated without labels. Evaluated on months of in-situ ARIS sonar data, SCOPE achieves a structural similarity index (SSIM) of 0.77, representing a 40% improvement over prior self-supervised denoising baselines, at bitrates down to <= 0.0118 bpp. It reduces uplink bandwidth by more than 80% while improving downstream detection. The system runs in real time, with 3.1 ms encoding on an embedded GPU and 97 ms full multi-layer decoding on the server end. SCOPE has been deployed for months in three Pacific Northwest rivers to support real-time salmon enumeration and environmental monitoring in the wild. Results demonstrate that learning frequency-structured latents enables practical, low-bitrate sonar streaming with preserved signal details under real-world deployment conditions.",
          "authors": [
            "Rongsheng Qian",
            "Chi Xu",
            "Xiaoqiang Ma",
            "Hao Fang",
            "Yili Jin",
            "William I. Atlas",
            "Jiangchuan Liu"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.13922",
          "title": "Self-Supervised Compression and Artifact Correction for Streaming Underwater Imaging Sonar",
          "abstract": "Real-time imaging sonar is crucial for underwater monitoring where optical sensing fails, but its use is limited by low uplink bandwidth and severe sonar-specific artifacts (speckle, motion blur, reverberation, acoustic shadows) affecting up to 98% of frames. We present SCOPE, a self-supervised framework that jointly performs compression and artifact correction without clean-noise pairs or synthetic assumptions. SCOPE combines (i) Adaptive Codebook Compression (ACC), which learns frequency-encoded latent representations tailored to sonar, with (ii) Frequency-Aware Multiscale Segmentation (FAMS), which decomposes frames into low-frequency structure and sparse high-frequency dynamics while suppressing rapidly fluctuating artifacts. A hedging training strategy further guides frequency-aware learning using low-pass proxy pairs generated without labels. Evaluated on months of in-situ ARIS sonar data, SCOPE achieves a structural similarity index (SSIM) of 0.77, representing a 40% improvement over prior self-supervised denoising baselines, at bitrates down to <= 0.0118 bpp. It reduces uplink bandwidth by more than 80% while improving downstream detection. The system runs in real time, with 3.1 ms encoding on an embedded GPU and 97 ms full multi-layer decoding on the server end. SCOPE has been deployed for months in three Pacific Northwest rivers to support real-time salmon enumeration and environmental monitoring in the wild. Results demonstrate that learning frequency-structured latents enables practical, low-bitrate sonar streaming with preserved signal details under real-world deployment conditions.",
          "authors": [
            "Rongsheng Qian",
            "Chi Xu",
            "Xiaoqiang Ma",
            "Hao Fang",
            "Yili Jin",
            "William I. Atlas",
            "Jiangchuan Liu"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.14763",
          "title": "Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm",
          "abstract": "Membership Inference Attack (MIA) aims to determine whether a specific data sample was included in the training dataset of a target model. Traditional MIA approaches rely on shadow models to mimic target model behavior, but their effectiveness diminishes for Large Language Model (LLM)-based recommendation systems due to the scale and complexity of training data. This paper introduces a novel knowledge distillation-based MIA paradigm tailored for LLM-based recommendation systems. Our method constructs a reference model via distillation, applying distinct strategies for member and non-member data to enhance discriminative capabilities. The paradigm extracts fused features (e.g., confidence, entropy, loss, and hidden layer vectors) from the reference model to train an attack model, overcoming limitations of individual features. Extensive experiments on extended datasets ( this http URL , MovieLens, Book-Crossing, Delicious) and diverse LLMs (T5, GPT-2, LLaMA3) demonstrate that our approach significantly outperforms shadow model-based MIAs and individual-feature baselines. The results show its practicality for privacy attacks in LLM-driven recommender systems.",
          "authors": [
            "Li Cuihong",
            "Huang Xiaowen",
            "Yin Chuanhuan",
            "Sang Jitao"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.14801",
          "title": "IHearYou: Linking Acoustic Features to DSM-5 Depressive Behavior Indicators",
          "abstract": "Depression affects over millions people worldwide, yet diagnosis still relies on subjective self-reports and interviews that may not capture authentic behavior. We present IHearYou, an approach to automated depression detection focused on speech acoustics. Using passive sensing in household environments, IHearYou extracts voice features and links them to DSM-5 (Diagnostic and Statistical Manual of Mental Disorders) indicators through a structured Linkage Framework instantiated for Major Depressive Disorder. The system runs locally to preserve privacy and includes a persistence schema and dashboard, presenting real-time throughput on a commodity laptop. To ensure reproducibility, we define a configuration-driven protocol with False Discovery Rate (FDR) correction and gender-stratified testing. Applied to the DAIC-WOZ dataset, this protocol reveals directionally consistent feature-indicator associations, while a TESS-based audio streaming experiment validates end-to-end feasibility. Our results show how passive voice sensing can be turned into explainable DSM-5 indicator scores, bridging the gap between black-box detection and clinically interpretable, on-device analysis.",
          "authors": [
            "Jonas Länzlinger",
            "Katharina Müller",
            "Burkhard Stiller",
            "Bruno Rodrigues"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15679",
          "title": "Front-door Reducibility: Reducing ADMGs to the Standard Front-door Setting via a Graphical Criterion",
          "abstract": "Front-door adjustment gives a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow. By contrast, the general ID algorithm can identify many more causal effects in arbitrary graphs, yet typically outputs algebraically complex expressions that are hard to estimate and interpret. We show that many such graphs can in fact be reduced to a standard front-door setting via front-door reducibility (FDR), a graphical condition on acyclic directed mixed graphs that aggregates variables into super-nodes $(\\boldsymbol{X}^{*},\\boldsymbol{Y}^{*},\\boldsymbol{M}^{*})$. We characterize the FDR criterion, prove it is equivalent (at the graph level) to the existence of an FDR adjustment, and present FDR-TID, an exact algorithm that finds an admissible FDR triple with correctness, completeness, and finite-termination guarantees. Empirical examples show that many graphs far outside the textbook front-door setting are FDR, yielding simple, estimable adjustments where general ID expressions would be cumbersome. FDR therefore complements existing identification methods by prioritizing interpretability and computational simplicity without sacrificing generality across mixed graphs.",
          "authors": [
            "Jianqiao Mao",
            "Max A. Little"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15679",
          "title": "Front-door Reducibility: Reducing ADMGs to the Standard Front-door Setting via a Graphical Criterion",
          "abstract": "Front-door adjustment gives a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow. By contrast, the general ID algorithm can identify many more causal effects in arbitrary graphs, yet typically outputs algebraically complex expressions that are hard to estimate and interpret. We show that many such graphs can in fact be reduced to a standard front-door setting via front-door reducibility (FDR), a graphical condition on acyclic directed mixed graphs that aggregates variables into super-nodes $(\\boldsymbol{X}^{*},\\boldsymbol{Y}^{*},\\boldsymbol{M}^{*})$. We characterize the FDR criterion, prove it is equivalent (at the graph level) to the existence of an FDR adjustment, and present FDR-TID, an exact algorithm that finds an admissible FDR triple with correctness, completeness, and finite-termination guarantees. Empirical examples show that many graphs far outside the textbook front-door setting are FDR, yielding simple, estimable adjustments where general ID expressions would be cumbersome. FDR therefore complements existing identification methods by prioritizing interpretability and computational simplicity without sacrificing generality across mixed graphs.",
          "authors": [
            "Jianqiao Mao",
            "Max A. Little"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15856",
          "title": "GLOBE: Accurate and Generalizable PDE Surrogates using Domain-Inspired Architectures and Equivariances",
          "abstract": "We introduce GLOBE, a new neural surrogate for homogeneous PDEs that draws inductive bias from boundary-element methods and equivariant ML. GLOBE represents solutions as superpositions of learnable Green's-function-like kernels evaluated from boundary faces to targets, composed across multiscale branches and communication hyperlayers. The architecture is translation-, rotation-, and parity-equivariant; discretization-invariant in the fine-mesh limit; and units-invariant via rigorous nondimensionalization. An explicit far-field decay envelope stabilizes extrapolation, boundary-to-boundary hyperlayer communication mediates long-range coupling, and the all-to-all boundary-to-target evaluation yields a global receptive field that respects PDE information flow, even for elliptic PDEs. On AirFRANS (steady incompressible RANS over NACA airfoils), GLOBE achieves substantial accuracy improvements. On the \"Full\" split, it reduces mean-squared error by roughly 200x on all fields relative to the dataset's reference baselines, and roughly 50x relative to the next-best-performing model. In the \"Scarce\" split, it achieves over 100x lower error on velocity and pressure fields and over 600x lower error on surface pressure than Transolver. Qualitative results show sharp near-wall gradients, coherent wakes, and limited errors under modest extrapolation in Reynolds number and angle of attack. In addition to this accuracy, the model is quite compact (117k parameters), and fields can be evaluated at arbitrary points during inference. We also demonstrate the ability to train and predict with non-watertight meshes, which has strong practical implications. These results show that rigorous physics- and domain-inspired inductive biases can achieve large gains in accuracy, generalizability, and practicality for ML-based PDE surrogates for industrial computer-aided engineering (CAE).",
          "authors": [
            "Peter Sharpe"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.15856",
          "title": "GLOBE: Accurate and Generalizable PDE Surrogates using Domain-Inspired Architectures and Equivariances",
          "abstract": "We introduce GLOBE, a new neural surrogate for homogeneous PDEs that draws inductive bias from boundary-element methods and equivariant ML. GLOBE represents solutions as superpositions of learnable Green's-function-like kernels evaluated from boundary faces to targets, composed across multiscale branches and communication hyperlayers. The architecture is translation-, rotation-, and parity-equivariant; discretization-invariant in the fine-mesh limit; and units-invariant via rigorous nondimensionalization. An explicit far-field decay envelope stabilizes extrapolation, boundary-to-boundary hyperlayer communication mediates long-range coupling, and the all-to-all boundary-to-target evaluation yields a global receptive field that respects PDE information flow, even for elliptic PDEs. On AirFRANS (steady incompressible RANS over NACA airfoils), GLOBE achieves substantial accuracy improvements. On the \"Full\" split, it reduces mean-squared error by roughly 200x on all fields relative to the dataset's reference baselines, and roughly 50x relative to the next-best-performing model. In the \"Scarce\" split, it achieves over 100x lower error on velocity and pressure fields and over 600x lower error on surface pressure than Transolver. Qualitative results show sharp near-wall gradients, coherent wakes, and limited errors under modest extrapolation in Reynolds number and angle of attack. In addition to this accuracy, the model is quite compact (117k parameters), and fields can be evaluated at arbitrary points during inference. We also demonstrate the ability to train and predict with non-watertight meshes, which has strong practical implications. These results show that rigorous physics- and domain-inspired inductive biases can achieve large gains in accuracy, generalizability, and practicality for ML-based PDE surrogates for industrial computer-aided engineering (CAE).",
          "authors": [
            "Peter Sharpe"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16024",
          "title": "Mixture of Ranks with Degradation-Aware Routing for One-Step Real-World Image Super-Resolution",
          "abstract": "The demonstrated success of sparsely-gated Mixture-of-Experts (MoE) architectures, exemplified by models such as DeepSeek and Grok, has motivated researchers to investigate their adaptation to diverse domains. In real-world image super-resolution (Real-ISR), existing approaches mainly rely on fine-tuning pre-trained diffusion models through Low-Rank Adaptation (LoRA) module to reconstruct high-resolution (HR) images. However, these dense Real-ISR models are limited in their ability to adaptively capture the heterogeneous characteristics of complex real-world degraded samples or enable knowledge sharing between inputs under equivalent computational budgets. To address this, we investigate the integration of sparse MoE into Real-ISR and propose a Mixture-of-Ranks (MoR) architecture for single-step image super-resolution. We introduce a fine-grained expert partitioning strategy that treats each rank in LoRA as an independent expert. This design enables flexible knowledge recombination while isolating fixed-position ranks as shared experts to preserve common-sense features and minimize routing redundancy. Furthermore, we develop a degradation estimation module leveraging CLIP embeddings and predefined positive-negative text pairs to compute relative degradation scores, dynamically guiding expert activation. To better accommodate varying sample complexities, we incorporate zero-expert slots and propose a degradation-aware load-balancing loss, which dynamically adjusts the number of active experts based on degradation severity, ensuring optimal computational resource allocation. Comprehensive experiments validate our framework's effectiveness and state-of-the-art performance.",
          "authors": [
            "Xiao He",
            "Zhijun Tu",
            "Kun Cheng",
            "Mingrui Zhu",
            "Jie Hu",
            "Nannan Wang",
            "Xinbo Gao"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16690",
          "title": "AI Text Detectors and the Misclassification of Slightly Polished Arabic Text",
          "abstract": "Many AI detection models have been developed to counter the presence of articles created by artificial intelligence (AI). However, if a human-authored article is slightly polished by AI, a shift will occur in the borderline decision of these AI detection models, leading them to consider it as AI-generated article. This misclassification may result in falsely accusing authors of AI plagiarism and harm the credibility of AI detectors. In English, some efforts were made to meet this challenge, but not in Arabic. In this paper, we generated two datasets. The first dataset contains 800 Arabic articles, half AI-generated and half human-authored. We used it to evaluate 14 Large Language models (LLMs) and commercial AI detectors to assess their ability in distinguishing between human-authored and AI-generated articles. The best 8 models were chosen to act as detectors for our primary concern, which is whether they would consider slightly polished human-authored text as AI-generated. The second dataset, Ar-APT, contains 400 Arabic human-authored articles polished by 10 LLMs using 4 polishing settings, totaling 16400 samples. We use it to evaluate the 8 nominated models and determine whether slight polishing will affect their performance. The results reveal that all AI detectors incorrectly attribute a significant number of articles to AI. The best performing LLM, Claude-4 Sonnet, achieved 83.51\\%, its performance decreased to 57.63\\% for articles slightly polished by LLaMA-3. Whereas the best performing commercial model, this http URL , achieves 92\\% accuracy, dropped to 12\\% for articles slightly polished by Mistral or Gemma-3.",
          "authors": [
            "Saleh Almohaimeed",
            "Saad Almohaimeed",
            "Mousa Jari",
            "Khaled A. Alobaid",
            "Fahad Alotaibi"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16708",
          "title": "Multi-Agent Code Verification via Information Theory",
          "abstract": "LLMs generate buggy code: 29.6% of SWE-bench solved patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, using submodularity of mutual information under conditional independence. Measuring agent correlation of rho = 0.05 to 0.25 confirms they detect different bugs. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method (Meta Prompt Testing: 75%) while running faster and without test execution. We tested all 15 agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with diminishing returns of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4, validating our theoretical model. The best two-agent combination (Correctness + Performance) reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.",
          "authors": [
            "Shreshth Rajan"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16854",
          "title": "MRI Super-Resolution with Deep Learning: A Comprehensive Survey",
          "abstract": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: this https URL . IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.",
          "authors": [
            "Mohammad Khateri",
            "Serge Vasylechko",
            "Morteza Ghahremani",
            "Liam Timms",
            "Deniz Kocanaogullari",
            "Simon K. Warfield",
            "Camilo Jaimes",
            "Davood Karimi",
            "Alejandra Sierra",
            "Jussi Tohka",
            "Sila Kurugol",
            "Onur Afacan"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16854",
          "title": "MRI Super-Resolution with Deep Learning: A Comprehensive Survey",
          "abstract": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: this https URL . IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.",
          "authors": [
            "Mohammad Khateri",
            "Serge Vasylechko",
            "Morteza Ghahremani",
            "Liam Timms",
            "Deniz Kocanaogullari",
            "Simon K. Warfield",
            "Camilo Jaimes",
            "Davood Karimi",
            "Alejandra Sierra",
            "Jussi Tohka",
            "Sila Kurugol",
            "Onur Afacan"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.16884",
          "title": "Generative AI in Sociological Research: State of the Discipline",
          "abstract": "Generative artificial intelligence (GenAI) has garnered considerable attention for its potential utility in research and scholarship. A growing body of work in sociology and related fields demonstrates both the potential advantages and risks of GenAI, but these studies are largely proof-of-concept or specific audits of models and products. We know comparatively little about how sociologists actually use GenAI in their research practices and how they view its present and future role in the discipline. In this paper, we describe the current landscape of GenAI use in sociological research based on a survey of authors in 50 sociology journals. Our sample includes both computational sociologists and non-computational sociologists and their collaborators. We find that sociologists primarily use GenAI to assist with writing tasks: revising, summarizing, editing, and translating their own work. Respondents report that GenAI saves time and that they are curious about its capabilities, but they do not currently feel strong institutional or field-level pressure to adopt it. Overall, respondents are wary of GenAI's social and environmental impacts and express low levels of trust in its outputs, but many believe that GenAI tools will improve over the next several years. We do not find large differences between computational and non-computational scholars in terms of GenAI use, attitudes, and concern; nor do we find strong patterns by familiarity or frequency of use. We discuss what these findings suggest about the future of GenAI in sociology and highlight challenges for developing shared norms around its use in research practice.",
          "authors": [
            "AJ Alvero",
            "Dustin S. Stoltz",
            "Oscar Stuhler",
            "Marshall Taylor"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17467",
          "title": "PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM",
          "abstract": "We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's \"persona\" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at this https URL",
          "authors": [
            "Siqi Liang",
            "Yudi Zhang",
            "Yue Guo"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.17722",
          "title": "Can Vision-Language Models Count? A Synthetic Benchmark and Analysis of Attention-Based Interventions",
          "abstract": "Recent research suggests that Vision Language Models (VLMs) often rely on inherent biases learned during training when responding to queries about visual properties of images. These biases are exacerbated when VLMs are asked highly specific questions that require them to focus on particular areas of the image in tasks such as counting. We build upon this research by developing a synthetic benchmark dataset and evaluation framework to systematically determine how counting performance varies as image and prompt properties change. Using open-source VLMs, we then analyze how attention allocation fluctuates with varying input parameters (e.g. number of objects in the image, objects color, background color, objects texture, background texture, and prompt specificity). We further implement attention-based interventions to modulate focus on visual tokens at different layers and evaluate their impact on counting performance across a range of visual conditions. Our experiments reveal that while VLM counting performance remains challenging, especially under high visual or linguistic complexity, certain attention interventions can lead to modest gains in counting performance.",
          "authors": [
            "Saurav Sengupta",
            "Nazanin Moradinasab",
            "Jiebei Liu",
            "Donald E. Brown"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18507",
          "title": "Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives",
          "abstract": "Continual learning in visual understanding aims to deal with catastrophic forgetting in Multimodal Large Language Models (MLLMs). MLLMs deployed on devices have to continuously adapt to dynamic scenarios in downstream tasks, such as variations in background and perspective, to effectively perform complex visual tasks. To this end, we construct a multimodal visual understanding dataset (MSVQA) encompassing four different scenarios and perspectives including high altitude, underwater, low altitude and indoor, to investigate the catastrophic forgetting in MLLMs under the dynamics of scenario shifts in real-world data streams. Furthermore, we propose mUltimodal coNtInual learning with MLLMs From multi-scenarIo pERspectives (UNIFIER) to address visual discrepancies while learning different scenarios. Specifically, it decouples the visual information from different scenarios into distinct branches within each vision block and projects them into the same feature space. A consistency constraint is imposed on the features of each branch to maintain the stability of visual representations across scenarios. Extensive experiments on the MSVQA dataset demonstrate that UNIFIER effectively alleviates forgetting of cross-scenario tasks and achieves knowledge accumulation within the same scenario.",
          "authors": [
            "Kai Jiang",
            "Siqi Huang",
            "Xiangyu Chen",
            "Jiawei Shao",
            "Hongyuan Zhang",
            "Xuelong Li"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18538",
          "title": "From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence",
          "abstract": "Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.",
          "authors": [
            "Jian Yang",
            "Xianglong Liu",
            "Weifeng Lv",
            "Ken Deng",
            "Shawn Guo",
            "Lin Jing",
            "Yizhi Li",
            "Shark Liu",
            "Xianzhen Luo",
            "Yuyu Luo",
            "Changzai Pan",
            "Ensheng Shi",
            "Yingshui Tan",
            "Renshuai Tao",
            "Jiajun Wu",
            "Xianjie Wu",
            "Zhenhe Wu",
            "Daoguang Zan",
            "Chenchen Zhang",
            "Wei Zhang",
            "He Zhu",
            "Terry Yue Zhuo",
            "Kerui Cao",
            "Xianfu Cheng",
            "Jun Dong",
            "Shengjie Fang",
            "Zhiwei Fei",
            "Xiangyuan Guan",
            "Qipeng Guo",
            "Zhiguang Han",
            "Joseph James",
            "Tianqi Luo",
            "Renyuan Li",
            "Yuhang Li",
            "Yiming Liang",
            "Congnan Liu",
            "Jiaheng Liu",
            "Qian Liu",
            "Ruitong Liu",
            "Tyler Loakman",
            "Xiangxin Meng",
            "Chuang Peng",
            "Tianhao Peng",
            "Jiajun Shi",
            "Mingjie Tang",
            "Boyang Wang",
            "Haowen Wang",
            "Yunli Wang",
            "Fanglin Xu",
            "Zihan Xu",
            "Fei Yuan",
            "Ge Zhang",
            "Jiayi Zhang",
            "Xinhao Zhang",
            "Wangchunshu Zhou",
            "Hualei Zhu",
            "King Zhu",
            "Bryan Dai",
            "Aishan Liu",
            "Zhoujun Li",
            "Chenghua Lin",
            "Tianyu Liu",
            "Chao Peng",
            "Kai Shen",
            "Libo Qin",
            "Shuangyong Song",
            "Zizheng Zhan",
            "Jiajun Zhang",
            "Jie Zhang",
            "Zhaoxiang Zhang",
            "Bo Zheng"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18688",
          "title": "Evaluation of GPU Video Encoder for Low-Latency Real-Time 4K UHD Encoding",
          "abstract": "The demand for high-quality, real-time video streaming has grown exponentially, with 4K Ultra High Definition (UHD) becoming the new standard for many applications such as live broadcasting, TV services, and interactive cloud gaming. This trend has driven the integration of dedicated hardware encoders into modern Graphics Processing Units (GPUs). Nowadays, these encoders support advanced codecs like HEVC and AV1 and feature specialized Low-Latency and Ultra Low-Latency tuning, targeting end-to-end latencies of < 2 seconds and < 500 ms, respectively. As the demand for such capabilities grows toward the 6G era, a clear understanding of their performance implications is essential. In this work, we evaluate the low-latency encoding modes on GPUs from NVIDIA, Intel, and AMD from both Rate-Distortion (RD) performance and latency perspectives. The results are then compared against both the normal-latency tuning of hardware encoders and leading software encoders. Results show hardware encoders achieve significantly lower E2E latency than software solutions with slightly better RD performance. While standard Low-Latency tuning yields a poor quality-latency trade-off, the Ultra Low-Latency mode reduces E2E latency to 83 ms (5 frames) without additional RD impact. Furthermore, hardware encoder latency is largely insensitive to quality presets, enabling high-quality, low-latency streams without compromise.",
          "authors": [
            "Kasidis Arunruangsirilert",
            "Jiro Katto"
          ],
          "primary_category": "cs.AR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18843",
          "title": "A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis",
          "abstract": "Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a systematic framework for applying BERTopic to focus group transcripts using data from ten focus groups exploring HPV vaccine perceptions in Tunisia (1,075 utterances). We conducted comprehensive hyperparameter exploration across 27 configurations, evaluating each through bootstrap stability analysis, performance metrics, and comparison with LDA baseline. Bootstrap analysis revealed that stability metrics (NMI and ARI) exhibited strong disagreement (r = -0.691) and showed divergent relationships with coherence, demonstrating that stability is multifaceted rather than monolithic. Our multi-criteria selection framework yielded a 7-topic model achieving 18\\% higher coherence than optimized LDA (0.573 vs. 0.486) with interpretable topics validated through independent human evaluation (ICC = 0.700, weighted Cohen's kappa = 0.678). These findings demonstrate that transformer-based topic modeling can extract interpretable themes from small focus group transcript corpora when systematically configured and validated, while revealing that quality metrics capture distinct, sometimes conflicting constructs requiring multi-criteria evaluation. We provide complete documentation and code to support reproducibility.",
          "authors": [
            "Heger Arfaoui",
            "Mohammed Iheb Hergli",
            "Beya Benzina",
            "Slimane BenMiled"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.18960",
          "title": "AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention",
          "abstract": "Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.",
          "authors": [
            "Lei Xiao",
            "Jifeng Li",
            "Juntao Gao",
            "Feiyang Ye",
            "Yan Jin",
            "Jingjing Qian",
            "Jing Zhang",
            "Yong Wu",
            "Xiaoyuan Yu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19514",
          "title": "SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation",
          "abstract": "Harnessing the reasoning power of Large Language Models (LLMs) for recommender systems is hindered by two fundamental challenges. First, current approaches lack a mechanism for automated, data-driven discovery of effective reasoning patterns, relying instead on brittle manual templates or unstable zero-shot prompting. Second, they employ structure-collapsing integration: direct prompting incurs prohibitive online inference costs, while feature extraction collapses reasoning chains into single vectors, discarding stepwise logic. To address these challenges, we propose SCoTER (Structured Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework that treats pattern discovery and structure-aware transfer as a jointly optimized problem. Specifically, SCoTER operationalizes this through two synergistic components: a GVM pipeline for automated pattern discovery and a structure-preserving integration architecture that transfers stepwise logic to efficient models. Formally, we provide information-theoretic justification proving that structure-preserving transfer achieves tighter performance bounds than structure-agnostic alternatives. Empirically, experiments on four benchmarks demonstrate improvements of 3.75\\%-11.59\\% over a strong TIGER backbone. Moreover, in production deployment on the Tencent Advertising Platform, SCoTER achieved a 2.14\\% lift in Gross Merchandise Value (GMV) while eliminating online LLM inference costs. Overall, SCoTER establishes a principled and production-validated blueprint for transferring structured LLM reasoning to large-scale recommender systems.",
          "authors": [
            "Yang Wu",
            "Qian Li",
            "Yuling Xiong",
            "Hongbo Tang",
            "Xun Liu",
            "Jun Zhang",
            "Huan Yu",
            "Jie Jiang",
            "Hailong Shi"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.19584",
          "title": "Learning Massively Multitask World Models for Continuous Control",
          "abstract": "General-purpose control demands agents that act across many tasks and embodiments, yet research on reinforcement learning (RL) for continuous control remains dominated by single-task or offline regimes, reinforcing a view that online RL does not scale. Inspired by the foundation model recipe (large-scale pretraining followed by light RL) we ask whether a single agent can be trained on hundreds of tasks with online interaction. To accelerate research in this direction, we introduce a new benchmark with 200 diverse tasks spanning many domains and embodiments, each with language instructions, demonstrations, and optionally image observations. We then present \\emph{Newt}, a language-conditioned multitask world model that is first pretrained on demonstrations to acquire task-aware representations and action priors, and then jointly optimized with online interaction across all tasks. Experiments show that Newt yields better multitask performance and data-efficiency than a set of strong baselines, exhibits strong open-loop control, and enables rapid adaptation to unseen tasks. We release our environments, demonstrations, code for training and evaluation, as well as 200+ checkpoints.",
          "authors": [
            "Nicklas Hansen",
            "Hao Su",
            "Xiaolong Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20225",
          "title": "DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised Multi-Label Learning",
          "abstract": "Semi-supervised multi-label learning (SSMLL) aims to address the challenge of limited labeled data in multi-label learning (MLL) by leveraging unlabeled data to improve the model's performance. While pseudo-labeling has become a dominant strategy in SSMLL, most existing methods assign equal weights to all pseudo-labels regardless of their quality, which can amplify the impact of noisy or uncertain predictions and degrade the overall performance. In this paper, we theoretically verify that the optimal weight for a pseudo-label should reflect its correctness likelihood. Empirically, we observe that on the same dataset, the correctness likelihood distribution of unlabeled data remains stable, even as the number of labeled training samples varies. Building on this insight, we propose Distribution-Calibrated Pseudo-labeling (DiCaP), a correctness-aware framework that estimates posterior precision to calibrate pseudo-label weights. We further introduce a dual-thresholding mechanism to separate confident and ambiguous regions: confident samples are pseudo-labeled and weighted accordingly, while ambiguous ones are explored by unsupervised contrastive learning. Experiments conducted on multiple benchmark datasets verify that our method achieves consistent improvements, surpassing state-of-the-art methods by up to 4.27%.",
          "authors": [
            "Bo Han",
            "Zhuoming Li",
            "Xiaoyu Wang",
            "Yaxin Hou",
            "Hui Liu",
            "Junhui Hou",
            "Yuheng Jia"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20515",
          "title": "AlignBench: Benchmarking Fine-Grained Image-Text Alignment with Synthetic Image-Caption Pairs",
          "abstract": "Assessing image-text alignment models such as CLIP is crucial for bridging visual and linguistic representations. Yet existing benchmarks rely on rule-based perturbations or short captions, limiting their ability to measure fine-grained alignment. We introduce AlignBench, a benchmark that provides a new indicator of image-text alignment by evaluating detailed image-caption pairs generated by diverse image-to-text and text-to-image models. Each sentence is annotated for correctness, enabling direct assessment of VLMs as alignment evaluators. Benchmarking a wide range of decoder-based VLMs reveals three key findings: (i) CLIP-based models, even those tailored for compositional reasoning, remain nearly blind; (ii) detectors systematically over-score early sentences; and (iii) they show strong self-preference, favoring their own outputs and harming detection performance. Our project page will be available at this https URL .",
          "authors": [
            "Kuniaki Saito",
            "Risa Shinoda",
            "Shohei Tanaka",
            "Tosho Hirasawa",
            "Fumio Okura",
            "Yoshitaka Ushiku"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20532",
          "title": "MIMIC-MJX: Neuromechanical Emulation of Animal Behavior",
          "abstract": "The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.",
          "authors": [
            "Charles Y. Zhang",
            "Yuanjia Yang",
            "Aidan Sirbu",
            "Elliott T.T. Abe",
            "Emil Wärnberg",
            "Eric J. Leonardis",
            "Diego E. Aldarondo",
            "Adam Lee",
            "Aaditya Prasad",
            "Jason Foat",
            "Kaiwen Bian",
            "Joshua Park",
            "Rusham Bhatt",
            "Hutton Saunders",
            "Akira Nagamori",
            "Ayesha R. Thanawalla",
            "Kee Wui Huang",
            "Fabian Plum",
            "Hendrik K. Beck",
            "Steven W. Flavell",
            "David Labonte",
            "Blake A. Richards",
            "Bingni W. Brunton",
            "Eiman Azim",
            "Bence P. Ölveczky",
            "Talmo D. Pereira"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.20532",
          "title": "MIMIC-MJX: Neuromechanical Emulation of Animal Behavior",
          "abstract": "The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.",
          "authors": [
            "Charles Y. Zhang",
            "Yuanjia Yang",
            "Aidan Sirbu",
            "Elliott T.T. Abe",
            "Emil Wärnberg",
            "Eric J. Leonardis",
            "Diego E. Aldarondo",
            "Adam Lee",
            "Aaditya Prasad",
            "Jason Foat",
            "Kaiwen Bian",
            "Joshua Park",
            "Rusham Bhatt",
            "Hutton Saunders",
            "Akira Nagamori",
            "Ayesha R. Thanawalla",
            "Kee Wui Huang",
            "Fabian Plum",
            "Hendrik K. Beck",
            "Steven W. Flavell",
            "David Labonte",
            "Blake A. Richards",
            "Bingni W. Brunton",
            "Eiman Azim",
            "Bence P. Ölveczky",
            "Talmo D. Pereira"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21890",
          "title": "Sparse Multiple Kernel Learning: Alternating Best Response and Semidefinite Relaxations",
          "abstract": "We study Sparse Multiple Kernel Learning (SMKL), which is the problem of selecting a sparse convex combination of prespecified kernels for support vector binary classification. Unlike prevailing l1 regularized approaches that approximate a sparsifying penalty, we formulate the problem by imposing an explicit cardinality constraint on the kernel weights and add an l2 penalty for robustness. We solve the resulting non-convex minimax problem via an alternating best response algorithm with two subproblems: the alpha subproblem is a standard kernel SVM dual solved via LIBSVM, while the beta subproblem admits an efficient solution via the Greedy Selector and Simplex Projector algorithm. We reformulate SMKL as a mixed integer semidefinite optimization problem and derive a hierarchy of semidefinite convex relaxations which can be used to certify near-optimality of the solutions returned by our best response algorithm and also to warm start it. On ten UCI benchmarks, our method with random initialization outperforms state-of-the-art MKL approaches in out-of-sample prediction accuracy on average by 3.34 percentage points (relative to the best performing benchmark) while selecting a small number of candidate kernels in comparable runtime. With warm starting, our method outperforms the best performing benchmark's out-of-sample prediction accuracy on average by 4.05 percentage points. Our convex relaxations provide a certificate that in several cases, the solution returned by our best response algorithm is the globally optimal solution.",
          "authors": [
            "Dimitris Bertsimas",
            "Caio de Prospero Iglesias",
            "Nicholas A. G. Johnson"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.21890",
          "title": "Sparse Multiple Kernel Learning: Alternating Best Response and Semidefinite Relaxations",
          "abstract": "We study Sparse Multiple Kernel Learning (SMKL), which is the problem of selecting a sparse convex combination of prespecified kernels for support vector binary classification. Unlike prevailing l1 regularized approaches that approximate a sparsifying penalty, we formulate the problem by imposing an explicit cardinality constraint on the kernel weights and add an l2 penalty for robustness. We solve the resulting non-convex minimax problem via an alternating best response algorithm with two subproblems: the alpha subproblem is a standard kernel SVM dual solved via LIBSVM, while the beta subproblem admits an efficient solution via the Greedy Selector and Simplex Projector algorithm. We reformulate SMKL as a mixed integer semidefinite optimization problem and derive a hierarchy of semidefinite convex relaxations which can be used to certify near-optimality of the solutions returned by our best response algorithm and also to warm start it. On ten UCI benchmarks, our method with random initialization outperforms state-of-the-art MKL approaches in out-of-sample prediction accuracy on average by 3.34 percentage points (relative to the best performing benchmark) while selecting a small number of candidate kernels in comparable runtime. With warm starting, our method outperforms the best performing benchmark's out-of-sample prediction accuracy on average by 4.05 percentage points. Our convex relaxations provide a certificate that in several cases, the solution returned by our best response algorithm is the globally optimal solution.",
          "authors": [
            "Dimitris Bertsimas",
            "Caio de Prospero Iglesias",
            "Nicholas A. G. Johnson"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22154",
          "title": "WearVQA: A Visual Question Answering Benchmark for Wearables in Egocentric Authentic Real-world scenarios",
          "abstract": "We introduce WearVQA, the first benchmark specifically designed to evaluate the Visual Question Answering (VQA) capabilities of multi-model AI assistant on wearable devices like smart glasses. Unlike prior benchmarks that focus on high-quality, third-person imagery, WearVQA reflects the unique challenges of ego-centric interaction-where visual inputs may be occluded, poorly lit, unzoomed, or blurry, and questions are grounded in realistic wearable use cases. The benchmark comprises 2,520 carefully curated image-question-answer triplets, spanning 7 diverse image domains including both text-centric and general scenes, 10 cognitive task types ranging from basic recognition to various forms of reasoning, and 6 common wearables-specific image quality issues. All questions are designed to be answerable using only the visual input and common senses. WearVQA is paired with a rigorous LLM-as-a-judge evaluation framework with 96% labeling accuracy. Open-source and proprietary multi-model LLMs achieved a QA accuracy as low as 24-52% on WearVQA, with substantial drops on lower-quality images and reasoning-heavy tasks. These observations position WearVQA as a comprehensive and challenging benchmark for guiding technical advancement towards robust, real-world multi-model wearables AI systems.",
          "authors": [
            "Eun Chang",
            "Zhuangqun Huang",
            "Yiwei Liao",
            "Sagar Ravi Bhavsar",
            "Amogh Param",
            "Tammy Stark",
            "Adel Ahmadyan",
            "Xiao Yang",
            "Jiaqi Wang",
            "Ahsan Abdullah",
            "Giang Nguyen",
            "Akil Iyer",
            "David Hall",
            "Elissa Li",
            "Shane Moon",
            "Nicolas Scheffer",
            "Kirmani Ahmed",
            "Babak Damavandi",
            "Rakesh Wanga",
            "Anuj Kumar",
            "Rohit Patel",
            "Xin Luna Dong"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22307",
          "title": "Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language Model Feedback",
          "abstract": "Double perovskites (DPs) are promising candidates for sustainable energy technologies due to their compositional tunability and compatibility with low-energy fabrication, yet their vast design space poses a major challenge for conditional materials discovery. This work introduces a multi-agent, text gradient-driven framework that performs DP composition generation under natural-language conditions by integrating three complementary feedback sources: LLM-based self-evaluation, DP-specific domain knowledge-informed feedback, and ML surrogate-based feedback. Analogous to how knowledge-informed machine learning improves the reliability of conventional data-driven models, our framework incorporates domain-informed text gradients to guide the generative process toward physically meaningful regions of the DP composition space. Systematic comparison of three incremental configurations, (i) pure LLM generation, (ii) LLM generation with LLM reasoning-based feedback, and (iii) LLM generation with domain knowledge-guided feedback, shows that iterative guidance from knowledge-informed gradients improves stability-condition satisfaction without additional training data, achieving over 98% compositional validity and up to 54% stable or metastable candidates, surpassing both the LLM-only baseline (43%) and prior GAN-based results (27%). Analyses of ML-based gradients further reveal that they enhance performance in in-distribution (ID) regions but become unreliable in out-of-distribution (OOD) regimes. Overall, this work provides the first systematic analysis of multi-agent, knowledge-guided text gradients for DP discovery and establishes a generalizable blueprint for MAS-driven generative materials design aimed at advancing sustainable technologies.",
          "authors": [
            "Inhyo Lee",
            "Junhyeong Lee",
            "Jongwon Park",
            "KyungTae Lim",
            "Seunghwa Ryu"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22433",
          "title": "SkeletonAgent: An Agentic Interaction Framework for Skeleton-based Action Recognition",
          "abstract": "Recent advances in skeleton-based action recognition increasingly leverage semantic priors from Large Language Models (LLMs) to enrich skeletal representations. However, the LLM is typically queried in isolation from the recognition model and receives no performance feedback. As a result, it often fails to deliver the targeted discriminative cues critical to distinguish similar actions. To overcome these limitations, we propose SkeletonAgent, a novel framework that bridges the recognition model and the LLM through two cooperative agents, i.e., Questioner and Selector. Specifically, the Questioner identifies the most frequently confused classes and supplies them to the LLM as context for more targeted guidance. Conversely, the Selector parses the LLM's response to extract precise joint-level constraints and feeds them back to the recognizer, enabling finer-grained cross-modal alignment. Comprehensive evaluations on five benchmarks, including NTU RGB+D, NTU RGB+D 120, Kinetics-Skeleton, FineGYM, and UAV-Human, demonstrate that SkeletonAgent consistently outperforms state-of-the-art benchmark methods. The code is available at this https URL .",
          "authors": [
            "Hongda Liu",
            "Yunfan Liu",
            "Changlu Wang",
            "Yunlong Wang",
            "Zhenan Sun"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22686",
          "title": "Emergent Extreme-View Geometry in 3D Foundation Models",
          "abstract": "3D foundation models (3DFMs) have recently transformed 3D vision, enabling joint prediction of depths, poses, and point maps directly from images. Yet their ability to reason under extreme, non-overlapping views remains largely unexplored. In this work, we study their internal representations and find that 3DFMs exhibit an emergent understanding of extreme-view geometry, despite never being trained for such conditions. To further enhance these capabilities, we introduce a lightweight alignment scheme that refines their internal 3D representation by tuning only a small subset of backbone bias terms, leaving all decoder heads frozen. This targeted adaptation substantially improves relative pose estimation under extreme viewpoints without degrading per-image depth or point quality. Additionally, we contribute MegaUnScene, a new benchmark of Internet scenes unseen by existing 3DFMs, with dedicated test splits for both relative pose estimation and dense 3D reconstruction. All code and data will be released.",
          "authors": [
            "Yiwen Zhang",
            "Joseph Tung",
            "Ruojin Cai",
            "David Fouhey",
            "Hadar Averbuch-Elor"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.22699",
          "title": "Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer",
          "abstract": "The landscape of high-performance image generation models is currently dominated by proprietary systems, such as Nano Banana Pro and Seedream 4.0. Leading open-source alternatives, including Qwen-Image, Hunyuan-Image-3.0 and FLUX.2, are characterized by massive parameter counts (20B to 80B), making them impractical for inference, and fine-tuning on consumer-grade hardware. To address this gap, we propose Z-Image, an efficient 6B-parameter foundation generative model built upon a Scalable Single-Stream Diffusion Transformer (S3-DiT) architecture that challenges the \"scale-at-all-costs\" paradigm. By systematically optimizing the entire model lifecycle -- from a curated data infrastructure to a streamlined training curriculum -- we complete the full training workflow in just 314K H800 GPU hours (approx. $630K). Our few-step distillation scheme with reward post-training further yields Z-Image-Turbo, offering both sub-second inference latency on an enterprise-grade H800 GPU and compatibility with consumer-grade hardware (<16GB VRAM). Additionally, our omni-pre-training paradigm also enables efficient training of Z-Image-Edit, an editing model with impressive instruction-following capabilities. Both qualitative and quantitative experiments demonstrate that our model achieves performance comparable to or surpassing that of leading competitors across various dimensions. Most notably, Z-Image exhibits exceptional capabilities in photorealistic image generation and bilingual text rendering, delivering results that rival top-tier commercial models, thereby demonstrating that state-of-the-art results are achievable with significantly reduced computational overhead. We publicly release our code, weights, and online demo to foster the development of accessible, budget-friendly, yet state-of-the-art generative models.",
          "authors": [
            "Z-Image Team",
            "Huanqia Cai",
            "Sihan Cao",
            "Ruoyi Du",
            "Peng Gao",
            "Steven Hoi",
            "Zhaohui Hou",
            "Shijie Huang",
            "Dengyang Jiang",
            "Xin Jin",
            "Liangchen Li",
            "Zhen Li",
            "Zhong-Yu Li",
            "David Liu",
            "Dongyang Liu",
            "Junhan Shi",
            "Qilong Wu",
            "Feng Yu",
            "Chi Zhang",
            "Shifeng Zhang",
            "Shilin Zhou"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23177",
          "title": "Data-Efficient Motor Condition Monitoring with Time Series Foundation Models",
          "abstract": "Motor condition monitoring is essential for ensuring system reliability and preventing catastrophic failures. However, data-driven diagnostic methods often suffer from sparse fault labels and severe class imbalance, which limit their effectiveness in real-world applications. This paper proposes a motor condition monitoring framework that leverages the general features learned during pre-training of two time series foundation models, MOMENT and Mantis, to address these challenges. By transferring broad temporal representations from large-scale pre-training, the proposed approach significantly reduces dependence on labeled data while maintaining high diagnostic accuracy. Experimental results show that MOMENT achieves nearly twice the performance of conventional deep learning models using only 1% of the training data, whereas Mantis surpasses state-of-the-art baselines by 22%, reaching 90% accuracy with the same data ratio. These results demonstrate the strong generalization and data efficiency of time series foundation models in fault diagnosis, providing new insights into scalable and adaptive frameworks for intelligent motor condition monitoring.",
          "authors": [
            "Deyu Li",
            "Xinyuan Liao",
            "Shaowei Chen",
            "Shuai Zhao"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23177",
          "title": "Data-Efficient Motor Condition Monitoring with Time Series Foundation Models",
          "abstract": "Motor condition monitoring is essential for ensuring system reliability and preventing catastrophic failures. However, data-driven diagnostic methods often suffer from sparse fault labels and severe class imbalance, which limit their effectiveness in real-world applications. This paper proposes a motor condition monitoring framework that leverages the general features learned during pre-training of two time series foundation models, MOMENT and Mantis, to address these challenges. By transferring broad temporal representations from large-scale pre-training, the proposed approach significantly reduces dependence on labeled data while maintaining high diagnostic accuracy. Experimental results show that MOMENT achieves nearly twice the performance of conventional deep learning models using only 1% of the training data, whereas Mantis surpasses state-of-the-art baselines by 22%, reaching 90% accuracy with the same data ratio. These results demonstrate the strong generalization and data efficiency of time series foundation models in fault diagnosis, providing new insights into scalable and adaptive frameworks for intelligent motor condition monitoring.",
          "authors": [
            "Deyu Li",
            "Xinyuan Liao",
            "Shaowei Chen",
            "Shuai Zhao"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23198",
          "title": "Clustering Malware at Scale: A First Full-Benchmark Study",
          "abstract": "Recent years have shown that malware attacks still happen with high frequency. Malware experts seek to categorize and classify incoming samples to confirm their trustworthiness or prove their maliciousness. One of the ways in which groups of malware samples can be identified is through malware clustering. Despite the efforts of the community, malware clustering which incorporates benign samples has been under-explored. Moreover, despite the availability of larger public benchmark malware datasets, malware clustering studies have avoided fully utilizing these datasets in their experiments, often resorting to small datasets with only a few families. Additionally, the current state-of-the-art solutions for malware clustering remain unclear. In our study, we evaluate malware clustering quality and establish the state-of-the-art on Bodmas and Ember - two large public benchmark malware datasets. Ours is the first study of malware clustering performed on whole malware benchmark datasets. Additionally, we extend the malware clustering task by incorporating benign samples. Our results indicate that incorporating benign samples does not significantly degrade clustering quality. We find that there are differences in the quality of the created clusters between Ember and Bodmas, as well as a private industry dataset. Contrary to popular opinion, our top clustering performers are K-Means and BIRCH, with DBSCAN and HAC falling behind.",
          "authors": [
            "Martin Mocko",
            "Jakub Ševcech",
            "Daniela Chudá"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2511.23227",
          "title": "PointCNN++: Performant Convolution on Native Points",
          "abstract": "Existing convolutional learning methods for 3D point cloud data are divided into two paradigms: point-based methods that preserve geometric precision but often face performance challenges, and voxel-based methods that achieve high efficiency through quantization at the cost of geometric fidelity. This loss of precision is a critical bottleneck for tasks such as point cloud registration. We propose PointCNN++, a novel architectural design that fundamentally mitigates this precision-performance trade-off. It $\\textbf{generalizes sparse convolution from voxels to points}$, treating voxel-based convolution as a specialized, degraded case of our more general point-based convolution. First, we introduce a point-centric convolution where the receptive field is centered on the original, high-precision point coordinates. Second, to make this high-fidelity operation performant, we design a computational strategy that operates $\\textbf{natively}$ on points. We formulate the convolution on native points as a Matrix-Vector Multiplication and Reduction (MVMR) problem, for which we develop a dedicated, highly-optimized GPU kernel. Experiments demonstrate that PointCNN++ $\\textbf{uses an order of magnitude less memory and is several times faster}$ than representative point-based methods. Furthermore, when used as a simple replacement for the voxel-based backbones it generalizes, it $\\textbf{significantly improves point cloud registration accuracies while proving both more memory-efficient and faster}$. PointCNN++ shows that preserving geometric detail and achieving high performance are not mutually exclusive, paving the way for a new class of 3D learning with high fidelity and efficiency. Our code will be open sourced.",
          "authors": [
            "Lihan Li",
            "Haofeng Zhong",
            "Rui Bu",
            "Mingchao Sun",
            "Wenzheng Chen",
            "Baoquan Chen",
            "Yangyan Li"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00003",
          "title": "Efficient Turing Machine Simulation with Transformers",
          "abstract": "Constant bit-size Transformers are known to be Turing complete, but existing constructions require $\\Omega(s(n))$ chain-of-thought (CoT) steps per simulated Turing machine (TM) step, leading to impractical reasoning lengths. In this paper, we significantly reduce this efficiency gap by proving that any $(t(n),s(n))$-bounded multi-tape TM can be simulated by a constant bit-size Transformer with an optimal $O(s(n))$-long context window and only $O(s(n)^c)$ CoT steps per TM step, where $c>0$ can be made arbitrarily small by letting the Transformers' head-layer product sufficiently large. In addition, our construction shows that sparse attention with fixed geometric offsets suffices for efficient universal computation. Our proof leverages multi-queue TMs as a bridge. The main technical novelty is a more efficient simulation of multi-tape TMs by synchronous multi-queue TMs, improving both time and space complexity under stricter model assumptions.",
          "authors": [
            "Qian Li",
            "Yuyi Wang"
          ],
          "primary_category": "cs.CC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00283",
          "title": "BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models",
          "abstract": "Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.",
          "authors": [
            "Yi Fang",
            "Haoran Xu",
            "Jiaxin Han",
            "Sirui Ding",
            "Yizhi Wang",
            "Yue Wang",
            "Xuan Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00283",
          "title": "BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models",
          "abstract": "Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.",
          "authors": [
            "Yi Fang",
            "Haoran Xu",
            "Jiaxin Han",
            "Sirui Ding",
            "Yizhi Wang",
            "Yue Wang",
            "Xuan Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00338",
          "title": "On Statistical Inference for High-Dimensional Binary Time Series",
          "abstract": "The analysis of non-real-valued data, such as binary time series, has attracted great interest in recent years. This manuscript proposes a post-selection estimator for estimating the coefficient matrices of a high-dimensional generalized binary vector autoregressive process and establishes a Gaussian approximation theorem for the proposed estimator. Furthermore, it introduces a second-order wild bootstrap algorithm to enable statistical inference on the coefficient matrices. Numerical studies and empirical applications demonstrate the good finite-sample performance of the proposed method.",
          "authors": [
            "Dehao Dai",
            "Yunyi Zhang"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00338",
          "title": "On Statistical Inference for High-Dimensional Binary Time Series",
          "abstract": "The analysis of non-real-valued data, such as binary time series, has attracted great interest in recent years. This manuscript proposes a post-selection estimator for estimating the coefficient matrices of a high-dimensional generalized binary vector autoregressive process and establishes a Gaussian approximation theorem for the proposed estimator. Furthermore, it introduces a second-order wild bootstrap algorithm to enable statistical inference on the coefficient matrices. Numerical studies and empirical applications demonstrate the good finite-sample performance of the proposed method.",
          "authors": [
            "Dehao Dai",
            "Yunyi Zhang"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00470",
          "title": "LAP: Fast LAtent Diffusion Planner with Fine-Grained Feature Distillation for Autonomous Driving",
          "abstract": "Diffusion models have demonstrated strong capabilities for modeling human-like driving behaviors in autonomous driving, but their iterative sampling process induces substantial latency, and operating directly on raw trajectory points forces the model to spend capacity on low-level kinematics, rather than high-level multi-modal semantics. To address these limitations, we propose LAtent Planner (LAP), a framework that plans in a VAE-learned latent space that disentangles high-level intents from low-level kinematics, enabling our planner to capture rich, multi-modal driving strategies. We further introduce a fine-grained feature distillation mechanism to guide a better interaction and fusion between the high-level semantic planning space and the vectorized scene context. Notably, LAP can produce high-quality plans in one single denoising step, substantially reducing computational overhead. Through extensive evaluations on the large-scale nuPlan benchmark, LAP achieves state-of-the-art closed-loop performance among learning-based planning methods, while demonstrating an inference speed-up of at most 10 times over previous SOTA approaches. Code will be released at: this https URL .",
          "authors": [
            "Jinhao Zhang",
            "Wenlong Xia",
            "Zhexuan Zhou",
            "Youmin Gong",
            "Jie Mei"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00513",
          "title": "Truthful and Trustworthy IoT AI Agents via Immediate-Penalty Enforcement under Approximate VCG Mechanisms",
          "abstract": "The deployment of autonomous AI agents in Internet of Things (IoT) energy systems requires decision-making mechanisms that remain robust, efficient, and trustworthy under real-time constraints and imperfect monitoring. While reinforcement learning enables adaptive prosumer behaviors, ensuring economic consistency and preventing strategic manipulation remain open challenges, particularly when sensing noise or partial observability reduces the operator's ability to verify actions. This paper introduces a trust-enforcement framework for IoT energy trading that combines an approximate Vickrey-Clarke-Groves (VCG) double auction with an immediate one-shot penalty. Unlike reputation- or history-based approaches, the proposed mechanism restores truthful reporting within a single round, even when allocation accuracy is approximate and monitoring is noisy. We theoretically characterize the incentive gap induced by approximation and derive a penalty threshold that guarantees truthful bidding under bounded sensing errors. To evaluate learning-enabled prosumers, we embed the mechanism into a multi-agent reinforcement learning environment reflecting stochastic generation, dynamic loads, and heterogeneous trading opportunities. Experiments show that improved allocation accuracy reduces deviation incentives, the required penalty matches analytical predictions, and learned bidding behaviors remain stable and interpretable despite imperfect monitoring. These results demonstrate that lightweight penalty designs can reliably align strategic IoT agents with socially efficient energy-trading outcomes.",
          "authors": [
            "Xun Shao",
            "Ryuuto Shimizu",
            "Zhi Liu",
            "Kaoru Ota",
            "Mianxiong Dong"
          ],
          "primary_category": "cs.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00686",
          "title": "Using physics-inspired Singular Learning Theory to understand grokking & other phase transitions in modern neural networks",
          "abstract": "Classical statistical inference and learning theory often fail to explain the success of modern neural networks. A key reason is that these models are non-identifiable (singular), violating core assumptions behind PAC bounds and asymptotic normality. Singular learning theory (SLT), a physics-inspired framework grounded in algebraic geometry, has gained popularity for its ability to close this theory-practice gap. In this paper, we empirically study SLT in toy settings relevant to interpretability and phase transitions. First, we understand the SLT free energy $\\mathcal{F}_n$ by testing an Arrhenius-style rate hypothesis using both a grokking modulo-arithmetic model and Anthropic's Toy Models of Superposition. Second, we understand the local learning coefficient $\\lambda_{\\alpha}$ by measuring how it scales with problem difficulty across several controlled network families (polynomial regressors, low-rank linear networks, and low-rank autoencoders). Our experiments recover known scaling laws while others yield meaningful deviations from theoretical expectations. Overall, our paper illustrates the many merits of SLT for understanding neural network phase transitions, and poses open research questions for the field.",
          "authors": [
            "Anish Lakkapragada"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00686",
          "title": "Using physics-inspired Singular Learning Theory to understand grokking & other phase transitions in modern neural networks",
          "abstract": "Classical statistical inference and learning theory often fail to explain the success of modern neural networks. A key reason is that these models are non-identifiable (singular), violating core assumptions behind PAC bounds and asymptotic normality. Singular learning theory (SLT), a physics-inspired framework grounded in algebraic geometry, has gained popularity for its ability to close this theory-practice gap. In this paper, we empirically study SLT in toy settings relevant to interpretability and phase transitions. First, we understand the SLT free energy $\\mathcal{F}_n$ by testing an Arrhenius-style rate hypothesis using both a grokking modulo-arithmetic model and Anthropic's Toy Models of Superposition. Second, we understand the local learning coefficient $\\lambda_{\\alpha}$ by measuring how it scales with problem difficulty across several controlled network families (polynomial regressors, low-rank linear networks, and low-rank autoencoders). Our experiments recover known scaling laws while others yield meaningful deviations from theoretical expectations. Overall, our paper illustrates the many merits of SLT for understanding neural network phase transitions, and poses open research questions for the field.",
          "authors": [
            "Anish Lakkapragada"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00783",
          "title": "Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment",
          "abstract": "To address the gap in humanoid robot cognitive systems regarding the lack of a time-updable mediating thought space between semantics and continuous control, this study constructs and trains a VLA model named \"Sigma\" that runs on a single RTX 4090. It uses the open-source pi05_base model as a foundation and preprocesses svla_so101_pickplace into a training dataset. The researcher independently designed an architecture for a vision-language-action model that combines deep semantic understanding and association to achieve telepathic communication. The training process involved repeated optimizations of data preprocessing, LoRA fine-tuning, and the inference-stage adapter. The experiment employed offline closed-loop replay, comparing Sigma with the untuned pure pi05_base model under data conditions. Results showed that Sigma exhibited a stable decrease in control MSE across vector, fragment, and entire trajectory timescales, while maintaining the telepathy norm and semantic-text alignment quality unchanged. It demonstrates that mind-responsive alignment control is quantified through an architecture that combines deep understanding of semantics and association without retraining the base model, which provides reproducible experience for semantic alignment and intention-driven behavior in humanoid robots.",
          "authors": [
            "Libo Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00791",
          "title": "Limitations of Using Identical Distributions for Training and Testing When Learning Boolean Functions",
          "abstract": "When the distributions of the training and test data do not coincide, the problem of understanding generalization becomes considerably more complex, prompting a variety of questions. Prior work has shown that, for some fixed learning methods, there are scenarios where training on a distribution different from the test distribution improves generalization. However, these results do not account for the possibility of choosing, for each training distribution, the optimal learning algorithm, leaving open whether the observed benefits stem from the mismatch itself or from suboptimality of the learner. In this work, we address this question in full generality. That is, we study whether it is always optimal for the training distribution to be identical to the test distribution when the learner is allowed to be optimally adapted to the training distribution. Surprisingly, assuming the existence of one-way functions, we find that the answer is no. That is, matching distributions is not always the best scenario. Nonetheless, we also show that when certain regularities are imposed on the target functions, the standard conclusion is recovered in the case of the uniform distribution.",
          "authors": [
            "Jordi Pérez-Guijarro"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00862",
          "title": "HBLLM: A Haar-Based Approach for Accurate Structured 1-Bit Quantized LLMs",
          "abstract": "We introduce HBLLM, a wavelet-enhanced high-fidelity $1$-bit post-training quantization method for Large Language Models (LLMs). By leveraging Haar wavelet transforms to enhance expressive capacity through frequency decomposition, HBLLM significantly improves quantization fidelity while maintaining minimal overhead. This approach features two innovative structure-aware grouping strategies: (1) frequency-aware multi-parameter intra-row grouping and (2) $\\ell_2$-norm-based saliency-driven column selection. For non-salient weights, a shared mean is employed across quantization groups within each frequency band to optimize storage efficiency. Experiments conducted on the OPT and LLaMA models demonstrate that HBLLM achieves state-of-the-art performance in $1$-bit quantization, attaining a perplexity of $6.71$ on LLaMA$2$-$13$B with an average weight storage of only $1.08$ bits. Code available at: this https URL .",
          "authors": [
            "Ningning Chen",
            "Weicai Ye",
            "Ying Jiang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.00882",
          "title": "Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints",
          "abstract": "Vision-Language Models (VLMs) exhibit significant performance plateaus in specialized domains like precision agriculture, primarily due to \"Reasoning-Driven Hallucination\" where linguistic priors override visual perception. A key bottleneck is the \"Modality Gap\": visual embeddings fail to reliably activate the fine-grained expert knowledge already encoded in model parameters. We propose \"Look, Recite, Then Answer,\" a parameter-efficient framework that enhances VLMs via self-generated knowledge hints while keeping backbone models frozen. The framework decouples inference into three stages: (1) Look generates objective visual descriptions and candidate sets; (2) Recite employs a lightweight 1.7B router to transform visual cues into targeted queries that trigger candidate-specific parametric knowledge; (3) Answer performs parallel evidence alignment between descriptions and recited knowledge to select the most consistent label. On AgroBench, our method achieves state-of-the-art results, improving Weed Identification accuracy by 23.52% over Qwen2-VL-72B and surpassing GPT-4o without external search overhead. This modular design mitigates hallucinations by transforming passive perception into active, controllable knowledge retrieval",
          "authors": [
            "Xisheng Feng"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01155",
          "title": "Beyond Greenfield: The D3 Framework for AI-Driven Productivity in Brownfield Engineering",
          "abstract": "Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and 83% of participants spent less time fixing or rewriting code due to better initial planning with AI. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.",
          "authors": [
            "Krishna Kumaar Sharma"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01234",
          "title": "Proactive Agentic Whiteboards: Enhancing Diagrammatic Learning",
          "abstract": "Educators frequently rely on diagrams to explain complex concepts during lectures, yet creating clear and complete visual representations in real time while simultaneously speaking can be cognitively demanding. Incomplete or unclear diagrams may hinder student comprehension, as learners must mentally reconstruct missing information while following the verbal explanation. Inspired by advances in code completion tools, we introduce DrawDash, an AI-powered whiteboard assistant that proactively completes and refines educational diagrams through multimodal understanding. DrawDash adopts a TAB-completion interaction model: it listens to spoken explanations, detects intent, and dynamically suggests refinements that can be accepted with a single keystroke. We demonstrate DrawDash across four diverse teaching scenarios, spanning topics from computer science and web development to biology. This work represents an early exploration into reducing instructors' cognitive load and improving diagram-based pedagogy through real-time, speech-driven visual assistance, and concludes with a discussion of current limitations and directions for formal classroom evaluation.",
          "authors": [
            "Suveen Ellawela",
            "Sashenka Gamage",
            "Dinithi Dissanayake"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01282",
          "title": "Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning",
          "abstract": "As web platforms evolve towards greater personalization and emotional complexity, conversational agents must transcend superficial empathy to demonstrate identity-aware emotional reasoning. However, existing systems face two limitations: (1) reliance on situation-centric datasets lacking persistent user identity, which hampers the capture of personalized affective nuances; and (2) dependence on opaque, coarse reward signals that hinder development of verifiable empathetic reasoning. To address these gaps, we introduce KardiaBench, a large-scale user-grounded benchmark comprising 178,080 QA pairs across 22,080 multi-turn conversations anchored to 671 real-world profiles. The dataset is constructed via a model-in-the-loop pipeline with iterative rubric-guided refinement to ensure psychological plausibility and persona consistency. This progressive empathy pipeline that integrates user comprehension, contextual reasoning, and emotion perception into conversations, followed by iterative critique and rubric-based refinement to ensure psychological plausibility, emotional fidelity, and persona consistency. Building on this, we propose Kardia-R1, a framework that trains models for interpretable, stepwise empathetic cognition. Kardia-R1 leverages Rubric-as-Judge Empathetic Reinforcement Learning (Rubric-ERL), a GRPO-based method that uses explainable, human-aligned rubric rewards to tightly couple user understanding, emotional inference, and supportive response generation. Extensive experiments across four LLM backbones demonstrate that Kardia-R1 consistently outperforms othet methods in emotion accuracy, empathy, relevance, persona consistency, and safety. Our dataset and model will be released at this https URL .",
          "authors": [
            "Jiahao Yuan",
            "Zhiqing Cui",
            "Hanqing Wang",
            "Yuansheng Gao",
            "Yucheng Zhou",
            "Usman Naseem"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01292",
          "title": "Diffusion Model in Latent Space for Medical Image Segmentation Task",
          "abstract": "Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.",
          "authors": [
            "Huynh Trinh Ngoc",
            "Toan Nguyen Hai",
            "Ba Luong Son",
            "Long Tran Quoc"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01343",
          "title": "Intrinsic Structure as a Proxy for Saliency: SVD-Based Weight Preservation for Mixed-Precision Quantization in Large Language Models",
          "abstract": "As Large Language Models (LLMs) continue to scale in parameter count, deploying them on commodity hardware has become increasingly challenging. Post-Training Quantization (PTQ) addresses this by reducing the precision of model weights, typically to 4-bit or lower. However, uniform quantization often leads to significant performance degradation due to the presence of ``outlier features'' -- weights that, while few in number, are critical for maintaining model accuracy. Current state-of-the-art methods such as AWQ (Activation-aware Weight Quantization) and SpQR (Sparse Quantization Representations) rely on calibration data to identify these salient weights via activation magnitudes or Hessian sensitivity. In scenarios where data privacy is paramount or calibration data is unavailable, these methods are inapplicable. In this work, we propose a data-free, structure-aware hypothesis: that the weights identified as Principal Components via Singular Value Decomposition (SVD) are intrinsically important to the model's downstream performance. We introduce a novel selection heuristic that preserves the top-$k$ weights aligned with the principal components in FP32, while aggressively quantizing the residual weights. We compare our method against activation-aware (AWQ) and second-order (SpQR) methods across GLUE benchmarks (MRPC, RTE, QNLI) using a DistilBERT backbone. Our experiments reveal that structural importance is highly correlated with functional importance. On the challenging RTE task, our SVD-based method achieves an accuracy of 66.06\\%, outperforming both AWQ (65.34\\%) and SpQR (65.34\\%) at high protection budgets, validating that intrinsic matrix structure can serve as a robust proxy for weight saliency without the need for forward passes or calibration data.",
          "authors": [
            "Shashank Landge",
            "Abhishek Patil",
            "Tejas kamble",
            "Bhushan Buddhivant",
            "Priyanka Joshi"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01354",
          "title": "The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness",
          "abstract": "Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse. This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators. The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33. Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.",
          "authors": [
            "Zhongjie Jiang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01354",
          "title": "The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness",
          "abstract": "Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse. This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators. The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33. Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.",
          "authors": [
            "Zhongjie Jiang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01374",
          "title": "Stabilizing Reinforcement Learning with LLMs: Formulation and Practices",
          "abstract": "This paper proposes a novel formulation for reinforcement learning (RL) with large language models, explaining why and under what conditions the true sequence-level reward can be optimized via a surrogate token-level objective in policy gradient methods such as REINFORCE. Specifically, through a first-order approximation, we show that this surrogate becomes increasingly valid only when both the training-inference discrepancy and policy staleness are minimized. This insight provides a principled explanation for the crucial role of several widely adopted techniques in stabilizing RL training, including importance sampling correction, clipping, and particularly Routing Replay for Mixture-of-Experts (MoE) models. Through extensive experiments with a 30B MoE model totaling hundreds of thousands of GPU hours, we show that for on-policy training, the basic policy gradient algorithm with importance sampling correction achieves the highest training stability. When off-policy updates are introduced to accelerate convergence, combining clipping and Routing Replay becomes essential to mitigate the instability caused by policy staleness. Notably, once training is stabilized, prolonged optimization consistently yields comparable final performance regardless of cold-start initialization. We hope that the shared insights and the developed recipes for stable RL training will facilitate future research.",
          "authors": [
            "Chujie Zheng",
            "Kai Dang",
            "Bowen Yu",
            "Mingze Li",
            "Huiqiang Jiang",
            "Junrong Lin",
            "Yuqiong Liu",
            "Hao Lin",
            "Chencan Wu",
            "Feng Hu",
            "An Yang",
            "Jingren Zhou",
            "Junyang Lin"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01463",
          "title": "hls4ml: A Flexible, Open-Source Platform for Deep Learning Acceleration on Reconfigurable Hardware",
          "abstract": "We present hls4ml, a free and open-source platform that translates machine learning (ML) models from modern deep learning frameworks into high-level synthesis (HLS) code that can be integrated into full designs for field-programmable gate arrays (FPGAs) or application-specific integrated circuits (ASICs). With its flexible and modular design, hls4ml supports a large number of deep learning frameworks and can target HLS compilers from several vendors, including Vitis HLS, Intel oneAPI and Catapult HLS. Together with a wider eco-system for software-hardware co-design, hls4ml has enabled the acceleration of ML inference in a wide range of commercial and scientific applications where low latency, resource usage, and power consumption are critical. In this paper, we describe the structure and functionality of the hls4ml platform. The overarching design considerations for the generated HLS code are discussed, together with selected performance results.",
          "authors": [
            "Jan-Frederik Schulte",
            "Benjamin Ramhorst",
            "Chang Sun",
            "Jovan Mitrevski",
            "Nicolò Ghielmetti",
            "Enrico Lupi",
            "Dimitrios Danopoulos",
            "Vladimir Loncar",
            "Javier Duarte",
            "David Burnette",
            "Lauri Laatu",
            "Stylianos Tzelepis",
            "Konstantinos Axiotis",
            "Quentin Berthet",
            "Haoyan Wang",
            "Paul White",
            "Suleyman Demirsoy",
            "Marco Colombo",
            "Thea Aarrestad",
            "Sioni Summers",
            "Maurizio Pierini",
            "Giuseppe Di Guglielmo",
            "Jennifer Ngadiuba",
            "Javier Campos",
            "Ben Hawks",
            "Abhijith Gandrakota",
            "Farah Fahim",
            "Nhan Tran",
            "George Constantinides",
            "Zhiqiang Que",
            "Wayne Luk",
            "Alexander Tapper",
            "Duc Hoang",
            "Noah Paladino",
            "Philip Harris",
            "Bo-Cheng Lai",
            "Manuel Valentin",
            "Ryan Forelli",
            "Seda Ogrenci",
            "Lino Gerlach",
            "Rian Flynn",
            "Mia Liu",
            "Daniel Diaz",
            "Elham Khoda",
            "Melissa Quinnan",
            "Russell Solares",
            "Santosh Parajuli",
            "Mark Neubauer",
            "Christian Herwig",
            "Ho Fung Tsoi",
            "Dylan Rankin",
            "Shih-Chieh Hsu",
            "Scott Hauck"
          ],
          "primary_category": "cs.AR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01563",
          "title": "MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration",
          "abstract": "Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at this https URL .",
          "authors": [
            "Thao Thi Phuong Dao",
            "Tan-Cong Nguyen",
            "Nguyen Chi Thanh",
            "Truong Hoang Viet",
            "Trong-Le Do",
            "Mai-Khiem Tran",
            "Minh-Khoi Pham",
            "Trung-Nghia Le",
            "Minh-Triet Tran",
            "Thanh Dinh Le"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01589",
          "title": "Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation",
          "abstract": "Abscesses in the head and neck represent an acute infectious process that can potentially lead to sepsis or mortality if not diagnosed and managed promptly. Accurate detection and delineation of these lesions on imaging are essential for diagnosis, treatment planning, and surgical intervention. In this study, we introduce AbscessHeNe, a curated and comprehensively annotated dataset comprising 4,926 contrast-enhanced CT slices with clinically confirmed head and neck abscesses. The dataset is designed to facilitate the development of robust semantic segmentation models that can accurately delineate abscess boundaries and evaluate deep neck space involvement, thereby supporting informed clinical decision-making. To establish performance baselines, we evaluate several state-of-the-art segmentation architectures, including CNN, Transformer, and Mamba-based models. The highest-performing model achieved a Dice Similarity Coefficient of 0.39, Intersection-over-Union of 0.27, and Normalized Surface Distance of 0.67, indicating the challenges of this task and the need for further research. Beyond segmentation, AbscessHeNe is structured for future applications in content-based multimedia indexing and case-based retrieval. Each CT scan is linked with pixel-level annotations and clinical metadata, providing a foundation for building intelligent retrieval systems and supporting knowledge-driven clinical workflows. The dataset will be made publicly available at this https URL .",
          "authors": [
            "Thao Thi Phuong Dao",
            "Tan-Cong Nguyen",
            "Trong-Le Do",
            "Truong Hoang Viet",
            "Nguyen Chi Thanh",
            "Huynh Nguyen Thuan",
            "Do Vo Cong Nguyen",
            "Minh-Khoi Pham",
            "Mai-Khiem Tran",
            "Viet-Tham Huynh",
            "Trong-Thuan Nguyen",
            "Trung-Nghia Le",
            "Vo Thanh Toan",
            "Tam V. Nguyen",
            "Minh-Triet Tran",
            "Thanh Dinh Le"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01594",
          "title": "Confidential, Attestable, and Efficient Inter-CVM Communication with Arm CCA",
          "abstract": "Confidential Virtual Machines (CVMs) are increasingly adopted to protect sensitive workloads from privileged adversaries such as the hypervisor. While they provide strong isolation guarantees, existing CVM architectures lack first-class mechanisms for inter-CVM data sharing due to their disjoint memory model, making inter-CVM data exchange a performance bottleneck in compartmentalized or collaborative multi-CVM systems. Under this model, a CVM's accessible memory is either shared with the hypervisor or protected from both the hypervisor and all other CVMs. This design simplifies reasoning about memory ownership; however, it fundamentally precludes plaintext data sharing between CVMs because all inter-CVM communication must pass through hypervisor-accessible memory, requiring costly encryption and decryption to preserve confidentiality and integrity. In this paper, we introduce CAEC, a system that enables protected memory sharing between CVMs. CAEC builds on Arm Confidential Compute Architecture (CCA) and extends its firmware to support Confidential Shared Memory (CSM), a memory region securely shared between multiple CVMs while remaining inaccessible to the hypervisor and all non-participating CVMs. CAEC's design is fully compatible with CCA hardware and introduces only a modest increase (4%) in CCA firmware code size. CAEC delivers substantial performance benefits across a range of workloads. For instance, inter-CVM communication over CAEC achieves up to 209$\\times$ reduction in CPU cycles compared to encryption-based mechanisms over hypervisor-accessible shared memory. By combining high performance, strong isolation guarantees, and attestable sharing semantics, CAEC provides a practical and scalable foundation for the next generation of trusted multi-CVM services across both edge and cloud environments.",
          "authors": [
            "Sina Abdollahi",
            "Amir Al Sadi",
            "Marios Kogias",
            "David Kotz",
            "Hamed Haddadi"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01629",
          "title": "SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge",
          "abstract": "Articulated 3D objects are critical for embodied AI, robotics, and interactive scene understanding, yet creating simulation-ready assets remains labor-intensive and requires expert modeling of part hierarchies and motion structures. We introduce SPARK, a framework for reconstructing physically consistent, kinematic part-level articulated objects from a single RGB image. Given an input image, we first leverage VLMs to extract coarse URDF parameters and generate part-level reference images. We then integrate the part-image guidance and the inferred structure graph into a generative diffusion transformer to synthesize consistent part and complete shapes of articulated objects. To further refine the URDF parameters, we incorporate differentiable forward kinematics and differentiable rendering to optimize joint types, axes, and origins under VLM-generated open-state supervision. Extensive experiments show that SPARK produces high-quality, simulation-ready articulated assets across diverse categories, enabling downstream applications such as robotic manipulation and interaction modeling. Project page: this https URL .",
          "authors": [
            "Yumeng He",
            "Ying Jiang",
            "Jiayin Lu",
            "Yin Yang",
            "Chenfanfu Jiang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01678",
          "title": "Morphling: Fast, Fused, and Flexible GNN Training at Scale",
          "abstract": "Graph Neural Networks (GNNs) present a fundamental hardware challenge by fusing irregular, memory-bound graph traversals with regular, compute-intensive dense matrix operations. While frameworks such as PyTorch Geometric (PyG) and Deep Graph Library (DGL) prioritize high-level usability, they fail to address these divergent execution characteristics. As a result, they rely on generic kernels that suffer from poor cache locality, excessive memory movement, and substantial intermediate allocations. To address these limitations, we present Morphling, a domain-specific code synthesizer designed to bridge this gap. Morphling compiles high-level GNN specifications into portable, backend-specialized implementations targeting OpenMP, CUDA, and MPI. It achieves this by instantiating a library of optimized, architecture-aware primitives tailored to each execution environment. Morphling also incorporates a runtime sparsity-aware execution engine that dynamically selects dense or sparse execution paths using input feature statistics, reducing unnecessary computation on zero-valued entries. We evaluate Morphling on eleven real-world datasets spanning diverse graph structures, feature dimensionalities, and sparsity regimes. The results show that Morphling improves per-epoch training throughput by an average of 20X on CPUs and 19X on GPUs over PyG and DGL, with peak speedups reaching 66X. Morphling's memory-efficient layouts further reduce peak memory consumption by up to 15X, enabling large-scale GNN training on commodity hardware. These findings demonstrate that specialized, architecture-aware code synthesis provides an effective and scalable path toward high-performance GNN execution across diverse parallel and distributed platforms.",
          "authors": [
            "Anubhab",
            "Rupesh Nasre"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01783",
          "title": "The Active and Noise-Tolerant Strategic Perceptron",
          "abstract": "We initiate the study of active learning algorithms for classifying strategic agents. Active learning is a well-established framework in machine learning in which the learner selectively queries labels, often achieving substantially higher accuracy and efficiency than classical supervised methods-especially in settings where labeling is costly or time-consuming, such as hiring, admissions, and loan decisions. Strategic classification, however, addresses scenarios where agents modify their features to obtain more favorable outcomes, resulting in observed data that is not truthful. Such manipulation introduces challenges beyond those in learning from clean data. Our goal is to design active and noise-tolerant algorithms that remain effective in strategic environments-algorithms that classify strategic agents accurately while issuing as few label requests as possible. The central difficulty is to simultaneously account for strategic manipulation and preserve the efficiency gains of active learning. Our main result is an algorithm for actively learning linear separators in the strategic setting that preserves the exponential improvement in label complexity over passive learning previously obtained only in the non-strategic case. Specifically, for data drawn uniformly from the unit sphere, we show that a modified version of the Active Perceptron algorithm [DKM05,YZ17] achieves excess error $\\epsilon$ using only $\\tilde{O}(d \\ln \\frac{1}{\\epsilon})$ label queries and incurs at most $\\tilde{O}(d \\ln \\frac{1}{\\epsilon})$ additional mistakes relative to the optimal classifier, even in the nonrealizable case, when a $\\tilde{\\Omega}(\\epsilon)$ fraction of inputs have inconsistent labels with the optimal classifier. The algorithm is computationally efficient and, under these distributional assumptions, requires substantially fewer label queries than prior work on strategic Perceptron [ABBN21].",
          "authors": [
            "Maria-Florina Balcan",
            "Hedyeh Beyhaghi"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01797",
          "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons in LLMs",
          "abstract": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.",
          "authors": [
            "Cheng Gao",
            "Huimin Chen",
            "Chaojun Xiao",
            "Zhiyi Chen",
            "Zhiyuan Liu",
            "Maosong Sun"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01801",
          "title": "GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation",
          "abstract": "We present GR-RL, a robotic learning framework that turns a generalist vision-language-action (VLA) policy into a highly capable specialist for long-horizon dexterous manipulation. Assuming the optimality of human demonstrations is core to existing VLA policies. However, we claim that in highly dexterous and precise manipulation tasks, human demonstrations are noisy and suboptimal. GR-RL proposes a multi-stage training pipeline that filters, augments, and reinforces the demonstrations by reinforcement learning. First, GR-RL learns a vision-language-conditioned task progress, filters the demonstration trajectories, and only keeps the transitions that contribute positively to the progress. Specifically, we show that by directly applying offline RL with sparse reward, the resulting $Q$-values can be treated as a robust progress function. Next, we introduce morphological symmetry augmentation that greatly improves the generalization and performance of GR-RL. Lastly, to better align the VLA policy with its deployment behaviors for high-precision control, we perform online RL by learning a latent space noise predictor. With this pipeline, GR-RL is, to our knowledge, the first learning-based policy that can autonomously lace up a shoe by threading shoelaces through multiple eyelets with an 83.3% success rate, a task requiring long-horizon reasoning, millimeter-level precision, and compliant soft-body interaction. We hope GR-RL provides a step toward enabling generalist robot foundations models to specialize into reliable real-world experts.",
          "authors": [
            "Yunfei Li",
            "Xiao Ma",
            "Jiafeng Xu",
            "Yu Cui",
            "Zhongren Cui",
            "Zhigang Han",
            "Liqun Huang",
            "Tao Kong",
            "Yuxiao Liu",
            "Hao Niu",
            "Wanli Peng",
            "Jingchao Qiao",
            "Zeyu Ren",
            "Haixin Shi",
            "Zhi Su",
            "Jiawen Tian",
            "Yuyang Xiao",
            "Shenyu Zhang",
            "Liwei Zheng",
            "Hang Li",
            "Yonghui Wu"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01830",
          "title": "OpenREAD: Reinforced Open-Ended Reasoning for End-to-End Autonomous Driving with LLM-as-Critic",
          "abstract": "Recently, two-stage fine-tuning strategies, e.g., acquiring essential driving knowledge through supervised fine-tuning (SFT) and further enhancing decision-making and planning via reinforcement fine-tuning (RFT), have shown strong potential in advancing the knowledge-driven autonomous driving (AD) paradigm. However, the learning nature of SFT still limits the generalization of reasoning, thereby constraining the full potential of driving performance. Meanwhile, current RFT approaches are primarily applied to downstream tasks, since scene understanding is an open-ended problem where corresponding rewards are difficult to quantify. To address these limitations, we propose OpenREAD, an OPEN-ended REasoning reinforced vision-language model (VLM)-based autonomous driving (AD) framework that enables end-to-end RFT across the full spectrum from high-level reasoning to low-level trajectory planning. Specifically, we begin by constructing large-scale Chain-of-Thought (CoT) annotations on open-source driving-related knowledge datasets, and employ the powerful Qwen3 large language model (LLM) as the critic in RFT to quantify reasoning quality for open-ended questions during reward modeling. Extensive experiments confirm that joint end-to-end RFT yields substantial improvements in both upstream and downstream tasks, enabling OpenREAD to achieve state-of-the-art performance on reasoning and planning benchmarks.",
          "authors": [
            "Songyan Zhang",
            "Wenhui Huang",
            "Zhan Chen",
            "Chua Jiahao Collister",
            "Qihang Huang",
            "Chen Lv"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01853",
          "title": "COACH: Collaborative Agents for Contextual Highlighting - A Multi-Agent Framework for Sports Video Analysis",
          "abstract": "Intelligent sports video analysis demands a comprehensive understanding of temporal context, from micro-level actions to macro-level game strategies. Existing end-to-end models often struggle with this temporal hierarchy, offering solutions that lack generalization, incur high development costs for new tasks, and suffer from poor interpretability. To overcome these limitations, we propose a reconfigurable Multi-Agent System (MAS) as a foundational framework for sports video understanding. In our system, each agent functions as a distinct \"cognitive tool\" specializing in a specific aspect of analysis. The system's architecture is not confined to a single temporal dimension or task. By leveraging iterative invocation and flexible composition of these agents, our framework can construct adaptive pipelines for both short-term analytic reasoning (e.g., Rally QA) and long-term generative summarization (e.g., match summaries). We demonstrate the adaptability of this framework using two representative tasks in badminton analysis, showcasing its ability to bridge fine-grained event detection and global semantic organization. This work presents a paradigm shift towards a flexible, scalable, and interpretable system for robust, cross-task sports video intelligence. The project homepage is available at this https URL",
          "authors": [
            "Tsz-To Wong",
            "Ching-Chun Huang",
            "Hong-Han Shuai"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01856",
          "title": "Is Image-based Object Pose Estimation Ready to Support Grasping?",
          "abstract": "We present a framework for evaluating 6-DoF instance-level object pose estimators, focusing on those that require a single RGB (not RGB-D) image as input. Besides gaining intuition about how accurate these estimators are, we are interested in the degree to which they can serve as the sole perception mechanism for robotic grasping. To assess this, we perform grasping trials in a physics-based simulator, using image-based pose estimates to guide a parallel gripper and an underactuated robotic hand in picking up 3D models of objects. Our experiments on a subset of the BOP (Benchmark for 6D Object Pose Estimation) dataset compare five open-source object pose estimators and provide insights that were missing from the literature.",
          "authors": [
            "Eric C. Joyce",
            "Qianwen Zhao",
            "Nathaniel Burgdorfer",
            "Long Wang",
            "Philippos Mordohai"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01881",
          "title": "Unifying Sign and Magnitude for Optimizing Deep Vision Networks via ThermoLion",
          "abstract": "The training of deep vision models is fundamentally a signal recovery problem amidst high-dimensional stochastic noise. Current optimization paradigms impose a static compromise on information channel capacity. For instance, magnitude-based methods, such as AdamW, operate on the assumption that gradient norms are high-fidelity curvature signals. While this allows for precision in smooth regimes, it leads to catastrophic noise amplification when applied to rugged, non-convex landscapes. Conversely, sign-based methods (e.g., Lion) perform a radical 1-bit quantization of the gradient, which aims to provide robust regularization at the cost of discarding fine-grained descent information. We propose that optimal convergence requires neither static prior, but rather a dynamic modulation of the update bitrate. We introduce ThermoLion, a vision-centric framework that utilizes local Signal-to-Noise Ratio (SNR) gating to autonomously transition parameters between a \"low-bit\" exploration phase and a \"high-precision\" exploitation phase. Furthermore, we introduce a Momentum Alignment mechanism that detects constructive interference between historical drift and instantaneous gradients to accelerate convergence during stable trajectories. Empirical benchmarks across 12 diverse vision datasets (including CIFAR, SVHN, and GTSRB) demonstrate that ThermoLion surpasses state-of-the-art optimizers, such as AdamW and Lion, in convergence speed and terminal accuracy.",
          "authors": [
            "Ahmed Nebli"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01946",
          "title": "Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models",
          "abstract": "Robust robotic manipulation requires reliable failure detection and recovery. Although current Vision-Language Models (VLMs) show promise, their accuracy and generalization are limited by the scarcity of failure data. To address this data gap, we propose an automatic robot failure synthesis approach that procedurally perturbs successful trajectories to generate diverse planning and execution failures. This method produces not only binary classification labels but also fine-grained failure categories and step-by-step reasoning traces in both simulation and the real world. With it, we construct three new failure detection benchmarks: RLBench-Fail, BridgeDataV2-Fail, and UR5-Fail, substantially expanding the diversity and scale of existing failure datasets. We then train Guardian, a VLM with multi-view images for detailed failure reasoning and detection. Guardian achieves state-of-the-art performance on both existing and newly introduced benchmarks. It also effectively improves task success rates when integrated into a state-of-the-art manipulation system in simulation and real robots, demonstrating the impact of our generated failure data. Code, Data, and Models available at this https URL .",
          "authors": [
            "Paul Pacaud",
            "Ricardo Garcia",
            "Shizhe Chen",
            "Cordelia Schmid"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01970",
          "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning",
          "abstract": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.",
          "authors": [
            "Sitao Cheng",
            "Xunjian Yin",
            "Ruiwen Zhou",
            "Yuxuan Li",
            "Xinyi Wang",
            "Liangming Pan",
            "William Yang Wang",
            "Victor Zhong"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01976",
          "title": "Consistent Synthetic Sequences Unlock Structural Diversity in Fully Atomistic De Novo Protein Design",
          "abstract": "High-quality training datasets are crucial for the development of effective protein design models, but existing synthetic datasets often include unfavorable sequence-structure pairs, impairing generative model performance. We leverage ProteinMPNN, whose sequences are experimentally favorable as well as amenable to folding, together with structure prediction models to align high-quality synthetic structures with recoverable synthetic sequences. In that way, we create a new dataset designed specifically for training expressive, fully atomistic protein generators. By retraining La-Proteina, which models discrete residue type and side chain structure in a continuous latent space, on this dataset, we achieve new state-of-the-art results, with improvements of +54% in structural diversity and +27% in co-designability. To validate the broad utility of our approach, we further introduce Proteina Atomistica, a unified flow-based framework that jointly learns the distribution of protein backbone structure, discrete sequences, and atomistic side chains without latent variables. We again find that training on our new sequence-structure data dramatically boosts benchmark performance, improving \\method's structural diversity by +73% and co-designability by +5%. Our work highlights the critical importance of aligned sequence-structure data for training high-performance de novo protein design models. All data will be publicly released.",
          "authors": [
            "Danny Reidenbach",
            "Zhonglin Cao",
            "Zuobai Zhang",
            "Kieran Didi",
            "Tomas Geffner",
            "Guoqing Zhou",
            "Jian Tang",
            "Christian Dallago",
            "Arash Vahdat",
            "Emine Kucukbenli",
            "Karsten Kreis"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.01987",
          "title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments",
          "abstract": "Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.",
          "authors": [
            "Suzan Ece Ada",
            "Georg Martius",
            "Emre Ugur",
            "Erhan Oztop"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02022",
          "title": "Reinforcement Learning for Robotic Safe Control with Force Sensing",
          "abstract": "For the task with complicated manipulation in unstructured environments, traditional hand-coded methods are ineffective, while reinforcement learning can provide more general and useful policy. Although the reinforcement learning is able to obtain impressive results, its stability and reliability is hard to guarantee, which would cause the potential safety threats. Besides, the transfer from simulation to real world also will lead in unpredictable situations. To enhance the safety and reliability of robots, we introduce the force and haptic perception into reinforcement learning. Force and tactual sensation play key roles in robotic dynamic control and human-robot interaction. We demonstrate that the force-based reinforcement learning method can be more adaptive to environment, especially in sim-to-real transfer. Experimental results show in object pushing task, our strategy is safer and more efficient in both simulation and real world, thus it holds prospects for a wide variety of robotic applications.",
          "authors": [
            "Nan Lin",
            "Linrui Zhang",
            "Yuxuan Chen",
            "Zhenrui Chen",
            "Yujun Zhu",
            "Ruoxi Chen",
            "Peichen Wu",
            "Xiaoping Chen"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02023",
          "title": "An Improved Ensemble-Based Machine Learning Model with Feature Optimization for Early Diabetes Prediction",
          "abstract": "Diabetes is a serious worldwide health issue, and successful intervention depends on early detection. However, overlapping risk factors and data asymmetry make prediction difficult. To use extensive health survey data to create a machine learning framework for diabetes classification that is both accurate and comprehensible, to produce results that will aid in clinical decision-making. Using the BRFSS dataset, we assessed a number of supervised learning techniques. SMOTE and Tomek Links were used to correct class imbalance. To improve prediction performance, both individual models and ensemble techniques such as stacking were investigated. The 2015 BRFSS dataset, which includes roughly 253,680 records with 22 numerical features, is used in this study. Strong ROC-AUC performance of approximately 0.96 was attained by the individual models Random Forest, XGBoost, CatBoost, and this http URL stacking ensemble with XGBoost and KNN yielded the best overall results with 94.82\\% accuracy, ROC-AUC of 0.989, and PR-AUC of 0.991, indicating a favourable balance between recall and precision. In our study, we proposed and developed a React Native-based application with a Python Flask backend to support early diabetes prediction, providing users with an accessible and efficient health monitoring tool.",
          "authors": [
            "Md. Najmul Islam",
            "Md. Miner Hossain Rimon",
            "Shah Sadek-E-Akbor Shamim",
            "Zarif Mohaimen Fahad",
            "Md. Jehadul Islam Mony",
            "Md. Jalal Uddin Chowdhury"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02024",
          "title": "Human-Level and Beyond: Benchmarking Large Language Models Against Clinical Pharmacists in Prescription Review",
          "abstract": "The rapid advancement of large language models (LLMs) has accelerated their integration into clinical decision support, particularly in prescription review. To enable systematic and fine-grained evaluation, we developed RxBench, a comprehensive benchmark that covers common prescription review categories and consolidates 14 frequent types of prescription errors drawn from authoritative pharmacy references. RxBench consists of 1,150 single-choice, 230 multiple-choice, and 879 short-answer items, all reviewed by experienced clinical pharmacists. We benchmarked 18 state-of-the-art LLMs and identified clear stratification of performance across tasks. Notably, Gemini-2.5-pro-preview-05-06, Grok-4-0709, and DeepSeek-R1-0528 consistently formed the first tier, outperforming other models in both accuracy and robustness. Comparisons with licensed pharmacists indicated that leading LLMs can match or exceed human performance in certain tasks. Furthermore, building on insights from our benchmark evaluation, we performed targeted fine-tuning on a mid-tier model, resulting in a specialized model that rivals leading general-purpose LLMs in performance on short-answer question tasks. The main contribution of RxBench lies in establishing a standardized, error-type-oriented framework that not only reveals the capabilities and limitations of frontier LLMs in prescription review but also provides a foundational resource for building more reliable and specialized clinical tools.",
          "authors": [
            "Yan Yang",
            "Mouxiao Bian",
            "Peiling Li",
            "Bingjian Wen",
            "Ruiyao Chen",
            "Kangkun Mao",
            "Xiaojun Ye",
            "Tianbin Li",
            "Pengcheng Chen",
            "Bing Han",
            "Jie Xu",
            "Kaifeng Qiu",
            "Junyan Wu"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02025",
          "title": "DySTAN: Joint Modeling of Sedentary Activity and Social Context from Smartphone Sensors",
          "abstract": "Accurately recognizing human context from smartphone sensor data remains a significant challenge, especially in sedentary settings where activities such as studying, attending lectures, relaxing, and eating exhibit highly similar inertial patterns. Furthermore, social context plays a critical role in understanding user behavior, yet is often overlooked in mobile sensing research. To address these gaps, we introduce LogMe, a mobile sensing application that passively collects smartphone sensor data (accelerometer, gyroscope, magnetometer, and rotation vector) and prompts users for hourly self-reports capturing both sedentary activity and social context. Using this dual-label dataset, we propose DySTAN (Dynamic Cross-Stitch with Task Attention Network), a multi-task learning framework that jointly classifies both context dimensions from shared sensor inputs. It integrates task-specific layers with cross-task attention to model subtle distinctions effectively. DySTAN improves sedentary activity macro F1 scores by 21.8% over a single-task CNN-BiLSTM-GRU (CBG) model and by 8.2% over the strongest multi-task baseline, Sluice Network (SN). These results demonstrate the importance of modeling multiple, co-occurring context dimensions to improve the accuracy and robustness of mobile context recognition.",
          "authors": [
            "Aditya Sneh",
            "Nilesh Kumar Sahu",
            "Snehil Gupta",
            "Haroon R. Lone"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02025",
          "title": "DySTAN: Joint Modeling of Sedentary Activity and Social Context from Smartphone Sensors",
          "abstract": "Accurately recognizing human context from smartphone sensor data remains a significant challenge, especially in sedentary settings where activities such as studying, attending lectures, relaxing, and eating exhibit highly similar inertial patterns. Furthermore, social context plays a critical role in understanding user behavior, yet is often overlooked in mobile sensing research. To address these gaps, we introduce LogMe, a mobile sensing application that passively collects smartphone sensor data (accelerometer, gyroscope, magnetometer, and rotation vector) and prompts users for hourly self-reports capturing both sedentary activity and social context. Using this dual-label dataset, we propose DySTAN (Dynamic Cross-Stitch with Task Attention Network), a multi-task learning framework that jointly classifies both context dimensions from shared sensor inputs. It integrates task-specific layers with cross-task attention to model subtle distinctions effectively. DySTAN improves sedentary activity macro F1 scores by 21.8% over a single-task CNN-BiLSTM-GRU (CBG) model and by 8.2% over the strongest multi-task baseline, Sluice Network (SN). These results demonstrate the importance of modeling multiple, co-occurring context dimensions to improve the accuracy and robustness of mobile context recognition.",
          "authors": [
            "Aditya Sneh",
            "Nilesh Kumar Sahu",
            "Snehil Gupta",
            "Haroon R. Lone"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02026",
          "title": "Towards Sustainable Precision: Machine Learning for Laser Micromachining Optimization",
          "abstract": "In the pursuit of sustainable manufacturing, ultra-short pulse laser micromachining stands out as a promising solution while also offering high-precision and qualitative laser processing. However, unlocking the full potential of ultra-short pulse lasers requires an optimized monitoring system capable of early detection of defective workpieces, regardless of the preprocessing technique employed. While advances in machine learning can help predict process quality features, the complexity of monitoring data necessitates reducing both model size and data dimensionality to enable real-time analysis. To address these challenges, this paper introduces a machine learning framework designed to enhance surface quality assessment across diverse preprocessing techniques. To facilitate real-time laser processing monitoring, our solution aims to optimize the computational requirements of the machine learning model. Experimental results show that the proposed model not only outperforms the generalizability achieved by previous works across diverse preprocessing techniques but also significantly reduces the computational requirements for training. Through these advancements, we aim to establish the baseline for a more sustainable manufacturing process.",
          "authors": [
            "Luis Correas-Naranjo",
            "Miguel Camacho-Sánchez",
            "Laëtitia Launet",
            "Milena Zuric",
            "Valery Naranjo"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02026",
          "title": "Towards Sustainable Precision: Machine Learning for Laser Micromachining Optimization",
          "abstract": "In the pursuit of sustainable manufacturing, ultra-short pulse laser micromachining stands out as a promising solution while also offering high-precision and qualitative laser processing. However, unlocking the full potential of ultra-short pulse lasers requires an optimized monitoring system capable of early detection of defective workpieces, regardless of the preprocessing technique employed. While advances in machine learning can help predict process quality features, the complexity of monitoring data necessitates reducing both model size and data dimensionality to enable real-time analysis. To address these challenges, this paper introduces a machine learning framework designed to enhance surface quality assessment across diverse preprocessing techniques. To facilitate real-time laser processing monitoring, our solution aims to optimize the computational requirements of the machine learning model. Experimental results show that the proposed model not only outperforms the generalizability achieved by previous works across diverse preprocessing techniques but also significantly reduces the computational requirements for training. Through these advancements, we aim to establish the baseline for a more sustainable manufacturing process.",
          "authors": [
            "Luis Correas-Naranjo",
            "Miguel Camacho-Sánchez",
            "Laëtitia Launet",
            "Milena Zuric",
            "Valery Naranjo"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02027",
          "title": "On the Difficulty of Token-Level Modeling of Dysfluency and Fluency Shaping Artifacts",
          "abstract": "Automatic transcription of stuttered speech remains a challenge, even for modern end-to-end (E2E) automatic speech recognition (ASR) frameworks. Dysfluencies and fluency-shaping artifacts are often overlooked, resulting in non-verbatim transcriptions with limited clinical and research value. We propose a parameter-efficient adaptation method to decode dysfluencies and fluency modifications as special tokens within transcriptions, evaluated on simulated (LibriStutter, English) and natural (KSoF, German) stuttered speech datasets. To mitigate ASR performance disparities and bias towards English, we introduce a multi-step fine-tuning strategy with language-adaptive pretraining. Tokenization analysis further highlights the tokenizer's English-centric bias, which poses challenges for improving performance on German data. Our findings demonstrate the effectiveness of lightweight adaptation techniques for dysfluency-aware ASR while exposing key limitations in multilingual E2E systems.",
          "authors": [
            "Kashaf Gulzar",
            "Dominik Wagner",
            "Sebastian P. Bayerl",
            "Florian Hönig",
            "Tobias Bocklet",
            "Korbinian Riedhammer"
          ],
          "primary_category": "eess.AS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02027",
          "title": "On the Difficulty of Token-Level Modeling of Dysfluency and Fluency Shaping Artifacts",
          "abstract": "Automatic transcription of stuttered speech remains a challenge, even for modern end-to-end (E2E) automatic speech recognition (ASR) frameworks. Dysfluencies and fluency-shaping artifacts are often overlooked, resulting in non-verbatim transcriptions with limited clinical and research value. We propose a parameter-efficient adaptation method to decode dysfluencies and fluency modifications as special tokens within transcriptions, evaluated on simulated (LibriStutter, English) and natural (KSoF, German) stuttered speech datasets. To mitigate ASR performance disparities and bias towards English, we introduce a multi-step fine-tuning strategy with language-adaptive pretraining. Tokenization analysis further highlights the tokenizer's English-centric bias, which poses challenges for improving performance on German data. Our findings demonstrate the effectiveness of lightweight adaptation techniques for dysfluency-aware ASR while exposing key limitations in multilingual E2E systems.",
          "authors": [
            "Kashaf Gulzar",
            "Dominik Wagner",
            "Sebastian P. Bayerl",
            "Florian Hönig",
            "Tobias Bocklet",
            "Korbinian Riedhammer"
          ],
          "primary_category": "eess.AS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02028",
          "title": "Seizure-NGCLNet: Representation Learning of SEEG Spatial Pathological Patterns for Epileptic Seizure Detection via Node-Graph Dual Contrastive Learning",
          "abstract": "Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization.",
          "authors": [
            "Yiping Wang",
            "Peiren Wang",
            "Zhenye Li",
            "Fang Liu",
            "Jinguo Huang"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02028",
          "title": "Seizure-NGCLNet: Representation Learning of SEEG Spatial Pathological Patterns for Epileptic Seizure Detection via Node-Graph Dual Contrastive Learning",
          "abstract": "Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization.",
          "authors": [
            "Yiping Wang",
            "Peiren Wang",
            "Zhenye Li",
            "Fang Liu",
            "Jinguo Huang"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02028",
          "title": "Seizure-NGCLNet: Representation Learning of SEEG Spatial Pathological Patterns for Epileptic Seizure Detection via Node-Graph Dual Contrastive Learning",
          "abstract": "Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization.",
          "authors": [
            "Yiping Wang",
            "Peiren Wang",
            "Zhenye Li",
            "Fang Liu",
            "Jinguo Huang"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02029",
          "title": "HODL Strategy or Fantasy? 480 Million Crypto Market Simulations and the Macro-Sentiment Effect",
          "abstract": "Crypto enthusiasts claim that buying and holding crypto assets yields high returns, often citing Bitcoin's past performance to promote other tokens and fuel fear of missing out. However, understanding the real risk-return trade-off and what factors affect future crypto returns is crucial as crypto becomes increasingly accessible to retail investors through major brokerages. We examine the HODL strategy through two independent analyses. First, we implement 480 million Monte Carlo simulations across 378 non-stablecoin crypto assets, net of trading fees and the opportunity cost of 1-month Treasury bills, and find strong evidence of survivorship bias and extreme downside concentration. At the 2-3 year horizon, the median excess return is -28.4 percent, the 1 percent conditional value at risk indicates that tail scenarios wipe out principal after all costs, and only the top quartile achieves very large gains, with a mean excess return of 1,326.7 percent. These results challenge the HODL narrative: across a broad set of assets, simple buy-and-hold loads extreme downside risk onto most investors, and the miracles mostly belong to the luckiest quarter. Second, using a Bayesian multi-horizon local projection framework, we find that endogenous predictors based on realized risk-return metrics have economically negligible and unstable effects, while macro-finance factors, especially the 24-week exponential moving average of the Fear and Greed Index, display persistent long-horizon impacts and high cross-basket stability. Where significant, a one-standard-deviation sentiment shock reduces forward top-quartile mean excess returns by 15-22 percentage points and median returns by 6-10 percentage points over 1-3 year horizons, suggesting that macro-sentiment conditions, rather than realized return histories, are the dominant indicators for future outcomes.",
          "authors": [
            "Weikang Zhang",
            "Alison Watts"
          ],
          "primary_category": "q-fin.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02029",
          "title": "HODL Strategy or Fantasy? 480 Million Crypto Market Simulations and the Macro-Sentiment Effect",
          "abstract": "Crypto enthusiasts claim that buying and holding crypto assets yields high returns, often citing Bitcoin's past performance to promote other tokens and fuel fear of missing out. However, understanding the real risk-return trade-off and what factors affect future crypto returns is crucial as crypto becomes increasingly accessible to retail investors through major brokerages. We examine the HODL strategy through two independent analyses. First, we implement 480 million Monte Carlo simulations across 378 non-stablecoin crypto assets, net of trading fees and the opportunity cost of 1-month Treasury bills, and find strong evidence of survivorship bias and extreme downside concentration. At the 2-3 year horizon, the median excess return is -28.4 percent, the 1 percent conditional value at risk indicates that tail scenarios wipe out principal after all costs, and only the top quartile achieves very large gains, with a mean excess return of 1,326.7 percent. These results challenge the HODL narrative: across a broad set of assets, simple buy-and-hold loads extreme downside risk onto most investors, and the miracles mostly belong to the luckiest quarter. Second, using a Bayesian multi-horizon local projection framework, we find that endogenous predictors based on realized risk-return metrics have economically negligible and unstable effects, while macro-finance factors, especially the 24-week exponential moving average of the Fear and Greed Index, display persistent long-horizon impacts and high cross-basket stability. Where significant, a one-standard-deviation sentiment shock reduces forward top-quartile mean excess returns by 15-22 percentage points and median returns by 6-10 percentage points over 1-3 year horizons, suggesting that macro-sentiment conditions, rather than realized return histories, are the dominant indicators for future outcomes.",
          "authors": [
            "Weikang Zhang",
            "Alison Watts"
          ],
          "primary_category": "q-fin.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02030",
          "title": "Generative design and validation of therapeutic peptides for glioblastoma based on a potential target ATP5A",
          "abstract": "Glioblastoma (GBM) remains the most aggressive tumor, urgently requiring novel therapeutic strategies. Here, we present a dry-to-wet framework combining generative modeling and experimental validation to optimize peptides targeting ATP5A, a potential peptide-binding protein for GBM. Our framework introduces the first lead-conditioned generative model, which focuses exploration on geometrically relevant regions around lead peptides and mitigates the combinatorial complexity of de novo methods. Specifically, we propose POTFlow, a \\underline{P}rior and \\underline{O}ptimal \\underline{T}ransport-based \\underline{Flow}-matching model for peptide optimization. POTFlow employs secondary structure information (e.g., helix, sheet, loop) as geometric constraints, which are further refined by optimal transport to produce shorter flow paths. With this design, our method achieves state-of-the-art performance compared with five popular approaches. When applied to GBM, our method generates peptides that selectively inhibit cell viability and significantly prolong survival in a patient-derived xenograft (PDX) model. As the first lead peptide-conditioned flow matching model, POTFlow holds strong potential as a generalizable framework for therapeutic peptide design.",
          "authors": [
            "Hao Qian",
            "Pu You",
            "Lin Zeng",
            "Jingyuan Zhou",
            "Dengdeng Huang",
            "Kaicheng Li",
            "Shikui Tu",
            "Lei Xu"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02030",
          "title": "Generative design and validation of therapeutic peptides for glioblastoma based on a potential target ATP5A",
          "abstract": "Glioblastoma (GBM) remains the most aggressive tumor, urgently requiring novel therapeutic strategies. Here, we present a dry-to-wet framework combining generative modeling and experimental validation to optimize peptides targeting ATP5A, a potential peptide-binding protein for GBM. Our framework introduces the first lead-conditioned generative model, which focuses exploration on geometrically relevant regions around lead peptides and mitigates the combinatorial complexity of de novo methods. Specifically, we propose POTFlow, a \\underline{P}rior and \\underline{O}ptimal \\underline{T}ransport-based \\underline{Flow}-matching model for peptide optimization. POTFlow employs secondary structure information (e.g., helix, sheet, loop) as geometric constraints, which are further refined by optimal transport to produce shorter flow paths. With this design, our method achieves state-of-the-art performance compared with five popular approaches. When applied to GBM, our method generates peptides that selectively inhibit cell viability and significantly prolong survival in a patient-derived xenograft (PDX) model. As the first lead peptide-conditioned flow matching model, POTFlow holds strong potential as a generalizable framework for therapeutic peptide design.",
          "authors": [
            "Hao Qian",
            "Pu You",
            "Lin Zeng",
            "Jingyuan Zhou",
            "Dengdeng Huang",
            "Kaicheng Li",
            "Shikui Tu",
            "Lei Xu"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02031",
          "title": "Pharmacophore-based design by learning on voxel grids",
          "abstract": "Ligand-based drug discovery (LBDD) relies on making use of known binders to a protein target to find structurally diverse molecules similarly likely to bind. This process typically involves a brute force search of the known binder (query) against a molecular library using some metric of molecular similarity. One popular approach overlays the pharmacophore-shape profile of the known binder to 3D conformations enumerated for each of the library molecules, computes overlaps, and picks a set of diverse library molecules with high overlaps. While this virtual screening workflow has had considerable success in hit diversification, scaffold hopping, and patent busting, it scales poorly with library sizes and restricts candidate generation to existing library compounds. Leveraging recent advances in voxel-based generative modelling, we propose a pharmacophore-based generative model and workflows that address the scaling and fecundity issues of conventional pharmacophore-based virtual screening. We introduce \\emph{VoxCap}, a voxel captioning method for generating SMILES strings from voxelised molecular representations. We propose two workflows as practical use cases as well as benchmarks for pharmacophore-based generation: \\emph{de-novo} design, in which we aim to generate new molecules with high pharmacophore-shape similarities to query molecules, and fast search, which aims to combine generative design with a cheap 2D substructure similarity search for efficient hit identification. Our results show that VoxCap significantly outperforms previous methods in generating diverse \\textit{de-novo} hits. When combined with our fast search workflow, VoxCap reduces computational time by orders of magnitude while returning hits for all query molecules, enabling the search of large libraries that are intractable to search by brute force.",
          "authors": [
            "Omar Mahmood",
            "Pedro O. Pinheiro",
            "Richard Bonneau",
            "Saeed Saremi",
            "Vishnu Sresht"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02031",
          "title": "Pharmacophore-based design by learning on voxel grids",
          "abstract": "Ligand-based drug discovery (LBDD) relies on making use of known binders to a protein target to find structurally diverse molecules similarly likely to bind. This process typically involves a brute force search of the known binder (query) against a molecular library using some metric of molecular similarity. One popular approach overlays the pharmacophore-shape profile of the known binder to 3D conformations enumerated for each of the library molecules, computes overlaps, and picks a set of diverse library molecules with high overlaps. While this virtual screening workflow has had considerable success in hit diversification, scaffold hopping, and patent busting, it scales poorly with library sizes and restricts candidate generation to existing library compounds. Leveraging recent advances in voxel-based generative modelling, we propose a pharmacophore-based generative model and workflows that address the scaling and fecundity issues of conventional pharmacophore-based virtual screening. We introduce \\emph{VoxCap}, a voxel captioning method for generating SMILES strings from voxelised molecular representations. We propose two workflows as practical use cases as well as benchmarks for pharmacophore-based generation: \\emph{de-novo} design, in which we aim to generate new molecules with high pharmacophore-shape similarities to query molecules, and fast search, which aims to combine generative design with a cheap 2D substructure similarity search for efficient hit identification. Our results show that VoxCap significantly outperforms previous methods in generating diverse \\textit{de-novo} hits. When combined with our fast search workflow, VoxCap reduces computational time by orders of magnitude while returning hits for all query molecules, enabling the search of large libraries that are intractable to search by brute force.",
          "authors": [
            "Omar Mahmood",
            "Pedro O. Pinheiro",
            "Richard Bonneau",
            "Saeed Saremi",
            "Vishnu Sresht"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02032",
          "title": "Characterizing Continuous and Discrete Hybrid Latent Spaces for Structural Connectomes",
          "abstract": "Structural connectomes are detailed graphs that map how different brain regions are physically connected, offering critical insight into aging, cognition, and neurodegenerative diseases. However, these connectomes are high-dimensional and densely interconnected, which makes them difficult to interpret and analyze at scale. While low-dimensional spaces like PCA and autoencoders are often used to capture major sources of variation, their latent spaces are generally continuous and cannot fully reflect the mixed nature of variability in connectomes, which include both continuous (e.g., connectivity strength) and discrete factors (e.g., imaging site). Motivated by this, we propose a variational autoencoder (VAE) with a hybrid latent space that jointly models the discrete and continuous components. We analyze a large dataset of 5,761 connectomes from six Alzheimer's disease studies with ten acquisition protocols. Each connectome represents a single scan from a unique subject (3579 females, 2182 males), aged 22 to 102, with 4338 cognitively normal, 809 with mild cognitive impairment (MCI), and 614 with Alzheimer's disease (AD). Each connectome contains 121 brain regions defined by the BrainCOLOR atlas. We train our hybrid VAE in an unsupervised way and characterize what each latent component captures. We find that the discrete space is particularly effective at capturing subtle site-related differences, achieving an Adjusted Rand Index (ARI) of 0.65 with site labels, significantly outperforming PCA and a standard VAE followed by clustering (p < 0.05). These results demonstrate that the hybrid latent space can disentangle distinct sources of variability in connectomes in an unsupervised manner, offering potential for large-scale connectome analysis.",
          "authors": [
            "Gaurav Rudravaram",
            "Lianrui Zuo",
            "Adam M. Saunders",
            "Michael E. Kim",
            "Praitayini Kanakaraj",
            "Nancy R. Newlin",
            "Aravind R. Krishnan",
            "Elyssa M. McMaster",
            "Chloe Cho",
            "Susan M. Resnick",
            "Lori L. Beason Held",
            "Derek Archer",
            "Timothy J. Hohman",
            "Daniel C. Moyer",
            "Bennett A. Landman"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02032",
          "title": "Characterizing Continuous and Discrete Hybrid Latent Spaces for Structural Connectomes",
          "abstract": "Structural connectomes are detailed graphs that map how different brain regions are physically connected, offering critical insight into aging, cognition, and neurodegenerative diseases. However, these connectomes are high-dimensional and densely interconnected, which makes them difficult to interpret and analyze at scale. While low-dimensional spaces like PCA and autoencoders are often used to capture major sources of variation, their latent spaces are generally continuous and cannot fully reflect the mixed nature of variability in connectomes, which include both continuous (e.g., connectivity strength) and discrete factors (e.g., imaging site). Motivated by this, we propose a variational autoencoder (VAE) with a hybrid latent space that jointly models the discrete and continuous components. We analyze a large dataset of 5,761 connectomes from six Alzheimer's disease studies with ten acquisition protocols. Each connectome represents a single scan from a unique subject (3579 females, 2182 males), aged 22 to 102, with 4338 cognitively normal, 809 with mild cognitive impairment (MCI), and 614 with Alzheimer's disease (AD). Each connectome contains 121 brain regions defined by the BrainCOLOR atlas. We train our hybrid VAE in an unsupervised way and characterize what each latent component captures. We find that the discrete space is particularly effective at capturing subtle site-related differences, achieving an Adjusted Rand Index (ARI) of 0.65 with site labels, significantly outperforming PCA and a standard VAE followed by clustering (p < 0.05). These results demonstrate that the hybrid latent space can disentangle distinct sources of variability in connectomes in an unsupervised manner, offering potential for large-scale connectome analysis.",
          "authors": [
            "Gaurav Rudravaram",
            "Lianrui Zuo",
            "Adam M. Saunders",
            "Michael E. Kim",
            "Praitayini Kanakaraj",
            "Nancy R. Newlin",
            "Aravind R. Krishnan",
            "Elyssa M. McMaster",
            "Chloe Cho",
            "Susan M. Resnick",
            "Lori L. Beason Held",
            "Derek Archer",
            "Timothy J. Hohman",
            "Daniel C. Moyer",
            "Bennett A. Landman"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02033",
          "title": "CONFIDE: Hallucination Assessment for Reliable Biomolecular Structure Prediction and Design",
          "abstract": "Reliable evaluation of protein structure predictions remains challenging, as metrics like pLDDT capture energetic stability but often miss subtle errors such as atomic clashes or conformational traps reflecting topological frustration within the protein folding energy landscape. We present CODE (Chain of Diffusion Embeddings), a self evaluating metric empirically found to quantify topological frustration directly from the latent diffusion embeddings of the AlphaFold3 series of structure predictors in a fully unsupervised manner. Integrating this with pLDDT, we propose CONFIDE, a unified evaluation framework that combines energetic and topological perspectives to improve the reliability of AlphaFold3 and related models. CODE strongly correlates with protein folding rates driven by topological frustration, achieving a correlation of 0.82 compared to pLDDT's 0.33 (a relative improvement of 148\\%). CONFIDE significantly enhances the reliability of quality evaluation in molecular glue structure prediction benchmarks, achieving a Spearman correlation of 0.73 with RMSD, compared to pLDDT's correlation of 0.42, a relative improvement of 73.8\\%. Beyond quality assessment, our approach applies to diverse drug design tasks, including all-atom binder design, enzymatic active site mapping, mutation induced binding affinity prediction, nucleic acid aptamer screening, and flexible protein modeling. By combining data driven embeddings with theoretical insight, CODE and CONFIDE outperform existing metrics across a wide range of biomolecular systems, offering robust and versatile tools to refine structure predictions, advance structural biology, and accelerate drug discovery.",
          "authors": [
            "Zijun Gao",
            "Mutian He",
            "Shijia Sun",
            "Hanqun Cao",
            "Jingjie Zhang",
            "Zihao Luo",
            "Xiaorui Wang",
            "Xiaojun Yao",
            "Chang-Yu Hsieh",
            "Chunbin Gu",
            "Pheng Ann Heng"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02033",
          "title": "CONFIDE: Hallucination Assessment for Reliable Biomolecular Structure Prediction and Design",
          "abstract": "Reliable evaluation of protein structure predictions remains challenging, as metrics like pLDDT capture energetic stability but often miss subtle errors such as atomic clashes or conformational traps reflecting topological frustration within the protein folding energy landscape. We present CODE (Chain of Diffusion Embeddings), a self evaluating metric empirically found to quantify topological frustration directly from the latent diffusion embeddings of the AlphaFold3 series of structure predictors in a fully unsupervised manner. Integrating this with pLDDT, we propose CONFIDE, a unified evaluation framework that combines energetic and topological perspectives to improve the reliability of AlphaFold3 and related models. CODE strongly correlates with protein folding rates driven by topological frustration, achieving a correlation of 0.82 compared to pLDDT's 0.33 (a relative improvement of 148\\%). CONFIDE significantly enhances the reliability of quality evaluation in molecular glue structure prediction benchmarks, achieving a Spearman correlation of 0.73 with RMSD, compared to pLDDT's correlation of 0.42, a relative improvement of 73.8\\%. Beyond quality assessment, our approach applies to diverse drug design tasks, including all-atom binder design, enzymatic active site mapping, mutation induced binding affinity prediction, nucleic acid aptamer screening, and flexible protein modeling. By combining data driven embeddings with theoretical insight, CODE and CONFIDE outperform existing metrics across a wide range of biomolecular systems, offering robust and versatile tools to refine structure predictions, advance structural biology, and accelerate drug discovery.",
          "authors": [
            "Zijun Gao",
            "Mutian He",
            "Shijia Sun",
            "Hanqun Cao",
            "Jingjie Zhang",
            "Zihao Luo",
            "Xiaorui Wang",
            "Xiaojun Yao",
            "Chang-Yu Hsieh",
            "Chunbin Gu",
            "Pheng Ann Heng"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02036",
          "title": "Integration of LSTM Networks in Random Forest Algorithms for Stock Market Trading Predictions",
          "abstract": "The aim of this paper is the analysis and selection of stock trading systems that combine different models with data of different nature, such as financial and microeconomic information. Specifically, based on previous work by the authors and applying advanced techniques of Machine Learning and Deep Learning, our objective is to formulate trading algorithms for the stock market with empirically tested statistical advantages, thus improving results published in the literature. Our approach integrates Long Short-Term Memory (LSTM) networks with algorithms based on decision trees, such as Random Forest and Gradient Boosting. While the former analyze price patterns of financial assets, the latter are fed with economic data of companies. Numerical simulations of algorithmic trading with data from international companies and 10-weekday predictions confirm that an approach based on both fundamental and technical variables can outperform the usual approaches, which do not combine those two types of variables. In doing so, Random Forest turned out to be the best performer among the decision trees. We also discuss how the prediction performance of such a hybrid approach can be boosted by selecting the technical variables.",
          "authors": [
            "Juan C. King",
            "Jose M. Amigo"
          ],
          "primary_category": "q-fin.CP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02036",
          "title": "Integration of LSTM Networks in Random Forest Algorithms for Stock Market Trading Predictions",
          "abstract": "The aim of this paper is the analysis and selection of stock trading systems that combine different models with data of different nature, such as financial and microeconomic information. Specifically, based on previous work by the authors and applying advanced techniques of Machine Learning and Deep Learning, our objective is to formulate trading algorithms for the stock market with empirically tested statistical advantages, thus improving results published in the literature. Our approach integrates Long Short-Term Memory (LSTM) networks with algorithms based on decision trees, such as Random Forest and Gradient Boosting. While the former analyze price patterns of financial assets, the latter are fed with economic data of companies. Numerical simulations of algorithmic trading with data from international companies and 10-weekday predictions confirm that an approach based on both fundamental and technical variables can outperform the usual approaches, which do not combine those two types of variables. In doing so, Random Forest turned out to be the best performer among the decision trees. We also discuss how the prediction performance of such a hybrid approach can be boosted by selecting the technical variables.",
          "authors": [
            "Juan C. King",
            "Jose M. Amigo"
          ],
          "primary_category": "q-fin.CP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02037",
          "title": "Statistical Arbitrage in Polish Equities Market Using Deep Learning Techniques",
          "abstract": "We study a systematic approach to a popular Statistical Arbitrage technique: Pairs Trading. Instead of relying on two highly correlated assets, we replace the second asset with a replication of the first using risk factor representations. These factors are obtained through Principal Components Analysis (PCA), exchange traded funds (ETFs), and, as our main contribution, Long Short Term Memory networks (LSTMs). Residuals between the main asset and its replication are examined for mean reversion properties, and trading signals are generated for sufficiently fast mean reverting portfolios. Beyond introducing a deep learning based replication method, we adapt the framework of Avellaneda and Lee (2008) to the Polish market. Accordingly, components of WIG20, mWIG40, and selected sector indices replace the original S&P500 universe, and market parameters such as the risk free rate and transaction costs are updated to reflect local conditions. We outline the full strategy pipeline: risk factor construction, residual modeling via the Ornstein Uhlenbeck process, and signal generation. Each replication technique is described together with its practical implementation. Strategy performance is evaluated over two periods: 2017-2019 and the recessive year 2020. All methods yield profits in 2017-2019, with PCA achieving roughly 20 percent cumulative return and an annualized Sharpe ratio of up to 2.63. Despite multiple adaptations, our conclusions remain consistent with those of the original paper. During the COVID-19 recession, only the ETF based approach remains profitable (about 5 percent annual return), while PCA and LSTM methods underperform. LSTM results, although negative, are promising and indicate potential for future optimization.",
          "authors": [
            "Marek Adamczyk",
            "Michał Dąbrowski"
          ],
          "primary_category": "q-fin.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02037",
          "title": "Statistical Arbitrage in Polish Equities Market Using Deep Learning Techniques",
          "abstract": "We study a systematic approach to a popular Statistical Arbitrage technique: Pairs Trading. Instead of relying on two highly correlated assets, we replace the second asset with a replication of the first using risk factor representations. These factors are obtained through Principal Components Analysis (PCA), exchange traded funds (ETFs), and, as our main contribution, Long Short Term Memory networks (LSTMs). Residuals between the main asset and its replication are examined for mean reversion properties, and trading signals are generated for sufficiently fast mean reverting portfolios. Beyond introducing a deep learning based replication method, we adapt the framework of Avellaneda and Lee (2008) to the Polish market. Accordingly, components of WIG20, mWIG40, and selected sector indices replace the original S&P500 universe, and market parameters such as the risk free rate and transaction costs are updated to reflect local conditions. We outline the full strategy pipeline: risk factor construction, residual modeling via the Ornstein Uhlenbeck process, and signal generation. Each replication technique is described together with its practical implementation. Strategy performance is evaluated over two periods: 2017-2019 and the recessive year 2020. All methods yield profits in 2017-2019, with PCA achieving roughly 20 percent cumulative return and an annualized Sharpe ratio of up to 2.63. Despite multiple adaptations, our conclusions remain consistent with those of the original paper. During the COVID-19 recession, only the ETF based approach remains profitable (about 5 percent annual return), while PCA and LSTM methods underperform. LSTM results, although negative, are promising and indicate potential for future optimization.",
          "authors": [
            "Marek Adamczyk",
            "Michał Dąbrowski"
          ],
          "primary_category": "q-fin.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02038",
          "title": "Deep Research: A Systematic Survey",
          "abstract": "Large language models (LLMs) have rapidly evolved from text generators into powerful problem solvers. Yet, many open tasks demand critical thinking, multi-source, and verifiable outputs, which are beyond single-shot prompting or standard retrieval-augmented generation. Recently, numerous studies have explored Deep Research (DR), which aims to combine the reasoning capabilities of LLMs with external tools, such as search engines, thereby empowering LLMs to act as research agents capable of completing complex, open-ended tasks. This survey presents a comprehensive and systematic overview of deep research systems, including a clear roadmap, foundational components, practical implementation techniques, important challenges, and future directions. Specifically, our main contributions are as follows: (i) we formalize a three-stage roadmap and distinguish deep research from related paradigms; (ii) we introduce four key components: query planning, information acquisition, memory management, and answer generation, each paired with fine-grained sub-taxonomies; (iii) we summarize optimization techniques, including prompting, supervised fine-tuning, and agentic reinforcement learning; and (iv) we consolidate evaluation criteria and open challenges, aiming to guide and facilitate future development. As the field of deep research continues to evolve rapidly, we are committed to continuously updating this survey to reflect the latest progress in this area.",
          "authors": [
            "Zhengliang Shi",
            "Yiqun Chen",
            "Haitao Li",
            "Weiwei Sun",
            "Shiyu Ni",
            "Yougang Lyu",
            "Run-Ze Fan",
            "Bowen Jin",
            "Yixuan Weng",
            "Minjun Zhu",
            "Qiujie Xie",
            "Xinyu Guo",
            "Qu Yang",
            "Jiayi Wu",
            "Jujia Zhao",
            "Xiaqiang Tang",
            "Xinbei Ma",
            "Cunxiang Wang",
            "Jiaxin Mao",
            "Qingyao Ai",
            "Jen-Tse Huang",
            "Wenxuan Wang",
            "Yue Zhang",
            "Yiming Yang",
            "Zhaopeng Tu",
            "Zhaochun Ren"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02043",
          "title": "Mirror, Mirror on the Wall -- Which is the Best Model of Them All?",
          "abstract": "Large Language Models (LLMs) have become one of the most transformative tools across many applications, as they have significantly boosted productivity and achieved impressive results in various domains such as finance, healthcare, education, telecommunications, and law, among others. Typically, state-of-the-art (SOTA) foundation models are developed by large corporations based on large data collections and substantial computational and financial resources required to pretrain such models from scratch. These foundation models then serve as the basis for further development and domain adaptation for specific use cases or tasks. However, given the dynamic and fast-paced nature of launching new foundation models, the process of selecting the most suitable model for a particular use case, application, or domain becomes increasingly complex. We argue that there are two main dimensions that need to be taken into consideration when selecting a model for further training: a qualitative dimension (which model is best suited for a task based on information, for instance, taken from model cards) and a quantitative dimension (which is the best performing model). The quantitative performance of models is assessed through leaderboards, which rank models based on standardized benchmarks and provide a consistent framework for comparing different LLMs. In this work, we address the analysis of the quantitative dimension by exploring the current leaderboards and benchmarks. To illustrate this analysis, we focus on the medical domain as a case study, demonstrating the evolution, current landscape, and practical significance of this quantitative evaluation dimension. Finally, we propose a Model Selection Methodology (MSM), a systematic approach designed to guide the navigation, prioritization, and selection of the model that best aligns with a given use case.",
          "authors": [
            "Dina Sayed",
            "Heiko Schuldt"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02044",
          "title": "Beyond Confidence: Adaptive and Coherent Decoding for Diffusion Language Models",
          "abstract": "Diffusion Language Models (DLMs) have recently achieved significant success due to their any-order generation capabilities. However, existing inference methods typically rely on local, immediate-step metrics such as confidence or entropy which inherently lack a more reliable perspective. This limitation frequently leads to inconsistent sampling trajectories and suboptimal generation quality. To address this, we propose Coherent Contextual Decoding (CCD), a novel inference framework built upon two core innovations. First, CCD employs a trajectory rectification mechanism that leverages historical context to enhance sequence coherence, enabling the early rejection of suboptimal paths. We demonstrate that this mechanism is theoretically equivalent to modeling the consistency of historical steps via the conditional mutual information between context and token predictions. Building on this theoretical insight, we further address the inefficiency of conventional uniform decoding budgets. Instead of rigid allocations based on diffusion steps, we introduce an adaptive sampling strategy that dynamically adjusts the unmasking budget for each step according to our consistency metric. Consequently, our method significantly improves the quality of generation trajectories while accelerating the sampling process. Empirically, our method achieves a simultaneous enhancement in both inference speed and performance across diverse benchmarks on Dream and LLaDA, delivering up to 3.48x speedup alongside 3.91% performance improvement.",
          "authors": [
            "Kecheng Chen",
            "Ziru Liu",
            "Xijia Tao",
            "Hui Liu",
            "Xinyu Fu",
            "Suiyun Zhang",
            "Dandan Tu",
            "Lingpeng Kong",
            "Rui Liu",
            "Haoliang Li"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02046",
          "title": "Global AI Governance Overview: Understanding Regulatory Requirements Across Global Jurisdictions",
          "abstract": "The rapid advancement of general-purpose AI models has increased concerns about copyright infringement in training data, yet current regulatory frameworks remain predominantly reactive rather than proactive. This paper examines the regulatory landscape of AI training data governance in major jurisdictions, including the EU, the United States, and the Asia-Pacific region. It also identifies critical gaps in enforcement mechanisms that threaten both creator rights and the sustainability of AI development. Through analysis of major cases we identified critical gaps in pre-training data filtering. Existing solutions such as transparency tools, perceptual hashing, and access control mechanisms address only specific aspects of the problem and cannot prevent initial copyright violations. We identify two fundamental challenges: pre-training license collection and content filtering, which faces the impossibility of comprehensive copyright management at scale, and verification mechanisms, which lack tools to confirm filtering prevented infringement. We propose a multilayered filtering pipeline that combines access control, content verification, machine learning classifiers, and continuous database cross-referencing to shift copyright protection from post-training detection to pre-training prevention. This approach offers a pathway toward protecting creator rights while enabling continued AI innovation.",
          "authors": [
            "Mariia Kyrychenko",
            "Mykyta Mudryi",
            "Markiyan Chaklosh"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02047",
          "title": "Copyright in AI Pre-Training Data Filtering: Regulatory Landscape and Mitigation Strategies",
          "abstract": "The rapid advancement of general-purpose AI models has increased concerns about copyright infringement in training data, yet current regulatory frameworks remain predominantly reactive rather than proactive. This paper examines the regulatory landscape of AI training data governance in major jurisdictions, including the EU, the United States, and the Asia-Pacific region. It also identifies critical gaps in enforcement mechanisms that threaten both creator rights and the sustainability of AI development. Through analysis of major cases we identified critical gaps in pre-training data filtering. Existing solutions such as transparency tools, perceptual hashing, and access control mechanisms address only specific aspects of the problem and cannot prevent initial copyright violations. We identify two fundamental challenges: pre-training license collection and content filtering, which faces the impossibility of comprehensive copyright management at scale, and verification mechanisms, which lack tools to confirm filtering prevented infringement. We propose a multilayered filtering pipeline that combines access control, content verification, machine learning classifiers, and continuous database cross-referencing to shift copyright protection from post-training detection to pre-training prevention. This approach offers a pathway toward protecting creator rights while enabling continued AI innovation.",
          "authors": [
            "Mariia Kyrychenko",
            "Mykyta Mudryi",
            "Markiyan Chaklosh"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02049",
          "title": "PIBNet: a Physics-Inspired Boundary Network for Multiple Scattering Simulations",
          "abstract": "The boundary element method (BEM) provides an efficient numerical framework for solving multiple scattering problems in unbounded homogeneous domains, since it reduces the discretization to the domain boundaries, thereby condensing the computational complexity. The procedure first consists in determining the solution trace on the boundaries of the domain by solving a boundary integral equation, after which the volumetric solution can be recovered at low computational cost with a boundary integral representation. As the first step of the BEM represents the main computational bottleneck, we introduce PIBNet, a learning-based approach designed to approximate the solution trace. The method leverages a physics-inspired graph-based strategy to model obstacles and their long-range interactions efficiently. Then, we introduce a novel multiscale graph neural network architecture for simulating the multiple scattering. To train and evaluate our network, we present a benchmark consisting of several datasets of different types of multiple scattering problems. The results indicate that our approach not only surpasses existing state-of-the-art learning-based methods on the considered tasks but also exhibits superior generalization to settings with an increased number of obstacles. this http URL",
          "authors": [
            "Rémi Marsal",
            "Stéphanie Chaillat"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02053",
          "title": "Contextual Gating within the Transformer Stack: Synergistic Feature Modulation for Enhanced Lyrical Classification and Calibration",
          "abstract": "This study introduces a significant architectural advancement in feature fusion for lyrical content classification by integrating auxiliary structural features directly into the self-attention mechanism of a pre-trained Transformer. I propose the SFL Transformer, a novel deep learning model that utilizes a Contextual Gating mechanism (an Intermediate SFL) to modulate the sequence of hidden states within the BERT encoder stack, rather than fusing features at the final output layer. This approach modulates the deep, contextualized semantic features (Hseq) using low-dimensional structural cues (Fstruct). The model is applied to a challenging binary classification task derived from UMAP-reduced lyrical embeddings. The SFL Transformer achieved an Accuracy of 0.9910 and a Macro F1 score of 0.9910, significantly improving the state-of-the-art established by the previously published SFL model (Accuracy 0.9894). Crucially, this Contextual Gating strategy maintained exceptional reliability, with a low Expected Calibration Error (ECE = 0.0081) and Log Loss (0.0489). This work validates the hypothesis that injecting auxiliary context mid-stack is the most effective means of synergistically combining structural and semantic information, creating a model with both superior discriminative power and high-fidelity probability estimates.",
          "authors": [
            "M.A. Gameiro"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02055",
          "title": "Leveraging AI multimodal geospatial foundation models for improved near-real-time flood mapping at a global scale",
          "abstract": "Floods are among the most damaging weather-related hazards, and in 2024, the warmest year on record, extreme flood events affected communities across five continents. Earth observation (EO) satellites provide critical, frequent coverage for mapping inundation, yet operational accuracy depends heavily on labeled datasets and model generalization. Recent Geospatial Foundation Models (GFMs), such as ESA-IBM's TerraMind, offer improved generalizability through large-scale self-supervised pretraining, but their performance on diverse global flood events remains poorly understood. We fine-tune TerraMind for flood extent mapping using FloodsNet, a harmonized multimodal dataset containing co-located Sentinel-1 (Synthetic Aperture Radar, SAR data) and Sentinel-2 (optical) imagery for 85 flood events worldwide. We tested four configurations (base vs. large models; frozen vs. unfrozen backbones) and compared against the TerraMind Sen1Floods11 example and a U-Net trained on both FloodsNet and Sen1Floods11. The base-unfrozen configuration provided the best balance of accuracy, precision, and recall at substantially lower computational cost than the large model. The large unfrozen model achieved the highest recall. Models trained on FloodsNet outperformed the Sen1Floods11-trained example in recall with similar overall accuracy. U-Net achieved higher recall than all GFM configurations, though with slightly lower accuracy and precision. Our results demonstrate that integrating multimodal optical and SAR data and fine-tuning a GFM can enhance near-real-time flood mapping. This study provides one of the first global-scale evaluations of a GFM for flood segmentation, highlighting both its potential and current limitations for climate adaptation and disaster resilience.",
          "authors": [
            "Mirela G. Tulbure",
            "Julio Caineta",
            "Mark Broich",
            "Mollie D. Gaines",
            "Philippe Rufin",
            "Leon-Friedrich Thomas",
            "Hamed Alemohammad",
            "Jan Hemmerling",
            "Patrick Hostert"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02056",
          "title": "Reversing Large Language Models for Efficient Training and Fine-Tuning",
          "abstract": "Large Language Models (LLMs) are known for their expensive and time-consuming training. Thus, oftentimes, LLMs are fine-tuned to address a specific task, given the pretrained weights of a pre-trained LLM considered a foundation model. In this work, we introduce memory-efficient, reversible architectures for LLMs, inspired by symmetric and symplectic differential equations, and investigate their theoretical properties. Different from standard, baseline architectures that store all intermediate activations, the proposed models use time-reversible dynamics to retrieve hidden states during backpropagation, relieving the need to store activations. This property allows for a drastic reduction in memory consumption, allowing for the processing of larger batch sizes for the same available memory, thereby offering improved throughput. In addition, we propose an efficient method for converting existing, non-reversible LLMs into reversible architectures through fine-tuning, rendering our approach practical for exploiting existing pre-trained models. Our results show comparable or improved performance on several datasets and benchmarks, on several LLMs, building a scalable and efficient path towards reducing the memory and computational costs associated with both training from scratch and fine-tuning of LLMs.",
          "authors": [
            "Eshed Gal",
            "Moshe Eliasof",
            "Javier Turek",
            "Uri Ascher",
            "Eran Treister",
            "Eldad Haber"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02057",
          "title": "Opening the Black Box: An Explainable, Few-shot AI4E Framework Informed by Physics and Expert Knowledge for Materials Engineering",
          "abstract": "The industrial adoption of Artificial Intelligence for Engineering (AI4E) faces two fundamental bottlenecks: scarce high-quality data and the lack of interpretability in black-box models-particularly critical in safety-sensitive sectors like aerospace. We present an explainable, few-shot AI4E framework that is systematically informed by physics and expert knowledge throughout its architecture. Starting from only 32 experimental samples in an aerial K439B superalloy castings repair welding case, we first augment physically plausible synthetic data through a three-stage protocol: differentiated noise injection calibrated to process variabilities, enforcement of hard physical constraints, and preservation of inter-parameter relationships. We then employ a nested optimization strategy for constitutive model discovery, where symbolic regression explores equation structures while differential evolution optimizes parameters, followed by intensive parameter refinement using hybrid global-local optimization. The resulting interpretable constitutive equation achieves 88% accuracy in predicting hot-cracking tendency. This equation not only provides quantitative predictions but also delivers explicit physical insight, revealing how thermal, geometric, and metallurgical mechanisms couple to drive cracking-thereby advancing engineers' cognitive understanding of the process. Furthermore, the constitutive equation serves as a multi-functional tool for process optimization and high-fidelity virtual data generation, enabling accuracy improvements in other data-driven models. Our approach provides a general blueprint for developing trustworthy AI systems that embed engineering domain knowledge directly into their architecture, enabling reliable adoption in high-stakes industrial applications where data is limited but physical understanding is available.",
          "authors": [
            "Haoxiang Zhang",
            "Ruihao Yuan",
            "Lihui Zhang",
            "Yushi Luo",
            "Qiang Zhang",
            "Pan Ding",
            "Xiaodong Ren",
            "Weijie Xing",
            "Niu Gao",
            "Jishan Chen",
            "Chubo Zhang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02058",
          "title": "Misalignment of LLM-Generated Personas with Human Perceptions in Low-Resource Settings",
          "abstract": "Recent advances enable Large Language Models (LLMs) to generate AI personas, yet their lack of deep contextual, cultural, and emotional understanding poses a significant limitation. This study quantitatively compared human responses with those of eight LLM-generated social personas (e.g., Male, Female, Muslim, Political Supporter) within a low-resource environment like Bangladesh, using culturally specific questions. Results show human responses significantly outperform all LLMs in answering questions, and across all matrices of persona perception, with particularly large gaps in empathy and credibility. Furthermore, LLM-generated content exhibited a systematic bias along the lines of the ``Pollyanna Principle'', scoring measurably higher in positive sentiment ($\\Phi_{avg} = 5.99$ for LLMs vs. $5.60$ for Humans). These findings suggest that LLM personas do not accurately reflect the authentic experience of real people in resource-scarce environments. It is essential to validate LLM personas against real-world human data to ensure their alignment and reliability before deploying them in social science research.",
          "authors": [
            "Tabia Tanzin Prama",
            "Christopher M. Danforth",
            "Peter Sheridan Dodds"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02060",
          "title": "From 'What-is' to 'What-if' in Human-Factor Analysis: A Post-Occupancy Evaluation Case",
          "abstract": "Human-factor analysis typically employs correlation analysis and significance testing to identify relationships between variables. However, these descriptive ('what-is') methods, while effective for identifying associations, are often insufficient for answering causal ('what-if') questions. Their application in such contexts often overlooks confounding and colliding variables, potentially leading to bias and suboptimal or incorrect decisions. We advocate for explicitly distinguishing descriptive from interventional questions in human-factor analysis, and applying causal inference frameworks specifically to these problems to prevent methodological mismatches. This approach disentangles complex variable relationships and enables counterfactual reasoning. Using post-occupancy evaluation (POE) data from the Center for the Built Environment's (CBE) Occupant Survey as a demonstration case, we show how causal discovery reveals intervention hierarchies and directional relationships that traditional associational analysis misses. The systematic distinction between causally associated and independent variables, combined with intervention prioritization capabilities, offers broad applicability to complex human-centric systems, for example, in building science or ergonomics, where understanding intervention effects is critical for optimization and decision-making.",
          "authors": [
            "Xia Chen",
            "Ruiji Sun",
            "Philipp Geyer",
            "André Borrmann",
            "Stefano Schiavon"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02060",
          "title": "From 'What-is' to 'What-if' in Human-Factor Analysis: A Post-Occupancy Evaluation Case",
          "abstract": "Human-factor analysis typically employs correlation analysis and significance testing to identify relationships between variables. However, these descriptive ('what-is') methods, while effective for identifying associations, are often insufficient for answering causal ('what-if') questions. Their application in such contexts often overlooks confounding and colliding variables, potentially leading to bias and suboptimal or incorrect decisions. We advocate for explicitly distinguishing descriptive from interventional questions in human-factor analysis, and applying causal inference frameworks specifically to these problems to prevent methodological mismatches. This approach disentangles complex variable relationships and enables counterfactual reasoning. Using post-occupancy evaluation (POE) data from the Center for the Built Environment's (CBE) Occupant Survey as a demonstration case, we show how causal discovery reveals intervention hierarchies and directional relationships that traditional associational analysis misses. The systematic distinction between causally associated and independent variables, combined with intervention prioritization capabilities, offers broad applicability to complex human-centric systems, for example, in building science or ergonomics, where understanding intervention effects is critical for optimization and decision-making.",
          "authors": [
            "Xia Chen",
            "Ruiji Sun",
            "Philipp Geyer",
            "André Borrmann",
            "Stefano Schiavon"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02061",
          "title": "Ada-MoGE: Adaptive Mixture of Gaussian Expert Model for Time Series Forecasting",
          "abstract": "Multivariate time series forecasts are widely used, such as industrial, transportation and financial forecasts. However, the dominant frequencies in time series may shift with the evolving spectral distribution of the data. Traditional Mixture of Experts (MoE) models, which employ a fixed number of experts, struggle to adapt to these changes, resulting in frequency coverage imbalance issue. Specifically, too few experts can lead to the overlooking of critical information, while too many can introduce noise. To this end, we propose Ada-MoGE, an adaptive Gaussian Mixture of Experts model. Ada-MoGE integrates spectral intensity and frequency response to adaptively determine the number of experts, ensuring alignment with the input data's frequency distribution. This approach prevents both information loss due to an insufficient number of experts and noise contamination from an excess of experts. Additionally, to prevent noise introduction from direct band truncation, we employ Gaussian band-pass filtering to smoothly decompose the frequency domain features, further optimizing the feature representation. The experimental results show that our model achieves state-of-the-art performance on six public benchmarks with only 0.2 million parameters.",
          "authors": [
            "Zhenliang Ni",
            "Xiaowen Ma",
            "Zhenkai Wu",
            "Shuai Xiao",
            "Han Shu",
            "Xinghao Chen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02062",
          "title": "Superpixel Attack: Enhancing Black-box Adversarial Attack with Image-driven Division Areas",
          "abstract": "Deep learning models are used in safety-critical tasks such as automated driving and face recognition. However, small perturbations in the model input can significantly change the predictions. Adversarial attacks are used to identify small perturbations that can lead to misclassifications. More powerful black-box adversarial attacks are required to develop more effective defenses. A promising approach to black-box adversarial attacks is to repeat the process of extracting a specific image area and changing the perturbations added to it. Existing attacks adopt simple rectangles as the areas where perturbations are changed in a single iteration. We propose applying superpixels instead, which achieve a good balance between color variance and compactness. We also propose a new search method, versatile search, and a novel attack method, Superpixel Attack, which applies superpixels and performs versatile search. Superpixel Attack improves attack success rates by an average of 2.10% compared with existing attacks. Most models used in this study are robust against adversarial attacks, and this improvement is significant for black-box adversarial attacks. The code is avilable at this https URL .",
          "authors": [
            "Issa Oe",
            "Keiichiro Yamamura",
            "Hiroki Ishikura",
            "Ryo Hamahira",
            "Katsuki Fujisawa"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02064",
          "title": "Neural Networks as Physics-Consistent Surrogates: An \\textit{Explainable AI} Validation Framework for Learning Constitutive Relations",
          "abstract": "This paper presents a Physics-\\textit{Explainable AI} (XAI) framework to validate and interpret neural networks for the constitutive modeling of solid materials. The study bridges the gap between data-driven models and continuum mechanics by applying a suite of explainability methods to neural networks trained on three distinct material behaviors: hyperelasticity (\\textit{Mooney-Rivlin}), elastoplasticity (\\textit{Chaboche}), and viscoelasticity (\\textit{Fractional Zener}). First, high-fidelity surrogate models, including dense feed-forward networks, LSTMs, and GRUs, are trained on synthetically generated data to accurately capture complex material responses. The core of the work then employs XAI techniques to \"open the black box\" and confirm that the networks learn physically meaningful principles. For hyperelasticity, gradient-based attributions (\\textit{Grad Input} (GI)) successfully match the analytical tangent modulus, proving the network learned material stiffness. For elastoplasticity, \\textit{SHapley Additive exPlanations} (SHAP) and \\textit{Principal Component Analysis} (PCA) demonstrate the \\textit{Recurrent Neural Network} (RNN) internalizes path-dependent memory, with SHAP identifying \\textit{plastic strain} as the dominant feature governing the stress prediction. For viscoelasticity, latent-space and wavelet analyses of the \\textit{Gated Recurrent Unit. } GRU layers reveal a clear temporal hierarchy, with different layers encoding instantaneous elastic response, intermediate relaxation, and long-term fractional memory. Ultimately, the study demonstrates that the XAI framework can verify that the neural networks are not merely curve-fitting but are, in fact, learning the underlying physical mechanisms of stiffness, history-dependence, and temporal damping.",
          "authors": [
            "Chandana Pati",
            "S. M. Mallikarjunaiah"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02069",
          "title": "Large Language Model based Smart Contract Auditing with LLMBugScanner",
          "abstract": "This paper presents LLMBugScanner, a large language model (LLM) based framework for smart contract vulnerability detection using fine-tuning and ensemble learning. Smart contract auditing presents several challenges for LLMs: different pretrained models exhibit varying reasoning abilities, and no single model performs consistently well across all vulnerability types or contract structures. These limitations persist even after fine-tuning individual LLMs. To address these challenges, LLMBugScanner combines domain knowledge adaptation with ensemble reasoning to improve robustness and generalization. Through domain knowledge adaptation, we fine-tune LLMs on complementary datasets to capture both general code semantics and instruction-guided vulnerability reasoning, using parameter-efficient tuning to reduce computational cost. Through ensemble reasoning, we leverage the complementary strengths of multiple LLMs and apply a consensus-based conflict resolution strategy to produce more reliable vulnerability assessments. We conduct extensive experiments across multiple popular LLMs and compare LLMBugScanner with both pretrained and fine-tuned individual models. Results show that LLMBugScanner achieves consistent accuracy improvements and stronger generalization, demonstrating that it provides a principled, cost-effective, and extensible framework for smart contract auditing.",
          "authors": [
            "Yining Yuan",
            "Yifei Wang",
            "Yichang Xu",
            "Zachary Yahn",
            "Sihao Hu",
            "Ling Liu"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02070",
          "title": "DPWMixer: Dual-Path Wavelet Mixer for Long-Term Time Series Forecasting",
          "abstract": "Long-term time series forecasting (LTSF) is a critical task in computational intelligence. While Transformer-based models effectively capture long-range dependencies, they often suffer from quadratic complexity and overfitting due to data sparsity. Conversely, efficient linear models struggle to depict complex non-linear local dynamics. Furthermore, existing multi-scale frameworks typically rely on average pooling, which acts as a non-ideal low-pass filter, leading to spectral aliasing and the irreversible loss of high-frequency transients. In response, this paper proposes DPWMixer, a computationally efficient Dual-Path architecture. The framework is built upon a Lossless Haar Wavelet Pyramid that replaces traditional pooling, utilizing orthogonal decomposition to explicitly disentangle trends and local fluctuations without information loss. To process these components, we design a Dual-Path Trend Mixer that integrates a global linear mapping for macro-trend anchoring and a flexible patch-based MLP-Mixer for micro-dynamic evolution. Finally, An adaptive multi-scale fusion module then integrates predictions from diverse scales, weighted by channel stationarity to optimize synthesis. Extensive experiments on eight public benchmarks demonstrate that our method achieves a consistent improvement over state-of-the-art baselines. The code is available at this https URL .",
          "authors": [
            "Li Qianyang",
            "Zhang Xingjun",
            "Wang Shaoxun",
            "Wei Jia"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02072",
          "title": "QCD in Language Models: What do they really know about QCD?",
          "abstract": "This study presents an analysis of modern open-source large language models (LLMs) -- including Llama, Qwen, and Gemma -- to evaluate their encoded knowledge of Quantum Chromodynamics (QCD). Through reverse engineering of these models' representations, we uncover the naturally idiosyncratic patterns in how foundational QCD concepts are embedded within their parameter spaces. Our methodology combines targeted probing techniques and knowledge extraction protocols to assess the models' understanding of critical QCD principles like color confinement, asymptotic freedom, and the running coupling constant. This work provides a tool for utilizing LLMs as an assistant in physics research, while also highlighting current limitations in their representation of advanced quantum field theory concepts that future model development should address.",
          "authors": [
            "Antonin Sulc",
            "Patrick L.S. Connor"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02072",
          "title": "QCD in Language Models: What do they really know about QCD?",
          "abstract": "This study presents an analysis of modern open-source large language models (LLMs) -- including Llama, Qwen, and Gemma -- to evaluate their encoded knowledge of Quantum Chromodynamics (QCD). Through reverse engineering of these models' representations, we uncover the naturally idiosyncratic patterns in how foundational QCD concepts are embedded within their parameter spaces. Our methodology combines targeted probing techniques and knowledge extraction protocols to assess the models' understanding of critical QCD principles like color confinement, asymptotic freedom, and the running coupling constant. This work provides a tool for utilizing LLMs as an assistant in physics research, while also highlighting current limitations in their representation of advanced quantum field theory concepts that future model development should address.",
          "authors": [
            "Antonin Sulc",
            "Patrick L.S. Connor"
          ],
          "primary_category": "hep-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02073",
          "title": "HTG-GCL: Leveraging Hierarchical Topological Granularity from Cellular Complexes for Graph Contrastive Learning",
          "abstract": "Graph contrastive learning (GCL) aims to learn discriminative semantic invariance by contrasting different views of the same graph that share critical topological patterns. However, existing GCL approaches with structural augmentations often struggle to identify task-relevant topological structures, let alone adapt to the varying coarse-to-fine topological granularities required across different downstream tasks. To remedy this issue, we introduce Hierarchical Topological Granularity Graph Contrastive Learning (HTG-GCL), a novel framework that leverages transformations of the same graph to generate multi-scale ring-based cellular complexes, embodying the concept of topological granularity, thereby generating diverse topological views. Recognizing that a certain granularity may contain misleading semantics, we propose a multi-granularity decoupled contrast and apply a granularity-specific weighting mechanism based on uncertainty estimation. Comprehensive experiments on various benchmarks demonstrate the effectiveness of HTG-GCL, highlighting its superior performance in capturing meaningful graph representations through hierarchical topological information.",
          "authors": [
            "Qirui Ji",
            "Bin Qin",
            "Yifan Jin",
            "Yunze Zhao",
            "Chuxiong Sun",
            "Changwen Zheng",
            "Jianwen Cao",
            "Jiangmeng Li"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02074",
          "title": "Dialect Identification Using Resource-Efficient Fine-Tuning Approaches",
          "abstract": "Dialect Identification (DI) is a task to recognize different dialects within the same language from a speech signal. DI can help to improve the downstream speech related tasks even when speakers have a strong dialect. However, fine-tuning a speech model for tasks like DI is expensive in terms of computation cost and memory requirement. Recent studies have explored fine-tuning pre-trained speech models for tasks like DI using Parameter-Efficient Fine-Tuning (PEFT) methods, which offer parameter efficiency but limited improvement in memory efficiency and training speed. To address these challenges, we explore Memory-Efficient Fine-Tuning (MEFT) methods, originally proposed for language processing, and apply them to the general-purpose pre-trained speech model. We then comprehensively analyze the GPU memory usage and fine-tuning speed based on various MEFT methods. As a case study, we fine-tune the Whisper model to identify six Mandarin subdialects from the KeSpeech dataset, reducing GPU memory usage by up to 73.25% and accelerating training speed by a factor of 2.1, while maintaining accuracy comparable to vanilla fine-tuning and PEFT methods.",
          "authors": [
            "Zirui Lin",
            "Haris Gulzar",
            "Monnika Roslianna Busto",
            "Akiko Masaki",
            "Takeharu Eda",
            "Kazuhiro Nakadai"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02076",
          "title": "FDRMFL:Multi-modal Federated Feature Extraction Model Based on Information Maximization and Contrastive Learning",
          "abstract": "This study focuses on the feature extraction problem in multi-modal data regression. To address three core challenges in real-world scenarios: limited and non-IID data, effective extraction and fusion of multi-modal information, and susceptibility to catastrophic forgetting in model learning, a task-driven supervised multi-modal federated feature extraction method is proposed. The method integrates multi-modal information extraction and contrastive learning mechanisms, and can adapt to different neural network structures as the latent mapping functions for data of each modality. It supports each client to independently learn low-dimensional representations of multi-modal data, and can flexibly control the degree of retention of effective information about the response variable in the predictive variables within the low-dimensional features through parameter tuning. The multi-constraint learning framework constructed by the method guarantees regression accuracy using Mean Squared Error loss. Through the synergistic effect of mutual information preservation constraint, symmetric Kullback-Leibler divergence constraint, and inter-model contrastive constraint, it achieves the retention of task-related information, the extraction, fusion, and alignment of multi-modal features, and the mitigation of representation drift and catastrophic forgetting in non-IID scenarios, respectively. This ensures that the feature extraction process always centers on improving the performance of downstream regression tasks. Experimental results from simulations and real-world data analysis demonstrate that the proposed method achieves more significant performance improvement on downstream regression tasks compared with classical feature extraction techniques.",
          "authors": [
            "Haozhe Wu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02080",
          "title": "The 4/$δ$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee",
          "abstract": "The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($\\delta$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $\\delta > 0$, with an expected iteration count bounded by $\\mathbb{E}[n] \\leq 4/\\delta$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.",
          "authors": [
            "PIerre Dantas",
            "Lucas Cordeiro",
            "Youcheng Sun",
            "Waldir Junior"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02082",
          "title": "Deterministic Random Bit Generators Based on Ascon for Embedded Systems",
          "abstract": "As the Deterministic Random Bit Generator (DRBG) serves as a fundamental component in random number generation and cryptographic applications, its performance and security are particularly critical in resource-constrained embedded systems, where memory capacity and computational efficiency are limited. Establishing a high-performance and secure DRBG is therefore an important issue for embedded system design. Furthermore, the National Institute of Standards and Technology (NIST) established the Ascon lightweight cryptographic standard in August 2025, which is suitable for use in resource-limited embedded environments. Therefore, this study revises the DRBG standard and proposes three Ascon-driven constructions: the Ascon-Driven Hash-Based DRBG, the Ascon-Driven keyed-Hash Message Authentication Code (HMAC) DRBG, and the Ascon-Driven Counter-mode (CTR) DRBG. In the experiments, these methods are implemented on a Raspberry Pi platform. The experimental results demonstrate that the proposed approaches achieve higher computational efficiency and lower memory usage compared with existing DRBG implementations, making them suitable for deployment in embedded systems.",
          "authors": [
            "Abel C. H. Chen"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02088",
          "title": "Comparing Baseline and Day-1 Diffusion MRI Using Multimodal Deep Embeddings for Stroke Outcome Prediction",
          "abstract": "This study compares baseline (J0) and 24-hour (J1) diffusion magnetic resonance imaging (MRI) for predicting three-month functional outcomes after acute ischemic stroke (AIS). Seventy-four AIS patients with paired apparent diffusion coefficient (ADC) scans and clinical data were analyzed. Three-dimensional ResNet-50 embeddings were fused with structured clinical variables, reduced via principal component analysis (<=12 components), and classified using linear support vector machines with eight-fold stratified group cross-validation. J1 multimodal models achieved the highest predictive performance (AUC = 0.923 +/- 0.085), outperforming J0-based configurations (AUC <= 0.86). Incorporating lesion-volume features further improved model stability and interpretability. These findings demonstrate that early post-treatment diffusion MRI provides superior prognostic value to pre-treatment imaging and that combining MRI, clinical, and lesion-volume features produces a robust and interpretable framework for predicting three-month functional outcomes in AIS patients.",
          "authors": [
            "Sina Raeisadigh",
            "Myles Joshua Toledo Tan",
            "Henning Müller",
            "Abderrahmane Hedjoudje"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02088",
          "title": "Comparing Baseline and Day-1 Diffusion MRI Using Multimodal Deep Embeddings for Stroke Outcome Prediction",
          "abstract": "This study compares baseline (J0) and 24-hour (J1) diffusion magnetic resonance imaging (MRI) for predicting three-month functional outcomes after acute ischemic stroke (AIS). Seventy-four AIS patients with paired apparent diffusion coefficient (ADC) scans and clinical data were analyzed. Three-dimensional ResNet-50 embeddings were fused with structured clinical variables, reduced via principal component analysis (<=12 components), and classified using linear support vector machines with eight-fold stratified group cross-validation. J1 multimodal models achieved the highest predictive performance (AUC = 0.923 +/- 0.085), outperforming J0-based configurations (AUC <= 0.86). Incorporating lesion-volume features further improved model stability and interpretability. These findings demonstrate that early post-treatment diffusion MRI provides superior prognostic value to pre-treatment imaging and that combining MRI, clinical, and lesion-volume features produces a robust and interpretable framework for predicting three-month functional outcomes in AIS patients.",
          "authors": [
            "Sina Raeisadigh",
            "Myles Joshua Toledo Tan",
            "Henning Müller",
            "Abderrahmane Hedjoudje"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02089",
          "title": "A Compact, Data-Logging Breath-Gas Analyzer",
          "abstract": "Respiratory ailments are increasing globally at an alarming rate and are currently one of the leading factors of death and infirmity worldwide. Among respiratory diseases, those linked to poor air quality and pollutants are increasing at a proportionally higher rate than those linked to viral or other factors. Diagnosing disorders of the respiratory system is often performed initially by routine physical examinations and questionnaires. Once most patients have symptoms that are severe enough to warrant clinical testing, the ailment could have already caused pulmonary damage. Clinical diagnosis involves the use of cumbersome, expensive equipment that measures different parameters separately, e.g., Capnography (CO2) and spirometry (bidirectional tidal mass flow). These disparate sets of data must then be interpreted collectively by a qualified medical practitioner. This paper details the design of a portable, inexpensive, mixed-signal data-logging system that measures a chosen set of parameters in exhaled breath from humans or animals. The data is a comprehensive set of pertinent gases and mass flow that when looked at simultaneously, gives a synergistic view of these interrelated breathing biomarkers and thus the state of the respiratory system as a whole. A mask-mounted, tabletop, and handheld version was developed for different applications. The system, when fully developed, would enable a new set of clinical vitals that only require a patient to breathe through a single, small device for a few moments. This new set of clinical vitals could enable the early diagnosis of many respiratory ailments, something that could have a large positive impact on disease prognosis and quality of life.",
          "authors": [
            "Shelby Lacouture",
            "Mitchell Kelley",
            "Noah Plues",
            "Laszlo Hunyadi",
            "Emily Sundman",
            "Annette Sobel",
            "Robert V. Duncan"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02090",
          "title": "Scalable, Cloud-Based Simulations of Blood Flow and Targeted Drug Delivery in Retinal Capillaries",
          "abstract": "We investigate the capabilities of cloud computing for large-scale,tightly-coupled simulations of biological fluids in complex geometries, traditionally performed in supercomputing centers. We demonstrate scalable and efficient simulations in the public cloud. We perform meso-scale simulations of blood flow in image-reconstructed capillaries, and examine targeted drug delivery by artificial bacterial flagella (ABFs). The simulations deploy dissipative particle dynamics (DPD) with two software frameworks, Mirheo (developed by our team) and LAMMPS. Mirheo exhibits remarkable weak scalability for up to 512 GPUs. Similarly, LAMMPS demonstrated excellent weak scalability for pure solvent as well as for blood suspensions and ABFs in reconstructed retinal capillaries. In particular, LAMMPS maintained weak scaling above 90% on the cloud for up to 2,000 cores. Our findings demonstrate that cloud computing can support tightly coupled, large-scale scientific simulations with competitive performance.",
          "authors": [
            "Lucas Amoudruz",
            "Sergey Litvinov",
            "Riccardo Murri",
            "Volker Eyrich",
            "Jens Zudrop",
            "Costas Bekas",
            "Petros Koumoutsakos"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02090",
          "title": "Scalable, Cloud-Based Simulations of Blood Flow and Targeted Drug Delivery in Retinal Capillaries",
          "abstract": "We investigate the capabilities of cloud computing for large-scale,tightly-coupled simulations of biological fluids in complex geometries, traditionally performed in supercomputing centers. We demonstrate scalable and efficient simulations in the public cloud. We perform meso-scale simulations of blood flow in image-reconstructed capillaries, and examine targeted drug delivery by artificial bacterial flagella (ABFs). The simulations deploy dissipative particle dynamics (DPD) with two software frameworks, Mirheo (developed by our team) and LAMMPS. Mirheo exhibits remarkable weak scalability for up to 512 GPUs. Similarly, LAMMPS demonstrated excellent weak scalability for pure solvent as well as for blood suspensions and ABFs in reconstructed retinal capillaries. In particular, LAMMPS maintained weak scaling above 90% on the cloud for up to 2,000 cores. Our findings demonstrate that cloud computing can support tightly coupled, large-scale scientific simulations with competitive performance.",
          "authors": [
            "Lucas Amoudruz",
            "Sergey Litvinov",
            "Riccardo Murri",
            "Volker Eyrich",
            "Jens Zudrop",
            "Costas Bekas",
            "Petros Koumoutsakos"
          ],
          "primary_category": "physics.flu-dyn",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02091",
          "title": "TT-Stack: A Transformer-Based Tiered-Stacking Ensemble Framework with Meta-Learning for Automated Breast Cancer Detection in Mammography",
          "abstract": "Breast cancer continues to be the second most common cause of cancer-related deaths around the world, with early detection being important to improve survival rates for patients. Traditional computer-aided diagnosis systems have limitations in their ability to represent features and generalize to the range of mammographic images. We present a new two-level Stack of Transformers (TT-Stack) ensemble framework based on using heterogeneous lightweight vision transformer architectures to automatically identify breast cancer in mammograms. Specifically, we integrate seven state-of-the-art vision transformers: RepViT, DaViT, EfficientViT, MobileViT, FasterViT, MViT, and PVT v2 while also designing a two-tier meta-learning approach for the ensemble by simply taking the logits from the base model and applying logistic regression for binary classification (Cancer vs. Non-Cancer). Each of the transformer backbone models was developed to process single-channel grayscale mammograms while still taking advantage of transfer learning from pre-training on ImageNet so that they would offer a parameter-efficient approach that may reasonably be applied in clinical practice with minimal variance. The training process included stratified 80/20 splits when necessary, class-balanced upsampling, early stopping, and an adaptive learning rate schedule on the public Mammogram Mastery dataset. In separate evaluations here, it was determined that EfficientViT and PVT-v2 were the top per-forming models achieving 99.33% validation, 97.96% F1-score, and perfect 1.000:0 ROC-AUC with only small train/validation gaps. Finally, the TT-Stack ensemble model by the end of the evaluation reached 99.33% accuracy with 100% precision, 96% recall, 97.96% F1-score and a 99.97% ROC-AUC, and demonstrated robustness in performance due to the diversity of the architecture.",
          "authors": [
            "Showkat Osman",
            "Md. Tajwar Munim Turzo",
            "Maher Ali Rusho",
            "Md. Makid Haider",
            "Sazzadul Islam Sajin",
            "Ayatullah Hasnat Behesti",
            "Ahmed Faizul Haque Dhrubo",
            "Md. Khurshid Jahan",
            "Mohammad Abdul Qayum"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02092",
          "title": "Opening the Black Box: Nowcasting Singapore's GDP Growth and its Explainability",
          "abstract": "Timely assessment of current conditions is essential especially for small, open economies such as Singapore, where external shocks transmit rapidly to domestic activity. We develop a real-time nowcasting framework for quarterly GDP growth using a high-dimensional panel of approximately 70 indicators, encompassing economic and financial indicators over 1990Q1-2023Q2. The analysis covers penalized regressions, dimensionality-reduction methods, ensemble learning algorithms, and neural architectures, benchmarked against a Random Walk, an AR(3), and a Dynamic Factor Model. The pipeline preserves temporal ordering through an expanding-window walk-forward design with Bayesian hyperparameter optimization, and uses moving block-bootstrap procedures both to construct prediction intervals and to obtain confidence bands for feature-importance measures. It adopts model-specific and XAI-based explainability tools. A Model Confidence Set procedure identifies statistically superior learners, which are then combined through simple, weighted, and exponentially weighted schemes; the resulting time-varying weights provide an interpretable representation of model contributions. Predictive ability is assessed via Giacomini-White tests. Empirical results show that penalized regressions, dimensionality-reduction models, and GRU networks consistently outperform all benchmarks, with RMSFE reductions of roughly 40-60%; aggregation delivers further gains. Feature-attribution methods highlight industrial production, external trade, and labor-market indicators as dominant drivers of Singapore's short-run growth dynamics.",
          "authors": [
            "Luca Attolico"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02092",
          "title": "Opening the Black Box: Nowcasting Singapore's GDP Growth and its Explainability",
          "abstract": "Timely assessment of current conditions is essential especially for small, open economies such as Singapore, where external shocks transmit rapidly to domestic activity. We develop a real-time nowcasting framework for quarterly GDP growth using a high-dimensional panel of approximately 70 indicators, encompassing economic and financial indicators over 1990Q1-2023Q2. The analysis covers penalized regressions, dimensionality-reduction methods, ensemble learning algorithms, and neural architectures, benchmarked against a Random Walk, an AR(3), and a Dynamic Factor Model. The pipeline preserves temporal ordering through an expanding-window walk-forward design with Bayesian hyperparameter optimization, and uses moving block-bootstrap procedures both to construct prediction intervals and to obtain confidence bands for feature-importance measures. It adopts model-specific and XAI-based explainability tools. A Model Confidence Set procedure identifies statistically superior learners, which are then combined through simple, weighted, and exponentially weighted schemes; the resulting time-varying weights provide an interpretable representation of model contributions. Predictive ability is assessed via Giacomini-White tests. Empirical results show that penalized regressions, dimensionality-reduction models, and GRU networks consistently outperform all benchmarks, with RMSFE reductions of roughly 40-60%; aggregation delivers further gains. Feature-attribution methods highlight industrial production, external trade, and labor-market indicators as dominant drivers of Singapore's short-run growth dynamics.",
          "authors": [
            "Luca Attolico"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02092",
          "title": "Opening the Black Box: Nowcasting Singapore's GDP Growth and its Explainability",
          "abstract": "Timely assessment of current conditions is essential especially for small, open economies such as Singapore, where external shocks transmit rapidly to domestic activity. We develop a real-time nowcasting framework for quarterly GDP growth using a high-dimensional panel of approximately 70 indicators, encompassing economic and financial indicators over 1990Q1-2023Q2. The analysis covers penalized regressions, dimensionality-reduction methods, ensemble learning algorithms, and neural architectures, benchmarked against a Random Walk, an AR(3), and a Dynamic Factor Model. The pipeline preserves temporal ordering through an expanding-window walk-forward design with Bayesian hyperparameter optimization, and uses moving block-bootstrap procedures both to construct prediction intervals and to obtain confidence bands for feature-importance measures. It adopts model-specific and XAI-based explainability tools. A Model Confidence Set procedure identifies statistically superior learners, which are then combined through simple, weighted, and exponentially weighted schemes; the resulting time-varying weights provide an interpretable representation of model contributions. Predictive ability is assessed via Giacomini-White tests. Empirical results show that penalized regressions, dimensionality-reduction models, and GRU networks consistently outperform all benchmarks, with RMSFE reductions of roughly 40-60%; aggregation delivers further gains. Feature-attribution methods highlight industrial production, external trade, and labor-market indicators as dominant drivers of Singapore's short-run growth dynamics.",
          "authors": [
            "Luca Attolico"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02130",
          "title": "Cross-View Topology-Aware Graph Representation Learning",
          "abstract": "Graph classification has gained significant attention due to its applications in chemistry, social networks, and bioinformatics. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they often overlook global topological features that are critical for robust representation learning. In this work, we propose GraphTCL, a dual-view contrastive learning framework that integrates structural embeddings from GNNs with topological embeddings derived from persistent homology. By aligning these complementary views through a cross-view contrastive loss, our method enhances representation quality and improves classification performance. Extensive experiments on benchmark datasets, including TU and OGB molecular graphs, demonstrate that GraphTCL consistently outperforms state-of-the-art baselines. This study highlights the importance of topology-aware contrastive learning for advancing graph representation methods.",
          "authors": [
            "Ahmet Sami Korkmaz",
            "Selim Coskunuzer",
            "Md Joshem Uddin"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02134",
          "title": "How Market Volatility Shapes Algorithmic Collusion: A Comparative Analysis of Learning-Based Pricing Algorithms",
          "abstract": "Autonomous pricing algorithms are increasingly influencing competition in digital markets; however, their behavior under realistic demand conditions remains largely unexamined. This paper offers a thorough analysis of four pricing algorithms -- Q-Learning, PSO, Double DQN, and DDPG -- across three classic duopoly models (Logit, Hotelling, Linear) and under various demand-shock regimes created by auto-regressive processes. By utilizing profit- and price-based collusion indices, we investigate how the interactions among algorithms, market structure, and stochastic demand collaboratively influence competitive outcomes. Our findings reveal that reinforcement-learning algorithms often sustain supra-competitive prices under stable demand, with DDPG demonstrating the most pronounced collusive tendencies. Demand shocks produce notably varied effects: Logit markets suffer significant performance declines, Hotelling markets remain stable, and Linear markets experience shock-induced profit inflation. Despite marked changes in absolute performance, the relative rankings of the algorithms are consistent across different environments. These results underscore the critical importance of market structure and demand uncertainty in shaping algorithmic competition, while also contributing to the evolving policy discussions surrounding autonomous pricing behavior.",
          "authors": [
            "Aheer Sravon",
            "Md. Ibrahim",
            "Devdyuti Mazumder",
            "Ridwan Al Aziz"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02141",
          "title": "Feature Selection Empowered BERT for Detection of Hate Speech with Vocabulary Augmentation",
          "abstract": "Abusive speech on social media poses a persistent and evolving challenge, driven by the continuous emergence of novel slang and obfuscated terms designed to circumvent detection systems. In this work, we present a data efficient strategy for fine tuning BERT on hate speech classification by significantly reducing training set size without compromising performance. Our approach employs a TF IDF-based sample selection mechanism to retain only the most informative 75 percent of examples, thereby minimizing training overhead. To address the limitations of BERT's native vocabulary in capturing evolving hate speech terminology, we augment the tokenizer with domain-specific slang and lexical variants commonly found in abusive contexts. Experimental results on a widely used hate speech dataset demonstrate that our method achieves competitive performance while improving computational efficiency, highlighting its potential for scalable and adaptive abusive content moderation.",
          "authors": [
            "Pritish N. Desai",
            "Tanay Kewalramani",
            "Srimanta Mandal"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02143",
          "title": "CoatFusion: Controllable Material Coating in Images",
          "abstract": "We introduce Material Coating, a novel image editing task that simulates applying a thin material layer onto an object while preserving its underlying coarse and fine geometry. Material coating is fundamentally different from existing \"material transfer\" methods, which are designed to replace an object's intrinsic material, often overwriting fine details. To address this new task, we construct a large-scale synthetic dataset (110K images) of 3D objects with varied, physically-based coatings, named DataCoat110K. We then propose CoatFusion, a novel architecture that enables this task by conditioning a diffusion model on both a 2D albedo texture and granular, PBR-style parametric controls, including roughness, metalness, transmission, and a key thickness parameter. Experiments and user studies show CoatFusion produces realistic, controllable coatings and significantly outperforms existing material editing and transfer methods on this new task.",
          "authors": [
            "Sagie Levy",
            "Elad Aharoni",
            "Matan Levy",
            "Ariel Shamir",
            "Dani Lischinski"
          ],
          "primary_category": "cs.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02152",
          "title": "Context-Enriched Contrastive Loss: Enhancing Presentation of Inherent Sample Connections in Contrastive Learning Framework",
          "abstract": "Contrastive learning has gained popularity and pushes state-of-the-art performance across numerous large-scale benchmarks. In contrastive learning, the contrastive loss function plays a pivotal role in discerning similarities between samples through techniques such as rotation or cropping. However, this learning mechanism can also introduce information distortion from the augmented samples. This is because the trained model may develop a significant overreliance on information from samples with identical labels, while concurrently neglecting positive pairs that originate from the same initial image, especially in expansive datasets. This paper proposes a context-enriched contrastive loss function that concurrently improves learning effectiveness and addresses the information distortion by encompassing two convergence targets. The first component, which is notably sensitive to label contrast, differentiates between features of identical and distinct classes which boosts the contrastive training efficiency. Meanwhile, the second component draws closer the augmented samples from the same source image and distances all other samples. We evaluate the proposed approach on image classification tasks, which are among the most widely accepted 8 recognition large-scale benchmark datasets: CIFAR10, CIFAR100, Caltech-101, Caltech-256, ImageNet, BiasedMNIST, UTKFace, and CelebA datasets. The experimental results demonstrate that the proposed method achieves improvements over 16 state-of-the-art contrastive learning methods in terms of both generalization performance and learning convergence speed. Interestingly, our technique stands out in addressing systematic distortion tasks. It demonstrates a 22.9% improvement compared to original contrastive loss functions in the downstream BiasedMNIST dataset, highlighting its promise for more efficient and equitable downstream training.",
          "authors": [
            "Haojin Deng",
            "Yimin Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02157",
          "title": "Factor(T,U): Factored Cognition Strengthens Monitoring of Untrusted AI",
          "abstract": "The field of AI Control seeks to develop robust control protocols, deployment safeguards for untrusted AI which may be intentionally subversive. However, existing protocols that rely on weaker monitors to detect unsafe behavior often fail on complex tasks beyond the monitor's comprehension. We develop control protocols based on factored cognition, in which a trusted model decomposes a task, an untrusted model solves each resultant child task in isolation, and the results are reassembled into a full solution. These protocols may improve safety by several means, such as by simplifying the context for monitors, or by obscuring vulnerabilities in the environment. We implement our protocols in the APPS coding setting and red team them against backdoor attempts from an adversarial GPT-4.1 Nano. We find that: (i) Adding factored cognition to a trusted monitoring protocol can boost safety from 41% to 63%; (ii) Safety improves because monitor performance improves; (iii) Factored cognition makes it no harder for capable LLMs to write backdoors in APPS. While our protocols show low usefulness in APPS, they hold promise for more complex tasks.",
          "authors": [
            "Aaron Sandoval",
            "Cody Rushing"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02160",
          "title": "Are we misdiagnosing ensemble forecast reliability? On the insufficiency of Spread-Error and rank-based reliability metrics",
          "abstract": "It has been documented that Spread-Error equality and a flat rank histogram are necessary but insufficient for demonstrating ensemble forecast reliability. Nevertheless, these metrics are heavily relied upon, both in the literature and at operational numerical weather prediction centers. In this study, we demonstrate theoretically why the Spread-Error relationship is necessary but insufficient for diagnosing reliability up to second order, even when mean bias is absent or accounted for. Assuming joint normality between ensemble members and the reference truth, we further show with idealized experiments that the same covariance structure responsible for this insufficiency also produces false diagnoses of reliability with the rank histogram and the reliability component of the continuous rank probability score. Under this structure and when the ensemble mean is meaningfully different from climatology, the truth lies among the least (most) extreme members when climatological variance is excessive (deficient) in each member. Importantly, this behavior is also shown to be plausible in operational ensemble weather forecasts. Combining these results with calibration principles from statistical postprocessing leads us to conclude that both perfect dispersion and underdispersion are ill-defined. When diagnostics are misinterpreted as indicating the latter, improper tuning can lead to further deterioration of forecast quality, even while improving Spread-Error and rank histogram behavior. To address these issues, we propose a new reliability diagnostic based on three easily computed statistics, motivated by the structure of the joint distribution of ensemble members and the reference truth up to second order. The diagnostic separates contributions to unreliability originating from climatology and predictability, enabling a more precise and robust characterization of ensemble behavior.",
          "authors": [
            "Arlan Dirkson",
            "Mark Buehner"
          ],
          "primary_category": "physics.ao-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02161",
          "title": "FineGRAIN: Evaluating Failure Modes of Text-to-Image Models with Vision Language Model Judges",
          "abstract": "Text-to-image (T2I) models are capable of generating visually impressive images, yet they often fail to accurately capture specific attributes in user prompts, such as the correct number of objects with the specified colors. The diversity of such errors underscores the need for a hierarchical evaluation framework that can compare prompt adherence abilities of different image generation models. Simultaneously, benchmarks of vision language models (VLMs) have not kept pace with the complexity of scenes that VLMs are used to annotate. In this work, we propose a structured methodology for jointly evaluating T2I models and VLMs by testing whether VLMs can identify 27 specific failure modes in the images generated by T2I models conditioned on challenging prompts. Our second contribution is a dataset of prompts and images generated by 5 T2I models (Flux, SD3-Medium, SD3-Large, SD3.5-Medium, SD3.5-Large) and the corresponding annotations from VLMs (Molmo, InternVL3, Pixtral) annotated by an LLM (Llama3) to test whether VLMs correctly identify the failure mode in a generated image. By analyzing failure modes on a curated set of prompts, we reveal systematic errors in attribute fidelity and object representation. Our findings suggest that current metrics are insufficient to capture these nuanced errors, highlighting the importance of targeted benchmarks for advancing generative model reliability and interpretability.",
          "authors": [
            "Kevin David Hayes",
            "Micah Goldblum",
            "Vikash Sehwag",
            "Gowthami Somepalli",
            "Ashwinee Panda",
            "Tom Goldstein"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02162",
          "title": "Mapping of Lesion Images to Somatic Mutations",
          "abstract": "Medical imaging is a critical initial tool used by clinicians to determine a patient's cancer diagnosis, allowing for faster intervention and more reliable patient prognosis. At subsequent stages of patient diagnosis, genetic information is extracted to help select specific patient treatment options. As the efficacy of cancer treatment often relies on early diagnosis and treatment, we build a deep latent variable model to determine patients' somatic mutation profiles based on their corresponding medical images. We first introduce a point cloud representation of lesions images to allow for invariance to the imaging modality. We then propose, LLOST, a model with dual variational autoencoders coupled together by a separate shared latent space that unifies features from the lesion point clouds and counts of distinct somatic mutations. Therefore our model consists of three latent space, each of which is learned with a conditional normalizing flow prior to account for the diverse distributions of each domain. We conduct qualitative and quantitative experiments on de-identified medical images from The Cancer Imaging Archive and the corresponding somatic mutations from the Pan Cancer dataset of The Cancer Genomic Archive. We show the model's predictive performance on the counts of specific mutations as well as it's ability to accurately predict the occurrence of mutations. In particular, shared patterns between the imaging and somatic mutation domain that reflect cancer type. We conclude with a remark on how to improve the model and possible future avenues of research to include other genetic domains.",
          "authors": [
            "Rahul Mehta"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02162",
          "title": "Mapping of Lesion Images to Somatic Mutations",
          "abstract": "Medical imaging is a critical initial tool used by clinicians to determine a patient's cancer diagnosis, allowing for faster intervention and more reliable patient prognosis. At subsequent stages of patient diagnosis, genetic information is extracted to help select specific patient treatment options. As the efficacy of cancer treatment often relies on early diagnosis and treatment, we build a deep latent variable model to determine patients' somatic mutation profiles based on their corresponding medical images. We first introduce a point cloud representation of lesions images to allow for invariance to the imaging modality. We then propose, LLOST, a model with dual variational autoencoders coupled together by a separate shared latent space that unifies features from the lesion point clouds and counts of distinct somatic mutations. Therefore our model consists of three latent space, each of which is learned with a conditional normalizing flow prior to account for the diverse distributions of each domain. We conduct qualitative and quantitative experiments on de-identified medical images from The Cancer Imaging Archive and the corresponding somatic mutations from the Pan Cancer dataset of The Cancer Genomic Archive. We show the model's predictive performance on the counts of specific mutations as well as it's ability to accurately predict the occurrence of mutations. In particular, shared patterns between the imaging and somatic mutation domain that reflect cancer type. We conclude with a remark on how to improve the model and possible future avenues of research to include other genetic domains.",
          "authors": [
            "Rahul Mehta"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02166",
          "title": "The Three-Dimensional Decomposition of Volatility Memory",
          "abstract": "This paper develops a three-dimensional decomposition of volatility memory into orthogonal components of level, shape, and tempo. The framework unifies regime-switching, fractional-integration, and business-time approaches within a single canonical representation that identifies how each dimension governs persistence strength, long-memory form, and temporal speed. We establish conditions for existence, uniqueness, and ergodicity of this decomposition and show that all GARCH-type processes arise as special cases. Empirically, applications to SPY and EURUSD (2005--2024) reveal that volatility memory is state-dependent: regime and tempo gates dominate in equities, while fractional-memory gates prevail in foreign exchange. The unified tri-gate model jointly captures these effects. By formalizing volatility dynamics through a level--shape--tempo structure, the paper provides a coherent link between information flow, market activity, and the evolving memory of financial volatility.",
          "authors": [
            "Ziyao Wang",
            "A. Alexandre Trindade",
            "Svetlozar T. Rachev"
          ],
          "primary_category": "q-fin.MF",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02170",
          "title": "Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code",
          "abstract": "Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present \\textsc{Flowchart2Mermaid}, a lightweight web system that converts flowchart images into editable this http URL code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.",
          "authors": [
            "Pritam Deka",
            "Barry Devereux"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02172",
          "title": "SplatSuRe: Selective Super-Resolution for Multi-view Consistent 3D Gaussian Splatting",
          "abstract": "3D Gaussian Splatting (3DGS) enables high-quality novel view synthesis, motivating interest in generating higher-resolution renders than those available during training. A natural strategy is to apply super-resolution (SR) to low-resolution (LR) input views, but independently enhancing each image introduces multi-view inconsistencies, leading to blurry renders. Prior methods attempt to mitigate these inconsistencies through learned neural components, temporally consistent video priors, or joint optimization on LR and SR views, but all uniformly apply SR across every image. In contrast, our key insight is that close-up LR views may contain high-frequency information for regions also captured in more distant views, and that we can use the camera pose relative to scene geometry to inform where to add SR content. Building from this insight, we propose SplatSuRe, a method that selectively applies SR content only in undersampled regions lacking high-frequency supervision, yielding sharper and more consistent results. Across Tanks & Temples, Deep Blending and Mip-NeRF 360, our approach surpasses baselines in both fidelity and perceptual quality. Notably, our gains are most significant in localized foreground regions where higher detail is desired.",
          "authors": [
            "Pranav Asthana",
            "Alex Hanson",
            "Allen Tu",
            "Tom Goldstein",
            "Matthias Zwicker",
            "Amitabh Varshney"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02175",
          "title": "Sampling on Metric Graphs",
          "abstract": "Metric graphs are structures obtained by associating edges in a standard graph with segments of the real line and gluing these segments at the vertices of the graph. The resulting structure has a natural metric that allows for the study of differential operators and stochastic processes on the graph. Brownian motions in these domains have been extensively studied theoretically using their generators. However, less work has been done on practical algorithms for simulating these processes. We introduce the first algorithm for simulating Brownian motions on metric graphs through a timestep splitting Euler-Maruyama-based discretization of their corresponding stochastic differential equation. By applying this scheme to Langevin diffusions on metric graphs, we also obtain the first algorithm for sampling on metric graphs. We provide theoretical guarantees on the number of timestep splittings required for the algorithm to converge to the underlying stochastic process. We also show that the exit probabilities of the simulated particle converge to the vertex-edge jump probabilities of the underlying stochastic differential equation as the timestep goes to zero. Finally, since this method is highly parallelizable, we provide fast, memory-aware implementations of our algorithm in the form of custom CUDA kernels that are up to ~8000x faster than a GPU implementation using PyTorch on simple star metric graphs. Beyond simple star graphs, we benchmark our algorithm on a real cortical vascular network extracted from a DuMuX tissue-perfusion model for tracer transport. Our algorithm is able to run stable simulations with timesteps significantly larger than the stable limit of the finite volume method used in DuMuX while also achieving speedups of up to ~1500x.",
          "authors": [
            "Rajat Vadiraj Dwaraknath",
            "Lexing Ying"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02175",
          "title": "Sampling on Metric Graphs",
          "abstract": "Metric graphs are structures obtained by associating edges in a standard graph with segments of the real line and gluing these segments at the vertices of the graph. The resulting structure has a natural metric that allows for the study of differential operators and stochastic processes on the graph. Brownian motions in these domains have been extensively studied theoretically using their generators. However, less work has been done on practical algorithms for simulating these processes. We introduce the first algorithm for simulating Brownian motions on metric graphs through a timestep splitting Euler-Maruyama-based discretization of their corresponding stochastic differential equation. By applying this scheme to Langevin diffusions on metric graphs, we also obtain the first algorithm for sampling on metric graphs. We provide theoretical guarantees on the number of timestep splittings required for the algorithm to converge to the underlying stochastic process. We also show that the exit probabilities of the simulated particle converge to the vertex-edge jump probabilities of the underlying stochastic differential equation as the timestep goes to zero. Finally, since this method is highly parallelizable, we provide fast, memory-aware implementations of our algorithm in the form of custom CUDA kernels that are up to ~8000x faster than a GPU implementation using PyTorch on simple star metric graphs. Beyond simple star graphs, we benchmark our algorithm on a real cortical vascular network extracted from a DuMuX tissue-perfusion model for tracer transport. Our algorithm is able to run stable simulations with timesteps significantly larger than the stable limit of the finite volume method used in DuMuX while also achieving speedups of up to ~1500x.",
          "authors": [
            "Rajat Vadiraj Dwaraknath",
            "Lexing Ying"
          ],
          "primary_category": "math.NA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02178",
          "title": "Tolerance Intervals Using Dirichlet Processes",
          "abstract": "In nonclinical pharmaceutical development, tolerance intervals are critical in ensuring product and process quality. They are statistical intervals designed to contain a specified proportion of the population with a given confidence level. Parametric and non-parametric methods have been developed to obtain tolerance intervals. The former work with small samples but can be affected by distribution misspecification. The latter offer larger flexibility but require large sample sizes. As an alternative, we propose Dirichlet process-based Bayesian nonparametric tolerance intervals to overcome the limitations. We develop a computationally efficient tolerance interval construction algorithm based on the analytically tractable quantile process of the Dirichlet process. Simulation studies show that our new approach is very robust to distributional assumptions and performs as efficiently as existing tolerance interval methods. To illustrate how the model works in practice, we apply our method to the tolerance interval estimation for potency data.",
          "authors": [
            "Seokjun Choi",
            "Tony Pourmohamad",
            "Bruno Sansó"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02179",
          "title": "Young Children's Anthropomorphism of AI Chatbots and the Role of Parent Co-Presence",
          "abstract": "Artificial Intelligence (AI) chatbots powered by a large language model (LLM) are entering young children's learning and play, yet little is known about how young children construe these agents or how such construals relate to engagement. We examined anthropomorphism of a social AI chatbot during collaborative storytelling and asked how children's attributions related to their behavior and prefrontal activation. Children at ages 5-6 (N = 23) completed three storytelling sessions: interacting with (1) an AI chatbot only, (2) a parent only, and (3) the AI and a parent together. After the sessions, children completed an interview assessing anthropomorphism toward both the AI chatbot and the parent. Behavioral engagement was indexed by the conversational turn count (CTC) ratio, and concurrent fNIRS measured oxygenated hemoglobin in bilateral vmPFC and dmPFC regions. Children reported higher anthropomorphism for parents than for the AI chatbot overall, although AI ratings were relatively high for perceptive abilities and epistemic states. Anthropomorphism was not associated with CTC. In the right dmPFC, higher perceptive scores were associated with greater activation during the AI-only condition and with lower activation during the AI+Parent condition. Exploratory analyses indicated that higher dmPFC activation during the AI-only condition correlated with higher end-of-session \"scared\" mood ratings. Findings suggest that stronger perceptive anthropomorphism can be associated with greater brain activation related to interpreting the AI's mental states, whereas parent co-presence may help some children interpret and regulate novel AI interactions. These results may have design implications for encouraging parent-AI co-use in early childhood.",
          "authors": [
            "Pilyoung Kim",
            "Jenna H. Chin",
            "Yun Xie",
            "Nolan Brady",
            "Tom Yeh",
            "Sujin Yang"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02180",
          "title": "CLEF: Clinically-Guided Contrastive Learning for Electrocardiogram Foundation Models",
          "abstract": "The electrocardiogram (ECG) is a key diagnostic tool in cardiovascular health. Single-lead ECG recording is integrated into both clinical-grade and consumer wearables. While self-supervised pretraining of foundation models on unlabeled ECGs improves diagnostic performance, existing approaches do not incorporate domain knowledge from clinical metadata. We introduce a novel contrastive learning approach that utilizes an established clinical risk score to adaptively weight negative pairs: clinically-guided contrastive learning. It aligns the similarities of ECG embeddings with clinically meaningful differences between subjects, with an explicit mechanism to handle missing metadata. On 12-lead ECGs from 161K patients in the MIMIC-IV dataset, we pretrain single-lead ECG foundation models at three scales, collectively called CLEF, using only routinely collected metadata without requiring per-sample ECG annotations. We evaluate CLEF on 18 clinical classification and regression tasks across 7 held-out datasets, and benchmark against 5 foundation model baselines and 3 self-supervised algorithms. When pretrained on 12-lead ECG data and tested on lead-I data, CLEF outperforms self-supervised foundation model baselines: the medium-sized CLEF achieves average AUROC improvements of at least 2.6% in classification and average reductions in MAEs of at least 3.2% in regression. Comparing with existing self-supervised learning algorithms, CLEF improves the average AUROC by at least 1.8%. Moreover, when pretrained only on lead-I data for classification tasks, CLEF performs comparably to the state-of-the-art ECGFounder, which was trained in a supervised manner. Overall, CLEF enables more accurate and scalable single-lead ECG analysis, advancing remote health monitoring. Code and pretrained CLEF models are available at: this http URL .",
          "authors": [
            "Yuxuan Shu",
            "Peter H. Charlton",
            "Fahim Kawsar",
            "Jussi Hernesniemi",
            "Mohammad Malekzadeh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02182",
          "title": "Efficient and Intuitive Two-Phase Validation Across Multiple Models via Principal Components",
          "abstract": "Two-phase sampling offers a cost-effective way to validate error-prone measurements in observational databases or randomized trials. Inexpensive or easy-to-obtain information is collected for the entire study in Phase I. Then, a subset of patients undergoes cost-intensive validation to collect more accurate data in Phase II. Critically, any Phase I variables can be used to strategically select the Phase II subset, often enriched for a particular model of interest. However, when balancing primary and secondary analyses in the same study, competing models and priorities can result in poorly defined objectives for the most informative Phase II sampling criterion. We propose an intuitive, easy-to-use solution that balances and prioritizes explaining the largest amount of variability across all models of interest. Using principal components to succinctly summarize the inherent variability of the error-prone covariates for all models. Then, we sample patients with the most \"extreme\" principal components (i.e., the smallest or largest values) for validation. Through simulations and an application to data from the National Health and Nutrition Examination Survey (NHANES), we show that extreme tail sampling on the first principal component offers simultaneous efficiency gains across multiple models of interest relative to sampling for one specific model. Our proposed sampling strategy is implemented in the open-source R package, auditDesignR.",
          "authors": [
            "Sarah C. Lotspeich",
            "Cole Manschot"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02185",
          "title": "Think Before You Prune: Self-Reflective Structured Pruning for Reasoning Language Models",
          "abstract": "Reasoning LLMs (RLMs) such as OpenAI o1, DeepSeek-R1, and Qwen3 deliver strong multi-step reasoning through chain-of-thought generation, but their large model sizes and lengthy decode-time outputs make them costly to deploy and unsuitable for resource-constrained settings. To reduce computing and memory cost, pruning offers a promising solution by removing unimportant parameters. However, despite their success on standard LLMs, existing pruning methods severely damage RLMs, as even moderate sparsity (e.g., 20%) can collapse accuracy and completely disrupt the model's reasoning coherence. We begin by analyzing why existing pruning pipelines fail on reasoning LLMs and find that their brittleness largely stems from a mismatch between the calibration data, the pruning objective, and the model's decode-time reasoning behavior. Our study further shows that the most reliable calibration signal comes not from human-written labels but from the model's own self-generated reasoning traces, which more accurately reflect its inference distribution. Guided by these insights, we introduce RESP, a self-reflective structured pruning framework that aligns pruning decisions with the model's reasoning dynamics through self-generated calibration, decode-only gradient-based importance estimation, and progressive regeneration that maintains calibration fidelity as sparsity increases. Experiments on Qwen3-8B demonstrate that RESP markedly outperforms existing structured pruning methods on both GSM8K and MathQA, preserving near-dense accuracy at 20-30% sparsity and substantially mitigating performance collapse at higher sparsity levels. At 40% sparsity, RESP attains 81.3% accuracy on GSM8K and 59.6% on MathQA, surpassing the strongest baselines by 66.87% and 47%, respectively.",
          "authors": [
            "Ziyan Wang",
            "Enmao Diao",
            "Qi Le",
            "Pu Wang",
            "Guanchu Wang",
            "Minwoo Lee",
            "Shu-ping Yeh",
            "Li Yang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02188",
          "title": "RobustSurg: Tackling domain generalisation for out-of-distribution surgical scene segmentation",
          "abstract": "While recent advances in deep learning for surgical scene segmentation have demonstrated promising results on single-centre and single-imaging modality data, these methods usually do not generalise to unseen distribution (i.e., from other centres) and unseen modalities. Current literature for tackling generalisation on out-of-distribution data and domain gaps due to modality changes has been widely researched but mostly for natural scene data. However, these methods cannot be directly applied to the surgical scenes due to limited visual cues and often extremely diverse scenarios compared to the natural scene data. Inspired by these works in natural scenes to push generalisability on OOD data, we hypothesise that exploiting the style and content information in the surgical scenes could minimise the appearances, making it less variable to sudden changes such as blood or imaging artefacts. This can be achieved by performing instance normalisation and feature covariance mapping techniques for robust and generalisable feature representations. Further, to eliminate the risk of removing salient feature representation associated with the objects of interest, we introduce a restitution module within the feature learning ResNet backbone that can enable the retention of useful task-relevant features. To tackle the lack of multiclass and multicentre data for surgical scene segmentation, we also provide a newly curated dataset that can be vital for addressing generalisability in this domain. Our proposed RobustSurg obtained nearly 23% improvement on the baseline DeepLabv3+ and from 10-32% improvement on the SOTA in terms of mean IoU score on an unseen centre HeiCholSeg dataset when trained on CholecSeg8K. Similarly, RobustSurg also obtained nearly 22% improvement over the baseline and nearly 11% improvement on a recent SOTA method for the target set of the EndoUDA polyp dataset.",
          "authors": [
            "Mansoor Ali",
            "Maksim Richards",
            "Gilberto Ochoa-Ruiz",
            "Sharib Ali"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02189",
          "title": "Microbenchmarking NVIDIA's Blackwell Architecture: An in-depth Architectural Analysis",
          "abstract": "As GPU architectures rapidly evolve to meet the overcoming demands of exascale computing and machine learning, the performance implications of architectural innovations remain poorly understood across diverse workloads. NVIDIA's Blackwell (B200) generation introduce significant architectural advances including the 5th generation tensor cores, tensor memory (TMEM), decompression engine (DE), and dual chips; however systematic methodologies for quantifying these improvements lag behind hardware development cycles. We contribute an open-source microbenchmark suite that offers practical insights into optimizing workloads to fully utilize the rich feature sets of the modern GPU architecture. This work aims to enable application developers make informed architectural decisions and guide future GPU design directions. Our work studies Blackwell GPUs, compares them to H200 generation with regards to the memory subsystem, tensor core pipeline and floating-point precisions (FP32, FP16, FP8, FP6, FP4). Our systematic evaluation of dense/sparse GEMM, transformer inference, and training workloads demonstrate that B200's tensor core enhancements achieves 1.56x higher mixed-precision throughput and 42% better energy efficiency than H200. Our memory analysis reveals 58% reduction in memory access latency in cache-misses, fundamentally changing optimal algorithm design strategies.",
          "authors": [
            "Aaron Jarmusch",
            "Sunita Chandrasekaran"
          ],
          "primary_category": "cs.AR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02192",
          "title": "Story2MIDI: Emotionally Aligned Music Generation from Text",
          "abstract": "In this paper, we introduce Story2MIDI, a sequence-to-sequence Transformer-based model for generating emotion-aligned music from a given piece of text. To develop this model, we construct the Story2MIDI dataset by merging existing datasets for sentiment analysis from text and emotion classification in music. The resulting dataset contains pairs of text blurbs and music pieces that evoke the same emotions in the reader or listener. Despite the small scale of our dataset and limited computational resources, our results indicate that our model effectively learns emotion-relevant features in music and incorporates them into its generation process, producing samples with diverse emotional responses. We evaluate the generated outputs using objective musical metrics and a human listening study, confirming the model's ability to capture intended emotional cues.",
          "authors": [
            "Mohammad Shokri",
            "Alexandra C. Salem",
            "Gabriel Levine",
            "Johanna Devaney",
            "Sarah Ita Levitan"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02193",
          "title": "From monoliths to modules: Decomposing transducers for efficient world modelling",
          "abstract": "World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.",
          "authors": [
            "Alexander Boyd",
            "Franz Nowak",
            "David Hyland",
            "Manuel Baltieri",
            "Fernando E. Rosas"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02194",
          "title": "Enforcing Orderedness to Improve Feature Consistency",
          "abstract": "Sparse autoencoders (SAEs) have been widely used for interpretability of neural networks, but their learned features often vary across seeds and hyperparameter settings. We introduce Ordered Sparse Autoencoders (OSAE), which extend Matryoshka SAEs by (1) establishing a strict ordering of latent features and (2) deterministically using every feature dimension, avoiding the sampling-based approximations of prior nested SAE methods. Theoretically, we show that OSAEs resolve permutation non-identifiability in settings of sparse dictionary learning where solutions are unique (up to natural symmetries). Empirically on Gemma2-2B and Pythia-70M, we show that OSAEs can help improve consistency compared to Matryoshka baselines.",
          "authors": [
            "Sophie L. Wang",
            "Alex Quach",
            "Nithin Parsan",
            "John J. Yang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02195",
          "title": "A Knowledge-Based Language Model: Deducing Grammatical Knowledge in a Multi-Agent Language Acquisition Simulation",
          "abstract": "This paper presents an initial study performed by the MODOMA system. The MODOMA is a computational multi-agent laboratory environment for unsupervised language acquisition experiments such that acquisition is based on the interaction between two language models, an adult and a child agent. Although this framework employs statistical as well as rule-based procedures, the result of language acquisition is a knowledge-based language model, which can be used to generate and parse new utterances of the target language. This system is fully parametrized and researchers can control all aspects of the experiments while the results of language acquisition, that is, the acquired grammatical knowledge, are explicitly represented and can be consulted. Thus, this system introduces novel possibilities for conducting computational language acquisition experiments. The experiments presented by this paper demonstrate that functional and content categories can be acquired and represented by the daughter agent based on training and test data containing different amounts of exemplars generated by the adult agent. Interestingly, similar patterns, which are well-established for human-generated data, are also found for these machine-generated data. As the procedures resulted in the successful acquisition of discrete grammatical categories by the child agent, these experiments substantiate the validity of the MODOMA approach to modelling language acquisition.",
          "authors": [
            "David Ph. Shakouri",
            "Crit Cremers",
            "Niels O. Schiller"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02197",
          "title": "Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection",
          "abstract": "We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.",
          "authors": [
            "Moussa Moussaoui",
            "Tarik Houichime",
            "Abdelalim Sadiq"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02198",
          "title": "Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation",
          "abstract": "Multifractal analysis has revealed regularities in many self-seeding phenomena, yet its use in modern deep learning remains limited. Existing end-to-end multifractal methods rely on heavy pooling or strong feature-space decimation, which constrain tasks such as semantic segmentation. Motivated by these limitations, we introduce two inductive priors: Monofractal and Multifractal Recalibration. These methods leverage relationships between the probability mass of the exponents and the multifractal spectrum to form statistical descriptions of encoder embeddings, implemented as channel-attention functions in convolutional networks. Using a U-Net-based framework, we show that multifractal recalibration yields substantial gains over a baseline equipped with other channel-attention mechanisms that also use higher-order statistics. Given the proven ability of multifractal analysis to capture pathological regularities, we validate our approach on three public medical-imaging datasets: ISIC18 (dermoscopy), Kvasir-SEG (endoscopy), and BUSI (ultrasound). Our empirical analysis also provides insights into the behavior of these attention layers. We find that excitation responses do not become increasingly specialized with encoder depth in U-Net architectures due to skip connections, and that their effectiveness may relate to global statistics of instance variability.",
          "authors": [
            "Miguel L. Martins",
            "Miguel T. Coimbra",
            "Francesco Renna"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02200",
          "title": "Modelling the Doughnut of social and planetary boundaries with frugal machine learning",
          "abstract": "The 'Doughnut' of social and planetary boundaries has emerged as a popular framework for assessing environmental and social sustainability. Here, we provide a proof-of-concept analysis that shows how machine learning (ML) methods can be applied to a simple macroeconomic model of the Doughnut. First, we show how ML methods can be used to find policy parameters that are consistent with 'living within the Doughnut'. Second, we show how a reinforcement learning agent can identify the optimal trajectory towards desired policies in the parameter space. The approaches we test, which include a Random Forest Classifier and $Q$-learning, are frugal ML methods that are able to find policy parameter combinations that achieve both environmental and social sustainability. The next step is the application of these methods to a more complex ecological macroeconomic model.",
          "authors": [
            "Stefano Vrizzi",
            "Daniel W. O'Neill"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02200",
          "title": "Modelling the Doughnut of social and planetary boundaries with frugal machine learning",
          "abstract": "The 'Doughnut' of social and planetary boundaries has emerged as a popular framework for assessing environmental and social sustainability. Here, we provide a proof-of-concept analysis that shows how machine learning (ML) methods can be applied to a simple macroeconomic model of the Doughnut. First, we show how ML methods can be used to find policy parameters that are consistent with 'living within the Doughnut'. Second, we show how a reinforcement learning agent can identify the optimal trajectory towards desired policies in the parameter space. The approaches we test, which include a Random Forest Classifier and $Q$-learning, are frugal ML methods that are able to find policy parameter combinations that achieve both environmental and social sustainability. The next step is the application of these methods to a more complex ecological macroeconomic model.",
          "authors": [
            "Stefano Vrizzi",
            "Daniel W. O'Neill"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02200",
          "title": "Modelling the Doughnut of social and planetary boundaries with frugal machine learning",
          "abstract": "The 'Doughnut' of social and planetary boundaries has emerged as a popular framework for assessing environmental and social sustainability. Here, we provide a proof-of-concept analysis that shows how machine learning (ML) methods can be applied to a simple macroeconomic model of the Doughnut. First, we show how ML methods can be used to find policy parameters that are consistent with 'living within the Doughnut'. Second, we show how a reinforcement learning agent can identify the optimal trajectory towards desired policies in the parameter space. The approaches we test, which include a Random Forest Classifier and $Q$-learning, are frugal ML methods that are able to find policy parameter combinations that achieve both environmental and social sustainability. The next step is the application of these methods to a more complex ecological macroeconomic model.",
          "authors": [
            "Stefano Vrizzi",
            "Daniel W. O'Neill"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02201",
          "title": "Swivuriso: The South African Next Voices Multilingual Speech Dataset",
          "abstract": "This paper introduces Swivuriso, a 3000-hour multilingual speech dataset developed as part of the African Next Voices project, to support the development and benchmarking of automatic speech recognition (ASR) technologies in seven South African languages. Covering agriculture, healthcare, and general domain topics, Swivuriso addresses significant gaps in existing ASR datasets. We describe the design principles, ethical considerations, and data collection procedures that guided the dataset creation. We present baseline results of training/finetuning ASR models with this data and compare to other ASR datasets for the langauges concerned.",
          "authors": [
            "Vukosi Marivatee",
            "Kayode Olaleye",
            "Sitwala Mundia",
            "Andinda Bakainga",
            "Unarine Netshifhefhe",
            "Mahmooda Milanzie",
            "Tsholofelo Hope Mogale",
            "Thapelo Sindane",
            "Zainab Abdulrasaq",
            "Kesego Mokgosi",
            "Chijioke Okorie",
            "Nia Zion Van Wyk",
            "Graham Morrissey",
            "Dale Dunbar",
            "Francois Smit",
            "Tsosheletso Chidi",
            "Rooweither Mabuya",
            "Andiswa Bukula",
            "Respect Mlambo",
            "Tebogo Macucwa",
            "Idris Abdulmumin",
            "and Seani Rananga"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02203",
          "title": "Unbiased Estimation of Multi-Way Gravity Models",
          "abstract": "Maximum likelihood estimators, such as the Poisson Pseudo-Maximum Likelihood (PPML), suffer from the incidental parameter problem: a bias in the estimation of structural parameters that arises from the joint estimation of structural and nuisance parameters. To address this issue in multi-way gravity models, we propose a novel, asymptotically unbiased estimator. Our method reframes the estimation as a series of classification tasks and is agnostic to both the number and structure of fixed effects. In sparse data environments, common in the network formation literature, it is also computationally faster than PPML. We provide empirical evidence that our estimator yields more accurate point estimates and confidence intervals than PPML and its bias-correction strategies. These improvements hold even under model misspecification and are more pronounced in sparse settings. While PPML remains competitive in dense, low-dimensional data, our approach offers a robust alternative for multi-way models that scales efficiently with sparsity. The method is applied to estimate the effect of a policy reform on spatial accessibility to health care in France.",
          "authors": [
            "Lucas Resende",
            "Guillaume Lecué",
            "Lionel Wilner",
            "Philippe Choné"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02203",
          "title": "Unbiased Estimation of Multi-Way Gravity Models",
          "abstract": "Maximum likelihood estimators, such as the Poisson Pseudo-Maximum Likelihood (PPML), suffer from the incidental parameter problem: a bias in the estimation of structural parameters that arises from the joint estimation of structural and nuisance parameters. To address this issue in multi-way gravity models, we propose a novel, asymptotically unbiased estimator. Our method reframes the estimation as a series of classification tasks and is agnostic to both the number and structure of fixed effects. In sparse data environments, common in the network formation literature, it is also computationally faster than PPML. We provide empirical evidence that our estimator yields more accurate point estimates and confidence intervals than PPML and its bias-correction strategies. These improvements hold even under model misspecification and are more pronounced in sparse settings. While PPML remains competitive in dense, low-dimensional data, our approach offers a robust alternative for multi-way models that scales efficiently with sparsity. The method is applied to estimate the effect of a policy reform on spatial accessibility to health care in France.",
          "authors": [
            "Lucas Resende",
            "Guillaume Lecué",
            "Lionel Wilner",
            "Philippe Choné"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02206",
          "title": "WhAM: Towards A Translative Model of Sperm Whale Vocalization",
          "abstract": "Sperm whales communicate in short sequences of clicks known as codas. We present WhAM (Whale Acoustics Model), the first transformer-based model capable of generating synthetic sperm whale codas from any audio prompt. WhAM is built by finetuning VampNet, a masked acoustic token model pretrained on musical audio, using 10k coda recordings collected over the past two decades. Through iterative masked token prediction, WhAM generates high-fidelity synthetic codas that preserve key acoustic features of the source recordings. We evaluate WhAM's synthetic codas using Fréchet Audio Distance and through perceptual studies with expert marine biologists. On downstream classification tasks including rhythm, social unit, and vowel classification, WhAM's learned representations achieve strong performance, despite being trained for generation rather than classification. Our code is available at this https URL",
          "authors": [
            "Orr Paradise",
            "Pranav Muralikrishnan",
            "Liangyuan Chen",
            "Hugo Flores García",
            "Bryan Pardo",
            "Roee Diamant",
            "David F. Gruber",
            "Shane Gero",
            "Shafi Goldwasser"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02210",
          "title": "Probabilistic Analysis of Various Squash Shots and Skill Study of Different Levels of Squash Players and Teams",
          "abstract": "We introduce a compact probabilistic model for two-player and two-team (four-player) squash matches, along with a practical skill-comparison rule derived from point-scoring probabilities. Using recorded shot types and court locations, we analyze how shot distributions differ between professional-level and intermediate-level players. Our analysis shows that professional players use a wider variety of shots and favor backcourt play to maintain control, while intermediate players concentrate more on mid-court shots, generate more errors, and exercise less positional control. These results quantify strategic differences in squash, offer a simple method to compare player and team skill, and provide actionable insights for sports analytics and coaching.",
          "authors": [
            "Prathamesh Anwekar",
            "Kaushal Kirpekar",
            "Mahesh B",
            "Sainath Bitragunta"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02210",
          "title": "Probabilistic Analysis of Various Squash Shots and Skill Study of Different Levels of Squash Players and Teams",
          "abstract": "We introduce a compact probabilistic model for two-player and two-team (four-player) squash matches, along with a practical skill-comparison rule derived from point-scoring probabilities. Using recorded shot types and court locations, we analyze how shot distributions differ between professional-level and intermediate-level players. Our analysis shows that professional players use a wider variety of shots and favor backcourt play to maintain control, while intermediate players concentrate more on mid-court shots, generate more errors, and exercise less positional control. These results quantify strategic differences in squash, offer a simple method to compare player and team skill, and provide actionable insights for sports analytics and coaching.",
          "authors": [
            "Prathamesh Anwekar",
            "Kaushal Kirpekar",
            "Mahesh B",
            "Sainath Bitragunta"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02213",
          "title": "InstructLR: A Scalable Approach to Create Instruction Dataset for Under-Resourced Languages",
          "abstract": "Effective text generation and chat interfaces for low-resource languages (LRLs) remain a challenge for state-of-the-art large language models (LLMs) to support. This is mainly due to the difficulty of curating high-quality instruction datasets for LRLs, a limitation prevalent in the languages spoken across the African continent and other regions. Current approaches, such as automated translation and synthetic data generation, frequently yield outputs that lack fluency or even orthographic consistency. In this paper, we introduce InstructLR, a novel framework designed to generate high-quality instruction datasets for LRLs. Our approach integrates LLM-driven text generation with a dual-layer quality filtering mechanism: an automated filtering layer based on retrieval-augmented-generation (RAG)-based n-shot prompting, and a human-in-the-loop validation layer. Drawing inspiration from benchmarks such as MMLU in task definition, InstructLR has facilitated the creation of three multi-domain instruction benchmarks: ZarmaInstruct-50k, BambaraInstruct-50k, and FulfuldeInstruct-50k.",
          "authors": [
            "Mamadou K. Keita",
            "Sebastien Diarra",
            "Christopher Homan",
            "Seydou Diallo"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02214",
          "title": "Improved Training Mechanism for Reinforcement Learning via Online Model Selection",
          "abstract": "We study the problem of online model selection in reinforcement learning, where the selector has access to a class of reinforcement learning agents and learns to adaptively select the agent with the right configuration. Our goal is to establish the improved efficiency and performance gains achieved by integrating online model selection methods into reinforcement learning training procedures. We examine the theoretical characterizations that are effective for identifying the right configuration in practice, and address three practical criteria from a theoretical perspective: 1) Efficient resource allocation, 2) Adaptation under non-stationary dynamics, and 3) Training stability across different seeds. Our theoretical results are accompanied by empirical evidence from various model selection tasks in reinforcement learning, including neural architecture selection, step-size selection, and self model selection.",
          "authors": [
            "Aida Afshar",
            "Aldo Pacchiano"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02216",
          "title": "Parameter-Efficient Subspace Optimization for LLM Fine-Tuning",
          "abstract": "This paper develops a new perspective on parameter-efficient fine-tuning for LLMs, inspired by the classical theory of subspace minimization. We introduce a unifying framework, Parameter-Efficient Subspace Optimization (PESO), which not only recovers many existing methods such as LoRA but also bridges them with the principled algorithmic and theoretical foundations of subspace optimization. This connection highlights a natural ``exploration--exploitation'' view of subspace methods, guiding the design of new algorithms that achieve strong convergence performance while still preserving memory efficiency. Importantly, our framework establishes the convergence in the full-parameter space, resolving a critical gap of LoRA variants where low-rank updates lack such guarantees. We further instantiate the framework into a practical algorithm named {PESO-LoRA}, based on LoRA-type parameterization. Our algorithm achieves notable improvements over existing methods on standard benchmarks.",
          "authors": [
            "Yuchen Lou",
            "Zeqi Ye",
            "Minshuo Chen"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02217",
          "title": "Uncertainty Reasoning with Photonic Bayesian Machines",
          "abstract": "Artificial intelligence (AI) systems increasingly influence safety-critical aspects of society, from medical diagnosis to autonomous mobility, making uncertainty awareness a central requirement for trustworthy AI. We present a photonic Bayesian machine that leverages the inherent randomness of chaotic light sources to enable uncertainty reasoning within the framework of Bayesian Neural Networks. The analog processor features a 1.28 Tbit/s digital interface compatible with PyTorch, enabling probabilistic convolutions processing within 37.5 ps per convolution. We use the system for simultaneous classification and out-of-domain detection of blood cell microscope images and demonstrate reasoning between aleatoric and epistemic uncertainties. The photonic Bayesian machine removes the bottleneck of pseudo random number generation in digital systems, minimizes the cost of sampling for probabilistic models, and thus enables high-speed trustworthy AI systems.",
          "authors": [
            "F. Brückerhoff-Plückelmann",
            "H. Borras",
            "S. U. Hulyal",
            "L. Meyer",
            "X. Ji",
            "J. Hu",
            "J. Sun",
            "B. Klein",
            "F. Ebert",
            "J. Dijkstra",
            "L. McRae",
            "P. Schmidt",
            "T. J. Kippenberg",
            "H. Fröning",
            "W. Pernice"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02217",
          "title": "Uncertainty Reasoning with Photonic Bayesian Machines",
          "abstract": "Artificial intelligence (AI) systems increasingly influence safety-critical aspects of society, from medical diagnosis to autonomous mobility, making uncertainty awareness a central requirement for trustworthy AI. We present a photonic Bayesian machine that leverages the inherent randomness of chaotic light sources to enable uncertainty reasoning within the framework of Bayesian Neural Networks. The analog processor features a 1.28 Tbit/s digital interface compatible with PyTorch, enabling probabilistic convolutions processing within 37.5 ps per convolution. We use the system for simultaneous classification and out-of-domain detection of blood cell microscope images and demonstrate reasoning between aleatoric and epistemic uncertainties. The photonic Bayesian machine removes the bottleneck of pseudo random number generation in digital systems, minimizes the cost of sampling for probabilistic models, and thus enables high-speed trustworthy AI systems.",
          "authors": [
            "F. Brückerhoff-Plückelmann",
            "H. Borras",
            "S. U. Hulyal",
            "L. Meyer",
            "X. Ji",
            "J. Hu",
            "J. Sun",
            "B. Klein",
            "F. Ebert",
            "J. Dijkstra",
            "L. McRae",
            "P. Schmidt",
            "T. J. Kippenberg",
            "H. Fröning",
            "W. Pernice"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02223",
          "title": "On the Approximation of Phylogenetic Distance Functions by Artificial Neural Networks",
          "abstract": "Inferring the phylogenetic relationships among a sample of organisms is a fundamental problem in modern biology. While distance-based hierarchical clustering algorithms achieved early success on this task, these have been supplanted by Bayesian and maximum likelihood search procedures based on complex models of molecular evolution. In this work we describe minimal neural network architectures that can approximate classic phylogenetic distance functions and the properties required to learn distances under a variety of molecular evolutionary models. In contrast to model-based inference (and recently proposed model-free convolutional and transformer networks), these architectures have a small computational footprint and are scalable to large numbers of taxa and molecular characters. The learned distance functions generalize well and, given an appropriate training dataset, achieve results comparable to state-of-the art inference methods.",
          "authors": [
            "Benjamin K. Rosenzweig",
            "Matthew W. Hahn"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02223",
          "title": "On the Approximation of Phylogenetic Distance Functions by Artificial Neural Networks",
          "abstract": "Inferring the phylogenetic relationships among a sample of organisms is a fundamental problem in modern biology. While distance-based hierarchical clustering algorithms achieved early success on this task, these have been supplanted by Bayesian and maximum likelihood search procedures based on complex models of molecular evolution. In this work we describe minimal neural network architectures that can approximate classic phylogenetic distance functions and the properties required to learn distances under a variety of molecular evolutionary models. In contrast to model-based inference (and recently proposed model-free convolutional and transformer networks), these architectures have a small computational footprint and are scalable to large numbers of taxa and molecular characters. The learned distance functions generalize well and, given an appropriate training dataset, achieve results comparable to state-of-the art inference methods.",
          "authors": [
            "Benjamin K. Rosenzweig",
            "Matthew W. Hahn"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02224",
          "title": "Towards Unified Video Quality Assessment",
          "abstract": "Recent works in video quality assessment (VQA) typically employ monolithic models that typically predict a single quality score for each test video. These approaches cannot provide diagnostic, interpretable feedback, offering little insight into why the video quality is degraded. Most of them are also specialized, format-specific metrics rather than truly ``generic\" solutions, as they are designed to learn a compromised representation from disparate perceptual domains. To address these limitations, this paper proposes Unified-VQA, a framework that provides a single, unified quality model applicable to various distortion types within multiple video formats by recasting generic VQA as a Diagnostic Mixture-of-Experts (MoE) problem. Unified-VQA employs multiple ``perceptual experts'' dedicated to distinct perceptual domains. A novel multi-proxy expert training strategy is designed to optimize each expert using a ranking-inspired loss, guided by the most suitable proxy metric for its domain. We also integrated a diagnostic multi-task head into this framework to generate a global quality score and an interpretable multi-dimensional artifact vector, which is optimized using a weakly-supervised learning strategy, leveraging the known properties of the large-scale training database generated for this work. With static model parameters (without retraining or fine-tuning), Unified-VQA demonstrates consistent and superior performance compared to over 18 benchmark methods for both generic VQA and diagnostic artifact detection tasks across 17 databases containing diverse streaming artifacts in HD, UHD, HDR and HFR formats. This work represents an important step towards practical, actionable, and interpretable video quality assessment.",
          "authors": [
            "Chen Feng",
            "Tianhao Peng",
            "Fan Zhang",
            "David Bull"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02227",
          "title": "Orchestration Framework for Financial Agents: From Algorithmic Trading to Agentic Trading",
          "abstract": "The financial market is a mission-critical playground for AI agents due to its temporal dynamics and low signal-to-noise ratio. Building an effective algorithmic trading system may require a professional team to develop and test over the years. In this paper, we propose an orchestration framework for financial agents, which aims to democratize financial intelligence to the general public. We map each component of the traditional algorithmic trading system to agents, including planner, orchestrator, alpha agents, risk agents, portfolio agents, backtest agents, execution agents, audit agents, and memory agent. We present two in-house trading examples. For the stock trading task (hourly data from 04/2024 to 12/2024), our approach achieved a return of $20.42\\%$, a Sharpe ratio of 2.63, and a maximum drawdown of $-3.59\\%$, while the S&P 500 index yielded a return of $15.97\\%$. For the BTC trading task (minute data from 27/07/2025 to 13/08/2025), our approach achieved a return of $8.39\\%$, a Sharpe ratio of $0.38$, and a maximum drawdown of $-2.80\\%$, whereas the BTC price increased by $3.80\\%$. Our code is available on \\href{ this https URL }{GitHub}.",
          "authors": [
            "Jifeng Li",
            "Arnav Grover",
            "Abraham Alpuerto",
            "Yupeng Cao",
            "Xiao-Yang Liu"
          ],
          "primary_category": "cs.MA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02228",
          "title": "STRIDE: A Systematic Framework for Selecting AI Modalities - Agentic AI, AI Assistants, or LLM Calls",
          "abstract": "The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk. We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context. Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.",
          "authors": [
            "Shubhi Asthana",
            "Bing Zhang",
            "Chad DeLuca",
            "Ruchi Mahindru",
            "Hima Patel"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02230",
          "title": "Benchmarking LLM Agents for Wealth-Management Workflows",
          "abstract": "Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.",
          "authors": [
            "Rory Milsom"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02231",
          "title": "See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding in Multimodal Large Language Models",
          "abstract": "Multimodal large language models (MLLMs) are expected to jointly interpret vision, audio, and language, yet existing video benchmarks rarely assess fine-grained reasoning about human speech. Many tasks remain visually solvable or only coarsely evaluate speech, offering limited insight into whether models can align who speaks, what is said, and when it occurs. We introduce AV-SpeakerBench, a curated benchmark of 3,212 multiple-choice questions focused on speaker-centric audiovisual reasoning in real-world videos. It features: (1) a speaker-centered formulation that treats speakers-not scenes-as the core reasoning unit; (2) fusion-grounded question design embedding audiovisual dependencies into question semantics; and (3) expert-curated annotations ensuring temporal precision and cross-modal validity. Comprehensive evaluations show that the Gemini family consistently outperforms open-source systems, with Gemini 2.5 Pro achieving the best results. Among open models, Qwen3-Omni-30B approaches Gemini 2.0 Flash but remains far behind Gemini 2.5 Pro, primarily due to weaker audiovisual fusion rather than visual perception. We believe AV-SpeakerBench establishes a rigorous foundation for advancing fine-grained audiovisual reasoning in future multimodal systems.",
          "authors": [
            "Le Thien Phuc Nguyen",
            "Zhuoran Yu",
            "Samuel Low Yu Hang",
            "Subin An",
            "Jeongik Lee",
            "Yohan Ban",
            "SeungEun Chung",
            "Thanh-Huy Nguyen",
            "JuWan Maeng",
            "Soochahn Lee",
            "Yong Jae Lee"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02240",
          "title": "Lightweight Latent Reasoning for Narrative Tasks",
          "abstract": "Large language models (LLMs) tackle complex tasks by generating long chains of thought or \"reasoning traces\" that act as latent variables in the generation of an output given a query. A model's ability to generate such traces can be optimized with reinforcement learning (RL) to improve their utility in predicting an answer. This optimization comes at a high computational cost, especially for narrative-related tasks that involve retrieving and processing many tokens. To this end, we propose LiteReason, a latent reasoning method that can be interleaved with standard token sampling and easily combined with RL techniques. LiteReason employs a lightweight Reasoning Projector module, trained to produce continuous latent tokens that help the model 'skip' reasoning steps. During RL, the policy model decides when to activate the projector, switching between latent and discrete reasoning as needed. Experimental results on plot hole detection and book chapter generation show that our method outperforms latent reasoning baselines and comes close to matching non-latent RL training, while reducing final reasoning length by 77-92%. Overall, LiteReason guides RL training to a more efficient part of the performance-computation tradeoff curve.",
          "authors": [
            "Alexander Gurung",
            "Nikolay Malkin",
            "Mirella Lapata"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02243",
          "title": "PhishSnap: Image-Based Phishing Detection Using Perceptual Hashing",
          "abstract": "Phishing remains one of the most prevalent online threats, exploiting human trust to harvest sensitive credentials. Existing URL- and HTML-based detection systems struggle against obfuscation and visual deception. This paper presents \\textbf{PhishSnap}, a privacy-preserving, on-device phishing detection system leveraging perceptual hashing (pHash). Implemented as a browser extension, PhishSnap captures webpage screenshots, computes visual hashes, and compares them against legitimate templates to identify visually similar phishing attempts. A \\textbf{2024 dataset of 10,000 URLs} (70\\%/20\\%/10\\% train/validation/test) was collected from PhishTank and Netcraft. Due to security takedowns, a subset of phishing pages was unavailable, reducing dataset diversity. The system achieved \\textbf{0.79 accuracy}, \\textbf{0.76 precision}, and \\textbf{0.78 recall}, showing that visual similarity remains a viable anti-phishing measure. The entire inference process occurs locally, ensuring user privacy and minimal latency.",
          "authors": [
            "Md Abdul Ahad Minhaz",
            "Zannatul Zahan Meem",
            "Md. Shohrab Hossain"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02246",
          "title": "DETAIL Matters: Measuring the Impact of Prompt Specificity on Reasoning in Large Language Models",
          "abstract": "Prompt design plays a critical role in the reasoning performance of large language models (LLMs), yet the impact of prompt specificity - how detailed or vague a prompt is - remains understudied. This paper introduces DETAIL, a framework for evaluating LLM performance across varying levels of prompt specificity. We generate multi-level prompts using GPT-4, quantify specificity via perplexity, and assess correctness using GPT-based semantic equivalence. Experiments on 30 novel reasoning tasks across GPT-4 and O3-mini reveal that specificity improves accuracy, especially for smaller models and procedural tasks. Our results highlight the need for adaptive prompting strategies and provide tools and data to support further research.",
          "authors": [
            "Olivia Kim"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02247",
          "title": "An exact pricing algorithm for revenue maximization under the logit demand function",
          "abstract": "Determining the optimal selling price is a challenge in revenue management, especially in markets characterized by nonlinear and price-sensitive demand. While traditional models, such as linear, power, and exponential demand functions, offer analytical convenience, they often fail to capture realistic purchase dynamics, leading to suboptimal pricing. The logit demand function addresses these limitations through its bounded, S-shaped curve, offering a more realistic representation of consumer behavior. Despite its advantages, most existing literature relies on heuristic approaches, such as pricing at the inflection point, which prioritizes maximum price sensitivity but does not guarantee maximum revenue. This study proposes a novel, exact pricing algorithm that analytically derives the revenue-maximizing price under the logit demand function using the Lambert W function. By providing a closed-form solution, the approach eliminates reliance on heuristic iterative methods and corrects the common practice of considering the inflection point price as market price. In fact, we demonstrate that the optimal price is consistently lower than the inflection-point price under reasonable assumptions, leading to lower prices for consumers and higher revenue for sellers. Numerical experiments illustrate the proposed algorithm and examine the changes in the optimality gap as demand function parameters vary. Results indicate that the optimal price is consistently lower than the inflection-point price, with an average 20% price reduction accompanied by a 15% increase in revenue.",
          "authors": [
            "Moddassir Khan Nayeem",
            "Omar Abbaas",
            "Suzan Alaswad",
            "Sinan Salman"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02249",
          "title": "Discrete Sequential Barycenter Arrays: Representation, Approximation, and Modeling of Probability Measures",
          "abstract": "Constructing flexible probability models that respect constraints on key functionals -- such as the mean -- is a fundamental problem in nonparametric statistics. Existing approaches lack systematic tools for enforcing such constraints while retaining full modeling flexibility. This paper introduces a new representation for univariate probability measures based on discrete sequential barycenter arrays (SBA). We study structural properties of SBA representations and establish new approximation results. In particular, we show that for any target distribution, its SBA-based discrete approximations converge in both the weak topology and in Wasserstein distances, and that the representation is exact for all distributions with finite discrete support. We further characterize a broad class of measures whose SBA partitions exhibit regularity and induce increasingly fine meshes, and we prove that this class is dense in standard probabilistic topologies. These theoretical results enable the construction of probability models that preserve prescribed values -- or full distributions -- of the mean while maintaining large support. As an application, we derive a mixture model for density estimation whose induced mixing distribution has a fixed or user-specified mean. The resulting framework provides a principled mechanism for incorporating mean constraints in nonparametric modeling while preserving strong approximation properties. The approach is illustrated using both simulated and real data.",
          "authors": [
            "Alejandro Jara",
            "Carlos Sing-Long"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02249",
          "title": "Discrete Sequential Barycenter Arrays: Representation, Approximation, and Modeling of Probability Measures",
          "abstract": "Constructing flexible probability models that respect constraints on key functionals --such as the mean-- is a fundamental problem in nonparametric statistics. Existing approaches lack systematic tools for enforcing such constraints while retaining full modeling flexibility. This paper introduces a new representation for univariate probability measures based on discrete sequential barycenter arrays (SBA). We study structural properties of SBA representations and establish new approximation results. In particular, we show that for any target distribution, its SBA-based discrete approximations converge in both the weak topology and in Wasserstein distances, and that the representation is exact for all distributions with finite discrete support. We further characterize a broad class of measures whose SBA partitions exhibit regularity and induce increasingly fine meshes, and we prove that this class is dense in standard probabilistic topologies. These theoretical results enable the construction of probability models that preserve prescribed values --or full distributions-- of the mean while maintaining large support. As an application, we derive a mixture model for density estimation whose induced mixing distribution has a fixed or user-specified mean. The resulting framework provides a principled mechanism for incorporating mean constraints in nonparametric modeling while preserving strong approximation properties. The approach is illustrated using both simulated and real data.",
          "authors": [
            "Alejandro Jara",
            "Carlos Sing-Long"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02251",
          "title": "CAIRNS: Balancing Readability and Scientific Accuracy in Climate Adaptation Question Answering",
          "abstract": "Climate adaptation strategies are proposed in response to climate change. They are practised in agriculture to sustain food production. These strategies can be found in unstructured data (for example, scientific literature from the Elsevier website) or structured (heterogeneous climate data via government APIs). We present Climate Adaptation question-answering with Improved Readability and Noted Sources (CAIRNS), a framework that enables experts -- farmer advisors -- to obtain credible preliminary answers from complex evidence sources from the web. It enhances readability and citation reliability through a structured ScholarGuide prompt and achieves robust evaluation via a consistency-weighted hybrid evaluator that leverages inter-model agreement with experts. Together, these components enable readable, verifiable, and domain-grounded question-answering without fine-tuning or reinforcement learning. Using a previously reported dataset of expert-curated question-answers, we show that CAIRNS outperforms the baselines on most of the metrics. Our thorough ablation study confirms the results on all metrics. To validate our LLM-based evaluation, we also report an analysis of correlations against human judgment.",
          "authors": [
            "Liangji Kong",
            "Aditya Joshi",
            "Sarvnaz Karimi"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02258",
          "title": "Exploring the Potentials of Spiking Neural Networks for Image Deraining",
          "abstract": "Biologically plausible and energy-efficient frameworks such as Spiking Neural Networks (SNNs) have not been sufficiently explored in low-level vision tasks. Taking image deraining as an example, this study addresses the representation of the inherent high-pass characteristics of spiking neurons, specifically in image deraining and innovatively proposes the Visual LIF (VLIF) neuron, overcoming the obstacle of lacking spatial contextual understanding present in traditional spiking neurons. To tackle the limitation of frequency-domain saturation inherent in conventional spiking neurons, we leverage the proposed VLIF to introduce the Spiking Decomposition and Enhancement Module and the lightweight Spiking Multi-scale Unit for hierarchical multi-scale representation learning. Extensive experiments across five benchmark deraining datasets demonstrate that our approach significantly outperforms state-of-the-art SNN-based deraining methods, achieving this superior performance with only 13\\% of their energy consumption. These findings establish a solid foundation for deploying SNNs in high-performance, energy-efficient low-level vision tasks.",
          "authors": [
            "Shuang Chen",
            "Tomas Krajnik",
            "Farshad Arvin",
            "Amir Atapour-Abarghouei"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02259",
          "title": "CVE Breadcrumbs: Tracking Vulnerabilities Through Versioned Apache Libraries",
          "abstract": "The Apache Software Foundation (ASF) ecosystem underpins a vast portion of modern software infrastructure, powering widely used components such as Log4j, Tomcat, and Struts. However, the ubiquity of these libraries has made them prime targets for high-impact security vulnerabilities, as illustrated by incidents like Log4Shell. Despite their widespread adoption, Apache projects are not immune to recurring and severe security weaknesses. We conduct a historical analysis of the Apache ecosystem to follow the \"breadcrumb trail of vulnerabilities\" by compiling a comprehensive dataset of Common Vulnerabilities and Exposures (CVEs) and Common Weakness Enumerations (CWEs). We examine trends in exploit recurrence, disclosure timelines, and remediation practices. Our analysis is guided by four key research questions: (1) What are the most persistent and repeated CWEs in Apache libraries? (2) How long do CVEs persist before being addressed? (3) What is the delay between CVE introduction and official disclosure? and (4) How long after disclosure are CVEs remediated? We present a detailed timeline of vulnerability lifecycle stages across Apache libraries and offer insights to improve secure coding practices, vulnerability monitoring, and remediation strategies. Our contributions include a curated dataset covering 24,285 Apache libraries, 1,285 CVEs, and 157 CWEs, along with empirical findings and developer-focused recommendations.",
          "authors": [
            "Derek Garcia",
            "Briana Lee",
            "Ibrahim Matar",
            "David Rickards",
            "Andrew Zilnicki"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02260",
          "title": "EcoCast: A Spatio-Temporal Model for Continual Biodiversity and Climate Risk Forecasting",
          "abstract": "Increasing climate change and habitat loss are driving unprecedented shifts in species distributions. Conservation professionals urgently need timely, high-resolution predictions of biodiversity risks, especially in ecologically diverse regions like Africa. We propose EcoCast, a spatio-temporal model designed for continual biodiversity and climate risk forecasting. Utilizing multisource satellite imagery, climate data, and citizen science occurrence records, EcoCast predicts near-term (monthly to seasonal) shifts in species distributions through sequence-based transformers that model spatio-temporal environmental dependencies. The architecture is designed with support for continual learning to enable future operational deployment with new data streams. Our pilot study in Africa shows promising improvements in forecasting distributions of selected bird species compared to a Random Forest baseline, highlighting EcoCast's potential to inform targeted conservation policies. By demonstrating an end-to-end pipeline from multi-modal data ingestion to operational forecasting, EcoCast bridges the gap between cutting-edge machine learning and biodiversity management, ultimately guiding data-driven strategies for climate resilience and ecosystem conservation throughout Africa.",
          "authors": [
            "Hammed A. Akande",
            "Abdulrauf A. Gidado"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02260",
          "title": "EcoCast: A Spatio-Temporal Model for Continual Biodiversity and Climate Risk Forecasting",
          "abstract": "Increasing climate change and habitat loss are driving unprecedented shifts in species distributions. Conservation professionals urgently need timely, high-resolution predictions of biodiversity risks, especially in ecologically diverse regions like Africa. We propose EcoCast, a spatio-temporal model designed for continual biodiversity and climate risk forecasting. Utilizing multisource satellite imagery, climate data, and citizen science occurrence records, EcoCast predicts near-term (monthly to seasonal) shifts in species distributions through sequence-based transformers that model spatio-temporal environmental dependencies. The architecture is designed with support for continual learning to enable future operational deployment with new data streams. Our pilot study in Africa shows promising improvements in forecasting distributions of selected bird species compared to a Random Forest baseline, highlighting EcoCast's potential to inform targeted conservation policies. By demonstrating an end-to-end pipeline from multi-modal data ingestion to operational forecasting, EcoCast bridges the gap between cutting-edge machine learning and biodiversity management, ultimately guiding data-driven strategies for climate resilience and ecosystem conservation throughout Africa.",
          "authors": [
            "Hammed A. Akande",
            "Abdulrauf A. Gidado"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02261",
          "title": "TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?",
          "abstract": "LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at this https URL .",
          "authors": [
            "Lewen Yan",
            "Jilin Mei",
            "Tianyi Zhou",
            "Lige Huang",
            "Jie Zhang",
            "Dongrui Liu",
            "Jing Shao"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02263",
          "title": "DepthScape: Authoring 2.5D Designs via Depth Estimation, Semantic Understanding, and Geometry Extraction",
          "abstract": "2.5D effects, such as occlusion and perspective foreshortening, enhance visual dynamics and realism by incorporating 3D depth cues into 2D designs. However, creating such effects remains challenging and labor-intensive due to the complexity of depth perception. We introduce DepthScape, a human-AI collaborative system that facilitates 2.5D effect creation by directly placing design elements into 3D reconstructions. Using monocular depth reconstruction, DepthScape transforms images into 3D reconstructions where visual contents are placed to automatically achieve realistic occlusion and perspective foreshortening. To further simplify 3D placement through a 2D viewport, DepthScape uses a vision-language model to analyze source images and extract key visual components as content anchors for direct manipulation editing. We evaluate DepthScape with nine participants of varying design backgrounds, confirming the effectiveness of our creation pipeline. We also test on 100 professional stock images to assess robustness, and conduct an expert evaluation that confirms the quality of DepthScape's results.",
          "authors": [
            "Xia Su",
            "Cuong Nguyen",
            "Matheus A. Gadelha",
            "Jon E. Froehlich"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02265",
          "title": "The Effect of Enforcing Fairness on Reshaping Explanations in Machine Learning Models",
          "abstract": "Trustworthy machine learning in healthcare requires strong predictive performance, fairness, and explanations. While it is known that improving fairness can affect predictive performance, little is known about how fairness improvements influence explainability, an essential ingredient for clinical trust. Clinicians may hesitate to rely on a model whose explanations shift after fairness constraints are applied. In this study, we examine how enhancing fairness through bias mitigation techniques reshapes Shapley-based feature rankings. We quantify changes in feature importance rankings after applying fairness constraints across three datasets: pediatric urinary tract infection risk, direct anticoagulant bleeding risk, and recidivism risk. We also evaluate multiple model classes on the stability of Shapley-based rankings. We find that increasing model fairness across racial subgroups can significantly alter feature importance rankings, sometimes in different ways across groups. These results highlight the need to jointly consider accuracy, fairness, and explainability in model assessment rather than in isolation.",
          "authors": [
            "Joshua Wolff Anderson",
            "Shyam Visweswaran"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02266",
          "title": "Estimating excess mortality during the Covid-19 pandemic in Aotearoa New Zealand: Addendum",
          "abstract": "In our previous article, we estimated excess mortality during in Aotearoa New Zealand for 2020 to 2023. Since our work was published, updated population estimates have been released by Statistics NZ. In this short letter, we provide the results of applying our original model to the new population data. Our updated excess mortality estimate of 2.0% (95% CI [0.5%, 3.3%]) is 1.3 percentage points higher than our original estimate because the new population estimates for the period 2020 to 2023 are smaller, but the main conclusions of our original article still apply.",
          "authors": [
            "Michael J. Plank",
            "Pubudu Senanayake",
            "Richard Lyon"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02268",
          "title": "Spatiotemporal Pyramid Flow Matching for Climate Emulation",
          "abstract": "Generative models have the potential to transform the way we emulate Earth's changing climate. Previous generative approaches rely on weather-scale autoregression for climate emulation, but this is inherently slow for long climate horizons and has yet to demonstrate stable rollouts under nonstationary forcings. Here, we introduce Spatiotemporal Pyramid Flows (SPF), a new class of flow matching approaches that model data hierarchically across spatial and temporal scales. Inspired by cascaded video models, SPF partitions the generative trajectory into a spatiotemporal pyramid, progressively increasing spatial resolution to reduce computation and coupling each stage with an associated timescale to enable direct sampling at any temporal level in the pyramid. This design, together with conditioning each stage on prescribed physical forcings (e.g., greenhouse gases or aerosols), enables efficient, parallel climate emulation at multiple timescales. On ClimateBench, SPF outperforms strong flow matching baselines and pre-trained models at yearly and monthly timescales while offering fast sampling, especially at coarser temporal levels. To scale SPF, we curate ClimateSuite, the largest collection of Earth system simulations to date, comprising over 33,000 simulation-years across ten climate models and the first dataset to include simulations of climate interventions. We find that the scaled SPF model demonstrates good generalization to held-out scenarios across climate models. Together, SPF and ClimateSuite provide a foundation for accurate, efficient, probabilistic climate emulation across temporal scales and realistic future scenarios. Data and code is publicly available at this https URL .",
          "authors": [
            "Jeremy Andrew Irvin",
            "Jiaqi Han",
            "Zikui Wang",
            "Abdulaziz Alharbi",
            "Yufei Zhao",
            "Nomin-Erdene Bayarsaikhan",
            "Daniele Visioni",
            "Andrew Y. Ng",
            "Duncan Watson-Parris"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02268",
          "title": "Spatiotemporal Pyramid Flow Matching for Climate Emulation",
          "abstract": "Generative models have the potential to transform the way we emulate Earth's changing climate. Previous generative approaches rely on weather-scale autoregression for climate emulation, but this is inherently slow for long climate horizons and has yet to demonstrate stable rollouts under nonstationary forcings. Here, we introduce Spatiotemporal Pyramid Flows (SPF), a new class of flow matching approaches that model data hierarchically across spatial and temporal scales. Inspired by cascaded video models, SPF partitions the generative trajectory into a spatiotemporal pyramid, progressively increasing spatial resolution to reduce computation and coupling each stage with an associated timescale to enable direct sampling at any temporal level in the pyramid. This design, together with conditioning each stage on prescribed physical forcings (e.g., greenhouse gases or aerosols), enables efficient, parallel climate emulation at multiple timescales. On ClimateBench, SPF outperforms strong flow matching baselines and pre-trained models at yearly and monthly timescales while offering fast sampling, especially at coarser temporal levels. To scale SPF, we curate ClimateSuite, the largest collection of Earth system simulations to date, comprising over 33,000 simulation-years across ten climate models and the first dataset to include simulations of climate interventions. We find that the scaled SPF model demonstrates good generalization to held-out scenarios across climate models. Together, SPF and ClimateSuite provide a foundation for accurate, efficient, probabilistic climate emulation across temporal scales and realistic future scenarios. Data and code is publicly available at this https URL .",
          "authors": [
            "Jeremy Andrew Irvin",
            "Jiaqi Han",
            "Zikui Wang",
            "Abdulaziz Alharbi",
            "Yufei Zhao",
            "Nomin-Erdene Bayarsaikhan",
            "Daniele Visioni",
            "Andrew Y. Ng",
            "Duncan Watson-Parris"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02268",
          "title": "Spatiotemporal Pyramid Flow Matching for Climate Emulation",
          "abstract": "Generative models have the potential to transform the way we emulate Earth's changing climate. Previous generative approaches rely on weather-scale autoregression for climate emulation, but this is inherently slow for long climate horizons and has yet to demonstrate stable rollouts under nonstationary forcings. Here, we introduce Spatiotemporal Pyramid Flows (SPF), a new class of flow matching approaches that model data hierarchically across spatial and temporal scales. Inspired by cascaded video models, SPF partitions the generative trajectory into a spatiotemporal pyramid, progressively increasing spatial resolution to reduce computation and coupling each stage with an associated timescale to enable direct sampling at any temporal level in the pyramid. This design, together with conditioning each stage on prescribed physical forcings (e.g., greenhouse gases or aerosols), enables efficient, parallel climate emulation at multiple timescales. On ClimateBench, SPF outperforms strong flow matching baselines and pre-trained models at yearly and monthly timescales while offering fast sampling, especially at coarser temporal levels. To scale SPF, we curate ClimateSuite, the largest collection of Earth system simulations to date, comprising over 33,000 simulation-years across ten climate models and the first dataset to include simulations of climate interventions. We find that the scaled SPF model demonstrates good generalization to held-out scenarios across climate models. Together, SPF and ClimateSuite provide a foundation for accurate, efficient, probabilistic climate emulation across temporal scales and realistic future scenarios. Data and code is publicly available at this https URL .",
          "authors": [
            "Jeremy Andrew Irvin",
            "Jiaqi Han",
            "Zikui Wang",
            "Abdulaziz Alharbi",
            "Yufei Zhao",
            "Nomin-Erdene Bayarsaikhan",
            "Daniele Visioni",
            "Andrew Y. Ng",
            "Duncan Watson-Parris"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02272",
          "title": "Intrusion Detection on Resource-Constrained IoT Devices with Hardware-Aware ML and DL",
          "abstract": "This paper proposes a hardware-aware intrusion detection system (IDS) for Internet of Things (IoT) and Industrial IoT (IIoT) networks; it targets scenarios where classification is essential for fast, privacy-preserving, and resource-efficient threat detection. The goal is to optimize both tree-based machine learning (ML) models and compact deep neural networks (DNNs) within strict edge-device constraints. This allows for a fair comparison and reveals trade-offs between model families. We apply constrained grid search for tree-based classifiers and hardware-aware neural architecture search (HW-NAS) for 1D convolutional neural networks (1D-CNNs). Evaluation on the Edge-IIoTset benchmark shows that selected models meet tight flash, RAM, and compute limits: LightGBM achieves 95.3% accuracy using 75 KB flash and 1.2 K operations, while the HW-NAS-optimized CNN reaches 97.2% with 190 KB flash and 840 K floating-point operations (FLOPs). We deploy the full pipeline on a Raspberry Pi 3 B Plus, confirming that tree-based models operate within 30 ms and that CNNs remain suitable when accuracy outweighs latency. These results highlight the practicality of hardware-constrained model design for real-time IDS at the edge.",
          "authors": [
            "Ali Diab",
            "Adel Chehade",
            "Edoardo Ragusa",
            "Paolo Gastaldo",
            "Rodolfo Zunino",
            "Amer Baghdadi",
            "Mostafa Rizk"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02273",
          "title": "Progressive Image Restoration via Text-Conditioned Video Generation",
          "abstract": "Recent text-to-video models have demonstrated strong temporal generation capabilities, yet their potential for image restoration remains underexplored. In this work, we repurpose CogVideo for progressive visual restoration tasks by fine-tuning it to generate restoration trajectories rather than natural video motion. Specifically, we construct synthetic datasets for super-resolution, deblurring, and low-light enhancement, where each sample depicts a gradual transition from degraded to clean frames. Two prompting strategies are compared: a uniform text prompt shared across all samples, and a scene-specific prompting scheme generated via LLaVA multi-modal LLM and refined with ChatGPT. Our fine-tuned model learns to associate temporal progression with restoration quality, producing sequences that improve perceptual metrics such as PSNR, SSIM, and LPIPS across frames. Extensive experiments show that CogVideo effectively restores spatial detail and illumination consistency while maintaining temporal coherence. Moreover, the model generalizes to real-world scenarios on the ReLoBlur dataset without additional training, demonstrating strong zero-shot robustness and interpretability through temporal restoration.",
          "authors": [
            "Peng Kang",
            "Xijun Wang",
            "Yu Yuan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02275",
          "title": "Understanding Down Syndrome Stereotypes in LLM-Based Personas",
          "abstract": "We present a case study of Persona-L, a system that leverages large language models (LLMs) and retrieval-augmented generation (RAG) to model personas of people with Down syndrome. Existing approaches to persona creation can often lead to oversimplified or stereotypical profiles of people with Down Syndrome. To that end, we built stereotype detection capabilities into Persona-L. Through interviews with caregivers and healthcare professionals (N=10), we examine how Down Syndrome stereotypes could manifest in both, content and delivery of LLMs, and interface design. Our findings show the challenges in stereotypes definition, and reveal the potential stereotype emergence from the training data, interface design, and the tone of LLM output. This highlights the need for participatory methods that capture the heterogeneity of lived experiences of people with Down Syndrome.",
          "authors": [
            "Chantelle Wu",
            "Peinan Wang",
            "Nafi Nibras",
            "Meida Li",
            "Dajun Yuan",
            "Zhixiao Wang",
            "Jiahuan He",
            "Mona Ali",
            "Mirjana Prpa"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02276",
          "title": "Adversarial Robustness of Traffic Classification under Resource Constraints: Input Structure Matters",
          "abstract": "Traffic classification (TC) plays a critical role in cybersecurity, particularly in IoT and embedded contexts, where inspection must often occur locally under tight hardware constraints. We use hardware-aware neural architecture search (HW-NAS) to derive lightweight TC models that are accurate, efficient, and deployable on edge platforms. Two input formats are considered: a flattened byte sequence and a 2D packet-wise time series; we examine how input structure affects adversarial vulnerability when using resource-constrained models. Robustness is assessed against white-box attacks, specifically Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD). On USTC-TFC2016, both HW-NAS models achieve over 99% clean-data accuracy while remaining within 65k parameters and 2M FLOPs. Yet under perturbations of strength 0.1, their robustness diverges: the flat model retains over 85% accuracy, while the time-series variant drops below 35%. Adversarial fine-tuning delivers robust gains, with flat-input accuracy exceeding 96% and the time-series variant recovering over 60 percentage points in robustness, all without compromising efficiency. The results underscore how input structure influences adversarial vulnerability, and show that even compact, resource-efficient models can attain strong robustness, supporting their practical deployment in secure edge-based TC.",
          "authors": [
            "Adel Chehade",
            "Edoardo Ragusa",
            "Paolo Gastaldo",
            "Rodolfo Zunino"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02278",
          "title": "Fantasy: Efficient Large-scale Vector Search on GPU Clusters with GPUDirect Async",
          "abstract": "Vector similarity search has become a critical component in AI-driven applications such as large language models (LLMs). To achieve high recall and low latency, GPUs are utilized to exploit massive parallelism for faster query processing. However, as the number of vectors continues to grow, the graph size quickly exceeds the memory capacity of a single GPU, making it infeasible to store and process the entire index on a single GPU. Recent work uses CPU-GPU architectures to keep vectors in CPU memory or SSDs, but the loading step stalls GPU computation. We present Fantasy, an efficient system that pipelines vector search and data transfer in a GPU cluster with GPUDirect Async. Fantasy overlaps computation and network communication to significantly improve search throughput for large graphs and deliver large query batch sizes.",
          "authors": [
            "Yi Liu",
            "Chen Qian"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02279",
          "title": "Limitations of Membership Queries in Testable Learning",
          "abstract": "Membership queries (MQ) often yield speedups for learning tasks, particularly in the distribution-specific setting. We show that in the \\emph{testable learning} model of Rubinfeld and Vasilyan [RV23], membership queries cannot decrease the time complexity of testable learning algorithms beyond the complexity of sample-only distribution-specific learning. In the testable learning model, the learner must output a hypothesis whenever the data distribution satisfies a desired property, and if it outputs a hypothesis, the hypothesis must be near-optimal. We give a general reduction from sample-based \\emph{refutation} of boolean concept classes, as presented in [Vadhan17, KL18], to testable learning with queries (TL-Q). This yields lower bounds for TL-Q via the reduction from learning to refutation given in [KL18]. The result is that, relative to a concept class and a distribution family, no $m$-sample TL-Q algorithm can be super-polynomially more time-efficient than the best $m$-sample PAC learner. Finally, we define a class of ``statistical'' MQ algorithms that encompasses many known distribution-specific MQ learners, such as those based on influence estimation or subcube-conditional statistical queries. We show that TL-Q algorithms in this class imply efficient statistical-query refutation and learning algorithms. Thus, combined with known SQ dimension lower bounds, our results imply that these efficient membership query learners cannot be made testable.",
          "authors": [
            "Jane Lange",
            "Mingda Qiao"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02280",
          "title": "Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence",
          "abstract": "Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fun- damentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self- monitoring, lack of meta-cognitive awareness, fixed and non- adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust general- ization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.",
          "authors": [
            "Noorbakhsh Amiri Golilarz",
            "Sindhuja Penchala",
            "Shahram Rahimi"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02281",
          "title": "Trinity: Disaggregating Vector Search from Prefill-Decode Disaggregation in LLM Serving",
          "abstract": "Prefill and decode (PD) disaggregation separates prompt prefill and token-by-token decode stages into distinct GPU pools and has become the dominant architecture for large-scale LLM serving in industry. Also, retrieval tasks via vector search remains entangled with the model inference process, like heterogeneous RAG requests and prompt answer caches, inflating tail latency. We are motivated to investigate how vector search should be orchestrated along with PD disaggregation with a dedicated deployment architecture without violating SLOs in various retrieval workloads. We present Trinity, a practical framework that consolidates all retrieval into a single, shared vector-search GPU pool and make it work with PD disaggregated LLM serving in match. Trinity introduces (1) a novel architecture for deploying GPU-based vector search service in PD disaggregation. (2) Continuous batching for vector search that make full used of GPUs under heterogeneous queries; (3) Stage-aware scheduling that preempts vector search requests between both decode and prefill tasks.",
          "authors": [
            "Yi Liu",
            "Chen Qian"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02282",
          "title": "DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses",
          "abstract": "Large language models (LLMs) now mediate many web-based mental- health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent frame- work for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discrimi- natory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse gen- erative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi- agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog- Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language ratio- nales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.",
          "authors": [
            "Han Luo",
            "Guy Laban"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02283",
          "title": "Model Recovery at the Edge under Resource Constraints for Physical AI",
          "abstract": "Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.",
          "authors": [
            "Bin Xu",
            "Ayan Banerjee",
            "Sandeep K.S. Gupta"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02285",
          "title": "Edge-Native, Behavior-Adaptive Drone System for Wildlife Monitoring",
          "abstract": "Wildlife monitoring with drones must balance competing demands: approaching close enough to capture behaviorally-relevant video while avoiding stress responses that compromise animal welfare and data validity. Human operators face a fundamental attentional bottleneck: they cannot simultaneously control drone operations and monitor vigilance states across entire animal groups. By the time elevated vigilance becomes obvious, an adverse flee response by the animals may be unavoidable. To solve this challenge, we present an edge-native, behavior-adaptive drone system for wildlife monitoring. This configurable decision-support system augments operator expertise with automated group-level vigilance monitoring. Our system continuously tracks individual behaviors using YOLOv11m detection and YOLO-Behavior classification, aggregates vigilance states into a real-time group stress metric, and provides graduated alerts (alert vigilance to flee response) with operator-tunable thresholds for context-specific calibration. We derive service-level objectives (SLOs) from video frame rates and behavioral dynamics: to monitor 30fps video streams in real-time, our system must complete detection and classification within 33ms per frame. Our edge-native pipeline achieves 23.8ms total inference on GPU-accelerated hardware, meeting this constraint with a substantial margin. Retrospective analysis of seven wildlife monitoring missions demonstrates detection capability and quantifies the cost of reactive control: manual piloting results in 14 seconds average adverse behavior duration with 71.9% usable frames. Our analysis reveals operators could have received actionable alerts 51s before animals fled in 57% of missions. Simulating 5-second operator intervention yields a projected performance of 82.8% usable frames with 1-second adverse behavior duration,a 93% reduction compared to manual piloting.",
          "authors": [
            "Jenna Kline",
            "Rugved Katole",
            "Tanya Berger-Wolf",
            "Christopher Stewart"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02285",
          "title": "Edge-Native, Behavior-Adaptive Drone System for Wildlife Monitoring",
          "abstract": "Wildlife monitoring with drones must balance competing demands: approaching close enough to capture behaviorally-relevant video while avoiding stress responses that compromise animal welfare and data validity. Human operators face a fundamental attentional bottleneck: they cannot simultaneously control drone operations and monitor vigilance states across entire animal groups. By the time elevated vigilance becomes obvious, an adverse flee response by the animals may be unavoidable. To solve this challenge, we present an edge-native, behavior-adaptive drone system for wildlife monitoring. This configurable decision-support system augments operator expertise with automated group-level vigilance monitoring. Our system continuously tracks individual behaviors using YOLOv11m detection and YOLO-Behavior classification, aggregates vigilance states into a real-time group stress metric, and provides graduated alerts (alert vigilance to flee response) with operator-tunable thresholds for context-specific calibration. We derive service-level objectives (SLOs) from video frame rates and behavioral dynamics: to monitor 30fps video streams in real-time, our system must complete detection and classification within 33ms per frame. Our edge-native pipeline achieves 23.8ms total inference on GPU-accelerated hardware, meeting this constraint with a substantial margin. Retrospective analysis of seven wildlife monitoring missions demonstrates detection capability and quantifies the cost of reactive control: manual piloting results in 14 seconds average adverse behavior duration with 71.9% usable frames. Our analysis reveals operators could have received actionable alerts 51s before animals fled in 57% of missions. Simulating 5-second operator intervention yields a projected performance of 82.8% usable frames with 1-second adverse behavior duration,a 93% reduction compared to manual piloting.",
          "authors": [
            "Jenna Kline",
            "Rugved Katole",
            "Tanya Berger-Wolf",
            "Christopher Stewart"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02288",
          "title": "Artographer: a Curatorial Interface for Art Space Exploration",
          "abstract": "Relating a piece to previously established works is crucial in creating and engaging with art, but AI interfaces tend to obscure such relationships, rather than helping users explore them. Embedding models present new opportunities to support discovering and relating artwork through spatial interaction. We built Artographer, an art exploration system featuring a zoomable 2-D map, constructed from the similarity-clustered embeddings of 15,000+ historical artworks. Using Artographer as a probe to investigate spatial artwork exploration, we analyzed how 20 participants (including 9 art history scholars) traversed the map, during a goal-driven task and when freely exploring. We observe divergent and convergent exploration behaviors (Jumping, Wandering, Fixation, Revisiting) and identify values enacted by spatial art-finding (Visibility, Agency, Serendipity, Friction.) We situate spatial maps within a space of Curatorial Interfaces, systems that select and present artworks, and discuss centering pluralism and agency in the design of more responsible AI systems for art curation.",
          "authors": [
            "Shm Garanganao Almeda",
            "John Joon Young Chung",
            "Bjoern Hartmann",
            "Sophia Liu",
            "Brett Halperin",
            "Yuwen Lu",
            "Max Kreminski"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02289",
          "title": "Multi-Objective Agentic Rewrites for Unstructured Data Processing",
          "abstract": "One year ago, we open-sourced DocETL, a declarative system for LLM-powered data processing that, as of November 2025, has 3.2K GitHub stars and users across domains (e.g., journalism, law, medicine, policy, finance, and urban planning). In DocETL, users build pipelines by composing operators described in natural language, also known as semantic operators, with an LLM executing each operator's logic. However, due to complexity in the operator or the data it operates on, LLMs often give inaccurate results. To address this challenge, DocETL introduced rewrite directives, or abstract rules that guide LLM agents in rewriting pipelines by decomposing operators or data. For example, decomposing a single filter(\"is this email sent from an executive and discussing fraud?\") into the conjunction of two separate semantic filters may improve accuracy. However, DocETL only optimizes for accuracy, not cost. How do we optimize for both? We present MOAR (Multi-Objective Agentic Rewrites), a new optimizer for DocETL. To target cost optimization, we introduce two new categories of directives and extend all three existing categories with new ones, bringing the total to over 30 directives -- more than doubling what DocETL originally had. Moreover, since operators can interact with each other unpredictably due to LLM behavior, optimizing operators or sub-pipelines individually can yield suboptimal overall plans. Recognizing this, we design a new global search algorithm that explores rewrites in the context of entire pipelines. Since the space of rewrites is infinite -- pipelines can be rewritten in many ways, and each rewritten pipeline can itself be rewritten -- our algorithm adapts a multi-armed bandit framework to prioritize which pipelines to rewrite. Across six workloads, MOAR achieves 27% higher accuracy than ABACUS, the next-best optimizer, while matching its best accuracy at 55% of its cost.",
          "authors": [
            "Lindsey Linxi Wei",
            "Shreya Shankar",
            "Sepanta Zeighami",
            "Yeounoh Chung",
            "Fatma Ozcan",
            "Aditya G. Parameswaran"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02290",
          "title": "Enhancing Cross Domain SAR Oil Spill Segmentation via Morphological Region Perturbation and Synthetic Label-to-SAR Generation",
          "abstract": "Deep learning models for SAR oil spill segmentation often fail to generalize across regions due to differences in sea-state, backscatter statistics, and slick morphology, a limitation that is particularly severe along the Peruvian coast where labeled Sentinel-1 data remain scarce. To address this problem, we propose \\textbf{MORP--Synth}, a two-stage synthetic augmentation framework designed to improve transfer from Mediterranean to Peruvian conditions. Stage~A applies Morphological Region Perturbation, a curvature guided label space method that generates realistic geometric variations of oil and look-alike regions. Stage~B renders SAR-like textures from the edited masks using a conditional generative INADE model. We compile a Peruvian dataset of 2112 labeled 512$\\times$512 patches from 40 Sentinel-1 scenes (2014--2024), harmonized with the Mediterranean CleanSeaNet benchmark, and evaluate seven segmentation architectures. Models pretrained on Mediterranean data degrade from 67.8\\% to 51.8\\% mIoU on the Peruvian domain; MORP--Synth improves performance up to +6 mIoU and boosts minority-class IoU (+10.8 oil, +14.6 look-alike).",
          "authors": [
            "Andre Juarez",
            "Luis Salsavilca",
            "Frida Coaquira",
            "Celso Gonzales"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02293",
          "title": "VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM",
          "abstract": "We present VIGS-SLAM, a visual-inertial 3D Gaussian Splatting SLAM system that achieves robust real-time tracking and high-fidelity reconstruction. Although recent 3DGS-based SLAM methods achieve dense and photorealistic mapping, their purely visual design degrades under motion blur, low texture, and exposure variations. Our method tightly couples visual and inertial cues within a unified optimization framework, jointly refining camera poses, depths, and IMU states. It features robust IMU initialization, time-varying bias modeling, and loop closure with consistent Gaussian updates. Experiments on four challenging datasets demonstrate our superiority over state-of-the-art methods. Project page: this https URL",
          "authors": [
            "Zihan Zhu",
            "Wei Zhang",
            "Norbert Haala",
            "Marc Pollefeys",
            "Daniel Barath"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02299",
          "title": "HealthContradict: Evaluating Biomedical Knowledge Conflicts in Language Models",
          "abstract": "How do language models use contextual information to answer health questions? How are their responses impacted by conflicting contexts? We assess the ability of language models to reason over long, conflicting biomedical contexts using HealthContradict, an expert-verified dataset comprising 920 unique instances, each consisting of a health-related question, a factual answer supported by scientific evidence, and two documents presenting contradictory stances. We consider several prompt settings, including correct, incorrect or contradictory context, and measure their impact on model outputs. Compared to existing medical question-answering evaluation benchmarks, HealthContradict provides greater distinctions of language models' contextual reasoning capabilities. Our experiments show that the strength of fine-tuned biomedical language models lies not only in their parametric knowledge from pretraining, but also in their ability to exploit correct context while resisting incorrect context.",
          "authors": [
            "Boya Zhang",
            "Alban Bornet",
            "Rui Yang",
            "Nan Liu",
            "Douglas Teodoro"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02300",
          "title": "DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications",
          "abstract": "Memory disaggregation is promising to scale memory capacity and improves utilization in HPC systems. However, the performance overhead of accessing remote memory poses a significant chal- lenge, particularly for compute-intensive HPC applications where execution times are highly sensitive to data locality. In this work, we present DOLMA, a Data Object Level M emory dis Aggregation framework designed for HPC applications. DOLMA intelligently identifies and offloads data objects to remote memory, while pro- viding quantitative analysis to decide a suitable local memory size. Furthermore, DOLMA leverages the predictable memory access patterns typical in HPC applications and enables remote memory prefetch via a dual-buffer design. By carefully balancing local and remote memory usage and maintaining multi-thread concurrency, DOLMA provides a flexible and efficient solution for leveraging dis- aggregated memory in HPC domains while minimally compromis- ing application performance. Evaluating with eight HPC workloads and computational kernels, DOLMA limits performance degrada- tion to less than 16% while reducing local memory usage by up to 63%, on average.",
          "authors": [
            "Haoyu Zheng",
            "Shouwei Gao",
            "Jie Ren",
            "Wenqian Dong"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02302",
          "title": "Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization",
          "abstract": "Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.",
          "authors": [
            "Varun Kumar Dasoju",
            "Qingsu Cheng",
            "Zeyun Yu"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02303",
          "title": "Training Dynamics of Learning 3D-Rotational Equivariance",
          "abstract": "While data augmentation is widely used to train symmetry-agnostic models, it remains unclear how quickly and effectively they learn to respect symmetries. We investigate this by deriving a principled measure of equivariance error that, for convex losses, calculates the percent of total loss attributable to imperfections in learned symmetry. We focus our empirical investigation to 3D-rotation equivariance on high-dimensional molecular tasks (flow matching, force field prediction, denoising voxels) and find that models reduce equivariance error quickly to $\\leq$2\\% held-out loss within 1k-10k training steps, a result robust to model and dataset size. This happens because learning 3D-rotational equivariance is an easier learning task, with a smoother and better-conditioned loss landscape, than the main prediction task. For 3D rotations, the loss penalty for non-equivariant models is small throughout training, so they may achieve lower test loss than equivariant models per GPU-hour unless the equivariant ``efficiency gap'' is narrowed. We also experimentally and theoretically investigate the relationships between relative equivariance error, learning gradients, and model parameters.",
          "authors": [
            "Max W. Shen",
            "Ewa Nowara",
            "Michael Maser",
            "Kyunghyun Cho"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02303",
          "title": "Training Dynamics of Learning 3D-Rotational Equivariance",
          "abstract": "While data augmentation is widely used to train symmetry-agnostic models, it remains unclear how quickly and effectively they learn to respect symmetries. We investigate this by deriving a principled measure of equivariance error that, for convex losses, calculates the percent of total loss attributable to imperfections in learned symmetry. We focus our empirical investigation to 3D-rotation equivariance on high-dimensional molecular tasks (flow matching, force field prediction, denoising voxels) and find that models reduce equivariance error quickly to $\\leq$2\\% held-out loss within 1k-10k training steps, a result robust to model and dataset size. This happens because learning 3D-rotational equivariance is an easier learning task, with a smoother and better-conditioned loss landscape, than the main prediction task. For 3D rotations, the loss penalty for non-equivariant models is small throughout training, so they may achieve lower test loss than equivariant models per GPU-hour unless the equivariant ``efficiency gap'' is narrowed. We also experimentally and theoretically investigate the relationships between relative equivariance error, learning gradients, and model parameters.",
          "authors": [
            "Max W. Shen",
            "Ewa Nowara",
            "Michael Maser",
            "Kyunghyun Cho"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02304",
          "title": "When Does Verification Pay Off? A Closer Look at LLMs as Solution Verifiers",
          "abstract": "Large language models (LLMs) can act as both problem solvers and solution verifiers, with verifiers improving solver performance by selecting high-quality answers from a pool of candidates. However, prior studies of solver-verifier interactions have been limited, focusing mainly on self-verification and rarely examining how verifiers judge outputs from models in their own or in another model family. Modern LLMs also undergo extensive post-training, but its effect on verification remains unclear. We present a systematic study across 37 models spanning multiple families, sizes, and base vs. post-trained variants, evaluated on 9 benchmarks covering logical reasoning, structured puzzles, symbolic computation, mathematics, commonsense, factual recall, and domain knowledge. We compare self-verification with verification within the same family and across different families. To support this, we introduce and empirically validate verifier gain, a metric that predicts the performance improvements from test-time verifier-based rejection sampling. We analyze how metrics like verifier gain and false positive rate scale with model size and post-training, and characterize differences in dataset verifiability. Our findings show that cross-family verification is especially effective; post-training reduces self-improvement but strengthens cross-family improvement; and mathematical and logical tasks exhibit the highest inherent verifiability.",
          "authors": [
            "Jack Lu",
            "Ryan Teehan",
            "Jinran Jin",
            "Mengye Ren"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02306",
          "title": "OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning",
          "abstract": "Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.",
          "authors": [
            "Boyu Zhu",
            "Xiaofei Wen",
            "Wenjie Jacky Mo",
            "Tinghui Zhu",
            "Yanan Xie",
            "Peng Qi",
            "Muhao Chen"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02309",
          "title": "End-to-end machine-learned interatomic potentials for modeling functionalized mesoporous aluminosilicates",
          "abstract": "The structural hierarchy and chemical flexibility of metallosilicates enable broad technological applications, yet they also make it challenging to uncover structure--property relations. Previous large-scale atomistic simulations have provided mechanistic insight, but their accuracy and achievable model complexity remain constrained by the available interatomic potentials. Here, we present an end-to-end workflow for developing accurate and efficient machine-learning potentials, specifically moment tensor potentials (MTPs), tailored for structurally and chemically complex systems such as metallosilicates. The workflow integrates de novo structure generation, surface functionalization, and property evaluation. A domain-specific training strategy is employed: Configurations associated with melt--quench generation and subsequent functionalization train the syn-MTP, whereas configurations near equilibrium train the eq-MTP. We apply the workflow to prototypical metallosilicates, i.e., aluminosilicates, which we also experimentally synthesize and characterize for benchmarking the simulations. The syn-MTP reliably generates amorphous aluminosilicates that match experimental density and pair distribution functions measured with synchrotron X-ray diffraction. The eq-MTP reproduces experimental infrared spectra and surface hydroxyl densities, along with density-functional-theory-derived dehydrogenation energies, demonstrating meta-GGA-level accuracy and validating the end-to-end workflow. Finally, we showcase the applicability of the developed potentials by predicting infrared spectra of functionalized porous aluminosilicates. This study establishes a robust path toward accurate modeling of realistic metallosilicates under operando-relevant conditions.",
          "authors": [
            "Jong Hyun Jung",
            "Tom Schächtel",
            "Yongliang Ou",
            "Selina Itzigehl",
            "Marc Högler",
            "Niels Hansen",
            "Johanna R. Bruckner",
            "Blazej Grabowski"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02310",
          "title": "The MEVIR Framework: A Virtue-Informed Moral-Epistemic Model of Human Trust Decisions",
          "abstract": "The 21st-century information landscape presents an unprecedented challenge: how do individuals make sound trust decisions amid complexity, polarization, and misinformation? Traditional rational-agent models fail to capture human trust formation, which involves a complex synthesis of reason, character, and pre-rational intuition. This report introduces the Moral-Epistemic VIRtue informed (MEVIR) framework, a comprehensive descriptive model integrating three theoretical perspectives: (1) a procedural model describing evidence-gathering and reasoning chains; (2) Linda Zagzebski's virtue epistemology, characterizing intellectual disposition and character-driven processes; and (3) Extended Moral Foundations Theory (EMFT), explaining rapid, automatic moral intuitions that anchor reasoning. Central to the framework are ontological concepts - Truth Bearers, Truth Makers, and Ontological Unpacking-revealing that disagreements often stem from fundamental differences in what counts as admissible reality. MEVIR reframes cognitive biases as systematic failures in applying epistemic virtues and demonstrates how different moral foundations lead agents to construct separate, internally coherent \"trust lattices\". Through case studies on vaccination mandates and climate policy, the framework shows that political polarization represents deeper divergence in moral priors, epistemic authorities, and evaluative heuristics. The report analyzes how propaganda, psychological operations, and echo chambers exploit the MEVIR process. The framework provides foundation for a Decision Support System to augment metacognition, helping individuals identify biases and practice epistemic virtues. The report concludes by acknowledging limitations and proposing longitudinal studies for future research.",
          "authors": [
            "Daniel Schwabe"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02312",
          "title": "Fast and Accurate Node-Age Estimation Under Fossil Calibration Uncertainty Using the Adjusted Pairwise Likelihood",
          "abstract": "Estimating divergence times from molecular sequence data is central to reconstructing the evolutionary history of lineages. Although Bayesian relaxed-clock methods provide a principled framework for incorporating fossil information, their dependence on repeated evaluations of the full phylogenetic likelihood makes them computationally demanding for large genomic datasets. Furthermore, because disagreements in divergence-time estimates often arise from uncertainty or error in fossil placement and prior specification, there is a need for methods that are both computationally efficient and robust to fossil-calibration uncertainty. In this study, we introduce fast and accurate alternatives based on the phylogenetic pairwise composite likelihood, presenting two adjusted pairwise likelihood (APW) formulations that employ asymptotic moment-matching weights to better approximate the behavior of the full likelihood within a Bayesian MCMC framework. Extensive simulations across diverse fossil-calibration scenarios show that APW methods produce node-age estimates comparable to those obtained from the full likelihood while offering greater robustness to fossil misplacement and prior misspecification, due to the reduced sensitivity of composite likelihoods to local calibration errors. Applied to a genome-scale dataset of modern birds, APW methods recover divergence time patterns consistent with recent studies, while reducing computational cost by more than an order of magnitude. Overall, our results demonstrate that adjusted pairwise likelihoods provide a calibration-robust and computationally efficient framework for Bayesian node dating, especially suited for large phylogenomic datasets and analyses in which fossil priors may be uncertain or imperfectly placed.",
          "authors": [
            "Gregory M Ellison",
            "Liang Liu"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02315",
          "title": "Few-shot Protein Fitness Prediction via In-context Learning and Test-time Training",
          "abstract": "Accurately predicting protein fitness with minimal experimental data is a persistent challenge in protein engineering. We introduce PRIMO (PRotein In-context Mutation Oracle), a transformer-based framework that leverages in-context learning and test-time training to adapt rapidly to new proteins and assays without large task-specific datasets. By encoding sequence information, auxiliary zero-shot predictions, and sparse experimental labels from many assays as a unified token set in a pre-training masked-language modeling paradigm, PRIMO learns to prioritize promising variants through a preference-based loss function. Across diverse protein families and properties-including both substitution and indel mutations-PRIMO outperforms zero-shot and fully supervised baselines. This work underscores the power of combining large-scale pre-training with efficient test-time adaptation to tackle challenging protein design tasks where data collection is expensive and label availability is limited.",
          "authors": [
            "Felix Teufel",
            "Aaron W. Kollasch",
            "Yining Huang",
            "Ole Winther",
            "Kevin K. Yang",
            "Pascal Notin",
            "Debora S. Marks"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02315",
          "title": "Few-shot Protein Fitness Prediction via In-context Learning and Test-time Training",
          "abstract": "Accurately predicting protein fitness with minimal experimental data is a persistent challenge in protein engineering. We introduce PRIMO (PRotein In-context Mutation Oracle), a transformer-based framework that leverages in-context learning and test-time training to adapt rapidly to new proteins and assays without large task-specific datasets. By encoding sequence information, auxiliary zero-shot predictions, and sparse experimental labels from many assays as a unified token set in a pre-training masked-language modeling paradigm, PRIMO learns to prioritize promising variants through a preference-based loss function. Across diverse protein families and properties-including both substitution and indel mutations-PRIMO outperforms zero-shot and fully supervised baselines. This work underscores the power of combining large-scale pre-training with efficient test-time adaptation to tackle challenging protein design tasks where data collection is expensive and label availability is limited.",
          "authors": [
            "Felix Teufel",
            "Aaron W. Kollasch",
            "Yining Huang",
            "Ole Winther",
            "Kevin K. Yang",
            "Pascal Notin",
            "Debora S. Marks"
          ],
          "primary_category": "q-bio.BM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02318",
          "title": "COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers",
          "abstract": "This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation this http URL Availability ( this https URL ).",
          "authors": [
            "Junyu Wang",
            "Changjia Zhu",
            "Yuanbo Zhou",
            "Lingyao Li",
            "Xu He",
            "Junjie Xiong"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02319",
          "title": "Associative Memory using Attribute-Specific Neuron Groups-1: Learning between Multiple Cue Balls",
          "abstract": "In this paper, we present a new neural network model based on attribute-specific representations (e.g., color, shape, size), a classic example of associative memory. The proposed model is based on a previous study on memory and recall of multiple images using the Cue Ball and Recall Net (referred to as the CB-RN system, or simply CB-RN) [1]. The system consists of three components, which are this http URL -RN for processing color, this http URL -RN for processing shape, and this http URL -RN for processing size. When an attribute data pattern is presented to the CB-RN system, the corresponding attribute pattern of the cue neurons within the Cue Balls is associatively recalled in the Recall Net. Each image pattern presented to these CB-RN systems is represented using a two-dimensional code, specifically a QR code [2].",
          "authors": [
            "Hiroshi Inazawa"
          ],
          "primary_category": "cs.NE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02321",
          "title": "LeechHijack: Covert Computational Resource Exploitation in Intelligent Agent Systems",
          "abstract": "Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in reasoning, planning, and tool usage. The recently proposed Model Context Protocol (MCP) has emerged as a unifying framework for integrating external tools into agent systems, enabling a thriving open ecosystem of community-built functionalities. However, the openness and composability that make MCP appealing also introduce a critical yet overlooked security assumption -- implicit trust in third-party tool providers. In this work, we identify and formalize a new class of attacks that exploit this trust boundary without violating explicit permissions. We term this new attack vector implicit toxicity, where malicious behaviors occur entirely within the allowed privilege scope. We propose LeechHijack, a Latent Embedded Exploit for Computation Hijacking, in which an adversarial MCP tool covertly expropriates the agent's computational resources for unauthorized workloads. LeechHijack operates through a two-stage mechanism: an implantation stage that embeds a benign-looking backdoor in a tool, and an exploitation stage where the backdoor activates upon predefined triggers to establish a command-and-control channel. Through this channel, the attacker injects additional tasks that the agent executes as if they were part of its normal workflow, effectively parasitizing the user's compute budget. We implement LeechHijack across four major LLM families. Experiments show that LeechHijack achieves an average success rate of 77.25%, with a resource overhead of 18.62% compared to the baseline. This study highlights the urgent need for computational provenance and resource attestation mechanisms to safeguard the emerging MCP ecosystem.",
          "authors": [
            "Yuanhe Zhang",
            "Weiliu Wang",
            "Zhenhong Zhou",
            "Kun Wang",
            "Jie Zhang",
            "Li Sun",
            "Yang Liu",
            "Sen Su"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02327",
          "title": "Leveraging ontologies to predict biological activity of chemicals across genes",
          "abstract": "High-throughput screening (HTS) is useful for evaluating chemicals for potential human health risks. However, given the extraordinarily large number of genes, assay endpoints, and chemicals of interest, available data are sparse, with dose-response curves missing for the vast majority of chemical-gene pairs. Although gene ontologies characterize similarity among genes with respect to known cellular functions and biological pathways, the sensitivity of various pathways to environmental contaminants remains unclear. We propose a novel Dose-Activity Response Tracking (DART) approach to predict the biological activity of chemicals across genes using information on chemical structural properties and gene ontologies within a Bayesian factor model. Designed to provide toxicologists with a flexible tool applicable across diverse HTS assay platforms, DART reveals the latent processes driving dose-response behavior and predicts new activity profiles for chemical-gene pairs lacking experimental data. We demonstrate the performance of DART through simulation studies and an application to a vast new multi-experiment data set consisting of dose-response observations generated by the exposure of HepG2 cells to per- and polyfluoroalkyl substances (PFAS), where it provides actionable guidance for chemical prioritization and inference on the structural and functional mechanisms underlying assay activation.",
          "authors": [
            "Jennifer N. Kampe",
            "David B. Dunson",
            "Celeste K. Carberry",
            "Julia E. Rager",
            "Daniel Zilber",
            "Kyle P. Messier"
          ],
          "primary_category": "stat.AP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02328",
          "title": "Molecular Embedding-Based Algorithm Selection in Protein-Ligand Docking",
          "abstract": "Selecting an effective docking algorithm is highly context-dependent, and no single method performs reliably across structural, chemical, or protocol regimes. We introduce MolAS, a lightweight algorithm selection system that predicts per-algorithm performance from pretrained protein-ligand embeddings using attentional pooling and a shallow residual decoder. With only hundreds to a few thousand labelled complexes, MolAS achieves up to 15% absolute improvement over the single-best solver (SBS) and closes 17-66% of the Virtual Best Solver (VBS)-SBS gap across five diverse docking benchmarks. Analyses of reliability, embedding geometry, and solver-selection patterns show that MolAS succeeds when the oracle landscape exhibits low entropy and separable solver behaviour, but collapses under protocol-induced hierarchy shifts. These findings indicate that the main barrier to robust docking AS is not representational capacity but instability in solver rankings across pose-generation regimes, positioning MolAS as both a practical in-domain selector and a diagnostic tool for assessing when AS is feasible.",
          "authors": [
            "Jiabao Brad Wang",
            "Siyuan Cao",
            "Hongxuan Wu",
            "Yiliang Yuan",
            "Mustafa Misir"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02328",
          "title": "Molecular Embedding-Based Algorithm Selection in Protein-Ligand Docking",
          "abstract": "Selecting an effective docking algorithm is highly context-dependent, and no single method performs reliably across structural, chemical, or protocol regimes. We introduce MolAS, a lightweight algorithm selection system that predicts per-algorithm performance from pretrained protein-ligand embeddings using attentional pooling and a shallow residual decoder. With only hundreds to a few thousand labelled complexes, MolAS achieves up to 15% absolute improvement over the single-best solver (SBS) and closes 17-66% of the Virtual Best Solver (VBS)-SBS gap across five diverse docking benchmarks. Analyses of reliability, embedding geometry, and solver-selection patterns show that MolAS succeeds when the oracle landscape exhibits low entropy and separable solver behaviour, but collapses under protocol-induced hierarchy shifts. These findings indicate that the main barrier to robust docking AS is not representational capacity but instability in solver rankings across pose-generation regimes, positioning MolAS as both a practical in-domain selector and a diagnostic tool for assessing when AS is feasible.",
          "authors": [
            "Jiabao Brad Wang",
            "Siyuan Cao",
            "Hongxuan Wu",
            "Yiliang Yuan",
            "Mustafa Misir"
          ],
          "primary_category": "q-bio.QM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02329",
          "title": "Towards autonomous normative multi-agent systems for Human-AI software engineering teams",
          "abstract": "This paper envisions a transformative paradigm in software engineering, where Artificial Intelligence, embodied in fully autonomous agents, becomes the primary driver of the core software development activities. We introduce a new class of software engineering agents, empowered by Large Language Models and equipped with beliefs, desires, intentions, and memory to enable human-like reasoning. These agents collaborate with humans and other agents to design, implement, test, and deploy software systems with a level of speed, reliability, and adaptability far beyond the current software development processes. Their coordination and collaboration are governed by norms expressed as deontic modalities - commitments, obligations, prohibitions and permissions - that regulate interactions and ensure regulatory compliance. These innovations establish a scalable, transparent and trustworthy framework for future Human-AI software engineering teams.",
          "authors": [
            "Hoa Khanh Dam",
            "Geeta Mahala",
            "Rashina Hoda",
            "Xi Zheng",
            "Cristina Conati"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02333",
          "title": "Retrieval-Augmented Memory for Online Learning",
          "abstract": "Retrieval-augmented models couple parametric predictors with non-parametric memories, but their use in streaming supervised learning with concept drift is not well understood. We study online classification in non-stationary environments and propose Retrieval-Augmented Memory for Online Learning (RAM-OL), a simple extension of stochastic gradient descent that maintains a small buffer of past examples. At each time step, RAM-OL retrieves a few nearest neighbours of the current input in the hidden representation space and updates the model jointly on the current example and the retrieved neighbours. We compare a naive replay variant with a gated replay variant that constrains neighbours using a time window, similarity thresholds, and gradient reweighting, in order to balance fast reuse of relevant past data against robustness to outdated regimes. From a theoretical perspective, we interpret RAM-OL under a bounded drift model and discuss how retrieval can reduce adaptation cost and improve regret constants when patterns recur over time. Empirically, we instantiate RAM-OL on a simple online multilayer perceptron and evaluate it on three real-world data streams derived from electricity pricing, electricity load, and airline delay data. On strongly and periodically drifting streams, RAM-OL improves prequential accuracy by up to about seven percentage points and greatly reduces variance across random seeds, while on a noisy airline stream the gated variant closely matches the purely online baseline. These results show that retrieval-augmented memory is a practical and robust tool for online learning under concept drift.",
          "authors": [
            "Wenzhang Du"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02334",
          "title": "Layered Division and Global Allocation for Community Detection in Multilayer Network",
          "abstract": "Community detection in multilayer networks (CDMN) is to divide a set of entities with multiple relation types into a few disjoint subsets, which has many applications in the Web, transportation, and sociology systems. Recent neural network-based solutions to the CDMN task adopt a kind of representation fusion and global division paradigm: Each node is first learned a kind of layer-wise representations which are then fused for global community division. However, even with contrastive or attentive fusion mechanisms, the fused global representations often lack the discriminative power to capture structural nuances unique to each layer. In this paper, we propose a novel paradigm for the CDMN task: Layered Division and Global Allocation (LDGA). The core idea is to first perform layer-wise group division, based on which global community allocation is next performed. Concretely, LDGA employs a multi-head Transformer as the backbone representation encoder, where each head is for encoding node structural characteristics in each network layer. We integrate the Transformer with a community-latent encoder to capture community prototypes in each layer. A shared scorer performs layered division by generating layer-wise soft assignments, while global allocation assigns each node the community label with highest confidence across all layers to form the final consensus partition. We design a loss function that couples differentiable multilayer modularity with a cluster balance regularizer to train our model in an unsupervised manner. Extensive experiments on synthetic and real-world multilayer networks demonstrate that our LDGA outperforms the state-of-the-art competitors in terms of higher detected community modularities. Our code with parameter settings and datasets are available at this https URL .",
          "authors": [
            "Fanghao Hu",
            "Junhong Lin",
            "Zhi Cai",
            "Bang Wang"
          ],
          "primary_category": "cs.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02336",
          "title": "Forecasting MBTA Transit Dynamics: A Performance Benchmarking of Statistical and Machine Learning Models",
          "abstract": "The Massachusetts Bay Transportation Authority (MBTA) is the main public transit provider in Boston, operating multiple means of transport, including trains, subways, and buses. However, the system often faces delays and fluctuations in ridership volume, which negatively affect efficiency and passenger satisfaction. To further understand this phenomenon, this paper compares the performance of existing and unique methods to determine the best approach in predicting gated station entries in the subway system (a proxy for subway usage) and the number of delays in the overall MBTA system. To do so, this research considers factors that tend to affect public transportation, such as day of week, season, pressure, wind speed, average temperature, and precipitation. This paper evaluates the performance of 10 statistical and machine learning models on predicting next-day subway usage. On predicting delay count, the number of models is extended to 11 per day by introducing a self-exciting point process model, representing a unique application of a point-process framework for MBTA delay modeling. This research involves experimenting with the selective inclusion of features to determine feature importance, testing model accuracy via Root Mean Squared Error (RMSE). Remarkably, it is found that providing either day of week or season data has a more substantial benefit to predictive accuracy compared to weather data; in fact, providing weather data generally worsens performance, suggesting a tendency of models to overfit.",
          "authors": [
            "Sai Siddharth Nalamalpu",
            "Kaining Yuan",
            "Aiden Zhou",
            "Eugene Pinsky"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02337",
          "title": "SpecPV: Improving Self-Speculative Decoding for Long-Context Generation via Partial Verification",
          "abstract": "Growing demands from tasks like code generation, deep reasoning, and long-document understanding have made long-context generation a crucial capability for large language models (LLMs). Speculative decoding is one of the most direct and effective approaches for accelerating generation. It follows a draft-verify paradigm, where a lightweight draft model proposes several candidate tokens and the target model verifies them. However, we find that as the context length grows, verification becomes the dominant bottleneck. To further accelerate speculative decoding in long-context generation, we introduce SpecPV, a self-speculative decoding approach that performs fast verification using partial key-value states (KV) and periodically applies full verification to eliminate accumulated errors. We validate SpecPV across multiple long-context benchmarks and models, including LLaMA-3.1-8B-Instruct and Qwen3-series. Experimental results show that SpecPV achieves up to 6x decoding speedup over standard autoregressive decoding with minor degradation.",
          "authors": [
            "Zhendong Tan",
            "Xingjun Zhang",
            "Chaoyi Hu",
            "Junjie Peng",
            "Kun Xia"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02339",
          "title": "Video Diffusion Models Excel at Tracking Similar-Looking Objects Without Supervision",
          "abstract": "Distinguishing visually similar objects by their motion remains a critical challenge in computer vision. Although supervised trackers show promise, contemporary self-supervised trackers struggle when visual cues become ambiguous, limiting their scalability and generalization without extensive labeled data. We find that pre-trained video diffusion models inherently learn motion representations suitable for tracking without task-specific training. This ability arises because their denoising process isolates motion in early, high-noise stages, distinct from later appearance refinement. Capitalizing on this discovery, our self-supervised tracker significantly improves performance in distinguishing visually similar objects, an underexplored failure point for existing methods. Our method achieves up to a 6-point improvement over recent self-supervised approaches on established benchmarks and our newly introduced tests focused on tracking visually similar items. Visualizations confirm that these diffusion-derived motion representations enable robust tracking of even identical objects across challenging viewpoint changes and deformations.",
          "authors": [
            "Chenshuang Zhang",
            "Kang Zhang",
            "Joon Son Chung",
            "In So Kweon",
            "Junmo Kim",
            "Chengzhi Mao"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02340",
          "title": "Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective",
          "abstract": "Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at this https URL , and the source codes of benchmark construction and VLM reasoning analysis are available at this https URL .",
          "authors": [
            "Qiyao Xue",
            "Weichen Liu",
            "Shiqi Wang",
            "Haoming Wang",
            "Yuyang Wu",
            "Wei Gao"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02341",
          "title": "TALO: Pushing 3D Vision Foundation Models Towards Globally Consistent Online Reconstruction",
          "abstract": "3D vision foundation models have shown strong generalization in reconstructing key 3D attributes from uncalibrated images through a single feed-forward pass. However, when deployed in online settings such as driving scenarios, predictions are made over temporal windows, making it non-trivial to maintain consistency across time. Recent strategies align consecutive predictions by solving global transformation, yet our analysis reveals their fundamental limitations in assumption validity, local alignment scope, and robustness under noisy geometry. In this work, we propose a higher-DOF and long-term alignment framework based on Thin Plate Spline, leveraging globally propagated control points to correct spatially varying inconsistencies. In addition, we adopt a point-agnostic submap registration design that is inherently robust to noisy geometry predictions. The proposed framework is fully plug-and-play, compatible with diverse 3D foundation models and camera configurations (e.g., monocular or surround-view). Extensive experiments demonstrate that our method consistently yields more coherent geometry and lower trajectory errors across multiple datasets, backbone models, and camera setups, highlighting its robustness and generality. Codes are publicly available at \\href{ this https URL }{ this https URL }.",
          "authors": [
            "Fengyi Zhang",
            "Tianjun Zhang",
            "Kasra Khosoussi",
            "Zheng Zhang",
            "Zi Huang",
            "Yadan Luo"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02344",
          "title": "A multi-weight self-matching visual explanation for cnns on sar images",
          "abstract": "In recent years, convolutional neural networks (CNNs) have achieved significant success in various synthetic aperture radar (SAR) tasks. However, the complexity and opacity of their internal mechanisms hinder the fulfillment of high-reliability requirements, thereby limiting their application in SAR. Improving the interpretability of CNNs is thus of great importance for their development and deployment in SAR. In this paper, a visual explanation method termed multi-weight self-matching class activation mapping (MS-CAM) is proposed. MS-CAM matches SAR images with the feature maps and corresponding gradients extracted by the CNN, and combines both channel-wise and element-wise weights to visualize the decision basis learned by the model in SAR images. Extensive experiments conducted on a self-constructed SAR target classification dataset demonstrate that MS-CAM more accurately highlights the network's regions of interest and captures detailed target feature information, thereby enhancing network interpretability. Furthermore, the feasibility of applying MS-CAM to weakly-supervised obiect localization is validated. Key factors affecting localization accuracy, such as pixel thresholds, are analyzed in depth to inform future work.",
          "authors": [
            "Siyuan Sun",
            "Yongping Zhang",
            "Hongcheng Zeng",
            "Yamin Wang",
            "Wei Yang",
            "Wanting Yang",
            "Jie Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02346",
          "title": "Near-Memory Architecture for Threshold-Ordinal Surface-Based Corner Detection of Event Cameras",
          "abstract": "Event-based Cameras (EBCs) are widely utilized in surveillance and autonomous driving applications due to their high speed and low power consumption. Corners are essential low-level features in event-driven computer vision, and novel algorithms utilizing event-based representations, such as Threshold-Ordinal Surface (TOS), have been developed for corner detection. However, the implementation of these algorithms on resource-constrained edge devices is hindered by significant latency, undermining the advantages of EBCs. To address this challenge, a near-memory architecture for efficient TOS updates (NM-TOS) is proposed. This architecture employs a read-write decoupled 8T SRAM cell and optimizes patch update speed through pipelining. Hardware-software co-optimized peripheral circuits and dynamic voltage and frequency scaling (DVFS) enable power and latency reductions. Compared to traditional digital implementations, our architecture reduces latency/energy by 24.7x/1.2x at Vdd = 1.2 V or 1.93x/6.6x at Vdd = 0.6 V based on 65nm CMOS process. Monte Carlo simulations confirm robust circuit operation, demonstrating zero bit error rate at operating voltages above 0.62 V, with only 0.2% at 0.61 V and 2.5% at 0.6 V. Corner detection evaluation using precision-recall area under curve (AUC) metrics reveals minor AUC reductions of 0.027 and 0.015 at 0.6 V for two popular EBC datasets.",
          "authors": [
            "Hongyang Shang",
            "An Guo",
            "Shuai Dong",
            "Junyi Yang",
            "Ye Ke",
            "Arindam Basu"
          ],
          "primary_category": "cs.AR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02349",
          "title": "ACM COMPUTE 2025 Best Practices Track Proceedings",
          "abstract": "COMPUTE is an annual Indian conference supported by ACM India and iSIGCSE. The focus of COMPUTE is to improve the quality of computing education in the country by providing a platform for academicians and researchers to interact and share best practices in teaching, learning, and education in general. The Best Practices Track of COMPUTE 2025 invited Computer Science Educators across the country to submit an experience report for the best practices under multiple categories: 1) Novel classroom activities, 2) Imaginative assignments that promote creativity and problem-solving, 3) Diverse pedagogical approaches (e.g., flipped classrooms, peer teaching, project-based learning), 4) Designing AI-resistant or AI-integrated assessment questions, and 5) Teaching CS to students from other disciplines (e.g., business, humanities, engineering). These proceedings contain papers selected from these submissions for presentation at the conference, as well as a report (written by the editors) from the two best practices sessions where these were presented.",
          "authors": [
            "Ritwik Murali",
            "Mrityunjay Kumar"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02350",
          "title": "FOVA: Offline Federated Reinforcement Learning with Mixed-Quality Data",
          "abstract": "Offline Federated Reinforcement Learning (FRL), a marriage of federated learning and offline reinforcement learning, has attracted increasing interest recently. Albeit with some advancement, we find that the performance of most existing offline FRL methods drops dramatically when provided with mixed-quality data, that is, the logging behaviors (offline data) are collected by policies with varying qualities across clients. To overcome this limitation, this paper introduces a new vote-based offline FRL framework, named FOVA. It exploits a \\emph{vote mechanism} to identify high-return actions during local policy evaluation, alleviating the negative effect of low-quality behaviors from diverse local learning policies. Besides, building on advantage-weighted regression (AWR), we construct consistent local and global training objectives, significantly enhancing the efficiency and stability of FOVA. Further, we conduct an extensive theoretical analysis and rigorously show that the policy learned by FOVA enjoys strict policy improvement over the behavioral policy. Extensive experiments corroborate the significant performance gains of our proposed algorithm over existing baselines on widely used benchmarks.",
          "authors": [
            "Nan Qiao",
            "Sheng Yue",
            "Ju Ren",
            "Yaoxue Zhang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02351",
          "title": "Understanding and Harnessing Sparsity in Unified Multimodal Models",
          "abstract": "Large multimodal models have achieved remarkable progress in both understanding and generation. Recent efforts pursue unified multimodal models that integrate heterogeneous components to support both capabilities within a single framework. However, such unification introduces inference inefficiencies, e.g., specific tasks or samples may not require the full knowledge or capacity of the unified model. Yet, a systematic understanding of how these inefficiencies manifest across different components remains limited. In this work, we first conduct a systematic analysis of unified multimodal model components using training-free pruning as a probing methodology, considering both depth pruning and width reduction. Our study reveals that the understanding component exhibits notable compressibility in both understanding and generation tasks, which is more pronounced in the latter. In contrast, the generation components are highly sensitive to compression, with performance deteriorating sharply even under moderate compression ratios. To address this limitation, we propose the Mixture-of-Experts (MoE) Adaptation, inspired by the dynamic activation patterns observed across different samples. This approach partitions the generation module into multiple experts and enables sparse activation to restore generation quality. We validate the effectiveness of sparse activation through expert-frozen tuning and further demonstrate that a fully trainable adaptation delivers additional gains. As a result, the adapted BAGEL model achieves performance comparable to the full model while activating only about half of its parameters. The code is released at \\href{ this https URL }{this link}.",
          "authors": [
            "Shwai He",
            "Chaorui Deng",
            "Ang Li",
            "Shen Yan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02352",
          "title": "Visibility-Graph Asymmetry as a Structural Indicator of Volatility Clustering",
          "abstract": "Volatility clustering is one of the most robust stylized facts of financial markets, yet it is typically detected using moment-based diagnostics or parametric models such as GARCH. This paper shows that clustered volatility also leaves a clear imprint on the time-reversal symmetry of horizontal visibility graphs (HVGs) constructed on absolute returns in physical time. For each time point, we compute the maximal forward and backward visibility distances, $L^{+}(t)$ and $L^{-}(t)$, and use their empirical distributions to build a visibility-asymmetry fingerprint comprising the Kolmogorov--Smirnov distance, variance difference, entropy difference, and a ratio of extreme visibility spans. In a Monte Carlo study, these HVG asymmetry features sharply separate volatility-clustered GARCH(1,1) dynamics from i.i.d.\\ Gaussian noise and from randomly shuffled GARCH series that preserve the marginal distribution but destroy temporal dependence; a simple linear classifier based on the fingerprint achieves about 90\\% in-sample accuracy. Applying the method to daily S\\&P500 data reveals a pronounced forward--backward imbalance, including a variance difference $\\Delta\\mathrm{Var}$ that exceeds the simulated GARCH values by two orders of magnitude and vanishes after shuffling. Overall, the visibility-graph asymmetry fingerprint emerges as a simple, model-free, and geometrically interpretable indicator of volatility clustering and time irreversibility in financial time series.",
          "authors": [
            "Michał Sikorski"
          ],
          "primary_category": "q-fin.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02354",
          "title": "Characterizing Off-Chain Influence Proof Transaction Fee Mechanisms",
          "abstract": "Roughgarden (2020) initiates the study of Transaction Fee Mechanisms (TFMs), and posits that the on-chain game of a ``good'' TFM should be on-chain simple (OnCS), i.e., incentive compatible for users and the miner. Recent work of Ganesh, Thomas and Weinberg (2024) posits that they should additionally be Off-Chain Influence Proof (OffCIP), which means that the miner cannot achieve any additional revenue by separately conducting an off-chain auction to determine on-chain inclusion. They observe that a cryptographic second-price auction satisfies both properties, but leave open the question of whether other mechanisms (e.g, non-cryptographic) satisfy these properties. In this paper, we characterize OffCIP TFMs: They are those satisfying a burn identity relating the burn rule to the allocation rule. In particular, we show that auction is OffCIP if and only if its (induced direct-revelation) allocation rule $\\bar{X}(\\cdot)$ and burn rule $\\bar{B}(\\cdot)$ (both of which take as input users' values $v_1, \\dots, v_n$) are truthful when viewing $\\big(\\bar{X}(\\cdot), \\bar{B}(\\cdot)\\big)$ as the allocation and pricing rule of a multi-item auction for a single additive buyer with values $\\big(\\varphi(v_1),\\ldots, \\varphi(v_n)\\big)$ equal to the users' virtual values. Building on this burn identity, we characterize deterministic OffCIP and OnCS TFMs that do not use cryptography: They are posted-price mechanisms with specially-tuned burns. As a corollary, we show that such TFMs can only exist with infinite supply and prior-dependence. However, we show that for randomized TFMs, there are additional OnCS and OffCIP auctions that do not use cryptography (even when there is finite supply, under prior-dependence with a bounded prior distribution). Holistically, our results show that while OffCIP is a fairly stringent requirement, families of OffCIP mechanisms can be found for a variety of settings.",
          "authors": [
            "Aadityan Ganesh",
            "Clayton Thomas",
            "S. Matthew Weinberg"
          ],
          "primary_category": "cs.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02358",
          "title": "Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games",
          "abstract": "Optimizing numerical systems and mechanism design is crucial for enhancing player experience in Massively Multiplayer Online (MMO) games. Traditional optimization approaches rely on large-scale online experiments or parameter tuning over predefined statistical models, which are costly, time-consuming, and may disrupt player experience. Although simplified offline simulation systems are often adopted as alternatives, their limited fidelity prevents agents from accurately mimicking real player reasoning and reactions to interventions. To address these limitations, we propose a generative agent-based MMO simulation system empowered by Large Language Models (LLMs). By applying Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on large-scale real player behavioral data, we adapt LLMs from general priors to game-specific domains, enabling realistic and interpretable player decision-making. In parallel, a data-driven environment model trained on real gameplay logs reconstructs dynamic in-game systems. Experiments demonstrate strong consistency with real-world player behaviors and plausible causal responses under interventions, providing a reliable, interpretable, and cost-efficient framework for data-driven numerical design optimization.",
          "authors": [
            "Ran Zhang",
            "Kun Ouyang",
            "Tiancheng Ma",
            "Yida Yang",
            "Dong Fang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02359",
          "title": "WSCF-MVCC: Weakly-supervised Calibration-free Multi-view Crowd Counting",
          "abstract": "Multi-view crowd counting can effectively mitigate occlusion issues that commonly arise in single-image crowd counting. Existing deep-learning multi-view crowd counting methods project different camera view images onto a common space to obtain ground-plane density maps, requiring abundant and costly crowd annotations and camera calibrations. Hence, calibration-free methods are proposed that do not require camera calibrations and scene-level crowd annotations. However, existing calibration-free methods still require expensive image-level crowd annotations for training the single-view counting module. Thus, in this paper, we propose a weakly-supervised calibration-free multi-view crowd counting method (WSCF-MVCC), directly using crowd count as supervision for the single-view counting module rather than density maps constructed from crowd annotations. Instead, a self-supervised ranking loss that leverages multi-scale priors is utilized to enhance the model's perceptual ability without additional annotation costs. What's more, the proposed model leverages semantic information to achieve a more accurate view matching and, consequently, a more precise scene-level crowd count estimation. The proposed method outperforms the state-of-the-art methods on three widely used multi-view counting datasets under weakly supervised settings, indicating that it is more suitable for practical deployment compared with calibrated methods. Code is released in this https URL .",
          "authors": [
            "Bin Li",
            "Daijie Chen",
            "Qi Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02361",
          "title": "VACoT: Rethinking Visual Data Augmentation with VLMs",
          "abstract": "While visual data augmentation remains a cornerstone for training robust vision models, it has received limited attention in visual language models (VLMs), which predominantly rely on large-scale real data acquisition or synthetic diversity. Consequently, they may struggle with basic perception tasks that conventional models handle reliably. Given the substantial cost of pre-training and fine-tuning VLMs, continue training on augmented data yields limited and diminishing returns. In this paper, we present Visual Augmentation Chain-of-Thought (VACoT), a framework that dynamically invokes image augmentations during model inference. By incorporating post-hoc transformations such as denoising, VACoT substantially improves robustness on challenging and out-of-distribution inputs, especially in OCR-related adversarial scenarios. Distinct from prior approaches limited to local cropping, VACoT integrates a structured collection of general visual augmentations, broadening the query image views while reducing training complexity and computational overhead with efficient agentic reinforcement learning. We propose a conditional reward scheme that encourages necessary augmentation while penalizing verbose responses, ensuring concise and effective reasoning in perception tasks. We demonstrate the superiority of VACoT with extensive experiments on 13 perception benchmarks and further introduce AdvOCR to highlight the generalization benefits of post-hoc visual augmentations in adversarial scenarios.",
          "authors": [
            "Zhengzhuo Xu",
            "Chong Sun",
            "SiNan Du",
            "Chen Li",
            "Jing Lyu",
            "Chun Yuan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02362",
          "title": "Reconstructing Large Scale Production Networks",
          "abstract": "This paper develops an algorithm to reconstruct large weighted firm-to-firm networks using information about the size of the firms and sectoral input-output flows. Our algorithm is based on a four-step procedure. We first generate a matrix of probabilities of connections between all firms in the economy using an augmented gravity model embedded in a logistic function that takes firm size as mass. The model is parameterized to allow for the probability of a link between two firms to depend not only on their sizes but also on flows across the sectors to which they belong. We then use a Bernoulli draw to construct a directed but unweighted random graph from the probability distribution generated by the logistic-gravity function. We make the graph aperiodic by adding self-loops and irreducible by adding links between Strongly Connected Components while limiting distortions to sectoral flows. We convert the unweighted network to a weighted network by solving a convex quadratic programming problem that minimizes the Euclidean norm of the weights. The solution preserves the observed firm sizes and sectoral flows within reasonable bounds, while limiting the strength of the self-loops. Computationally, the algorithm is O(N2) in the worst case, but it can be evaluated in O(N) via sector-wise binning of firm sizes, albeit with an approximation error. We implement the algorithm to reconstruct the full US production network with more than 5 million firms and 100 million buyer-seller connections. The reconstructed network exhibits topological properties consistent with small samples of the real US buyer-seller networks, including fat-tails in degree distribution, mild clustering, and near-zero reciprocity. We provide open-source code of the algorithm to enable researchers to reconstruct large-scale granular production networks from publicly available data.",
          "authors": [
            "Ashwin Bhattathiripad",
            "Vipin P Veetil"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02362",
          "title": "Reconstructing Large Scale Production Networks",
          "abstract": "This paper develops an algorithm to reconstruct large weighted firm-to-firm networks using information about the size of the firms and sectoral input-output flows. Our algorithm is based on a four-step procedure. We first generate a matrix of probabilities of connections between all firms in the economy using an augmented gravity model embedded in a logistic function that takes firm size as mass. The model is parameterized to allow for the probability of a link between two firms to depend not only on their sizes but also on flows across the sectors to which they belong. We then use a Bernoulli draw to construct a directed but unweighted random graph from the probability distribution generated by the logistic-gravity function. We make the graph aperiodic by adding self-loops and irreducible by adding links between Strongly Connected Components while limiting distortions to sectoral flows. We convert the unweighted network to a weighted network by solving a convex quadratic programming problem that minimizes the Euclidean norm of the weights. The solution preserves the observed firm sizes and sectoral flows within reasonable bounds, while limiting the strength of the self-loops. Computationally, the algorithm is O(N2) in the worst case, but it can be evaluated in O(N) via sector-wise binning of firm sizes, albeit with an approximation error. We implement the algorithm to reconstruct the full US production network with more than 5 million firms and 100 million buyer-seller connections. The reconstructed network exhibits topological properties consistent with small samples of the real US buyer-seller networks, including fat-tails in degree distribution, mild clustering, and near-zero reciprocity. We provide open-source code of the algorithm to enable researchers to reconstruct large-scale granular production networks from publicly available data.",
          "authors": [
            "Ashwin Bhattathiripad",
            "Vipin P Veetil"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02362",
          "title": "Reconstructing Large Scale Production Networks",
          "abstract": "This paper develops an algorithm to reconstruct large weighted firm-to-firm networks using information about the size of the firms and sectoral input-output flows. Our algorithm is based on a four-step procedure. We first generate a matrix of probabilities of connections between all firms in the economy using an augmented gravity model embedded in a logistic function that takes firm size as mass. The model is parameterized to allow for the probability of a link between two firms to depend not only on their sizes but also on flows across the sectors to which they belong. We then use a Bernoulli draw to construct a directed but unweighted random graph from the probability distribution generated by the logistic-gravity function. We make the graph aperiodic by adding self-loops and irreducible by adding links between Strongly Connected Components while limiting distortions to sectoral flows. We convert the unweighted network to a weighted network by solving a convex quadratic programming problem that minimizes the Euclidean norm of the weights. The solution preserves the observed firm sizes and sectoral flows within reasonable bounds, while limiting the strength of the self-loops. Computationally, the algorithm is O(N2) in the worst case, but it can be evaluated in O(N) via sector-wise binning of firm sizes, albeit with an approximation error. We implement the algorithm to reconstruct the full US production network with more than 5 million firms and 100 million buyer-seller connections. The reconstructed network exhibits topological properties consistent with small samples of the real US buyer-seller networks, including fat-tails in degree distribution, mild clustering, and near-zero reciprocity. We provide open-source code of the algorithm to enable researchers to reconstruct large-scale granular production networks from publicly available data.",
          "authors": [
            "Ashwin Bhattathiripad",
            "Vipin P Veetil"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02363",
          "title": "Memory-Augmented Knowledge Fusion with Safety-Aware Decoding for Domain-Adaptive Question Answering",
          "abstract": "Domain-specific question answering (QA) systems for services face unique challenges in integrating heterogeneous knowledge sources while ensuring both accuracy and safety. Existing large language models often struggle with factual consistency and context alignment in sensitive domains such as healthcare policies and government welfare. In this work, we introduce Knowledge-Aware Reasoning and Memory-Augmented Adaptation (KARMA), a novel framework designed to enhance QA performance in care scenarios. KARMA incorporates a dual-encoder architecture to fuse structured and unstructured knowledge sources, a gated memory unit to dynamically regulate external knowledge integration, and a safety-aware controllable decoder that mitigates unsafe outputs using safety classification and guided generation techniques. Extensive experiments on a proprietary QA dataset demonstrate that KARMA outperforms strong baselines in both answer quality and safety. This study offers a comprehensive solution for building trustworthy and adaptive QA systems in service contexts.",
          "authors": [
            "Lei Fu",
            "Xiang Chen",
            "Kaige Gao Xinyue Huang",
            "Kejian Tong"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02364",
          "title": "Tackling Tuberculosis: A Comparative Dive into Machine Learning for Tuberculosis Detection",
          "abstract": "This study explores the application of machine learning models, specifically a pretrained ResNet-50 model and a general SqueezeNet model, in diagnosing tuberculosis (TB) using chest X-ray images. TB, a persistent infectious disease affecting humanity for millennia, poses challenges in diagnosis, especially in resource-limited settings. Traditional methods, such as sputum smear microscopy and culture, are inefficient, prompting the exploration of advanced technologies like deep learning and computer vision. The study utilized a dataset from Kaggle, consisting of 4,200 chest X-rays, to develop and compare the performance of the two machine learning models. Preprocessing involved data splitting, augmentation, and resizing to enhance training efficiency. Evaluation metrics, including accuracy, precision, recall, and confusion matrix, were employed to assess model performance. Results showcase that the SqueezeNet achieved a loss of 32%, accuracy of 89%, precision of 98%, recall of 80%, and an F1 score of 87%. In contrast, the ResNet-50 model exhibited a loss of 54%, accuracy of 73%, precision of 88%, recall of 52%, and an F1 score of 65%. This study emphasizes the potential of machine learning in TB detection and possible implications for early identification and treatment initiation. The possibility of integrating such models into mobile devices expands their utility in areas lacking TB detection resources. However, despite promising results, the need for continued development of faster, smaller, and more accurate TB detection models remains crucial in contributing to the global efforts in combating TB.",
          "authors": [
            "Daanish Hindustani",
            "Sanober Hindustani",
            "Preston Nguyen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02368",
          "title": "Multi-Domain Enhanced Map-Free Trajectory Prediction with Selective Attention",
          "abstract": "Trajectory prediction is crucial for the reliability and safety of autonomous driving systems, yet it remains a challenging task in complex interactive scenarios. Existing methods often struggle to efficiently extract valuable scene information from redundant data, thereby reducing computational efficiency and prediction accuracy, especially when dealing with intricate agent interactions. To address these challenges, we propose a novel map-free trajectory prediction algorithm that achieves trajectory prediction across the temporal, spatial, and frequency domains. Specifically, in temporal information processing, We utilize a Mixture of Experts (MoE) mechanism to adaptively select critical frequency components. Concurrently, we extract these components and integrate multi-scale temporal features. Subsequently, a selective attention module is proposed to filter out redundant information in both temporal sequences and spatial interactions. Finally, we design a multimodal decoder. Under the supervision of patch-level and point-level losses, we obtain reasonable trajectory results. Experiments on Nuscences datasets demonstrate the superiority of our algorithm, validating its effectiveness in handling complex interactive scenarios.",
          "authors": [
            "Wenyi Xiong",
            "Jian Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02369",
          "title": "SAGE: Style-Adaptive Generalization for Privacy-Constrained Semantic Segmentation Across Domains",
          "abstract": "Domain generalization for semantic segmentation aims to mitigate the degradation in model performance caused by domain shifts. However, in many real-world scenarios, we are unable to access the model parameters and architectural details due to privacy concerns and security constraints. Traditional fine-tuning or adaptation is hindered, leading to the demand for input-level strategies that can enhance generalization without modifying model weights. To this end, we propose a \\textbf{S}tyle-\\textbf{A}daptive \\textbf{GE}neralization framework (\\textbf{SAGE}), which improves the generalization of frozen models under privacy constraints. SAGE learns to synthesize visual prompts that implicitly align feature distributions across styles instead of directly fine-tuning the backbone. Specifically, we first utilize style transfer to construct a diverse style representation of the source domain, thereby learning a set of style characteristics that can cover a wide range of visual features. Then, the model adaptively fuses these style cues according to the visual context of each input, forming a dynamic prompt that harmonizes the image appearance without touching the interior of the model. Through this closed-loop design, SAGE effectively bridges the gap between frozen model invariance and the diversity of unseen domains. Extensive experiments on five benchmark datasets demonstrate that SAGE achieves competitive or superior performance compared to state-of-the-art methods under privacy constraints and outperforms full fine-tuning baselines in all settings.",
          "authors": [
            "Qingmei Li",
            "Yang Zhang",
            "Peifeng Zhang",
            "Haohuan Fu",
            "Juepeng Zheng"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02371",
          "title": "Pushing Tensor Accelerators Beyond MatMul in a User-Schedulable Language",
          "abstract": "Tensor accelerators now represent a growing share of compute resources in modern CPUs and GPUs. However, they are hard to program, leading developers to use vendor-provided kernel libraries that support tensor accelerators. As a result, the usage of tensor accelerators is limited to the provided interface, mainly designed for traditional ML and scientific computing workloads. In this paper, we show that tensor accelerators can improve the performance of applications beyond simple variants of MatMul. For example, many image processing pipelines are linear transformations over matrices in disguise and can therefore utilize such specialized hardware. This is nonetheless hindered by the difficulties in programming tensor accelerators. We tackle this problem with compiler-based techniques. We use the Halide user-schedulable language and express operations as Halide algorithms succinctly. To this end, we implement a flexible tensor instruction selector based on equality saturation. The tensor instruction selector supports both CPU- and GPU-attached tensor accelerators and works with existing scheduling operations (e.g., producer-consumer fusion). Together, this enables developers to write diverse accelerator-leveraging applications in a few dozen lines. Using our system, we demonstrate the potential of tensor accelerators beyond their traditional domains. We implement several image processing pipelines (e.g., filtering, resampling, and denoising) in our system and evaluate them against non-accelerator-leveraging baselines. We show that these pipelines can achieve significant speedups. For example, a downsampling routine is sped up by $6.1\\times$ by utilizing Tensor Cores on an Nvidia RTX 4070 GPU.",
          "authors": [
            "Yihong Zhang",
            "Derek Gerstmann",
            "Andrew Adams",
            "Maaz Bin Safeer Ahmad"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02375",
          "title": "On-the-fly Feedback SfM: Online Explore-and-Exploit UAV Photogrammetry with Incremental Mesh Quality-Aware Indicator and Predictive Path Planning",
          "abstract": "Compared with conventional offline UAV photogrammetry, real-time UAV photogrammetry is essential for time-critical geospatial applications such as disaster response and active digital-twin maintenance. However, most existing methods focus on processing captured images or sequential frames in real time, without explicitly evaluating the quality of the on-the-go 3D reconstruction or providing guided feedback to enhance image acquisition in the target area. This work presents On-the-fly Feedback SfM, an explore-and-exploit framework for real-time UAV photogrammetry, enabling iterative exploration of unseen regions and exploitation of already observed and reconstructed areas in near real time. Built upon SfM on-the-fly , the proposed method integrates three modules: (1) online incremental coarse-mesh generation for dynamically expanding sparse 3D point cloud; (2) online mesh quality assessment with actionable indicators; and (3) predictive path planning for on-the-fly trajectory refinement. Comprehensive experiments demonstrate that our method achieves in-situ reconstruction and evaluation in near real time while providing actionable feedback that markedly reduces coverage gaps and re-flight costs. Via the integration of data collection, processing, 3D reconstruction and assessment, and online feedback, our on the-fly feedback SfM could be an alternative for the transition from traditional passive working mode to a more intelligent and adaptive exploration workflow. Code is now available at this https URL .",
          "authors": [
            "Liyuan Lou",
            "Wanyun Li",
            "Wentian Gan",
            "Yifei Yu",
            "Tengfei Wang",
            "Xin Wang",
            "Zongqian Zhan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02383",
          "title": "Reinforcement Learning in POMDP's via Direct Gradient Ascent",
          "abstract": "This paper discusses theoretical and experimental aspects of gradient-based approaches to the direct optimization of policy performance in controlled POMDPs. We introduce GPOMDP, a REINFORCE-like algorithm for estimating an approximation to the gradient of the average reward as a function of the parameters of a stochastic policy. The algorithm's chief advantages are that it requires only a single sample path of the underlying Markov chain, it uses only one free parameter $\\beta\\in [0,1)$, which has a natural interpretation in terms of bias-variance trade-off, and it requires no knowledge of the underlying state. We prove convergence of GPOMDP and show how the gradient estimates produced by GPOMDP can be used in a conjugate-gradient procedure to find local optima of the average reward.",
          "authors": [
            "Jonathan Baxter",
            "Peter L. Bartlett"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02384",
          "title": "Markov Chains Approximate Message Passing",
          "abstract": "Markov chain Monte Carlo algorithms have long been observed to obtain near-optimal performance in various Bayesian inference settings. However, developing a supporting theory that make these studies rigorous has proved challenging. In this paper, we study the classical spiked Wigner inference problem, where one aims to recover a planted Boolean spike from a noisy matrix measurement. We relate the recovery performance of Glauber dynamics on the annealed posterior to the performance of Approximate Message Passing (AMP), which is known to achieve Bayes-optimal performance. Our main results rely on the analysis of an auxiliary Markov chain called restricted Gaussian dynamics (RGD). Concretely, we establish the following results: 1. RGD can be reduced to an effective one-dimensional recursion which mirrors the evolution of the AMP iterates. 2. From a warm start, RGD rapidly converges to a fixed point in correlation space, which recovers Bayes-optimal performance when run on the posterior. 3. Conditioned on widely believed mixing results for the SK model, we recover the phase transition for non-trivial inference.",
          "authors": [
            "Amit Rajaraman",
            "David X. Wu"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02384",
          "title": "Markov Chains Approximate Message Passing",
          "abstract": "Markov chain Monte Carlo algorithms have long been observed to obtain near-optimal performance in various Bayesian inference settings. However, developing a supporting theory that make these studies rigorous has proved challenging. In this paper, we study the classical spiked Wigner inference problem, where one aims to recover a planted Boolean spike from a noisy matrix measurement. We relate the recovery performance of Glauber dynamics on the annealed posterior to the performance of Approximate Message Passing (AMP), which is known to achieve Bayes-optimal performance. Our main results rely on the analysis of an auxiliary Markov chain called restricted Gaussian dynamics (RGD). Concretely, we establish the following results: 1. RGD can be reduced to an effective one-dimensional recursion which mirrors the evolution of the AMP iterates. 2. From a warm start, RGD rapidly converges to a fixed point in correlation space, which recovers Bayes-optimal performance when run on the posterior. 3. Conditioned on widely believed mixing results for the SK model, we recover the phase transition for non-trivial inference.",
          "authors": [
            "Amit Rajaraman",
            "David X. Wu"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02389",
          "title": "Synthetic Error Injection Fails to Elicit Self-Correction In Language Models",
          "abstract": "Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.",
          "authors": [
            "David X. Wu",
            "Shreyas Kapur",
            "Anant Sahai",
            "Stuart Russell"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02392",
          "title": "From Detection to Association: Learning Discriminative Object Embeddings for Multi-Object Tracking",
          "abstract": "End-to-end multi-object tracking (MOT) methods have recently achieved remarkable progress by unifying detection and association within a single framework. Despite their strong detection performance, these methods suffer from relatively low association accuracy. Through detailed analysis, we observe that object embeddings produced by the shared DETR architecture display excessively high inter-object similarity, as it emphasizes only category-level discrimination within single frames. In contrast, tracking requires instance-level distinction across frames with spatial and temporal continuity, for which current end-to-end approaches insufficiently optimize object embeddings. To address this, we introduce FDTA (From Detection to Association), an explicit feature refinement framework that enhances object discriminativeness across three complementary perspectives. Specifically, we introduce a Spatial Adapter (SA) to integrate depth-aware cues for spatial continuity, a Temporal Adapter (TA) to aggregate historical information for temporal dependencies, and an Identity Adapter (IA) to leverage quality-aware contrastive learning for instance-level separability. Extensive experiments demonstrate that FDTA achieves state-of-the-art performance on multiple challenging MOT benchmarks, including DanceTrack, SportsMOT, and BFT, highlighting the effectiveness of our proposed discriminative embedding enhancement strategy. The code is available at this https URL .",
          "authors": [
            "Yuqing Shao",
            "Yuchen Yang",
            "Rui Yu",
            "Weilong Li",
            "Xu Guo",
            "Huaicheng Yan",
            "Wei Wang",
            "Xiao Sun"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02393",
          "title": "Process-Centric Analysis of Agentic Software Systems",
          "abstract": "Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success. Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.",
          "authors": [
            "Shuyang Liu",
            "Yang Chen",
            "Rahul Krishna",
            "Saurabh Sinha",
            "Jatin Ganhotra",
            "Reyhan Jabbarvand"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02394",
          "title": "Reproducing and Extending RaDelft 4D Radar with Camera-Assisted Labels",
          "abstract": "Recent advances in 4D radar highlight its potential for robust environment perception under adverse conditions, yet progress in radar semantic segmentation remains constrained by the scarcity of open source datasets and labels. The RaDelft data set, although seminal, provides only LiDAR annotations and no public code to generate radar labels, limiting reproducibility and downstream research. In this work, we reproduce the numerical results of the RaDelft group and demonstrate that a camera-guided radar labeling pipeline can generate accurate labels for radar point clouds without relying on human annotations. By projecting radar point clouds into camera-based semantic segmentation and applying spatial clustering, we create labels that significantly enhance the accuracy of radar labels. These results establish a reproducible framework that allows the research community to train and evaluate the labeled 4D radar data. In addition, we study and quantify how different fog levels affect the radar labeling performance.",
          "authors": [
            "Kejia Hu",
            "Mohammed Alsakabi",
            "John M. Dolan",
            "Ozan K. Tonguz"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02395",
          "title": "Skywork-R1V4: Toward Agentic Multimodal Intelligence through Interleaved Thinking with Images and DeepResearch",
          "abstract": "Despite recent progress in multimodal agentic systems, existing approaches often treat image manipulation and web search as disjoint capabilities, rely heavily on costly reinforcement learning, and lack planning grounded in real tool-execution traces. To address these limitations, we present Skywork-R1V4, a 30B (A3B) parameter multimodal agentic model that unifies multimodal planning, active image manipulation (\"thinking with images\"), deep multimodal search, and, most critically, interleaved reasoning that dynamically alternates between visual operations and external knowledge retrieval. Trained solely via supervised fine-tuning on fewer than 30,000 high-quality, planning-execution-consistent trajectories and validated through stepwise consistency filtering, Skywork-R1V4 achieves state-of-the-art results across perception and multimodal search benchmarks: it scores 66.1 on MMSearch and 67.2 on FVQA, surpassing Gemini 2.5 Flash on all 11 metrics. Skywork-R1V4 exhibits emergent long-horizon reasoning at inference time, successfully orchestrating more than 10 tool calls to solve complex, multi-step tasks. Our results demonstrate that sophisticated agentic multimodal intelligence can be achieved through carefully curated supervised learning alone, without any reliance on reinforcement learning.",
          "authors": [
            "Yifan Zhang",
            "Liang Hu",
            "Haofeng Sun",
            "Peiyu Wang",
            "Yichen Wei",
            "Shukang Yin",
            "Jiangbo Pei",
            "Wei Shen",
            "Peng Xia",
            "Yi Peng",
            "Tianyidan Xie",
            "Eric Li",
            "Yang Liu",
            "Xuchen Song",
            "Yahui Zhou"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02397",
          "title": "Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance",
          "abstract": "We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.",
          "authors": [
            "Emanuele Bossi",
            "C. Tyler Diggans",
            "Abd AlRahman R. AlMomani"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02397",
          "title": "Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance",
          "abstract": "We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.",
          "authors": [
            "Emanuele Bossi",
            "C. Tyler Diggans",
            "Abd AlRahman R. AlMomani"
          ],
          "primary_category": "cs.IT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02399",
          "title": "AtomGraph: Tackling Atomicity Violation in Smart Contracts using Multimodal GCNs",
          "abstract": "Smart contracts are a core component of blockchain technology and are widely deployed across various scenarios. However, atomicity violations have become a potential security risk. Existing analysis tools often lack the precision required to detect these issues effectively. To address this challenge, we introduce AtomGraph, an automated framework designed for detecting atomicity violations. This framework leverages Graph Convolutional Networks (GCN) to identify atomicity violations through multimodal feature learning and fusion. Specifically, driven by a collaborative learning mechanism, the model simultaneously learns from two heterogeneous modalities: extracting structural topological features from the contract's Control Flow Graph (CFG) and uncovering deep semantics from its opcode sequence. We designed an adaptive weighted fusion mechanism to dynamically adjust the weights of features from each modality to achieve optimal feature fusion. Finally, GCN detects graph-level atomicity violation on the contract. Comprehensive experimental evaluations demonstrate that AtomGraph achieves 96.88% accuracy and 96.97% F1 score, outperforming existing tools. Furthermore, compared to the concatenation fusion model, AtomGraph improves the F1 score by 6.4%, proving its potential in smart contract security detection.",
          "authors": [
            "Xiaoqi Li",
            "Zongwei Li",
            "Wenkai Li",
            "Zeng Zhang",
            "Lei Xie"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02400",
          "title": "Nav-$R^2$ Dual-Relation Reasoning for Generalizable Open-Vocabulary Object-Goal Navigation",
          "abstract": "Object-goal navigation in open-vocabulary settings requires agents to locate novel objects in unseen environments, yet existing approaches suffer from opaque decision-making processes and low success rate on locating unseen objects. To address these challenges, we propose Nav-$R^2$, a framework that explicitly models two critical types of relationships, target-environment modeling and environment-action planning, through structured Chain-of-Thought (CoT) reasoning coupled with a Similarity-Aware Memory. We construct a Nav$R^2$-CoT dataset that teaches the model to perceive the environment, focus on target-related objects in the surrounding context and finally make future action plans. Our SA-Mem preserves the most target-relevant and current observation-relevant features from both temporal and semantic perspectives by compressing video frames and fusing historical observations, while introducing no additional parameters. Compared to previous methods, Nav-R^2 achieves state-of-the-art performance in localizing unseen objects through a streamlined and efficient pipeline, avoiding overfitting to seen object categories while maintaining real-time inference at 2Hz. Resources will be made publicly available at \\href{ this https URL }{github link}.",
          "authors": [
            "Wentao Xiang",
            "Haokang Zhang",
            "Tianhang Yang",
            "Zedong Chu",
            "Ruihang Chu",
            "Shichao Xie",
            "Yujian Yuan",
            "Jian Sun",
            "Zhining Gu",
            "Junjie Wang",
            "Xiaolong Wu",
            "Mu Xu",
            "Yujiu Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02402",
          "title": "TaleFrame: An Interactive Story Generation System with Fine-Grained Control and Large Language Models",
          "abstract": "With the advancement of natural language generation (NLG) technologies, creative story generation systems have gained increasing attention. However, current systems often fail to accurately translate user intent into satisfactory story outputs due to a lack of fine-grained control and unclear input specifications, limiting their applicability. To address this, we propose TaleFrame, a system that combines large language models (LLMs) with human-computer interaction (HCI) to generate stories through structured information, enabling precise control over the generation process. The innovation of TaleFrame lies in decomposing the story structure into four basic units: entities, events, relationships, and story outline. We leverage the Tinystories dataset, parsing and constructing a preference dataset consisting of 9,851 JSON-formatted entries, which is then used to fine-tune a local Llama model. By employing this JSON2Story approach, structured data is transformed into coherent stories. TaleFrame also offers an intuitive interface that supports users in creating and editing entities and events and generates stories through the structured framework. Users can control these units through simple interactions (e.g., drag-and-drop, attach, and connect), thus influencing the details and progression of the story. The generated stories can be evaluated across seven dimensions (e.g., creativity, structural integrity), with the system providing suggestions for refinement based on these evaluations. Users can iteratively adjust the story until a satisfactory result is achieved. Finally, we conduct quantitative evaluation and user studies that demonstrate the usefulness of TaleFrame. Dataset available at this https URL .",
          "authors": [
            "Yunchao Wang",
            "Guodao Sun",
            "Zihang Fu",
            "Zhehao Liu",
            "Kaixing Du",
            "Haidong Gao",
            "Ronghua Liang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02403",
          "title": "ESACT: An End-to-End Sparse Accelerator for Compute-Intensive Transformers via Local Similarity",
          "abstract": "Transformers, composed of QKV generation, attention computation, and FFNs, have become the dominant model across various domains due to their outstanding performance. However, their high computational cost hinders efficient hardware deployment. Sparsity offers a promising solution, yet most existing accelerators exploit only intra-row sparsity in attention, while few consider inter-row sparsity. Approaches leveraging inter-row sparsity often rely on costly global similarity estimation, which diminishes the acceleration benefits of sparsity, and typically apply sparsity to only one or two transformer components. Through careful analysis of the attention distribution and computation flow, we observe that local similarity allows end-to-end sparse acceleration with lower computational overhead. Motivated by this observation, we propose ESACT, an end-to-end sparse accelerator for compute-intensive Transformers. ESACT centers on the Sparsity Prediction with Local Similarity (SPLS) mechanism, which leverages HLog quantization to accurately predict local attention sparsity prior to QK generation, achieving efficient sparsity across all transformer components. To support efficient hardware realization, we introduce three architectural innovations. Experimental results on 26 benchmarks demonstrate that SPLS reduces total computation by 52.03% with less than 1% accuracy loss. ESACT achieves an end-to-end energy efficiency of 3.29 TOPS/W, and improves attention-level energy efficiency by 2.95x and 2.26x over SOTA attention accelerators SpAtten and Sanger, respectively.",
          "authors": [
            "Hongxiang Liu",
            "Zhifang Deng",
            "Tong Pu",
            "Shengli Lu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02405",
          "title": "WISE: Weighted Iterative Society-of-Experts for Robust Multimodal Multi-Agent Debate",
          "abstract": "Recent large language models (LLMs) are trained on diverse corpora and tasks, leading them to develop complementary strengths. Multi-agent debate (MAD) has emerged as a popular way to leverage these strengths for robust reasoning, though it has mostly been applied to language-only tasks, leaving its efficacy on multimodal problems underexplored. In this paper, we study MAD for solving vision-and-language reasoning problems. Our setup enables generalizing the debate protocol with heterogeneous experts that possess single- and multi-modal capabilities. To this end, we present Weighted Iterative Society-of-Experts (WISE), a generalized and modular MAD framework that partitions the agents into Solvers, that generate solutions, and Reflectors, that verify correctness, assign weights, and provide natural language feedback. To aggregate the agents' solutions across debate rounds, while accounting for variance in their responses and the feedback weights, we present a modified Dawid-Skene algorithm for post-processing that integrates our two-stage debate model. We evaluate WISE on SMART-840, VisualPuzzles, EvoChart-QA, and a new SMART-840++ dataset with programmatically generated problem instances of controlled difficulty. Our results show that WISE consistently improves accuracy by 2-7% over the state-of-the-art MAD setups and aggregation methods across diverse multimodal tasks and LLM configurations.",
          "authors": [
            "Anoop Cherian",
            "River Doyle",
            "Eyal Ben-Dov",
            "Suhas Lohit",
            "Kuan-Chuan Peng"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02408",
          "title": "A unified framework for equation discovery and dynamic prediction of hysteretic systems",
          "abstract": "Hysteresis is a nonlinear phenomenon with memory effects, where a system's output depends on both its current state and past states. It is prevalent in various physical and mechanical systems, such as yielding structures under seismic excitation, ferromagnetic materials, and piezoelectric actuators. Analytical models like the Bouc-Wen model are often employed but rely on idealized assumptions and careful parameter calibration, limiting their applicability to diverse or mechanism-unknown behaviors. Existing equation discovery approaches for hysteresis are often system-specific or rely on predefined model libraries, which limit their flexibility and ability to capture the hidden mechanisms. To address these, this research develops a unified framework that integrates learning of internal variables (commonly used in modeling hysteresis) and symbolic regression to automatically extract internal hysteretic variable, and discover explicit governing equations directly from data without predefined libraries as required by methods such as sparse identification of nonlinear dynamics (SINDy). Solving the discovered equations naturally enables prediction of the dynamic responses of hysteretic systems. This work provides a systematic view and approach for both equation discovery and characterization of hysteretic dynamics, defining a unified framework for these types of problems.",
          "authors": [
            "Siyuan Yang",
            "Wei Liu",
            "Zhilu Lai"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02409",
          "title": "Data Curation Through the Lens of Spectral Dynamics: Static Limits, Dynamic Acceleration, and Practical Oracles",
          "abstract": "Large-scale neural models are increasingly trained with data pruning, synthetic data generation, cross-model distillation, reinforcement learning from human feedback (RLHF), and difficulty-based sampling. While several of these data-centric strategies reliably improve training efficiency and downstream performance, others fail to provide meaningful gains -- most notably self-generated synthetic data, which often increases dataset volume without enhancing model capability. We formalize data curation as reweighting the sampling distribution and map its effect onto the eigenstructure of the data-induced operator. Our first main result shows that \\textbf{static pruning induces a bounded operator and therefore cannot change the spectral tail exponent}; it provides at most finite-region improvements and cannot alter asymptotic neural scaling. Our second result analyzes \\textbf{time-dependent data curation}, showing that an ideal oracle capable of tracking spectral residuals and continuously re-normalizing the tail can provably accelerate learning -- although practical systems can only approximate this behavior.",
          "authors": [
            "Yizhou Zhang",
            "Lun Du"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02410",
          "title": "Decentralized Multi-Agent System with Trust-Aware Communication",
          "abstract": "The emergence of Large Language Models (LLMs) is rapidly accelerating the development of autonomous multi-agent systems (MAS), paving the way for the Internet of Agents. However, traditional centralized MAS architectures present significant challenges, including single points of failure, vulnerability to censorship, inherent scalability limitations, and critical trust issues. We propose a novel Decentralized Multi-Agent System (DMAS) architecture designed to overcome these fundamental problems by enabling trust-aware, scalable, and censorship-resistant interactions among autonomous agents. Our DMAS features a decentralized agent runtime underpinned by a blockchain-based architecture. We formalize a trust-aware communication protocol that leverages cryptographic primitives and on-chain operations to provide security properties: verifiable interaction cycles, communication integrity, authenticity, non-repudiation, and conditional confidentiality, which we further substantiate through a comprehensive security analysis. Our performance analysis validates the DMAS as a scalable and efficient solution for building trustworthy multi-agent systems.",
          "authors": [
            "Yepeng Ding",
            "Ahmed Twabi",
            "Junwei Yu",
            "Lingfeng Zhang",
            "Tohru Kondo",
            "Hiroyuki Sato"
          ],
          "primary_category": "cs.MA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02413",
          "title": "MitUNet: Enhancing Floor Plan Recognition using a Hybrid Mix-Transformer and U-Net Architecture",
          "abstract": "Automatic 3D reconstruction of indoor spaces from 2D floor plans requires high-precision semantic segmentation of structural elements, particularly walls. However, existing methods optimized for standard metrics often struggle to detect thin structural components and yield masks with irregular boundaries, lacking the geometric precision required for subsequent vectorization. To address this issue, we introduce MitUNet, a hybrid neural network architecture specifically designed for wall segmentation tasks in the context of 3D modeling. In MitUNet, we utilize a hierarchical Mix-Transformer encoder to capture global context and a U-Net decoder enhanced with scSE attention blocks for precise boundary recovery. Furthermore, we propose an optimization strategy based on the Tversky loss function to effectively balance precision and recall. By fine-tuning the hyperparameters of the loss function, we prioritize the suppression of false positive noise along wall boundaries while maintaining high sensitivity to thin structures. Our experiments on the public CubiCasa5k dataset and a proprietary regional dataset demonstrate that the proposed approach ensures the generation of structurally correct masks with high boundary accuracy, outperforming standard single-task models. MitUNet provides a robust tool for data preparation in automated 3D reconstruction pipelines.",
          "authors": [
            "Dmitriy Parashchuk",
            "Alexey Kapshitskiy",
            "Yuriy Karyakin"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02414",
          "title": "Characterizing Cyber Attacks against Space Infrastructures with Missing Data: Framework and Case Study",
          "abstract": "Cybersecurity of space infrastructures is an emerging topic, despite space-related cybersecurity incidents occurring as early as 1977 (i.e., hijacking of a satellite transmission signal). There is no single dataset that documents cyber attacks against space infrastructures that have occurred in the past; instead, these incidents are often scattered in media reports while missing many details, which we dub the missing-data problem. Nevertheless, even ``low-quality'' datasets containing such reports would be extremely valuable because of the dearth of space cybersecurity data and the sensitivity of space infrastructures which are often restricted from disclosure by governments. This prompts a research question: How can we characterize real-world cyber attacks against space infrastructures? In this paper, we address the problem by proposing a framework, including metrics, while also addressing the missing-data problem by leveraging methodologies such as the Space Attack Research and Tactic Analysis (SPARTA) and the Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) to ``extrapolate'' the missing data in a principled fashion. We show how the extrapolated data can be used to reconstruct ``hypothetical but plausible'' space cyber kill chains and space cyber attack campaigns that have occurred in practice. To show the usefulness of the framework, we extract data for 108 cyber attacks against space infrastructures and show how to extrapolate this ``low-quality'' dataset containing missing information to derive 6,206 attack technique-level space cyber kill chains. Our findings include: cyber attacks against space infrastructures are getting increasingly sophisticated; successful protection of the link segment between the space and user segments could have thwarted nearly half of the 108 attacks. We will make our dataset available.",
          "authors": [
            "Ekzhin Ear",
            "Jose Luis Castanon Remy",
            "Caleb Chang",
            "Qiren Que",
            "Antonia Feffer",
            "Shouhuai Xu"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02416",
          "title": "Localizing Preference Aggregation Conflicts: A Graph-Theoretic Approach Using Sheaves",
          "abstract": "We introduce a graph-theoretic framework based on discrete sheaves to diagnose and localize inconsistencies in preference aggregation. Unlike traditional linearization methods (e.g., HodgeRank), this approach preserves the discrete structure of ordinal preferences, identifying which specific voter interactions cause aggregation failure -- information that global methods cannot provide -- via the Obstruction Locus. We formalize the Incompatibility Index to quantify these local conflicts and examine their behavior under stochastic variations using the Mallows model. Additionally, we develop a rigorous sheaf-theoretic pushforward operation to model voter merging, implemented via a polynomial-time constraint DAG algorithm. We demonstrate that graph quotients transform distributed edge conflicts into local impossibilities (empty stalks), providing a topological characterization of how aggregation paradoxes persist across scales.",
          "authors": [
            "Karen Sargsyan"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02416",
          "title": "Localizing Preference Aggregation Conflicts: A Graph-Theoretic Approach Using Sheaves",
          "abstract": "We introduce a graph-theoretic framework based on discrete sheaves to diagnose and localize inconsistencies in preference aggregation. Unlike traditional linearization methods (e.g., HodgeRank), this approach preserves the discrete structure of ordinal preferences, identifying which specific voter interactions cause aggregation failure -- information that global methods cannot provide -- via the Obstruction Locus. We formalize the Incompatibility Index to quantify these local conflicts and examine their behavior under stochastic variations using the Mallows model. Additionally, we develop a rigorous sheaf-theoretic pushforward operation to model voter merging, implemented via a polynomial-time constraint DAG algorithm. We demonstrate that graph quotients transform distributed edge conflicts into local impossibilities (empty stalks), providing a topological characterization of how aggregation paradoxes persist across scales.",
          "authors": [
            "Karen Sargsyan"
          ],
          "primary_category": "econ.TH",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02417",
          "title": "Vehicle Dynamics Embedded World Models for Autonomous Driving",
          "abstract": "World models have gained significant attention as a promising approach for autonomous driving. By emulating human-like perception and decision-making processes, these models can predict and adapt to dynamic environments. Existing methods typically map high-dimensional observations into compact latent spaces and learn optimal policies within these latent representations. However, prior work usually jointly learns ego-vehicle dynamics and environmental transition dynamics from the image input, leading to inefficiencies and a lack of robustness to variations in vehicle dynamics. To address these issues, we propose the Vehicle Dynamics embedded Dreamer (VDD) method, which decouples the modeling of ego-vehicle dynamics from environmental transition dynamics. This separation allows the world model to generalize effectively across vehicles with diverse parameters. Additionally, we introduce two strategies to further enhance the robustness of the learned policy: Policy Adjustment during Deployment (PAD) and Policy Augmentation during Training (PAT). Comprehensive experiments in simulated environments demonstrate that the proposed model significantly improves both driving performance and robustness to variations in vehicle dynamics, outperforming existing approaches.",
          "authors": [
            "Huiqian Li",
            "Wei Pan",
            "Haodong Zhang",
            "Jin Huang",
            "Zhihua Zhong"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02418",
          "title": "Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins",
          "abstract": "Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).",
          "authors": [
            "Yuexin Xiang",
            "Yuchen Lei",
            "SM Mahir Shazeed Rish",
            "Yuanzhe Zhang",
            "Qin Wang",
            "Tsz Hon Yuen",
            "Jiangshan Yu"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02419",
          "title": "The brain-AI convergence: Predictive and generative world models for general-purpose computation",
          "abstract": "Recent advances in general-purpose AI systems with attention-based transformers offer a potential window into how the neocortex and cerebellum, despite their relatively uniform circuit architectures, give rise to diverse functions and, ultimately, to human intelligence. This Perspective provides a cross-domain comparison between the brain and AI that goes beyond the traditional focus on visual processing, adopting the emerging perspecive of world-model-based computation. Here, we identify shared computational mechanisms in the attention-based neocortex and the non-attentional cerebellum: both predict future world events from past inputs and construct internal world models through prediction-error learning. These predictive world models are repurposed for seemingly distinct functions--understanding in sensory processing and generation in motor processing-- enabling the brain to achieve multi-domain capabilities and human-like adaptive intelligence. Notably, attention-based AI has independently converged on a similar learning paradigm and world-model-based computation. We conclude that these shared mechanisms in both biological and artificial systems constitute a core computational foundation for realizing diverse functions including high-level intelligence, despite their relatively uniform circuit structures. Our theoretical insights bridge neuroscience and AI, advancing our understanding of the computational essence of intelligence.",
          "authors": [
            "Shogo Ohmae",
            "Keiko Ohmae"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02419",
          "title": "The brain-AI convergence: Predictive and generative world models for general-purpose computation",
          "abstract": "Recent advances in general-purpose AI systems with attention-based transformers offer a potential window into how the neocortex and cerebellum, despite their relatively uniform circuit architectures, give rise to diverse functions and, ultimately, to human intelligence. This Perspective provides a cross-domain comparison between the brain and AI that goes beyond the traditional focus on visual processing, adopting the emerging perspecive of world-model-based computation. Here, we identify shared computational mechanisms in the attention-based neocortex and the non-attentional cerebellum: both predict future world events from past inputs and construct internal world models through prediction-error learning. These predictive world models are repurposed for seemingly distinct functions--understanding in sensory processing and generation in motor processing-- enabling the brain to achieve multi-domain capabilities and human-like adaptive intelligence. Notably, attention-based AI has independently converged on a similar learning paradigm and world-model-based computation. We conclude that these shared mechanisms in both biological and artificial systems constitute a core computational foundation for realizing diverse functions including high-level intelligence, despite their relatively uniform circuit structures. Our theoretical insights bridge neuroscience and AI, advancing our understanding of the computational essence of intelligence.",
          "authors": [
            "Shogo Ohmae",
            "Keiko Ohmae"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02421",
          "title": "Generalizing Vision-Language Models with Dedicated Prompt Guidance",
          "abstract": "Fine-tuning large pretrained vision-language models (VLMs) has emerged as a prevalent paradigm for downstream adaptation, yet it faces a critical trade-off between domain specificity and domain generalization (DG) ability. Current methods typically fine-tune a universal model on the entire dataset, which potentially compromises the ability to generalize to unseen domains. To fill this gap, we provide a theoretical understanding of the generalization ability for VLM fine-tuning, which reveals that training multiple parameter-efficient expert models on partitioned source domains leads to better generalization than fine-tuning a universal model. Inspired by this finding, we propose a two-step domain-expert-Guided DG (GuiDG) framework. GuiDG first employs prompt tuning to obtain source domain experts, then introduces a Cross-Modal Attention module to guide the fine-tuning of the vision encoder via adaptive expert integration. To better evaluate few-shot DG, we construct ImageNet-DG from ImageNet and its variants. Extensive experiments on standard DG benchmarks and ImageNet-DG demonstrate that GuiDG improves upon state-of-the-art fine-tuning methods while maintaining efficiency.",
          "authors": [
            "Xinyao Li",
            "Yinjie Min",
            "Hongbo Chen",
            "Zhekai Du",
            "Fengling Li",
            "Jingjing Li"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02423",
          "title": "GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning",
          "abstract": "With the rapid development of Large Vision Language Models, the focus of Graphical User Interface (GUI) agent tasks shifts from single-screen tasks to complex screen navigation challenges. However, real-world GUI environments, such as PC software and mobile Apps, are often complex and proprietary, making it difficult to obtain the comprehensive environment information needed for agent training and evaluation. This limitation hinders systematic investigation and benchmarking of agent navigation capabilities. To address this limitation, we introduce GUI Exploration Lab, a simulation environment engine for GUI agent navigation research that enables flexible definition and composition of screens, icons, and navigation graphs, while providing full access to environment information for comprehensive agent training and evaluation. Through extensive experiments, we find that supervised fine-tuning enables effective memorization of fundamental knowledge, serving as a crucial foundation for subsequent training. Building on this, single-turn reinforcement learning further enhances generalization to unseen scenarios. Finally, multi-turn reinforcement learning encourages the development of exploration strategies through interactive trial and error, leading to further improvements in screen navigation performance. We validate our methods on both static and interactive benchmarks, demonstrating that our findings generalize effectively to real-world scenarios. These findings demonstrate the advantages of reinforcement learning approaches in GUI navigation and offer practical guidance for building more capable and generalizable GUI agents.",
          "authors": [
            "Haolong Yan",
            "Yeqing Shen",
            "Xin Huang",
            "Jia Wang",
            "Kaijun Tan",
            "Zhixuan Liang",
            "Hongxin Li",
            "Zheng Ge",
            "Osamu Yoshie",
            "Si Li",
            "Xiangyu Zhang",
            "Daxin Jiang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02424",
          "title": "Optimal Comprehensible Targeting",
          "abstract": "Developments in machine learning and big data allow firms to fully personalize and target their marketing mix. However, data and privacy regulations, such as those in the European Union (GDPR), incorporate a \"right to explanation,\" which is fulfilled when targeting policies are comprehensible to customers. This paper provides a framework for firms to navigate right-to-explanation legislation. First, I construct a class of comprehensible targeting policies that is represented by a sentence. Second, I show how to optimize over this class of policies to find the profit-maximizing comprehensible policy. I further demonstrate that it is optimal to estimate the comprehensible policy directly from the data, rather than projecting down the black box policy into a comprehensible policy. Third, I find the optimal black box targeting policy and compare it to the optimal comprehensible policy. I then empirically apply my framework using data from a price promotion field experiment from a durable goods retailer. I quantify the cost of explanation, which I define as the difference in expected profits between the optimal black box and comprehensible targeting policies. Compared to the black box benchmark, the comprehensible targeting policy reduces profits by 7.5% or 23 cents per customer.",
          "authors": [
            "Walter W. Zhang"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02424",
          "title": "Optimal Comprehensible Targeting",
          "abstract": "Developments in machine learning and big data allow firms to fully personalize and target their marketing mix. However, data and privacy regulations, such as those in the European Union (GDPR), incorporate a \"right to explanation,\" which is fulfilled when targeting policies are comprehensible to customers. This paper provides a framework for firms to navigate right-to-explanation legislation. First, I construct a class of comprehensible targeting policies that is represented by a sentence. Second, I show how to optimize over this class of policies to find the profit-maximizing comprehensible policy. I further demonstrate that it is optimal to estimate the comprehensible policy directly from the data, rather than projecting down the black box policy into a comprehensible policy. Third, I find the optimal black box targeting policy and compare it to the optimal comprehensible policy. I then empirically apply my framework using data from a price promotion field experiment from a durable goods retailer. I quantify the cost of explanation, which I define as the difference in expected profits between the optimal black box and comprehensible targeting policies. Compared to the black box benchmark, the comprehensible targeting policy reduces profits by 7.5% or 23 cents per customer.",
          "authors": [
            "Walter W. Zhang"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02425",
          "title": "WorldMM: Dynamic Multimodal Memory Agent for Long Video Reasoning",
          "abstract": "Recent advances in video large language models have demonstrated strong capabilities in understanding short clips. However, scaling them to hours- or days-long videos remains highly challenging due to limited context capacity and the loss of critical visual details during abstraction. Existing memory-augmented methods mitigate this by leveraging textual summaries of video segments, yet they heavily rely on text and fail to utilize visual evidence when reasoning over complex scenes. Moreover, retrieving from fixed temporal scales further limits their flexibility in capturing events that span variable durations. To address this, we introduce WorldMM, a novel multimodal memory agent that constructs and retrieves from multiple complementary memories, encompassing both textual and visual representations. WorldMM comprises three types of memory: episodic memory indexes factual events across multiple temporal scales, semantic memory continuously updates high-level conceptual knowledge, and visual memory preserves detailed information about scenes. During inference, an adaptive retrieval agent iteratively selects the most relevant memory source and leverages multiple temporal granularities based on the query, continuing until it determines that sufficient information has been gathered. WorldMM significantly outperforms existing baselines across five long video question-answering benchmarks, achieving an average 8.4% performance gain over previous state-of-the-art methods, showing its effectiveness on long video reasoning.",
          "authors": [
            "Woongyeong Yeo",
            "Kangsan Kim",
            "Jaehong Yoon",
            "Sung Ju Hwang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02427",
          "title": "Posted Pricing for Online Selection: Limited Price Changes and Risk Sensitivity",
          "abstract": "Posted-price mechanisms (PPMs) are a widely adopted strategy for online resource allocation due to their simplicity, intuitive nature, and incentive compatibility. To manage the uncertainty inherent in online settings, PPMs commonly employ dynamically increasing prices. While this adaptive pricing achieves strong performance, it introduces practical challenges: dynamically changing prices can lead to fairness concerns stemming from price discrimination and incur operational costs associated with frequent updates. This paper addresses these issues by investigating posted pricing constrained by a limited, pre-specified number of allowed price changes, denoted by $\\Delta$. We further extend this framework by incorporating a second critical dimension: risk sensitivity. Instead of evaluating performance based solely on expectation, we utilize a tail-risk objective-specifically, the Conditional Value at Risk (CVaR) of the total social welfare, parameterized by a risk level $\\delta \\in [0, 1]$. We formally introduce a novel problem class kSelection-$(\\delta,\\Delta)$ in online adversarial selection and propose a correlated PPM that utilizes a single random seed to correlate posted prices. This correlation scheme is designed to address both the limited price changes and simultaneously enhance the tail performance of the online algorithm. Our subsequent analysis provides performance guarantees under these joint constraints, revealing a clear trade-off between the number of allowed price changes and the algorithm's risk sensitivity. We also establish optimality results for several important special cases of the problem.",
          "authors": [
            "Hossein Nekouyan",
            "Bo Sun",
            "Raouf Boutaba",
            "Xiaoqi Tan"
          ],
          "primary_category": "cs.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02432",
          "title": "Continual Learning for Singing Voice Separation with Human in the Loop Adaptation",
          "abstract": "Deep learning-based works for singing voice separation have performed exceptionally well in the recent past. However, most of these works do not focus on allowing users to interact with the model to improve performance. This can be crucial when deploying the model in real-world scenarios where music tracks can vary from the original training data in both genre and instruments. In this paper, we present a deep learning-based interactive continual learning framework for singing voice separation that allows users to fine-tune the vocal separation model to conform it to new target songs. We use a U-Net-based base model architecture that produces a mask for separating vocals from the spectrogram, followed by a human-in-the-loop task where the user provides feedback by marking a few false positives, i.e., regions in the extracted vocals that should have been silence. We propose two continual learning algorithms. Experiments substantiate the improvement in singing voice separation performance by the proposed algorithms over the base model in intra-dataset and inter-dataset settings.",
          "authors": [
            "Ankur Gupta",
            "Anshul Rai",
            "Archit Bansal",
            "Vipul Arora"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02435",
          "title": "Cross-Domain Offline Policy Adaptation with Dynamics- and Value-Aligned Data Filtering",
          "abstract": "Cross-Domain Offline Reinforcement Learning aims to train an agent deployed in the target environment, leveraging both a limited target domain dataset and a source domain dataset with (possibly) sufficient data coverage. Due to the underlying dynamics misalignment between the source and target domain, simply merging the data from two datasets may incur inferior performance. Recent advances address this issue by selectively sharing source domain samples that exhibit dynamics alignment with the target domain. However, these approaches focus solely on dynamics alignment and overlook \\textit{value alignment}, i.e., selecting high-quality, high-value samples from the source domain. In this paper, we first demonstrate that both dynamics alignment and value alignment are essential for policy learning, by examining the limitations of the current theoretical framework for cross-domain RL and establishing a concrete sub-optimality gap of a policy trained on the source domain and evaluated on the target domain. Motivated by the theoretical insights, we propose to selectively share those source domain samples with both high dynamics and value alignment and present our \\textbf{\\underline{D}}ynamics- and \\textbf{\\underline{V}}alue-aligned \\textbf{\\underline{D}}ata \\textbf{\\underline{F}}iltering (DVDF) method. We design a range of dynamics shift settings, including kinematic and morphology shifts, and evaluate DVDF on various tasks and datasets, as well as in challenging extremely low-data settings where the target domain dataset contains only 5,000 transitions. Extensive experiments demonstrate that DVDF consistently outperforms prior strong baselines and delivers exceptional performance across multiple tasks and datasets.",
          "authors": [
            "Zhongjian Qiao",
            "Rui Yang",
            "Jiafei Lyu",
            "Chenjia Bai",
            "Xiu Li",
            "Zhuoran Yang",
            "Siyang Gao",
            "Shuang Qiu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02436",
          "title": "Semantic Trading: Agentic AI for Clustering and Relationship Discovery in Prediction Markets",
          "abstract": "Prediction markets allow users to trade on outcomes of real-world events, but are prone to fragmentation through overlapping questions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters markets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster market pairs whose resolved outcomes exhibit strong dependence, including same-outcome (correlated) and different-outcome (anti-correlated) relationships. Using a historical dataset of resolved markets on Polymarket, we evaluate the accuracy of the agent's relational predictions. We then translate discovered relationships into a simple trading strategy to quantify how these relationships map to actionable signals. Results show that agent-identified relationships achieve roughly 60-70% accuracy, and their induced trading strategies earn about 20% average returns over week-long horizons, highlighting the ability of agentic AI and large language models to uncover latent semantic structure in prediction markets.",
          "authors": [
            "Agostino Capponi",
            "Alfio Gliozzo",
            "Brian Zhu"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02437",
          "title": "LightHCG: a Lightweight yet powerful HSIC Disentanglement based Causal Glaucoma Detection Model framework",
          "abstract": "As a representative optic degenerative condition, glaucoma has been a threat to millions due to its irreversibility and severe impact on human vision fields. Mainly characterized by dimmed and blurred visions, or peripheral vision loss, glaucoma is well known to occur due to damages in the optic nerve from increased intraocular pressure (IOP) or neovascularization within the retina. Traditionally, most glaucoma related works and clinical diagnosis focused on detecting these damages in the optic nerve by using patient data from perimetry tests, optic papilla inspections and tonometer-based IOP measurements. Recently, with advancements in computer vision AI models, such as VGG16 or Vision Transformers (ViT), AI-automatized glaucoma detection and optic cup segmentation based on retinal fundus images or OCT recently exhibited significant performance in aiding conventional diagnosis with high performance. However, current AI-driven glaucoma detection approaches still have significant room for improvement in terms of reliability, excessive parameter usage, possibility of spurious correlation within detection, and limitations in applications to intervention analysis or clinical simulations. Thus, this research introduced a novel causal representation driven glaucoma detection model: LightHCG, an extremely lightweight Convolutional VAE-based latent glaucoma representation model that can consider the true causality among glaucoma-related physical factors within the optic nerve region. Using HSIC-based latent space disentanglement and Graph Autoencoder based unsupervised causal representation learning, LightHCG not only exhibits higher performance in classifying glaucoma with 93~99% less weights, but also enhances the possibility of AI-driven intervention analysis, compared to existing advanced vision models such as InceptionV3, MobileNetV2 or VGG16.",
          "authors": [
            "Daeyoung Kim"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02438",
          "title": "Boosting Medical Vision-Language Pretraining via Momentum Self-Distillation under Limited Computing Resources",
          "abstract": "In medical healthcare, obtaining detailed annotations is challenging, highlighting the need for robust Vision-Language Models (VLMs). Pretrained VLMs enable fine-tuning on small datasets or zero-shot inference, achieving performance comparable to task-specific models. Contrastive learning (CL) is a key paradigm for training VLMs but inherently requires large batch sizes for effective learning, making it computationally demanding and often limited to well-resourced institutions. Moreover, with limited data in healthcare, it is important to prioritize knowledge extraction from both data and models during training to improve performance. Therefore, we focus on leveraging the momentum method combined with distillation to simultaneously address computational efficiency and knowledge exploitation. Our contributions can be summarized as follows: (1) leveraging momentum self-distillation to enhance multimodal learning, and (2) integrating momentum mechanisms with gradient accumulation to enlarge the effective batch size without increasing resource consumption. Our method attains competitive performance with state-of-the-art (SOTA) approaches in zero-shot classification, while providing a substantial boost in the few-shot adaption, achieving over 90% AUC-ROC and improving retrieval tasks by 2-3%. Importantly, our method achieves high training efficiency with a single GPU while maintaining reasonable training time. Our approach aims to advance efficient multimodal learning by reducing resource requirements while improving performance over SOTA methods. The implementation of our method is available at this https URL .",
          "authors": [
            "Phuc Pham",
            "Nhu Pham",
            "Ngoc Quoc Ly"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02441",
          "title": "Basis-Oriented Low-rank Transfer for Few-Shot and Test-Time Adaptation",
          "abstract": "Adapting large pre-trained models to unseen tasks under tight data and compute budgets remains challenging. Meta-learning approaches explicitly learn good initializations, but they require an additional meta-training phase over many tasks, incur high training cost, and can be unstable. At the same time, the number of task-specific pre-trained models continues to grow, yet the question of how to transfer them to new tasks with minimal additional training remains relatively underexplored. We propose BOLT (Basis-Oriented Low-rank Transfer), a framework that reuses existing fine-tuned models not by merging weights, but instead by extracting an orthogonal, task-informed spectral basis and adapting within that subspace. In the offline phase, BOLT collects dominant singular directions from multiple task vectors and orthogonalizes them per layer to form reusable bases. In the online phase, we freeze these bases and train only a small set of diagonal coefficients per layer for the new task, yielding a rank-controlled update with very few trainable parameters. This design provides (i) a strong, training-free initialization for unseen tasks, obtained by pooling source-task coefficients, along with a lightweight rescaling step while leveraging the shared orthogonal bases, and (ii) a parameter-efficient fine-tuning (PEFT) path that, in our experiments, achieves robust performance compared to common PEFT baselines as well as a representative meta-learned initialization. Our results show that constraining adaptation to a task-informed orthogonal subspace provides an effective alternative for unseen-task transfer.",
          "authors": [
            "Junghwan Park",
            "Woojin Cho",
            "Junhyuk Heo",
            "Darongsae Kwon",
            "Kookjin Lee"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02442",
          "title": "A Visual Analytics System to Understand Behaviors of Multi Agents in Reinforcement Learning",
          "abstract": "Multi-Agent Reinforcement Learning (MARL) is a branch of machine learning in which agents interact and learn optimal policies through trial and error, addressing complex scenarios where multiple agents interact and learn in the same environment at the same time. Analyzing and understanding these complex interactions is challenging, and existing analysis methods are limited in their ability to fully reflect and interpret this complexity. To address these challenges, we provide MARLViz, a visual analytics system for visualizing and analyzing the policies and interactions of agents in MARL environments. The system is designed to visually show the difference in behavior of agents under different environment settings and help users understand complex interaction patterns. In this study, we analyzed agents with similar behaviors and selected scenarios to understand the interactions of the agents, which made it easier to understand the strategies of agents in MARL.",
          "authors": [
            "Changhee Lee",
            "Jeongmin Rhee",
            "DongHwa Shin"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02444",
          "title": "QJoin: Transformation-aware Joinable Data Discovery Using Reinforcement Learning",
          "abstract": "Discovering which tables in large, heterogeneous repositories can be joined and by what transformations is a central challenge in data integration and data discovery. Traditional join discovery methods are largely designed for equi-joins, which assume that join keys match exactly or nearly so. These techniques, while efficient in clean, well-normalized databases, fail in open or federated settings where identifiers are inconsistently formatted, embedded, or split across multiple columns. Approximate or fuzzy joins alleviate minor string variations but cannot capture systematic transformations. We introduce QJoin, a reinforcement-learning framework that learns and reuses transformation strategies across join tasks. QJoin trains an agent under a uniqueness-aware reward that balances similarity with key distinctiveness, enabling it to explore concise, high-value transformation chains. To accelerate new joins, we introduce two reuse mechanisms: (i) agent transfer, which initializes new policies from pretrained agents, and (ii) transformation reuse, which caches successful operator sequences for similar column clusters. On the AutoJoin Web benchmark (31 table pairs), QJoin achieves an average F1-score of 91.0%. For 19,990 join tasks in NYC+Chicago open datasets, Qjoin reduces runtime by up to 7.4% (13,747 s) by using reusing. These results demonstrate that transformation learning and reuse can make join discovery both more accurate and more efficient.",
          "authors": [
            "Ning Wang",
            "Sainyam Galhotra"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02445",
          "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents",
          "abstract": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window. New LLMs enable longer context windows and support tool calling capabilities. Prior works have focused mainly on evaluation of LLMs on long-context prompts, leaving agentic setup relatively unexplored, both from capability and safety perspectives. Our work addresses this gap. We find that LLM agents could be sensitive to length, type, and placement of the context, exhibiting unexpected and inconsistent shifts in task performance and in refusals to execute harmful requests. Models with 1M-2M token context windows show severe degradation already at 100K tokens, with performance drops exceeding 50\\% for both benign and harmful tasks. Refusal rates shift unpredictably: GPT-4.1-nano increases from $\\sim$5\\% to $\\sim$40\\% while Grok 4 Fast decreases from $\\sim$80\\% to $\\sim$10\\% at 200K tokens. Our work shows potential safety issues with agents operating on longer context and opens additional questions on the current metrics and paradigm for evaluating LLM agent safety on long multi-step tasks. In particular, our results on LLM agents reveal a notable divergence in both capability and safety performance compared to prior evaluations of LLMs on similar criteria.",
          "authors": [
            "Tsimur Hadeliya",
            "Mohammad Ali Jauhar",
            "Nidhi Sakpal",
            "Diogo Cruz"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02447",
          "title": "Temporal Dynamics Enhancer for Directly Trained Spiking Object Detectors",
          "abstract": "Spiking Neural Networks (SNNs), with their brain-inspired spatiotemporal dynamics and spike-driven computation, have emerged as promising energy-efficient alternatives to Artificial Neural Networks (ANNs). However, existing SNNs typically replicate inputs directly or aggregate them into frames at fixed intervals. Such strategies lead to neurons receiving nearly identical stimuli across time steps, severely limiting the model's expressive power, particularly in complex tasks like object detection. In this work, we propose the Temporal Dynamics Enhancer (TDE) to strengthen SNNs' capacity for temporal information modeling. TDE consists of two modules: a Spiking Encoder (SE) that generates diverse input stimuli across time steps, and an Attention Gating Module (AGM) that guides the SE generation based on inter-temporal dependencies. Moreover, to eliminate the high-energy multiplication operations introduced by the AGM, we propose a Spike-Driven Attention (SDA) to reduce attention-related energy consumption. Extensive experiments demonstrate that TDE can be seamlessly integrated into existing SNN-based detectors and consistently outperforms state-of-the-art methods, achieving mAP50-95 scores of 57.7% on the static PASCAL VOC dataset and 47.6% on the neuromorphic EvDET200K dataset. In terms of energy consumption, the SDA consumes only 0.240 times the energy of conventional attention modules.",
          "authors": [
            "Fan Luo",
            "Zeyu Gao",
            "Xinhao Luo",
            "Kai Zhao",
            "Yanfeng Lu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02448",
          "title": "nuScenes Revisited: Progress and Challenges in Autonomous Driving",
          "abstract": "Autonomous Vehicles (AV) and Advanced Driver Assistance Systems (ADAS) have been revolutionized by Deep Learning. As a data-driven approach, Deep Learning relies on vast amounts of driving data, typically labeled in great detail. As a result, datasets, alongside hardware and algorithms, are foundational building blocks for the development of AVs. In this work we revisit one of the most widely used autonomous driving datasets: the nuScenes dataset. nuScenes exemplifies key trends in AV development, being the first dataset to include radar data, to feature diverse urban driving scenes from two continents, and to be collected using a fully autonomous vehicle operating on public roads, while also promoting multi-modal sensor fusion, standardized benchmarks, and a broad range of tasks including perception, localization \\& mapping, prediction and planning. We provide an unprecedented look into the creation of nuScenes, as well as its extensions nuImages and Panoptic nuScenes, summarizing many technical details that have hitherto not been revealed in academic publications. Furthermore, we trace how the influence of nuScenes impacted a large number of other datasets that were released later and how it defined numerous standards that are used by the community to this day. Finally, we present an overview of both official and unofficial tasks using the nuScenes dataset and review major methodological developments, thereby offering a comprehensive survey of the autonomous driving literature, with a particular focus on nuScenes.",
          "authors": [
            "Whye Kit Fong",
            "Venice Erin Liong",
            "Kok Seang Tan",
            "Holger Caesar"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02450",
          "title": "HouseLayout3D: A Benchmark and Training-Free Baseline for 3D Layout Estimation in the Wild",
          "abstract": "Current 3D layout estimation models are primarily trained on synthetic datasets containing simple single room or single floor environments. As a consequence, they cannot natively handle large multi floor buildings and require scenes to be split into individual floors before processing, which removes global spatial context that is essential for reasoning about structures such as staircases that connect multiple levels. In this work, we introduce HouseLayout3D, a real world benchmark designed to support progress toward full building scale layout estimation, including multiple floors and architecturally intricate spaces. We also present MultiFloor3D, a simple training free baseline that leverages recent scene understanding methods and already outperforms existing 3D layout estimation models on both our benchmark and prior datasets, highlighting the need for further research in this direction. Data and code are available at: this https URL .",
          "authors": [
            "Valentin Bieri",
            "Marie-Julie Rakotosaona",
            "Keisuke Tateno",
            "Francis Engelmann",
            "Leonidas Guibas"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02453",
          "title": "ClusterStyle: Modeling Intra-Style Diversity with Prototypical Clustering for Stylized Motion Generation",
          "abstract": "Existing stylized motion generation models have shown their remarkable ability to understand specific style information from the style motion, and insert it into the content motion. However, capturing intra-style diversity, where a single style should correspond to diverse motion variations, remains a significant challenge. In this paper, we propose a clustering-based framework, ClusterStyle, to address this limitation. Instead of learning an unstructured embedding from each style motion, we leverage a set of prototypes to effectively model diverse style patterns across motions belonging to the same style category. We consider two types of style diversity: global-level diversity among style motions of the same category, and local-level diversity within the temporal dynamics of motion sequences. These components jointly shape two structured style embedding spaces, i.e., global and local, optimized via alignment with non-learnable prototype anchors. Furthermore, we augment the pretrained text-to-motion generation model with the Stylistic Modulation Adapter (SMA) to integrate the style features. Extensive experiments demonstrate that our approach outperforms existing state-of-the-art models in stylized motion generation and motion style transfer.",
          "authors": [
            "Kerui Chen",
            "Jianrong Zhang",
            "Ming Li",
            "Zhonglong Zheng",
            "Hehe Fan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02456",
          "title": "See, Think, Learn: A Self-Taught Multimodal Reasoner",
          "abstract": "Vision-Language Models (VLMs) have achieved remarkable progress in integrating visual perception with language understanding. However, effective multimodal reasoning requires both accurate perception and robust reasoning, and weakness in either limits the performance of VLMs. Prior efforts to enhance reasoning often depend on high-quality chain-of-thought (CoT) data, obtained via labor-intensive human annotations, costly proprietary models, or self-training methods that overlook perception. To address these limitations, we propose a simple yet effective self-training framework called See-Think-Learn (STL). At its core, STL introduces a structured reasoning template that encourages the model to see before thinking, first extracting visual attributes in textual form, then using them to guide reasoning. The framework jointly improves perception and reasoning by having the model generate and learn from its own structured rationales in a self-training loop. Furthermore, we augment the training data with negative rationales, i.e. explanations that justify why certain answer choices are incorrect, to enhance the model's ability to distinguish between correct and misleading responses. This fosters more discriminative and robust learning. Experiments across diverse domains show that STL consistently outperforms baselines trained directly only on answers or self-generated reasoning, while qualitative analysis confirms the high quality of its rationales. STL thus provides a cost-effective solution to enhance multimodal reasoning ability of VLMs.",
          "authors": [
            "Sourabh Sharma",
            "Sonam Gupta",
            "Sadbhawna"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02457",
          "title": "Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation",
          "abstract": "Recent audio-video generative systems suggest that coupling modalities benefits not only audio-video synchrony but also the video modality itself. We pose a fundamental question: Does audio-video joint denoising training improve video generation, even when we only care about video quality? To study this, we introduce a parameter-efficient Audio-Video Full DiT (AVFullDiT) architecture that leverages pre-trained text-to-video (T2V) and text-to-audio (T2A) modules for joint denoising. We train (i) a T2AV model with AVFullDiT and (ii) a T2V-only counterpart under identical settings. Our results provide the first systematic evidence that audio-video joint denoising can deliver more than synchrony. We observe consistent improvements on challenging subsets featuring large and object contact motions. We hypothesize that predicting audio acts as a privileged signal, encouraging the model to internalize causal relationships between visual events and their acoustic consequences (e.g., collision $\\times$ impact sound), which in turn regularizes video dynamics. Our findings suggest that cross-modal co-training is a promising approach to developing stronger, more physically grounded world models. Code and dataset will be made publicly available.",
          "authors": [
            "Jianzong Wu",
            "Hao Lian",
            "Dachao Hao",
            "Ye Tian",
            "Qingyu Shi",
            "Biaolong Chen",
            "Hao Jiang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02458",
          "title": "Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration",
          "abstract": "Existing research on indoor embodied tasks typically requires agents to actively explore unknown environments and reason about the scene to achieve a specific goal. However, when deployed in real life, agents often face sequential tasks, where each new sub-task follows the completion of the previous one, and certain sub-tasks may be infeasible, such as searching for a non-existent object. Compared with the single-task setting, the core challenge lies in reusing spatial knowledge accumulated from previous explorations to support subsequent reasoning and exploration. In this work, we investigate this underexplored yet practically significant embodied AI challenge. To evaluate this challenge, we introduce SEER-Bench, a new Sequential Embodied Exploration and Reasoning Benchmark encompassing encompassing two classic embodied tasks: Embodied Question Answering (EQA) and Embodied Multi-modal Navigation (EMN). Building on SEER-Bench, we propose 3DSPMR, a 3D SPatial Memory Reasoning approach that exploits relational, visual, and geometric cues from explored regions to augment Multi-Modal Large Language Models (MLLMs) for reasoning and exploration in sequential embodied tasks. To the best of our knowledge, this is the first work to explicitly incorporate geometric information into MLLM-based spatial understanding and reasoning. Extensive experiments verify that 3DSPMR achieves substantial performance gains on both sequential EQA and EMN tasks.",
          "authors": [
            "Zhongyi Cai",
            "Yi Du",
            "Chen Wang",
            "Yu Kong"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02459",
          "title": "Efficient Eye-based Emotion Recognition via Neural Architecture Search of Time-to-First-Spike-Coded Spiking Neural Networks",
          "abstract": "Eye-based emotion recognition enables eyewear devices to perceive users' emotional states and support emotion-aware interaction, yet deploying such functionality on their resource-limited embedded hardware remains challenging. Time-to-first-spike (TTFS)-coded spiking neural networks (SNNs) offer a promising solution, as each neuron emits at most one binary spike, resulting in extremely sparse and energy-efficient computation. While prior works have primarily focused on improving TTFS SNN training algorithms, the impact of network architecture has been largely overlooked. In this paper, we propose TNAS-ER, the first neural architecture search (NAS) framework tailored to TTFS SNNs for eye-based emotion recognition. TNAS-ER presents a novel ANN-assisted search strategy that leverages a ReLU-based ANN counterpart sharing an identity mapping with the TTFS SNN to guide architecture optimization. TNAS-ER employs an evolutionary algorithm, with weighted and unweighted average recall jointly defined as fitness objectives for emotion recognition. Extensive experiments demonstrate that TNAS-ER achieves high recognition performance with significantly improved efficiency. Furthermore, when deployed on neuromorphic hardware, TNAS-ER attains a low latency of 48 ms and an energy consumption of 0.05 J, confirming its superior energy efficiency and strong potential for practical applications.",
          "authors": [
            "Qianhui Liu",
            "Jing Yang",
            "Miao Yu",
            "Trevor E. Carlson",
            "Gang Pan",
            "Haizhou Li",
            "Zhumin Chen"
          ],
          "primary_category": "cs.NE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02460",
          "title": "UniCom: Towards a Unified and Cohesiveness-aware Framework for Community Search and Detection",
          "abstract": "Searching and detecting communities in real-world graphs underpins a wide range of applications. Despite the success achieved, current learning-based solutions regard community search, i.e., locating the best community for a given query, and community detection, i.e., partitioning the whole graph, as separate problems, necessitating task- and dataset-specific retraining. Such a strategy limits the applicability and generalization ability of the existing models. Additionally, these methods rely heavily on information from the target dataset, leading to suboptimal performance when supervision is limited or unavailable. To mitigate this limitation, we propose UniCom, a unified framework to solve both community search and detection tasks through knowledge transfer across multiple domains, thus alleviating the limitations of single-dataset learning. UniCom centers on a Domain-aware Specialization (DAS) procedure that adapts on the fly to unseen graphs or tasks, eliminating costly retraining while maintaining framework compactness with a lightweight prompt-based paradigm. This is empowered by a Universal Graph Learning (UGL) backbone, which distills transferable semantic and topological knowledge from multiple source domains via comprehensive pre-training. Both DAS and UGL are informed by local neighborhood signals and cohesive subgraph structures, providing consistent guidance throughout the framework. Extensive experiments on both tasks across 16 benchmark datasets and 22 baselines have been conducted to ensure a comprehensive and fair evaluation. UniCom consistently outperforms all state-of-the-art baselines across all tasks under settings with scarce or no supervision, while maintaining runtime efficiency.",
          "authors": [
            "Yifan Zhu",
            "Hanchen Wang",
            "Wenjie Zhang",
            "Alexander Zhou",
            "Ying Zhang"
          ],
          "primary_category": "cs.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02463",
          "title": "A Datalake for Data-driven Social Science Research",
          "abstract": "Social science research increasingly demands data-driven insights, yet researchers often face barriers such as lack of technical expertise, inconsistent data formats, and limited access to reliable this http URL science research increasingly demands data-driven insights, yet researchers often face barriers such as lack of technical expertise, inconsistent data formats, and limited access to reliable datasets. In this paper, we present a Datalake infrastructure tailored to the needs of interdisciplinary social science research. Our system supports ingestion and integration of diverse data types, automatic provenance and version tracking, role-based access control, and built-in tools for visualization and analysis. We demonstrate the utility of our Datalake using real-world use cases spanning governance, health, and education. A detailed walkthrough of one such use case -- analyzing the relationship between income, education, and infant mortality -- shows how our platform streamlines the research process while maintaining transparency and reproducibility. We argue that such infrastructure can democratize access to advanced data science practices, especially for NGOs, students, and grassroots organizations. The Datalake continues to evolve with plans to support ML pipelines, mobile access, and citizen data feedback mechanisms.",
          "authors": [
            "Puneet Arya",
            "Ojas Sahasrabudhe",
            "Adwaiya Srivastav",
            "Partha Pratim Das",
            "Maya Ramanath"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02465",
          "title": "TabGRU: An Enhanced Design for Urban Rainfall Intensity Estimation Using Commercial Microwave Links",
          "abstract": "In the face of accelerating global urbanization and the increasing frequency of extreme weather events, highresolution urban rainfall monitoring is crucial for building resilient smart cities. Commercial Microwave Links (CMLs) are an emerging data source with great potential for this this http URL traditional rainfall retrieval from CMLs relies on physicsbased models, these often struggle with real-world complexities like signal noise and nonlinear attenuation. To address these limitations, this paper proposes a novel hybrid deep learning architecture based on the Transformer and a Bidirectional Gated Recurrent Unit (BiGRU), which we name TabGRU. This design synergistically captures both long-term dependencies and local sequential features in the CML signal data. The model is further enhanced by a learnable positional embedding and an attention pooling mechanism to improve its dynamic feature extraction and generalization capabilities. The model was validated on a public benchmark dataset from Gothenburg, Sweden (June-September 2015). The evaluation used 12 sub-links from two rain gauges (Torp and Barl) over a test period (August 22-31) covering approximately 10 distinct rainfall events. The proposed TabGRU model demonstrated consistent advantages, outperforming deep learning baselines and achieving high coefficients of determination (R2) at both the Torp site (0.91) and the Barl site (0.96). Furthermore, compared to the physics-based approach, TabGRU maintained higher accuracy and was particularly effective in mitigating the significant overestimation problem observed in the PL model during peak rainfall events. This evaluation confirms that the TabGRU model can effectively overcome the limitations of traditional methods, providing a robust and accurate solution for CML-based urban rainfall monitoring under the tested conditions.",
          "authors": [
            "Xingwang Li",
            "Mengyun Chen",
            "Jiamou Liu",
            "Sijie Wang",
            "Shuanggen Jin",
            "Jafet C. M. Andersson",
            "Jonas Olsson",
            "Remco",
            "van de Beek",
            "Hai Victor Habi",
            "Congzheng Han"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02469",
          "title": "TGDD: Trajectory Guided Dataset Distillation with Balanced Distribution",
          "abstract": "Dataset distillation compresses large datasets into compact synthetic ones to reduce storage and computational costs. Among various approaches, distribution matching (DM)-based methods have attracted attention for their high efficiency. However, they often overlook the evolution of feature representations during training, which limits the expressiveness of synthetic data and weakens downstream performance. To address this issue, we propose Trajectory Guided Dataset Distillation (TGDD), which reformulates distribution matching as a dynamic alignment process along the model's training trajectory. At each training stage, TGDD captures evolving semantics by aligning the feature distribution between the synthetic and original dataset. Meanwhile, it introduces a distribution constraint regularization to reduce class overlap. This design helps synthetic data preserve both semantic diversity and representativeness, improving performance in downstream tasks. Without additional optimization overhead, TGDD achieves a favorable balance between performance and efficiency. Experiments on ten datasets demonstrate that TGDD achieves state-of-the-art performance, notably a 5.0% accuracy gain on high-resolution benchmarks.",
          "authors": [
            "Fengli Ran",
            "Xiao Pu",
            "Bo Liu",
            "Xiuli Bi",
            "Bin Xiao"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02471",
          "title": "scCluBench: Comprehensive Benchmarking of Clustering Algorithms for Single-Cell RNA Sequencing",
          "abstract": "Cell clustering is crucial for uncovering cellular heterogeneity in single-cell RNA sequencing (scRNA-seq) data by identifying cell types and marker genes. Despite its importance, benchmarks for scRNA-seq clustering methods remain fragmented, often lacking standardized protocols and failing to incorporate recent advances in artificial intelligence. To fill these gaps, we present scCluBench, a comprehensive benchmark of clustering algorithms for scRNA-seq data. First, scCluBench provides 36 scRNA-seq datasets collected from diverse public sources, covering multiple tissues, which are uniformly processed and standardized to ensure consistency for systematic evaluation and downstream analyses. To evaluate performance, we collect and reproduce a range of scRNA-seq clustering methods, including traditional, deep learning-based, graph-based, and biological foundation models. We comprehensively evaluate each method both quantitatively and qualitatively, using core performance metrics as well as visualization analyses. Furthermore, we construct representative downstream biological tasks, such as marker gene identification and cell type annotation, to further assess the practical utility. scCluBench then investigates the performance differences and applicability boundaries of various clustering models across diverse analytical tasks, systematically assessing their robustness and scalability in real-world scenarios. Overall, scCluBench offers a standardized and user-friendly benchmark for scRNA-seq clustering, with curated datasets, unified evaluation protocols, and transparent analyses, facilitating informed method selection and providing valuable insights into model generalizability and application scope.",
          "authors": [
            "Ping Xu",
            "Zaitian Wang",
            "Zhirui Wang",
            "Pengjiang Li",
            "Jiajia Wang",
            "Ran Zhang",
            "Pengfei Wang",
            "Yuanchun Zhou"
          ],
          "primary_category": "q-bio.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02471",
          "title": "scCluBench: Comprehensive Benchmarking of Clustering Algorithms for Single-Cell RNA Sequencing",
          "abstract": "Cell clustering is crucial for uncovering cellular heterogeneity in single-cell RNA sequencing (scRNA-seq) data by identifying cell types and marker genes. Despite its importance, benchmarks for scRNA-seq clustering methods remain fragmented, often lacking standardized protocols and failing to incorporate recent advances in artificial intelligence. To fill these gaps, we present scCluBench, a comprehensive benchmark of clustering algorithms for scRNA-seq data. First, scCluBench provides 36 scRNA-seq datasets collected from diverse public sources, covering multiple tissues, which are uniformly processed and standardized to ensure consistency for systematic evaluation and downstream analyses. To evaluate performance, we collect and reproduce a range of scRNA-seq clustering methods, including traditional, deep learning-based, graph-based, and biological foundation models. We comprehensively evaluate each method both quantitatively and qualitatively, using core performance metrics as well as visualization analyses. Furthermore, we construct representative downstream biological tasks, such as marker gene identification and cell type annotation, to further assess the practical utility. scCluBench then investigates the performance differences and applicability boundaries of various clustering models across diverse analytical tasks, systematically assessing their robustness and scalability in real-world scenarios. Overall, scCluBench offers a standardized and user-friendly benchmark for scRNA-seq clustering, with curated datasets, unified evaluation protocols, and transparent analyses, facilitating informed method selection and providing valuable insights into model generalizability and application scope.",
          "authors": [
            "Ping Xu",
            "Zaitian Wang",
            "Zhirui Wang",
            "Pengjiang Li",
            "Jiajia Wang",
            "Ran Zhang",
            "Pengfei Wang",
            "Yuanchun Zhou"
          ],
          "primary_category": "q-bio.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02472",
          "title": "Guided Self-Evolving LLMs with Minimal Human Supervision",
          "abstract": "AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.",
          "authors": [
            "Wenhao Yu",
            "Zhenwen Liang",
            "Chengsong Huang",
            "Kishan Panaganti",
            "Tianqing Fang",
            "Haitao Mi",
            "Dong Yu"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02473",
          "title": "WorldPack: Compressed Memory Improves Spatial Consistency in Video World Modeling",
          "abstract": "Video world models have attracted significant attention for their ability to produce high-fidelity future visual observations conditioned on past observations and navigation actions. Temporally- and spatially-consistent, long-term world modeling has been a long-standing problem, unresolved with even recent state-of-the-art models, due to the prohibitively expensive computational costs for long-context inputs. In this paper, we propose WorldPack, a video world model with efficient compressed memory, which significantly improves spatial consistency, fidelity, and quality in long-term generation despite much shorter context length. Our compressed memory consists of trajectory packing and memory retrieval; trajectory packing realizes high context efficiency, and memory retrieval maintains the consistency in rollouts and helps long-term generations that require spatial reasoning. Our performance is evaluated with LoopNav, a benchmark on Minecraft, specialized for the evaluation of long-term consistency, and we verify that WorldPack notably outperforms strong state-of-the-art models.",
          "authors": [
            "Yuta Oshima",
            "Yusuke Iwasawa",
            "Masahiro Suzuki",
            "Yutaka Matsuo",
            "Hiroki Furuta"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02474",
          "title": "Q-BERT4Rec: Quantized Semantic-ID Representation Learning for Multimodal Recommendation",
          "abstract": "Sequential recommendation plays a critical role in modern online platforms such as e-commerce, advertising, and content streaming, where accurately predicting users' next interactions is essential for personalization. Recent Transformer-based methods like BERT4Rec have shown strong modeling capability, yet they still rely on discrete item IDs that lack semantic meaning and ignore rich multimodal information (e.g., text and image). This leads to weak generalization and limited interpretability. To address these challenges, we propose Q-Bert4Rec, a multimodal sequential recommendation framework that unifies semantic representation and quantized modeling. Specifically, Q-Bert4Rec consists of three stages: (1) cross-modal semantic injection, which enriches randomly initialized ID embeddings through a dynamic transformer that fuses textual, visual, and structural features; (2) semantic quantization, which discretizes fused representations into meaningful tokens via residual vector quantization; and (3) multi-mask pretraining and fine-tuning, which leverage diverse masking strategies -- span, tail, and multi-region -- to improve sequential understanding. We validate our model on public Amazon benchmarks and demonstrate that Q-Bert4Rec significantly outperforms many strong existing methods, confirming the effectiveness of semantic tokenization for multimodal sequential recommendation. Our source code will be publicly available on GitHub after publishing.",
          "authors": [
            "Haofeng Huang",
            "Ling Gai"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02481",
          "title": "Impact of Brand Dynamics on Insurance Premiums in Turkey",
          "abstract": "This paper examines influences of brand dynamics on insurance premium productions in Turkey using a dynamic GMM panel estimation technique sampling 31 insurance firms over 2005-2015. The results reveals that brands trust appears as a chief driving force behind premium production where its unit increase augments premium outputs by 5.32 million Turkish Liras (TL). Moreover, the brand value of firms also appears a statistically significant determinant of premium sales, but its size impact remains limited comparing to brand trust, i.e. a million TL increase in brand value generates only 0.02 million TL increase in sales. On the other hand, the study also documents a strong momentum driven from past years premium production with trade-off magnitude of 1 to 0.85. This might imply a higher loyalty-stickiness of customers in Turkey, as well as a self-feeding \"bandwagon effect\".",
          "authors": [
            "Yhlas Sovbetov"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02481",
          "title": "Impact of Brand Dynamics on Insurance Premiums in Turkey",
          "abstract": "This paper examines influences of brand dynamics on insurance premium productions in Turkey using a dynamic GMM panel estimation technique sampling 31 insurance firms over 2005-2015. The results reveals that brands trust appears as a chief driving force behind premium production where its unit increase augments premium outputs by 5.32 million Turkish Liras (TL). Moreover, the brand value of firms also appears a statistically significant determinant of premium sales, but its size impact remains limited comparing to brand trust, i.e. a million TL increase in brand value generates only 0.02 million TL increase in sales. On the other hand, the study also documents a strong momentum driven from past years premium production with trade-off magnitude of 1 to 0.85. This might imply a higher loyalty-stickiness of customers in Turkey, as well as a self-feeding \"bandwagon effect\".",
          "authors": [
            "Yhlas Sovbetov"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02482",
          "title": "G-SHARP: Gaussian Surgical Hardware Accelerated Real-time Pipeline",
          "abstract": "We propose G-SHARP, a commercially compatible, real-time surgical scene reconstruction framework designed for minimally invasive procedures that require fast and accurate 3D modeling of deformable tissue. While recent Gaussian splatting approaches have advanced real-time endoscopic reconstruction, existing implementations often depend on non-commercial derivatives, limiting deployability. G-SHARP overcomes these constraints by being the first surgical pipeline built natively on the GSplat (Apache-2.0) differentiable Gaussian rasterizer, enabling principled deformation modeling, robust occlusion handling, and high-fidelity reconstructions on the EndoNeRF pulling benchmark. Our results demonstrate state-of-the-art reconstruction quality with strong speed-accuracy trade-offs suitable for intra-operative use. Finally, we provide a Holoscan SDK application that deploys G-SHARP on NVIDIA IGX Orin and Thor edge hardware, enabling real-time surgical visualization in practical operating-room settings.",
          "authors": [
            "Vishwesh Nath",
            "Javier G. Tejero",
            "Ruilong Li",
            "Filippo Filicori",
            "Mahdi Azizian",
            "Sean D. Huver"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02483",
          "title": "Identifying preferred routes of sharing information on social networks",
          "abstract": "The spread of information has become faster and wider than ever with the advent of social network platforms. The question raised in this study is whether information dissemination in social networks is random or follows a discernible structure. Our results from real-world hashtag data suggest that the spread of hashtags is not random and follows specific patterns. This study proposes two preferential models to explore how news spreads on social media. Specifically, we examine global and local preferential selection models and demonstrate that information dissemination aligns with these patterns. According to these two models, information flows are distributed through specific paths on networks. This suggests that new information tends to propagate along the same paths as previous news, with the specific pathways varying depending on the type of content. Finally, an examination of the propagation of political hashtags on Twitter confirms the existence of these paths that also emerge from the two preferential models.",
          "authors": [
            "Rozhin Mohammadikian",
            "Parsa Bigdeli",
            "Behrouz Askari",
            "G.Reza Jafari"
          ],
          "primary_category": "cs.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02483",
          "title": "Identifying preferred routes of sharing information on social networks",
          "abstract": "The spread of information has become faster and wider than ever with the advent of social network platforms. The question raised in this study is whether information dissemination in social networks is random or follows a discernible structure. Our results from real-world hashtag data suggest that the spread of hashtags is not random and follows specific patterns. This study proposes two preferential models to explore how news spreads on social media. Specifically, we examine global and local preferential selection models and demonstrate that information dissemination aligns with these patterns. According to these two models, information flows are distributed through specific paths on networks. This suggests that new information tends to propagate along the same paths as previous news, with the specific pathways varying depending on the type of content. Finally, an examination of the propagation of political hashtags on Twitter confirms the existence of these paths that also emerge from the two preferential models.",
          "authors": [
            "Rozhin Mohammadikian",
            "Parsa Bigdeli",
            "Behrouz Askari",
            "G.Reza Jafari"
          ],
          "primary_category": "cs.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02485",
          "title": "UCAgents: Unidirectional Convergence for Visual Evidence Anchored Multi-Agent Medical Decision-Making",
          "abstract": "Vision-Language Models (VLMs) show promise in medical diagnosis, yet suffer from reasoning detachment, where linguistically fluent explanations drift from verifiable image evidence, undermining clinical trust. Recent multi-agent frameworks simulate Multidisciplinary Team (MDT) debates to mitigate single-model bias, but open-ended discussions amplify textual noise and computational cost while failing to anchor reasoning to visual evidence, the cornerstone of medical decision-making. We propose UCAgents, a hierarchical multi-agent framework enforcing unidirectional convergence through structured evidence auditing. Inspired by clinical workflows, UCAgents forbids position changes and limits agent interactions to targeted evidence verification, suppressing rhetorical drift while amplifying visual signal extraction. In UCAgents, a one-round inquiry discussion is introduced to uncover potential risks of visual-textual misalignment. This design jointly constrains visual ambiguity and textual noise, a dual-noise bottleneck that we formalize via information theory. Extensive experiments on four medical VQA benchmarks show UCAgents achieves superior accuracy (71.3% on PathVQA, +6.0% over state-of-the-art) with 87.7% lower token cost, the evaluation results further confirm that UCAgents strikes a balance between uncovering more visual evidence and avoiding confusing textual interference. These results demonstrate that UCAgents exhibits both diagnostic reliability and computational efficiency critical for real-world clinical deployment. Code is available at this https URL .",
          "authors": [
            "Qianhan Feng",
            "Zhongzhen Huang",
            "Yakun Zhu",
            "Xiaofan Zhang",
            "Qi Dou"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02486",
          "title": "Dual-Robust Cross-Domain Offline Reinforcement Learning Against Dynamics Shifts",
          "abstract": "Single-domain offline reinforcement learning (RL) often suffers from limited data coverage, while cross-domain offline RL handles this issue by leveraging additional data from other domains with dynamics shifts. However, existing studies primarily focus on train-time robustness (handling dynamics shifts from training data), neglecting the test-time robustness against dynamics perturbations when deployed in practical scenarios. In this paper, we investigate dual (both train-time and test-time) robustness against dynamics shifts in cross-domain offline RL. We first empirically show that the policy trained with cross-domain offline RL exhibits fragility under dynamics perturbations during evaluation, particularly when target domain data is limited. To address this, we introduce a novel robust cross-domain Bellman (RCB) operator, which enhances test-time robustness against dynamics perturbations while staying conservative to the out-of-distribution dynamics transitions, thus guaranteeing the train-time robustness. To further counteract potential value overestimation or underestimation caused by the RCB operator, we introduce two techniques, the dynamic value penalty and the Huber loss, into our framework, resulting in the practical \\textbf{D}ual-\\textbf{RO}bust \\textbf{C}ross-domain \\textbf{O}ffline RL (DROCO) algorithm. Extensive empirical results across various dynamics shift scenarios show that DROCO outperforms strong baselines and exhibits enhanced robustness to dynamics perturbations.",
          "authors": [
            "Zhongjian Qiao",
            "Rui Yang",
            "Jiafei Lyu",
            "Xiu Li",
            "Zhongxiang Dai",
            "Zhuoran Yang",
            "Siyang Gao",
            "Shuang Qiu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02487",
          "title": "Masking Matters: Unlocking the Spatial Reasoning Capabilities of LLMs for 3D Scene-Language Understanding",
          "abstract": "Recent advances in 3D scene-language understanding have leveraged Large Language Models (LLMs) for 3D reasoning by transferring their general reasoning ability to 3D multi-modal contexts. However, existing methods typically adopt standard decoders from language modeling, which rely on a causal attention mask. This design introduces two fundamental conflicts in 3D scene understanding: sequential bias among order-agnostic 3D objects and restricted object-instruction attention, hindering task-specific reasoning. To overcome these limitations, we propose 3D Spatial Language Instruction Mask (3D-SLIM), an effective masking strategy that replaces the causal mask with an adaptive attention mask tailored to the spatial structure of 3D scenes. Our 3D-SLIM introduces two key components: a Geometry-adaptive Mask that constrains attention based on spatial density rather than token order, and an Instruction-aware Mask that enables object tokens to directly access instruction context. This design allows the model to process objects based on their spatial relationships while being guided by the user's task. 3D-SLIM is simple, requires no architectural modifications, and adds no extra parameters, yet it yields substantial performance improvements across diverse 3D scene-language tasks. Extensive experiments across multiple benchmarks and LLM baselines validate its effectiveness and underscore the critical role of decoder design in 3D multi-modal reasoning.",
          "authors": [
            "Yerim Jeon",
            "Miso Lee",
            "WonJun Moon",
            "Jae-Pil Heo"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02489",
          "title": "Hybrid(Penalized Regression and MLP) Models for Outcome Prediction in HDLSS Health Data",
          "abstract": "I present an application of established machine learning techniques to NHANES health survey data for predicting diabetes status. I compare baseline models (logistic regression, random forest, XGBoost) with a hybrid approach that uses an XGBoost feature encoder and a lightweight multilayer perceptron (MLP) head. Experiments show the hybrid model attains improved AUC and balanced accuracy compared to baselines on the processed NHANES subset. I release code and reproducible scripts to encourage replication.",
          "authors": [
            "Mithra D K"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02491",
          "title": "Stress-Testing Causal Claims via Cardinality Repairs",
          "abstract": "Causal analyses derived from observational data underpin high-stakes decisions in domains such as healthcare, public policy, and economics. Yet such conclusions can be surprisingly fragile: even minor data errors - duplicate records, or entry mistakes - may drastically alter causal relationships. This raises a fundamental question: how robust is a causal claim to small, targeted modifications in the data? Addressing this question is essential for ensuring the reliability, interpretability, and reproducibility of empirical findings. We introduce SubCure, a framework for robustness auditing via cardinality repairs. Given a causal query and a user-specified target range for the estimated effect, SubCure identifies a small set of tuples or subpopulations whose removal shifts the estimate into the desired range. This process not only quantifies the sensitivity of causal conclusions but also pinpoints the specific regions of the data that drive those conclusions. We formalize this problem under both tuple- and pattern-level deletion settings and show both are NP-complete. To scale to large datasets, we develop efficient algorithms that incorporate machine unlearning techniques to incrementally update causal estimates without retraining from scratch. We evaluate SubCure across four real-world datasets covering diverse application domains. In each case, it uncovers compact, high-impact subsets whose removal significantly shifts the causal conclusions, revealing vulnerabilities that traditional methods fail to detect. Our results demonstrate that cardinality repair is a powerful and general-purpose tool for stress-testing causal analyses and guarding against misleading claims rooted in ordinary data imperfections.",
          "authors": [
            "Yarden Gabbay",
            "Haoquan Guan",
            "Shaull Almagor",
            "El Kindi Rezig",
            "Brit Youngmann",
            "Babak Salimi"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02492",
          "title": "YingVideo-MV: Music-Driven Multi-Stage Video Generation",
          "abstract": "While diffusion model for audio-driven avatar video generation have achieved notable process in synthesizing long sequences with natural audio-visual synchronization and identity consistency, the generation of music-performance videos with camera motions remains largely unexplored. We present YingVideo-MV, the first cascaded framework for music-driven long-video generation. Our approach integrates audio semantic analysis, an interpretable shot planning module (MV-Director), temporal-aware diffusion Transformer architectures, and long-sequence consistency modeling to enable automatic synthesis of high-quality music performance videos from audio signals. We construct a large-scale Music-in-the-Wild Dataset by collecting web data to support the achievement of diverse, high-quality results. Observing that existing long-video generation methods lack explicit camera motion control, we introduce a camera adapter module that embeds camera poses into latent noise. To enhance continulity between clips during long-sequence inference, we further propose a time-aware dynamic window range strategy that adaptively adjust denoising ranges based on audio embedding. Comprehensive benchmark tests demonstrate that YingVideo-MV achieves outstanding performance in generating coherent and expressive music videos, and enables precise music-motion-camera synchronization. More videos are available in our project page: this https URL .",
          "authors": [
            "Jiahui Chen",
            "Weida Wang",
            "Runhua Shi",
            "Huan Yang",
            "Chaofan Ding",
            "Zihao Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02495",
          "title": "Bayesian Physics-Informed Neural Networks for Inverse Problems (BPINN-IP): Application in Infrared Image Processing",
          "abstract": "Inverse problems arise across scientific and engineering domains, where the goal is to infer hidden parameters or physical fields from indirect and noisy observations. Classical approaches, such as variational regularization and Bayesian inference, provide well established theoretical foundations for handling ill posedness. However, these methods often become computationally restrictive in high dimensional settings or when the forward model is governed by complex physics. Physics Informed Neural Networks (PINNs) have recently emerged as a promising framework for solving inverse problems by embedding physical laws directly into the training process of neural networks. In this paper, we introduce a new perspective on the Bayesian Physics Informed Neural Network (BPINN) framework, extending classical PINNs by explicitly incorporating training data generation, modeling and measurement uncertainties through Bayesian prior modeling and doing inference with the posterior laws. Also, as we focus on the inverse problems, we call this method BPINN-IP, and we show that the standard PINN formulation naturally appears as its special case corresponding to the Maximum A Posteriori (MAP) estimate. This unified formulation allows simultaneous exploitation of physical constraints, prior knowledge, and data-driven inference, while enabling uncertainty quantification through posterior distributions. To demonstrate the effectiveness of the proposed framework, we consider inverse problems arising in infrared image processing, including deconvolution and super-resolution, and present results on both simulated and real industrial data.",
          "authors": [
            "Ali Mohammad-Djafari",
            "Ning Chu",
            "Li Wang"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02495",
          "title": "Bayesian Physics-Informed Neural Networks for Inverse Problems (BPINN-IP): Application in Infrared Image Processing",
          "abstract": "Inverse problems arise across scientific and engineering domains, where the goal is to infer hidden parameters or physical fields from indirect and noisy observations. Classical approaches, such as variational regularization and Bayesian inference, provide well established theoretical foundations for handling ill posedness. However, these methods often become computationally restrictive in high dimensional settings or when the forward model is governed by complex physics. Physics Informed Neural Networks (PINNs) have recently emerged as a promising framework for solving inverse problems by embedding physical laws directly into the training process of neural networks. In this paper, we introduce a new perspective on the Bayesian Physics Informed Neural Network (BPINN) framework, extending classical PINNs by explicitly incorporating training data generation, modeling and measurement uncertainties through Bayesian prior modeling and doing inference with the posterior laws. Also, as we focus on the inverse problems, we call this method BPINN-IP, and we show that the standard PINN formulation naturally appears as its special case corresponding to the Maximum A Posteriori (MAP) estimate. This unified formulation allows simultaneous exploitation of physical constraints, prior knowledge, and data-driven inference, while enabling uncertainty quantification through posterior distributions. To demonstrate the effectiveness of the proposed framework, we consider inverse problems arising in infrared image processing, including deconvolution and super-resolution, and present results on both simulated and real industrial data.",
          "authors": [
            "Ali Mohammad-Djafari",
            "Ning Chu",
            "Li Wang"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02496",
          "title": "Attention-guided reference point shifting for Gaussian-mixture-based partial point set registration",
          "abstract": "This study investigates the impact of the invariance of feature vectors for partial-to-partial point set registration under translation and rotation of input point sets, particularly in the realm of techniques based on deep learning and Gaussian mixture models (GMMs). We reveal both theoretical and practical problems associated with such deep-learning-based registration methods using GMMs, with a particular focus on the limitations of DeepGMR, a pioneering study in this line, to the partial-to-partial point set registration. Our primary goal is to uncover the causes behind such methods and propose a comprehensible solution for that. To address this, we introduce an attention-based reference point shifting (ARPS) layer, which robustly identifies a common reference point of two partial point sets, thereby acquiring transformation-invariant features. The ARPS layer employs a well-studied attention module to find a common reference point rather than the overlap region. Owing to this, it significantly enhances the performance of DeepGMR and its recent variant, UGMMReg. Furthermore, these extension models outperform even prior deep learning methods using attention blocks and Transformer to extract the overlap region or common reference points. We believe these findings provide deeper insights into registration methods using deep learning and GMMs.",
          "authors": [
            "Mizuki Kikkawa",
            "Tatsuya Yatagawa",
            "Yutaka Ohtake",
            "Hiromasa Suzuki"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02497",
          "title": "A Large Scale Benchmark for Test Time Adaptation Methods in Medical Image Segmentation",
          "abstract": "Test time Adaptation is a promising approach for mitigating domain shift in medical image segmentation; however, current evaluations remain limited in terms of modality coverage, task diversity, and methodological consistency. We present MedSeg-TTA, a comprehensive benchmark that examines twenty representative adaptation methods across seven imaging modalities, including MRI, CT, ultrasound, pathology, dermoscopy, OCT, and chest X-ray, under fully unified data preprocessing, backbone configuration, and test time protocols. The benchmark encompasses four significant adaptation paradigms: Input-level Transformation, Feature-level Alignment, Output-level Regularization, and Prior Estimation, enabling the first systematic cross-modality comparison of their reliability and applicability. The results show that no single paradigm performs best in all conditions. Input-level methods are more stable under mild appearance shifts. Feature-level and Output-level methods offer greater advantages in boundary-related metrics, whereas prior-based methods exhibit strong modality dependence. Several methods degrade significantly under large inter-center and inter-device shifts, which highlights the importance of principled method selection for clinical deployment. MedSeg-TTA provides standardized datasets, validated implementations, and a public leaderboard, establishing a rigorous foundation for future research on robust, clinically reliable test-time adaptation. All source codes and open-source datasets are available at this https URL .",
          "authors": [
            "Wenjing Yu",
            "Shuo Jiang",
            "Yifei Chen",
            "Shuo Chang",
            "Yuanhan Wang",
            "Beining Wu",
            "Jie Dong",
            "Mingxuan Liu",
            "Shenghao Zhu",
            "Feiwei Qin",
            "Changmiao Wang",
            "Qiyuan Tian"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02498",
          "title": "dots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model",
          "abstract": "Document Layout Parsing serves as a critical gateway for Artificial Intelligence (AI) to access and interpret the world's vast stores of structured knowledge. This process,which encompasses layout detection, text recognition, and relational understanding, is particularly crucial for empowering next-generation Vision-Language Models. Current methods, however, rely on fragmented, multi-stage pipelines that suffer from error propagation and fail to leverage the synergies of joint training. In this paper, we introduce this http URL , a single Vision-Language Model that, for the first time, demonstrates the advantages of jointly learning three core tasks within a unified, end-to-end framework. This is made possible by a highly scalable data engine that synthesizes a vast multilingual corpus, empowering the model to deliver robust performance across a wide array of tasks, encompassing diverse languages, layouts, and domains. The efficacy of our unified paradigm is validated by state-of-the-art performance on the comprehensive OmniDocBench. Furthermore, to catalyze research in global document intelligence, we introduce XDocParse, a challenging new benchmark spanning 126 languages. On this testbed, this http URL establishes a powerful new baseline, outperforming the next-best competitor by a remarkable +7.4 point margin and proving its unparalleled multilingual capabilities.",
          "authors": [
            "Yumeng Li",
            "Guang Yang",
            "Hao Liu",
            "Bowen Wang",
            "Colin Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02499",
          "title": "COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes",
          "abstract": "Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.",
          "authors": [
            "Yongkai Liu",
            "Helena Feng",
            "Bin Jiang",
            "Yixin Wang",
            "Max Wintermark",
            "David S. Liebeskind",
            "Michael Moseley",
            "Maarten Lansberg",
            "Gregory Albers",
            "Jeremy Heit",
            "Greg Zaharchuk"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02502",
          "title": "AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations",
          "abstract": "The \"15-minute city\" envisions neighborhoods where residents can meet daily needs via a short walk or bike ride. Realizing this vision requires not only physical proximity but also efficient and reliable access to information about nearby places, services, and events. Existing location-based systems, however, focus mainly on city-level tasks and neglect the spatial, temporal, and cognitive factors that shape localized decision-making. We conceptualize this gap as the Local Life Information Accessibility (LLIA) problem and introduce AskNearby, an AI-driven community application that unifies retrieval and recommendation within the 15-minute life circle. AskNearby integrates (i) a three-layer Retrieval-Augmented Generation (RAG) pipeline that synergizes graph-based, semantic-vector, and geographic retrieval with (ii) a cognitive-map model that encodes each user's neighborhood familiarity and preferences. Experiments on real-world community datasets demonstrate that AskNearby significantly outperforms LLM-based and map-based baselines in retrieval accuracy and recommendation quality, achieving robust performance in spatiotemporal grounding and cognitive-aware ranking. Real-world deployments further validate its effectiveness. By addressing the LLIA challenge, AskNearby empowers residents to more effectively discover local resources, plan daily activities, and engage in community life.",
          "authors": [
            "Luyao Niu",
            "Zhicheng Deng",
            "Boyang Li",
            "Nuoxian Huang",
            "Ruiqi Liu",
            "Wenjia Zhang"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02503",
          "title": "Individual-specific precision neuroimaging of learning-related plasticity",
          "abstract": "Studying learning-related plasticity is central to understanding the acquisition of complex skills, for example learning to master a musical instrument. Over the past three decades, conventional group-based functional magnetic resonance imaging (fMRI) studies have advanced our understanding of how humans' neural representations change during skill acquisition. However, group-based fMRI studies average across heterogeneous learners and often rely on coarse pre- versus post-training comparisons, limiting the spatial and temporal precision with which neural changes can be estimated. Here, we outline an individual-specific precision approach that tracks neural changes within individuals by collecting high-quality neuroimaging data frequently over the course of training, mapping brain function in each person's own anatomical space, and gathering detailed behavioral measures of learning, allowing neural trajectories to be directly linked to individual learning progress. Complementing fMRI with mobile neuroimaging methods, such as functional near-infrared spectroscopy (fNIRS), will enable researchers to track plasticity during naturalistic practice and across extended time scales. This multi-modal approach will enhance sensitivity to individual learning trajectories and will offer more nuanced insights into how neural representations change with training. We also discuss how findings can be generalized beyond individuals, including through statistical methods based on replication in additional individuals. Together, this approach allows researchers to design highly informative longitudinal training studies that advance a mechanistic, personalized account of skill learning in the human brain.",
          "authors": [
            "Simon Leipold",
            "Ryssa Moffat"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02505",
          "title": "GeoDiT: A Diffusion-based Vision-Language Model for Geospatial Understanding",
          "abstract": "Autoregressive models are structurally misaligned with the inherently parallel nature of geospatial understanding, forcing a rigid sequential narrative onto scenes and fundamentally hindering the generation of structured and coherent outputs. We challenge this paradigm by reframing geospatial generation as a parallel refinement process, enabling a holistic, coarse-to-fine synthesis that resolves all semantic elements simultaneously. To operationalize this, we introduce GeoDiT, the first diffusion-based vision-language model tailored for the geospatial domain. Extensive experiments demonstrate that GeoDiT establishes a new state-of-the-art on benchmarks requiring structured, object-centric outputs. It achieves significant gains in image captioning, visual grounding, and multi-object detection, precisely the tasks where autoregressive models falter. Our work validates that aligning the generative process with the data's intrinsic structure is key to unlocking superior performance in complex geospatial analysis.",
          "authors": [
            "Jiaqi Liu",
            "Ronghao Fu",
            "Haoran Liu",
            "Lang Sun",
            "Bo Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02508",
          "title": "Water Quality Estimation Through Machine Learning Multivariate Analysis",
          "abstract": "The quality of water is key for the quality of agrifood sector. Water is used in agriculture for fertigation, for animal husbandry, and in the agrifood processing industry. In the context of the progressive digitalization of this sector, the automatic assessment of the quality of water is thus becoming an important asset. In this work, we present the integration of Ultraviolet-Visible (UV-Vis) spectroscopy with Machine Learning in the context of water quality assessment aiming at ensuring water safety and the compliance of water regulation. Furthermore, we emphasize the importance of model interpretability by employing SHapley Additive exPlanations (SHAP) to understand the contribution of absorbance at different wavelengths to the predictions. Our approach demonstrates the potential for rapid, accurate, and interpretable assessment of key water quality parameters.",
          "authors": [
            "Marco Cardia",
            "Stefano Chessa",
            "Alessio Micheli",
            "Antonella Giuliana Luminare",
            "Francesca Gambineri"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02509",
          "title": "The Invisible Hand: Characterizing Generative AI Adoption and its Effects on An Online Freelancing Market",
          "abstract": "Since the COVID-19 pandemic, freelancing platforms have experienced significant growth in both worker registrations and job postings. However, the rise of generative AI (GenAI) technologies has raised questions about how it affect the job posting in freelancer market. Despite growing discussions, there is limited empirical research on the GenAI adoption and its effect on job demand and worker engagement. We present a large-scale analysis of this http URL , utilizing over 1.8 million job posts and 3.8 million users. We investigate the emergence of jobs with the adoption of GenAI and identify leading position of ChatGPT in the freelancing market. With a focus on ChatGPT related jobs, we inspect their specific skill requirements, and the tasks that workers are asked to perform. Our findings provide insights into the evolving landscape of freelancing in the age of AI, offering a comprehensive profile of GenAI's effects on employment, skills, and user behaviors in freelancing market.",
          "authors": [
            "Yiming Zhu",
            "Gareth Tyson",
            "Pan Hui"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02512",
          "title": "Two-Stage Vision Transformer for Image Restoration: Colorization Pretraining + Residual Upsampling",
          "abstract": "In computer vision, Single Image Super-Resolution (SISR) is still a difficult problem. We present ViT-SR, a new technique to improve the performance of a Vision Transformer (ViT) employing a two-stage training strategy. In our method, the model learns rich, generalizable visual representations from the data itself through a self-supervised pretraining phase on a colourization task. The pre-trained model is then adjusted for 4x super-resolution. By predicting the addition of a high-frequency residual image to an initial bicubic interpolation, this design simplifies residual learning. ViT-SR, trained and evaluated on the DIV2K benchmark dataset, achieves an impressive SSIM of 0.712 and PSNR of 22.90 dB. These results demonstrate the efficacy of our two-stage approach and highlight the potential of self-supervised pre-training for complex image restoration tasks. Further improvements may be possible with larger ViT architectures or alternative pretext tasks.",
          "authors": [
            "Aditya Chaudhary",
            "Prachet Dev Singh",
            "Ankit Jha"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02513",
          "title": "Decentralized Fairness Aware Multi Task Federated Learning for VR Network",
          "abstract": "Wireless connectivity promises to unshackle virtual reality (VR) experiences, allowing users to engage from anywhere, anytime. However, delivering seamless, high-quality, real-time VR video wirelessly is challenging due to the stringent quality of experience requirements, low latency constraints, and limited VR device capabilities. This paper addresses these challenges by introducing a novel decentralized multi task fair federated learning (DMTFL) based caching that caches and prefetches each VR user's field of view (FOV) at base stations (BSs) based on the caching strategies tailored to each BS. In federated learning (FL) in its naive form, often biases toward certain users, and a single global model fails to capture the statistical heterogeneity across users and BSs. In contrast, the proposed DMTFL algorithm personalizes content delivery by learning individual caching models at each BS. These models are further optimized to perform well under any target distribution, while providing theoretical guarantees via Rademacher complexity and a probably approximately correct (PAC) bound on the loss. Using a realistic VR head-tracking dataset, our simulations demonstrate the superiority of our proposed DMTFL algorithm compared to baseline algorithms.",
          "authors": [
            "Krishnendu S. Tharakan",
            "Carlo Fischione"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02513",
          "title": "Decentralized Fairness Aware Multi Task Federated Learning for VR Network",
          "abstract": "Wireless connectivity promises to unshackle virtual reality (VR) experiences, allowing users to engage from anywhere, anytime. However, delivering seamless, high-quality, real-time VR video wirelessly is challenging due to the stringent quality of experience requirements, low latency constraints, and limited VR device capabilities. This paper addresses these challenges by introducing a novel decentralized multi task fair federated learning (DMTFL) based caching that caches and prefetches each VR user's field of view (FOV) at base stations (BSs) based on the caching strategies tailored to each BS. In federated learning (FL) in its naive form, often biases toward certain users, and a single global model fails to capture the statistical heterogeneity across users and BSs. In contrast, the proposed DMTFL algorithm personalizes content delivery by learning individual caching models at each BS. These models are further optimized to perform well under any target distribution, while providing theoretical guarantees via Rademacher complexity and a probably approximately correct (PAC) bound on the loss. Using a realistic VR head-tracking dataset, our simulations demonstrate the superiority of our proposed DMTFL algorithm compared to baseline algorithms.",
          "authors": [
            "Krishnendu S. Tharakan",
            "Carlo Fischione"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02515",
          "title": "VibOmni: Towards Scalable Bone-conduction Speech Enhancement on Earables",
          "abstract": "Earables, such as True Wireless Stereo earphones and VR/AR headsets, are increasingly popular, yet their compact design poses challenges for robust voice-related applications like telecommunication and voice assistant interactions in noisy environments. Existing speech enhancement systems, reliant solely on omnidirectional microphones, struggle with ambient noise like competing speakers. To address these issues, we propose VibOmni, a lightweight, end-to-end multi-modal speech enhancement system for earables that leverages bone-conducted vibrations captured by widely available Inertial Measurement Units (IMUs). VibOmni integrates a two-branch encoder-decoder deep neural network to fuse audio and vibration features. To overcome the scarcity of paired audio-vibration datasets, we introduce a novel data augmentation technique that models Bone Conduction Functions (BCFs) from limited recordings, enabling synthetic vibration data generation with only 4.5% spectrogram similarity error. Additionally, a multi-modal SNR estimator facilitates continual learning and adaptive inference, optimizing performance in dynamic, noisy settings without on-device back-propagation. Evaluated on real-world datasets from 32 volunteers with different devices, VibOmni achieves up to 21% improvement in Perceptual Evaluation of Speech Quality (PESQ), 26% in Signal-to-Noise Ratio (SNR), and about 40% WER reduction with much less latency on mobile devices. A user study with 35 participants showed 87% preferred VibOmni over baselines, demonstrating its effectiveness for deployment in diverse acoustic environments.",
          "authors": [
            "Lixing He",
            "Yunqi Guo",
            "Haozheng Hou",
            "Zhenyu Yan"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02517",
          "title": "SkyMoE: A Vision-Language Foundation Model for Enhancing Geospatial Interpretation with Mixture of Experts",
          "abstract": "The emergence of large vision-language models (VLMs) has significantly enhanced the efficiency and flexibility of geospatial interpretation. However, general-purpose VLMs remain suboptimal for remote sensing (RS) tasks. Existing geospatial VLMs typically adopt a unified modeling strategy and struggle to differentiate between task types and interpretation granularities, limiting their ability to balance local detail perception and global contextual understanding. In this paper, we present SkyMoE, a Mixture-of-Experts (MoE) vision-language model tailored for multimodal, multi-task RS interpretation. SkyMoE employs an adaptive router that generates task- and granularity-aware routing instructions, enabling specialized large language model experts to handle diverse sub-tasks. To further promote expert decoupling and granularity sensitivity, we introduce a context-disentangled augmentation strategy that creates contrastive pairs between local and global features, guiding experts toward level-specific representation learning. We also construct MGRS-Bench, a comprehensive benchmark covering multiple RS interpretation tasks and granularity levels, to evaluate generalization in complex scenarios. Extensive experiments on 21 public datasets demonstrate that SkyMoE achieves state-of-the-art performance across tasks, validating its adaptability, scalability, and superior multi-granularity understanding in remote sensing.",
          "authors": [
            "Jiaqi Liu",
            "Ronghao Fu",
            "Lang Sun",
            "Haoran Liu",
            "Xiao Yang",
            "Weipeng Zhang",
            "Xu Na",
            "Zhuoran Duan",
            "Bo Yang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02520",
          "title": "On the Problem of Consistent Anomalies in Zero-Shot Anomaly Detection",
          "abstract": "Zero-shot anomaly classification and segmentation (AC/AS) aim to detect anomalous samples and regions without any training data, a capability increasingly crucial in industrial inspection and medical imaging. This dissertation aims to investigate the core challenges of zero-shot AC/AS and presents principled solutions rooted in theory and algorithmic design. We first formalize the problem of consistent anomalies, a failure mode in which recurring similar anomalies systematically bias distance-based methods. By analyzing the statistical and geometric behavior of patch representations from pre-trained Vision Transformers, we identify two key phenomena - similarity scaling and neighbor-burnout - that describe how relationships among normal patches change with and without consistent anomalies in settings characterized by highly similar objects. We then introduce CoDeGraph, a graph-based framework for filtering consistent anomalies built on the similarity scaling and neighbor-burnout phenomena. Through multi-stage graph construction, community detection, and structured refinement, CoDeGraph effectively suppresses the influence of consistent anomalies. Next, we extend this framework to 3D medical imaging by proposing a training-free, computationally efficient volumetric tokenization strategy for MRI data. This enables a genuinely zero-shot 3D anomaly detection pipeline and shows that volumetric anomaly segmentation is achievable without any 3D training samples. Finally, we bridge batch-based and text-based zero-shot methods by demonstrating that CoDeGraph-derived pseudo-masks can supervise prompt-driven vision-language models. Together, this dissertation provides theoretical understanding and practical solutions for the zero-shot AC/AS problem.",
          "authors": [
            "Tai Le-Gia"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02520",
          "title": "On the Problem of Consistent Anomalies in Zero-Shot Anomaly Detection",
          "abstract": "Zero-shot anomaly classification and segmentation (AC/AS) aim to detect anomalous samples and regions without any training data, a capability increasingly crucial in industrial inspection and medical imaging. This dissertation aims to investigate the core challenges of zero-shot AC/AS and presents principled solutions rooted in theory and algorithmic design. We first formalize the problem of consistent anomalies, a failure mode in which recurring similar anomalies systematically bias distance-based methods. By analyzing the statistical and geometric behavior of patch representations from pre-trained Vision Transformers, we identify two key phenomena - similarity scaling and neighbor-burnout - that describe how relationships among normal patches change with and without consistent anomalies in settings characterized by highly similar objects. We then introduce CoDeGraph, a graph-based framework for filtering consistent anomalies built on the similarity scaling and neighbor-burnout phenomena. Through multi-stage graph construction, community detection, and structured refinement, CoDeGraph effectively suppresses the influence of consistent anomalies. Next, we extend this framework to 3D medical imaging by proposing a training-free, computationally efficient volumetric tokenization strategy for MRI data. This enables a genuinely zero-shot 3D anomaly detection pipeline and shows that volumetric anomaly segmentation is achievable without any 3D training samples. Finally, we bridge batch-based and text-based zero-shot methods by demonstrating that CoDeGraph-derived pseudo-masks can supervise prompt-driven vision-language models. Together, this dissertation provides theoretical understanding and practical solutions for the zero-shot AC/AS problem.",
          "authors": [
            "Tai Le-Gia"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02523",
          "title": "Generative Multi-modal Feedback for Singing Voice Synthesis Evaluation",
          "abstract": "Singing voice synthesis (SVS) has advanced significantly, enabling models to generate vocals with accurate pitch and consistent style. As these capabilities improve, the need for reliable evaluation and optimization becomes increasingly critical. However, current methods like reward systems often rely on single numerical scores, struggle to capture various dimensions such as phrasing or expressiveness, and require costly annotations, limiting interpretability and generalization. To address these issues, we propose a generative feedback (i.e., reward model) framework that provides multi-dimensional language and audio feedback for SVS assessment. Our approach leverages an audio-language model to generate text and audio critiques-covering aspects such as melody, content, and auditory quality. The model is fine-tuned on a hybrid dataset combining human music reactions and synthetic critiques from a MLLMs, enhancing diversity and linguistic richness. Quantitative experiments validate the effectiveness of the proposed dataset and training strategy, demonstrating that the framework produces musically accurate and interpretable evaluations suitable for guiding generative model improvement. The code is at [ this https URL ]( this https URL )",
          "authors": [
            "Xueyan Li",
            "Yuxin Wang",
            "Mengjie Jiang",
            "Qingzi Zhu",
            "Jiang Zhang",
            "Zoey Kim",
            "Yazhe Niu"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02527",
          "title": "A Concise Review of Hallucinations in LLMs and their Mitigation",
          "abstract": "Traditional language models face a challenge from hallucinations. Their very presence casts a large, dangerous shadow over the promising realm of natural language processing. It becomes crucial to understand the various kinds of hallucinations that occur nowadays, their origins, and ways of reducing them. This document provides a concise and straightforward summary of that. It serves as a one-stop resource for a general understanding of hallucinations and how to mitigate them.",
          "authors": [
            "Parth Pulkundwar",
            "Vivek Dhanawade",
            "Rohit Yadav",
            "Minal Sonkar",
            "Medha Asurlekar",
            "Sarita Rathod"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02530",
          "title": "Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration",
          "abstract": "The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and this http URL a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge this http URL experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.",
          "authors": [
            "Yuxiang He",
            "Jian Zhao",
            "Yuchen Yuan",
            "Tianle Zhang",
            "Wei Cai",
            "Haojie Cheng",
            "Ziyan Shi",
            "Ming Zhu",
            "Haichuan Tang",
            "Chi Zhang",
            "Xuelong Li"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02532",
          "title": "Laplace Approximation For Tensor Train Kernel Machines In System Identification",
          "abstract": "To address the scalability limitations of Gaussian process (GP) regression, several approximation techniques have been proposed. One such method is based on tensor networks, which utilizes an exponential number of basis functions without incurring exponential computational cost. However, extending this model to a fully probabilistic formulation introduces several design challenges. In particular, for tensor train (TT) models, it is unclear which TT-core should be treated in a Bayesian manner. We introduce a Bayesian tensor train kernel machine that applies Laplace approximation to estimate the posterior distribution over a selected TT-core and employs variational inference (VI) for precision hyperparameters. Experiments show that core selection is largely independent of TT-ranks and feature structure, and that VI replaces cross-validation while offering up to 65x faster training. The method's effectiveness is demonstrated on an inverse dynamics problem.",
          "authors": [
            "Albert Saiapin",
            "Kim Batselier"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02532",
          "title": "Laplace Approximation For Tensor Train Kernel Machines In System Identification",
          "abstract": "To address the scalability limitations of Gaussian process (GP) regression, several approximation techniques have been proposed. One such method is based on tensor networks, which utilizes an exponential number of basis functions without incurring exponential computational cost. However, extending this model to a fully probabilistic formulation introduces several design challenges. In particular, for tensor train (TT) models, it is unclear which TT-core should be treated in a Bayesian manner. We introduce a Bayesian tensor train kernel machine that applies Laplace approximation to estimate the posterior distribution over a selected TT-core and employs variational inference (VI) for precision hyperparameters. Experiments show that core selection is largely independent of TT-ranks and feature structure, and that VI replaces cross-validation while offering up to 65x faster training. The method's effectiveness is demonstrated on an inverse dynamics problem.",
          "authors": [
            "Albert Saiapin",
            "Kim Batselier"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02533",
          "title": "PopSim: Social Network Simulation for Social Media Popularity Prediction",
          "abstract": "Accurately predicting the popularity of user-generated content (UGC) is essential for advancing social media analytics and recommendation systems. Existing approaches typically follow an inductive paradigm, where researchers train static models on historical data for popularity prediction. However, the UGC propagation is inherently a dynamic process, and static modeling based on historical features fails to capture the complex interactions and nonlinear evolution. In this paper, we propose PopSim, a novel simulation-based paradigm for social media popularity prediction (SMPP). Unlike the inductive paradigm, PopSim leverages the large language models (LLMs)-based multi-agent social network sandbox to simulate UGC propagation dynamics for popularity prediction. Specifically, to effectively model the UGC propagation process in the network, we design a social-mean-field-based agent interaction mechanism, which models the dual-channel and bidirectional individual-population interactions, enhancing agents' global perception and decision-making capabilities. In addition, we propose a multi-source information aggregation module that transforms heterogeneous social metadata into a uniform formulation for LLMs. Finally, propagation dynamics with multimodal information are fused to provide comprehensive popularity prediction. Extensive experiments on real-world datasets demonstrate that SimPop consistently outperforms the state-of-the-art methods, reducing prediction error by an average of 8.82%, offering a new perspective for research on the SMPP task.",
          "authors": [
            "Yijun Liu",
            "Wu Liu",
            "Xiaoyan Gu",
            "Allen He",
            "Weiping Wang",
            "Yongdong Zhang"
          ],
          "primary_category": "cs.MM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02534",
          "title": "Detection of Crowdsourcing Cryptocurrency Laundering via Multi-Task Collaboration",
          "abstract": "USDT, a stablecoin pegged to dollar, has become a preferred choice for money laundering due to its stability, anonymity, and ease of use. Notably, a new form of money laundering on stablecoins -- we refer to as crowdsourcing laundering -- disperses funds through recruiting a large number of ordinary individuals, and has rapidly emerged as a significant threat. However, due to the refined division of labor, crowdsourcing laundering transactions exhibit diverse patterns and a polycentric structure, posing significant challenges for detection. In this paper, we introduce transaction group as auxiliary information, and propose the Multi-Task Collaborative Crowdsourcing Laundering Detection (MCCLD) framework. MCCLD employs an end-to-end graph neural network to realize collaboration between laundering transaction detection and transaction group detection tasks, enhancing detection performance on diverse patterns within crowdsourcing laundering group. These two tasks are jointly optimized through a shared classifier, with a shared feature encoder that fuses multi-level feature embeddings to provide rich transaction semantics and potential group information. Extensive experiments on both crowdsourcing and general laundering demonstrate MCCLD's effectiveness and generalization. To the best of our knowledge, this is the first work on crowdsourcing laundering detection.",
          "authors": [
            "Guang Li",
            "Litong Sun",
            "Jieying Zhou",
            "Weigang Wu"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02535",
          "title": "AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning",
          "abstract": "Information gathering in large-scale or time-critical scenarios (e.g., environmental monitoring, search and rescue) requires broad coverage within limited time budgets, motivating the use of multi-agent systems. These scenarios are commonly formulated as multi-agent informative path planning (MAIPP), where multiple agents must coordinate to maximize information gain while operating under budget constraints. A central challenge in MAIPP is ensuring effective coordination while the belief over the environment evolves with incoming measurements. Recent learning-based approaches address this by using distributions over future positions as \"intent\" to support coordination. However, these autoregressive intent predictors are computationally expensive and prone to compounding errors. Inspired by the effectiveness of diffusion models as expressive, long-horizon policies, we propose AID, a fully decentralized MAIPP framework that leverages diffusion models to generate long-term trajectories in a non-autoregressive manner. AID first performs behavior cloning on trajectories produced by existing MAIPP planners and then fine-tunes the policy using reinforcement learning via Diffusion Policy Policy Optimization (DPPO). This two-stage pipeline enables the policy to inherit expert behavior while learning improved coordination through online reward feedback. Experiments demonstrate that AID consistently improves upon the MAIPP planners it is trained from, achieving up to 4x faster execution and 17% increased information gain, while scaling effectively to larger numbers of agents. Our implementation is publicly available at this https URL .",
          "authors": [
            "Jeric Lew",
            "Yuhong Cao",
            "Derek Ming Siang Tan",
            "Guillaume Sartoretti"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02536",
          "title": "WeMMU: Enhanced Bridging of Vision-Language Models and Diffusion Models via Noisy Query Tokens",
          "abstract": "Recent progress in multimodal large language models (MLLMs) has highlighted the challenge of efficiently bridging pre-trained Vision-Language Models (VLMs) with Diffusion Models. While methods using a fixed number of learnable query tokens offer computational efficiency, they suffer from task generalization collapse, failing to adapt to new tasks that are distant from their pre-training tasks. To overcome this, we propose Noisy Query Tokens, which learn a distributed representation space between the VLM and Diffusion Model via end-to-end optimization, enhancing continual learning. Additionally, we introduce a VAE branch with linear projection to recover fine-grained image details. Experimental results confirm our approach mitigates generalization collapse and enables stable continual learning across diverse tasks.",
          "authors": [
            "Jian Yang",
            "Dacheng Yin",
            "Xiaoxuan He",
            "Yong Li",
            "Fengyun Rao",
            "Jing Lyu",
            "Wei Zhai",
            "Yang Cao",
            "Zheng-Jun Zha"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02541",
          "title": "AVGGT: Rethinking Global Attention for Accelerating VGGT",
          "abstract": "Since DUSt3R, models such as VGGT and $\\pi^3$ have shown strong multi-view 3D performance, but their heavy reliance on global self-attention results in high computational cost. Existing sparse-attention variants offer partial speedups, yet lack a systematic analysis of how global attention contributes to multi-view reasoning. In this paper, we first conduct an in-depth investigation of the global attention modules in VGGT and $\\pi^3$ to better understand their roles. Our analysis reveals a clear division of roles in the alternating global-frame architecture: early global layers do not form meaningful correspondences, middle layers perform cross-view alignment, and last layers provide only minor refinements. Guided by these findings, we propose a training-free two-step acceleration scheme: (1) converting early global layers into frame attention, and (2) subsampling global attention by subsampling K/V over patch tokens with diagonal preservation and a mean-fill component. We instantiate this strategy on VGGT and $\\pi^3$ and evaluate across standard pose and point-map benchmarks. Our method achieves up to $8$-$10\\times$ speedup in inference time while matching or slightly improving the accuracy of the original models, and remains robust even in extremely dense multi-view settings where prior sparse-attention baselines fail.",
          "authors": [
            "Xianbing Sun",
            "Zhikai Zhu",
            "Zhengyu Lou",
            "Bo Yang",
            "Jinyang Tang",
            "Liqing Zhang",
            "He Wang",
            "Jianfu Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02543",
          "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs",
          "abstract": "The world currently has an abundance of ideas for how to use new LLM agents, and developers seek to rapidly prototype and test new agentic designs. However, executing agents at scale using high-capacity LLMs incurs high inference costs. We propose a simple method for reducing LLM agent inference costs without incurring the development friction costs associated with LLM fine-tuning (long training cycles, optimization hyperparameter tweaking loops) or manual prompt engineering (laborious trial and error). Most importantly, we introduce $\\textit{in-context distillation}$, which adapts the idea of knowledge distillation (training a low cost-student model to mimic a high-cost teacher) to an in-context learning setting. Our approach retrieves relevant teacher demonstrations at each agent step and provides them to the student as in-context examples, enabling the student to imitate teacher behavior on-the-fly. We combine in-context distillation with the established idea of $\\textit{self-consistency cascades}$ to know when the trust the student. This adaptive strategy realizes the cost benefits of model specialization while preserving the productivity of working with frozen models. On the multi-step embodied reasoning benchmark ALFWorld, our method matches teacher-level accuracy at $\\textbf{2.5$\\times$ lower cost}$, reducing per-episode costs from \\$0.059 to \\$0.024. The upfront demonstration cost amortizes after just 843 episodes, yielding cumulative savings exceeding \\$34,900 at deployment scale (1M episodes). On AppWorld, a complex agent benchmark requiring multi-step API workflows, we shift the Pareto frontier by achieving a $\\textbf{2$\\times$ cost reduction}$ at iso-accuracy. By reducing operational costs while maintaining rapid experimentation cycles with frozen models, our approach makes advanced agentic systems economically viable for a broader range of applications.",
          "authors": [
            "Vishnu Sarukkai",
            "Asanshay Gupta",
            "James Hong",
            "Michaël Gharbi",
            "Kayvon Fatahalian"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02544",
          "title": "A Human-centric Framework for Debating the Ethics of AI Consciousness Under Uncertainty",
          "abstract": "As AI systems become increasingly sophisticated, questions about machine consciousness and its ethical implications have moved from fringe speculation to mainstream academic debate. Current ethical frameworks in this domain often implicitly rely on contested functionalist assumptions, prioritize speculative AI welfare over concrete human interests, and lack coherent theoretical foundations. We address these limitations through a structured three-level framework grounded in philosophical uncertainty. At the foundational level, we establish five factual determinations about AI consciousness alongside human-centralism as our meta-ethical stance. These foundations logically entail three operational principles: presumption of no consciousness (placing the burden of proof on consciousness claims), risk prudence (prioritizing human welfare under uncertainty), and transparent reasoning (enabling systematic evaluation and adaptation). At the application level, the third component of our framework, we derive default positions on pressing ethical questions through a transparent logical process where each position can be explicitly traced back to our foundational commitments. Our approach balances philosophical rigor with practical guidance, distinguishes consciousness from anthropomorphism, and creates pathways for responsible evolution as scientific understanding advances, providing a human-centric foundation for navigating these profound ethical challenges.",
          "authors": [
            "Zhou Ziheng",
            "Haiqiang Dai",
            "Bin Ling",
            "Ying Nian Wu",
            "Demetri Terzopoulos"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02546",
          "title": "Solutions for Distributed Memory Access Mechanism on HPC Clusters",
          "abstract": "Paper presents and evaluates various mechanisms for remote access to memory in distributed systems based on two distinct HPC clusters. We are comparing solutions based on the shared storage and MPI (over Infiniband and Slingshot) to the local memory access. This paper also mentions medical use-cases that would mostly benefit from the described solution. We have found out that results for remote access esp. backed by MPI are similar to local memory access.",
          "authors": [
            "Jan Meizner",
            "Maciej Malawski"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02547",
          "title": "Tensor Network Based Feature Learning Model",
          "abstract": "Many approximations were suggested to circumvent the cubic complexity of kernel-based algorithms, allowing their application to large-scale datasets. One strategy is to consider the primal formulation of the learning problem by mapping the data to a higher-dimensional space using tensor-product structured polynomial and Fourier features. The curse of dimensionality due to these tensor-product features was effectively solved by a tensor network reparameterization of the model parameters. However, another important aspect of model training - identifying optimal feature hyperparameters - has not been addressed and is typically handled using the standard cross-validation approach. In this paper, we introduce the Feature Learning (FL) model, which addresses this issue by representing tensor-product features as a learnable Canonical Polyadic Decomposition (CPD). By leveraging this CPD structure, we efficiently learn the hyperparameters associated with different features alongside the model parameters using an Alternating Least Squares (ALS) optimization method. We prove the effectiveness of the FL model through experiments on real data of various dimensionality and scale. The results show that the FL model can be consistently trained 3-5 times faster than and have the prediction quality on par with a standard cross-validated model.",
          "authors": [
            "Albert Saiapin",
            "Kim Batselier"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02549",
          "title": "Robotic capabilities framework: A boundary object and intermediate-level knowledge artifact for co-designing robotic processes",
          "abstract": "As robots become more adaptable, responsive, and capable of interacting with humans, the design of effective human-robot collaboration becomes critical. Yet, this design process is typically led by monodisciplinary approaches, often overlooking interdisciplinary knowledge and the experiential knowledge of workers who will ultimately share tasks with these systems. To address this gap, we introduce the robotic capabilities framework, a vocabulary that enables transdisciplinary collaborations to meaningfully shape the future of work when robotic systems are integrated into the workplace. Rather than focusing on the internal workings of robots, the framework centers discussion on high-level capabilities, supporting dialogue around which elements of a task should remain human-led and which can be delegated to robots. We developed the framework through reflexive and iterative processes, and applied it in two distinct settings: by engaging roboticists in describing existing commercial robots using its vocabulary, and through a design activity with students working on robotics-related projects. The framework emerges as an intermediate-level knowledge artifact and a boundary object that bridges technical and experiential domains, guiding designers, empowering workers, and contributing to more just and collaborative futures of work.",
          "authors": [
            "Alessandro Ianniello",
            "Dave Murray-Rust",
            "Sara Muscolo",
            "Olger Siebinga",
            "Nicky Mol",
            "Denis Zatyagov",
            "Eva Verhoef",
            "Deborah Forster",
            "David Abbink"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02550",
          "title": "Sparse Computations in Deep Learning Inference",
          "abstract": "The computational demands of modern Deep Neural Networks (DNNs) are immense and constantly growing. While training costs usually capture public attention, inference demands are also contributing in significant computational, energy and environmental footprints. Sparsity stands out as a critical mechanism for drastically reducing these resource demands. However, its potential remains largely untapped and is not yet fully incorporated in production AI systems. To bridge this gap, this work provides the necessary knowledge and insights for performance engineers keen to get involved in deep learning inference optimization. In particular, in this work we: a) discuss the various forms of sparsity that can be utilized in DNN inference, b) explain how the original dense computations translate to sparse kernels, c) provide an extensive bibliographic review of the state-of-the-art in the implementation of these kernels for CPUs and GPUs, d) discuss the availability of sparse datasets in support of sparsity-related research and development, e) explore the current software tools and frameworks that provide robust sparsity support, and f) present evaluation results of different implementations of the key SpMM and SDDMM kernels on CPU and GPU platforms. Ultimately, this paper aims to serve as a resource for performance engineers seeking to develop and deploy highly efficient sparse deep learning models in productions.",
          "authors": [
            "Ioanna Tasou",
            "Panagiotis Mpakos",
            "Angelos Vlachos",
            "Dionysios Adamopoulos",
            "Georgios Giannakopoulos",
            "Konstantinos Katsikopoulos",
            "Ioannis Karaparisis",
            "Maria Lazou",
            "Spyridon Loukovitis",
            "Areti Mei",
            "Anastasia Poulopoulou",
            "Angeliki Dimitriou",
            "Giorgos Filandrianos",
            "Dimitrios Galanopoulos",
            "Vasileios Karampinis",
            "Ilias Mitsouras",
            "Nikolaos Spanos",
            "Petros Anastasiadis",
            "Ioannis Doudalis",
            "Konstantinos Nikas",
            "George Retsinas",
            "Paraskevi Tzouveli",
            "Christina Giannoula",
            "Nectarios Koziris",
            "Nikela Papadopoulou",
            "Giorgos Stamou",
            "Athanasios Voulodimos",
            "Georgios Goumas"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02551",
          "title": "CUDA-L2: Surpassing cuBLAS Performance for Matrix Multiplication through Reinforcement Learning",
          "abstract": "In this paper, we propose CUDA-L2, a system that combines large language models (LLMs) and reinforcement learning (RL) to automatically optimize Half-precision General Matrix Multiply (HGEMM) CUDA kernels. Using CUDA execution speed as the RL reward, CUDA-L2 automatically optimizes HGEMM kernels across 1,000 configurations. CUDA-L2 systematically outperforms major matmul baselines to date, from the widely-used {\\it this http URL } to state-of-the-art Nvidia's closed-source libraries, i.e., {\\it cuBLAS}, {\\it cuBLASLt}. In offline mode, where kernels are executed consecutively without time intervals, CUDA-L2 yields +22.0\\% over {\\it this http URL } on average; +19.2\\% over {\\it cuBLAS} using the optimal layout configuration (normal-normal NN and transposed-normal TN); +16.8\\% over {\\it cuBLASLt-heuristic}, which queries {\\it cuBLASLt} library and selects the algorithm based on the heuristic's suggestion; and +11.4\\% over the most competitive {\\it cuBLASLt-AutoTuning} model, which selects the fastest algorithm from up to 100 candidates from {\\it cuBLASLt}'s suggestions. In server mode, where kernels are executed at random intervals simulating real-time inference, the speedups further increase to +28.7\\%, +26.0\\%, +22.4\\%, and +15.9\\% for {\\it this http URL }, {\\it cuBLAS}, {\\it cuBLASLt-heuristic}, and {\\it cuBLASLt-AutoTuning} respectively. CUDA-L2 shows that even the most performance-critical, heavily-optimized kernels like HGEMM can be improved through LLM-guided RL automation by systematically exploring configuration spaces at scales impractical for humans. Project and code can be found at this http URL",
          "authors": [
            "Songqiao Su",
            "Xiaofei Sun",
            "Xiaoya Li",
            "Albert Wang",
            "Jiwei Li",
            "Chris Shum"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02552",
          "title": "What Signals Really Matter for Misinformation Tasks? Evaluating Fake-News Detection and Virality Prediction under Real-World Constraints",
          "abstract": "We present an evaluation-driven study of two practical tasks regarding online misinformation: (i) fake-news detection and (ii) virality prediction in the context of operational settings, with the necessity for rapid reaction. Using the EVONS and FakeNewsNet datasets, we compare textual embeddings (RoBERTa; with a control using Mistral) against lightweight numeric features (timing, follower counts, verification, likes) and sequence models (GRU, gating architectures, Transformer encoders). We show that textual content alone is a strong discriminator for fake-news detection, while numeric-only pipelines remain viable when language models are unavailable or compute is constrained. Virality prediction is markedly harder than fake-news detection and is highly sensitive to label construction; in our setup, a median-based ''viral'' split (<50 likes) is pragmatic but underestimates real-world virality, and time-censoring for engagement features is desirable yet difficult under current API limits. Dimensionality-reduction analyses suggest non-linear structure is more informative for virality than for fake-news detection (t-SNE > PCA on numeric features). Swapping RoBERTa for Mistral embeddings yields only modest deltas, leaving conclusions unchanged. We discuss implications for evaluation design and report reproducibility constraints that realistically affect the field. We release splits and code where possible and provide guidance for metric selection.",
          "authors": [
            "Francesco Paolo Savatteri",
            "Chahan Vidal-Gorène",
            "Florian Cafiero"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02554",
          "title": "OmniPerson: Unified Identity-Preserving Pedestrian Generation",
          "abstract": "Person re-identification (ReID) suffers from a lack of large-scale high-quality training data due to challenges in data privacy and annotation costs. While previous approaches have explored pedestrian generation for data augmentation, they often fail to ensure identity consistency and suffer from insufficient controllability, thereby limiting their effectiveness in dataset augmentation. To address this, We introduce OmniPerson, the first unified identity-preserving pedestrian generation pipeline for visible/infrared image/video ReID tasks. Our contributions are threefold: 1) We proposed OmniPerson, a unified generation model, offering holistic and fine-grained control over all key pedestrian attributes. Supporting RGB/IR modality image/video generation with any number of reference images, two kinds of person poses, and text. Also including RGB-to-IR transfer and image super-resolution abilities.2) We designed Multi-Refer Fuser for robust identity preservation with any number of reference images as input, making OmniPerson could distill a unified identity from a set of multi-view reference images, ensuring our generated pedestrians achieve high-fidelity pedestrian generation.3) We introduce PersonSyn, the first large-scale dataset for multi-reference, controllable pedestrian generation, and present its automated curation pipeline which transforms public, ID-only ReID benchmarks into a richly annotated resource with the dense, multi-modal supervision required for this task. Experimental results demonstrate that OmniPerson achieves SoTA in pedestrian generation, excelling in both visual fidelity and identity consistency. Furthermore, augmenting existing datasets with our generated data consistently improves the performance of ReID models. We will open-source the full codebase, pretrained model, and the PersonSyn dataset.",
          "authors": [
            "Changxiao Ma",
            "Chao Yuan",
            "Xincheng Shi",
            "Yuzhuo Ma",
            "Yongfei Zhang",
            "Longkun Zhou",
            "Yujia Zhang",
            "Shangze Li",
            "Yifan Xu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02555",
          "title": "ADORE: Autonomous Domain-Oriented Relevance Engine for E-commerce",
          "abstract": "Relevance modeling in e-commerce search remains challenged by semantic gaps in term-matching methods (e.g., BM25) and neural models' reliance on the scarcity of domain-specific hard samples. We propose ADORE, a self-sustaining framework that synergizes three innovations: (1) A Rule-aware Relevance Discrimination module, where a Chain-of-Thought LLM generates intent-aligned training data, refined via Kahneman-Tversky Optimization (KTO) to align with user behavior; (2) An Error-type-aware Data Synthesis module that auto-generates adversarial examples to harden robustness; and (3) A Key-attribute-enhanced Knowledge Distillation module that injects domain-specific attribute hierarchies into a deployable student model. ADORE automates annotation, adversarial generation, and distillation, overcoming data scarcity while enhancing reasoning. Large-scale experiments and online A/B testing verify the effectiveness of ADORE. The framework establishes a new paradigm for resource-efficient, cognitively aligned relevance modeling in industrial applications.",
          "authors": [
            "Zheng Fang",
            "Donghao Xie",
            "Ming Pang",
            "Chunyuan Yuan",
            "Xue Jiang",
            "Changping Peng",
            "Zhangang Lin",
            "Zheng Luo"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02556",
          "title": "DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models",
          "abstract": "We introduce DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance. The key technical breakthroughs of DeepSeek-V3.2 are as follows: (1) DeepSeek Sparse Attention (DSA): We introduce DSA, an efficient attention mechanism that substantially reduces computational complexity while preserving model performance in long-context scenarios. (2) Scalable Reinforcement Learning Framework: By implementing a robust reinforcement learning protocol and scaling post-training compute, DeepSeek-V3.2 performs comparably to GPT-5. Notably, our high-compute variant, DeepSeek-V3.2-Speciale, surpasses GPT-5 and exhibits reasoning proficiency on par with Gemini-3.0-Pro, achieving gold-medal performance in both the 2025 International Mathematical Olympiad (IMO) and the International Olympiad in Informatics (IOI). (3) Large-Scale Agentic Task Synthesis Pipeline: To integrate reasoning into tool-use scenarios, we developed a novel synthesis pipeline that systematically generates training data at scale. This methodology facilitates scalable agentic post-training, yielding substantial improvements in generalization and instruction-following robustness within complex, interactive environments.",
          "authors": [
            "DeepSeek-AI",
            "Aixin Liu",
            "Aoxue Mei",
            "Bangcai Lin",
            "Bing Xue",
            "Bingxuan Wang",
            "Bingzheng Xu",
            "Bochao Wu",
            "Bowei Zhang",
            "Chaofan Lin",
            "Chen Dong",
            "Chengda Lu",
            "Chenggang Zhao",
            "Chengqi Deng",
            "Chenhao Xu",
            "Chong Ruan",
            "Damai Dai",
            "Daya Guo",
            "Dejian Yang",
            "Deli Chen",
            "Erhang Li",
            "Fangqi Zhou",
            "Fangyun Lin",
            "Fucong Dai",
            "Guangbo Hao",
            "Guanting Chen",
            "Guowei Li",
            "H. Zhang",
            "Hanwei Xu",
            "Hao Li",
            "Haofen Liang",
            "Haoran Wei",
            "Haowei Zhang",
            "Haowen Luo",
            "Haozhe Ji",
            "Honghui Ding",
            "Hongxuan Tang",
            "Huanqi Cao",
            "Huazuo Gao",
            "Hui Qu",
            "Hui Zeng",
            "Jialiang Huang",
            "Jiashi Li",
            "Jiaxin Xu",
            "Jiewen Hu",
            "Jingchang Chen",
            "Jingting Xiang",
            "Jingyang Yuan",
            "Jingyuan Cheng",
            "Jinhua Zhu",
            "Jun Ran",
            "Junguang Jiang",
            "Junjie Qiu",
            "Junlong Li",
            "Junxiao Song",
            "Kai Dong",
            "Kaige Gao",
            "Kang Guan",
            "Kexin Huang",
            "Kexing Zhou",
            "Kezhao Huang",
            "Kuai Yu",
            "Lean Wang",
            "Lecong Zhang",
            "Lei Wang",
            "Liang Zhao",
            "Liangsheng Yin",
            "Lihua Guo",
            "Lingxiao Luo",
            "Linwang Ma",
            "Litong Wang",
            "Liyue Zhang",
            "M.S. Di",
            "M.Y Xu",
            "Mingchuan Zhang",
            "Minghua Zhang",
            "Minghui Tang",
            "Mingxu Zhou",
            "Panpan Huang",
            "Peixin Cong",
            "Peiyi Wang",
            "Qiancheng Wang",
            "Qihao Zhu",
            "Qingyang Li",
            "Qinyu Chen",
            "Qiushi Du",
            "Ruiling Xu",
            "Ruiqi Ge",
            "Ruisong Zhang",
            "Ruizhe Pan",
            "Runji Wang",
            "Runqiu Yin",
            "Runxin Xu",
            "Ruomeng Shen",
            "Ruoyu Zhang",
            "S.H. Liu",
            "Shanghao Lu",
            "Shangyan Zhou",
            "Shanhuang Chen",
            "Shaofei Cai"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02558",
          "title": "Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance",
          "abstract": "Prevalent empathy prediction techniques primarily concentrate on a singular modality, typically textual, thus neglecting multi-modal processing capabilities. They also overlook the utilization of certain privileged information, which may encompass additional empathetic content. In response, we introduce an advanced multi-modal empathy prediction method integrating video, audio, and text information. The method comprises the Multi-Modal Empathy Prediction and Supervisory Documentation Assisted Training. We use pre-trained networks in the empathy prediction network to extract features from various modalities, followed by a cross-modal fusion. This process yields a multi-modal feature representation, which is employed to predict empathy labels. To enhance the extraction of text features, we incorporate supervisory documents as privileged information during the assisted training phase. Specifically, we apply the Latent Dirichlet Allocation model to identify potential topic distributions to constrain text features. These supervisory documents, created by supervisors, focus on the counseling topics and the counselor's display of empathy. Notably, this privileged information is only available during training and is not accessible during the prediction phase. Experimental results on the multi-modal and dialogue empathy datasets demonstrate that our approach is superior to the existing methods.",
          "authors": [
            "Yufei Xiao",
            "Shangfei Wang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02561",
          "title": "EZYer: A simulacrum of high school with generative agent",
          "abstract": "With the rapid development of the online education and large language model, the existing educational tools still suffer from incomplete service, insufficient performance and weak interactivity in terms of courseware generation, interactive notes and quality assurance of content. In particular, the proposed generative agent EZYer : 1) Teacher Module: Integrating the Text Corpus retrieval and in-depth generation technologies, it automatically generates structured teaching materials and LaTeX Beamer courseware in line with the high school mathematics syllabus and supports user-defined image insertion. 2) Student Module: Throughout the collaborative interaction of the four roles of Teacher, Assistant, Top Student and Struggling Student, Note Taker summarizes and generates academic notes to enhance the depth and interest of learning. 3) Controller: set up keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system. This ensure academic strictness and pedagogical propriety of EZYer inputs and outputs. In order to evaluate EZYer, this paper designs five-dimensional evaluation indexes of content accuracy, knowledge coverage, usability, formatting correctness and visual design and appeal, and scores 100 Beamer and Notes generated by EZYer by five large language models, separately, and the results show that the quality of EZYer-generated content is excellent and has a good application prospect.",
          "authors": [
            "Jinming Yang",
            "Zimu Ji",
            "Weiqi Luo",
            "Gaoxi Wang",
            "Bin Ma",
            "Yueling Deng"
          ],
          "primary_category": "cs.MA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02564",
          "title": "Retail Price Ripples",
          "abstract": "Much like small ripples in a stream, which get lost in the larger waves, small changes in retail prices often fly under the radar of public perceptions, while large price changes appear as marketing moves associated with demand and competition. Unnoticed, these could increase consumers out of pocket expenses. Indeed, retailers could boost their profits by making numerous small price increases or by obfuscating large price increases with numerous small price decreases, thereby bypassing the consumers full attention and consideration, and triggering consumer fairness concerns. Yet only a handful of papers study small price changes. Extant results are often based on a single retailer, limited products, short time span, and legacy datasets dating back to the 1980s and 1990s, leaving their current practical relevance questionable. Researchers have also questioned whether the reported observations of small price changes are artifacts of measurement errors driven by data aggregation. In a series of analyses of a large dataset containing almost 79 billion weekly price observations from 2006 to 2015, covering 527 products, and about 35,000 stores across 161 retailers, we find robust evidence of asymmetric pricing in the small, where small price increases outnumber small price decreases, but no such asymmetry is present in the large. We also document the reverse phenomenon, where small price decreases outnumber small price increases. Our results are robust to several possible measurement issues. Importantly, our findings indicate a greater current relevance and generalizability of such asymmetric pricing practices than the existing literature recognizes.",
          "authors": [
            "Xiao Ling",
            "Sourav Ray",
            "Daniel Levy"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02564",
          "title": "Retail Price Ripples",
          "abstract": "Much like small ripples in a stream, which get lost in the larger waves, small changes in retail prices often fly under the radar of public perceptions, while large price changes appear as marketing moves associated with demand and competition. Unnoticed, these could increase consumers out of pocket expenses. Indeed, retailers could boost their profits by making numerous small price increases or by obfuscating large price increases with numerous small price decreases, thereby bypassing the consumers full attention and consideration, and triggering consumer fairness concerns. Yet only a handful of papers study small price changes. Extant results are often based on a single retailer, limited products, short time span, and legacy datasets dating back to the 1980s and 1990s, leaving their current practical relevance questionable. Researchers have also questioned whether the reported observations of small price changes are artifacts of measurement errors driven by data aggregation. In a series of analyses of a large dataset containing almost 79 billion weekly price observations from 2006 to 2015, covering 527 products, and about 35,000 stores across 161 retailers, we find robust evidence of asymmetric pricing in the small, where small price increases outnumber small price decreases, but no such asymmetry is present in the large. We also document the reverse phenomenon, where small price decreases outnumber small price increases. Our results are robust to several possible measurement issues. Importantly, our findings indicate a greater current relevance and generalizability of such asymmetric pricing practices than the existing literature recognizes.",
          "authors": [
            "Xiao Ling",
            "Sourav Ray",
            "Daniel Levy"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02566",
          "title": "From Panel to Pixel: Zoom-In Vision-Language Pretraining from Biomedical Scientific Literature",
          "abstract": "There is a growing interest in developing strong biomedical vision-language models. A popular approach to achieve robust representations is to use web-scale scientific data. However, current biomedical vision-language pretraining typically compresses rich scientific figures and text into coarse figure-level pairs, discarding the fine-grained correspondences that clinicians actually rely on when zooming into local structures. To tackle this issue, we introduce Panel2Patch, a novel data pipeline that mines hierarchical structure from existing biomedical scientific literature, i.e., multi-panel, marker-heavy figures and their surrounding text, and converts them into multi-granular supervision. Given scientific figures and captions, Panel2Patch parses layouts, panels, and visual markers, then constructs hierarchical aligned vision-language pairs at the figure, panel, and patch levels, preserving local semantics instead of treating each figure as a single data sample. Built on this hierarchical corpus, we develop a granularity-aware pretraining strategy that unifies heterogeneous objectives from coarse didactic descriptions to fine region-focused phrases. By applying Panel2Patch to only a small set of the literature figures, we extract far more effective supervision than prior pipelines, enabling substantially better performance with less pretraining data.",
          "authors": [
            "Kun Yuan",
            "Min Woo Sun",
            "Zhen Chen",
            "Alejandro Lozano",
            "Xiangteng He",
            "Shi Li",
            "Nassir Navab",
            "Xiaoxiao Sun",
            "Nicolas Padoy",
            "Serena Yeung-Levy"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02567",
          "title": "Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System",
          "abstract": "The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes. We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables. Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.",
          "authors": [
            "Martin Weiss",
            "Jesko Hecking-Harbusch",
            "Jochen Quante",
            "Matthias Woehrle"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02569",
          "title": "Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models",
          "abstract": "This perspective reframes human-robot interaction (HRI) through extended reality (XR), arguing that virtual robots powered by large foundation models (FMs) can serve as cognitively grounded, empathic agents. Unlike physical robots, XR-native agents are unbound by hardware constraints and can be instantiated, adapted, and scaled on demand, while still affording embodiment and co-presence. We synthesize work across XR, HRI, and cognitive AI to show how such agents can support safety-critical scenarios, socially and cognitively empathic interaction across domains, and outreaching physical capabilities with XR and AI integration. We then discuss how multimodal large FMs (e.g., large language model, large vision model, and vision-language model) enable context-aware reasoning, affect-sensitive situations, and long-term adaptation, positioning virtual robots as cognitive and empathic mediators rather than mere simulation assets. At the same time, we highlight challenges and potential risks, including overtrust, cultural and representational bias, privacy concerns around biometric sensing, and data governance and transparency. The paper concludes by outlining a research agenda for human-centered, ethically grounded XR agents - emphasizing multi-layered evaluation frameworks, multi-user ecosystems, mixed virtual-physical embodiment, and societal and ethical design practices to envision XR-based virtual agents powered by FMs as reshaping future HRI into a more efficient and adaptive paradigm.",
          "authors": [
            "Yuchong Zhang",
            "Yong Ma",
            "Danica Kragic"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02576",
          "title": "Co-speech Gesture Video Generation via Motion-Based Graph Retrieval",
          "abstract": "Synthesizing synchronized and natural co-speech gesture videos remains a formidable challenge. Recent approaches have leveraged motion graphs to harness the potential of existing video data. To retrieve an appropriate trajectory from the graph, previous methods either utilize the distance between features extracted from the input audio and those associated with the motions in the graph or embed both the input audio and motion into a shared feature space. However, these techniques may not be optimal due to the many-to-many mapping nature between audio and gestures, which cannot be adequately addressed by one-to-one mapping. To alleviate this limitation, we propose a novel framework that initially employs a diffusion model to generate gesture motions. The diffusion model implicitly learns the joint distribution of audio and motion, enabling the generation of contextually appropriate gestures from input audio sequences. Furthermore, our method extracts both low-level and high-level features from the input audio to enrich the training process of the diffusion model. Subsequently, a meticulously designed motion-based retrieval algorithm is applied to identify the most suitable path within the graph by assessing both global and local similarities in motion. Given that not all nodes in the retrieved path are sequentially continuous, the final step involves seamlessly stitching together these segments to produce a coherent video output. Experimental results substantiate the efficacy of our proposed method, demonstrating a significant improvement over prior approaches in terms of synchronization accuracy and naturalness of generated gestures.",
          "authors": [
            "Yafei Song",
            "Peng Zhang",
            "Bang Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02580",
          "title": "From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks",
          "abstract": "Reinforcement learning has emerged as a paradigm for post-training large language models, boosting their reasoning capabilities. Such approaches compute an advantage value for each sample, reflecting better or worse performance than expected, thereby yielding both positive and negative signals for training. However, the indiscriminate mixing of the two signals in existing methods, especially from the early stages, may lead to ambiguous guidance and limited gains. To address this issue, we propose **CAPO** (**C**urriculum **A**dvantage **P**olicy **O**ptimization), an adaptive curriculum mechanism based on advantage signals. The proposed mechanism bootstraps imitation learning with positive-only advantage samples to establish robust foundations, and subsequently introduces negative signals to cultivate discriminative capabilities, thereby improving generalization across complex scenarios. Compatible with diverse optimization methods including GRPO, PPO, RLOO, and Reinforce++, our method consistently achieves stable and significant improvements in mathematical reasoning tasks, and further generalizes effectively to multimodal Graphical User Interface (GUI) reasoning scenarios, establishing itself as a versatile and robust optimization framework.",
          "authors": [
            "Changpeng Yang",
            "Jinyang Wu",
            "Yuchen Liu",
            "Shuai Zhang",
            "Yang Li",
            "Qiliang Liang",
            "Hongzhen Wang",
            "Shuai Nie",
            "Jiaming Xu",
            "Runyu Shi",
            "Ying Huang",
            "Guoquan Zhang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02581",
          "title": "GoRL: An Algorithm-Agnostic Framework for Online Reinforcement Learning with Generative Policies",
          "abstract": "Reinforcement learning (RL) faces a persistent tension: policies that are stable to optimize are often too simple to represent the multimodal action distributions needed for complex control. Gaussian policies provide tractable likelihoods and smooth gradients, but their unimodal form limits expressiveness. Conversely, generative policies based on diffusion or flow matching can model rich multimodal behaviors; however, in online RL, they are frequently unstable due to intractable likelihoods and noisy gradients propagating through deep sampling chains. We address this tension with a key structural principle: decoupling optimization from generation. Building on this insight, we introduce GoRL (Generative Online Reinforcement Learning), a framework that optimizes a tractable latent policy while utilizing a conditional generative decoder to synthesize actions. A two-timescale update schedule enables the latent policy to learn stably while the decoder steadily increases expressiveness, without requiring tractable action likelihoods. Across a range of continuous-control tasks, GoRL consistently outperforms both Gaussian policies and recent generative-policy baselines. Notably, on the HopperStand task, it reaches a normalized return above 870, more than 3 times that of the strongest baseline. These results demonstrate that separating optimization from generation provides a practical path to policies that are both stable and highly expressive.",
          "authors": [
            "Chubin Zhang",
            "Zhenglin Wan",
            "Feng Chen",
            "Xingrui Yu",
            "Ivor Tsang",
            "Bo An"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02584",
          "title": "Stepwise Schema-Guided Prompting Framework with Parameter Efficient Instruction Tuning for Multimedia Event Extraction",
          "abstract": "Multimedia Event Extraction (MEE) has become an important task in information extraction research as news today increasingly prefers to contain multimedia content. Current MEE works mainly face two challenges: (1) Inadequate extraction framework modeling for handling complex and flexible multimedia event structure; (2) The absence of multimodal-aligned training data for effective knowledge transfer to MEE task. In this work, we propose a Stepwise Schema-Guided Prompting Framework (SSGPF) using Multimodal Large Language Model (MLLM) as backbone for adaptive structure capturing to solve MEE task. At the initial step of SSGPF, we design Event Type Schema Guided Prompting (ETSGP) for event detection, then we devise Argument Role Schema Guided Prompting (ARSGP) that contains multi-step prompts with text-bridged grounding technique for argument extraction. We construct a weakly-aligned multimodal event labeled dataset based on existing unimodal event annotations, then conduct parameter efficient instruction tuning with LoRA on LLaVA-v1.5-7B under SSGPF. Experiments on the M2E2 benchmark demonstrate that SSGPF significantly outperforms current SOTA baselines by 5.8 percent F1 on event detection and 8.4 percent F1 on argument extraction.",
          "authors": [
            "Xiang Yuan",
            "Xinrong Chen",
            "Haochen Li",
            "Hang Yang",
            "Guanyu Wang",
            "Weiping Li",
            "Tong Mo"
          ],
          "primary_category": "cs.MM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02585",
          "title": "Framework for Electrochemical & Electrical Energy Storage Materials Database",
          "abstract": "Several electrochemical and electrical energy storage devices are reported every day, with the claim of outperforming the established ones. The use of newer materials and recent advanced techniques to synthesize and/or assemble them into a device leads to improved performance. Cyclic stability of a device is the most effective way of assessing the performance of the device. A wide variety of parameters can influence the cyclic stability of a cell, and there is no single fundamental parameter that reliably captures or assesses its overall performance. Therefore, we developed a multi-dimensional assessment framework that could account for various parameters like various types of materials used, selected fabrication techniques, current density, operating voltage window, temperature, environment, and other conditions, and can effectively rank cell performance based on essential assessment metrics like specific capacity and energy density that are substantial for a well-founded comparison. The framework is designed with 45+ fields that capture various details related to i) materials used to fabricate cells, ii) processing techniques associated with electrode preparation and cell assembly, iii) cell information like weights and volumes, iv) electrochemical testing parameters, and v) cyclic charge-discharge performance details of a cell. The framework also accommodates charge-discharge gravimetric specific capacity, which is believed to be a key asset in accurately extracting lots of useful information, such as specific capacity, energy density, quantum efficiency, and other efficiencies. A distinctive feature of the framework is its ability to store data from both experimental and theoretical/computational sources (such as DFT and ML predictions) and facilitate effective comparison between them.",
          "authors": [
            "Vinod Sarky",
            "P. Laxman Mani Kanta",
            "Shivangi Keshri",
            "Mannanvali Shaik",
            "B. R. K. Nanda",
            "Satyesh K. Yadav"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02586",
          "title": "Numerical analysis of the impact of water temperature setpoint and energy strategies on indoor pool performance",
          "abstract": "Indoor swimming pools (ISPs) consume significant amounts of electrical and thermal energy to ensure the heating of water and air, ventilation, and maintaining adequate humidity levels. This is measured in GWh per year for large installations, such as Olympic swimming pools (SPs). In this paper, the problem is initially addressed using a phenomenological approach at steady state of the air-water coupling, based on a real case study. The aim is to identify the key phenomena and the constraints that are the most sensitive, including those related to water and air quality management. A key action lever is found in evaporation, and more specifically, water temperature and the indoor dewpoint temperature, which act as its precursors. In a second step, two different strategies were tested to reduce energy consumption for water heating. It was determined that a strategy which incorporates night setback in conjunction with a precise restart time yields a maximum gain of 4%. The second strategy aims to enhance the energy recovery of thermal solar panels by enabling slight overheating of the pool. Its large volume provides effective energy storage, with estimated energy savings of up to 17% for a 1___ C overheating. This strategy appears to be a viable option, as it is straightforward to implement. However, the impact of water overheating on the energy consumption of AHU still needs to be analyzed and managed.",
          "authors": [
            "Younes Benakcha",
            "Matthieu Labat",
            "Ion Hazyuk",
            "Stéphane Ginestet"
          ],
          "primary_category": "physics.class-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02589",
          "title": "PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing",
          "abstract": "Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at this https URL .",
          "authors": [
            "Junyi Hou",
            "Andre Lin Huikai",
            "Nuo Chen",
            "Yiwei Gong",
            "Bingsheng He"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02593",
          "title": "Spoken Conversational Agents with Large Language Models",
          "abstract": "Spoken conversational agents are converging toward voice-native LLMs. This tutorial distills the path from cascaded ASR/NLU to end-to-end, retrieval-and vision-grounded systems. We frame adaptation of text LLMs to audio, cross-modal alignment, and joint speech-text training; review datasets, metrics, and robustness across accents and compare design choices (cascaded vs. E2E, post-ASR correction, streaming). We link industrial assistants to current open-domain and task-oriented agents, highlight reproducible baselines, and outline open problems in privacy, safety, and evaluation. Attendees leave with practical recipes and a clear systems-level roadmap.",
          "authors": [
            "Chao-Han Huck Yang",
            "Andreas Stolcke",
            "Larry Heck"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02593",
          "title": "Spoken Conversational Agents with Large Language Models",
          "abstract": "Spoken conversational agents are converging toward voice-native LLMs. This tutorial distills the path from cascaded ASR/NLU to end-to-end, retrieval-and vision-grounded systems. We frame adaptation of text LLMs to audio, cross-modal alignment, and joint speech-text training; review datasets, metrics, and robustness across accents and compare design choices (cascaded vs. E2E, post-ASR correction, streaming). We link industrial assistants to current open-domain and task-oriented agents, highlight reproducible baselines, and outline open problems in privacy, safety, and evaluation. Attendees leave with practical recipes and a clear systems-level roadmap.",
          "authors": [
            "Chao-Han Huck Yang",
            "Andreas Stolcke",
            "Larry Heck"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02600",
          "title": "S3C2 SICP Summit 2025-06: Vulnerability Response Summit",
          "abstract": "Recent years have shown increased cyber attacks targeting less secure elements in the software supply chain and causing significant damage to businesses and organizations. The US and EU governments and industry are equally interested in enhancing software security, including supply chain and vulnerability response. On June 26, 2025, researchers from the NSF-supported Secure Software Supply Chain Center (S3C2) and the Software Innovation Campus Paderborn (SICP) conducted a Vulnerability Response Summit with a diverse set of 9 practitioners from 9 companies. The goal of the Summit is to enable sharing between industry practitioners having practical experiences and challenges with software supply chain security, including vulnerability response, and helping to form new collaborations. We conducted five panel discussions based on open-ended questions regarding experiences with vulnerability reports, tools used for vulnerability discovery and management, organizational structures to report vulnerability response and management, preparedness and implementations for Cyber Resilience Act1 (CRA) and NIS22, and bug bounties. The open discussions enabled mutual sharing and shed light on common challenges that industry practitioners with practical experience face when securing their software supply chain, including vulnerability response. In this paper, we provide a summary of the Summit. Full panel questions can be found in the appendix.",
          "authors": [
            "Anna Lena Rotthaler",
            "Simon Oberthür",
            "Juraj Somorovsky",
            "Kirsten Thommes",
            "Simon Trang",
            "Yasemin Acar",
            "Michel Cukier",
            "William Enck",
            "Alexandros Kapravelos",
            "Christian Kästner",
            "Dominik Wermke",
            "Laurie Williams"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02605",
          "title": "IACT: A Self-Organizing Recursive Model for General AI Agents: A Technical White Paper on the Architecture Behind kragent.ai",
          "abstract": "This technical white paper introduces the Interactive Agents Call Tree (IACT), a computational model designed to address the limitations of static, hard-coded agent workflows. Unlike traditional systems that require pre-defined graphs or specialized programming, IACT operates as a general-purpose autonomous system driven purely by user dialogue. Given a high-level objective, the system autonomously grows a dynamic, recursive agent topology incrementally tailored to the problem's structure. This allows it to scale its organizational complexity to match open-ended tasks. To mitigate the error propagation inherent in unidirectional function calls, IACT introduces interactional redundancy by replacing rigid invocations with bidirectional, stateful dialogues. This mechanism enables runtime error correction and ambiguity resolution. We describe the architecture, design principles, and practical lessons behind the production deployment of this model in the this http URL system, presenting qualitative evidence from real-world workflows rather than exhaustive benchmark results.",
          "authors": [
            "Pengju Lu"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02606",
          "title": "Parameter identification of lithium-ion batteries: a comparative study of various models and optimization techniques for battery modeling",
          "abstract": "This work presents a comparative study of optimization techniques for parameter identification in equivalent electrical models of lithium-ion batteries. The 2RC model is applied to a set of twelve batteries using four publicly available datasets obtained from well-established research institutions. The methodology is structured in four stages: first, the 2RC model is selected due to its balance between physical interpretability and computational simplicity; second, experimental charge-discharge cycle data are collected; third, various optimization techniques are applied with the aim of minimizing the error between the experimental data and the response estimated by the model; and finally, accuracy is evaluated using the mean squared error, while computational efficiency is assessed through execution time. Traditional, metaheuristic, and bio-inspired optimization methods are considered, including least squares optimization, particle swarm optimization, simulated annealing, and several nature-inspired variants. It is demonstrated that bio-inspired techniques achieve greater accuracy than traditional methods, without a significant increase in computational cost. In particular, particle swarm optimization shows superior performance in terms of precision and robustness against local minima. It is concluded that the integration of advanced optimization strategies significantly enhances the fidelity of equivalent electrical models, which is essential for accurate estimation of internal states such as state of charge, aging, and service life in lithium-ion batteries used in electric vehicles and aerospace systems.",
          "authors": [
            "Johan Sebastian Suarez Sepúlveda",
            "Edgar Hernando Sepúlveda-Oviedo",
            "Bruno Jammes",
            "Corinne Alonso"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02608",
          "title": "Investigating the Integrated Digital Interventions Delivered by a Therapeutic Companion Agent for Young Adults with Symptoms of Depression: A Proof-of-Concept Study",
          "abstract": "Background: Despite the clinical effectiveness of digital interventions for young adults with depression, low engagement and adherence remain persistent challenges. Building a strong digital therapeutic alliance has been proposed to address these barriers. This study highlights the need for a conversational therapeutic companion agent (TCA)-based intervention design. Objective: This study aimed to develop a Wizard-of-Oz TCA-centered prototype integrating social-support-based ecological momentary assessment (EMA), ecological momentary intervention (EMI), behavioral activation, and gamification. We evaluated the six-week proof-of-concept efficacy of this intervention among young adults with depressive symptoms. Methods: Korean young adults aged 20--39 years with mild-to-moderate depressive symptoms (PHQ-9) were recruited online. The intervention group ($n = 29$) received a six-week TCA-based digital intervention, while the control group ($n = 29$), recruited four weeks later, continued their usual routines. The TCA guided four daily behavioral-activation tasks, three mood assessments, meditation, daily summaries, and weekly mission feedback. Both groups were assessed at baseline and at weeks 2, 4, and 6 using the BDI-II, GAD-7, and Q-LES-Q-SF. Results: Of 58 participants, 57 completed the study (one dropout in the intervention group). At week 6, the intervention group showed significantly greater reductions in depressive symptoms and improvements in quality of life than controls. Adherence was 78\\% for EMA, 51\\% for EMI, and 65\\% for daily routines. Conclusions: The TCA-based digital intervention improved depressive symptoms and quality of life with adherence levels comparable to previous digital health interventions. Future studies should refine the TCA design and conduct larger-scale evaluations.",
          "authors": [
            "Youngjae Yoo",
            "Minuk Kim",
            "Soyoung Kim",
            "Gayeon Lee",
            "Jinwoo Kim"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02609",
          "title": "SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction",
          "abstract": "Imitation learning for robotic grasping is often plagued by the multimodal problem: when a scene contains multiple valid targets, demonstrations of grasping different objects create conflicting training signals. Standard imitation learning policies fail by averaging these distinct actions into a single, invalid action. In this paper, we introduce SAM2Grasp, a novel framework that resolves this issue by reformulating the task as a uni-modal, prompt-conditioned prediction problem. Our method leverages the frozen SAM2 model to use its powerful visual temporal tracking capability and introduces a lightweight, trainable action head that operates in parallel with its native segmentation head. This design allows for training only the small action head on pre-computed temporal-visual features from SAM2. During inference, an initial prompt, such as a bounding box provided by an upstream object detection model, designates the specific object to be grasped. This prompt conditions the action head to predict a unique, unambiguous grasp trajectory for that object alone. In all subsequent video frames, SAM2's built-in temporal tracking capability automatically maintains stable tracking of the selected object, enabling our model to continuously predict the grasp trajectory from the video stream without further external guidance. This temporal-prompted approach effectively eliminates ambiguity from the visuomotor policy. We demonstrate through extensive experiments that SAM2Grasp achieves state-of-the-art performance in cluttered, multi-object grasping tasks.",
          "authors": [
            "Shengkai Wu",
            "Jinrong Yang",
            "Wenqiu Luo",
            "Linfeng Gao",
            "Chaohui Shang",
            "Meiyu Zhi",
            "Mingshan Sun",
            "Fangping Yang",
            "Liangliang Ren",
            "Yong Zhao"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02610",
          "title": "Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction",
          "abstract": "Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at this https URL .",
          "authors": [
            "Yubo Hou",
            "Mohamed Ragab",
            "Min Wu",
            "Chee-Keong Kwoh",
            "Xiaoli Li",
            "Zhenghua Chen"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02618",
          "title": "Modeling and Inverse Identification of Interfacial Heat Conduction in Finite Layer and Semi-Infinite Substrate Systems via a Physics-Guided Neural Framework",
          "abstract": "Heat transfer in semiconductor devices is dominated by chip and substrate assemblies, where heat generated within a finite chip layer dissipates into a semi-infinite substrate with much higher thermophysical properties. This mismatch produces steep interfacial temperature gradients, making the transient thermal response highly sensitive to the interface. Conventional numerical solvers require excessive discretization to resolve these dynamics, while physics-informed neural networks (PINNs) often exhibit unstable convergence and loss of physical consistency near the material interface. To address these challenges, we introduce HeatTransFormer, a physics-guided Transformer architecture for interface-dominated diffusion problems. The framework integrates physically informed spatiotemporal sampling, a Laplace-based activation emulating analytical diffusion solutions, and a mask-free attention mechanism supporting bidirectional spatiotemporal coupling. These components enable the model to resolve steep gradients, maintain physical consistency, and remain stable where PINNs typically fail. HeatTransFormer produces coherent temperature fields across the interface when applied to a finite layer and semi-infinite substrate configuration. Coupled with a physics-constrained inverse strategy, it further enables reliable identification of three unknown thermal properties simultaneously using only external measurements. Overall, this work demonstrates that physics-guided Transformer architectures provide a unified framework for forward and inverse modeling in interface-dominated thermal systems.",
          "authors": [
            "Wenhao Sha",
            "Tienchong Chang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02618",
          "title": "Modeling and Inverse Identification of Interfacial Heat Conduction in Finite Layer and Semi-Infinite Substrate Systems via a Physics-Guided Neural Framework",
          "abstract": "Heat transfer in semiconductor devices is dominated by chip and substrate assemblies, where heat generated within a finite chip layer dissipates into a semi-infinite substrate with much higher thermophysical properties. This mismatch produces steep interfacial temperature gradients, making the transient thermal response highly sensitive to the interface. Conventional numerical solvers require excessive discretization to resolve these dynamics, while physics-informed neural networks (PINNs) often exhibit unstable convergence and loss of physical consistency near the material interface. To address these challenges, we introduce HeatTransFormer, a physics-guided Transformer architecture for interface-dominated diffusion problems. The framework integrates physically informed spatiotemporal sampling, a Laplace-based activation emulating analytical diffusion solutions, and a mask-free attention mechanism supporting bidirectional spatiotemporal coupling. These components enable the model to resolve steep gradients, maintain physical consistency, and remain stable where PINNs typically fail. HeatTransFormer produces coherent temperature fields across the interface when applied to a finite layer and semi-infinite substrate configuration. Coupled with a physics-constrained inverse strategy, it further enables reliable identification of three unknown thermal properties simultaneously using only external measurements. Overall, this work demonstrates that physics-guided Transformer architectures provide a unified framework for forward and inverse modeling in interface-dominated thermal systems.",
          "authors": [
            "Wenhao Sha",
            "Tienchong Chang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02619",
          "title": "Quantum LLMs Using Quantum Computing to Analyze and Process Semantic Information",
          "abstract": "We present a quantum computing approach to analyzing Large Language Model (LLM) embeddings, leveraging complex-valued representations and modeling semantic relationships using quantum mechanical principles. By establishing a direct mapping between LLM semantic spaces and quantum circuits, we demonstrate the feasibility of estimating semantic similarity using quantum hardware. One of the key results is the experimental calculation of cosine similarity between Google Sentence Transformer embeddings using a real quantum computer, providing a tangible demonstration of a quantum approach to semantic analysis. This work reveals a connection between LLMs and quantum mechanics, suggesting that these principles can offer new perspectives on semantic representation and processing, and paving the way for future development of quantum algorithms for natural language processing.",
          "authors": [
            "Timo Aukusti Laine"
          ],
          "primary_category": "quant-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02621",
          "title": "Content-Aware Texturing for Gaussian Splatting",
          "abstract": "Gaussian Splatting has become the method of choice for 3D reconstruction and real-time rendering of captured real scenes. However, fine appearance details need to be represented as a large number of small Gaussian primitives, which can be wasteful when geometry and appearance exhibit different frequency characteristics. Inspired by the long tradition of texture mapping, we propose to use texture to represent detailed appearance where possible. Our main focus is to incorporate per-primitive texture maps that adapt to the scene in a principled manner during Gaussian Splatting optimization. We do this by proposing a new appearance representation for 2D Gaussian primitives with textures where the size of a texel is bounded by the image sampling frequency and adapted to the content of the input images. We achieve this by adaptively upscaling or downscaling the texture resolution during optimization. In addition, our approach enables control of the number of primitives during optimization based on texture resolution. We show that our approach performs favorably in image quality and total number of parameters used compared to alternative solutions for textured Gaussian primitives. Project page: this https URL",
          "authors": [
            "Panagiotis Papantonakis",
            "Georgios Kopanas",
            "Fredo Durand",
            "George Drettakis"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02622",
          "title": "RULER-Bench: Probing Rule-based Reasoning Abilities of Next-level Video Generation Models for Vision Foundation Intelligence",
          "abstract": "Recent advances in video generation have enabled the synthesis of videos with strong temporal consistency and impressive visual quality, marking a crucial step toward vision foundation models. To evaluate these video generation models, existing benchmarks primarily focus on factors related to visual perception and understanding, like visual aesthetics, instruction adherence, and temporal coherence. However, the rule-based reasoning capabilities of video generation models remain largely unexplored. Although recent studies have carried out preliminary explorations into whether video models can serve as zero-shot learners, they still lack a fine-grained decomposition of reasoning capabilities and a comprehensive evaluation protocol. To address this gap, we introduce RULER-Bench, a benchmark designed to evaluate the reasoning ability of video generation models from the perspective of cognitive rules. Built upon two fundamental paradigms: text-to-video and image-to-video, RULER-Bench covers 40 representative tasks spanning six rule categories with 622 high-quality annotated instances. For the evaluation of each generated video, we construct a checklist covering four metrics and leverage GPT-o3 to assign scores to each question, achieving 85% alignment with human judgements. Extensive experiments show that the state-of-the-art model achieves only 48.87% on the rule coherence metric, highlighting significant room for improvement in the reasoning capability of next-level video models. We expect that the insight obtained from RULER-Bench will facilitate further development of reasoning-aware video generation, advancing video generation models toward vision foundation intelligence.",
          "authors": [
            "Xuming He",
            "Zehao Fan",
            "Hengjia Li",
            "Fan Zhuo",
            "Hankun Xu",
            "Senlin Cheng",
            "Di Weng",
            "Haifeng Liu",
            "Can Ye",
            "Boxi Wu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02624",
          "title": "PPTBench: Towards Holistic Evaluation of Large Language Models for PowerPoint Layout and Design Understanding",
          "abstract": "PowerPoint presentations combine rich textual content with structured visual layouts, making them a natural testbed for evaluating the multimodal reasoning and layout understanding abilities of modern MLLMs. However, existing benchmarks focus solely on narrow subtasks while overlooking layout-centric challenges, which are central to real-world slide creation and editing. To bridge this gap, we introduce PPTBench, a comprehensive multimodal benchmark for evaluating LLMs on PowerPoint-related tasks. Leveraging a diverse source of 958 PPTX files, PPTBench evaluates models across four categories with 4,439 samples, including Detection, Understanding, Modification, and Generation. Our experiments reveal a substantial gap between semantic understanding and visual-layout reasoning in current MLLMs: models can interpret slide content but fail to produce coherent spatial arrangements. Ablation and further analysis show that current MLLMs struggle to combine visual cues with JSON-based layout structures and fail to integrate visual information into their API planning ability. And case studies visually expose systematic layout errors such as misalignment and element overlap. These findings provides a new perspective on evaluating VLLMs in PPT scenarios, highlighting challenges and directions for future research on visual-structural reasoning and coherent slide generation. All datasets and code are fully released to support reproducibility and future research.",
          "authors": [
            "Zheng Huang",
            "Xukai Liu",
            "Tianyu Hu",
            "Kai Zhang",
            "Ye Liu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02625",
          "title": "CryptoQA: A Large-scale Question-answering Dataset for AI-assisted Cryptography",
          "abstract": "Large language models (LLMs) excel at many general-purpose natural language processing tasks. However, their ability to perform deep reasoning and mathematical analysis, particularly for complex tasks as required in cryptography, remains poorly understood, largely due to the lack of suitable data for evaluation and training. To address this gap, we present CryptoQA, the first large-scale question-answering (QA) dataset specifically designed for cryptography. CryptoQA contains over two million QA pairs drawn from curated academic sources, along with contextual metadata that can be used to test the cryptographic capabilities of LLMs and to train new LLMs on cryptographic tasks. We benchmark 15 state-of-the-art LLMs on CryptoQA, evaluating their factual accuracy, mathematical reasoning, consistency, referencing, backward reasoning, and robustness to adversarial samples. In addition to quantitative metrics, we provide expert reviews that qualitatively assess model outputs and establish a gold-standard baseline. Our results reveal significant performance deficits of LLMs, particularly on tasks that require formal reasoning and precise mathematical knowledge. This shows the urgent need for LLM assistants tailored to cryptography research and development. We demonstrate that, by using CryptoQA, LLMs can be fine-tuned to exhibit better performance on cryptographic tasks.",
          "authors": [
            "Mayar Elfares",
            "Pascal Reisert",
            "Tilman Dietz",
            "Manpa Barman",
            "Ahmed Zaki",
            "Ralf Küsters",
            "Andreas Bulling"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02626",
          "title": "Adapting Tensor Kernel Machines to Enable Efficient Transfer Learning for Seizure Detection",
          "abstract": "Transfer learning aims to optimize performance in a target task by learning from a related source problem. In this work, we propose an efficient transfer learning method using a tensor kernel machine. Our method takes inspiration from the adaptive SVM and hence transfers 'knowledge' from the source to the 'adapted' model via regularization. The main advantage of using tensor kernel machines is that they leverage low-rank tensor networks to learn a compact non-linear model in the primal domain. This allows for a more efficient adaptation without adding more parameters to the model. To demonstrate the effectiveness of our approach, we apply the adaptive tensor kernel machine (Adapt-TKM) to seizure detection on behind-the-ear EEG. By personalizing patient-independent models with a small amount of patient-specific data, the patient-adapted model (which utilizes the Adapt-TKM), achieves better performance compared to the patient-independent and fully patient-specific models. Notably, it is able to do so while requiring around 100 times fewer parameters than the adaptive SVM model, leading to a correspondingly faster inference speed. This makes the Adapt-TKM especially useful for resource-constrained wearable devices.",
          "authors": [
            "Seline J.S. de Rooij",
            "Borbála Hunyadi"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02626",
          "title": "Adapting Tensor Kernel Machines to Enable Efficient Transfer Learning for Seizure Detection",
          "abstract": "Transfer learning aims to optimize performance in a target task by learning from a related source problem. In this work, we propose an efficient transfer learning method using a tensor kernel machine. Our method takes inspiration from the adaptive SVM and hence transfers 'knowledge' from the source to the 'adapted' model via regularization. The main advantage of using tensor kernel machines is that they leverage low-rank tensor networks to learn a compact non-linear model in the primal domain. This allows for a more efficient adaptation without adding more parameters to the model. To demonstrate the effectiveness of our approach, we apply the adaptive tensor kernel machine (Adapt-TKM) to seizure detection on behind-the-ear EEG. By personalizing patient-independent models with a small amount of patient-specific data, the patient-adapted model (which utilizes the Adapt-TKM), achieves better performance compared to the patient-independent and fully patient-specific models. Notably, it is able to do so while requiring around 100 times fewer parameters than the adaptive SVM model, leading to a correspondingly faster inference speed. This makes the Adapt-TKM especially useful for resource-constrained wearable devices.",
          "authors": [
            "Seline J.S. de Rooij",
            "Borbála Hunyadi"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02630",
          "title": "A new family of models with generalized orientation in data envelopment analysis",
          "abstract": "In the framework of data envelopment analysis, we review directional models \\citep{Chambers1996, Chambers1998, Briec1997} and show that they are inadequate when inputs and outputs are improved simultaneously under constant returns to scale. Conversely, we introduce a new family of quadratically constrained models with generalized orientation and demonstrate that these models overcome this limitation. Furthermore, we extend the Farrell measure of technical efficiency using these new models. Additionally, we prove that the family of generalized oriented models satisfies some desired monotonicity properties. Finally, we show that the new models, although being quadratically constrained, can be solved through linear programs in a fundamental particular case.",
          "authors": [
            "V. J. Bolos",
            "R Benitez",
            "V. Coll-Serrano"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02630",
          "title": "A new family of models with generalized orientation in data envelopment analysis",
          "abstract": "In the framework of data envelopment analysis, we review directional models \\citep{Chambers1996, Chambers1998, Briec1997} and show that they are inadequate when inputs and outputs are improved simultaneously under constant returns to scale. Conversely, we introduce a new family of quadratically constrained models with generalized orientation and demonstrate that these models overcome this limitation. Furthermore, we extend the Farrell measure of technical efficiency using these new models. Additionally, we prove that the family of generalized oriented models satisfies some desired monotonicity properties. Finally, we show that the new models, although being quadratically constrained, can be solved through linear programs in a fundamental particular case.",
          "authors": [
            "V. J. Bolos",
            "R Benitez",
            "V. Coll-Serrano"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02631",
          "title": "SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization",
          "abstract": "Existing Vision-Language Navigation (VLN) agents based on Large Vision-Language Models (LVLMs) often suffer from perception errors, reasoning errors, and planning errors, which significantly hinder their navigation performance. To address these limitations, a novel VLN agent framework, named SeeNav-Agent, is proposed in this work. First, to reduce perception hallucinations of the visual module of the VLN agent, a dual-view Visual Prompt (VP) technique is introduced in the input space, which can also improve the agent's understanding of current spatial states. Subsequently, a novel step-level Reinforcement Fine-Tuning (RFT) method, Step Reward Group Policy Optimization (SRGPO), is designed for the post-training of VLN agents. In SRGPO, we first define verifiable process rewards for the navigation task, and then perform efficient step-level advantage estimation by randomly grouping different navigation steps. SRGPO provides dense reward signals for the reinforcement learning process of the VLN agent and enhances its planning capability. Experimental results on the EmbodiedBench Navigation benchmark indicate that by introducing the zero-shot VP module, the GPT-4.1 achieves a navigation success rate of 86.7%, surpassing the current best LVLM by approximately 20 percentage points (pp). Through post-training based on SRGPO, the Qwen2.5-VL-3B model reaches a navigation success rate of 72.3%, outperforming the best existing LVLM model by 5.6 pp. Moreover, compared to RFT algorithms such as GRPO and GiGPO, the proposed SRGPO demonstrates significant improvements in training stability, convergence efficiency, and generalization capability.",
          "authors": [
            "Zhengcheng Wang",
            "Zichuan Lin",
            "Yijun Yang",
            "Haobo Fu",
            "Deheng Ye"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02633",
          "title": "Zero-Shot Instruction Following in RL via Structured LTL Representations",
          "abstract": "Linear temporal logic (LTL) is a compelling framework for specifying complex, structured tasks for reinforcement learning (RL) agents. Recent work has shown that interpreting LTL instructions as finite automata, which can be seen as high-level programs monitoring task progress, enables learning a single generalist policy capable of executing arbitrary instructions at test time. However, existing approaches fall short in environments where multiple high-level events (i.e., atomic propositions) can be true at the same time and potentially interact in complicated ways. In this work, we propose a novel approach to learning a multi-task policy for following arbitrary LTL instructions that addresses this shortcoming. Our method conditions the policy on sequences of simple Boolean formulae, which directly align with transitions in the automaton, and are encoded via a graph neural network (GNN) to yield structured task representations. Experiments in a complex chess-based environment demonstrate the advantages of our approach.",
          "authors": [
            "Mattia Giuri",
            "Mathias Jackermeier",
            "Alessandro Abate"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02636",
          "title": "Joint Distillation for Fast Likelihood Evaluation and Sampling in Flow-based Models",
          "abstract": "Log-likelihood evaluation enables important capabilities in generative models, including model comparison, certain fine-tuning objectives, and many downstream applications. Yet paradoxically, some of today's best generative models -- diffusion and flow-based models -- still require hundreds to thousands of neural function evaluations (NFEs) to compute a single likelihood. While recent distillation methods have successfully accelerated sampling to just a few steps, they achieve this at the cost of likelihood tractability: existing approaches either abandon likelihood computation entirely or still require expensive integration over full trajectories. We present fast flow joint distillation (F2D2), a framework that simultaneously reduces the number of NFEs required for both sampling and likelihood evaluation by two orders of magnitude. Our key insight is that in continuous normalizing flows, the coupled ODEs for sampling and likelihood are computed from a shared underlying velocity field, allowing us to jointly distill both the sampling trajectory and cumulative divergence using a single model. F2D2 is modular, compatible with existing flow-based few-step sampling models, and requires only an additional divergence prediction head. Experiments demonstrate F2D2's capability of achieving accurate log-likelihood with few-step evaluations while maintaining high sample quality, solving a long-standing computational bottleneck in flow-based generative models. As an application of our approach, we propose a lightweight self-guidance method that enables a 2-step MeanFlow model to outperform a 1024 step teacher model with only a single additional backward NFE.",
          "authors": [
            "Xinyue Ai",
            "Yutong He",
            "Albert Gu",
            "Ruslan Salakhutdinov",
            "J Zico Kolter",
            "Nicholas Matthew Boffi",
            "Max Simchowitz"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02643",
          "title": "Leveraging Large-Scale Pretrained Spatial-Spectral Priors for General Zero-Shot Pansharpening",
          "abstract": "Existing deep learning methods for remote sensing image fusion often suffer from poor generalization when applied to unseen datasets due to the limited availability of real training data and the domain gap between different satellite sensors. To address this challenge, we explore the potential of foundation models by proposing a novel pretraining strategy that leverages large-scale simulated datasets to learn robust spatial-spectral priors. Specifically, our approach first constructs diverse simulated datasets by applying various degradation operations (blur, noise, downsampling) and augmentations (bands generation, channel shuffling, high-pass filtering, color jittering, etc.) to natural images from ImageNet and remote sensing images from SkyScript. We then pretrain fusion models on these simulated data to learn generalizable spatial-spectral representations. The pretrained models are subsequently evaluated on six datasets (WorldView-2/3/4, IKONOS, QuickBird, GaoFen-2) using zero-shot and one-shot paradigms, with both full- and freeze-tuning approaches for fine-tuning. Extensive experiments on different network architectures including convolutional neural networks, Transformer, and Mamba demonstrate that our pretraining strategy significantly improves generalization performance across different satellite sensors and imaging conditions for various fusion models. The pretrained models achieve superior results in zero-shot scenarios and show remarkable adaptation capability with minimal real data in one-shot settings. Our work provides a practical solution for cross-domain pansharpening, establishes a new benchmark for generalization in remote sensing image fusion tasks, and paves the way for leveraging foundation models through advanced training strategies.",
          "authors": [
            "Yongchuan Cui",
            "Peng Liu",
            "Yi Zeng"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02646",
          "title": "Offloading Artificial Intelligence Workloads across the Computing Continuum by means of Active Storage Systems",
          "abstract": "The increasing demand for artificial intelligence (AI) workloads across diverse computing environments has driven the need for more efficient data management strategies. Traditional cloud-based architectures struggle to handle the sheer volume and velocity of AI-driven data, leading to inefficiencies in storage, computation, and data movement. This paper explores the integration of active storage systems within the computing continuum to optimize AI workload distribution. By embedding computation directly into storage architectures, active storage is able to reduce data transfer overhead, enhancing performance and improving resource utilization. Other existing frameworks and architectures offer mechanisms to distribute certain AI processes across distributed environments; however, they lack the flexibility and adaptability that the continuum requires, both regarding the heterogeneity of devices and the rapid-changing algorithms and models being used by domain experts and researchers. This article proposes a software architecture aimed at seamlessly distributing AI workloads across the computing continuum, and presents its implementation using mainstream Python libraries and dataClay, an active storage platform. The evaluation shows the benefits and trade-offs regarding memory consumption, storage requirements, training times, and execution efficiency across different devices. Experimental results demonstrate that the process of offloading workloads through active storage significantly improves memory efficiency and training speeds while maintaining accuracy. Our findings highlight the potential of active storage to revolutionize AI workload management, making distributed AI deployments more scalable and resource-efficient with a very low entry barrier for domain experts and application developers.",
          "authors": [
            "Alex Barceló",
            "Sebastián A. Cajas Ordoñez",
            "Jaydeep Samanta",
            "Andrés L. Suárez-Cetrulo",
            "Romila Ghosh",
            "Ricardo Simón Carbajo",
            "Anna Queralt"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02648",
          "title": "PoreTrack3D: A Benchmark for Dynamic 3D Gaussian Splatting in Pore-Scale Facial Trajectory Tracking",
          "abstract": "We introduce PoreTrack3D, the first benchmark for dynamic 3D Gaussian splatting in pore-scale, non-rigid 3D facial trajectory tracking. It contains over 440,000 facial trajectories in total, among which more than 52,000 are longer than 10 frames, including 68 manually reviewed trajectories that span the entire 150 frames. To the best of our knowledge, PoreTrack3D is the first benchmark dataset to capture both traditional facial landmarks and pore-scale keypoints trajectory, advancing the study of fine-grained facial expressions through the analysis of subtle skin-surface motion. We systematically evaluate state-of-the-art dynamic 3D Gaussian splatting methods on PoreTrack3D, establishing the first performance baseline in this domain. Overall, the pipeline developed for this benchmark dataset's creation establishes a new framework for high-fidelity facial motion capture and dynamic 3D reconstruction. Our dataset are publicly available at: this https URL",
          "authors": [
            "Dong Li",
            "Jiahao Xiong",
            "Yingda Huang",
            "Le Chang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02650",
          "title": "Hear What Matters! Text-conditioned Selective Video-to-Audio Generation",
          "abstract": "This work introduces a new task, text-conditioned selective video-to-audio (V2A) generation, which produces only the user-intended sound from a multi-object video. This capability is especially crucial in multimedia production, where audio tracks are handled individually for each sound source for precise editing, mixing, and creative control. However, current approaches generate single source-mixed sounds at once, largely because visual features are entangled, and region cues or prompts often fail to specify the source. We propose SelVA, a novel text-conditioned V2A model that treats the text prompt as an explicit selector of target source and modulates video encoder to distinctly extract prompt-relevant video features. The proposed supplementary tokens promote cross-attention by suppressing text-irrelevant activations with efficient parameter tuning, yielding robust semantic and temporal grounding. SelVA further employs a self-augmentation scheme to overcome the lack of mono audio track supervision. We evaluate SelVA on VGG-MONOAUDIO, a curated benchmark of clean single-source videos for such a task. Extensive experiments and ablations consistently verify its effectiveness across audio quality, semantic alignment, and temporal synchronization. Code and demo are available at this https URL .",
          "authors": [
            "Junwon Lee",
            "Juhan Nam",
            "Jiyoung Lee"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02650",
          "title": "Hear What Matters! Text-conditioned Selective Video-to-Audio Generation",
          "abstract": "This work introduces a new task, text-conditioned selective video-to-audio (V2A) generation, which produces only the user-intended sound from a multi-object video. This capability is especially crucial in multimedia production, where audio tracks are handled individually for each sound source for precise editing, mixing, and creative control. However, current approaches generate single source-mixed sounds at once, largely because visual features are entangled, and region cues or prompts often fail to specify the source. We propose SelVA, a novel text-conditioned V2A model that treats the text prompt as an explicit selector of target source and modulates video encoder to distinctly extract prompt-relevant video features. The proposed supplementary tokens promote cross-attention by suppressing text-irrelevant activations with efficient parameter tuning, yielding robust semantic and temporal grounding. SelVA further employs a self-augmentation scheme to overcome the lack of mono audio track supervision. We evaluate SelVA on VGG-MONOAUDIO, a curated benchmark of clean single-source videos for such a task. Extensive experiments and ablations consistently verify its effectiveness across audio quality, semantic alignment, and temporal synchronization. Code and demo are available at this https URL .",
          "authors": [
            "Junwon Lee",
            "Juhan Nam",
            "Jiyoung Lee"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02651",
          "title": "Real-Time Multimodal Data Collection Using Smartwatches and Its Visualization in Education",
          "abstract": "Wearable sensors, such as smartwatches, have become increasingly prevalent across domains like healthcare, sports, and education, enabling continuous monitoring of physiological and behavioral data. In the context of education, these technologies offer new opportunities to study cognitive and affective processes such as engagement, attention, and performance. However, the lack of scalable, synchronized, and high-resolution tools for multimodal data acquisition continues to be a significant barrier to the widespread adoption of Multimodal Learning Analytics in real-world educational settings. This paper presents two complementary tools developed to address these challenges: Watch-DMLT, a data acquisition application for Fitbit Sense 2 smartwatches that enables real-time, multi-user monitoring of physiological and motion signals; and ViSeDOPS, a dashboard-based visualization system for analyzing synchronized multimodal data collected during oral presentations. We report on a classroom deployment involving 65 students and up to 16 smartwatches, where data streams including heart rate, motion, gaze, video, and contextual annotations were captured and analyzed. Results demonstrate the feasibility and utility of the proposed system for supporting fine-grained, scalable, and interpretable Multimodal Learning Analytics in real learning environments.",
          "authors": [
            "Alvaro Becerra",
            "Pablo Villegas",
            "Ruth Cobos"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02652",
          "title": "Pianist Transformer: Towards Expressive Piano Performance Rendering via Scalable Self-Supervised Pre-Training",
          "abstract": "Existing methods for expressive music performance rendering rely on supervised learning over small labeled datasets, which limits scaling of both data volume and model size, despite the availability of vast unlabeled music, as in vision and language. To address this gap, we introduce Pianist Transformer, with four key contributions: 1) a unified Musical Instrument Digital Interface (MIDI) data representation for learning the shared principles of musical structure and expression without explicit annotation; 2) an efficient asymmetric architecture, enabling longer contexts and faster inference without sacrificing rendering quality; 3) a self-supervised pre-training pipeline with 10B tokens and 135M-parameter model, unlocking data and model scaling advantages for expressive performance rendering; 4) a state-of-the-art performance model, which achieves strong objective metrics and human-level subjective ratings. Overall, Pianist Transformer establishes a scalable path toward human-like performance synthesis in the music domain.",
          "authors": [
            "Hong-Jie You",
            "Jie-Jing Shao",
            "Xiao-Wen Yang",
            "Lin-Han Jia",
            "Lan-Zhe Guo",
            "Yu-Feng Li"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02653",
          "title": "Adaptive Weighted LSSVM for Multi-View Classification",
          "abstract": "Multi-view learning integrates diverse representations of the same instances to improve performance. Most existing kernel-based multi-view learning methods use fusion techniques without enforcing an explicit collaboration type across views or co-regularization which limits global collaboration. We propose AW-LSSVM, an adaptive weighted LS-SVM that promotes complementary learning by an iterative global coupling to make each view focus on hard samples of others from previous iterations. Experiments demonstrate that AW-LSSVM outperforms existing kernel-based multi-view methods on most datasets, while keeping raw features isolated, making it also suitable for privacy-preserving scenarios.",
          "authors": [
            "Farnaz Faramarzi Lighvan",
            "Mehrdad Asadi",
            "Lynn Houthuys"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02654",
          "title": "Cybersecurity AI: The World's Top AI Agent for Security Capture-the-Flag (CTF)",
          "abstract": "Are Capture-the-Flag competitions obsolete? In 2025, Cybersecurity AI (CAI) systematically conquered some of the world's most prestigious hacking competitions, achieving Rank #1 at multiple events and consistently outperforming thousands of human teams. Across five major circuits-HTB's AI vs Humans, Cyber Apocalypse (8,129 teams), Dragos OT CTF, UWSP Pointer Overflow, and the Neurogrid CTF showdown-CAI demonstrated that Jeopardy-style CTFs have become a solved game for well-engineered AI agents. At Neurogrid, CAI captured 41/45 flags to claim the $50,000 top prize; at Dragos OT, it sprinted 37% faster to 10K points than elite human teams; even when deliberately paused mid-competition, it maintained top-tier rankings. Critically, CAI achieved this dominance through our specialized alias1 model architecture, which delivers enterprise-scale AI security operations at unprecedented cost efficiency and with augmented autonomy-reducing 1B token inference costs from $5,940 to just $119, making continuous security agent operation financially viable for the first time. These results force an uncomfortable reckoning: if autonomous agents now dominate competitions designed to identify top security talent at negligible cost, what are CTFs actually measuring? This paper presents comprehensive evidence of AI capability across the 2025 CTF circuit and argues that the security community must urgently transition from Jeopardy-style contests to Attack & Defense formats that genuinely test adaptive reasoning and resilience-capabilities that remain uniquely human, for now.",
          "authors": [
            "Víctor Mayoral-Vilches",
            "Luis Javier Navarrete-Lozano",
            "Francesco Balassone",
            "María Sanz-Gómez",
            "Cristóbal R. J. Veas Chavez",
            "Maite del Mundo de Torres",
            "Vanesa Turiel"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02657",
          "title": "Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models",
          "abstract": "The recent rapid growth of visual generative models trained on vast web-scale datasets has created significant tension with data privacy regulations and copyright laws, such as GDPR's ``Right to be Forgotten.'' This necessitates machine unlearning (MU) to remove specific concepts without the prohibitive cost of retraining. However, existing MU techniques are fundamentally ill-equipped for real-world scenarios where deletion requests arrive sequentially, a setting known as continual unlearning (CUL). Naively applying one-shot methods in a continual setting triggers a stability crisis, leading to a cascade of degradation characterized by retention collapse, compounding collateral damage to related concepts, and a sharp decline in generative quality. To address this critical challenge, we introduce a novel generative distillation based continual unlearning framework that ensures targeted and stable unlearning under sequences of deletion requests. By reframing each unlearning step as a multi-objective, teacher-student distillation process, the framework leverages principles from continual learning to maintain model integrity. Experiments on a 10-step sequential benchmark demonstrate that our method unlearns forget concepts with better fidelity and achieves this without significant interference to the performance on retain concepts or the overall image quality, substantially outperforming baselines. This framework provides a viable pathway for the responsible deployment and maintenance of large-scale generative models, enabling industries to comply with ongoing data removal requests in a practical and effective manner.",
          "authors": [
            "Naveen George",
            "Naoki Murata",
            "Yuhta Takida",
            "Konda Reddy Mopuri",
            "Yuki Mitsufuji"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02660",
          "title": "Spatially-Grounded Document Retrieval via Patch-to-Region Relevance Propagation",
          "abstract": "Vision-language models (VLMs) like ColPali achieve state-of-the-art document retrieval by embedding pages as images and computing fine-grained similarity between query tokens and visual patches. However, they return entire pages rather than specific regions, limiting utility for retrieval-augmented generation (RAG) where precise context is paramount. Conversely, OCR-based systems extract structured text with bounding box coordinates but lack semantic grounding for relevance assessment. We propose a hybrid architecture that unifies these paradigms: using ColPali's patch-level similarity scores as spatial relevance filters over OCR-extracted regions. We formalize the coordinate mapping between vision transformer patch grids and OCR bounding boxes, introduce intersection metrics for relevance propagation, and establish theoretical bounds on retrieval precision. Our approach operates at inference time without additional training. We release Snappy, an open-source implementation demonstrating practical applicability, with empirical evaluation ongoing.",
          "authors": [
            "Agathoklis Georgiou"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02664",
          "title": "PolarGuide-GSDR: 3D Gaussian Splatting Driven by Polarization Priors and Deferred Reflection for Real-World Reflective Scenes",
          "abstract": "Polarization-aware Neural Radiance Fields (NeRF) enable novel view synthesis of specular-reflection scenes but face challenges in slow training, inefficient rendering, and strong dependencies on material/viewpoint assumptions. However, 3D Gaussian Splatting (3DGS) enables real-time rendering yet struggles with accurate reflection reconstruction from reflection-geometry entanglement, adding a deferred reflection module introduces environment map dependence. We address these limitations by proposing PolarGuide-GSDR, a polarization-forward-guided paradigm establishing a bidirectional coupling mechanism between polarization and 3DGS: first 3DGS's geometric priors are leveraged to resolve polarization ambiguity, and then the refined polarization information cues are used to guide 3DGS's normal and spherical harmonic representation. This process achieves high-fidelity reflection separation and full-scene reconstruction without requiring environment maps or restrictive material assumptions. We demonstrate on public and self-collected datasets that PolarGuide-GSDR achieves state-of-the-art performance in specular reconstruction, normal estimation, and novel view synthesis, all while maintaining real-time rendering capabilities. To our knowledge, this is the first framework embedding polarization priors directly into 3DGS optimization, yielding superior interpretability and real-time performance for modeling complex reflective scenes.",
          "authors": [
            "Derui Shan",
            "Qian Qiao",
            "Hao Lu",
            "Tao Du",
            "Peng Lu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02665",
          "title": "Input Order Shapes LLM Semantic Alignment in Multi-Document Summarization",
          "abstract": "Large language models (LLMs) are now used in settings such as Google's AI Overviews, where it summarizes multiple long documents. However, it remains unclear whether they weight all inputs equally. Focusing on abortion-related news, we construct 40 pro-neutral-con article triplets, permute each triplet into six input orders, and prompt Gemini 2.5 Flash to generate a neutral overview. We evaluate each summary against its source articles using ROUGE-L (lexical overlap), BERTScore (semantic similarity), and SummaC (factual consistency). One-way ANOVA reveals a significant primacy effect for BERTScore across all stances, indicating that summaries are more semantically aligned with the first-seen article. Pairwise comparisons further show that Position 1 differs significantly from Positions 2 and 3, while the latter two do not differ from each other, confirming a selective preference for the first document. The findings present risks for applications that rely on LLM-generated overviews and for agentic AI systems, where the steps involving LLMs can disproportionately influence downstream actions.",
          "authors": [
            "Jing Ma"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02667",
          "title": "Graph VQ-Transformer (GVT): Fast and Accurate Molecular Generation via High-Fidelity Discrete Latents",
          "abstract": "The de novo generation of molecules with desirable properties is a critical challenge, where diffusion models are computationally intensive and autoregressive models struggle with error propagation. In this work, we introduce the Graph VQ-Transformer (GVT), a two-stage generative framework that achieves both high accuracy and efficiency. The core of our approach is a novel Graph Vector Quantized Variational Autoencoder (VQ-VAE) that compresses molecular graphs into high-fidelity discrete latent sequences. By synergistically combining a Graph Transformer with canonical Reverse Cuthill-McKee (RCM) node ordering and Rotary Positional Embeddings (RoPE), our VQ-VAE achieves near-perfect reconstruction rates. An autoregressive Transformer is then trained on these discrete latents, effectively converting graph generation into a well-structured sequence modeling problem. Crucially, this mapping of complex graphs to high-fidelity discrete sequences bridges molecular design with the powerful paradigm of large-scale sequence modeling, unlocking potential synergies with Large Language Models (LLMs). Extensive experiments show that GVT achieves state-of-the-art or highly competitive performance across major benchmarks like ZINC250k, MOSES, and GuacaMol, and notably outperforms leading diffusion models on key distribution similarity metrics such as FCD and KL Divergence. With its superior performance, efficiency, and architectural novelty, GVT not only presents a compelling alternative to diffusion models but also establishes a strong new baseline for the field, paving the way for future research in discrete latent-space molecular generation.",
          "authors": [
            "Haozhuo Zheng",
            "Cheng Wang",
            "Yang Liu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02668",
          "title": "UAUTrack: Towards Unified Multimodal Anti-UAV Visual Tracking",
          "abstract": "Research in Anti-UAV (Unmanned Aerial Vehicle) tracking has explored various modalities, including RGB, TIR, and RGB-T fusion. However, a unified framework for cross-modal collaboration is still lacking. Existing approaches have primarily focused on independent models for individual tasks, often overlooking the potential for cross-modal information sharing. Furthermore, Anti-UAV tracking techniques are still in their infancy, with current solutions struggling to achieve effective multimodal data fusion. To address these challenges, we propose UAUTrack, a unified single-target tracking framework built upon a single-stream, single-stage, end-to-end architecture that effectively integrates multiple modalities. UAUTrack introduces a key component: a text prior prompt strategy that directs the model to focus on UAVs across various scenarios. Experimental results show that UAUTrack achieves state-of-the-art performance on the Anti-UAV and DUT Anti-UAV datasets, and maintains a favourable trade-off between accuracy and speed on the Anti-UAV410 dataset, demonstrating both high accuracy and practical efficiency across diverse Anti-UAV scenarios.",
          "authors": [
            "Qionglin Ren",
            "Dawei Zhang",
            "Chunxu Tian",
            "Dan Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02669",
          "title": "SAND Challenge: Four Approaches for Dysartria Severity Classification",
          "abstract": "This paper presents a unified study of four distinct modeling approaches for classifying dysarthria severity in the Speech Analysis for Neurodegenerative Diseases (SAND) challenge. All models tackle the same five class classification task using a common dataset of speech recordings. We investigate: (1) a ViT-OF method leveraging a Vision Transformer on spectrogram images, (2) a 1D-CNN approach using eight 1-D CNN's with majority-vote fusion, (3) a BiLSTM-OF approach using nine BiLSTM models with majority vote fusion, and (4) a Hierarchical XGBoost ensemble that combines glottal and formant features through a two stage learning framework. Each method is described, and their performances on a validation set of 53 speakers are compared. Results show that while the feature-engineered XGBoost ensemble achieves the highest macro-F1 (0.86), the deep learning models (ViT, CNN, BiLSTM) attain competitive F1-scores (0.70) and offer complementary insights into the problem.",
          "authors": [
            "Gauri Deshpande",
            "Harish Battula",
            "Ashish Panda",
            "Sunil Kumar Kopparapu"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02671",
          "title": "Translating Measures onto Mechanisms: The Cognitive Relevance of Higher-Order Information",
          "abstract": "Higher-order information theory has become a rapidly growing toolkit in computational neuroscience, motivated by the idea that multivariate dependencies can reveal aspects of neural computation and communication that are invisible to pairwise analyses. Yet functional interpretations of synergy and redundancy often outpace principled arguments for how statistical quantities map onto mechanistic cognitive processes. Here we review the main families of higher-order measures with the explicit goal of translating mathematical properties into defensible mechanistic inferences. First, we systematize Shannon-based multivariate metrics and demonstrate that higher-order dependence is parsimoniously characterized by two largely independent axes: interaction strength and redundancy-synergy balance. We argue that balanced layering of synergistic integration and redundant broadcasting optimizes multiscale complexity, formalizing a computation-communication tradeoff. We then examine the partial information decomposition and outline pragmatic considerations for its deployment in neural data. Equipped with the relevant mathematical essentials, we connect redundancy-synergy balance to cognitive function by progressively embedding their mathematical properties in real-world constraints, starting with small synthetic systems before gradually building up to neuroimaging. We close by identifying key future directions for mechanistic insight: cross-scale bridging, intervention-based validation, and thermodynamically grounded unification of information dynamics.",
          "authors": [
            "D. Rebbin",
            "K. J. A. Down",
            "T. F. Varley",
            "R. Ince",
            "A. Canales-Johnson"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02676",
          "title": "Exploring the Impacts of Economic Growth on Ecosystem and Its Subcomponents in Türkiye",
          "abstract": "This study analyzes the impacts of economic growth on ecosystem in Türkiye. The study uses annual data for the period 1995-2021 and the ARDL method. The study utilizes the Ecosystem Vitality Index, a sub-dimension of the Environmental Performance Index. In addition, seven models were constructed to assess in detail the impact of economic growth on different dimensions of the ecosystem. The results show that economic growth has a significant impact in all models analyzed. However, the direction of this impact differs across ecosystem components. Economic growth is found to have a positive impact on agriculture and water resources. In these models, a 1% increase in GDP increases the agriculture and water resources indices by 0.074-0.672%. In contrast, economic growth has a negative impact on biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality. In these models, a 1% increase in GDP reduces the indices of biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality by 0.101-2.144%. The results suggest that the environmental costs of economic growth processes need to be considered. Environmentally friendly policies should be combined with sustainable development strategies to reduce the negative impacts of economic growth.",
          "authors": [
            "Emre Akusta"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02676",
          "title": "Exploring the Impacts of Economic Growth on Ecosystem and Its Subcomponents in Türkiye",
          "abstract": "This study analyzes the impacts of economic growth on ecosystem in Türkiye. The study uses annual data for the period 1995-2021 and the ARDL method. The study utilizes the Ecosystem Vitality Index, a sub-dimension of the Environmental Performance Index. In addition, seven models were constructed to assess in detail the impact of economic growth on different dimensions of the ecosystem. The results show that economic growth has a significant impact in all models analyzed. However, the direction of this impact differs across ecosystem components. Economic growth is found to have a positive impact on agriculture and water resources. In these models, a 1% increase in GDP increases the agriculture and water resources indices by 0.074-0.672%. In contrast, economic growth has a negative impact on biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality. In these models, a 1% increase in GDP reduces the indices of biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality by 0.101-2.144%. The results suggest that the environmental costs of economic growth processes need to be considered. Environmentally friendly policies should be combined with sustainable development strategies to reduce the negative impacts of economic growth.",
          "authors": [
            "Emre Akusta"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02677",
          "title": "Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks",
          "abstract": "Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.",
          "authors": [
            "Zhiyuan He"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02679",
          "title": "Off-grid solar energy storage system with lithium iron phosphate (LFP) batteries in high mountains: a case report of Tianchi Lodge in Taiwan",
          "abstract": "Mountain huts are buildings located at high altitude, providing shelter and a place for hikers. Energy supply on mountain huts remains an open issue. Using renewable energies could be an appropriate solution. Tianchi Lodge, a famous mountain hut in Taiwan, has operated an off-grid solar energy storage system with lithium iron phosphate (LFP) batteries since 2020. In this case report, the energy architecture, detailed descriptions, and historical status of the system are provided.",
          "authors": [
            "Hsien-Ching Chung"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02679",
          "title": "Off-grid solar energy storage system with lithium iron phosphate (LFP) batteries in high mountains: a case report of Tianchi Lodge in Taiwan",
          "abstract": "Mountain huts are buildings located at high altitude, providing shelter and a place for hikers. Energy supply on mountain huts remains an open issue. Using renewable energies could be an appropriate solution. Tianchi Lodge, a famous mountain hut in Taiwan, has operated an off-grid solar energy storage system with lithium iron phosphate (LFP) batteries since 2020. In this case report, the energy architecture, detailed descriptions, and historical status of the system are provided.",
          "authors": [
            "Hsien-Ching Chung"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02681",
          "title": "PGP-DiffSR: Phase-Guided Progressive Pruning for Efficient Diffusion-based Image Super-Resolution",
          "abstract": "Although diffusion-based models have achieved impressive results in image super-resolution, they often rely on large-scale backbones such as Stable Diffusion XL (SDXL) and Diffusion Transformers (DiT), which lead to excessive computational and memory costs during training and inference. To address this issue, we develop a lightweight diffusion method, PGP-DiffSR, by removing redundant information from diffusion models under the guidance of the phase information of inputs for efficient image super-resolution. We first identify the intra-block redundancy within the diffusion backbone and propose a progressive pruning approach that removes redundant blocks while reserving restoration capability. We note that the phase information of the restored images produced by the pruned diffusion model is not well estimated. To solve this problem, we propose a phase-exchange adapter module that explores the phase information of the inputs to guide the pruned diffusion model for better restoration performance. We formulate the progressive pruning approach and the phase-exchange adapter module into a unified model. Extensive experiments demonstrate that our method achieves competitive restoration quality while significantly reducing computational load and memory consumption. The code is available at this https URL .",
          "authors": [
            "Zhongbao Yang",
            "Jiangxin Dong",
            "Yazhou Yao",
            "Jinhui Tang",
            "Jinshan Pan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02682",
          "title": "Beyond Single-Agent Safety: A Taxonomy of Risks in LLM-to-LLM Interactions",
          "abstract": "This paper examines why safety mechanisms designed for human-model interaction do not scale to environments where large language models (LLMs) interact with each other. Most current governance practices still rely on single-agent safety containment, prompts, fine-tuning, and moderation layers that constrain individual model behavior but leave the dynamics of multi-model interaction ungoverned. These mechanisms assume a dyadic setting: one model responding to one user under stable oversight. Yet research and industrial development are rapidly shifting toward LLM-to-LLM ecosystems, where outputs are recursively reused as inputs across chains of agents. In such systems, local compliance can aggregate into collective failure even when every model is individually aligned. We propose a conceptual transition from model-level safety to system-level safety, introducing the framework of the Emergent Systemic Risk Horizon (ESRH) to formalize how instability arises from interaction structure rather than from isolated misbehavior. The paper contributes (i) a theoretical account of collective risk in interacting LLMs, (ii) a taxonomy connecting micro, meso, and macro-level failure modes, and (iii) a design proposal for InstitutionalAI, an architecture for embedding adaptive oversight within multi-agent systems.",
          "authors": [
            "Piercosma Bisconti",
            "Marcello Galisai",
            "Federico Pierucci",
            "Marcantonio Bracale",
            "Matteo Prandi"
          ],
          "primary_category": "cs.MA",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02685",
          "title": "Unsupervised Structural Scene Decomposition via Foreground-Aware Slot Attention with Pseudo-Mask Guidance",
          "abstract": "Recent advances in object-centric representation learning have shown that slot attention-based methods can effectively decompose visual scenes into object slot representations without supervision. However, existing approaches typically process foreground and background regions indiscriminately, often resulting in background interference and suboptimal instance discovery performance on real-world data. To address this limitation, we propose Foreground-Aware Slot Attention (FASA), a two-stage framework that explicitly separates foreground from background to enable precise object discovery. In the first stage, FASA performs a coarse scene decomposition to distinguish foreground from background regions through a dual-slot competition mechanism. These slots are initialized via a clustering-based strategy, yielding well-structured representations of salient regions. In the second stage, we introduce a masked slot attention mechanism where the first slot captures the background while the remaining slots compete to represent individual foreground objects. To further address over-segmentation of foreground objects, we incorporate pseudo-mask guidance derived from a patch affinity graph constructed with self-supervised image features to guide the learning of foreground slots. Extensive experiments on both synthetic and real-world datasets demonstrate that FASA consistently outperforms state-of-the-art methods, validating the effectiveness of explicit foreground modeling and pseudo-mask guidance for robust scene decomposition and object-coherent representation. Code will be made publicly available.",
          "authors": [
            "Huankun Sheng",
            "Ming Li",
            "Yixiang Wei",
            "Yeying Fan",
            "Yu-Hui Wen",
            "Tieliang Gong",
            "Yong-Jin Liu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02686",
          "title": "ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data",
          "abstract": "Anomaly segmentation seeks to detect and localize unknown or out-of-distribution (OoD) objects that fall outside predefined semantic classes a capability essential for safe autonomous driving. However, the scarcity and limited diversity of anomaly data severely constrain model generalization in open-world environments. Existing approaches mitigate this issue through synthetic data generation, either by copy-pasting external objects into driving scenes or by leveraging text-to-image diffusion models to inpaint anomalous regions. While these methods improve anomaly diversity, they often lack contextual coherence and physical realism, resulting in domain gaps between synthetic and real data. In this paper, we present ClimaDrive, a semantics-guided image-to-image framework for synthesizing semantically coherent, weather-diverse, and physically plausible OoD driving data. ClimaDrive unifies structure-guided multi-weather generation with prompt-driven anomaly inpainting, enabling the creation of visually realistic training data. Based on this framework, we construct ClimaOoD, a large-scale benchmark spanning six representative driving scenarios under both clear and adverse weather conditions. Extensive experiments on four state-of-the-art methods show that training with ClimaOoD leads to robust improvements in anomaly segmentation. Across all methods, AUROC, AP, and FPR95 show notable gains, with FPR95 dropping from 3.97 to 3.52 for RbA on Fishyscapes LAF. These results demonstrate that ClimaOoD enhances model robustness, offering valuable training data for better generalization in open-world anomaly detection.",
          "authors": [
            "Yuxing Liu",
            "Yong Liu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02687",
          "title": "Measuring and Rating Socioeconomic Disparities among Provinces: A Case of Turkiye",
          "abstract": "Regional disparities in the economic and social structures of countries have a great impact on their development levels. In geographically, culturally and economically diverse countries like Turkiye, determining the socioeconomic status of the provinces and regional differences is an important step for planning and implementing effective policies. Therefore, this study aims to determine the socioeconomic disparities of the provinces in Turkiye. For this purpose, a socioeconomic development index covering the economic and social dimensions of 81 provinces was constructed. For the index, 16 different indicators representing economic and social factors were used. These indicators were converted into indices using the Min-Max normalization method and Principal Component Analysis. Afterwards, using these indices, the provinces were divided into groups using the K-Means clustering algorithm and the Elbow method. In the last part of the study, the results are presented in a visual format using Scatter Plots, clustering maps and QGIS mapping tools. The results of the study show that 2 of the 81 provinces in Turkiye have very high, 30 high, 25 medium and 24 low socioeconomic indices. Istanbul and Ankara have very high socioeconomic status. In general, the provinces in western Turkiye have a high socioeconomic index, while the provinces in eastern and southeastern Anatolia face serious challenges in terms of socioeconomic indicators.",
          "authors": [
            "Emre Akusta"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02687",
          "title": "Measuring and Rating Socioeconomic Disparities among Provinces: A Case of Turkiye",
          "abstract": "Regional disparities in the economic and social structures of countries have a great impact on their development levels. In geographically, culturally and economically diverse countries like Turkiye, determining the socioeconomic status of the provinces and regional differences is an important step for planning and implementing effective policies. Therefore, this study aims to determine the socioeconomic disparities of the provinces in Turkiye. For this purpose, a socioeconomic development index covering the economic and social dimensions of 81 provinces was constructed. For the index, 16 different indicators representing economic and social factors were used. These indicators were converted into indices using the Min-Max normalization method and Principal Component Analysis. Afterwards, using these indices, the provinces were divided into groups using the K-Means clustering algorithm and the Elbow method. In the last part of the study, the results are presented in a visual format using Scatter Plots, clustering maps and QGIS mapping tools. The results of the study show that 2 of the 81 provinces in Turkiye have very high, 30 high, 25 medium and 24 low socioeconomic indices. Istanbul and Ankara have very high socioeconomic status. In general, the provinces in western Turkiye have a high socioeconomic index, while the provinces in eastern and southeastern Anatolia face serious challenges in terms of socioeconomic indicators.",
          "authors": [
            "Emre Akusta"
          ],
          "primary_category": "econ.GN",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02689",
          "title": "An Empirical Survey of Model Merging Algorithms for Social Bias Mitigation",
          "abstract": "Large language models (LLMs) are known to inherit and even amplify societal biases present in their pre-training corpora, threatening fairness and social trust. To address this issue, recent work has explored ``editing'' LLM parameters to mitigate social bias with model merging approaches; however, there is no empirical comparison. In this work, we empirically survey seven algorithms: Linear, Karcher Mean, SLERP, NuSLERP, TIES, DELLA, and Nearswap, applying 13 open weight models in the GPT, LLaMA, and Qwen families. We perform a comprehensive evaluation using three bias datasets (BBQ, BOLD, and HONEST) and measure the impact of these techniques on LLM performance in downstream tasks of the SuperGLUE benchmark. We find a trade-off between bias reduction and downstream performance: methods achieving greater bias mitigation degrade accuracy, particularly on tasks requiring reading comprehension and commonsense and causal reasoning. Among the merging algorithms, Linear, SLERP, and Nearswap consistently reduce bias while maintaining overall performance, with SLERP at moderate interpolation weights emerging as the most balanced choice. These results highlight the potential of model merging algorithms for bias mitigation, while indicating that excessive debiasing or inappropriate merging methods may lead to the degradation of important linguistic abilities.",
          "authors": [
            "Daiki Shirafuji",
            "Tatsuhiko Saito",
            "Yasutomo Kimura"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02690",
          "title": "Monotone Near-Zero-Sum Games: A Generalization of Convex-Concave Minimax",
          "abstract": "Zero-sum and non-zero-sum (aka general-sum) games are relevant in a wide range of applications. While general non-zero-sum games are computationally hard, researchers focus on the special class of monotone games for gradient-based algorithms. However, there is a substantial gap between the gradient complexity of monotone zero-sum and monotone general-sum games. Moreover, in many practical scenarios of games the zero-sum assumption needs to be relaxed. To address these issues, we define a new intermediate class of monotone near-zero-sum games that contains monotone zero-sum games as a special case. Then, we present a novel algorithm that transforms the near-zero-sum games into a sequence of zero-sum subproblems, improving the gradient-based complexity for the class. Finally, we demonstrate the applicability of this new class to model practical scenarios of games motivated from the literature.",
          "authors": [
            "Ruichen Luo",
            "Sebastian U. Stich",
            "Krishnendu Chatterjee"
          ],
          "primary_category": "cs.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02690",
          "title": "Monotone Near-Zero-Sum Games: A Generalization of Convex-Concave Minimax",
          "abstract": "Zero-sum and non-zero-sum (aka general-sum) games are relevant in a wide range of applications. While general non-zero-sum games are computationally hard, researchers focus on the special class of monotone games for gradient-based algorithms. However, there is a substantial gap between the gradient complexity of monotone zero-sum and monotone general-sum games. Moreover, in many practical scenarios of games the zero-sum assumption needs to be relaxed. To address these issues, we define a new intermediate class of monotone near-zero-sum games that contains monotone zero-sum games as a special case. Then, we present a novel algorithm that transforms the near-zero-sum games into a sequence of zero-sum subproblems, improving the gradient-based complexity for the class. Finally, we demonstrate the applicability of this new class to model practical scenarios of games motivated from the literature.",
          "authors": [
            "Ruichen Luo",
            "Sebastian U. Stich",
            "Krishnendu Chatterjee"
          ],
          "primary_category": "cs.GT",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02694",
          "title": "Embedding networks with the random walk first return time distribution",
          "abstract": "We propose the first return time distribution (FRTD) of a random walk as an interpretable and mathematically grounded node embedding. The FRTD assigns a probability mass function to each node, allowing us to define a distance between any pair of nodes using standard metrics for discrete distributions. We present several arguments to motivate the FRTD embedding. First, we show that FRTDs are strictly more informative than eigenvalue spectra, yet insufficient for complete graph identification, thus placing FRTD equivalence between cospectrality and isomorphism. Second, we argue that FRTD equivalence between nodes captures structural similarity. Third, we empirically demonstrate that the FRTD embedding outperforms manually designed graph metrics in network alignment tasks. Finally, we show that random networks that approximately match the FRTD of a desired target also preserve other salient features. Together these results demonstrate the FRTD as a simple and mathematically principled embedding for complex networks.",
          "authors": [
            "Vedanta Thapar",
            "Renaud Lambiotte",
            "George T. Cantwell"
          ],
          "primary_category": "cs.SI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02695",
          "title": "Double-Helix based Real-Time Single Particle Tracking",
          "abstract": "In Real-Time, Feedback-Driven Single Particle Tracking methods, measurements of the emission intensity from a labeled, nanometer-scale particle are used in a feedback loop to track the motion of the particle as it moves inside its native environment, including within living cells. In this work, we take advantage of Point Spread Function (PSF) engineering techniques that encode the axial position of the particle into the shape of the PSF in the focal plane to eliminate the need for out-of-focal-plane measurements, reducing the complexity of implementation and decreasing the overall measurement time of the control loop. Specifically, we used the Double Helix PSF (DH-PSF) in which a single fluorescent source gives rise to two lobes in the image plane with the lobes rotating in the plane as the particle moves along the optical axis. We designed simple estimators of the relative error between the particle and the tracker, and a simple proportional feedback controller to regulate that error to zero. We explored the efficacy of the approach through simulation studies, demonstrating the tracking of fast-moving particles (with diffusion coefficients up to 10 {\\mu\\text{m}^2/\\text{s}}) over long time periods (multiple seconds).",
          "authors": [
            "Md Faysal Hossain",
            "Sean B. Andersson"
          ],
          "primary_category": "physics.optics",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02696",
          "title": "ALDI-ray: Adapting the ALDI Framework for Security X-ray Object Detection",
          "abstract": "Domain adaptation in object detection is critical for real-world applications where distribution shifts degrade model performance. Security X-ray imaging presents a unique challenge due to variations in scanning devices and environmental conditions, leading to significant domain discrepancies. To address this, we apply ALDI++, a domain adaptation framework that integrates self-distillation, feature alignment, and enhanced training strategies to mitigate domain shift effectively in this area. We conduct extensive experiments on the EDS dataset, demonstrating that ALDI++ surpasses the state-of-the-art (SOTA) domain adaptation methods across multiple adaptation scenarios. In particular, ALDI++ with a Vision Transformer for Detection (ViTDet) backbone achieves the highest mean average precision (mAP), confirming the effectiveness of transformer-based architectures for cross-domain object detection. Additionally, our category-wise analysis highlights consistent improvements in detection accuracy, reinforcing the robustness of the model across diverse object classes. Our findings establish ALDI++ as an efficient solution for domain-adaptive object detection, setting a new benchmark for performance stability and cross-domain generalization in security X-ray imagery.",
          "authors": [
            "Omid Reza Heidari",
            "Yang Wang",
            "Xinxin Zuo"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02697",
          "title": "GeoBridge: A Semantic-Anchored Multi-View Foundation Model Bridging Images and Text for Geo-Localization",
          "abstract": "Cross-view geo-localization infers a location by retrieving geo-tagged reference images that visually correspond to a query image. However, the traditional satellite-centric paradigm limits robustness when high-resolution or up-to-date satellite imagery is unavailable. It further underexploits complementary cues across views (e.g., drone, satellite, and street) and modalities (e.g., language and image). To address these challenges, we propose GeoBridge, a foundation model that performs bidirectional matching across views and supports language-to-image retrieval. Going beyond traditional satellite-centric formulations, GeoBridge builds on a novel semantic-anchor mechanism that bridges multi-view features through textual descriptions for robust, flexible localization. In support of this task, we construct GeoLoc, the first large-scale, cross-modal, and multi-view aligned dataset comprising over 50,000 pairs of drone, street-view panorama, and satellite images as well as their textual descriptions, collected from 36 countries, ensuring both geographic and semantic alignment. We performed broad evaluations across multiple tasks. Experiments confirm that GeoLoc pre-training markedly improves geo-location accuracy for GeoBridge while promoting cross-domain generalization and cross-modal knowledge transfer. The dataset, source code, and pretrained models were released at this https URL .",
          "authors": [
            "Zixuan Song",
            "Jing Zhang",
            "Di Wang",
            "Zidie Zhou",
            "Wenbin Liu",
            "Haonan Guo",
            "En Wang",
            "Bo Du"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02699",
          "title": "Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding",
          "abstract": "In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.",
          "authors": [
            "Hyeongseop Rha",
            "Jeong Hun Yeo",
            "Junil Won",
            "Se Jin Park",
            "Yong Man Ro"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02700",
          "title": "VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm",
          "abstract": "Vision-language models (VLMs) excel at image understanding tasks, but the large number of visual tokens imposes significant computational costs, hindering deployment on mobile devices. Many pruning methods rely solely on token importance and thus overlook inter-token redundancy, retaining numerous duplicated tokens and wasting capacity. Although some redundancy-aware approaches have been proposed, they often ignore the spatial relationships among visual tokens. This can lead to overly sparse selections of retained tokens that fail to adequately cover the regions of target objects. To address these limitations, we propose VLM-Pruner, a training-free token pruning algorithm that explicitly balances redundancy and spatial sparsity. We introduce a centrifugal token pruning paradigm that enables near-to-far selection while prioritizing the preservation of fine-grained object details. Moreover, we design a Buffering for Spatial Sparsity (BSS) criterion that defers the selection of spatially distant tokens. We further adopt a parallel greedy strategy to conduct token selection efficiently. To mitigate information loss from pruning, we selectively fuse salient information from the discarded tokens into the retained ones. Comprehensive comparisons demonstrate that VLM-Pruner consistently outperforms strong baselines across five VLMs with an 88.9\\% pruning rate, while delivering an end-to-end inference speedup.",
          "authors": [
            "Zhenkai Wu",
            "Xiaowen Ma",
            "Zhenliang Ni",
            "Dengming Zhang",
            "Han Shu",
            "Xin Jiang",
            "Xinghao Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02702",
          "title": "Tissue-mask supported inter-subject whole-body image registration in the UK Biobank - A method benchmarking study",
          "abstract": "The UK Biobank is a large-scale study collecting whole-body MR imaging and non-imaging health data. Robust and accurate inter-subject image registration of these whole-body MR images would enable their body-wide spatial standardization, and region-/voxel-wise correlation analysis of non-imaging data with image-derived parameters (e.g., tissue volume or fat content). We propose a sex-stratified inter-subject whole-body MR image registration approach that uses subcutaneous adipose tissue- and muscle-masks from the state-of-the-art VIBESegmentator method to augment intensity-based graph-cut registration. The proposed method was evaluated on a subset of 4000 subjects by comparing it to an intensity-only method as well as two previously published registration methods, uniGradICON and MIRTK. The evaluation comprised overlap measures applied to the 71 VIBESegmentator masks: 1) Dice scores, and 2) voxel-wise label error frequency. Additionally, voxel-wise correlation between age and each of fat content and tissue volume was studied to exemplify the usefulness for medical research. The proposed method exhibited a mean dice score of 0.77 / 0.75 across the cohort and the 71 masks for males/females, respectively. When compared to the intensity-only registration, the mean values were 6 percentage points (pp) higher for both sexes, and the label error frequency was decreased in most tissue regions. These differences were 9pp / 8pp against uniGradICON and 12pp / 13pp against MIRTK. Using the proposed method, the age-correlation maps were less noisy and showed higher anatomical alignment. In conclusion, the image registration method using two tissue masks improves whole-body registration of UK Biobank images.",
          "authors": [
            "Yasemin Utkueri",
            "Elin Lundström",
            "Håkan Ahlström",
            "Johan Öfverstedt",
            "Joel Kullberg"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02705",
          "title": "FGC-Comp: Adaptive Neighbor-Grouped Attribute Completion for Graph-based Anomaly Detection",
          "abstract": "Graph-based Anomaly Detection models have gained widespread adoption in recent years, identifying suspicious nodes by aggregating neighborhood information. However, most existing studies overlook the pervasive issues of missing and adversarially obscured node attributes, which can undermine aggregation stability and prediction reliability. To mitigate this, we propose FGC-Comp, a lightweight, classifier-agnostic, and deployment-friendly attribute completion module-designed to enhance neighborhood aggregation under incomplete attributes. We partition each node's neighbors into three label-based groups, apply group-specific transforms to the labeled groups while a node-conditioned gate handles unknowns, fuse messages via residual connections, and train end-to-end with a binary classification objective to improve aggregation stability and prediction reliability under missing attributes. Experiments on two real-world fraud datasets validate the effectiveness of the approach with negligible computational overhead.",
          "authors": [
            "Junpeng Wu",
            "Pinheng Zong"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02707",
          "title": "Empirical Assessment of the Perception of Software Product Line Engineering by an SME before Migrating its Code Base",
          "abstract": "Migrating a set of software variants into a software product line (SPL) is an expensive and potentially challenging endeavor. Indeed, SPL engineering can significantly impact a company's development process and often requires changes to established developer practices. The work presented in this paper stems from a collaboration with a Small and Medium-sized Enterprise (SME) that decided to migrate its existing code base into an SPL. In this study, we conducted an in-depth evaluation of the company's current development processes and practices, as well as the anticipated benefits and risks associated with the migration. Key stakeholders involved in software development participated in this evaluation to provide insight into their perceptions of the migration and their potential resistance to change. This paper describes the design of the interviews conducted with these stakeholders and presents an analysis of the results. Among the qualitative findings, we observed that all participants, regardless of their role in the development process, identified benefits of the migration relevant to their own activities. Furthermore, our results suggest that an effective risk mitigation strategy involves keeping stakeholders informed and engaged throughout the process, preserving as many good practices as possible, and actively involving them in the migration to ensure a smooth transition and minimize potential challenges.",
          "authors": [
            "Thomas Georges",
            "Marianne Huchard",
            "Mélanie König",
            "Clémentine Nebut",
            "Chouki Tibermacine"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02710",
          "title": "Beyond N-grams: A Hierarchical Reward Learning Framework for Clinically-Aware Medical Report Generation",
          "abstract": "Automatic medical report generation can greatly reduce the workload of doctors, but it is often unreliable for real-world deployment. Current methods can write formally fluent sentences but may be factually flawed, introducing serious medical errors known as clinical hallucinations, which make them untrustworthy for diagnosis. To bridge this gap, we introduce HiMed-RL, a Hierarchical Medical Reward Learning Framework designed to explicitly prioritize clinical quality. HiMed-RL moves beyond simple text matching by deconstructing reward learning into three synergistic levels: it first ensures linguistic fluency at the token-level, then enforces factual grounding at the concept-level by aligning key medical terms with expert knowledge, and finally assesses high-level diagnostic consistency at the semantic-level using a specialized LLM verifier. This hierarchical reward is implemented via a Human-inspired Dynamic Reward Adjustment, a strategy which first teaches the model to learn basic facts before progressing to more complex diagnostic reasoning. Experimentally, HiMed-3B achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks, particularly on the latter, with an improvement of 12.1% over the second-best baseline. Our work provides a robust paradigm for generating reports that not only improve fluency but clinical fine-grained quality.",
          "authors": [
            "Yuan Wang",
            "Shujian Gao",
            "Jiaxiang Liu",
            "Songtao Jiang",
            "Haoxiang Xia",
            "Xiaotian Zhang",
            "Zhaolu Kang",
            "Yemin Wang",
            "Zuozhu Liu"
          ],
          "primary_category": "cs.CE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02711",
          "title": "CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer",
          "abstract": "Ensuring content safety in large language models (LLMs) is essential for their deployment in real-world applications. However, existing safety guardrails are predominantly tailored for high-resource languages, leaving a significant portion of the world's population underrepresented who communicate in low-resource languages. To address this, we introduce CREST (CRoss-lingual Efficient Safety Transfer), a parameter-efficient multilingual safety classification model that supports 100 languages with only 0.5B parameters. By training on a strategically chosen subset of only 13 high-resource languages, our model utilizes cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages. This approach addresses the challenge of limited training data in low-resource settings. We conduct comprehensive evaluations across six safety benchmarks to demonstrate that CREST outperforms existing state-of-the-art guardrails of comparable scale and achieves competitive results against models with significantly larger parameter counts (2.5B parameters and above). Our findings highlight the limitations of language-specific guardrails and underscore the importance of developing universal, language-agnostic safety systems that can scale effectively to serve global populations.",
          "authors": [
            "Lavish Bansal",
            "Naman Mishra"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02712",
          "title": "G-PIFNN: A Generalizable Physics-informed Fourier Neural Network Framework for Electrical Circuits",
          "abstract": "Physics-Informed Neural Networks (PINNs) have advanced the data-driven solution of differential equations (DEs) in dynamic physical systems, yet challenges remain in explainability, scalability, and architectural complexity. This paper presents a Generalizable Physics-Informed Fourier Neural Network (G-PIFNN) framework that enhances PINN architectures for efficient and interpretable electrical circuit analysis. The proposed G-PIFNN introduces three key advancements: (1) improved performance and interpretability via a physics activation function (PAF) and a lightweight Physics-Informed Fourier Neural Network (PIFNN) architecture; (2) automated, bond graph (BG) based formulation of physics-informed loss functions for systematic differential equation generation; and (3) integration of intra-circuit and cross-circuit class transfer learning (TL) strategies, enabling unsupervised fine-tuning for rapid adaptation to varying circuit topologies. Numerical simulations demonstrate that G-PIFNN achieves significantly better predictive performance and generalization across diverse circuit classes, while significantly reducing the number of trainable parameters compared to standard PINNs.",
          "authors": [
            "Ibrahim Shahbaz",
            "Mohammad J. Abdel-Rahman",
            "Eman Hammad"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02713",
          "title": "Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs",
          "abstract": "As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.",
          "authors": [
            "Theodoros Aivalis",
            "Iraklis A. Klampanos",
            "Antonis Troumpoukis",
            "Joemon M. Jose"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02715",
          "title": "GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding",
          "abstract": "Recent advances in multimodal large language models(MLLMs) have led to remarkable progress in visual grounding, enabling fine-grained cross-modal alignment between textual queries and image regions. However, transferring such capabilities to remote sensing imagery remains challenging, as targets are often extremely small within kilometer-scale scenes, and queries typically involve intricate geospatial relations such as relative positions, spatial hierarchies, or contextual dependencies across distant objects. To address these challenges, we propose GeoViS, a Geospatially Rewarded Visual Search framework that reformulates remote sensing visual grounding as a progressive search-and-reasoning process. Rather than directly predicting the target location in a single step, GeoViS actively explores the global image through a tree-structured sequence of visual cues, integrating multimodal perception, spatial reasoning, and reward-guided exploration to refine geospatial hypotheses iteratively. This design enables the model to detect subtle small-scale targets while maintaining holistic scene awareness. Extensive experiments on five remote sensing grounding benchmarks demonstrate that GeoViS achieves precise geospatial understanding and consistently surpasses existing methods across key visual grounding metrics, highlighting its strong cross-domain generalization and interpretability.",
          "authors": [
            "Peirong Zhang",
            "Yidan Zhang",
            "Luxiao Xu",
            "Jinliang Lin",
            "Zonghao Guo",
            "Fengxiang Wang",
            "Xue Yang",
            "Kaiwen Wei",
            "Lei Wang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02716",
          "title": "Menta: A Small Language Model for On-Device Mental Health Prediction",
          "abstract": "Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: this https URL",
          "authors": [
            "Tianyi Zhang",
            "Xiangyuan Xue",
            "Lingyan Ruan",
            "Shiya Fu",
            "Feng Xia",
            "Simon D'Alfonso",
            "Vassilis Kostakos",
            "Hong Jia"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02717",
          "title": "A Port-Hamiltonian Modeling Approach for Integrated Hydrogen Systems",
          "abstract": "Hydrogen's growing role in the transition towards climate-neutral energy systems necessitates structured modeling frameworks. Existing gas network models, largely developed for natural gas, fail to capture hydrogen systems distinct properties, particularly the coupling of hydrogen pipes with electrolyzers, fuel cells, and electrically driven compressors. In this work, we present a unified systematic port-Hamiltonian (pH) framework for modeling hydrogen systems, which inherently provides a passive input-output map of the overall interconnected system and, thus, a promising foundation for structured analysis, control and optimization of this type of newly emerging energy systems.",
          "authors": [
            "Abdullah Shahin",
            "Hannes Gernandt",
            "Anton Plietzsch",
            "Johannes Schiffer"
          ],
          "primary_category": "math.OC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02719",
          "title": "Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs",
          "abstract": "Large language models (LLMs) excel at explicit reasoning, but their implicit computational strategies remain underexplored. Decades of psychophysics research show that humans intuitively process and integrate noisy signals using near-optimal Bayesian strategies in perceptual tasks. We ask whether LLMs exhibit similar behaviour and perform optimal multimodal integration without explicit training or instruction. Adopting the psychophysics paradigm, we infer computational principles of LLMs from systematic behavioural studies. We introduce a behavioural benchmark - BayesBench: four magnitude estimation tasks (length, location, distance, and duration) over text and image, inspired by classic psychophysics, and evaluate a diverse set of nine LLMs alongside human judgments for calibration. Through controlled ablations of noise, context, and instruction prompts, we measure performance, behaviour and efficiency in multimodal cue-combination. Beyond accuracy and efficiency metrics, we introduce a Bayesian Consistency Score that detects Bayes-consistent behavioural shifts even when accuracy saturates. Our results show that while capable models often adapt in Bayes-consistent ways, accuracy does not guarantee robustness. Notably, GPT-5 Mini achieves perfect text accuracy but fails to integrate visual cues efficiently. This reveals a critical dissociation between capability and strategy, suggesting accuracy-centric benchmarks may over-index on performance while missing brittle uncertainty handling. These findings reveal emergent principled handling of uncertainty and highlight the correlation between accuracy and Bayesian tendencies. We release our psychophysics benchmark and consistency metric ( this https URL ) as evaluation tools and to inform future multimodal architecture designs.",
          "authors": [
            "Julian Ma",
            "Jun Wang",
            "Zafeirios Fountas"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02719",
          "title": "Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs",
          "abstract": "Large language models (LLMs) excel at explicit reasoning, but their implicit computational strategies remain underexplored. Decades of psychophysics research show that humans intuitively process and integrate noisy signals using near-optimal Bayesian strategies in perceptual tasks. We ask whether LLMs exhibit similar behaviour and perform optimal multimodal integration without explicit training or instruction. Adopting the psychophysics paradigm, we infer computational principles of LLMs from systematic behavioural studies. We introduce a behavioural benchmark - BayesBench: four magnitude estimation tasks (length, location, distance, and duration) over text and image, inspired by classic psychophysics, and evaluate a diverse set of nine LLMs alongside human judgments for calibration. Through controlled ablations of noise, context, and instruction prompts, we measure performance, behaviour and efficiency in multimodal cue-combination. Beyond accuracy and efficiency metrics, we introduce a Bayesian Consistency Score that detects Bayes-consistent behavioural shifts even when accuracy saturates. Our results show that while capable models often adapt in Bayes-consistent ways, accuracy does not guarantee robustness. Notably, GPT-5 Mini achieves perfect text accuracy but fails to integrate visual cues efficiently. This reveals a critical dissociation between capability and strategy, suggesting accuracy-centric benchmarks may over-index on performance while missing brittle uncertainty handling. These findings reveal emergent principled handling of uncertainty and highlight the correlation between accuracy and Bayesian tendencies. We release our psychophysics benchmark and consistency metric ( this https URL ) as evaluation tools and to inform future multimodal architecture designs.",
          "authors": [
            "Julian Ma",
            "Jun Wang",
            "Zafeirios Fountas"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02720",
          "title": "StockMem: An Event-Reflection Memory Framework for Stock Forecasting",
          "abstract": "Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.",
          "authors": [
            "He Wang",
            "Wenyilin Xiao",
            "Songqiao Han",
            "Hailiang Huang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02722",
          "title": "Credal Graph Neural Networks",
          "abstract": "Uncertainty quantification is essential for deploying reliable Graph Neural Networks (GNNs), where existing approaches primarily rely on Bayesian inference or ensembles. In this paper, we introduce the first credal graph neural networks (CGNNs), which extend credal learning to the graph domain by training GNNs to output set-valued predictions in the form of credal sets. To account for the distinctive nature of message passing in GNNs, we develop a complementary approach to credal learning that leverages different aspects of layer-wise information propagation. We assess our approach on uncertainty quantification in node classification under out-of-distribution conditions. Our analysis highlights the critical role of the graph homophily assumption in shaping the effectiveness of uncertainty estimates. Extensive experiments demonstrate that CGNNs deliver more reliable representations of epistemic uncertainty and achieve state-of-the-art performance under distributional shift on heterophilic graphs.",
          "authors": [
            "Matteo Tolloso",
            "Davide Bacciu"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02726",
          "title": "AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping",
          "abstract": "Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \\textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.",
          "authors": [
            "Md Abdul Kadir",
            "Sai Suresh Macharla Vasu",
            "Sidharth S. Nair",
            "Daniel Sonntag"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02727",
          "title": "DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions",
          "abstract": "Modeling daily hand interactions often struggles with severe occlusions, such as when two hands overlap, which highlights the need for robust feature learning in 3D hand pose estimation (HPE). To handle such occluded hand images, it is vital to effectively learn the relationship between local image features (e.g., for occluded joints) and global context (e.g., cues from inter-joints, inter-hands, or the scene). However, most current 3D HPE methods still rely on ResNet for feature extraction, and such CNN's inductive bias may not be optimal for 3D HPE due to its limited capability to model the global context. To address this limitation, we propose an effective and efficient framework for visual feature extraction in 3D HPE using recent state space modeling (i.e., Mamba), dubbed Deformable Mamba (DF-Mamba). DF-Mamba is designed to capture global context cues beyond standard convolution through Mamba's selective state modeling and the proposed deformable state scanning. Specifically, for local features after convolution, our deformable scanning aggregates these features within an image while selectively preserving useful cues that represent the global context. This approach significantly improves the accuracy of structured 3D HPE, with comparable inference speed to ResNet-50. Our experiments involve extensive evaluations on five divergent datasets including single-hand and two-hand scenarios, hand-only and hand-object interactions, as well as RGB and depth-based estimation. DF-Mamba outperforms the latest image backbones, including VMamba and Spatial-Mamba, on all datasets and achieves state-of-the-art performance.",
          "authors": [
            "Yifan Zhou",
            "Takehiko Ohkawa",
            "Guwenxiao Zhou",
            "Kanoko Goto",
            "Takumi Hirose",
            "Yusuke Sekikawa",
            "Nakamasa Inoue"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02728",
          "title": "Integrative Analysis of Risk Management Methodologies in Data Science Projects",
          "abstract": "Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.",
          "authors": [
            "Sabrina Delmondes da Costa Feitosa"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02729",
          "title": "RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning",
          "abstract": "We introduce Robowheel, a data engine that converts human hand object interaction (HOI) videos into training-ready supervision for cross morphology robotic learning. From monocular RGB or RGB-D inputs, we perform high precision HOI reconstruction and enforce physical plausibility via a reinforcement learning (RL) optimizer that refines hand object relative poses under contact and penetration constraints. The reconstructed, contact rich trajectories are then retargeted to cross-embodiments, robot arms with simple end effectors, dexterous hands, and humanoids, yielding executable actions and rollouts. To scale coverage, we build a simulation-augmented framework on Isaac Sim with diverse domain randomization (embodiments, trajectories, object retrieval, background textures, hand motion mirroring), which enriches the distributions of trajectories and observations while preserving spatial relationships and physical plausibility. The entire data pipeline forms an end to end pipeline from video,reconstruction,retargeting,augmentation data acquisition. We validate the data on mainstream vision language action (VLA) and imitation learning architectures, demonstrating that trajectories produced by our pipeline are as stable as those from teleoperation and yield comparable continual performance gains. To our knowledge, this provides the first quantitative evidence that HOI modalities can serve as effective supervision for robotic learning. Compared with teleoperation, Robowheel is lightweight, a single monocular RGB(D) camera is sufficient to extract a universal, embodiment agnostic motion representation that could be flexibly retargeted across embodiments. We further assemble a large scale multimodal dataset combining multi-camera captures, monocular videos, and public HOI corpora for training and evaluating embodied models.",
          "authors": [
            "Yuhong Zhang",
            "Zihan Gao",
            "Shengpeng Li",
            "Ling-Hao Chen",
            "Kaisheng Liu",
            "Runqing Cheng",
            "Xiao Lin",
            "Junjia Liu",
            "Zhuoheng Li",
            "Jingyi Feng",
            "Ziyan He",
            "Jintian Lin",
            "Zheyan Huang",
            "Zhifang Liu",
            "Haoqian Wang"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02731",
          "title": "Self-Improving AI Agents through Self-Play",
          "abstract": "We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $\\nu_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $\\Theta$, and we identify the coefficient of self-improvement $\\kappa$ as the Lie derivative of the capability functional along this flow. The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $\\kappa > 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough. We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.",
          "authors": [
            "Przemyslaw Chojecki"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02735",
          "title": "A Framework for Causal Concept-based Model Explanations",
          "abstract": "This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.",
          "authors": [
            "Anna Rodum Bjøru",
            "Jacob Lysnæs-Larsen",
            "Oskar Jørgensen",
            "Inga Strümke",
            "Helge Langseth"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02737",
          "title": "Beyond Paired Data: Self-Supervised UAV Geo-Localization from Reference Imagery Alone",
          "abstract": "Image-based localization in GNSS-denied environments is critical for UAV autonomy. Existing state-of-the-art approaches rely on matching UAV images to geo-referenced satellite images; however, they typically require large-scale, paired UAV-satellite datasets for training. Such data are costly to acquire and often unavailable, limiting their applicability. To address this challenge, we adopt a training paradigm that removes the need for UAV imagery during training by learning directly from satellite-view reference images. This is achieved through a dedicated augmentation strategy that simulates the visual domain shift between satellite and real-world UAV views. We introduce CAEVL, an efficient model designed to exploit this paradigm, and validate it on ViLD, a new and challenging dataset of real-world UAV images that we release to the community. Our method achieves competitive performance compared to approaches trained with paired data, demonstrating its effectiveness and strong generalization capabilities.",
          "authors": [
            "Tristan Amadei",
            "Enric Meinhardt-Llopis",
            "Benedicte Bascle",
            "Corentin Abgrall",
            "Gabriele Facciolo"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02738",
          "title": "Probabilistic energy profiler for statically typed JVM-based programming languages",
          "abstract": "Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.",
          "authors": [
            "Joel Nyholm",
            "Wojciech Mostowski",
            "Christoph Reichenbach"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02740",
          "title": "Adversarial Jamming for Autoencoder Distribution Matching",
          "abstract": "We propose the use of adversarial wireless jamming to regularise the latent space of an autoencoder to match a diagonal Gaussian distribution. We consider the minimisation of a mean squared error distortion, where a jammer attempts to disrupt the recovery of a Gaussian source encoded and transmitted over the adversarial channel. A straightforward consequence of existing theoretical results is the fact that the saddle point of a minimax game - involving such an encoder, its corresponding decoder, and an adversarial jammer - consists of diagonal Gaussian noise output by the jammer. We use this result as inspiration for a novel approach to distribution matching in the latent space, utilising jamming as an auxiliary objective to encourage the aggregated latent posterior to match a diagonal Gaussian distribution. Using this new technique, we achieve distribution matching comparable to standard variational autoencoders and to Wasserstein autoencoders. This approach can also be generalised to other latent distributions.",
          "authors": [
            "Waleed El-Geresy",
            "Deniz Gündüz"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02740",
          "title": "Adversarial Jamming for Autoencoder Distribution Matching",
          "abstract": "We propose the use of adversarial wireless jamming to regularise the latent space of an autoencoder to match a diagonal Gaussian distribution. We consider the minimisation of a mean squared error distortion, where a jammer attempts to disrupt the recovery of a Gaussian source encoded and transmitted over the adversarial channel. A straightforward consequence of existing theoretical results is the fact that the saddle point of a minimax game - involving such an encoder, its corresponding decoder, and an adversarial jammer - consists of diagonal Gaussian noise output by the jammer. We use this result as inspiration for a novel approach to distribution matching in the latent space, utilising jamming as an auxiliary objective to encourage the aggregated latent posterior to match a diagonal Gaussian distribution. Using this new technique, we achieve distribution matching comparable to standard variational autoencoders and to Wasserstein autoencoders. This approach can also be generalised to other latent distributions.",
          "authors": [
            "Waleed El-Geresy",
            "Deniz Gündüz"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02743",
          "title": "Reasoning-Aware Multimodal Fusion for Hateful Video Detection",
          "abstract": "Hate speech in online videos is posing an increasingly serious threat to digital platforms, especially as video content becomes increasingly multimodal and context-dependent. Existing methods often struggle to effectively fuse the complex semantic relationships between modalities and lack the ability to understand nuanced hateful content. To address these issues, we propose an innovative Reasoning-Aware Multimodal Fusion (RAMF) framework. To tackle the first challenge, we design Local-Global Context Fusion (LGCF) to capture both local salient cues and global temporal structures, and propose Semantic Cross Attention (SCA) to enable fine-grained multimodal semantic interaction. To tackle the second challenge, we introduce adversarial reasoning-a structured three-stage process where a vision-language model generates (i) objective descriptions, (ii) hate-assumed inferences, and (iii) non-hate-assumed inferences-providing complementary semantic perspectives that enrich the model's contextual understanding of nuanced hateful intent. Evaluations on two real-world hateful video datasets demonstrate that our method achieves robust generalisation performance, improving upon state-of-the-art methods by 3% and 7% in Macro-F1 and hate class recall, respectively. We will release the code after the anonymity period ends.",
          "authors": [
            "Shuonan Yang",
            "Tailin Chen",
            "Jiangbei Yue",
            "Guangliang Cheng",
            "Jianbo Jiao",
            "Zeyu Fu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02744",
          "title": "Implicit score-driven filters for time-varying parameter models",
          "abstract": "We propose an observation-driven modeling framework that permits time variation in the model parameters using an implicit score-driven (ISD) update. The ISD update maximizes the logarithmic observation density with respect to the parameter vector, while penalizing the weighted L2 norm relative to a one-step-ahead predicted parameter. This yields an implicit stochastic-gradient update. We show that the popular class of explicit score-driven (ESD) models arises if the observation log density is linearly approximated around the prediction. By preserving the full density, the ISD update globalizes favorable local properties of the ESD update. Namely, for log-concave observation densities, whether correctly specified or not, the ISD filter is stable for all learning rates, while its updates are contractive in mean squared error toward the (pseudo-)true parameter at every time step. We demonstrate the usefulness of ISD filters in simulations and empirical illustrations in finance and macroeconomics.",
          "authors": [
            "Rutger-Jan Lange",
            "Bram van Os",
            "Dick van Dijk"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02744",
          "title": "Implicit score-driven filters for time-varying parameter models",
          "abstract": "We propose an observation-driven modeling framework that permits time variation in the model parameters using an implicit score-driven (ISD) update. The ISD update maximizes the logarithmic observation density with respect to the parameter vector, while penalizing the weighted L2 norm relative to a one-step-ahead predicted parameter. This yields an implicit stochastic-gradient update. We show that the popular class of explicit score-driven (ESD) models arises if the observation log density is linearly approximated around the prediction. By preserving the full density, the ISD update globalizes favorable local properties of the ESD update. Namely, for log-concave observation densities, whether correctly specified or not, the ISD filter is stable for all learning rates, while its updates are contractive in mean squared error toward the (pseudo-)true parameter at every time step. We demonstrate the usefulness of ISD filters in simulations and empirical illustrations in finance and macroeconomics.",
          "authors": [
            "Rutger-Jan Lange",
            "Bram van Os",
            "Dick van Dijk"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02748",
          "title": "BART Streams: Real-time Reconstruction Using a Modular Framework for Pipeline Processing",
          "abstract": "Purpose: To create modular solutions for interactive real-time MRI using reconstruction algorithms implemented in BART. Methods: A new protocol for streaming of multidimensional arrays is presented and integrated into BART. The new functionality is demonstrated using examples for interactive real-time MRI based on radial FLASH, where iterative reconstruction is combined with advanced features such as dynamic coil compression and gradient-delay correction. We analyze the latency of the reconstruction and measure end-to-end latency of the full imaging process. Results: Reconstruction pipelines with iterative reconstruction and advanced functionality can be built in a modular way using scripting. Latency measurements demonstrate latency sufficient for interactive real-time MRI. Conclusion: With the new streaming capabilities, real-time reconstruction pipelines can be assembled using BART in a flexible way, enabling rapid prototyping of advanced applications such as interactive real-time MRI.",
          "authors": [
            "Philip Schaten",
            "Moritz Blumenthal",
            "Bernhard Rapp",
            "Christina Unterberg-Buchwald",
            "Martin Uecker"
          ],
          "primary_category": "physics.med-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02750",
          "title": "\"Can you feel the vibes?\": An exploration of novice programmer engagement with vibe coding",
          "abstract": "Emerging alongside generative AI and the broader trend of AI-assisted coding, the term \"vibe coding\" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.",
          "authors": [
            "Kiev Gama",
            "Filipe Calegario",
            "Victoria Jackson",
            "Alexander Nolte",
            "Luiz Augusto Morais",
            "Vinicius Garcia"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02751",
          "title": "AttMetNet: Attention-Enhanced Deep Neural Network for Methane Plume Detection in Sentinel-2 Satellite Imagery",
          "abstract": "Methane is a powerful greenhouse gas that contributes significantly to global warming. Accurate detection of methane emissions is the key to taking timely action and minimizing their impact on climate change. We present AttMetNet, a novel attention-enhanced deep learning framework for methane plume detection with Sentinel-2 satellite imagery. The major challenge in developing a methane detection model is to accurately identify methane plumes from Sentinel-2's B11 and B12 bands while suppressing false positives caused by background variability and diverse land cover types. Traditional detection methods typically depend on the differences or ratios between these bands when comparing the scenes with and without plumes. However, these methods often require verification by a domain expert because they generate numerous false positives. Recent deep learning methods make some improvements using CNN-based architectures, but lack mechanisms to prioritize methane-specific features. AttMetNet introduces a methane-aware architecture that fuses the Normalized Difference Methane Index (NDMI) with an attention-enhanced U-Net. By jointly exploiting NDMI's plume-sensitive cues and attention-driven feature selection, AttMetNet selectively amplifies methane absorption features while suppressing background noise. This integration establishes a first-of-its-kind architecture tailored for robust methane plume detection in real satellite imagery. Additionally, we employ focal loss to address the severe class imbalance arising from both limited positive plume samples and sparse plume pixels within imagery. Furthermore, AttMetNet is trained on the real methane plume dataset, making it more robust to practical scenarios. Extensive experiments show that AttMetNet surpasses recent methods in methane plume detection with a lower false positive rate, better precision recall balance, and higher IoU.",
          "authors": [
            "Rakib Ahsan",
            "MD Sadik Hossain Shanto",
            "Md Sultanul Arifin",
            "Tanzima Hashem"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02759",
          "title": "Towards Language-Independent Face-Voice Association with Multimodal Foundation Models",
          "abstract": "This paper describes the UZH-CL system submitted to the FAME2026 Challenge. The challenge focuses on cross-modal verification under unique multilingual conditions, specifically unseen and unheard languages. Our approach investigates two distinct architectures, consisting of a baseline dual-encoder system trained from scratch using contrastive and orthogonal projection losses, and a foundation model approach leveraging ImageBind with LoRA. To address the data scarcity and language constraints of the challenge, we curated an external Arabic dataset from VoxBlink. Our best-performing system, ImageBind-LoRA, demonstrates remarkable cross-lingual generalization: despite being fine-tuned exclusively on Arabic audio, it achieved an EER of 24.73% on the evaluation set (English and German), securing 2nd place in the competition.",
          "authors": [
            "Aref Farhadipour",
            "Teodora Vukovic",
            "Volker Dellwo"
          ],
          "primary_category": "eess.AS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02759",
          "title": "Towards Language-Independent Face-Voice Association with Multimodal Foundation Models",
          "abstract": "This paper describes the UZH-CL system submitted to the FAME2026 Challenge. The challenge focuses on cross-modal verification under unique multilingual conditions, specifically unseen and unheard languages. Our approach investigates two distinct architectures, consisting of a baseline dual-encoder system trained from scratch using contrastive and orthogonal projection losses, and a foundation model approach leveraging ImageBind with LoRA. To address the data scarcity and language constraints of the challenge, we curated an external Arabic dataset from VoxBlink. Our best-performing system, ImageBind-LoRA, demonstrates remarkable cross-lingual generalization: despite being fine-tuned exclusively on Arabic audio, it achieved an EER of 24.73% on the evaluation set (English and German), securing 2nd place in the competition.",
          "authors": [
            "Aref Farhadipour",
            "Teodora Vukovic",
            "Volker Dellwo"
          ],
          "primary_category": "eess.AS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02763",
          "title": "SurveyEval: Towards Comprehensive Evaluation of LLM-Generated Academic Surveys",
          "abstract": "LLM-based automatic survey systems are transforming how users acquire information from the web by integrating retrieval, organization, and content synthesis into end-to-end generation pipelines. While recent works focus on developing new generation pipelines, how to evaluate such complex systems remains a significant challenge. To this end, we introduce SurveyEval, a comprehensive benchmark that evaluates automatically generated surveys across three dimensions: overall quality, outline coherence, and reference accuracy. We extend the evaluation across 7 subjects and augment the LLM-as-a-Judge framework with human references to strengthen evaluation-human alignment. Evaluation results show that while general long-text or paper-writing systems tend to produce lower-quality surveys, specialized survey-generation systems are able to deliver substantially higher-quality results. We envision SurveyEval as a scalable testbed to understand and improve automatic survey systems across diverse subjects and evaluation criteria.",
          "authors": [
            "Jiahao Zhao",
            "Shuaixing Zhang",
            "Nan Xu",
            "Lei Wang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02764",
          "title": "PEFT-Factory: Unified Parameter-Efficient Fine-Tuning of Autoregressive Large Language Models",
          "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods address the increasing size of Large Language Models (LLMs). Currently, many newly introduced PEFT methods are challenging to replicate, deploy, or compare with one another. To address this, we introduce PEFT-Factory, a unified framework for efficient fine-tuning LLMs using both off-the-shelf and custom PEFT methods. While its modular design supports extensibility, it natively provides a representative set of 19 PEFT methods, 27 classification and text generation datasets addressing 12 tasks, and both standard and PEFT-specific evaluation metrics. As a result, PEFT-Factory provides a ready-to-use, controlled, and stable environment, improving replicability and benchmarking of PEFT methods. PEFT-Factory is a downstream framework that originates from the popular LLaMA-Factory, and is publicly available at this https URL",
          "authors": [
            "Robert Belanec",
            "Ivan Srba",
            "Maria Bielikova"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02765",
          "title": "Effects of disease duration and antipsychotics on brain age in schizophrenia",
          "abstract": "Accelerated brain aging has been consistently reported in patients with schizophrenia. Over the past decade, these findings have been replicated using the Brain Age paradigm, which applies machine learning techniques to estimate brain age from neuroimaging data. This approach yields a single index, the Brain Age Gap, defined as the difference between predicted and chronological age. Nevertheless, both the progressive nature of this phenomenon and the potential role of antipsychotic medication remain unclear. To investigate its progression, we compared the Brain Age Gap between individuals experiencing a first episode of psychosis and healthy controls using ANCOVA, adjusting for age, sex, body mass index, and estimated total intracranial volume. To enhance the robustness of our findings, we employed two distinct models: a transformer-inspired model based on harmonized volumetric brain features extracted with FastSurfer, and a previously trained deep learning model. To assess the potential effect of medication, we further compared bipolar patients who received antipsychotic treatment with those who did not. Mann-Whitney U test consistently showed that medicated bipolar patients did not exhibit a significantly larger Brain Age Gap. Both models converge on the conclusion that accelerated brain aging is unlikely to be explained by antipsychotic medication alone. Longitudinal studies are therefore required to clarify the temporal dynamics of brain aging in schizophrenia.",
          "authors": [
            "Alejandro Roig-Herrero",
            "Luis M. San-José-Revuelta",
            "Rafael Navarro-González",
            "Rodrigo de Luis-García",
            "Vicente Molina"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02768",
          "title": "Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements",
          "abstract": "Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios.",
          "authors": [
            "Hefei Gao",
            "Tianyao Huang",
            "Letian Guo",
            "Jie He",
            "Yonina C. Eldar"
          ],
          "primary_category": "eess.SP",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02771",
          "title": "Position-Sensitive Silicon Photomultiplier Array with Enhanced Position Reconstruction by means of a Deep Neural Network",
          "abstract": "Single-photon sensitive detectors like Silicon Photomultipliers are widely used in many medical imaging applications. By using detectors with position resolutions, it is possible to build compact photodetector readouts with reduced number of channels, but still preserving position resolution and gamma-rays imaging capabilities. In this work, we present the advantage of using a Deep Neural Networks (DNNs) light position reconstruction applied to a 2x2 array of linearly-graded SiPMs (LG-SiPMs), to minimize the distortions on the reconstructed event maps. Our approach significantly enhances both the resolution and linearity of position detection compared to the nominal reconstruction formula based on the device architecture. Remarkably, the DNN-based reconstruction boosts the number of resolved areas (pixels) by a factor of at least 5.7, allowing a higher level of precision and performance in light detection.",
          "authors": [
            "Cyril Alispach",
            "Fabio Acerbi",
            "Hossein Arabi",
            "Domenico della Volpe",
            "Alberto Gola",
            "Aramis Raiola",
            "Habib Zaidi"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02771",
          "title": "Position-Sensitive Silicon Photomultiplier Array with Enhanced Position Reconstruction by means of a Deep Neural Network",
          "abstract": "Single-photon sensitive detectors like Silicon Photomultipliers are widely used in many medical imaging applications. By using detectors with position resolutions, it is possible to build compact photodetector readouts with reduced number of channels, but still preserving position resolution and gamma-rays imaging capabilities. In this work, we present the advantage of using a Deep Neural Networks (DNNs) light position reconstruction applied to a 2x2 array of linearly-graded SiPMs (LG-SiPMs), to minimize the distortions on the reconstructed event maps. Our approach significantly enhances both the resolution and linearity of position detection compared to the nominal reconstruction formula based on the device architecture. Remarkably, the DNN-based reconstruction boosts the number of resolved areas (pixels) by a factor of at least 5.7, allowing a higher level of precision and performance in light detection.",
          "authors": [
            "Cyril Alispach",
            "Fabio Acerbi",
            "Hossein Arabi",
            "Domenico della Volpe",
            "Alberto Gola",
            "Aramis Raiola",
            "Habib Zaidi"
          ],
          "primary_category": "physics.ins-det",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02772",
          "title": "Towards Unification of Hallucination Detection and Fact Verification for Large Language Models",
          "abstract": "Large Language Models (LLMs) frequently exhibit hallucinations, generating content that appears fluent and coherent but is factually incorrect. Such errors undermine trust and hinder their adoption in real-world applications. To address this challenge, two distinct research paradigms have emerged: model-centric Hallucination Detection (HD) and text-centric Fact Verification (FV). Despite sharing the same goal, these paradigms have evolved in isolation, using distinct assumptions, datasets, and evaluation protocols. This separation has created a research schism that hinders their collective progress. In this work, we take a decisive step toward bridging this divide. We introduce UniFact, a unified evaluation framework that enables direct, instance-level comparison between FV and HD by dynamically generating model outputs and corresponding factuality labels. Through large-scale experiments across multiple LLM families and detection methods, we reveal three key findings: (1) No paradigm is universally superior; (2) HD and FV capture complementary facets of factual errors; and (3) hybrid approaches that integrate both methods consistently achieve state-of-the-art performance. Beyond benchmarking, we provide the first in-depth analysis of why FV and HD diverged, as well as empirical evidence supporting the need for their unification. The comprehensive experimental results call for a new, integrated research agenda toward unifying Hallucination Detection and Fact Verification in LLMs. We have open-sourced all the code, data, and baseline implementation at: this https URL",
          "authors": [
            "Weihang Su",
            "Jianming Long",
            "Changyue Wang",
            "Shiyu Lin",
            "Jingyan Xu",
            "Ziyi Ye",
            "Qingyao Ai",
            "Yiqun Liu"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02774",
          "title": "AI-Driven Document Redaction in UK Public Authorities: Implementation Gaps, Regulatory Challenges, and the Human Oversight Imperative",
          "abstract": "Document redaction in public authorities faces critical challenges as traditional manual approaches struggle to balance growing transparency demands with increasingly stringent data protection requirements. This study investigates the implementation of AI-driven document redaction within UK public authorities through Freedom of Information (FOI) requests. While AI technologies offer potential solutions to redaction challenges, their actual implementation within public sector organizations remains underexplored. Based on responses from 44 public authorities across healthcare, government, and higher education sectors, this study reveals significant gaps between technological possibilities and organizational realities. Findings show highly limited AI adoption (only one authority reported using AI tools), widespread absence of formal redaction policies (50 percent reported \"information not held\"), and deficiencies in staff training. The study identifies three key barriers to effective AI implementation: poor record-keeping practices, lack of standardized redaction guidelines, and insufficient specialized training for human oversight. These findings highlight the need for a socio-technical approach that balances technological automation with meaningful human expertise. This research provides the first empirical assessment of AI redaction practices in UK public authorities and contributes evidence to support policymakers navigating the complex interplay between transparency obligations, data protection requirements, and emerging AI technologies in public administration.",
          "authors": [
            "Yijun Chen"
          ],
          "primary_category": "cs.CY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02777",
          "title": "CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy",
          "abstract": "Safe autonomous driving in mixed traffic requires a unified understanding of multimodal interactions and dynamic planning under uncertainty. Existing learning based approaches struggle to capture rare but safety critical behaviors, while rule based systems often lack adaptability in complex interactions. To address these limitations, CogDrive introduces a cognition driven multimodal prediction and planning framework that integrates explicit modal reasoning with safety aware trajectory optimization. The prediction module adopts cognitive representations of interaction modes based on topological motion semantics and nearest neighbor relational encoding. With a differentiable modal loss and multimodal Gaussian decoding, CogDrive learns sparse and unbalanced interaction behaviors and improves long horizon trajectory prediction. The planning module incorporates an emergency response concept and optimizes safety stabilized trajectories, where short term consistent branches ensure safety during replanning cycles and long term branches support smooth and collision free motion under low probability switching modes. Experiments on Argoverse2 and INTERACTION datasets show that CogDrive achieves strong performance in trajectory accuracy and miss rate, while closed loop simulations confirm adaptive behavior in merge and intersection scenarios. By combining cognitive multimodal prediction with safety oriented planning, CogDrive offers an interpretable and reliable paradigm for safe autonomy in complex traffic.",
          "authors": [
            "Heye Huang",
            "Yibin Yang",
            "Mingfeng Fan",
            "Haoran Wang",
            "Xiaocong Zhao",
            "Jianqiang Wang"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02780",
          "title": "Rethinking Surgical Smoke: A Smoke-Type-Aware Laparoscopic Video Desmoking Method and Dataset",
          "abstract": "Electrocautery or lasers will inevitably generate surgical smoke, which hinders the visual guidance of laparoscopic videos for surgical procedures. The surgical smoke can be classified into different types based on its motion patterns, leading to distinctive spatio-temporal characteristics across smoky laparoscopic videos. However, existing desmoking methods fail to account for such smoke-type-specific distinctions. Therefore, we propose the first Smoke-Type-Aware Laparoscopic Video Desmoking Network (STANet) by introducing two smoke types: Diffusion Smoke and Ambient Smoke. Specifically, a smoke mask segmentation sub-network is designed to jointly conduct smoke mask and smoke type predictions based on the attention-weighted mask aggregation, while a smokeless video reconstruction sub-network is proposed to perform specially desmoking on smoky features guided by two types of smoke mask. To address the entanglement challenges of two smoke types, we further embed a coarse-to-fine disentanglement module into the mask segmentation sub-network, which yields more accurate disentangled masks through the smoke-type-aware cross attention between non-entangled and entangled regions. In addition, we also construct the first large-scale synthetic video desmoking dataset with smoke type annotations. Extensive experiments demonstrate that our method not only outperforms state-of-the-art approaches in quality evaluations, but also exhibits superior generalization across multiple downstream surgical tasks.",
          "authors": [
            "Qifan Liang",
            "Junlin Li",
            "Zhen Han",
            "Xihao Wang",
            "Zhongyuan Wang",
            "Bin Mei"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02781",
          "title": "LumiX: Structured and Coherent Text-to-Intrinsic Generation",
          "abstract": "We present LumiX, a structured diffusion framework for coherent text-to-intrinsic generation. Conditioned on text prompts, LumiX jointly generates a comprehensive set of intrinsic maps (e.g., albedo, irradiance, normal, depth, and final color), providing a structured and physically consistent description of an underlying scene. This is enabled by two key contributions: 1) Query-Broadcast Attention, a mechanism that ensures structural consistency by sharing queries across all maps in each self-attention block. 2) Tensor LoRA, a tensor-based adaptation that parameter-efficiently models cross-map relations for efficient joint training. Together, these designs enable stable joint diffusion training and unified generation of multiple intrinsic properties. Experiments show that LumiX produces coherent and physically meaningful results, achieving 23% higher alignment and a better preference score (0.19 vs. -0.41) compared to the state of the art, and it can also perform image-conditioned intrinsic decomposition within the same framework.",
          "authors": [
            "Xu Han",
            "Biao Zhang",
            "Xiangjun Tang",
            "Xianzhi Li",
            "Peter Wonka"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02783",
          "title": "Exploring Definitions of Quality and Diversity in Sonic Measurement Spaces",
          "abstract": "Digital sound synthesis presents the opportunity to explore vast parameter spaces containing millions of configurations. Quality diversity (QD) evolutionary algorithms offer a promising approach to harness this potential, yet their success hinges on appropriate sonic feature representations. Existing QD methods predominantly employ handcrafted descriptors or supervised classifiers, potentially introducing unintended exploration biases and constraining discovery to familiar sonic regions. This work investigates unsupervised dimensionality reduction methods for automatically defining and dynamically reconfiguring sonic behaviour spaces during QD search. We apply Principal Component Analysis (PCA) and autoencoders to project high-dimensional audio features onto structured grids for MAP-Elites, implementing dynamic reconfiguration through model retraining at regular intervals. Comparison across two experimental scenarios shows that automatic approaches achieve significantly greater diversity than handcrafted behaviour spaces while avoiding expert-imposed biases. Dynamic behaviour-space reconfiguration maintains evolutionary pressure and prevents stagnation, with PCA proving most effective among the dimensionality reduction techniques. These results contribute to automated sonic discovery systems capable of exploring vast parameter spaces without manual intervention or supervised training constraints.",
          "authors": [
            "Björn Þór Jónsson",
            "Çağrı Erdem",
            "Stefano Fasciani",
            "Kyrre Glette"
          ],
          "primary_category": "cs.SD",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02785",
          "title": "Perception of AI-Generated Music - The Role of Composer Identity, Personality Traits, Music Preferences, and Perceived Humanness",
          "abstract": "The rapid rise of AI-generated art has sparked debate about potential biases in how audiences perceive and evaluate such works. This study investigates how composer information and listener characteristics shape the perception of AI-generated music, adopting a mixed-method approach. Using a diverse set of stimuli across various genres from two AI music models, we examine effects of perceived authorship on liking and emotional responses, and explore how attitudes toward AI, personality traits, and music-related variables influence evaluations. We further assess the influence of perceived humanness and analyze open-ended responses to uncover listener criteria for judging AI-generated music. Attitudes toward AI proved to be the best predictor of both liking and emotional intensity of AI-generated music. This quantitative finding was complemented by qualitative themes from our thematic analysis, which identified ethical, cultural, and contextual considerations as important criteria in listeners' evaluations of AI-generated music. Our results offer a nuanced view of how people experience music created by AI tools and point to key factors and methodological considerations for future research on music perception in human-AI interaction.",
          "authors": [
            "David Stammer",
            "Hannah Strauss",
            "Peter Knees"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02786",
          "title": "FiMMIA: scaling semantic perturbation-based membership inference across modalities",
          "abstract": "Membership Inference Attacks (MIAs) aim to determine whether a specific data point was included in the training set of a target model. Although there are have been numerous methods developed for detecting data contamination in large language models (LLMs), their performance on multimodal LLMs (MLLMs) falls short due to the instabilities introduced through multimodal component adaptation and possible distribution shifts across multiple inputs. In this work, we investigate multimodal membership inference and address two issues: first, by identifying distribution shifts in the existing datasets, and second, by releasing an extended baseline pipeline to detect them. We also generalize the perturbation-based membership inference methods to MLLMs and release \\textbf{FiMMIA} -- a modular \\textbf{F}ramework for \\textbf{M}ultimodal \\textbf{MIA}.\\footnote{The source code and framework have been made publicly available under the MIT license via \\href{ this https URL }{link}.The video demonstration is available on \\href{ this https URL }{YouTube}.} Our approach trains a neural network to analyze the target model's behavior on perturbed inputs, capturing distributional differences between members and non-members. Comprehensive evaluations on various fine-tuned multimodal models demonstrate the effectiveness of our perturbation-based membership inference attacks in multimodal domains.",
          "authors": [
            "Anton Emelyanov",
            "Sergei Kudriashov",
            "Alena Fenogenova"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02787",
          "title": "Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols",
          "abstract": "Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic manipulation, yet they remain limited in failure diagnosis and learning from failures. Additionally, existing failure datasets are mostly generated programmatically in simulation, which limits their generalization to the real world. In light of these, we introduce ViFailback, a framework designed to diagnose robotic manipulation failures and provide both textual and visual correction guidance. Our framework utilizes explicit visual symbols to enhance annotation efficiency. We further release the ViFailback dataset, a large-scale collection of 58,126 Visual Question Answering (VQA) pairs along with their corresponding 5,202 real-world manipulation trajectories. Based on the dataset, we establish ViFailback-Bench, a benchmark of 11 fine-grained VQA tasks designed to assess the failure diagnosis and correction abilities of Vision-Language Models (VLMs), featuring ViFailback-Bench Lite for closed-ended and ViFailback-Bench Hard for open-ended evaluation. To demonstrate the effectiveness of our framework, we built the ViFailback-8B VLM, which not only achieves significant overall performance improvement on ViFailback-Bench but also generates visual symbols for corrective action guidance. Finally, by integrating ViFailback-8B with a VLA model, we conduct real-world robotic experiments demonstrating its ability to assist the VLA model in recovering from failures. Project Website: this https URL",
          "authors": [
            "Xianchao Zeng",
            "Xinyu Zhou",
            "Youcheng Li",
            "Jiayou Shi",
            "Tianle Li",
            "Liangming Chen",
            "Lei Ren",
            "Yong-Lu Li"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02789",
          "title": "TrackNetV5: Residual-Driven Spatio-Temporal Refinement and Motion Direction Decoupling for Fast Object Tracking",
          "abstract": "The TrackNet series has established a strong baseline for fast-moving small object tracking in sports. However, existing iterations face significant limitations: V1-V3 struggle with occlusions due to a reliance on purely visual cues, while TrackNetV4, despite introducing motion inputs, suffers from directional ambiguity as its absolute difference method discards motion polarity. To overcome these bottlenecks, we propose TrackNetV5, a robust architecture integrating two novel mechanisms. First, to recover lost directional priors, we introduce the Motion Direction Decoupling (MDD) module. Unlike V4, MDD decomposes temporal dynamics into signed polarity fields, explicitly encoding both movement occurrence and trajectory direction. Second, we propose the Residual-Driven Spatio-Temporal Refinement (R-STR) head. Operating on a coarse-to-fine paradigm, this Transformer-based module leverages factorized spatio-temporal contexts to estimate a corrective residual, effectively recovering occluded targets. Extensive experiments on the TrackNetV2 dataset demonstrate that TrackNetV5 achieves a new state-of-the-art F1-score of 0.9859 and an accuracy of 0.9733, significantly outperforming previous versions. Notably, this performance leap is achieved with a marginal 3.7% increase in FLOPs compared to V4, maintaining real-time inference capabilities while delivering superior tracking precision.",
          "authors": [
            "Tang Haonan",
            "Chen Yanjun",
            "Jiang Lezhi"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02790",
          "title": "UnicEdit-10M: A Dataset and Benchmark Breaking the Scale-Quality Barrier via Unified Verification for Reasoning-Enriched Edits",
          "abstract": "With the rapid advances of powerful multimodal models such as GPT-4o, Nano Banana, and Seedream 4.0 in Image Editing, the performance gap between closed-source and open-source models is widening, primarily due to the scarcity of large-scale, high-quality training data and comprehensive benchmarks capable of diagnosing model weaknesses across diverse editing behaviors. Existing data construction methods face a scale-quality trade-off: human annotations are high-quality but not scalable, while automated pipelines suffer from error propagation and noise. To address this, we introduce a lightweight data pipeline that replaces multi-toolchains with an end-to-end model and a unified post-verification stage. For scalable quality control, we train a 7B dual-task expert model, \\textbf{Qwen-Verify}, for efficient failure detection and instruction recaptioning. This pipeline yields \\textbf{UnicEdit-10M}, a 10M-scale dataset spanning diverse basic and complex editing tasks. We also propose \\textbf{UnicBench}, a general benchmark that extends beyond basic edits to explicitly assess spatial and knowledge-driven reasoning. To enable fine-grained diagnosis, we introduce novel metrics, including \\textit{Non-edit Consistency} and \\textit{Reasoning Accuracy}. Our analysis of mainstream models on UnicBench reveals their limitations and provides clear directions for future research.",
          "authors": [
            "Keming Ye",
            "Zhipeng Huang",
            "Canmiao Fu",
            "Qingyang Liu",
            "Jiani Cai",
            "Zheqi Lv",
            "Chen Li",
            "Jing Lyu",
            "Zhou Zhao",
            "Shengyu Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02791",
          "title": "Making Dialogue Grounding Data Rich: A Three-Tier Data Synthesis Framework for Generalized Referring Expression Comprehension",
          "abstract": "Dialogue-Based Generalized Referring Expressions Comprehension (GREC) requires models to ground the expression and unlimited targets in complex visual scenes while resolving coreference across a long dialogue context. However, existing systems struggle under distribution shift between training and evaluation domains, a gap exacerbated by the scarcity of annotated dialogue grounding data. We address this challenge with a three-tier data-synthesis method that balances realism and controllability to produce scalable supervision for dialogue-conditioned grounding. Fine-tuning on the synthesized data yields consistent, substantial improvements over prior approaches across standard evaluation metrics.",
          "authors": [
            "Juexi Shao",
            "Siyou Li",
            "Yujian Gan",
            "Chris Madge",
            "Vanja Karan",
            "Massimo Poesio"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02792",
          "title": "HUD: Hierarchical Uncertainty-Aware Disambiguation Network for Composed Video Retrieval",
          "abstract": "Composed Video Retrieval (CVR) is a challenging video retrieval task that utilizes multi-modal queries, consisting of a reference video and modification text, to retrieve the desired target video. The core of this task lies in understanding the multi-modal composed query and achieving accurate composed feature learning. Within multi-modal queries, the video modality typically carries richer semantic content compared to the textual modality. However, previous works have largely overlooked the disparity in information density between these two modalities. This limitation can lead to two critical issues: 1) modification subject referring ambiguity and 2) limited detailed semantic focus, both of which degrade the performance of CVR models. To address the aforementioned issues, we propose a novel CVR framework, namely the Hierarchical Uncertainty-aware Disambiguation network (HUD). HUD is the first framework that leverages the disparity in information density between video and text to enhance multi-modal query understanding. It comprises three key components: (a) Holistic Pronoun Disambiguation, (b) Atomistic Uncertainty Modeling, and (c) Holistic-to-Atomistic Alignment. By exploiting overlapping semantics through holistic cross-modal interaction and fine-grained semantic alignment via atomistic-level cross-modal interaction, HUD enables effective object disambiguation and enhances the focus on detailed semantics, thereby achieving precise composed feature learning. Moreover, our proposed HUD is also applicable to the Composed Image Retrieval (CIR) task and achieves state-of-the-art performance across three benchmark datasets for both CVR and CIR tasks. The codes are available on this https URL .",
          "authors": [
            "Zhiwei Chen",
            "Yupeng Hu",
            "Zixu Li",
            "Zhiheng Fu",
            "Haokun Wen",
            "Weili Guan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02793",
          "title": "IC-World: In-Context Generation for Shared World Modeling",
          "abstract": "Video-based world models have recently garnered increasing attention for their ability to synthesize diverse and dynamic visual environments. In this paper, we focus on shared world modeling, where a model generates multiple videos from a set of input images, each representing the same underlying world in different camera poses. We propose IC-World, a novel generation framework, enabling parallel generation for all input images via activating the inherent in-context generation capability of large video models. We further finetune IC-World via reinforcement learning, Group Relative Policy Optimization, together with two proposed novel reward models to enforce scene-level geometry consistency and object-level motion consistency among the set of generated videos. Extensive experiments demonstrate that IC-World substantially outperforms state-of-the-art methods in both geometry and motion consistency. To the best of our knowledge, this is the first work to systematically explore the shared world modeling problem with video-based world models.",
          "authors": [
            "Fan Wu",
            "Jiacheng Wei",
            "Ruibo Li",
            "Yi Xu",
            "Junyou Li",
            "Deheng Ye",
            "Guosheng Lin"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02794",
          "title": "PhyCustom: Towards Realistic Physical Customization in Text-to-Image Generation",
          "abstract": "Recent diffusion-based text-to-image customization methods have achieved significant success in understanding concrete concepts to control generation processes, such as styles and shapes. However, few efforts dive into the realistic yet challenging customization of physical concepts. The core limitation of current methods arises from the absence of explicitly introducing physical knowledge during training. Even when physics-related words appear in the input text prompts, our experiments consistently demonstrate that these methods fail to accurately reflect the corresponding physical properties in the generated results. In this paper, we propose PhyCustom, a fine-tuning framework comprising two novel regularization losses to activate diffusion model to perform physical customization. Specifically, the proposed isometric loss aims at activating diffusion models to learn physical concepts while decouple loss helps to eliminate the mixture learning of independent concepts. Experiments are conducted on a diverse dataset and our benchmark results demonstrate that PhyCustom outperforms previous state-of-the-art and popular methods in terms of physical customization quantitatively and qualitatively.",
          "authors": [
            "Fan Wu",
            "Cheng Chen",
            "Zhoujie Fu",
            "Jiacheng Wei",
            "Yi Xu",
            "Deheng Ye",
            "Guosheng Lin"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02795",
          "title": "Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior",
          "abstract": "Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: this https URL",
          "authors": [
            "Marcus Kessel"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02799",
          "title": "TriLex: A Framework for Multilingual Sentiment Analysis in Low-Resource South African Languages",
          "abstract": "Low-resource African languages remain underrepresented in sentiment analysis, limiting both lexical coverage and the performance of multilingual Natural Language Processing (NLP) systems. This study proposes TriLex, a three-stage retrieval augmented framework that unifies corpus-based extraction, cross lingual mapping, and retrieval augmented generation (RAG) driven lexical refinement to systematically expand sentiment lexicons for low-resource languages. Using the enriched lexicon, the performance of two prominent African pretrained language models (AfroXLMR and AfriBERTa) is evaluated across multiple case studies. Results demonstrate that AfroXLMR delivers superior performance, achieving F1-scores above 80% for isiXhosa and isiZulu and exhibiting strong cross-lingual stability. Although AfriBERTa lacks pre-training on these target languages, it still achieves reliable F1-scores around 64%, validating its utility in computationally constrained settings. Both models outperform traditional machine learning baselines, and ensemble analyses further enhance precision and robustness. The findings establish TriLex as a scalable and effective framework for multilingual sentiment lexicon expansion and sentiment modeling in low-resource South African languages.",
          "authors": [
            "Mike Nkongolo",
            "Hilton Vorster",
            "Josh Warren",
            "Trevor Naick",
            "Deandre Vanmali",
            "Masana Mashapha",
            "Luke Brand",
            "Alyssa Fernandes",
            "Janco Calitz",
            "Sibusiso Makhoba"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02803",
          "title": "System Identification for Dynamic Modeling of a Bumper Car",
          "abstract": "This paper presents the modeling of autonomous vehicles with high maneuverability used in an experimental framework for educational purposes. Since standard bicycle models typically neglect wide steering angles, we develop modified planar bicycle models and combine them with both parametric and non-parametric identification techniques that progressively incorporate physical knowledge. The resulting models are systematically compared to evaluate the tradeoff between model accuracy and computational requirements, showing that physics-informed neural network models surpass the purely physical baseline in accuracy at lower computational cost.",
          "authors": [
            "Tobias Petri",
            "Simone Baratto",
            "Giancarlo Ferrari Trecate"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02803",
          "title": "System Identification for Dynamic Modeling of a Bumper Car",
          "abstract": "This paper presents the modeling of autonomous vehicles with high maneuverability used in an experimental framework for educational purposes. Since standard bicycle models typically neglect wide steering angles, we develop modified planar bicycle models and combine them with both parametric and non-parametric identification techniques that progressively incorporate physical knowledge. The resulting models are systematically compared to evaluate the tradeoff between model accuracy and computational requirements, showing that physics-informed neural network models surpass the purely physical baseline in accuracy at lower computational cost.",
          "authors": [
            "Tobias Petri",
            "Simone Baratto",
            "Giancarlo Ferrari Trecate"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02807",
          "title": "SR-GRPO: Stable Rank as an Intrinsic Geometric Reward for Large Language Model Alignment",
          "abstract": "Aligning Large Language Models (LLMs) with human preferences typically relies on external supervision, which faces critical limitations: human annotations are scarce and subjective, reward models are vulnerable to reward hacking, and self-evaluation methods suffer from prompt sensitivity and biases. In this work, we propose stable rank, an intrinsic, annotation-free quality signal derived from model representations. Stable rank measures the effective dimensionality of hidden states by computing the ratio of total variance to dominant-direction variance, capturing quality through how information distributes across representation dimensions. Empirically, stable rank achieves 84.04% accuracy on RewardBench and improves task accuracy by an average of 11.3 percentage points over greedy decoding via Best-of-N sampling. Leveraging this insight, we introduce Stable Rank Group Relative Policy Optimization (SR-GRPO), which uses stable rank as a reward signal for reinforcement learning. Without external supervision, SR-GRPO improves Qwen2.5-1.5B-Instruct by 10% on STEM and 19% on mathematical reasoning, outperforming both learned reward models and self-evaluation baselines. Our findings demonstrate that quality signals can be extracted from internal model geometry, offering a path toward scalable alignment without external supervision.",
          "authors": [
            "Yixuan Tang",
            "Yi Yang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02810",
          "title": "Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms",
          "abstract": "Multi-robot task allocation in construction automation has traditionally relied on optimization methods such as Dynamic Programming and Reinforcement Learning. This research introduces the LangGraph-based Task Allocation Agent (LTAA), an LLM-driven framework that integrates phase-adaptive allocation strategies, multi-stage validation with hierarchical retries, and dynamic prompting for efficient robot coordination. Although recent LLM approaches show potential for construction robotics, they largely lack rigorous validation and benchmarking against established algorithms. This paper presents the first systematic comparison of LLM-based task allocation with traditional methods in construction this http URL study validates LLM feasibility through SMART-LLM replication and addresses implementation challenges using a Self-Corrective Agent Architecture. LTAA leverages natural-language reasoning combined with structured validation mechanisms, achieving major computational gains reducing token usage by 94.6% and allocation time by 86% through dynamic prompting. The framework adjusts its strategy across phases: emphasizing execution feasibility early and workload balance in later this http URL authors evaluate LTAA against Dynamic Programming, Q-learning, and Deep Q-Network (DQN) baselines using construction operations from the TEACh human-robot collaboration dataset. In the Heavy Excels setting, where robots have strong task specializations, LTAA achieves 77% task completion with superior workload balance, outperforming all traditional methods. These findings show that LLM-based reasoning with structured validation can match established optimization algorithms while offering additional advantages such as interpretability, adaptability, and the ability to update task logic without retraining.",
          "authors": [
            "Shyam prasad reddy Kaitha",
            "Hongrui Yu"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02812",
          "title": "Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents",
          "abstract": "Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\\% and 13\\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.",
          "authors": [
            "Zijie Lin",
            "Qilin Cai",
            "Liang Shen",
            "Mingjun Xiao"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02814",
          "title": "Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control",
          "abstract": "Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.",
          "authors": [
            "Yongrui Yu",
            "Zhongzhen Huang",
            "Linjie Mu",
            "Shaoting Zhang",
            "Xiaofan Zhang"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02816",
          "title": "A benchmark dataset for evaluating Syndrome Differentiation and Treatment in large language models",
          "abstract": "The emergence of Large Language Models (LLMs) within the Traditional Chinese Medicine (TCM) domain presents an urgent need to assess their clinical application capabilities. However, such evaluations are challenged by the individualized, holistic, and diverse nature of TCM's \"Syndrome Differentiation and Treatment\" (SDT). Existing benchmarks are confined to knowledge-based question-answering or the accuracy of syndrome differentiation, often neglecting assessment of treatment decision-making. Here, we propose a comprehensive, clinical case-based benchmark spearheaded by TCM experts, and a specialized reward model employed to quantify prescription-syndrome congruence. Data annotation follows a rigorous pipeline. This benchmark, designated TCM-BEST4SDT, encompasses four tasks, including TCM Basic Knowledge, Medical Ethics, LLM Content Safety, and SDT. The evaluation framework integrates three mechanisms, namely selected-response evaluation, judge model evaluation, and reward model evaluation. The effectiveness of TCM-BEST4SDT was corroborated through experiments on 15 mainstream LLMs, spanning both general and TCM domains. To foster the development of intelligent TCM research, TCM-BEST4SDT is now publicly available.",
          "authors": [
            "Kunning Li",
            "Jianbin Guo",
            "Zhaoyang Shang",
            "Yiqing Liu",
            "Hongmin Du",
            "Lingling Liu",
            "Yuping Zhao",
            "Lifeng Dong"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02817",
          "title": "BOOM: Beyond Only One Modality KIT's Multimodal Multilingual Lecture Companion",
          "abstract": "The globalization of education and rapid growth of online learning have made localizing educational content a critical challenge. Lecture materials are inherently multimodal, combining spoken audio with visual slides, which requires systems capable of processing multiple input modalities. To provide an accessible and complete learning experience, translations must preserve all modalities: text for reading, slides for visual understanding, and speech for auditory learning. We present \\textbf{BOOM}, a multimodal multilingual lecture companion that jointly translates lecture audio and slides to produce synchronized outputs across three modalities: translated text, localized slides with preserved visual elements, and synthesized speech. This end-to-end approach enables students to access lectures in their native language while aiming to preserve the original content in its entirety. Our experiments demonstrate that slide-aware transcripts also yield cascading benefits for downstream tasks such as summarization and question answering. We release our Slide Translation code at this https URL and integrate it in Lecture Translator at this https URL }\\footnote{All released code and models are licensed under the MIT License.",
          "authors": [
            "Sai Koneru",
            "Fabian Retkowski",
            "Christian Huber",
            "Lukas Hilgert",
            "Seymanur Akti",
            "Enes Yavuz Ugan",
            "Alexander Waibel",
            "Jan Niehues"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02818",
          "title": "Designing FAIR Workflows at OLCF: Building Scalable and Reusable Ecosystems for HPC Science",
          "abstract": "High Performance Computing (HPC) centers provide advanced infrastructure that enables scientific research at extreme scale. These centers operate with hardware configurations, software environments, and security requirements that differ substantially from most users' local systems. As a result, users often develop customized digital artifacts that are tightly coupled to a given HPC center. This practice can lead to significant duplication of effort as multiple users independently create similar solutions to common problems. The FAIR Principles offer a framework to address these challenges. Initially designed to improve data stewardship, the FAIR approach has since been extended to encompass software, workflows, models, and infrastructure. By encouraging the use of rich metadata and community standards, FAIR practices aim to make digital artifacts easier to share and reuse, both within and across scientific domains. Many FAIR initiatives have emerged within individual research communities, often aligned by discipline (e.g. bioinformatics, earth sciences). These communities have made progress in adopting FAIR practices, but their domain-specific nature can lead to silos that limit broader collaboration. Thus, we propose that HPC centers play a more active role in fostering FAIR ecosystems that support research across multiple disciplines. This requires designing infrastructure that enables researchers to discover, share, and reuse computational components more effectively. Here, we build on the architecture of the European Open Science Cloud (EOSC) EOSC-Life FAIR Workflows Collaboratory to propose a model tailored to the needs of HPC. Rather than focusing on entire workflows, we emphasize the importance of making individual workflow components FAIR. This component-based approach better supports the diverse and evolving needs of HPC users while maximizing the long-term value of their work.",
          "authors": [
            "Sean R. Wilkinson",
            "Patrick Widener",
            "Sarp Oral",
            "Rafael Ferreira da Silva"
          ],
          "primary_category": "cs.DC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02820",
          "title": "Q-triplet characterization of atmospheric time series at Antofagasta: A missing values problem",
          "abstract": "Located in northern Chile (23.7°S, 70.4°W), Antofagasta has an exceptionally arid and stable climate characterized by minimal precipitation and consistent weather patterns. Nevertheless, despite these climate conditions being meaningful for several research and practical applications, our understanding of weather dynamics remains limited. The available meteorological data from 1969 to 2016 is analogical, which presents a significant challenge to analyze because these records are riddled with missing values, some measurements were taken at irregular measuring intervals, making it an interesting puzzle to grasp the Antofagasta's climate scenario. To overcome this issue, we present a comprehensive statistical analysis of atmospheric temperature, pressure, and humidity time series. Our analytical approach involves the q-triplet calculation method, serving as a powerful tool to identify distinctive behavior within systems under non-equilibrium states. Our results suggest that, in general, the q-triplet values satisfy the condition $q_\\text{sens}<1<q_\\text{stat}<q_\\text{rel}$, a pattern that has been observed in previous studies.",
          "authors": [
            "Hishan Farfán-Bachiloglu",
            "Francisco A. Calderón",
            "Darío G. Pérez"
          ],
          "primary_category": "physics.ao-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02820",
          "title": "Q-triplet characterization of atmospheric time series at Antofagasta: A missing values problem",
          "abstract": "Located in northern Chile (23.7°S, 70.4°W), Antofagasta has an exceptionally arid and stable climate characterized by minimal precipitation and consistent weather patterns. Nevertheless, despite these climate conditions being meaningful for several research and practical applications, our understanding of weather dynamics remains limited. The available meteorological data from 1969 to 2016 is analogical, which presents a significant challenge to analyze because these records are riddled with missing values, some measurements were taken at irregular measuring intervals, making it an interesting puzzle to grasp the Antofagasta's climate scenario. To overcome this issue, we present a comprehensive statistical analysis of atmospheric temperature, pressure, and humidity time series. Our analytical approach involves the q-triplet calculation method, serving as a powerful tool to identify distinctive behavior within systems under non-equilibrium states. Our results suggest that, in general, the q-triplet values satisfy the condition $q_\\text{sens}<1<q_\\text{stat}<q_\\text{rel}$, a pattern that has been observed in previous studies.",
          "authors": [
            "Hishan Farfán-Bachiloglu",
            "Francisco A. Calderón",
            "Darío G. Pérez"
          ],
          "primary_category": "physics.ao-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02823",
          "title": "Tempering the Bayes Filter towards Improved Model-Based Estimation",
          "abstract": "Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.",
          "authors": [
            "Menno van Zutphen",
            "Domagoj Herceg",
            "Giannis Delimpaltadakis",
            "Duarte J. Antunes"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02823",
          "title": "Tempering the Bayes Filter towards Improved Model-Based Estimation",
          "abstract": "Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.",
          "authors": [
            "Menno van Zutphen",
            "Domagoj Herceg",
            "Giannis Delimpaltadakis",
            "Duarte J. Antunes"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02823",
          "title": "Tempering the Bayes Filter towards Improved Model-Based Estimation",
          "abstract": "Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.",
          "authors": [
            "Menno van Zutphen",
            "Domagoj Herceg",
            "Giannis Delimpaltadakis",
            "Duarte J. Antunes"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02823",
          "title": "Tempering the Bayes Filter towards Improved Model-Based Estimation",
          "abstract": "Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.",
          "authors": [
            "Menno van Zutphen",
            "Domagoj Herceg",
            "Giannis Delimpaltadakis",
            "Duarte J. Antunes"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02824",
          "title": "Learning Science and the Illusion of Understanding: Exploring the Effects of Integrating Learning Tasks after Explainer Videos",
          "abstract": "Explainer videos are increasingly used to support science learning. While prior research has demonstrated their potential, studies have also identified limitations - particularly their tendency to foster an illusion of understanding, where learners overestimate their grasp of a topic despite gaps in their actual knowledge. Pairing explainer videos with cognitively engaging elements may help mitigate this effect. This paper reports two experimental studies examining the immediate and long-term effects of learning tasks following a physics explainer video on learners' illusion of understanding. Study 1 (N = 244 learners) compared high-level learning tasks with watching the video alone. Study 2 (N = 175) compared high-level and low-level tasks. Results show that high-level learning tasks significantly reduce the illusion of understanding immediately after the intervention compared to watching the video alone (t(88) = 6.50, p < .001, d = 0.69). Over the long term, both high-and low-level tasks are similarly effective. Learners with lower prior content knowledge are more susceptible to an illusion of understanding. We conclude that explainer videos should not be used in isolation in science classrooms. To prevent misjudged understanding - particularly among students with limited prior knowledge - they should be combined with cognitively demanding follow-up activities.",
          "authors": [
            "Madeleine Hörnlein",
            "Christoph Kulgemeyer"
          ],
          "primary_category": "physics.ed-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02826",
          "title": "From Navigation to Refinement: Revealing the Two-Stage Nature of Flow-based Diffusion Models through Oracle Velocity",
          "abstract": "Flow-based diffusion models have emerged as a leading paradigm for training generative models across images and videos. However, their memorization-generalization behavior remains poorly understood. In this work, we revisit the flow matching (FM) objective and study its marginal velocity field, which admits a closed-form expression, allowing exact computation of the oracle FM target. Analyzing this oracle velocity field reveals that flow-based diffusion models inherently formulate a two-stage training target: an early stage guided by a mixture of data modes, and a later stage dominated by the nearest data sample. The two-stage objective leads to distinct learning behaviors: the early navigation stage generalizes across data modes to form global layouts, whereas the later refinement stage increasingly memorizes fine-grained details. Leveraging these insights, we explain the effectiveness of practical techniques such as timestep-shifted schedules, classifier-free guidance intervals, and latent space design choices. Our study deepens the understanding of diffusion model training dynamics and offers principles for guiding future architectural and algorithmic improvements.",
          "authors": [
            "Haoming Liu",
            "Jinnuo Liu",
            "Yanhao Li",
            "Liuyang Bai",
            "Yunkai Ji",
            "Yuanhe Guo",
            "Shenji Wan",
            "Hongyi Wen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02830",
          "title": "Defense That Attacks: How Robust Models Become Better Attackers",
          "abstract": "Deep learning has achieved great success in computer vision, but remains vulnerable to adversarial attacks. Adversarial training is the leading defense designed to improve model robustness. However, its effect on the transferability of attacks is underexplored. In this work, we ask whether adversarial training unintentionally increases the transferability of adversarial examples. To answer this, we trained a diverse zoo of 36 models, including CNNs and ViTs, and conducted comprehensive transferability experiments. Our results reveal a clear paradox: adversarially trained (AT) models produce perturbations that transfer more effectively than those from standard models, which introduce a new ecosystem risk. To enable reproducibility and further study, we release all models, code, and experimental scripts. Furthermore, we argue that robustness evaluations should assess not only the resistance of a model to transferred attacks but also its propensity to produce transferable adversarial examples.",
          "authors": [
            "Mohamed Awad",
            "Mahmoud Akrm",
            "Walid Gomaa"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02831",
          "title": "Revisiting Theory of Contrastive Learning for Domain Generalization",
          "abstract": "Contrastive learning is among the most popular and powerful approaches for self-supervised representation learning, where the goal is to map semantically similar samples close together while separating dissimilar ones in the latent space. Existing theoretical methods assume that downstream task classes are drawn from the same latent class distribution used during the pretraining phase. However, in real-world settings, downstream tasks may not only exhibit distributional shifts within the same label space but also introduce new or broader label spaces, leading to domain generalization challenges. In this work, we introduce novel generalization bounds that explicitly account for both types of mismatch: domain shift and domain generalization. Specifically, we analyze scenarios where downstream tasks either (i) draw classes from the same latent class space but with shifted distributions, or (ii) involve new label spaces beyond those seen during pretraining. Our analysis reveals how the performance of contrastively learned representations depends on the statistical discrepancy between pretraining and downstream distributions. This extended perspective allows us to derive provable guarantees on the performance of learned representations on average classification tasks involving class distributions outside the pretraining latent class set.",
          "authors": [
            "Ali Alvandi",
            "Mina Rezaei"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02831",
          "title": "Revisiting Theory of Contrastive Learning for Domain Generalization",
          "abstract": "Contrastive learning is among the most popular and powerful approaches for self-supervised representation learning, where the goal is to map semantically similar samples close together while separating dissimilar ones in the latent space. Existing theoretical methods assume that downstream task classes are drawn from the same latent class distribution used during the pretraining phase. However, in real-world settings, downstream tasks may not only exhibit distributional shifts within the same label space but also introduce new or broader label spaces, leading to domain generalization challenges. In this work, we introduce novel generalization bounds that explicitly account for both types of mismatch: domain shift and domain generalization. Specifically, we analyze scenarios where downstream tasks either (i) draw classes from the same latent class space but with shifted distributions, or (ii) involve new label spaces beyond those seen during pretraining. Our analysis reveals how the performance of contrastively learned representations depends on the statistical discrepancy between pretraining and downstream distributions. This extended perspective allows us to derive provable guarantees on the performance of learned representations on average classification tasks involving class distributions outside the pretraining latent class set.",
          "authors": [
            "Ali Alvandi",
            "Mina Rezaei"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02831",
          "title": "Revisiting Theory of Contrastive Learning for Domain Generalization",
          "abstract": "Contrastive learning is among the most popular and powerful approaches for self-supervised representation learning, where the goal is to map semantically similar samples close together while separating dissimilar ones in the latent space. Existing theoretical methods assume that downstream task classes are drawn from the same latent class distribution used during the pretraining phase. However, in real-world settings, downstream tasks may not only exhibit distributional shifts within the same label space but also introduce new or broader label spaces, leading to domain generalization challenges. In this work, we introduce novel generalization bounds that explicitly account for both types of mismatch: domain shift and domain generalization. Specifically, we analyze scenarios where downstream tasks either (i) draw classes from the same latent class space but with shifted distributions, or (ii) involve new label spaces beyond those seen during pretraining. Our analysis reveals how the performance of contrastively learned representations depends on the statistical discrepancy between pretraining and downstream distributions. This extended perspective allows us to derive provable guarantees on the performance of learned representations on average classification tasks involving class distributions outside the pretraining latent class set.",
          "authors": [
            "Ali Alvandi",
            "Mina Rezaei"
          ],
          "primary_category": "stat.ML",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02832",
          "title": "Analysis of hypothesis tests for multiple uncertain finite populations with applications to normal uncertainty distributions",
          "abstract": "Hypothesis test plays a key role in uncertain statistics based on uncertain measure. This paper extends the parametric hypothesis of a single uncertain population to multiple cases, thereby addressing a broader range of scenarios. First, an uncertain family-wise error rate is defined to control the overall error in simultaneous testing. Subsequently, a hypothesis test of two uncertain populations is proposed, and the rejection region for the null hypothesis at a significance level is derived, laying the foundation for further analysis. Building on this, a homogeneity test for multiple populations is developed to assess whether the unknown population parameters differ significantly. When there is no significant difference in these parameters among finite populations or within a subset, a common test is used to determine whether they equal a fixed constant. Finally, homogeneity and common tests for normal uncertain populations with means and standard deviations are conducted under three cases: only means, only standard deviations, or both are unknown. Numerical simulations demonstrate the feasibility and accuracy of the proposed methods, and a real example is provided to illustrate their effectiveness.",
          "authors": [
            "Fan Zhang",
            "Zhiming Li"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02833",
          "title": "A Comparative Study on How Data Normalization Affects Zero-Shot Generalization in Time Series Foundation Models",
          "abstract": "We investigate input normalization methods for Time-Series Foundation Models (TSFMs). While normalization is well-studied in dataset-specific time-series models, it remains overlooked in TSFMs where generalization is critical. Time-series data, unlike text or images, exhibits significant scale variation across domains and channels, coupled with non-stationarity, can undermine TSFM performance regardless of architectural complexity. Through systematic evaluation across four architecturally diverse TSFMs, we empirically establish REVIN as the most efficient approach, reducing zero-shot MASE by 89\\% relative to an un-normalized baseline and by 44\\% versus other normalization methods, while matching the best in-domain accuracy (0.84 MASE) without any dataset-level preprocessing -- yielding the highest accuracy-efficiency trade-off. Yet its effect utilization depends on architectural design choices and optimization objective, particularly with respect to training loss scale sensitivity and model type (probabilistic, point-forecast, or LLM-based models).",
          "authors": [
            "Ihab Ahmed",
            "Denis Krompaß",
            "Cheng Feng",
            "Volker Tresp"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02834",
          "title": "Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach",
          "abstract": "Vision-Language-Action (VLA) models, trained via flow-matching or diffusion objectives, excel at learning complex behaviors from large-scale, multi-modal datasets (e.g., human teleoperation, scripted policies). However, since VLAs incorporate diverse data modes in the pre-training stage, and the finetuning dataset often contains demonstration data collected in a kinematically suboptimal or undesirable way, it exists redundant action modes that are irrelevant to the success action modes of the downstream task. Specifically, we observe a critical inference-time fragility among various sampled noises after supervised finetuning of pre-trained VLAs. In this paper, we attribute this instability to the distribution shift between the VLA policy and the policy induced by stable success modes of the downstream task dataset. Thus, we propose \\textbf{TACO}, a test-time-scaling (TTS) framework that applies a lightweight pseudo-count estimator as a high-fidelity verifier of action chunks. The VLA models integrated with TACO can execute the actions with maximum pseudo-count from all sampled action chunks, thereby preventing distribution shifts while preserving the generalization ability of VLAs since the constraint is applied only during inference. Our method resembles the classical anti-exploration principle in offline reinforcement learning (RL), and being gradient-free, it incurs significant computational benefits compared to RL update, especially for flow or diffusion-based VLAs which are difficult to perform RL update due to denoising process. Extensive experiments across four simulation benchmarks (RoboTwin2.0, Robotwin, LIBERO, SimplerEnv) and a dual-arm platform demonstrate that our method significantly improves the inference stability and success rates in downstream-task adaptations.",
          "authors": [
            "Siyuan Yang",
            "Yang Zhang",
            "Haoran He",
            "Ling Pan",
            "Xiu Li",
            "Chenjia Bai",
            "Xuelong Li"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02835",
          "title": "ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning",
          "abstract": "Reasoning-centric video object segmentation is an inherently complex task: the query often refers to dynamics, causality, and temporal interactions, rather than static appearances. Yet existing solutions generally collapse these factors into simplified reasoning with latent embeddings, rendering the reasoning chain opaque and essentially intractable. We therefore adopt an explicit decomposition perspective and introduce ReVSeg, which executes reasoning as sequential decisions in the native interface of pretrained vision language models (VLMs). Rather than folding all reasoning into a single-step prediction, ReVSeg executes three explicit operations -- semantics interpretation, temporal evidence selection, and spatial grounding -- aligning pretrained capabilities. We further employ reinforcement learning to optimize the multi-step reasoning chain, enabling the model to self-refine its decision quality from outcome-driven signals. Experimental results demonstrate that ReVSeg attains state-of-the-art performances on standard video object segmentation benchmarks and yields interpretable reasoning trajectories. Project page is available at this https URL .",
          "authors": [
            "Yifan Li",
            "Yingda Yin",
            "Lingting Zhu",
            "Weikai Chen",
            "Shengju Qian",
            "Xin Wang",
            "Yanwei Fu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02840",
          "title": "promptolution: A Unified, Modular Framework for Prompt Optimization",
          "abstract": "Prompt optimization has become crucial for enhancing the performance of large language models (LLMs) across a broad range of tasks. Although many research papers show its effectiveness, practical adoption is hindered as existing implementations are often tied to unmaintained and isolated research codebases. To address this, we introduce promptolution, a unified and modular open-source framework that provides all components required for prompt optimization within a single extensible system for both practitioners and researchers. It integrates multiple contemporary discrete prompt optimizers while remaining agnostic to the underlying LLM implementation.",
          "authors": [
            "Tom Zehle",
            "Timo Heiß",
            "Moritz Schlager",
            "Matthias Aßenmacher",
            "Matthias Feurer"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02841",
          "title": "Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages",
          "abstract": "System prompts provide a lightweight yet powerful mechanism for conditioning large language models (LLMs) at inference time. While prior work has focused on English-only settings, real-world deployments benefit from having a single prompt to operate reliably across languages. This paper presents a comprehensive study of how different system prompts steer models toward accurate and robust cross-lingual behavior. We propose a unified four-dimensional evaluation framework to assess system prompts in multilingual environments. Through large-scale experiments on five languages, three LLMs, and three benchmarks, we uncover that certain prompt components, such as CoT, emotion, and scenario, correlate with robust multilingual behavior. We develop a prompt optimization framework for multilingual settings and show it can automatically discover prompts that improve all metrics by 5-10%. Finally, we analyze over 10 million reasoning units and find that more performant system prompts induce more structured and consistent reasoning patterns, while reducing unnecessary language-switching. Together, we highlight system prompt optimization as a scalable path to accurate and robust multilingual LLM behavior.",
          "authors": [
            "Lechen Zhang",
            "Yusheng Zhou",
            "Tolga Ergen",
            "Lajanugen Logeswaran",
            "Moontae Lee",
            "David Jurgens"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02842",
          "title": "A Critical Analysis of Affirmative Action and Academic Performance: A Response to the Preprint Authored by Matheus et al. (2025)",
          "abstract": "This article offers a critical response to the preprint by Matheus et al. (2025), which evaluates the academic performance of students admitted through different entry routes at Sao Paulo State University. Although the dataset compiled by the authors is valuable, their analysis contains conceptual, methodological, and historical limitations that undermine the validity of their conclusions. We argue that the preprint misinterprets the purpose of Brazil's affirmative action policy, which is intended to ensure equitable access rather than equalize academic performance at the point of university entry. Early performance differences among universal system, public school, and racial-quota students reflect longstanding inequalities in Brazil's basic education system. Furthermore, the preprint generalizes findings basically from only three undergraduate programs (Physics, Biology, and Pedagogy) to represent entire academic domains (STEM, Biological Sciences, and Humanities), an extrapolation that reduces the reliability of its conclusions. Overall, we contend that early performance differences indicate structural educational inequality, not policy failure. Affirmative action fulfills its mandate by guaranteeing access, while universities bear the responsibility for providing equitable conditions for academic progression.",
          "authors": [
            "Claudio Andre Barbosa de Lira",
            "Ricardo Borges Viana"
          ],
          "primary_category": "physics.ed-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02844",
          "title": "VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion",
          "abstract": "The safe deployment of autonomous driving systems (ADSs) relies on comprehensive testing and evaluation. However, safety-critical scenarios that can effectively expose system vulnerabilities are extremely sparse in the real world. Existing scenario generation methods face challenges in efficiently constructing long-tail scenarios that ensure fidelity, criticality, and interactivity, while particularly lacking real-time dynamic response capabilities to the vehicle under test (VUT). To address these challenges, this paper proposes a safety-critical testing scenario generation framework that integrates the high-level semantic understanding capabilities of Vision Language Models (VLMs) with the fine-grained generation capabilities of adaptive guided diffusion models. The framework establishes a three-layer hierarchical architecture comprising a strategic layer for VLM-directed scenario generation objective determination, a tactical layer for guidance function formulation, and an operational layer for guided diffusion execution. We first establish a high-quality fundamental diffusion model that learns the data distribution of real driving scenarios. Next, we design an adaptive guided diffusion method that enables real-time, precise control of background vehicles (BVs) in closed-loop simulation. The VLM is then incorporated to autonomously generate scenario generation objectives and guidance functions through deep scenario understanding and risk reasoning, ultimately guiding the diffusion model to achieve VLM-directed scenario generation. Experimental results demonstrate that the proposed method can efficiently generate realistic, diverse, and highly interactive safety-critical testing scenarios. Furthermore, case studies validate the adaptability and VLM-directed generation performance of the proposed method.",
          "authors": [
            "Xinzheng Wu",
            "Junyi Chen",
            "Naiting Zhong",
            "Yong Shen"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02845",
          "title": "Bangla Hate Speech Classification with Fine-tuned Transformer Models",
          "abstract": "Hate speech recognition in low-resource lan- guages remains a difficult problem due to in- sufficient datasets, orthographic heterogeneity, and linguistic variety. Bangla is spoken by more than 230 million people of Bangladesh and India (West Bengal). Despite the grow- ing need for automated moderation on social media platforms, Bangla is significantly under- represented in computational resources. In this work, we study Subtask 1A and Subtask 1B of the BLP 2025 Shared Task on hate speech detection. We reproduce the official base- lines (e.g., Majority, Random, Support Vec- tor Machine) and also produce and consider Logistic Regression, Random Forest, and De- cision Tree as baseline methods. We also uti- lized transformer-based models such as Dis- tilBERT, BanglaBERT, m-BERT, and XLM- RoBERTa for hate speech classification. All the transformer-based models outperformed base- line methods for the subtasks, except for Distil- BERT. Among the transformer-based models, BanglaBERT produces the best performance for both subtasks. Despite being smaller in size, BanglaBERT outperforms both m-BERT and XLM-RoBERTa, which suggests language- specific pre-training is very important. Our results highlight the potential and need for pre- trained language models for the low-resource Bangla language.",
          "authors": [
            "Yalda Keivan Jafari",
            "Krishno Dey"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02846",
          "title": "Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?",
          "abstract": "Anticipating actions before they occur is a core challenge in action understanding research. While conventional methods rely on extracting and aggregating temporal information from videos, as humans we can often predict upcoming actions by observing a single moment from a scene, when given sufficient context. Can a model achieve this competence? The short answer is yes, although its effectiveness depends on the complexity of the task. In this work, we investigate to what extent video aggregation can be replaced with alternative modalities. To this end, based on recent advances in visual feature extraction and language-based reasoning, we introduce AAG, a method for Action Anticipation at a Glimpse. AAG combines RGB features with depth cues from a single frame for enhanced spatial reasoning, and incorporates prior action information to provide long-term context. This context is obtained either through textual summaries from Vision-Language Models, or from predictions generated by a single-frame action recognizer. Our results demonstrate that multimodal single-frame action anticipation using AAG can perform competitively compared to both temporally aggregated video baselines and state-of-the-art methods across three instructional activity datasets: IKEA-ASM, Meccano, and Assembly101.",
          "authors": [
            "Manuel Benavent-Lledo",
            "Konstantinos Bacharidis",
            "Victoria Manousaki",
            "Konstantinos Papoutsakis",
            "Antonis Argyros",
            "Jose Garcia-Rodriguez"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02848",
          "title": "Humans incorrectly reject confident accusatory AI judgments",
          "abstract": "Automated verbal deception detection using methods from Artificial Intelligence (AI) has been shown to outperform humans in disentangling lies from truths. Research suggests that transparency and interpretability of computational methods tend to increase human acceptance of using AI to support decisions. However, the extent to which humans accept AI judgments for deception detection remains unclear. We experimentally examined how an AI model's accuracy (i.e., its overall performance in deception detection) and confidence (i.e., the model's uncertainty in single-statements predictions) influence human adoption of the model's judgments. Participants (n=373) were presented with veracity judgments of an AI model with high or low overall accuracy and various degrees of prediction confidence. The results showed that humans followed predictions from a highly accurate model more than from a less accurate one. Interestingly, the more confident the model, the more people deviated from it, especially if the model predicted deception. We also found that human interaction with algorithmic predictions either worsened the machine's performance or was ineffective. While this human aversion to accept highly confident algorithmic predictions was partly explained by participants' tendency to overestimate humans' deception detection abilities, we also discuss how truth-default theory and the social costs of accusing someone of lying help explain the findings.",
          "authors": [
            "Riccardo Loconte",
            "Merylin Monaro",
            "Pietro Pietrini",
            "Bruno Verschuere",
            "Bennett Kleinberg"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02849",
          "title": "GraphMatch: Fusing Language and Graph Representations in a Dynamic Two-Sided Work Marketplace",
          "abstract": "Recommending matches in a text-rich, dynamic two-sided marketplace presents unique challenges due to evolving content and interaction graphs. We introduce GraphMatch, a new large-scale recommendation framework that fuses pre-trained language models with graph neural networks to overcome these challenges. Unlike prior approaches centered on standalone models, GraphMatch is a comprehensive recipe built on powerful text encoders and GNNs working in tandem. It employs adversarial negative sampling alongside point-in-time subgraph training to learn representations that capture both the fine-grained semantics of evolving text and the time-sensitive structure of the graph. We evaluated extensively on interaction data from Upwork, a leading labor marketplace, at large scale, and discuss our approach towards low-latency inference suitable for real-time use. In our experiments, GraphMatch outperforms language-only and graph-only baselines on matching tasks while being efficient at runtime. These results demonstrate that unifying language and graph representations yields a highly effective solution to text-rich, dynamic two-sided recommendations, bridging the gap between powerful pretrained LMs and large-scale graphs in practice.",
          "authors": [
            "Mikołaj Sacha",
            "Hammad Jafri",
            "Mattie Terzolo",
            "Ayan Sinha",
            "Andrew Rabinovich"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02850",
          "title": "Are Detectors Fair to Indian IP-AIGC? A Cross-Generator Study",
          "abstract": "Modern image editors can produce identity-preserving AIGC (IP-AIGC), where the same person appears with new attire, background, or lighting. The robustness and fairness of current detectors in this regime remain unclear, especially for under-represented populations. We present what we believe is the first systematic study of IP-AIGC detection for Indian and South-Asian faces, quantifying cross-generator generalization and intra-population performance. We assemble Indian-focused training splits from FairFD and HAV-DF, and construct two held-out IP-AIGC test sets (HIDF-img-ip-genai and HIDF-vid-ip-genai) using commercial web-UI generators (Gemini and ChatGPT) with identity-preserving prompts. We evaluate two state-of-the-art detectors (AIDE and Effort) under pretrained (PT) and fine-tuned (FT) regimes and report AUC, AP, EER, and accuracy. Fine-tuning yields strong in-domain gains (for example, Effort AUC 0.739 to 0.944 on HAV-DF-test; AIDE EER 0.484 to 0.259), but consistently degrades performance on held-out IP-AIGC for Indian cohorts (for example, AIDE AUC 0.923 to 0.563 on HIDF-img-ip-genai; Effort 0.740 to 0.533), which indicates overfitting to training-generator cues. On non-IP HIDF images, PT performance remains high, which suggests a specific brittleness to identity-preserving edits rather than a generic distribution shift. Our study establishes IP-AIGC-Indian as a challenging and practically relevant scenario and motivates representation-preserving adaptation and India-aware benchmark curation to close generalization gaps in AIGC detection.",
          "authors": [
            "Vishal Dubey",
            "Pallavi Tyagi"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02851",
          "title": "SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots",
          "abstract": "Visual traversability estimation is critical for autonomous navigation, but existing VLM-based methods rely on hand-crafted prompts, generalize poorly across embodiments, and output only traversability maps, leaving trajectory generation to slow external planners. We propose SwarmDiffusion, a lightweight end-to-end diffusion model that jointly predicts traversability and generates a feasible trajectory from a single RGB image. To remove the need for annotated or planner-produced paths, we introduce a planner-free trajectory construction pipeline based on randomized waypoint sampling, Bezier smoothing, and regularization enforcing connectivity, safety, directionality, and path thinness. This enables learning stable motion priors without demonstrations. SwarmDiffusion leverages VLM-derived supervision without prompt engineering and conditions the diffusion process on a compact embodiment state, producing physically consistent, traversable paths that transfer across different robot platforms. Across indoor environments and two embodiments (quadruped and aerial), the method achieves 80-100\\% navigation success and 0.09 s inference, and adapts to a new robot using only-500 additional visual samples. It generalizes reliably to unseen environments in simulation and real-world trials, offering a scalable, prompt-free approach to unified traversability reasoning and trajectory generation.",
          "authors": [
            "Iana Zhura",
            "Sausar Karaf",
            "Faryal Batool",
            "Nipun Dhananjaya Weerakkodi Mudalige",
            "Valerii Serpiva",
            "Ali Alridha Abdulkarim",
            "Aleksey Fedoseev",
            "Didar Seyidov",
            "Amjad Hajira",
            "Dzmitry Tsetserukou"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02852",
          "title": "Adaptive Decentralized Federated Learning for Robust Optimization",
          "abstract": "In decentralized federated learning (DFL), the presence of abnormal clients, often caused by noisy or poisoned data, can significantly disrupt the learning process and degrade the overall robustness of the model. Previous methods on this issue often require a sufficiently large number of normal neighboring clients or prior knowledge of reliable clients, which reduces the practical applicability of DFL. To address these limitations, we develop here a novel adaptive DFL (aDFL) approach for robust estimation. The key idea is to adaptively adjust the learning rates of clients. By assigning smaller rates to suspicious clients and larger rates to normal clients, aDFL mitigates the negative impact of abnormal clients on the global model in a fully adaptive way. Our theory does not put any stringent conditions on neighboring nodes and requires no prior knowledge. A rigorous convergence analysis is provided to guarantee the oracle property of aDFL. Extensive numerical experiments demonstrate the superior performance of the aDFL method.",
          "authors": [
            "Shuyuan Wu",
            "Feifei Wang",
            "Yuan Gao",
            "Hansheng Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02852",
          "title": "Adaptive Decentralized Federated Learning for Robust Optimization",
          "abstract": "In decentralized federated learning (DFL), the presence of abnormal clients, often caused by noisy or poisoned data, can significantly disrupt the learning process and degrade the overall robustness of the model. Previous methods on this issue often require a sufficiently large number of normal neighboring clients or prior knowledge of reliable clients, which reduces the practical applicability of DFL. To address these limitations, we develop here a novel adaptive DFL (aDFL) approach for robust estimation. The key idea is to adaptively adjust the learning rates of clients. By assigning smaller rates to suspicious clients and larger rates to normal clients, aDFL mitigates the negative impact of abnormal clients on the global model in a fully adaptive way. Our theory does not put any stringent conditions on neighboring nodes and requires no prior knowledge. A rigorous convergence analysis is provided to guarantee the oracle property of aDFL. Extensive numerical experiments demonstrate the superior performance of the aDFL method.",
          "authors": [
            "Shuyuan Wu",
            "Feifei Wang",
            "Yuan Gao",
            "Hansheng Wang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02860",
          "title": "RFOP: Rethinking Fusion and Orthogonal Projection for Face-Voice Association",
          "abstract": "Face-voice association in multilingual environment challenge 2026 aims to investigate the face-voice association task in multilingual scenario. The challenge introduces English-German face-voice pairs to be utilized in the evaluation phase. To this end, we revisit the fusion and orthogonal projection for face-voice association by effectively focusing on the relevant semantic information within the two modalities. Our method performs favorably on the English-German data split and ranked 3rd in the FAME 2026 challenge by achieving the EER of 33.1.",
          "authors": [
            "Abdul Hannan",
            "Furqan Malik",
            "Hina Jabbar",
            "Syed Suleman Sadiq",
            "Mubashir Noman"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02861",
          "title": "Network Self-Configuration based on Fine-Tuned Small Language Models",
          "abstract": "As modern networks grow in scale and complexity, manual configuration becomes increasingly inefficient and prone to human error. While intent-driven self-configuration using large language models has shown significant promise, such models remain computationally expensive, resource-intensive, and often raise privacy concerns because they typically rely on external cloud infrastructure. This work introduces SLM_netconfig, a fine-tuned small language model framework that uses an agent-based architecture and parameter-efficient adaptation techniques to translate configuration intents expressed as natural language requirements or questions into syntactically and semantically valid network configurations. The system is trained on a domain-specific dataset generated through a pipeline derived from vendor documentation, ensuring strong alignment with real-world configuration practices. Extensive evaluation shows that SLM_netconfig, when using its question-to-configuration model, achieves higher syntactic accuracy and goal accuracy than LLM-NetCFG while substantially reducing translation latency and producing concise, interpretable configurations. These results demonstrate that fine-tuned small language models, as implemented in SLM_netconfig, can deliver efficient, accurate, and privacy-preserving automated configuration generation entirely on-premise, making them a practical and scalable solution for modern autonomous network configuration.",
          "authors": [
            "Oscar G. Lira",
            "Oscar M. Caicedo",
            "Nelson L. S. Da Fonseca"
          ],
          "primary_category": "cs.NI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02862",
          "title": "PystachIO: Efficient Distributed GPU Query Processing with PyTorch over Fast Networks & Fast Storage",
          "abstract": "The AI hardware boom has led modern data centers to adopt HPC-style architectures centered on distributed, GPU-centric computation. Large GPU clusters interconnected by fast RDMA networks and backed by high-bandwidth NVMe storage enable scalable computation and rapid access to storage-resident data. Tensor computation runtimes (TCRs), such as PyTorch, originally designed for AI workloads, have recently been shown to accelerate analytical workloads. However, prior work has primarily considered settings where the data fits in aggregated GPU memory. In this paper, we systematically study how TCRs can support scalable, distributed query processing for large-scale, storage-resident OLAP workloads. Although TCRs provide abstractions for network and storage I/O, naive use often underutilizes GPU and I/O bandwidth due to insufficient overlap between computation and data movement. As a core contribution, we present PystachIO, a PyTorch-based distributed OLAP engine that combines fast network and storage I/O with key optimizations to maximize GPU, network, and storage utilization. Our evaluation shows up to 3x end-to-end speedups over existing distributed GPU-based query processing approaches.",
          "authors": [
            "Jigao Luo",
            "Nils Boeschen",
            "Muhammad El-Hindi",
            "Carsten Binnig"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02863",
          "title": "Leveraging generative adversarial networks with spatially adaptive denormalization for multivariate stochastic seismic data inversion",
          "abstract": "Probabilistic seismic inverse modeling often requires the prediction of both spatially correlated geological heterogeneities (e.g., facies) and continuous parameters (e.g., rock and elastic properties). Generative adversarial networks (GANs) provide an efficient training-image-based simulation framework capable of reproducing complex geological models with high accuracy and comparably low generative cost. However, their application in stochastic geophysical inversion for multivariate property prediction is limited, as representing multiple coupled properties requires large and unstable networks with high memory and training demands. A more recent variant of GANs with spatially adaptive denormalization (SPADE-GAN) enables the direct conditioning of facies spatial distributions on local probability maps. Leveraging on such features, an iterative geostatistical inversion algorithm is proposed, SPADE-GANInv, integrating a pre-trained SPADE-GAN with geostatistical simulation, for the prediction of facies and multiple correlated continuous properties from seismic data. The SPADE-GAN is trained to reproduce realistic facies geometries, while sequential stochastic co-simulation predicts the spatial variability of the facies-dependent continuous properties. At each iteration, a set of subsurface realizations is generated and used to compute synthetic seismic data. The realizations providing the highest similarity coefficient to the observed data are used to update the subsurface probability models in the next iteration. The method is demonstrated on both 2-D synthetic scenarios and field data, targeting the prediction of facies, porosity, and acoustic impedance from full-stack seismic data. Results show that the algorithm enables accurate multivariate prediction, mitigates the impact of biased prior data, and accommodates additional local conditioning such as well logs.",
          "authors": [
            "Roberto Miele",
            "Leonardo Azevedo"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02863",
          "title": "Leveraging generative adversarial networks with spatially adaptive denormalization for multivariate stochastic seismic data inversion",
          "abstract": "Probabilistic seismic inverse modeling often requires the prediction of both spatially correlated geological heterogeneities (e.g., facies) and continuous parameters (e.g., rock and elastic properties). Generative adversarial networks (GANs) provide an efficient training-image-based simulation framework capable of reproducing complex geological models with high accuracy and comparably low generative cost. However, their application in stochastic geophysical inversion for multivariate property prediction is limited, as representing multiple coupled properties requires large and unstable networks with high memory and training demands. A more recent variant of GANs with spatially adaptive denormalization (SPADE-GAN) enables the direct conditioning of facies spatial distributions on local probability maps. Leveraging on such features, an iterative geostatistical inversion algorithm is proposed, SPADE-GANInv, integrating a pre-trained SPADE-GAN with geostatistical simulation, for the prediction of facies and multiple correlated continuous properties from seismic data. The SPADE-GAN is trained to reproduce realistic facies geometries, while sequential stochastic co-simulation predicts the spatial variability of the facies-dependent continuous properties. At each iteration, a set of subsurface realizations is generated and used to compute synthetic seismic data. The realizations providing the highest similarity coefficient to the observed data are used to update the subsurface probability models in the next iteration. The method is demonstrated on both 2-D synthetic scenarios and field data, targeting the prediction of facies, porosity, and acoustic impedance from full-stack seismic data. Results show that the algorithm enables accurate multivariate prediction, mitigates the impact of biased prior data, and accommodates additional local conditioning such as well logs.",
          "authors": [
            "Roberto Miele",
            "Leonardo Azevedo"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02863",
          "title": "Leveraging generative adversarial networks with spatially adaptive denormalization for multivariate stochastic seismic data inversion",
          "abstract": "Probabilistic seismic inverse modeling often requires the prediction of both spatially correlated geological heterogeneities (e.g., facies) and continuous parameters (e.g., rock and elastic properties). Generative adversarial networks (GANs) provide an efficient training-image-based simulation framework capable of reproducing complex geological models with high accuracy and comparably low generative cost. However, their application in stochastic geophysical inversion for multivariate property prediction is limited, as representing multiple coupled properties requires large and unstable networks with high memory and training demands. A more recent variant of GANs with spatially adaptive denormalization (SPADE-GAN) enables the direct conditioning of facies spatial distributions on local probability maps. Leveraging on such features, an iterative geostatistical inversion algorithm is proposed, SPADE-GANInv, integrating a pre-trained SPADE-GAN with geostatistical simulation, for the prediction of facies and multiple correlated continuous properties from seismic data. The SPADE-GAN is trained to reproduce realistic facies geometries, while sequential stochastic co-simulation predicts the spatial variability of the facies-dependent continuous properties. At each iteration, a set of subsurface realizations is generated and used to compute synthetic seismic data. The realizations providing the highest similarity coefficient to the observed data are used to update the subsurface probability models in the next iteration. The method is demonstrated on both 2-D synthetic scenarios and field data, targeting the prediction of facies, porosity, and acoustic impedance from full-stack seismic data. Results show that the algorithm enables accurate multivariate prediction, mitigates the impact of biased prior data, and accommodates additional local conditioning such as well logs.",
          "authors": [
            "Roberto Miele",
            "Leonardo Azevedo"
          ],
          "primary_category": "physics.geo-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02866",
          "title": "HeteroJIVE: Joint Subspace Estimation for Heterogeneous Multi-View Data",
          "abstract": "Many modern datasets consist of multiple related matrices measured on a common set of units, where the goal is to recover the shared low-dimensional subspace. While the Angle-based Joint and Individual Variation Explained (AJIVE) framework provides a solution, it relies on equal-weight aggregation, which can be strictly suboptimal when views exhibit significant statistical heterogeneity (arising from varying SNR and dimensions) and structural heterogeneity (arising from individual components). In this paper, we propose HeteroJIVE, a weighted two-stage spectral algorithm tailored to such heterogeneity. Theoretically, we first revisit the ``non-diminishing\" error barrier with respect to the number of views $K$ identified in recent literature for the equal-weight case. We demonstrate that this barrier is not universal: under generic geometric conditions, the bias term vanishes and our estimator achieves the $O(K^{-1/2})$ rate without the need for iterative refinement. Extending this to the general-weight case, we establish error bounds that explicitly disentangle the two layers of heterogeneity. Based on this, we derive an oracle-optimal weighting scheme implemented via a data-driven procedure. Extensive simulations corroborate our theoretical findings, and an application to TCGA-BRCA multi-omics data validates the superiority of HeteroJIVE in practice.",
          "authors": [
            "Jingyang Li",
            "Zhongyuan Lyu"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02866",
          "title": "HeteroJIVE: Joint Subspace Estimation for Heterogeneous Multi-View Data",
          "abstract": "Many modern datasets consist of multiple related matrices measured on a common set of units, where the goal is to recover the shared low-dimensional subspace. While the Angle-based Joint and Individual Variation Explained (AJIVE) framework provides a solution, it relies on equal-weight aggregation, which can be strictly suboptimal when views exhibit significant statistical heterogeneity (arising from varying SNR and dimensions) and structural heterogeneity (arising from individual components). In this paper, we propose HeteroJIVE, a weighted two-stage spectral algorithm tailored to such heterogeneity. Theoretically, we first revisit the ``non-diminishing\" error barrier with respect to the number of views $K$ identified in recent literature for the equal-weight case. We demonstrate that this barrier is not universal: under generic geometric conditions, the bias term vanishes and our estimator achieves the $O(K^{-1/2})$ rate without the need for iterative refinement. Extending this to the general-weight case, we establish error bounds that explicitly disentangle the two layers of heterogeneity. Based on this, we derive an oracle-optimal weighting scheme implemented via a data-driven procedure. Extensive simulations corroborate our theoretical findings, and an application to TCGA-BRCA multi-omics data validates the superiority of HeteroJIVE in practice.",
          "authors": [
            "Jingyang Li",
            "Zhongyuan Lyu"
          ],
          "primary_category": "math.ST",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02867",
          "title": "MICCAI STSR 2025 Challenge: Semi-Supervised Teeth and Pulp Segmentation and CBCT-IOS Registration",
          "abstract": "Cone-Beam Computed Tomography (CBCT) and Intraoral Scanning (IOS) are essential for digital dentistry, but annotated data scarcity limits automated solutions for pulp canal segmentation and cross-modal registration. To benchmark semi-supervised learning (SSL) in this domain, we organized the STSR 2025 Challenge at MICCAI 2025, featuring two tasks: (1) semi-supervised segmentation of teeth and pulp canals in CBCT, and (2) semi-supervised rigid registration of CBCT and IOS. We provided 60 labeled and 640 unlabeled IOS samples, plus 30 labeled and 250 unlabeled CBCT scans with varying resolutions and fields of view. The challenge attracted strong community participation, with top teams submitting open-source deep learning-based SSL solutions. For segmentation, leading methods used nnU-Net and Mamba-like State Space Models with pseudo-labeling and consistency regularization, achieving a Dice score of 0.967 and Instance Affinity of 0.738 on the hidden test set. For registration, effective approaches combined PointNetLK with differentiable SVD and geometric augmentation to handle modality gaps; hybrid neural-classical refinement enabled accurate alignment despite limited labels. All data and code are publicly available at this https URL to ensure reproducibility.",
          "authors": [
            "Yaqi Wang",
            "Zhi Li",
            "Chengyu Wu",
            "Jun Liu",
            "Yifan Zhang",
            "Jialuo Chen",
            "Jiaxue Ni",
            "Qian Luo",
            "Jin Liu",
            "Can Han",
            "Changkai Ji",
            "Zhi Qin Tan",
            "Ajo Babu George",
            "Liangyu Chen",
            "Qianni Zhang",
            "Dahong Qian",
            "Shuai Wang",
            "Huiyu Zhou"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02868",
          "title": "Assessing the performance of correlation-based multi-fidelity neural emulators",
          "abstract": "Outer loop tasks such as optimization, uncertainty quantification or inference can easily become intractable when the underlying high-fidelity model is computationally expensive. Similarly, data-driven architectures typically require large datasets to perform predictive tasks with sufficient accuracy. A possible approach to mitigate these challenges is the development of multi-fidelity emulators, leveraging potentially biased, inexpensive low-fidelity information while correcting and refining predictions using scarce, accurate high-fidelity data. This study investigates the performance of multi-fidelity neural emulators, neural networks designed to learn the input-to-output mapping by integrating limited high-fidelity data with abundant low-fidelity model solutions. We investigate the performance of such emulators for low and high-dimensional functions, with oscillatory character, in the presence of discontinuities, for collections of models with equal and dissimilar parametrization, and for a possibly large number of potentially corrupted low-fidelity sources. In doing so, we consider a large number of architectural, hyperparameter, and dataset configurations including networks with a different amount of spectral bias (Multi-Layered Perceptron, Siren and Kolmogorov Arnold Network), various mechanisms for coordinate encoding, exact or learnable low-fidelity information, and for varying training dataset size. We further analyze the added value of the multi-fidelity approach by conducting equivalent single-fidelity tests for each case, quantifying the performance gains achieved through fusing multiple sources of information.",
          "authors": [
            "Cristian J. Villatoro",
            "Gianluca Geraci",
            "Daniele E. Schiavazzi"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02870",
          "title": "Taming Camera-Controlled Video Generation with Verifiable Geometry Reward",
          "abstract": "Recent advances in video diffusion models have remarkably improved camera-controlled video generation, but most methods rely solely on supervised fine-tuning (SFT), leaving online reinforcement learning (RL) post-training largely underexplored. In this work, we introduce an online RL post-training framework that optimizes a pretrained video generator for precise camera control. To make RL effective in this setting, we design a verifiable geometry reward that delivers dense segment-level feedback to guide model optimization. Specifically, we estimate the 3D camera trajectories for both generated and reference videos, divide each trajectory into short segments, and compute segment-wise relative poses. The reward function then compares each generated-reference segment pair and assigns an alignment score as the reward signal, which helps alleviate reward sparsity and improve optimization efficiency. Moreover, we construct a comprehensive dataset featuring diverse large-amplitude camera motions and scenes with varied subject dynamics. Extensive experiments show that our online RL post-training clearly outperforms SFT baselines across multiple aspects, including camera-control accuracy, geometric consistency, and visual quality, demonstrating its superiority in advancing camera-controlled video generation.",
          "authors": [
            "Zhaoqing Wang",
            "Xiaobo Xia",
            "Zhuolin Bie",
            "Jinlin Liu",
            "Dongdong Yu",
            "Jia-Wang Bian",
            "Changhu Wang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02874",
          "title": "Think in Parallel, Answer as One: Logit Averaging for Open-Ended Reasoning",
          "abstract": "Majority voting has proven effective for close-ended question answering by aggregating parallel reasoning traces. However, it is not directly applicable to open-ended reasoning, such as code generation and web-based deep research, where a \"majority\" over complete solutions is ill-defined. We introduce ThinkMerge, a training-free, plug-and-play decoding strategy that runs K parallel reasoning traces and averages their next-token logits at synchronization points to produce a single coherent output. ThinkMerge integrates seamlessly with vLLM/SGLang and remains compatible with standard decoding techniques such as Top-p/Top-k. Empirically, it matches or surpasses majority voting on AIME and GPQA, while delivering consistent gains on open-ended coding tasks: on LiveCodeBench (hard), pass@1 improves by +8.28% for DeepCoder-14B-Preview and +7.58% for Qwen3-8B. Beyond code, we further show that ThinkMerge improves web-based deep-research agents (e.g., WebSailor-7B/32B) across GAIA, BrowseComp-en/zh, and XbenchDeepSearch. These results demonstrate that parallel test-time scaling can benefit open-ended reasoning without relying on voting over complete outputs.",
          "authors": [
            "Haonan Wang",
            "Chao Du",
            "Kenji Kawaguchi",
            "Tianyu Pang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02878",
          "title": "Correcting for sampling variability in maximum likelihood-based one-sample log-rank tests",
          "abstract": "Single-arm studies in the early development phases of new treatments are not uncommon in the context of rare diseases or in paediatrics. If an assessment of efficacy is to be made at the end of such a study, the observed endpoints can be compared with reference values that can be derived from historical data. For a time-to-event endpoint, a statistical comparison with a reference curve can be made using the one-sample log-rank test. In order to ensure the interpretability of the results of this test, the role of the reference curve is crucial. This quantity is often estimated from a historical control group using a parametric procedure. Hence, it should be noted that it is subject to estimation uncertainty. However, this aspect is not taken into account in the one-sample log-rank test statistic. We analyse this estimation uncertainty for the common situation that the reference curve is estimated parametrically using the maximum likelihood method, and indicate how the variance estimation of the one-sample log-rank test can be adapted in order to take this variability into account. The resulting test procedures are illustrated using a data example and analysed in more detail using simulations.",
          "authors": [
            "Moritz Fabian Danzer",
            "Rene Schmidt"
          ],
          "primary_category": "stat.ME",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02882",
          "title": "OptPO: Optimal Rollout Allocation for Test-time Policy Optimization",
          "abstract": "Test-time policy optimization enables large language models (LLMs) to adapt to distribution shifts by leveraging feedback from self-generated rollouts. However, existing methods rely on fixed-budget majority voting to estimate rewards, incurring substantial computational redundancy. We propose Optimal Rollout Allocation for Test-time Policy Optimization (OptPO), a principled framework that adaptively allocates inference budgets. By formulating the voting process as a Bayesian sequential probability ratio test, OptPO dynamically halts sampling once the posterior confidence in a consensus answer exceeds a specified threshold. Crucially, it utilizes the retained rollouts for on-policy updates, seamlessly integrating with algorithms like PPO or GRPO without requiring ground-truth labels. Across diverse reasoning benchmarks, OptPO significantly reduces rollout overhead compared to fixed-sample baselines while preserving or improving accuracy. By unifying statistically optimal stopping with test-time learning, OptPO offers a computationally efficient paradigm for test-time adaptation. The source code will be open upon acceptance at https://open-upon-acceptance.",
          "authors": [
            "Youkang Wang",
            "Jian Wang",
            "Rubing Chen",
            "Tianyi Zeng",
            "Xiao-Yong Wei",
            "Qing Li"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02891",
          "title": "Perceptual evaluation of Acoustic Level of Detail in Virtual Acoustic Environments",
          "abstract": "Virtual acoustic environments enable the creation and simulation of realistic and eco-logically valid daily-life situations vital for hearing research and audiology. Reverberant indoor environments are particularly important. For real-time applications, room acous-tics simulation requires simplifications, however, the necessary acoustic level of detail (ALOD) remains unclear in order to capture all perceptually relevant effects. This study examines the impact of varying ALOD in simulations of three real environments: a living room with a coupled kitchen, a pub, and an underground station. ALOD was varied by generating different numbers of image sources for early reflections, or by excluding geo-metrical room details specific for each environment. Simulations were perceptually eval-uated using headphones in comparison to binaural room impulse responses measured with a dummy head in the corresponding real environments, or by using loudspeakers. The study assessed the perceived overall difference for a pulse stimulus, a played electric bass and a speech token. Additionally, plausibility, speech intelligibility, and externaliza-tion were evaluated. Results indicate that a strong reduction in ALOD is feasible while maintaining similar plausibility, speech intelligibility, and externalization as with dummy head recordings. The number and accuracy of early reflections appear less relevant, pro-vided diffuse late reverberation is appropriately represented.",
          "authors": [
            "Stefan Fichna",
            "Steven van de Par",
            "Bernhard U. Seeber",
            "Stephan D. Ewert"
          ],
          "primary_category": "eess.AS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02892",
          "title": "Fast-Decoding Diffusion Language Models via Progress-Aware Confidence Schedules",
          "abstract": "Diffusion large language models (dLLMs) offer a promising alternative to autoregressive models, but their practical utility is severely hampered by slow, iterative sampling. We present SchED, a training-free, model-agnostic early-exit algorithm that aggregates full-span logit margins and halts decoding once a smooth, progress-dependent confidence threshold is met. We evaluated SchED on two dLLM families (Dream and LLaDA), in base and instruction-tuned variants across ten benchmarks spanning downstream tasks including multiple-choice question answering (MCQ), math, long-form QA/summarization, and translation. SchED delivers large, stable accelerations: on instruction-tuned models, it achieves $3.8$-$4.0\\times$ speedups while retaining $99.8$-$100\\%$ of the baseline score on average. On base models, SchED yields consistent speedup gains with $99.1$-$100\\%$ performance retention, with up to $2.34\\times$ under more aggressive settings. Using a conservative speed metric that heavily penalizes quality loss (QPS, $\\gamma{=}4$), we show that SchED is robust and clearly outperforms prior confidence-based early-exit methods, which break down on long-form generation. An entropy analysis of the model's token predictions reveals that instruction tuning speeds up the decay of predictive entropy. By turning genuine confidence stabilization into computational savings, SchED makes dLLM decoding substantially more efficient.",
          "authors": [
            "Amr Mohamed",
            "Yang Zhang",
            "Michalis Vazirgiannis",
            "Guokan Shang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02895",
          "title": "MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm",
          "abstract": "We present MindGPT-4ov, a multimodal large language model (MLLM) that introduces a general post-training paradigm spanning data production, model training, and efficient deployment. It achieves state-of-the-art performance across multiple benchmarks at low cost, effectively enhancing the foundational capabilities of MLLMs and the generalization ability. Focusing on data construction, supervised fine-tuning strategies, and multimodal reinforcement learning methods, this work proposes three key innovations: (1) An information density-based data generation scheme, integrated with a dual-dimensional tree-structured label system, enabling automated generation of high-quality cross-domain data. (2) A collaborative curriculum supervised fine-tuning approach that balances the injection of domain-specific knowledge with the preservation of general capabilities. (3) A hybrid reinforcement learning paradigm that enhances reasoning ability while simultaneously addressing multi-objective optimization such as diversity exploration, maintenance of multimodal perception, and response conciseness. Moreover, we implement a series of infrastructure optimizations, such as 5D parallel training, operator optimization, and inference quantization to enhance training and inference efficiency while reducing the cost of domain adaptation. Experimental results demonstrate that the MindGPT-4ov model outperforms state-of-the-art models on benchmarks such as MMBench, MMStar, MathVision, and MathVista. In addition, MindGPT-4ov also demonstrates superior user experience in vertical domain tasks, enabling a seamless transition from academic research to industrial deployment. MindGPT-4ov provides a general post-training paradigm applicable to a wide range of MLLMs. The model weights, datasets, and code for the Qwen3-VL-based variants will be recently open-sourced to support the community's development of MLLMs.",
          "authors": [
            "Wei Chen",
            "Chaoqun Du",
            "Feng Gu",
            "Wei He",
            "Qizhen Li",
            "Zide Liu",
            "Xuhao Pan",
            "Chang Ren",
            "Xudong Rao",
            "Chenfeng Wang",
            "Tao Wei",
            "Chengjun Yu",
            "Pengfei Yu",
            "Yufei Zheng",
            "Chunpeng Zhou",
            "Pan Zhou",
            "Xuhan Zhu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02897",
          "title": "Polar Perspectives: Evaluating 2-D LiDAR Projections for Robust Place Recognition with Visual Foundation Models",
          "abstract": "This work presents a systematic investigation into how alternative LiDAR-to-image projections affect metric place recognition when coupled with a state-of-the-art vision foundation model. We introduce a modular retrieval pipeline that controls for backbone, aggregation, and evaluation protocol, thereby isolating the influence of the 2-D projection itself. Using consistent geometric and structural channels across multiple datasets and deployment scenarios, we identify the projection characteristics that most strongly determine discriminative power, robustness to environmental variation, and suitability for real-time autonomy. Experiments with different datasets, including integration into an operational place recognition policy, validate the practical relevance of these findings and demonstrate that carefully designed projections can serve as an effective surrogate for end-to-end 3-D learning in LiDAR place recognition.",
          "authors": [
            "Pierpaolo Serio",
            "Giulio Pisaneschi",
            "Andrea Dan Ryals",
            "Vincenzo Infantino",
            "Lorenzo Gentilini",
            "Valentina Donzella",
            "Lorenzo Pollini"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02898",
          "title": "Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits",
          "abstract": "Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults. This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).",
          "authors": [
            "Pedro Orvalho",
            "Marta Kwiatkowska",
            "Mikoláš Janota",
            "Vasco Manquinho"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02899",
          "title": "Glance: Accelerating Diffusion Models with 1 Sample",
          "abstract": "Diffusion models have achieved remarkable success in image generation, yet their deployment remains constrained by the heavy computational cost and the need for numerous inference steps. Previous efforts on fewer-step distillation attempt to skip redundant steps by training compact student models, yet they often suffer from heavy retraining costs and degraded generalization. In this work, we take a different perspective: we accelerate smartly, not evenly, applying smaller speedups to early semantic stages and larger ones to later redundant phases. We instantiate this phase-aware strategy with two experts that specialize in slow and fast denoising phases. Surprisingly, instead of investing massive effort in retraining student models, we find that simply equipping the base model with lightweight LoRA adapters achieves both efficient acceleration and strong generalization. We refer to these two adapters as Slow-LoRA and Fast-LoRA. Through extensive experiments, our method achieves up to 5 acceleration over the base model while maintaining comparable visual quality across diverse benchmarks. Remarkably, the LoRA experts are trained with only 1 samples on a single V100 within one hour, yet the resulting models generalize strongly on unseen prompts.",
          "authors": [
            "Zhuobai Dong",
            "Rui Zhao",
            "Songjie Wu",
            "Junchao Yi",
            "Linjie Li",
            "Zhengyuan Yang",
            "Lijuan Wang",
            "Alex Jinpeng Wang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02901",
          "title": "FAIRY2I: Universal Extremely-Low Bit QAT framework via Widely-Linear Representation and Phase-Aware Quantization",
          "abstract": "Large language models (LLMs) have revolutionized artificial intelligence, yet their massive memory and computational demands necessitate aggressive quantization, increasingly pushing representations toward the theoretical limit of a single bit. While complex-valued LLMs, such as iFairy, offer a superior chance for low-bit representation compared to real-valued counterparts, they require training from scratch, preventing the utilization of the vast ecosystem of pre-trained real-valued foundation models. Here we present Fairy2i, a universal framework that transforms pre-trained real-valued layers into an equivalent widely-linear complex form, enabling extremely low-bit quantization while reusing existing checkpoints. By proving a lossless mathematical equivalence between real and widely-linear maps, we convert standard Transformers into the complex domain and employ a phase-aware quantization scheme with a highly efficient codebook of fourth roots of unity. Furthermore, we introduce a recursive residual quantization mechanism that iteratively minimizes quantization error, allowing inference to proceed via efficient multiplication-free accumulation. We demonstrate that Fairy2i restores the performance of LLaMA-2 7B at an effective 2-bit precision to levels nearly comparable with full-precision baselines, significantly outperforming state-of-the-art real-valued binary and ternary quantization methods. This work bridges the gap between the representational efficiency of complex-valued arithmetic and the practical utility of pre-trained models, paving a new way for efficient inference on commodity hardware.",
          "authors": [
            "Feiyu Wang",
            "Xinyu Tan",
            "Bokai Huang",
            "Yihao Zhang",
            "Guoan Wang",
            "Peizhuang Cong",
            "Tong Yang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02902",
          "title": "VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling",
          "abstract": "Vision-language-action (VLA) models achieve strong in-distribution performance but degrade sharply under novel camera viewpoints and visual perturbations. We show that this brittleness primarily arises from misalignment in Spatial Modeling, rather than Physical Modeling. To address this, we propose a one-shot adaptation framework that recalibrates visual representations through lightweight, learnable updates. Our first method, Feature Token Modulation (FTM), applies a global affine transformation to visual tokens and improves Libero viewpoint accuracy from 48.5% to 87.1% with only 4K parameters. Building on this, Feature Linear Adaptation (FLA) introduces low-rank updates to the ViT encoder, achieving 90.8% success with 4.7M parameters -- matching LoRA-scale finetuning at far lower cost. Together, these results reveal substantial untapped robustness in pretrained VLA models and demonstrate that targeted, minimal visual adaptation is sufficient to restore viewpoint generalization.",
          "authors": [
            "Weiqi Li",
            "Quande Zhang",
            "Ruifeng Zhai",
            "Liang Lin",
            "Guangrun Wang"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02904",
          "title": "Towards a fully differentiable digital twin for solar cells",
          "abstract": "Maximizing energy yield (EY) - the total electric energy generated by a solar cell within a year at a specific location - is crucial in photovoltaics (PV), especially for emerging technologies. Computational methods provide the necessary insights and guidance for future research. However, existing simulations typically focus on only isolated aspects of solar cells. This lack of consistency highlights the need for a framework unifying all computational levels, from material to cell properties, for accurate prediction and optimization of EY prediction. To address this challenge, a differentiable digital twin, Sol(Di)$^2$T, is introduced to enable comprehensive end-to-end optimization of solar cells. The workflow starts with material properties and morphological processing parameters, followed by optical and electrical simulations. Finally, climatic conditions and geographic location are incorporated to predict the EY. Each step is either intrinsically differentiable or replaced with a machine-learned surrogate model, enabling not only accurate EY prediction but also gradient-based optimization with respect to input parameters. Consequently, Sol(Di)$^2$T extends EY predictions to previously unexplored conditions. Demonstrated for an organic solar cell, the proposed framework marks a significant step towards tailoring solar cells for specific applications while ensuring maximal performance.",
          "authors": [
            "Marie Louise Schubert",
            "Houssam Metni",
            "Jan David Fischbach",
            "Benedikt Zerulla",
            "Marjan Krstić",
            "Ulrich W. Paetzold",
            "Seyedamir Orooji",
            "Olivier J. J. Ronsin",
            "Yasin Ameslon",
            "Jens Harting",
            "Thomas Kirchartz",
            "Sandheep Ravishankar",
            "Chris Dreessen",
            "Eunchi Kim",
            "Christian Sprau",
            "Mohamed Hussein",
            "Alexander Colsmann",
            "Karen Forberich",
            "Klaus Jäger",
            "Pascal Friederich",
            "Carsten Rockstuhl"
          ],
          "primary_category": "physics.comp-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02904",
          "title": "Towards a fully differentiable digital twin for solar cells",
          "abstract": "Maximizing energy yield (EY) - the total electric energy generated by a solar cell within a year at a specific location - is crucial in photovoltaics (PV), especially for emerging technologies. Computational methods provide the necessary insights and guidance for future research. However, existing simulations typically focus on only isolated aspects of solar cells. This lack of consistency highlights the need for a framework unifying all computational levels, from material to cell properties, for accurate prediction and optimization of EY prediction. To address this challenge, a differentiable digital twin, Sol(Di)$^2$T, is introduced to enable comprehensive end-to-end optimization of solar cells. The workflow starts with material properties and morphological processing parameters, followed by optical and electrical simulations. Finally, climatic conditions and geographic location are incorporated to predict the EY. Each step is either intrinsically differentiable or replaced with a machine-learned surrogate model, enabling not only accurate EY prediction but also gradient-based optimization with respect to input parameters. Consequently, Sol(Di)$^2$T extends EY predictions to previously unexplored conditions. Demonstrated for an organic solar cell, the proposed framework marks a significant step towards tailoring solar cells for specific applications while ensuring maximal performance.",
          "authors": [
            "Marie Louise Schubert",
            "Houssam Metni",
            "Jan David Fischbach",
            "Benedikt Zerulla",
            "Marjan Krstić",
            "Ulrich W. Paetzold",
            "Seyedamir Orooji",
            "Olivier J. J. Ronsin",
            "Yasin Ameslon",
            "Jens Harting",
            "Thomas Kirchartz",
            "Sandheep Ravishankar",
            "Chris Dreessen",
            "Eunchi Kim",
            "Christian Sprau",
            "Mohamed Hussein",
            "Alexander Colsmann",
            "Karen Forberich",
            "Klaus Jäger",
            "Pascal Friederich",
            "Carsten Rockstuhl"
          ],
          "primary_category": "physics.comp-ph",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02906",
          "title": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding",
          "abstract": "Understanding high-resolution images remains a significant challenge for multimodal large language models (MLLMs). Recent study address this issue by dividing the image into smaller crops and computing the semantic similarity between each crop and a query using a pretrained retrieval-augmented generation (RAG) model. The most relevant crops are then selected to localize the target object and suppress irrelevant information. However, such crop-based processing can fragment complete objects across multiple crops, thereby disrupting the computation of semantic similarity. In our experiments, we find that image crops of objects with different sizes are better handled at different resolutions. Based on this observation, we propose Multi-resolution Retrieval-Detection (MRD), a training-free framework for high-resolution image understanding. To address the issue of semantic similarity bias caused by objects being split across different image crops, we propose a multi-resolution semantic fusion method, which integrates semantic similarity maps obtained at different resolutions to produce more accurate semantic information and preserve the integrity of target objects. Furthermore, to achieve direct localization of target objects at a global scale, we introduce an open-vocalbulary object detection (OVD) model that identifies object regions using a sliding-window this http URL on high-resolution image understanding benchmarks using different MLLMs demonstrate the effectiveness of our approach.",
          "authors": [
            "Fan Yang",
            "Kaihao Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02910",
          "title": "In Silico Development of Psychometric Scales: Feasibility of Representative Population Data Simulation with LLMs",
          "abstract": "Developing and validating psychometric scales requires large samples, multiple testing phases, and substantial resources. Recent advances in Large Language Models (LLMs) enable the generation of synthetic participant data by prompting models to answer items while impersonating individuals of specific demographic profiles, potentially allowing in silico piloting before real data collection. Across four preregistered studies (N = circa 300 each), we tested whether LLM-simulated datasets can reproduce the latent structures and measurement properties of human responses. In Studies 1-2, we compared LLM-generated data with real datasets for two validated scales; in Studies 3-4, we created new scales using EFA on simulated data and then examined whether these structures generalized to newly collected human samples. Simulated datasets replicated the intended factor structures in three of four studies and showed consistent configural and metric invariance, with scalar invariance achieved for the two newly developed scales. However, correlation-based tests revealed substantial differences between real and synthetic datasets, and notable discrepancies appeared in score distributions and variances. Thus, while LLMs capture group-level latent structures, they do not approximate individual-level data properties. Simulated datasets also showed full internal invariance across gender. Overall, LLM-generated data appear useful for early-stage, group-level psychometric prototyping, but not as substitutes for individual-level validation. We discuss methodological limitations, risks of bias and data pollution, and ethical considerations related to in silico psychometric simulations.",
          "authors": [
            "Enrico Cipriani",
            "Pavel Okopnyi",
            "Danilo Menicucci",
            "Simone Grassini"
          ],
          "primary_category": "cs.HC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02912",
          "title": "Hypothesis Testing for Generalized Thurstone Models",
          "abstract": "In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying \\emph{generalized Thurstone model} $\\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\\mathcal{T}_F$ models. We then derive upper and lower bounds on the critical threshold for testing that depend on the topology of the observation graph. For the special case of complete observation graphs, this threshold scales as $\\Theta((nk)^{-1/2})$, where $n$ is the number of agents and $k$ is the number of comparisons per pair. Furthermore, we propose a hypothesis test based on our separation distance, construct confidence intervals, establish time-uniform bounds on the probabilities of type I and II errors using reverse martingale techniques, and derive minimax lower bounds using information-theoretic methods. Finally, we validate our results through experiments on synthetic and real-world datasets.",
          "authors": [
            "Anuran Makur",
            "Japneet Singh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02912",
          "title": "Hypothesis Testing for Generalized Thurstone Models",
          "abstract": "In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying \\emph{generalized Thurstone model} $\\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\\mathcal{T}_F$ models. We then derive upper and lower bounds on the critical threshold for testing that depend on the topology of the observation graph. For the special case of complete observation graphs, this threshold scales as $\\Theta((nk)^{-1/2})$, where $n$ is the number of agents and $k$ is the number of comparisons per pair. Furthermore, we propose a hypothesis test based on our separation distance, construct confidence intervals, establish time-uniform bounds on the probabilities of type I and II errors using reverse martingale techniques, and derive minimax lower bounds using information-theoretic methods. Finally, we validate our results through experiments on synthetic and real-world datasets.",
          "authors": [
            "Anuran Makur",
            "Japneet Singh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02912",
          "title": "Hypothesis Testing for Generalized Thurstone Models",
          "abstract": "In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying \\emph{generalized Thurstone model} $\\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\\mathcal{T}_F$ models. We then derive upper and lower bounds on the critical threshold for testing that depend on the topology of the observation graph. For the special case of complete observation graphs, this threshold scales as $\\Theta((nk)^{-1/2})$, where $n$ is the number of agents and $k$ is the number of comparisons per pair. Furthermore, we propose a hypothesis test based on our separation distance, construct confidence intervals, establish time-uniform bounds on the probabilities of type I and II errors using reverse martingale techniques, and derive minimax lower bounds using information-theoretic methods. Finally, we validate our results through experiments on synthetic and real-world datasets.",
          "authors": [
            "Anuran Makur",
            "Japneet Singh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02914",
          "title": "Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning",
          "abstract": "Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics. This property implies that, under rational belief updating, the expected value of future beliefs should remain equal to the current belief, i.e., belief updates are unpredictable from the current belief. We propose the unsupervised, regression-based Martingale Score to measure violations of this property, which signal deviation from the Bayesian ability of updating on new evidence. In open-ended problem domains including event forecasting, value-laden questions, and academic paper review, we find such violations to be widespread across models and setups, where the current belief positively predicts future belief updates, a phenomenon which we term belief entrenchment. We identify the models, reasoning techniques, and domains more prone to belief entrenchment. Finally, we validate the Martingale Score by showing that it predicts ground-truth accuracy on problem domains where ground truth labels are available. This indicates that, while designed as an unsupervised metric that operates even in domains without access to ground truth, the Martingale Score is a useful proxy of the truth-seeking ability of a reasoning process.",
          "authors": [
            "Zhonghao He",
            "Tianyi Qiu",
            "Hirokazu Shirado",
            "Maarten Sap"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02917",
          "title": "Maintaining SUV Accuracy in Low-Count PET with PETfectior: A Deep Learning Denoising Solution",
          "abstract": "Background: Diagnostic PET image quality depends on the administered activity and acquisition time. However, minimizing these variables is desirable to reduce patient radiation exposure and radiopharmaceutical costs. PETfectior is an artificial intelligence-based software that processes PET scans and increases signal-to-noise ratio, obtaining high-quality images from low-count-rate images. We perform an initial clinical validation of PETfectior on images acquired with half of the counting statistics required to meet the most recent EANM quantitative standards for 18F-FDG PET, evaluating lesions detectability, quantitative performance and image quality. Materials and methods: 258 patients referred for 18F-FDG PET/CT were prospectively included. The standard-of-care scans (100% scans) were acquired and reconstructed according to EARL standards 2. Half-counting-statistics versions were generated from list-mode data and processed with PETfecftior (50%+PETfectior scans). All oncologic lesions were segmented on both PET/CT versions, manually or automatically, and lesions detectability was evaluated. The SUVmax of the lesions was measured and the quantitative concordance of 50%+PETfectior and 100% images was evaluated. Subjective image quality was visually assessed by two experienced physicians. Results: 1649 lesions were detected in a total of 198 studies. The 50%+PETfectior images showed high sensitivity for lesion detection (99.9%) and only 1 false positive was detected. The SUVmax measured in 100% and 50%+PETfectior images agreed within 12.5% (95% limits of agreement), with a bias of -1.01%. Image quality of the 50%+PETfectior images was rated equal to or better than the standard-of-care images. Conclusion: PETfectior can safely be used in clinical practice at half counting statistics, with high sensitivity and specificity, low quantitative bias and high subjective image quality.",
          "authors": [
            "Yamila Rotstein Habarnau",
            "Nicolás Bustos",
            "Paola Corona",
            "Christian González",
            "Sonia Traverso",
            "Federico Matorra",
            "Francisco Funes",
            "Juan Martín Giraut",
            "Laura Pelegrina",
            "Gabriel Bruno",
            "Mauro Namías"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02917",
          "title": "Maintaining SUV Accuracy in Low-Count PET with PETfectior: A Deep Learning Denoising Solution",
          "abstract": "Background: Diagnostic PET image quality depends on the administered activity and acquisition time. However, minimizing these variables is desirable to reduce patient radiation exposure and radiopharmaceutical costs. PETfectior is an artificial intelligence-based software that processes PET scans and increases signal-to-noise ratio, obtaining high-quality images from low-count-rate images. We perform an initial clinical validation of PETfectior on images acquired with half of the counting statistics required to meet the most recent EANM quantitative standards for 18F-FDG PET, evaluating lesions detectability, quantitative performance and image quality. Materials and methods: 258 patients referred for 18F-FDG PET/CT were prospectively included. The standard-of-care scans (100% scans) were acquired and reconstructed according to EARL standards 2. Half-counting-statistics versions were generated from list-mode data and processed with PETfecftior (50%+PETfectior scans). All oncologic lesions were segmented on both PET/CT versions, manually or automatically, and lesions detectability was evaluated. The SUVmax of the lesions was measured and the quantitative concordance of 50%+PETfectior and 100% images was evaluated. Subjective image quality was visually assessed by two experienced physicians. Results: 1649 lesions were detected in a total of 198 studies. The 50%+PETfectior images showed high sensitivity for lesion detection (99.9%) and only 1 false positive was detected. The SUVmax measured in 100% and 50%+PETfectior images agreed within 12.5% (95% limits of agreement), with a bias of -1.01%. Image quality of the 50%+PETfectior images was rated equal to or better than the standard-of-care images. Conclusion: PETfectior can safely be used in clinical practice at half counting statistics, with high sensitivity and specificity, low quantitative bias and high subjective image quality.",
          "authors": [
            "Yamila Rotstein Habarnau",
            "Nicolás Bustos",
            "Paola Corona",
            "Christian González",
            "Sonia Traverso",
            "Federico Matorra",
            "Francisco Funes",
            "Juan Martín Giraut",
            "Laura Pelegrina",
            "Gabriel Bruno",
            "Mauro Namías"
          ],
          "primary_category": "eess.IV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02918",
          "title": "Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts",
          "abstract": "Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\\% critical and 79\\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.",
          "authors": [
            "Wanxu Xia",
            "Ziqiao Kong",
            "Zhengwei Li",
            "Yi Lu",
            "Pan Li",
            "Liqun Yang",
            "Yang Liu",
            "Xiapu Luo",
            "Shaohua Li"
          ],
          "primary_category": "cs.CR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02920",
          "title": "Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation",
          "abstract": "We consider analyzing traffic accident patterns using both road network data and satellite images aligned to road graph nodes. Previous work for predicting accident occurrences relies primarily on road network structural features while overlooking physical and environmental information from the road surface and its surroundings. In this work, we construct a large multimodal dataset across six U.S. states, containing nine million traffic accident records from official sources, and one million high-resolution satellite images for each node of the road network. Additionally, every node is annotated with features such as the region's weather statistics and road type (e.g., residential vs. motorway), and each edge is annotated with traffic volume information (i.e., Average Annual Daily Traffic). Utilizing this dataset, we conduct a comprehensive evaluation of multimodal learning methods that integrate both visual and network embeddings. Our findings show that integrating both data modalities improves prediction accuracy, achieving an average AUROC of $90.1\\%$, which is a $3.7\\%$ gain over graph neural network models that only utilize graph structures. With the improved embeddings, we conduct a causal analysis based on a matching estimator to estimate the key contributing factors influencing traffic accidents. We find that accident rates rise by $24\\%$ under higher precipitation, by $22\\%$ on higher-speed roads such as motorways, and by $29\\%$ due to seasonal patterns, after adjusting for other confounding factors. Ablation studies confirm that satellite imagery features are essential for achieving accurate prediction.",
          "authors": [
            "Ziniu Zhang",
            "Minxuan Duan",
            "Haris N. Koutsopoulos",
            "Hongyang R. Zhang"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02924",
          "title": "AutoNeural: Co-Designing Vision-Language Models for NPU Inference",
          "abstract": "While Neural Processing Units (NPUs) offer high theoretical efficiency for edge AI, state-of-the-art Vision--Language Models (VLMs) tailored for GPUs often falter on these substrates. We attribute this hardware-model mismatch to two primary factors: the quantization brittleness of Vision Transformers (ViTs) and the I/O-bound nature of autoregressive attention mechanisms, which fail to utilize the high arithmetic throughput of NPUs. To bridge this gap, we propose AutoNeural, an NPU-native VLM architecture co-designed for integer-only inference. We replace the standard ViT encoder with a MobileNetV5-style backbone utilizing depthwise separable convolutions, which ensures bounded activation distributions for stable INT4/8/16 quantization. Complementing this, our language backbone integrates State-Space Model (SSM) principles with Transformer layers, employing efficient gated convolutions to achieve linear-time complexity. This hybrid design eliminates the heavy memory I/O overhead of Key-Value caching during generation. Our approach delivers substantial efficiency gains, reducing quantization error of vision encoder by up to 7x and end-to-end latency by 14x compared to conventional baselines. The AutoNeural also delivers 3x decoding speed and 4x longer context window than the baseline. We validate these improvements via a real-world automotive case study on the Qualcomm SA8295P SoC, demonstrating real-time performance for cockpit applications. Our results highlight that rethinking model topology specifically for NPU constraints is a prerequisite for robust multi-modal edge intelligence.",
          "authors": [
            "Wei Chen",
            "Liangmin Wu",
            "Yunhai Hu",
            "Zhiyuan Li",
            "Zhiyuan Cheng",
            "Yicheng Qian",
            "Lingyue Zhu",
            "Zhipeng Hu",
            "Luoyi Liang",
            "Qiang Tang",
            "Zhen Liu",
            "Han Yang"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02929",
          "title": "BD-Index: Scalable Biharmonic Distance Queries on Large Graphs via Divide-and-Conquer Indexing",
          "abstract": "Biharmonic distance (\\bd) is a powerful graph distance metric with many applications, including identifying critical links in road networks and mitigating over-squashing problem in \\gnn. However, computing \\bd\\ is extremely difficult, especially on large graphs. In this paper, we focus on the problem of \\emph{single-pair} \\bd\\ query. Existing methods mainly rely on random walk-based approaches, which work well on some graphs but become inefficient when the random walk cannot mix this http URL overcome this issue, we first show that the biharmonic distance between two nodes $s,t$, denoted by $b(s,t)$, can be interpreted as the distance between two random walk distributions starting from $s$ and $t$. To estimate these distributions, the required random walk length is large when the underlying graph can be easily cut into smaller pieces. Inspired by this observation, we present novel formulas of \\bd to represent $b(s,t)$ by independent random walks within two node sets $\\mathcal{V}_s$, $\\mathcal{V}_t$ separated by a small \\emph{cut set} $\\mathcal{V}_{cut}$, where $\\mathcal{V}_s\\cup\\mathcal{V}_t\\cup\\mathcal{V}_{cut}=\\mathcal{V}$ is the set of graph nodes. Building upon this idea, we propose \\bindex, a novel index structure which follows a divide-and-conquer strategy. The graph is first cut into pieces so that each part can be processed easily. Then, all the required random walk probabilities can be deterministically computed in a bottom-top manner. When a query comes, only a small part of the index needs to be accessed. We prove that \\bindex\\ requires $O(n\\cdot h)$ space, can be built in $O(n\\cdot h\\cdot (h+d_{max}))$ time, and answers each query in $O(n\\cdot h)$ time, where $h$ is the height of a hierarchy partition tree and $d_{max}$ is the maximum degree, which are both usually much smaller than $n$.",
          "authors": [
            "Yueyang Pan",
            "Meihao Liao",
            "Rong-Hua Li"
          ],
          "primary_category": "cs.DS",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02931",
          "title": "DiverseAR: Boosting Diversity in Bitwise Autoregressive Image Generation",
          "abstract": "In this paper, we investigate the underexplored challenge of sample diversity in autoregressive (AR) generative models with bitwise visual tokenizers. We first analyze the factors that limit diversity in bitwise AR models and identify two key issues: (1) the binary classification nature of bitwise modeling, which restricts the prediction space, and (2) the overly sharp logits distribution, which causes sampling collapse and reduces diversity. Building on these insights, we propose DiverseAR, a principled and effective method that enhances image diversity without sacrificing visual quality. Specifically, we introduce an adaptive logits distribution scaling mechanism that dynamically adjusts the sharpness of the binary output distribution during sampling, resulting in smoother predictions and greater diversity. To mitigate potential fidelity loss caused by distribution smoothing, we further develop an energy-based generation path search algorithm that avoids sampling low-confidence tokens, thereby preserving high visual quality. Extensive experiments demonstrate that DiverseAR substantially improves sample diversity in bitwise autoregressive image generation.",
          "authors": [
            "Ying Yang",
            "Zhengyao Lv",
            "Tianlin Pan",
            "Haofan Wang",
            "Binxin Yang",
            "Hubery Yin",
            "Chen Li",
            "Chenyang Si"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02932",
          "title": "EGGS: Exchangeable 2D/3D Gaussian Splatting for Geometry-Appearance Balanced Novel View Synthesis",
          "abstract": "Novel view synthesis (NVS) is crucial in computer vision and graphics, with wide applications in AR, VR, and autonomous driving. While 3D Gaussian Splatting (3DGS) enables real-time rendering with high appearance fidelity, it suffers from multi-view inconsistencies, limiting geometric accuracy. In contrast, 2D Gaussian Splatting (2DGS) enforces multi-view consistency but compromises texture details. To address these limitations, we propose Exchangeable Gaussian Splatting (EGGS), a hybrid representation that integrates 2D and 3D Gaussians to balance appearance and geometry. To achieve this, we introduce Hybrid Gaussian Rasterization for unified rendering, Adaptive Type Exchange for dynamic adaptation between 2D and 3D Gaussians, and Frequency-Decoupled Optimization that effectively exploits the strengths of each type of Gaussian representation. Our CUDA-accelerated implementation ensures efficient training and inference. Extensive experiments demonstrate that EGGS outperforms existing methods in rendering quality, geometric accuracy, and efficiency, providing a practical solution for high-quality NVS.",
          "authors": [
            "Yancheng Zhang",
            "Guangyu Sun",
            "Chen Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02933",
          "title": "LoVoRA: Text-guided and Mask-free Video Object Removal and Addition with Learnable Object-aware Localization",
          "abstract": "Text-guided video editing, particularly for object removal and addition, remains a challenging task due to the need for precise spatial and temporal consistency. Existing methods often rely on auxiliary masks or reference images for editing guidance, which limits their scalability and generalization. To address these issues, we propose LoVoRA, a novel framework for mask-free video object removal and addition using object-aware localization mechanism. Our approach utilizes a unique dataset construction pipeline that integrates image-to-video translation, optical flow-based mask propagation, and video inpainting, enabling temporally consistent edits. The core innovation of LoVoRA is its learnable object-aware localization mechanism, which provides dense spatio-temporal supervision for both object insertion and removal tasks. By leveraging a Diffusion Mask Predictor, LoVoRA achieves end-to-end video editing without requiring external control signals during inference. Extensive experiments and human evaluation demonstrate the effectiveness and high-quality performance of LoVoRA.",
          "authors": [
            "Zhihan Xiao",
            "Lin Liu",
            "Yixin Gao",
            "Xiaopeng Zhang",
            "Haoxuan Che",
            "Songping Mai",
            "Qi Tian"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02936",
          "title": "From Administrative Chaos to Analytical Cohorts: A Three-Stage Normalisation Pipeline for Longitudinal University Administrative Records",
          "abstract": "The growing use of longitudinal university administrative records in data-driven decision-making often overlooks a critical layer: how raw, inconsistent data are normalised before modelling. This article presents a three-stage normalisation pipeline for a dataset of 24,133 engineering students at a Latin American public university, spanning four decades (1980-2019). The pipeline comprises: (i) N1 CENSAL, harmonising demographics into a single person-level layer; (ii) N1b IDENTITY RESOLUTION, consolidating duplicate identifiers into a canonical ID while preserving an audit trail; and (iii) N1c GEO and SECONDARY-SCHOOL NORMALISATION, which builds reference tables, classifies school types (state national, state provincial, private secular, private religious), and flags irrecoverable cases as DATA_MISSING. The pipeline preserves 100% of students, achieves full geocoding, and yields valid school types for 56.6% of the population. The remaining 43.4% are identified as structurally missing due to legacy enrolment practices rather than stochastic non-response. Forensic analysis (chi-square, logistic regression) shows missingness is highly predictable from entry decade and geography, confirming a structural, historically induced mechanism. The article contributes: (a) a transparent, reproducible normalisation pipeline tailored to higher education; (b) a framework for treating structurally missing information without speculative imputation; and (c) guidance on defining analytically coherent cohorts (full population vs. secondary-school-informed subcohorts) for downstream learning analytics and policy evaluation.",
          "authors": [
            "H. R. Paz"
          ],
          "primary_category": "cs.DB",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02942",
          "title": "Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench",
          "abstract": "The next frontier for video generation lies in developing models capable of zero-shot reasoning, where understanding real-world scientific laws is crucial for accurate physical outcome modeling under diverse conditions. However, existing video benchmarks are physical commonsense-based, offering limited insight into video models' scientific reasoning capability. We introduce VideoScience-Bench, a benchmark designed to evaluate undergraduate-level scientific understanding in video models. Each prompt encodes a composite scientific scenario that requires understanding and reasoning across multiple scientific concepts to generate the correct phenomenon. The benchmark comprises 200 carefully curated prompts spanning 14 topics and 103 concepts in physics and chemistry. We conduct expert-annotated evaluations across seven state-of-the-art video models in T2V and I2V settings along five dimensions: Prompt Consistency, Phenomenon Congruency, Correct Dynamism, Immutability, and Spatio-Temporal Continuity. Using a VLM-as-a-Judge to assess video generations, we observe strong correlation with human assessments. To the best of our knowledge, VideoScience-Bench is the first benchmark to evaluate video models not only as generators but also as reasoners, requiring their generations to demonstrate scientific understanding consistent with expected physical and chemical phenomena. Our data and evaluation code are available at: \\href{ this https URL }{ this http URL }.",
          "authors": [
            "Lanxiang Hu",
            "Abhilash Shankarampeta",
            "Yixin Huang",
            "Zilin Dai",
            "Haoyang Yu",
            "Yujie Zhao",
            "Haoqiang Kang",
            "Daniel Zhao",
            "Tajana Rosing",
            "Hao Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02947",
          "title": "Representation of Inorganic Synthesis Reactions and Prediction: Graphical Framework and Datasets",
          "abstract": "While machine learning has enabled the rapid prediction of inorganic materials with novel properties, the challenge of determining how to synthesize these materials remains largely unsolved. Previous work has largely focused on predicting precursors or reaction conditions, but only rarely on full synthesis pathways. We introduce the ActionGraph, a directed acyclic graph framework that encodes both the chemical and procedural structure, in terms of synthesis operations, of inorganic synthesis reactions. Using 13,017 text-mined solid-state synthesis reactions from the Materials Project, we show that incorporating PCA-reduced ActionGraph adjacency matrices into a $k$-nearest neighbors retrieval model significantly improves synthesis pathway prediction. While the ActionGraph framework only results in a 1.34% and 2.76% increase in precursor and operation F1 scores (average over varying numbers of PCA components) respectively, the operation length matching accuracy rises 3.4 times (from 15.8% to 53.3%). We observe an interesting trade-off where precursor prediction performance peaks at 10-11 PCA components while operation prediction continues improving up to 30 components. This suggests composition information dominates precursor selection while structural information is critical for operation sequencing. Overall, the ActionGraph framework demonstrates strong potential, and with further adoption, its full range of benefits can be effectively realized.",
          "authors": [
            "Samuel Andrello",
            "Daniel Alabi",
            "Simon J. L. Billinge"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02947",
          "title": "Representation of Inorganic Synthesis Reactions and Prediction: Graphical Framework and Datasets",
          "abstract": "While machine learning has enabled the rapid prediction of inorganic materials with novel properties, the challenge of determining how to synthesize these materials remains largely unsolved. Previous work has largely focused on predicting precursors or reaction conditions, but only rarely on full synthesis pathways. We introduce the ActionGraph, a directed acyclic graph framework that encodes both the chemical and procedural structure, in terms of synthesis operations, of inorganic synthesis reactions. Using 13,017 text-mined solid-state synthesis reactions from the Materials Project, we show that incorporating PCA-reduced ActionGraph adjacency matrices into a $k$-nearest neighbors retrieval model significantly improves synthesis pathway prediction. While the ActionGraph framework only results in a 1.34% and 2.76% increase in precursor and operation F1 scores (average over varying numbers of PCA components) respectively, the operation length matching accuracy rises 3.4 times (from 15.8% to 53.3%). We observe an interesting trade-off where precursor prediction performance peaks at 10-11 PCA components while operation prediction continues improving up to 30 components. This suggests composition information dominates precursor selection while structural information is critical for operation sequencing. Overall, the ActionGraph framework demonstrates strong potential, and with further adoption, its full range of benefits can be effectively realized.",
          "authors": [
            "Samuel Andrello",
            "Daniel Alabi",
            "Simon J. L. Billinge"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02951",
          "title": "Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger",
          "abstract": "Task-space control of robotic fingers is a critical enabler of dexterous manipulation, as manipulation objectives are most naturally specified in terms of fingertip motions and applied forces rather than individual joint angles. While task-space planning and control have been extensively studied for larger, arm-scale manipulators, demonstrations of precise task-space trajectory tracking in compact, multi-DoF robotic fingers remain scarce. In this paper, we present the physical prototyping and experimental characterization of a three-degree-of-freedom, linkage-driven, series-parallel robotic finger with analytic forward kinematics and a closed-form Jacobian. A resolved motion rate control (RMRC) scheme is implemented to achieve closed-loop task-space trajectory tracking. We experimentally evaluate the fingertip tracking performance across a variety of trajectories, including straight lines, circles, and more complex curves, and report millimeter-level accuracy. To the best of our knowledge, this work provides one of the first systematic experimental demonstrations of precise task-space trajectory tracking in a linkage-driven robotic finger, thereby establishing a benchmark for future designs aimed at dexterous in-hand manipulation.",
          "authors": [
            "Nicholas Baiata",
            "Nilanjan Chakraborty"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02952",
          "title": "Layout Anything: One Transformer for Universal Room Layout Estimation",
          "abstract": "We present Layout Anything, a transformer-based framework for indoor layout estimation that adapts the OneFormer's universal segmentation architecture to geometric structure prediction. Our approach integrates OneFormer's task-conditioned queries and contrastive learning with two key modules: (1) a layout degeneration strategy that augments training data while preserving Manhattan-world constraints through topology-aware transformations, and (2) differentiable geometric losses that directly enforce planar consistency and sharp boundary predictions during training. By unifying these components in an end-to-end framework, the model eliminates complex post-processing pipelines while achieving high-speed inference at 114ms. Extensive experiments demonstrate state-of-the-art performance across standard benchmarks, with pixel error (PE) of 5.43% and corner error (CE) of 4.02% on the LSUN, PE of 7.04% (CE 5.17%) on the Hedau and PE of 4.03% (CE 3.15%) on the Matterport3D-Layout datasets. The framework's combination of geometric awareness and computational efficiency makes it particularly suitable for augmented reality applications and large-scale 3D scene reconstruction tasks.",
          "authors": [
            "Md Sohag Mia",
            "Muhammad Abdullah Adnan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02953",
          "title": "The Evolutionary Ecology of Software: Constraints, Innovation, and the AI Disruption",
          "abstract": "This chapter investigates the evolutionary ecology of software, focusing on the symbiotic relationship between software and innovation. An interplay between constraints, tinkering, and frequency-dependent selection drives the complex evolutionary trajectories of these socio-technological systems. Our approach integrates agent-based modeling and case studies, drawing on complex network analysis and evolutionary theory to explore how software evolves under the competing forces of novelty generation and imitation. By examining the evolution of programming languages and their impact on developer practices, we illustrate how technological artifacts co-evolve with and shape societal norms, cultural dynamics, and human interactions. This ecological perspective also informs our analysis of the emerging role of AI-driven development tools in software evolution. While large language models (LLMs) provide unprecedented access to information, their widespread adoption introduces new evolutionary pressures that may contribute to cultural stagnation, much like the decline of diversity in past software ecosystems. Understanding the evolutionary pressures introduced by AI-mediated software production is critical for anticipating broader patterns of cultural change, technological adaptation, and the future of software innovation.",
          "authors": [
            "Sergi Valverde",
            "Blai Vidiella",
            "Salva Duran-Nebreda"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02953",
          "title": "The Evolutionary Ecology of Software: Constraints, Innovation, and the AI Disruption",
          "abstract": "This chapter investigates the evolutionary ecology of software, focusing on the symbiotic relationship between software and innovation. An interplay between constraints, tinkering, and frequency-dependent selection drives the complex evolutionary trajectories of these socio-technological systems. Our approach integrates agent-based modeling and case studies, drawing on complex network analysis and evolutionary theory to explore how software evolves under the competing forces of novelty generation and imitation. By examining the evolution of programming languages and their impact on developer practices, we illustrate how technological artifacts co-evolve with and shape societal norms, cultural dynamics, and human interactions. This ecological perspective also informs our analysis of the emerging role of AI-driven development tools in software evolution. While large language models (LLMs) provide unprecedented access to information, their widespread adoption introduces new evolutionary pressures that may contribute to cultural stagnation, much like the decline of diversity in past software ecosystems. Understanding the evolutionary pressures introduced by AI-mediated software production is critical for anticipating broader patterns of cultural change, technological adaptation, and the future of software innovation.",
          "authors": [
            "Sergi Valverde",
            "Blai Vidiella",
            "Salva Duran-Nebreda"
          ],
          "primary_category": "cs.SE",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02965",
          "title": "A Lightweight Real-Time Low-Light Enhancement Network for Embedded Automotive Vision Systems",
          "abstract": "In low-light environments like nighttime driving, image degradation severely challenges in-vehicle camera safety. Since existing enhancement algorithms are often too computationally intensive for vehicular applications, we propose UltraFast-LieNET, a lightweight multi-scale shifted convolutional network for real-time low-light image enhancement. We introduce a Dynamic Shifted Convolution (DSConv) kernel with only 12 learnable parameters for efficient feature extraction. By integrating DSConv with varying shift distances, a Multi-scale Shifted Residual Block (MSRB) is constructed to significantly expand the receptive field. To mitigate lightweight network instability, a residual structure and a novel multi-level gradient-aware loss function are incorporated. UltraFast-LieNET allows flexible parameter configuration, with a minimum size of only 36 parameters. Results on the LOLI-Street dataset show a PSNR of 26.51 dB, outperforming state-of-the-art methods by 4.6 dB while utilizing only 180 parameters. Experiments across four benchmark datasets validate its superior balance of real-time performance and enhancement quality under limited resources. Code is available at https://githubhttps://github.com/YuhanChen2024/UltraFast-LiNET",
          "authors": [
            "Yuhan Chen",
            "Yicui Shi",
            "Guofa Li",
            "Guangrui Bai",
            "Jinyuan Shao",
            "Xiangfei Huang",
            "Wenbo Chu",
            "Keqiang Li"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02966",
          "title": "Lumos: Let there be Language Model System Certification",
          "abstract": "We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs. Lumos supports certifying LMS for arbitrary prompt distributions via integration with statistical certifiers. We provide hybrid (operational and denotational) semantics for Lumos, providing a rigorous way to interpret the specifications. Using only a small set of composable constructs, Lumos can encode existing LMS specifications, including complex relational and temporal specifications. It also facilitates specifying new properties - we present the first safety specifications for vision-language models (VLMs) in autonomous driving scenarios developed with Lumos. Using these, we show that the state-of-the-art VLM Qwen-VL exhibits critical safety failures, producing incorrect and unsafe responses with at least 90% probability in right-turn scenarios under rainy driving conditions, revealing substantial safety risks. Lumos's modular structure allows easy modification of the specifications, enabling LMS certification to stay abreast with the rapidly evolving threat landscape. We further demonstrate that specification programs written in Lumos enable finding specific failure cases exhibited by state-of-the-art LMS. Lumos is the first systematic and extensible language-based framework for specifying and certifying LMS behaviors, paving the way for a wider adoption of LMS certification.",
          "authors": [
            "Isha Chaudhary",
            "Vedaant Jain",
            "Avaljot Singh",
            "Kavya Sachdeva",
            "Sayan Ranu",
            "Gagandeep Singh"
          ],
          "primary_category": "cs.PL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02967",
          "title": "Pruning AMR: Efficient Visualization of Implicit Neural Representations via Weight Matrix Analysis",
          "abstract": "An implicit neural representation (INR) is a neural network that approximates a spatiotemporal function. Many memory-intensive visualization tasks, including modern 4D CT scanning methods, represent data natively as INRs. While INRs are prized for being more memory-efficient than traditional data stored on a lattice, many visualization tasks still require discretization to a regular grid. We present PruningAMR, an algorithm that builds a mesh with resolution adapted to geometric features encoded by the INR. To identify these geometric features, we use an interpolative decomposition pruning method on the weight matrices of the INR. The resulting pruned network is used to guide adaptive mesh refinement, enabling automatic mesh generation tailored to the underlying resolution of the function. Starting from a pre-trained INR--without access to its training data--we produce a variable resolution visualization with substantial memory savings.",
          "authors": [
            "Jennifer Zvonek",
            "Andrew Gillette"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02967",
          "title": "Pruning AMR: Efficient Visualization of Implicit Neural Representations via Weight Matrix Analysis",
          "abstract": "An implicit neural representation (INR) is a neural network that approximates a spatiotemporal function. Many memory-intensive visualization tasks, including modern 4D CT scanning methods, represent data natively as INRs. While INRs are prized for being more memory-efficient than traditional data stored on a lattice, many visualization tasks still require discretization to a regular grid. We present PruningAMR, an algorithm that builds a mesh with resolution adapted to geometric features encoded by the INR. To identify these geometric features, we use an interpolative decomposition pruning method on the weight matrices of the INR. The resulting pruned network is used to guide adaptive mesh refinement, enabling automatic mesh generation tailored to the underlying resolution of the function. Starting from a pre-trained INR--without access to its training data--we produce a variable resolution visualization with substantial memory savings.",
          "authors": [
            "Jennifer Zvonek",
            "Andrew Gillette"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02968",
          "title": "Flexible Gravitational-Wave Parameter Estimation with Transformers",
          "abstract": "Gravitational-wave data analysis relies on accurate and efficient methods to extract physical information from noisy detector signals, yet the increasing rate and complexity of observations represent a growing challenge. Deep learning provides a powerful alternative to traditional inference, but existing neural models typically lack the flexibility to handle variations in data analysis settings. Such variations accommodate imperfect observations or are required for specialized tests, and could include changes in detector configurations, overall frequency ranges, or localized cuts. We introduce a flexible transformer-based architecture paired with a training strategy that enables adaptation to diverse analysis settings at inference time. Applied to parameter estimation, we demonstrate that a single flexible model -- called Dingo-T1 -- can (i) analyze 48 gravitational-wave events from the third LIGO-Virgo-KAGRA Observing Run under a wide range of analysis configurations, (ii) enable systematic studies of how detector and frequency configurations impact inferred posteriors, and (iii) perform inspiral-merger-ringdown consistency tests probing general relativity. Dingo-T1 also improves median sample efficiency on real events from a baseline of 1.4% to 4.2%. Our approach thus demonstrates flexible and scalable inference with a principled framework for handling missing or incomplete data -- key capabilities for current and next-generation observatories.",
          "authors": [
            "Annalena Kofler",
            "Maximilian Dax",
            "Stephen R. Green",
            "Jonas Wildberger",
            "Nihar Gupte",
            "Jakob H. Macke",
            "Jonathan Gair",
            "Alessandra Buonanno",
            "Bernhard Schölkopf"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02968",
          "title": "Flexible Gravitational-Wave Parameter Estimation with Transformers",
          "abstract": "Gravitational-wave data analysis relies on accurate and efficient methods to extract physical information from noisy detector signals, yet the increasing rate and complexity of observations represent a growing challenge. Deep learning provides a powerful alternative to traditional inference, but existing neural models typically lack the flexibility to handle variations in data analysis settings. Such variations accommodate imperfect observations or are required for specialized tests, and could include changes in detector configurations, overall frequency ranges, or localized cuts. We introduce a flexible transformer-based architecture paired with a training strategy that enables adaptation to diverse analysis settings at inference time. Applied to parameter estimation, we demonstrate that a single flexible model -- called Dingo-T1 -- can (i) analyze 48 gravitational-wave events from the third LIGO-Virgo-KAGRA Observing Run under a wide range of analysis configurations, (ii) enable systematic studies of how detector and frequency configurations impact inferred posteriors, and (iii) perform inspiral-merger-ringdown consistency tests probing general relativity. Dingo-T1 also improves median sample efficiency on real events from a baseline of 1.4% to 4.2%. Our approach thus demonstrates flexible and scalable inference with a principled framework for handling missing or incomplete data -- key capabilities for current and next-generation observatories.",
          "authors": [
            "Annalena Kofler",
            "Maximilian Dax",
            "Stephen R. Green",
            "Jonas Wildberger",
            "Nihar Gupte",
            "Jakob H. Macke",
            "Jonathan Gair",
            "Alessandra Buonanno",
            "Bernhard Schölkopf"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02968",
          "title": "Flexible Gravitational-Wave Parameter Estimation with Transformers",
          "abstract": "Gravitational-wave data analysis relies on accurate and efficient methods to extract physical information from noisy detector signals, yet the increasing rate and complexity of observations represent a growing challenge. Deep learning provides a powerful alternative to traditional inference, but existing neural models typically lack the flexibility to handle variations in data analysis settings. Such variations accommodate imperfect observations or are required for specialized tests, and could include changes in detector configurations, overall frequency ranges, or localized cuts. We introduce a flexible transformer-based architecture paired with a training strategy that enables adaptation to diverse analysis settings at inference time. Applied to parameter estimation, we demonstrate that a single flexible model -- called Dingo-T1 -- can (i) analyze 48 gravitational-wave events from the third LIGO-Virgo-KAGRA Observing Run under a wide range of analysis configurations, (ii) enable systematic studies of how detector and frequency configurations impact inferred posteriors, and (iii) perform inspiral-merger-ringdown consistency tests probing general relativity. Dingo-T1 also improves median sample efficiency on real events from a baseline of 1.4% to 4.2%. Our approach thus demonstrates flexible and scalable inference with a principled framework for handling missing or incomplete data -- key capabilities for current and next-generation observatories.",
          "authors": [
            "Annalena Kofler",
            "Maximilian Dax",
            "Stephen R. Green",
            "Jonas Wildberger",
            "Nihar Gupte",
            "Jakob H. Macke",
            "Jonathan Gair",
            "Alessandra Buonanno",
            "Bernhard Schölkopf"
          ],
          "primary_category": "gr-qc",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02970",
          "title": "Identification of Multivariate Measurement Error Models",
          "abstract": "This paper develops new identification results for multidimensional continuous measurement-error models where all observed measurements are contaminated by potentially correlated errors and none provides an injective mapping of the latent distribution. Using third order cross moments, the paper constructs a three way tensor whose unique decomposition, guaranteed by Kruskal theorem, identifies the factor loading matrices. Starting with a linear structure, the paper recovers the full distribution of latent factors by constructing suitable measurements and applying scalar or multivariate versions of Kotlarski identity. As a result, the joint distribution of the latent vector and measurement errors is fully identified without requiring injective measurements, showing that multivariate latent structure can be recovered in broader settings than previously believed. Under injectivity, the paper also provides user-friendly testable conditions for identification. Finally, this paper provides general identification results for nonlinear models using a newly-defined generalized Kruskal rank - signal rank - of intergral operators. These results have wide applicability in empirical work involving noisy or indirect measurements, including factor models, survey data with reporting errors, mismeasured regressors in econometrics, and multidimensional latent-trait models in psychology and marketing, potentially enabling more robust estimation and interpretation when clean measurements are unavailable.",
          "authors": [
            "Yingyao Hu"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02970",
          "title": "Identification of Multivariate Measurement Error Models",
          "abstract": "This paper develops new identification results for multidimensional continuous measurement-error models where all observed measurements are contaminated by potentially correlated errors and none provides an injective mapping of the latent distribution. Using third order cross moments, the paper constructs a three way tensor whose unique decomposition, guaranteed by Kruskal theorem, identifies the factor loading matrices. Starting with a linear structure, the paper recovers the full distribution of latent factors by constructing suitable measurements and applying scalar or multivariate versions of Kotlarski identity. As a result, the joint distribution of the latent vector and measurement errors is fully identified without requiring injective measurements, showing that multivariate latent structure can be recovered in broader settings than previously believed. Under injectivity, the paper also provides user-friendly testable conditions for identification. Finally, this paper provides general identification results for nonlinear models using a newly-defined generalized Kruskal rank - signal rank - of intergral operators. These results have wide applicability in empirical work involving noisy or indirect measurements, including factor models, survey data with reporting errors, mismeasured regressors in econometrics, and multidimensional latent-trait models in psychology and marketing, potentially enabling more robust estimation and interpretation when clean measurements are unavailable.",
          "authors": [
            "Yingyao Hu"
          ],
          "primary_category": "econ.EM",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02972",
          "title": "BEVDilation: LiDAR-Centric Multi-Modal Fusion for 3D Object Detection",
          "abstract": "Integrating LiDAR and camera information in the bird's eye view (BEV) representation has demonstrated its effectiveness in 3D object detection. However, because of the fundamental disparity in geometric accuracy between these sensors, indiscriminate fusion in previous methods often leads to degraded performance. In this paper, we propose BEVDilation, a novel LiDAR-centric framework that prioritizes LiDAR information in the fusion. By formulating image BEV features as implicit guidance rather than naive concatenation, our strategy effectively alleviates the spatial misalignment caused by image depth estimation errors. Furthermore, the image guidance can effectively help the LiDAR-centric paradigm to address the sparsity and semantic limitations of point clouds. Specifically, we propose a Sparse Voxel Dilation Block that mitigates the inherent point sparsity by densifying foreground voxels through image priors. Moreover, we introduce a Semantic-Guided BEV Dilation Block to enhance the LiDAR feature diffusion processing with image semantic guidance and long-range context capture. On the challenging nuScenes benchmark, BEVDilation achieves better performance than state-of-the-art methods while maintaining competitive computational efficiency. Importantly, our LiDAR-centric strategy demonstrates greater robustness to depth noise compared to naive fusion. The source code is available at this https URL .",
          "authors": [
            "Guowen Zhang",
            "Chenhang He",
            "Liyi Chen",
            "Lei Zhang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02973",
          "title": "Contextual Image Attack: How Visual Context Exposes Multimodal Safety Vulnerabilities",
          "abstract": "While Multimodal Large Language Models (MLLMs) show remarkable capabilities, their safety alignments are susceptible to jailbreak attacks. Existing attack methods typically focus on text-image interplay, treating the visual modality as a secondary prompt. This approach underutilizes the unique potential of images to carry complex, contextual information. To address this gap, we propose a new image-centric attack method, Contextual Image Attack (CIA), which employs a multi-agent system to subtly embeds harmful queries into seemingly benign visual contexts using four distinct visualization strategies. To further enhance the attack's efficacy, the system incorporate contextual element enhancement and automatic toxicity obfuscation techniques. Experimental results on the MMSafetyBench-tiny dataset show that CIA achieves high toxicity scores of 4.73 and 4.83 against the GPT-4o and Qwen2.5-VL-72B models, respectively, with Attack Success Rates (ASR) reaching 86.31\\% and 91.07\\%. Our method significantly outperforms prior work, demonstrating that the visual modality itself is a potent vector for jailbreaking advanced MLLMs.",
          "authors": [
            "Yuan Xiong",
            "Ziqi Miao",
            "Lijun Li",
            "Chen Qian",
            "Jie Li",
            "Jing Shao"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02978",
          "title": "Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding",
          "abstract": "Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal 'one-size-fits-all' method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique.",
          "authors": [
            "Paul Barbaste",
            "Olivier Oullier",
            "Xavier Vasques"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02978",
          "title": "Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding",
          "abstract": "Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial Patterns (CSP), Riemannian geometry, functional connectivity, and fractal- or entropy-based features across three open-access EEG datasets. Unlike prior studies, our analysis operates at the per-participant level and across multiple frequency bands (8-15 Hz and 8-30 Hz), enabling direct assessment of both group-level performance and individual variability. Covariance tangent space projection (cov-tgsp) and CSP consistently achieved the highest average classification accuracies. However, their effectiveness was strongly dataset-dependent, and marked participant-level differences persisted, particularly in the most heterogeneous of the datasets. Importantly, nonlinear methods outperformed spatial approaches for specific individuals, underscoring the need for personalized pipeline selection. Our findings highlight that no universal 'one-size-fits-all' method can optimally decode EEG motor imagery patterns across all users or datasets. Future work will require adaptive, multimodal, and possibly novel approaches to fully address neurophysiological variability in practical BCI applications where the system can automatically adapt to what makes each user unique.",
          "authors": [
            "Paul Barbaste",
            "Olivier Oullier",
            "Xavier Vasques"
          ],
          "primary_category": "q-bio.NC",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02981",
          "title": "InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration",
          "abstract": "Hallucination remains a critical challenge in large language models (LLMs), hindering the development of reliable multimodal LLMs (MLLMs). Existing solutions often rely on human intervention or underutilize the agent's ability to autonomously mitigate hallucination. To address these limitations, we draw inspiration from how humans make reliable decisions in the real world. They begin with introspective reasoning to reduce uncertainty and form an initial judgment, then rely on external verification from diverse perspectives to reach a final decision. Motivated by this cognitive paradigm, we propose InEx, a training-free, multi-agent framework designed to autonomously mitigate hallucination. InEx introduces internal introspective reasoning, guided by entropy-based uncertainty estimation, to improve the reliability of the decision agent's reasoning process. The agent first generates a response, which is then iteratively verified and refined through external cross-modal multi-agent collaboration with the editing agent and self-reflection agents, further enhancing reliability and mitigating hallucination. Extensive experiments show that InEx consistently outperforms existing methods, achieving 4%-27% gains on general and hallucination benchmarks, and demonstrating strong robustness.",
          "authors": [
            "Zhongyu Yang",
            "Yingfang Yuan",
            "Xuanming Jiang",
            "Baoyi An",
            "Wei Pang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02982",
          "title": "U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences",
          "abstract": "Modeling dynamic 3D environments from LiDAR sequences is central to building reliable 4D worlds for autonomous driving and embodied AI. Existing generative frameworks, however, often treat all spatial regions uniformly, overlooking the varying uncertainty across real-world scenes. This uniform generation leads to artifacts in complex or ambiguous regions, limiting realism and temporal stability. In this work, we present U4D, an uncertainty-aware framework for 4D LiDAR world modeling. Our approach first estimates spatial uncertainty maps from a pretrained segmentation model to localize semantically challenging regions. It then performs generation in a \"hard-to-easy\" manner through two sequential stages: (1) uncertainty-region modeling, which reconstructs high-entropy regions with fine geometric fidelity, and (2) uncertainty-conditioned completion, which synthesizes the remaining areas under learned structural priors. To further ensure temporal coherence, U4D incorporates a mixture of spatio-temporal (MoST) block that adaptively fuses spatial and temporal representations during diffusion. Extensive experiments show that U4D produces geometrically faithful and temporally consistent LiDAR sequences, advancing the reliability of 4D world modeling for autonomous perception and simulation.",
          "authors": [
            "Xiang Xu",
            "Ao Liang",
            "Youquan Liu",
            "Linfeng Li",
            "Lingdong Kong",
            "Ziwei Liu",
            "Qingshan Liu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02983",
          "title": "ProteinPNet: Prototypical Part Networks for Concept Learning in Spatial Proteomics",
          "abstract": "Understanding the spatial architecture of the tumor microenvironment (TME) is critical to advance precision oncology. We present ProteinPNet, a novel framework based on prototypical part networks that discovers TME motifs from spatial proteomics data. Unlike traditional post-hoc explanability models, ProteinPNet directly learns discriminative, interpretable, faithful spatial prototypes through supervised training. We validate our approach on synthetic datasets with ground truth motifs, and further test it on a real-world lung cancer spatial proteomics dataset. ProteinPNet consistently identifies biologically meaningful prototypes aligned with different tumor subtypes. Through graphical and morphological analyses, we show that these prototypes capture interpretable features pointing to differences in immune infiltration and tissue modularity. Our results highlight the potential of prototype-based learning to reveal interpretable spatial biomarkers within the TME, with implications for mechanistic discovery in spatial omics.",
          "authors": [
            "Louis McConnell",
            "Jieran Sun",
            "Theo Maffei",
            "Raphael Gottardo",
            "Marianna Rapsomaniki"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02985",
          "title": "Learning interpretable surface elasticity properties from bulk properties",
          "abstract": "Surface elasticity is central to understanding the mechanics and stability of surfaces and interfaces. It is characterized by quantities such as surface tension, residual surface stress, and surface stiffness, however their analytical expressions are typically difficult to derive from atomistic data, and depend strongly on modeling choices. This work presents a neural network-based equation learner which combines customized activation functions and connection-based pruning to discover parsimonious, closed-form equations for surface elasticity from atomistic simulations. Applying the method to seven face centered cubic (FCC) metals, our equation learner uncovers interpretable equations that describe both low-Miller index and high-Miller index surface properties, capturing long-tail property distributions accurately. The discovered expressions are decoupled into two components: a universal, geometry-driven orientation function, and material-specific baseline coefficients. We find that lower-order properties such as surface tension are fundamentally geometry dependent, while higher-order properties such as surface stress and elasticity show more complex geometry and material dependence. We also relate material dependent coefficients to bulk properties, forming a clear map from bulk material properties to surface elasticity. Overall, this approach demonstrates that interpretable neurosymbolic machine learning can bridge the gap between atomistic simulations and physical laws, enabling the discovery of generalizable structure-property relationships for materials science phenomena such as surface elasticity.",
          "authors": [
            "Saaketh Desai",
            "Prasad P. Iyer",
            "Remi Dingreville"
          ],
          "primary_category": "cond-mat.mtrl-sci",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02987",
          "title": "Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic",
          "abstract": "Recent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision. This work introduces a novel framework that inputs English sentences, converts them into logical expressions, and then translates them into Conjunctive Normal Form (CNF) for satisfiability solving. It employs classical NLP techniques with self-defined grammar, symbolic computation libraries, and a fine-tuned language model to reduce hallucinations. In the early experiments, we observed that the fine-tuned model, trained on different grammar settings, could intentionally correct the same types of hallucinations made by the original model. Thus, it provides reliable CNF generation.",
          "authors": [
            "Muyu Pan",
            "Dheeraj Kodakandla",
            "Mahfuza Farooque"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02991",
          "title": "GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection",
          "abstract": "Despite significant progress in 3D object detection, point clouds remain challenging due to sparse data, incomplete structures, and limited semantic information. Capturing contextual relationships between distant objects presents additional difficulties. To address these challenges, we propose GraphFusion3D, a unified framework combining multi-modal fusion with advanced feature learning. Our approach introduces the Adaptive Cross-Modal Transformer (ACMT), which adaptively integrates image features into point representations to enrich both geometric and semantic information. For proposal refinement, we introduce the Graph Reasoning Module (GRM), a novel mechanism that models neighborhood relationships to simultaneously capture local geometric structures and global semantic context. The module employs multi-scale graph attention to dynamically weight both spatial proximity and feature similarity between proposals. We further employ a cascade decoder that progressively refines detections through multi-stage predictions. Extensive experiments on SUN RGB-D (70.6\\% AP$_{25}$ and 51.2\\% AP$_{50}$) and ScanNetV2 (75.1\\% AP$_{25}$ and 60.8\\% AP$_{50}$) demonstrate a substantial performance improvement over existing approaches.",
          "authors": [
            "Md Sohag Mia",
            "Md Nahid Hasan",
            "Tawhid Ahmed",
            "Muhammad Abdullah Adnan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.02993",
          "title": "TEXTRIX: Latent Attribute Grid for Native Texture Generation and Beyond",
          "abstract": "Prevailing 3D texture generation methods, which often rely on multi-view fusion, are frequently hindered by inter-view inconsistencies and incomplete coverage of complex surfaces, limiting the fidelity and completeness of the generated content. To overcome these challenges, we introduce TEXTRIX, a native 3D attribute generation framework for high-fidelity texture synthesis and downstream applications such as precise 3D part segmentation. Our approach constructs a latent 3D attribute grid and leverages a Diffusion Transformer equipped with sparse attention, enabling direct coloring of 3D models in volumetric space and fundamentally avoiding the limitations of multi-view fusion. Built upon this native representation, the framework naturally extends to high-precision 3D segmentation by training the same architecture to predict semantic attributes on the grid. Extensive experiments demonstrate state-of-the-art performance on both tasks, producing seamless, high-fidelity textures and accurate 3D part segmentation with precise boundaries.",
          "authors": [
            "Yifei Zeng",
            "Yajie Bao",
            "Jiachen Qian",
            "Shuang Wu",
            "Youtian Lin",
            "Hao Zhu",
            "Buyu Li",
            "Feihu Zhang",
            "Xun Cao",
            "Yao Yao"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03000",
          "title": "DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling",
          "abstract": "Understanding the dynamic physical world, characterized by its evolving 3D structure, real-world motion, and semantic content with textual descriptions, is crucial for human-agent interaction and enables embodied agents to perceive and act within real environments with human-like capabilities. However, existing datasets are often derived from limited simulators or utilize traditional Structurefrom-Motion for up-to-scale annotation and offer limited descriptive captioning, which restricts the capacity of foundation models to accurately interpret real-world dynamics from monocular videos, commonly sourced from the internet. To bridge these gaps, we introduce DynamicVerse, a physical-scale, multimodal 4D world modeling framework for dynamic real-world video. We employ large vision, geometric, and multimodal models to interpret metric-scale static geometry, real-world dynamic motion, instance-level masks, and holistic descriptive captions. By integrating window-based Bundle Adjustment with global optimization, our method converts long real-world video sequences into a comprehensive 4D multimodal format. DynamicVerse delivers a large-scale dataset consists of 100K+ videos with 800K+ annotated masks and 10M+ frames from internet videos. Experimental evaluations on three benchmark tasks, namely video depth estimation, camera pose estimation, and camera intrinsics estimation, demonstrate that our 4D modeling achieves superior performance in capturing physical-scale measurements with greater global accuracy than existing methods.",
          "authors": [
            "Kairun Wen",
            "Yuzhi Huang",
            "Runyu Chen",
            "Hui Zheng",
            "Yunlong Lin",
            "Panwang Pan",
            "Chenxin Li",
            "Wenyan Cong",
            "Jian Zhang",
            "Junbin Lu",
            "Chenguo Lin",
            "Dilin Wang",
            "Zhicheng Yan",
            "Hongyu Xu",
            "Justin Theiss",
            "Yue Huang",
            "Xinghao Ding",
            "Rakesh Ranjan",
            "Zhiwen Fan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03001",
          "title": "Invasive Context Engineering to Control Large Language Models",
          "abstract": "Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.",
          "authors": [
            "Thomas Rivasseau"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03004",
          "title": "DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images",
          "abstract": "Autonomous driving needs fast, scalable 4D reconstruction and re-simulation for training and evaluation, yet most methods for dynamic driving scenes still rely on per-scene optimization, known camera calibration, or short frame windows, making them slow and impractical. We revisit this problem from a feedforward perspective and introduce \\textbf{Driving Gaussian Grounded Transformer (DGGT)}, a unified framework for pose-free dynamic scene reconstruction. We note that the existing formulations, treating camera pose as a required input, limit flexibility and scalability. Instead, we reformulate pose as an output of the model, enabling reconstruction directly from sparse, unposed images and supporting an arbitrary number of views for long sequences. Our approach jointly predicts per-frame 3D Gaussian maps and camera parameters, disentangles dynamics with a lightweight dynamic head, and preserves temporal consistency with a lifespan head that modulates visibility over time. A diffusion-based rendering refinement further reduces motion/interpolation artifacts and improves novel-view quality under sparse inputs. The result is a single-pass, pose-free algorithm that achieves state-of-the-art performance and speed. Trained and evaluated on large-scale driving benchmarks (Waymo, nuScenes, Argoverse2), our method outperforms prior work both when trained on each dataset and in zero-shot transfer across datasets, and it scales well as the number of input frames increases.",
          "authors": [
            "Xiaoxue Chen",
            "Ziyi Xiong",
            "Yuantao Chen",
            "Gen Li",
            "Nan Wang",
            "Hongcheng Luo",
            "Long Chen",
            "Haiyang Sun",
            "Bing Wang",
            "Guang Chen",
            "Hangjun Ye",
            "Hongyang Li",
            "Ya-Qin Zhang",
            "Hao Zhao"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03005",
          "title": "From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?",
          "abstract": "The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.",
          "authors": [
            "Dawei Li",
            "Abdullah Alnaibari",
            "Arslan Bisharat",
            "Manny Sandoval",
            "Deborah Hall",
            "Yasin Silva",
            "Huan Liu"
          ],
          "primary_category": "cs.AI",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03010",
          "title": "SurfFill: Completion of LiDAR Point Clouds via Gaussian Surfel Splatting",
          "abstract": "LiDAR-captured point clouds are often considered the gold standard in active 3D reconstruction. While their accuracy is exceptional in flat regions, the capturing is susceptible to miss small geometric structures and may fail with dark, absorbent materials. Alternatively, capturing multiple photos of the scene and applying 3D photogrammetry can infer these details as they often represent feature-rich regions. However, the accuracy of LiDAR for featureless regions is rarely reached. Therefore, we suggest combining the strengths of LiDAR and camera-based capture by introducing SurfFill: a Gaussian surfel-based LiDAR completion scheme. We analyze LiDAR capturings and attribute LiDAR beam divergence as a main factor for artifacts, manifesting mostly at thin structures and edges. We use this insight to introduce an ambiguity heuristic for completed scans by evaluating the change in density in the point cloud. This allows us to identify points close to missed areas, which we can then use to grow additional points from to complete the scan. For this point growing, we constrain Gaussian surfel reconstruction [Huang et al. 2024] to focus optimization and densification on these ambiguous areas. Finally, Gaussian primitives of the reconstruction in ambiguous areas are extracted and sampled for points to complete the point cloud. To address the challenges of large-scale reconstruction, we extend this pipeline with a divide-and-conquer scheme for building-sized point cloud completion. We evaluate on the task of LiDAR point cloud completion of synthetic and real-world scenes and find that our method outperforms previous reconstruction methods.",
          "authors": [
            "Svenja Strobel",
            "Matthias Innmann",
            "Bernhard Egger",
            "Marc Stamminger",
            "Linus Franke"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03013",
          "title": "In-Context Sync-LoRA for Portrait Video Editing",
          "abstract": "Editing portrait videos is a challenging task that requires flexible yet precise control over a wide range of modifications, such as appearance changes, expression edits, or the addition of objects. The key difficulty lies in preserving the subject's original temporal behavior, demanding that every edited frame remains precisely synchronized with the corresponding source frame. We present Sync-LoRA, a method for editing portrait videos that achieves high-quality visual modifications while maintaining frame-accurate synchronization and identity consistency. Our approach uses an image-to-video diffusion model, where the edit is defined by modifying the first frame and then propagated to the entire sequence. To enable accurate synchronization, we train an in-context LoRA using paired videos that depict identical motion trajectories but differ in appearance. These pairs are automatically generated and curated through a synchronization-based filtering process that selects only the most temporally aligned examples for training. This training setup teaches the model to combine motion cues from the source video with the visual changes introduced in the edited first frame. Trained on a compact, highly curated set of synchronized human portraits, Sync-LoRA generalizes to unseen identities and diverse edits (e.g., modifying appearance, adding objects, or changing backgrounds), robustly handling variations in pose and expression. Our results demonstrate high visual fidelity and strong temporal coherence, achieving a robust balance between edit fidelity and precise motion preservation.",
          "authors": [
            "Sagi Polaczek",
            "Or Patashnik",
            "Ali Mahdavi-Amiri",
            "Daniel Cohen-Or"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03014",
          "title": "Instant Video Models: Universal Adapters for Stabilizing Image-Based Networks",
          "abstract": "When applied sequentially to video, frame-based networks often exhibit temporal inconsistency - for example, outputs that flicker between frames. This problem is amplified when the network inputs contain time-varying corruptions. In this work, we introduce a general approach for adapting frame-based models for stable and robust inference on video. We describe a class of stability adapters that can be inserted into virtually any architecture and a resource-efficient training process that can be performed with a frozen base network. We introduce a unified conceptual framework for describing temporal stability and corruption robustness, centered on a proposed accuracy-stability-robustness loss. By analyzing the theoretical properties of this loss, we identify the conditions where it produces well-behaved stabilizer training. Our experiments validate our approach on several vision tasks including denoising (NAFNet), image enhancement (HDRNet), monocular depth (Depth Anything v2), and semantic segmentation (DeepLabv3+). Our method improves temporal stability and robustness against a range of image corruptions (including compression artifacts, noise, and adverse weather), while preserving or improving the quality of predictions.",
          "authors": [
            "Matthew Dutson",
            "Nathan Labiosa",
            "Yin Li",
            "Mohit Gupta"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03018",
          "title": "AutoBrep: Autoregressive B-Rep Generation with Unified Topology and Geometry",
          "abstract": "The boundary representation (B-Rep) is the standard data structure used in Computer-Aided Design (CAD) for defining solid models. Despite recent progress, directly generating B-Reps end-to-end with precise geometry and watertight topology remains a challenge. This paper presents AutoBrep, a novel Transformer model that autoregressively generates B-Reps with high quality and validity. AutoBrep employs a unified tokenization scheme that encodes both geometric and topological characteristics of a B-Rep model as a sequence of discrete tokens. Geometric primitives (i.e., surfaces and curves) are encoded as latent geometry tokens, and their structural relationships are defined as special topological reference tokens. Sequence order in AutoBrep naturally follows a breadth first traversal of the B-Rep face adjacency graph. At inference time, neighboring faces and edges along with their topological structure are progressively generated. Extensive experiments demonstrate the advantages of our unified representation when coupled with next-token prediction for B-Rep generation. AutoBrep outperforms baselines with better quality and watertightness. It is also highly scalable to complex solids with good fidelity and inference speed. We further show that autocompleting B-Reps is natively supported through our unified tokenization, enabling user-controllable CAD generation with minimal changes. Code is available at this https URL .",
          "authors": [
            "Xiang Xu",
            "Pradeep Kumar Jayaraman",
            "Joseph G. Lambourne",
            "Yilin Liu",
            "Durvesh Malpure",
            "Pete Meltzer"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03019",
          "title": "Distribution-Calibrated Inference time compute for Thinking LLM-as-a-Judge",
          "abstract": "Thinking Large Language Models (LLMs) used as judges for pairwise preferences remain noisy at the single-sample level, and common aggregation rules (majority vote, soft self-consistency, or instruction-based self-aggregation) are inconsistent when ties are allowed. We study inference-time compute (ITC) for evaluators that generate n independent thinking-rating samples per item, and propose a principled, distribution-calibrated aggregation scheme. Our method models three-way preferences with a Bradley-Terry-Davidson formulation on rating counts, leveraging both polarity (margin among non-ties) and decisiveness (non-tie rate) to distinguish narrow margins from strong consensus. Across various evaluation benchmarks, our approach consistently reduces MAE and increases pairwise accuracy versus standard baselines, and when evaluated against human-consensus meta-labels, matches or exceeds individual human raters. These results show that carefully allocating ITC and aggregating with distribution-aware methods turns noisy individual model judgments into reliable ratings for evaluation.",
          "authors": [
            "Hamid Dadkhahi",
            "Firas Trabelsi",
            "Parker Riley",
            "Juraj Juraska",
            "Mehdi Mirzazadeh"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03020",
          "title": "Unrolled Networks are Conditional Probability Flows in MRI Reconstruction",
          "abstract": "Magnetic Resonance Imaging (MRI) offers excellent soft-tissue contrast without ionizing radiation, but its long acquisition time limits clinical utility. Recent methods accelerate MRI by under-sampling $k$-space and reconstructing the resulting images using deep learning. Unrolled networks have been widely used for the reconstruction task due to their efficiency, but suffer from unstable evolving caused by freely-learnable parameters in intermediate steps. In contrast, diffusion models based on stochastic differential equations offer theoretical stability in both medical and natural image tasks but are computationally expensive. In this work, we introduce flow ODEs to MRI reconstruction by theoretically proving that unrolled networks are discrete implementations of conditional probability flow ODEs. This connection provides explicit formulations for parameters and clarifies how intermediate states should evolve. Building on this insight, we propose Flow-Aligned Training (FLAT), which derives unrolled parameters from the ODE discretization and aligns intermediate reconstructions with the ideal ODE trajectory to improve stability and convergence. Experiments on three MRI datasets show that FLAT achieves high-quality reconstructions with up to $3\\times$ fewer iterations than diffusion-based generative models and significantly greater stability than unrolled networks.",
          "authors": [
            "Kehan Qi",
            "Saumya Gupta",
            "Qingqiao Hu",
            "Weimin Lyu",
            "Chao Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03021",
          "title": "Semiparametric Robust Estimation of Population Location",
          "abstract": "Real-world measurements often comprise a dominant signal contaminated by a noisy background. Robustly estimating the dominant signal in practice has been a fundamental statistical problem. Classically, mixture models have been used to cluster the heterogeneous population into homogeneous components. Modeling such data with fully parametric models risks bias under misspecification, while fully nonparametric approaches can dissipate power and computational resources. We propose a middle path: a semiparametric method that models only the dominant component parametrically and leaves the background completely nonparametric, yet remains computationally scalable and statistically robust. So instead of outlier downweighting, traditionally done in robust statistics literature, we maximize the observed likelihood such that the noisy background is absorbed by the nonparametric component. Computationally, we propose a new approximate FFT-accelerated likelihood maximization algorithm. Empirically, this FFT plug-in achieves order-of-magnitude speedups over vanilla weighted EM while preserving statistical accuracy and large sample properties.",
          "authors": [
            "Ananyabrata Barua",
            "Ayanendranath Basu"
          ],
          "primary_category": "stat.CO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03024",
          "title": "TokenPowerBench: Benchmarking the Power Consumption of LLM Inference",
          "abstract": "Large language model (LLM) services now answer billions of queries per day, and industry reports show that inference, not training, accounts for more than 90% of total power consumption. However, existing benchmarks focus on either training/fine-tuning or performance of inference and provide little support for power consumption measurement and analysis of inference. We introduce TokenPowerBench, the first lightweight and extensible benchmark designed for LLM-inference power consumption studies. The benchmark combines (i) a declarative configuration interface covering model choice, prompt set, and inference engine, (ii) a measurement layer that captures GPU-, node-, and system-level power without specialized power meters, and (iii) a phase-aligned metrics pipeline that attributes energy to the prefill and decode stages of every request. These elements make it straight-forward to explore the power consumed by an LLM inference run; furthermore, by varying batch size, context length, parallelism strategy and quantization, users can quickly assess how each setting affects joules per token and other energy-efficiency metrics. We evaluate TokenPowerBench on four of the most widely used model series (Llama, Falcon, Qwen, and Mistral). Our experiments cover from 1 billion parameters up to the frontier-scale Llama3-405B model. Furthermore, we release TokenPowerBench as open source to help users to measure power consumption, forecast operating expenses, and meet sustainability targets when deploying LLM services.",
          "authors": [
            "Chenxu Niu",
            "Wei Zhang",
            "Jie Li",
            "Yongjian Zhao",
            "Tongyang Wang",
            "Xi Wang",
            "Yong Chen"
          ],
          "primary_category": "cs.LG",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03025",
          "title": "LORE: A Large Generative Model for Search Relevance",
          "abstract": "Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceiling. We argue this stems from treating relevance as a monolithic task, lacking principled deconstruction. Our key insight is that relevance comprises distinct capabilities: knowledge and reasoning, multi-modal matching, and rule adherence. We contend that a qualitative-driven decomposition is essential for breaking through current performance bottlenecks. Contributions. LORE provides a complete blueprint for the LLM relevance lifecycle. Key contributions include: (1) A two-stage training paradigm combining progressive CoT synthesis via SFT with human preference alignment via RL. (2) A comprehensive benchmark, RAIR, designed to evaluate these core capabilities. (3) A query frequency-stratified deployment strategy that efficiently transfers offline LLM capabilities to the online system. LORE serves as both a practical solution and a methodological reference for other vertical domains.",
          "authors": [
            "Chenji Lu",
            "Zhuo Chen",
            "Hui Zhao",
            "Zhiyuan Zeng",
            "Gang Zhao",
            "Junjie Ren",
            "Ruicong Xu",
            "Haoran Li",
            "Songyan Liu",
            "Pengjie Wang",
            "Jian Xu",
            "Bo Zheng"
          ],
          "primary_category": "cs.IR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03026",
          "title": "The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models",
          "abstract": "The rapid advancement and adaptability of Large Language Models (LLMs) highlight the need for moral consistency, the capacity to maintain ethically coherent reasoning across varied contexts. Existing alignment frameworks, structured approaches designed to align model behavior with human ethical and social norms, often rely on static datasets and post-hoc evaluations, offering limited insight into how ethical reasoning may evolve across different contexts or temporal scales. This study presents the Moral Consistency Pipeline (MoCoP), a dataset-free, closed-loop framework for continuously evaluating and interpreting the moral stability of LLMs. MoCoP combines three supporting layers: (i) lexical integrity analysis, (ii) semantic risk estimation, and (iii) reasoning-based judgment modeling within a self-sustaining architecture that autonomously generates, evaluates, and refines ethical scenarios without external supervision. Our empirical results on GPT-4-Turbo and DeepSeek suggest that MoCoP effectively captures longitudinal ethical behavior, revealing a strong inverse relationship between ethical and toxicity dimensions (correlation rET = -0.81, p value less than 0.001) and a near-zero association with response latency (correlation rEL approximately equal to 0). These findings demonstrate that moral coherence and linguistic safety tend to emerge as stable and interpretable characteristics of model behavior rather than short-term fluctuations. Furthermore, by reframing ethical evaluation as a dynamic, model-agnostic form of moral introspection, MoCoP offers a reproducible foundation for scalable, continuous auditing and advances the study of computational morality in autonomous AI systems.",
          "authors": [
            "Saeid Jamshidi",
            "Kawser Wazed Nafi",
            "Arghavan Moradi Dakhel",
            "Negar Shahabi",
            "Foutse Khomh"
          ],
          "primary_category": "cs.CL",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03028",
          "title": "SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control",
          "abstract": "Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In this work, we present Score-Matching Motion Priors (SMP), which leverages pre-trained motion diffusion models and score distillation sampling (SDS) to create reusable task-agnostic motion priors. SMPs can be pre-trained on a motion dataset, independent of any control policy or task. Once trained, SMPs can be kept frozen and reused as general-purpose reward functions to train policies to produce naturalistic behaviors for downstream tasks. We show that a general motion prior trained on large-scale datasets can be repurposed into a variety of style-specific priors. Furthermore SMP can compose different styles to synthesize new styles not present in the original dataset. Our method produces high-quality motion comparable to state-of-the-art adversarial imitation learning methods through reusable and modular motion priors. We demonstrate the effectiveness of SMP across a diverse suite of control tasks with physically simulated humanoid characters. Video demo available at this https URL",
          "authors": [
            "Yuxuan Mu",
            "Ziyu Zhang",
            "Yi Shi",
            "Minami Matsumoto",
            "Kotaro Imamura",
            "Guy Tevet",
            "Chuan Guo",
            "Michael Taylor",
            "Chang Shu",
            "Pengcheng Xi",
            "Xue Bin Peng"
          ],
          "primary_category": "cs.GR",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03034",
          "title": "MAViD: A Multimodal Framework for Audio-Visual Dialogue Understanding and Generation",
          "abstract": "We propose MAViD, a novel Multimodal framework for Audio-Visual Dialogue understanding and generation. Existing approaches primarily focus on non-interactive systems and are limited to producing constrained and unnatural human this http URL primary challenge of this task lies in effectively integrating understanding and generation capabilities, as well as achieving seamless multimodal audio-video fusion. To solve these problems, we propose a Conductor-Creator architecture that divides the dialogue system into two primary this http URL Conductor is tasked with understanding, reasoning, and generating instructions by breaking them down into motion and speech components, thereby enabling fine-grained control over interactions. The Creator then delivers interactive responses based on these this http URL , to address the difficulty of generating long videos with consistent identity, timbre, and tone using dual DiT structures, the Creator adopts a structure that combines autoregressive (AR) and diffusion models. The AR model is responsible for audio generation, while the diffusion model ensures high-quality video this http URL , we propose a novel fusion module to enhance connections between contextually consecutive clips and modalities, enabling synchronized long-duration audio-visual content this http URL experiments demonstrate that our framework can generate vivid and contextually coherent long-duration dialogue interactions and accurately interpret users' multimodal queries.",
          "authors": [
            "Youxin Pang",
            "Jiajun Liu",
            "Lingfeng Tan",
            "Yong Zhang",
            "Feng Gao",
            "Xiang Deng",
            "Zhuoliang Kang",
            "Xiaoming Wei",
            "Yebin Liu"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03035",
          "title": "Learning Physically Consistent Lagrangian Control Models Without Acceleration Measurements",
          "abstract": "This article investigates the modeling and control of Lagrangian systems involving non-conservative forces using a hybrid method that does not require acceleration calculations. It focuses in particular on the derivation and identification of physically consistent models, which are essential for model-based control synthesis. Lagrangian or Hamiltonian neural networks provide useful structural guarantees but the learning of such models often leads to inconsistent models, especially on real physical systems where training data are limited, partial and noisy. Motivated by this observation and the objective to exploit these models for model-based nonlinear control, a learning algorithm relying on an original loss function is proposed to improve the physical consistency of Lagrangian systems. A comparative analysis of different learning-based modeling approaches with the proposed solution shows significant improvements in terms of physical consistency of the learned models, on both simulated and experimental systems. The model's consistency is then exploited to demonstrate, on an experimental benchmark, the practical relevance of the proposed methodology for feedback linearization and energy-based control techniques.",
          "authors": [
            "Ibrahim Laiche",
            "Mokrane Boudaoud",
            "Patrick Gallinari",
            "Pascal Morin"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03035",
          "title": "Learning Physically Consistent Lagrangian Control Models Without Acceleration Measurements",
          "abstract": "This article investigates the modeling and control of Lagrangian systems involving non-conservative forces using a hybrid method that does not require acceleration calculations. It focuses in particular on the derivation and identification of physically consistent models, which are essential for model-based control synthesis. Lagrangian or Hamiltonian neural networks provide useful structural guarantees but the learning of such models often leads to inconsistent models, especially on real physical systems where training data are limited, partial and noisy. Motivated by this observation and the objective to exploit these models for model-based nonlinear control, a learning algorithm relying on an original loss function is proposed to improve the physical consistency of Lagrangian systems. A comparative analysis of different learning-based modeling approaches with the proposed solution shows significant improvements in terms of physical consistency of the learned models, on both simulated and experimental systems. The model's consistency is then exploited to demonstrate, on an experimental benchmark, the practical relevance of the proposed methodology for feedback linearization and energy-based control techniques.",
          "authors": [
            "Ibrahim Laiche",
            "Mokrane Boudaoud",
            "Patrick Gallinari",
            "Pascal Morin"
          ],
          "primary_category": "eess.SY",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03036",
          "title": "ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation",
          "abstract": "Despite progress in video-to-audio generation, the field focuses predominantly on mono output, lacking spatial immersion. Existing binaural approaches remain constrained by a two-stage pipeline that first generates mono audio and then performs spatialization, often resulting in error accumulation and spatio-temporal inconsistencies. To address this limitation, we introduce the task of end-to-end binaural spatial audio generation directly from silent video. To support this task, we present the BiAudio dataset, comprising approximately 97K video-binaural audio pairs spanning diverse real-world scenes and camera rotation trajectories, constructed through a semi-automated pipeline. Furthermore, we propose ViSAudio, an end-to-end framework that employs conditional flow matching with a dual-branch audio generation architecture, where two dedicated branches model the audio latent flows. Integrated with a conditional spacetime module, it balances consistency between channels while preserving distinctive spatial characteristics, ensuring precise spatio-temporal alignment between audio and the input video. Comprehensive experiments demonstrate that ViSAudio outperforms existing state-of-the-art methods across both objective metrics and subjective evaluations, generating high-quality binaural audio with spatial immersion that adapts effectively to viewpoint changes, sound-source motion, and diverse acoustic environments. Project website: this https URL .",
          "authors": [
            "Mengchen Zhang",
            "Qi Chen",
            "Tong Wu",
            "Zihan Liu",
            "Dahua Lin"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03040",
          "title": "Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation",
          "abstract": "We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires semantic localization, instruction following, and planning. Both tasks use video-only inputs, without auxiliary modalities such as depth or poses. With simple yet effective design choices in the framework and data curation, Video4Spatial demonstrates strong spatial understanding from video context: it plans navigation and grounds target objects end-to-end, follows camera-pose instructions while maintaining spatial consistency, and generalizes to long contexts and out-of-domain environments. Taken together, these results advance video generative models toward general visuospatial reasoning.",
          "authors": [
            "Zeqi Xiao",
            "Yiwei Zhao",
            "Lingxiao Li",
            "Yushi Lan",
            "Yu Ning",
            "Rahul Garg",
            "Roshni Cooper",
            "Mohammad H. Taghavi",
            "Xingang Pan"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03041",
          "title": "MultiShotMaster: A Controllable Multi-Shot Video Generation Framework",
          "abstract": "Current video generation techniques excel at single-shot clips but struggle to produce narrative multi-shot videos, which require flexible shot arrangement, coherent narrative, and controllability beyond text prompts. To tackle these challenges, we propose MultiShotMaster, a framework for highly controllable multi-shot video generation. We extend a pretrained single-shot model by integrating two novel variants of RoPE. First, we introduce Multi-Shot Narrative RoPE, which applies explicit phase shift at shot transitions, enabling flexible shot arrangement while preserving the temporal narrative order. Second, we design Spatiotemporal Position-Aware RoPE to incorporate reference tokens and grounding signals, enabling spatiotemporal-grounded reference injection. In addition, to overcome data scarcity, we establish an automated data annotation pipeline to extract multi-shot videos, captions, cross-shot grounding signals and reference images. Our framework leverages the intrinsic architectural properties to support multi-shot video generation, featuring text-driven inter-shot consistency, customized subject with motion control, and background-driven customized scene. Both shot count and duration are flexibly configurable. Extensive experiments demonstrate the superior performance and outstanding controllability of our framework.",
          "authors": [
            "Qinghe Wang",
            "Xiaoyu Shi",
            "Baolu Li",
            "Weikang Bian",
            "Quande Liu",
            "Huchuan Lu",
            "Xintao Wang",
            "Pengfei Wan",
            "Kun Gai",
            "Xu Jia"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03042",
          "title": "PPTArena: A Benchmark for Agentic PowerPoint Editing",
          "abstract": "We introduce PPTArena, a benchmark for PowerPoint editing that measures reliable modifications to real slides under natural-language instructions. In contrast to image-PDF renderings or text-to-slide generation, PPTArena focuses on in-place editing across 100 decks, 2125 slides, and over 800 targeted edits covering text, charts, tables, animations, and master-level styles. Each case includes a ground-truth deck, a fully specified target outcome, and a dual VLM-as-judge pipeline that separately scores instruction following and visual quality using both structural diffs and slide images. Building on this setting, we propose PPTPilot, a structure-aware slide-editing agent that plans semantic edit sequences, routes between high-level programmatic tools and deterministic XML operations for precise control, and verifies outputs through an iterative plan-edit-check loop against task-specific constraints. In our experiments, PPTPilot outperforms strong proprietary agents and frontier VLM systems by over 10 percentage points on compound, layout-sensitive, and cross-slide edits, with particularly large gains in visual fidelity and deck-wide consistency. Despite these improvements, existing agents still underperform on long-horizon, document-scale tasks in PPTArena, highlighting the remaining challenges in reliable PPT editing.",
          "authors": [
            "Michael Ofengenden",
            "Yunze Man",
            "Ziqi Pang",
            "Yu-Xiong Wang"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03043",
          "title": "OneThinker: All-in-one Reasoning Model for Image and Video",
          "abstract": "Reinforcement learning (RL) has recently achieved remarkable success in eliciting visual reasoning within Multimodal Large Language Models (MLLMs). However, existing approaches typically train separate models for different tasks and treat image and video reasoning as disjoint domains. This results in limited scalability toward a multimodal reasoning generalist, which restricts practical versatility and hinders potential knowledge sharing across tasks and modalities. To this end, we propose OneThinker, an all-in-one reasoning model that unifies image and video understanding across diverse fundamental visual tasks, including question answering, captioning, spatial and temporal grounding, tracking, and segmentation. To achieve this, we construct the OneThinker-600k training corpus covering all these tasks and employ commercial models for CoT annotation, resulting in OneThinker-SFT-340k for SFT cold start. Furthermore, we propose EMA-GRPO to handle reward heterogeneity in multi-task RL by tracking task-wise moving averages of reward standard deviations for balanced optimization. Extensive experiments on diverse visual benchmarks show that OneThinker delivers strong performance on 31 benchmarks, across 10 fundamental visual understanding tasks. Moreover, it exhibits effective knowledge transfer between certain tasks and preliminary zero-shot generalization ability, marking a step toward a unified multimodal reasoning generalist. All code, model, and data are released.",
          "authors": [
            "Kaituo Feng",
            "Manyuan Zhang",
            "Hongyu Li",
            "Kaixuan Fan",
            "Shuang Chen",
            "Yilei Jiang",
            "Dian Zheng",
            "Peiwen Sun",
            "Yiyuan Zhang",
            "Haoze Sun",
            "Yan Feng",
            "Peng Pei",
            "Xunliang Cai",
            "Xiangyu Yue"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03044",
          "title": "Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling",
          "abstract": "Robust perception and dynamics modeling are fundamental to real-world robotic policy learning. Recent methods employ video diffusion models (VDMs) to enhance robotic policies, improving their understanding and modeling of the physical world. However, existing approaches overlook the coherent and physically consistent motion representations inherently encoded across frames in VDMs. To this end, we propose Video2Act, a framework that efficiently guides robotic action learning by explicitly integrating spatial and motion-aware representations. Building on the inherent representations of VDMs, we extract foreground boundaries and inter-frame motion variations while filtering out background noise and task-irrelevant biases. These refined representations are then used as additional conditioning inputs to a diffusion transformer (DiT) action head, enabling it to reason about what to manipulate and how to move. To mitigate inference inefficiency, we propose an asynchronous dual-system design, where the VDM functions as the slow System 2 and the DiT head as the fast System 1, working collaboratively to generate adaptive actions. By providing motion-aware conditions to System 1, Video2Act maintains stable manipulation even with low-frequency updates from the VDM. For evaluation, Video2Act surpasses previous state-of-the-art VLA methods by 7.7% in simulation and 21.7% in real-world tasks in terms of average success rate, further exhibiting strong generalization capabilities.",
          "authors": [
            "Yueru Jia",
            "Jiaming Liu",
            "Shengbang Liu",
            "Rui Zhou",
            "Wanhe Yu",
            "Yuyang Yan",
            "Xiaowei Chi",
            "Yandong Guo",
            "Boxin Shi",
            "Shanghang Zhang"
          ],
          "primary_category": "cs.RO",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03045",
          "title": "CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models",
          "abstract": "Multi-view diffusion models have recently emerged as a powerful paradigm for novel view synthesis, yet the underlying mechanism that enables their view-consistency remains unclear. In this work, we first verify that the attention maps of these models acquire geometric correspondence throughout training, attending to the geometrically corresponding regions across reference and target views for view-consistent generation. However, this correspondence signal remains incomplete, with its accuracy degrading under large viewpoint changes. Building on these findings, we introduce CAMEO, a simple yet effective training technique that directly supervises attention maps using geometric correspondence to enhance both the training efficiency and generation quality of multi-view diffusion models. Notably, supervising a single attention layer is sufficient to guide the model toward learning precise correspondences, thereby preserving the geometry and structure of reference images, accelerating convergence, and improving novel view synthesis performance. CAMEO reduces the number of training iterations required for convergence by half while achieving superior performance at the same iteration counts. We further demonstrate that CAMEO is model-agnostic and can be applied to any multi-view diffusion model.",
          "authors": [
            "Minkyung Kwon",
            "Jinhyeok Choi",
            "Jiho Park",
            "Seonghu Jeon",
            "Jinhyuk Jang",
            "Junyoung Seo",
            "Minseop Kwak",
            "Jin-Hwa Kim",
            "Seungryong Kim"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        },
        {
          "id": "arXiv:2512.03046",
          "title": "MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues",
          "abstract": "We propose MagicQuill V2, a novel system that introduces a \\textbf{layered composition} paradigm to generative image editing, bridging the gap between the semantic power of diffusion models and the granular control of traditional graphics software. While diffusion transformers excel at holistic generation, their use of singular, monolithic prompts fails to disentangle distinct user intentions for content, position, and appearance. To overcome this, our method deconstructs creative intent into a stack of controllable visual cues: a content layer for what to create, a spatial layer for where to place it, a structural layer for how it is shaped, and a color layer for its palette. Our technical contributions include a specialized data generation pipeline for context-aware content integration, a unified control module to process all visual cues, and a fine-tuned spatial branch for precise local editing, including object removal. Extensive experiments validate that this layered approach effectively resolves the user intention gap, granting creators direct, intuitive control over the generative process.",
          "authors": [
            "Zichen Liu",
            "Yue Yu",
            "Hao Ouyang",
            "Qiuyu Wang",
            "Shuailei Ma",
            "Ka Leong Cheng",
            "Wen Wang",
            "Qingyan Bai",
            "Yuxuan Zhang",
            "Yanhong Zeng",
            "Yixuan Li",
            "Xing Zhu",
            "Yujun Shen",
            "Qifeng Chen"
          ],
          "primary_category": "cs.CV",
          "published": "2025-12-03T00:00:00+08:00",
          "updated": "2025-12-03T00:00:00+08:00"
        }
      ]
    }
  ],
  "noise": [
    "arXiv:2310.10419",
    "arXiv:2310.10419",
    "arXiv:2502.16292",
    "arXiv:2502.16292",
    "arXiv:2512.00347",
    "arXiv:2512.00347",
    "arXiv:2512.01904",
    "arXiv:2512.01904",
    "arXiv:2512.01904",
    "arXiv:2512.02075",
    "arXiv:2512.02140",
    "arXiv:2512.02140",
    "arXiv:2512.02190",
    "arXiv:2512.02695",
    "arXiv:2512.02695",
    "arXiv:2512.02811",
    "arXiv:2512.02811",
    "arXiv:2512.02859",
    "arXiv:2512.02875",
    "arXiv:2512.02884"
  ]
}