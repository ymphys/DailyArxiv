[
  {
    "id": "arXiv:2512.03120",
    "title": "Enhanced slow magnetic-Coriolis waves with magnetic field orthogonal to rotation axis",
    "abstract": "We consider an isolated Gaussian velocity vortex perturbation in an otherwise quiescent, electrically conducting, and rotating fluid permeated by a uniform magnetic field $\\bf{B}$. Studies suggest a presence of strong azimuthal wave motions on the timescale of centuries within the Earth's liquid outer core at higher latitudes. To understand these long-period oscillations, we focus on magnetostrophic waves, a slow component of magnetic-Coriolis waves with $\\bf{B}$ orthogonally aligned with the rotation vector $\\bf{\\Omega}$, which replicate the field lines in the azimuthal direction. We present an analytical solution to the magnetic-Coriolis wave equation in Cartesian coordinates. Later, with numerical solution, we validate our analytical estimates and show that magnetostrophic waves travel relatively faster along the magnetic field when $\\bf{B} \\perp \\bf{\\Omega}$ compared with the case when both are aligned. The study confirms that with a magnetic field $\\bf{B}$ orthogonally aligned to the rotation vector $\\bf{\\Omega}$, wave vectors satisfying the condition $\\bf{\\Omega}\\cdot\\bf{k} \\approx 0$, travel with Alfvén velocities along the magnetic field lines as a component of inertial-Alfvén waves. The timescales on which Alfvén waves travel are relatively short, and it is also less likely that inertial-Alfvén waves will be sustained inside the core at higher latitudes \\citep{Davidson2017}. This study shows that, excluding the inertial-Alfvén waves contribution ($k_z\\neq 0$), there exists intensified magnetostrophic wave propagation when $\\bf{B} \\perp \\bf{\\Omega}$, which can explain the strong periodic oscillations on the time scales of centuries along the azimuthal field at higher latitudes. Results show persistence of the magnetostrophic waves despite the lower Lehnert number $Le$, suggesting the plausible existence of a low-intensity azimuthal magnetic field in the Earth's core.",
    "authors": [
      "Raviraj Narayan Shinde",
      "Ghanesh Narasimhan"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03128",
    "title": "Characterization of debris disks observed with SPHERE",
    "abstract": "This study aims to characterize debris disks observed with SPHERE across multiple programs, with the goal of identifying systematic trends in disk morphology, dust mass, and grain properties as a function of stellar parameters. We analyzed a sample of 161 young stars using SPHERE observations at optical and near-IR wavelengths. Disk geometries were derived from ellipse fitting and model grids, while dust mass and properties were constrained by modified blackbody (MBB) and size distribution (SD) modeling of SEDs. The dynamical modeling was performed to assess whether the observed disk structures can be explained by the presence of unseen planets. We resolved 51 debris disks, including four new detections: HD 36968, BD-20 951, and the inner belts of HR 8799 and HD 36546. In addition, we found a second transiting giant planet in the HD 114082 system, with a radius of 1.29 $R_{\\rm Jup}$ and an orbital distance of ~1 au. We identified nine multi-belt systems, with outer-to-inner belt radius ratios of $1.5-2$, and found close agreement between scattered-light and millimeter-continuum belt radii. They scale weakly with stellar luminosity ($R_{\\rm belt} \\propto L_{\\star}^{0.11}$), but show steeper dependencies when separated by CO and CO$_2$ freeze-out regimes. Disk fractional luminosities follow collisional decay trends, declining as $t_{\\rm age}^{-1.18}$ for A and $t_{\\rm age}^{-0.81}$ for F stars. The inferred dust masses span $10^{-5}-1\\,M_\\oplus$ from MBB and $0.01-1\\,M_\\oplus$ from SD modeling. These masses scale as $R_{\\rm belt}^n$ with $n>2$ in belt radius and super-linearly with stellar mass, consistent with trends seen in protoplanetary disks. Analysing correlation between disk polarized flux and IR excess, we found an offset of ~1 dex between total-intensity (HST) and polarized fluxes. A new parametric approach to estimate dust albedo and maximum polarization fraction is introduced.",
    "authors": [
      "N. Engler",
      "J. Milli",
      "N. Pawellek",
      "R. Gratton",
      "P. Thébault",
      "C. Lazzoni",
      "J. Olofsson",
      "H. M. Schmid",
      "S. Ulmer-Moll",
      "C. Perrot",
      "J.-C. Augereau",
      "S. Desidera",
      "G. Chauvin",
      "M. Janson",
      "C. Xie",
      "Th. Henning",
      "A. Boccaletti",
      "S. B. Brown-Sevilla",
      "E. Choquet",
      "C. Dominik",
      "M. Samland",
      "A. Zurlo",
      "M. Feldt",
      "T. Fusco",
      "C. Ginski",
      "J. H. Girard",
      "D. Gisler",
      "R. G. van Holstein",
      "M. Langlois",
      "A.-L. Maire",
      "D. Mesa",
      "P. Rabou",
      "L. Rodet",
      "T. Schmidt",
      "A. Vigan"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03129",
    "title": "Taming the Tarantula: How Stellar Wind Feedback Shapes Gas and Dust in 30 Doradus",
    "abstract": "Observations of massive star-forming regions show that classical stellar wind models over-predict the luminosity of the X-ray emitting gas, indicating a significant fraction of wind energy is lost. In this paper, we present a multi-wavelength analysis of the giant HII region 30 Doradus and its central star cluster R136 using 2 Ms of Chandra X-ray Observatory data, combined with James Webb Space Telescope and Hubble Space Telescope imaging and Spitzer spectral-energy distributions, to investigate how the hot gas energy is lost through turbulent mixing, radiative cooling, and physical leakage. We compare the spatial and spectral properties of the hot gas with those of the warm ionized gas and dust. We find no significant correlation between the dust and hot gas temperatures, suggesting they are not directly coupled and that the dust resides in the swept-up shells where it is heated radiatively. H$\\alpha$ and X-ray surface brightness profiles show that the X-rays peak interior to the H$\\alpha$ shells, demonstrating partial confinement of the hot gas. The fragmented shell structure and bright X-ray interior that declines near the H$\\alpha$ shell reflect efficient cooling from turbulent mixing at the hot-cold interface. We compare against recent simulations of stellar-feedback driven bubbles which have broad agreement with the morphology of the X-ray and H$\\alpha$ emission, but the simulations produce a dip in the interior X-ray surface brightness and a lack of hard X-rays compared to the observations. These differences may suggest thermal conduction is important as mass-loading of the hot bubble could reproduce the X-ray observables.",
    "authors": [
      "Jennifer A. Rodriguez",
      "Laura A. Lopez",
      "Lachlan Lancaster",
      "Anna L. Rosen",
      "Omnarayani Nayak",
      "Sebastian Lopez",
      "Tyler Holland-Ashford",
      "Trinity L. Webb"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03130",
    "title": "A Critical Evaluation of the Physical Nature of the Little Red Dots",
    "abstract": "Little Red Dots (LRDs) are a newly identified class of active galactic nuclei (AGNs) uncovered by JWST deep surveys. Their enigmatic properties challenge the canonical AGN paradigm and have stimulated ideas on early massive black hole (BH) formation. In this review, we summarize how early BHs shape the characteristic features of LRDs, how their nuclear environments differ from those of normal AGNs, and how future observations can distinguish between competing scenarios. Our main conclusions are as follows: (1) LRDs show broad-line emission consistent with mass accretion onto BHs with $M_{\\rm BH}\\simeq 10^{6-7}~M_\\odot$, suggesting that AGN activity is a plausible origin of their dominant red optical emission. (2) Stellar components can reproduce the continuum energetics through dusty star formation. However, the required stellar mass would be too large to remain consistent with other LRD properties. Therefore, a purely stellar origin is unlikely to be the dominant power source, although star formation may still contribute to the UV emission. (3) The coexistence of broad-line emission with Balmer absorption and break features on LRD spectra, neither of which can be explained by stellar populations, suggests that nuclear BHs are enshrouded by dense gas with a high covering fraction. (4) Gas-enshrouded AGNs can produce red optical spectra without requiring dust reddening through a combination of gas attenuation and thermal self-emission with an effective temperature of $T_{\\rm eff}\\simeq 5000~{\\rm K}$, which also accounts for the flat infrared continuum. (5) From the spectral features and redshift evolution, LRDs are likely a transient phase in early BH growth, possibly the first accretion episodes of newborn BHs. (6) Testing models for LRD spectra and origins through time variability, ionizing sources, post-LRD objects, and low-redshift analogs is particularly promising.",
    "authors": [
      "Kohei Inayoshi",
      "Luis C. Ho"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03132",
    "title": "The DREAMS Project: Disentangling the Impact of Halo-to-Halo Variance and Baryonic Feedback on Milky Way Dark Matter Density Profiles",
    "abstract": "Astrophysical searches for dark matter in the Milky Way require a reliable model for its density distribution, which in turn depends on the influence of baryonic feedback on the Galaxy. In this work, we utilize a new suite of Milky Way-mass halos from the DREAMS Project, simulated with Cold Dark Matter (CDM),to quantify the influence of baryon feedback and intrinsic halo-to-halo variance on dark matter density profiles. Our suite of 1024 halos varies over supernova and black hole feedback parameters from the IllustrisTNG model, as well as variations in two cosmological parameters. We find that Milky Way-mass dark matter density profiles in the IllustrisTNG model are largely insensitive to astrophysics and cosmology variations, with the dominant source of scatter instead arising from halo-to-halo variance. However, most of the (comparatively minor) feedback-driven variations come from the changes to supernova prescriptions. By comparing to dark matter-only simulations, we find that the strongest supernova wind energies are so effective at preventing galaxy formation that the halos are nearly entirely collisionless dark matter. Finally, regardless of physics variation, all the DREAMS halos are roughly consistent with a halo contracting adiabatically from the presence of baryons, unlike models that have bursty stellar feedback. This work represents a step toward assessing the robustness of Milky Way dark matter profiles, with direct implications for dark matter searches where systematic uncertainty in the density profile remains a major challenge.",
    "authors": [
      "Alex M. Garcia",
      "Jonah C. Rose",
      "Paul Torrey",
      "Andrea Caputo",
      "Mariangela Lisanti",
      "Andrew B. Pace",
      "Hongwan Liu",
      "Abdelaziz Hussein",
      "Haozhe Liu",
      "Francisco Villaescusa-Navarro",
      "John Barry",
      "Ilem Leisher",
      "Belén Costanza",
      "Jonathan Kho",
      "Ethan Lilie",
      "Jiaxuan Li",
      "Niusha Ahvazi",
      "Aklant Bhowmick",
      "Tri Nguyen",
      "Stephanie O'Neil",
      "Xiaowei Ou",
      "Xuejian Shen",
      "Arya Farahi",
      "Nitya Kallivayalil",
      "Lina Necib",
      "Mark Vogelsberger"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03134",
    "title": "The Mass-Metallicity Relation and its Observational Effects at z~3-6",
    "abstract": "The correlation between galaxy stellar mass and gas-phase metallicity, known as the mass-metallicity relation (MZR), gives key insights into the processes that govern galaxy evolution. However, unquantified observational and selection biases can result in systematic errors in attempts to recover the intrinsic MZR, particularly at higher redshifts. We characterize the MZR at z~3-6 within a fully Bayesian framework using JWST NIRSpec spectra of 193 galaxies from the RUBIES survey. We forward model the observed mass-metallicity surface using prospector-generated spectra to account for two selection biases: the survey selection function and success in observing high signal-to-noise emission lines. We demonstrate that the RUBIES selection function, based on F444W magnitude and F150W-F444W color, has a negligible effect on our measured MZR. A correct treatment of the non-Gaussian metallicity uncertainties from strong-line calibrations lowers the derived MZR normalization by 0.2 dex and flattens the slope by ~20%; forward-modeling the effect of emission line observability steepens the slope by ~15%. Both of these biases must be taken into account in order to properly measure the intrinsic MZR. This novel forward modeling process motivates careful consideration of selection functions in future surveys, and paves the way for robust, high-redshift chemical enrichment studies that trace the evolution of the mass-metallicity relation across cosmic time.",
    "authors": [
      "Zach Lewis",
      "Michael V. Maseda",
      "Anna de Graaff",
      "Joel Leja",
      "Bingjie Wang",
      "Hans-Walter Rix",
      "Ian McConachie",
      "Nikko J. Cleri",
      "Rachel Bezanson",
      "Leindert A. Boogaard",
      "Gabriel Brammer",
      "Jenny E. Greene",
      "Michaela Hirschmann",
      "Harley Katz",
      "Ivo Labbe",
      "Jorryt Matthee",
      "Tim B. Miller",
      "Rohan P. Naidu",
      "Pascal A. Oesch",
      "David J. Setton",
      "Katherine A. Suess",
      "Andrea Weibel",
      "Katherine E. Whitaker",
      "Christina C. Williams"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03136",
    "title": "GRB 230204B: GIT Discovery of a Fast Fading Afterglow Associated with an Energetic GRB from a Massive-Star Progenitor",
    "abstract": "We present a comprehensive multi-wavelength study of a bright gamma-ray burst GRB 230204B, analyzing both prompt and afterglow emissions. This GRB is highly energetic, with an isotropic equivalent energy emission $E_{\\mathrm{iso}} \\sim 2.2 \\times 10^{54}\\ \\mathrm{erg}$, released during the prompt emission. The GROWTH-India Telescope discovered a bright afterglow ($m_r = 15.55$) that faded rapidly ($\\propto t^{-1.82}$). The prompt emission shows strong thermal photospheric emission, along with a non-thermal high-energy component. We explore the evolution of these components and find them to be consistent with theoretical expectations. Afterglow modeling reveals an energetic jet $E_{tot} \\gtrsim 10^{52}\\ \\mathrm{erg}$ expanding into a wind-type medium viewed nearly on-axis, suggesting a massive star progenitor with strong winds. We also explore correlations between the prompt emission and afterglow that may help to understand the complete picture of GRB progenitors.",
    "authors": [
      "Vishwajeet Swain",
      "Varun Bhalerao",
      "Harsh Kumar",
      "Mehul Goyal",
      "Ankur Ghosh",
      "Utkarsh Pathak",
      "Poonam Chandra",
      "Tomas Ahumada",
      "G. C. Anupama",
      "Suman Bala",
      "Sudhanshu Barway",
      "Joshua S. Bloom",
      "Dimple Dimple",
      "Viraj R. Karambelkar",
      "Mansi M. Kasliwal",
      "Kuntal Misra",
      "Josiah Purdum",
      "Divita Saraogi",
      "Jesper Sollerman",
      "Aswin Suresh",
      "Stefan J. van der Walt",
      "Gaurav Waratkar"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03139",
    "title": "Cosmology after Phantom Crossing by Horndeski Gravity",
    "abstract": "One possible way to explain the observed effective dark energy equation of state crossing $w=-1$ (the phantom divide) is through modified gravity. A key point is to not view the expansion history in isolation but to take into account the other gravitational impacts on growth of large scale structure, lensing, etc. Within shift symmetric Horndeski gravity this implies three main paths for the late time cosmic expansion. All require unusual kinetic structure and we analyze their various implications for how $w$ should behave after phantom crossing.",
    "authors": [
      "Eric V. Linder"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03140",
    "title": "A Wind-Driven Origin for the Firework Morphology of the Supernova Remnant Pa 30",
    "abstract": "Pa 30 -- the likely remnant of the Galactic type Iax supernova of 1181 AD -- displays an unusual, firework-like morphology, consisting of radial filaments extending from a common center, where a white dwarf (WD) currently drives a very fast wind (speed $\\gtrsim 10^{4}$ km s$^{-1}$). We propose the filaments arose from the Rayleigh-Taylor-unstable nature of the interface between the circumstellar medium (CSM) and the shocked wind launched by the natal WD; the filaments then elongated intact due to the Kelvin-Helmholtz-stable nature of the large initial density contrast between the wind and CSM, supplemented by the slowly declining wind density profile (relative to homologously expanding ejecta). To support this interpretation, we present two-dimensional hydrodynamical simulations and derive the filament properties, including their speed, density, and temperature, all of which are consistent with observations. We suggest the filaments elongate until the wind and CSM densities become comparable at the contact discontinuity, which occurs within 1--10 years, and then truncate because the RTI halts. The subsequent KHI growth timescale across the current width of the filaments is longer than the age of Pa 30, so they remain intact. The filament-less central region in Pa 30 is therefore more likely a consequence of the finite timescale over which the RTI operates, rather than a wind termination shock. In general, firework-like filaments may form in other systems, provided there is a sufficiently large density contrast between the ejecta and its surroundings.",
    "authors": [
      "Eric R. Coughlin",
      "Greg Salvesen",
      "Dheeraj R. Pasham"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03143",
    "title": "Infrared emission from $z \\sim 6.5$ quasar host galaxies: a direct estimate of dust physical properties",
    "abstract": "Quasars at the dawn of Cosmic Time ($z>6$) are fundamental probes to investigate the early co-evolution of supermassive black holes and their host galaxy. Nevertheless, their infrared spectral energy distribution remains at the present time poorly constrained, due to the limited photometric coverage probing the far-infrared wavelength range where the dust modified black-body is expected to peak ($\\sim80$ $\\mathrm{\\mu m}$). Here we present a study of the high-frequency dust emission via a dedicated ALMA Band 8 ($\\sim$400 GHz) campaign targeting 11 quasar host galaxies at $6<z<7$. Combined with archival observations in other ALMA bands, this program enables a detailed characterization of their infrared emission, allowing for the derivation of dust masses ($M_{d}$), dust emissivity indexes ($\\beta$), dust temperatures ($T_{d}$), infrared luminosities ($L_{IR}$), and associated star formation rates (SFRs). Our analysis confirms that dust temperature is on average higher in this sample (34-65 K) if compared to local main-sequence galaxies' values, and that this finding can be linked to the increased star formation efficiency we derive in our work, as also suggested by the [CII]$_{158\\mu m}$ deficit. Most remarkably, we note that the average value of $T_d$ of this sample doesn't differ from the one that is observed in luminous, ultra-luminous and hyper-luminous infrared galaxies at different redshifts that show no signs of hosting a quasar. Finally, our findings suggest that the presence of a bright AGN does not significantly bias the derived infrared properties, although further high-frequency, high-spatial resolution observations might reveal more subtle impacts on sub-kiloparsec scales.",
    "authors": [
      "M. Costa",
      "R. Decarli",
      "F. Pozzi",
      "P. Cox",
      "R. A. Meyer",
      "A. Pensabene",
      "B. P. Venemans",
      "F. Walter",
      "F. Xu"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03145",
    "title": "On the Origin of Gas-stripping of Galaxies in Group Environments",
    "abstract": "We investigate how low-mass group environments ($M_{\\rm vir} \\sim 10^{12-13}\\,M_{\\odot}$) influence the gas content of their satellite galaxies with $M_* > 10^{7}\\,M_{\\odot}$ using the \\NHtwo\\ simulation. Many satellite galaxies preserve substantial gas reservoirs, yet show signs of outer gas stripping, reminiscent of jellyfish galaxies in clusters. In contrast, low-mass satellites ($<10^8 \\, M_{\\odot}$) are largely gas-deficient, and some of them undergo gas removal within their host group by external pressure triggered by either galaxy interactions or ram pressure exerted by the hot intragroup medium. Complete gas removal in these satellite galaxies occurs when the external hydrodynamic pressure exceeds the gravitational restoring force, typically due to stochastic events such as galaxy-galaxy interaction or nearby galactic outflows. The emergence of a characteristic stellar mass of $10^8 \\, M_{\\odot}$ which determines the efficiency of gas removal in groups, likely reflects the differing scaling relations of external pressure with halo mass and gravitational restoring force with stellar mass. While tidal interactions can be a significant cause of gas loss in satellite galaxies, those severe enough to affect the gas content in the central regions typically lead to the complete disruption of the galaxy. Consequently, gas loss driven by tidal interactions may be underestimated in the studies focusing solely on surviving galaxies. Group environments, where environmental effects are weaker and satellite galaxies tend to have lower restoring forces due to their low masses, exhibit complex manifestations of gas loss that are not seen in more massive environments such as clusters.",
    "authors": [
      "Jinsu Rhee",
      "Christophe Pichon",
      "Yohan Dubois",
      "Sukyoung K. Yi",
      "Jongwan Ko",
      "Yun-Kyeong Sheen",
      "San Han",
      "Seyoung Jeon",
      "J. K. Jang",
      "Wonki Lee",
      "Emanuele Contini",
      "Bumhyun Lee",
      "Jaehyun Lee",
      "Katarina Kraljic",
      "Sébastien Peirani"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03150",
    "title": "Joint JWST-DECam Lensing Reveals That the Bullet Cluster Is a Minor Merger",
    "abstract": "We present the first robust virial masses of the Bullet Cluster's three individual components from a joint weak+strong lensing analysis combining JWST/NIRCam and DECam observations. Despite its status as the benchmark system for dark matter and merger studies, inferred mass ratios for the Bullet Cluster have spanned a wide range from $\\sim$2:1 to $\\gtrsim$10:1 over more than two decades. We revisit this tension through three key advances: (1) JWST's exceptional data quality enables us to resolve three distinct halos, (2) DECam's wide-field coverage beyond its virial radius eliminates the need for extrapolation, and (3) high-fidelity strong-lensing priors mitigate weak-lensing model bias. We obtain $M_{200c} = 15.11^{+2.48}_{-2.10} \\times 10^{14}M_{\\odot}$ for the main cluster and $1.49^{+0.32}_{-0.25} \\times 10^{14}M_{\\odot}$ for the subcluster, yielding a mass ratio of $10.14^{+3.22}_{-2.47}$, definitively classifying the Bullet Cluster as a minor merger. This result reconciles the long-standing tension in the mass ratio and provides updated initial parameters for future modeling of this iconic system.",
    "authors": [
      "Boseong Young Cho",
      "M. James Jee",
      "Hyungjin Joo",
      "Sangjun Cha",
      "Kim HyeongHan"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03151",
    "title": "Bright Region Reset: an on-detector strategy for minimizing the impacts of atmospheric emission lines on spectral observations",
    "abstract": "Observations in the near-infrared using large ground-based telescopes are adversely impacted by bright atmospheric emission lines, particularly the OH Meinel bands. These lines can saturate a moderate-resolution spectrograph on the order of minutes, resulting in information loss at the wavelengths of the lines. OH lines also vary on similar timescales, requiring frequent sky exposures to be able to subtract the sky spectrum from that of the target. In this paper we present a new method, which we call bright region reset (BRR), to prevent the saturation of these lines in near-infrared spectra while simultaneously improving information about their variability. This is accomplished by periodically resetting pixels that contain bright lines on a detector capable of sub-window readout while the rest of the detector continues integrating. This method is demonstrated on the McKellar Spectrograph in the 1.2 m telescope at the Dominion Astrophysical Observatory in Victoria, Canada. Using a Teledyne H2RG detector, we reset the emission lines produced by an arc lamp while still recording their flux. We show no degradation in the resulting spectrum compared to a conventional observing mode. Unlike other OH line mitigation strategies, the BRR method not only avoids loss of information at wavelengths containing the lines, but also provides higher-cadence information on sky line variability, making it a promising technique for implementation at observatories. We advocate demonstrating this method on sky at existing 8--10 m class facilities with near-infrared spectrographs equipped with HxRG detectors in order to test its feasibility for use in sky subtraction schemes for premier modern spectrographs, including the upcoming generation of instruments for the Extremely Large Telescopes.",
    "authors": [
      "Theodore A. Grosson",
      "Edward L. Chapin",
      "Tim Hardy",
      "Masen Lamb",
      "Jordan Lothrop",
      "Alan W. McConnachie",
      "Richard Murowinski"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03154",
    "title": "An Ancient Descendant of the First Galaxies",
    "abstract": "JWST has revealed unexpectedly bright galaxies in the first 500 Myr after the Big Bang. Their overabundance suggests that they are preferentially observed during burst phases, where their star formation rates increase dramatically. In cosmological simulations, such bursts transition into short ($\\approx 40$ Myr) periods without star formation or naps. Using JWST/NIRCam medium-band observations, we report the discovery of the galaxy CANUCS-A370-2228423 ($z = 5.95 \\pm 0.06$, $\\log(M_\\ast/M_{\\odot}) = 9.14 \\pm 0.09$), dubbed The Sleeper. Its star formation history indicates rapid assembly in the first 300 Myr ($z \\gtrsim 14$), where it formed a $\\log(M_\\ast/M_{\\odot}) = 8.7^{+0.3}_{-0.4}\\ M_{\\odot}$ progenitor, comparable in stellar mass to the few spectroscopically confirmed galaxies at those redshifts. Unexpectedly, this is followed by several hundred million years of suppressed star formation, in stark contrast to nappers. This results in a remarkably strong hydrogen Balmer break, exceeding that of any galaxy observed within the first billion years by a factor of $\\approx 3$. Furthermore, Sleeper-like systems are overabundant in the observed survey volume compared to theory, as the probability of finding such galaxies in simulations is $< 0.2\\%$. The discovery of The Sleeper therefore disrupts the current narrative that all luminous galaxies in the first few hundred million years grow into massive descendants. Instead it presents an alternative evolutionary pathway in which these unusually luminous galaxies fade into inefficient dwarfs after an early starburst, revealing greater diversity in the first stages of galaxy evolution.",
    "authors": [
      "Jacqueline Antwi-Danso",
      "Adam Muzzin",
      "Luke Robbins",
      "Yoshihisa Asada",
      "Danilo Marchesini",
      "Marcin Sawicki",
      "Kartheik Iyer",
      "Kate Whitaker",
      "Joshua Speagle",
      "Casey Papovich",
      "Chris Willott",
      "Maruša Bradač",
      "Guillaume Desprez",
      "Vladan Markov",
      "Nicholas Martis",
      "Gaël Noirot",
      "Ghassan Sarrouh",
      "Rahul Kannan",
      "Roberto Abraham",
      "Seiji Fujimoto",
      "Katherine Myers"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03156",
    "title": "High-angular-resolution ALMA imaging of the inhomogeneous dynamical atmosphere of the asymptotic giant branch star W Hya",
    "abstract": "We present high-angular-resolution imaging of the asymptotic giant branch star W Hya with the Atacama Large Millimeter/submillimeter Array (ALMA) to probe the dynamics and chemistry in the atmosphere and inner wind. W Hya was observed with the longest baselines of ALMA at 250-268 GHz with an angular resolution of ~17x20 mas. ALMA's high angular resolution allowed us to resolve the stellar disk of W Hya, along with clumpy, irregularly shaped emission extending to ~100 mas: plume in the north-northwest, a tail in the south-southwest, and the extended atmosphere elongated in the east-northeast--west-southwest direction, with semimajor and semiminor axes of ~70 and 40 mas (~3.4 and 1.9 Rstar), respectively. We identified 57 lines, which include SiO, H2O, SO2, SO, HCN, AlO, AlOH, TiO, TiO2, OH, and some of their isotopologues. The molecular line images show spatially inhomogeneous molecular formation. Our ALMA data taken at phase 0.53 (minimum light) indicate global, accelerating infall within ~75 mas (3.6 Rstar) but also outflow at up to ~10 km/s in deeper layers. While 38 of the detected lines appear in absorption against the continuum stellar disk as expected, we detect nonthermal emission on top of the continuum over the stellar disk in 19 lines of SiO, H2O, SO2, and AlO. The emission of SiO, AlO, TiO, TiO2, SO, and SO2 coincides well with the clumpy dust cloud distribution obtained from contemporaneous visible polarimetric imaging in addition to H2O reported in our previous work. This lends support to the idea that SiO, H2O, and AlO are directly involved in grain nucleation. The overlap of SO/SO2 (possibly also TiO/TiO2) with the dust clouds suggests the formation of these molecules and dust behind shocks induced by pulsation and/or convection. We detect HCN emission close to the star, down to ~30 mas (~1.4 Rstar), which is consistent with shock-induced chemistry.",
    "authors": [
      "K. Ohnaka",
      "K. T. Wong",
      "G. Weigelt",
      "K.-H. Hofmann"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03159",
    "title": "A Catalogue of Interstellar Material Delivery From Nearby Debris Disks",
    "abstract": "We modeled the trajectories of material ejected from 20 nearby debris disk stars, including Epsilon Eridani (Ran), Vega, Fomalhaut, and Beta Pictoris, within a simulated Milky Way potential in order to quantify their contribution to the population of interstellar material entering the solar system. Our simulations show that material from each of these 20 systems is currently to be expected within our planetary system. We calculate expected fluxes of both macroscopic interstellar objects (ISOs, $\\geq100~$m), which could be detected by telescopic surveys, and smaller meteoroids ($\\geq200~$microns), which could manifest as meteors in Earth's atmosphere. We estimate that the ISO population originating from these debris disks and currently within the inner solar system is on the order of ~2, only a fraction of the expected total ISO population but nonetheless likely to be discovered by Rubin. Meteors in Earth's atmosphere from these systems are expected as well, but current methods, both radar and video, might require decades to collect even a single event. Our sample is found to be rich in relatively low excess velocity particles compared to the broader expected ISO population, which might make them harder to distinguish observationally from bound objects in some cases. These results provide a framework for linking detections of interstellar material to their astrophysical origins, offering new opportunities to probe the composition and dynamical history of nearby planetary systems.",
    "authors": [
      "Cole R. Gregg",
      "Paul A. Wiegert"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03168",
    "title": "The Origins of the Bulk flow",
    "abstract": "We analyze the origin of the large scale bulk flow using the CosmicFlows 4 (CF4) peculiar velocity catalog. We decompose the observed motions into internal components, generated by mass fluctuations within 200Mpc/h, and external ones arising from structures beyond this volume. A weighted average technique is developed to test the model's self consistency while minimizing the impact of non Gaussian distance errors. The CF4 velocities show excellent agreement with the predicted internal field, yielding beta = 0.31 pm 0.01. We also determine that the value of the Hubble constant that should be used for calculating peculiar velocities from the CF4 to be H0 = 75.9 pm 0.1 km/s/ Mpc, consistent with CF4 calibrations. Using the minimum variance formalism, we further separate the bulk flow into its internal and external contributions and find that the observed large scale bulk flow is dominated by sources beyond 200Mpc/h. The amplitude of this externally driven flow increases monotonically with scale, consistent with the influence of a distant, massive overdensity. These findings reinforce the reliability of the CF4 velocity field while calling into question the assumption of a spatially uniform flow generated by external sources. Our results challenge the commonly made assumption that the flow in our local volume due to external mass concentrations can be modeled as being spatially uniform.",
    "authors": [
      "Richard Watkins",
      "Hume A. Feldman"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03169",
    "title": "Magnetic Field Amplification and Particle Acceleration in Weakly Magnetized Trans-relativistic Electron-ion Shocks",
    "abstract": "We investigate the physics of quasi-parallel trans-relativistic shocks propagating in weakly magnetized plasmas by means of long-duration two-dimensional particle-in-cell simulations. The structure of the shock precursor is shaped by a competition between the Bell instability and the Weibel instability. The Bell instability is dominant at relatively high magnetizations $(\\sigma\\gtrsim10^{-3})$, whereas the Weibel instability prevails at lower magnetizations $(\\sigma\\lesssim10^{-4})$. Bell-dominated shocks efficiently accelerate ions, converting a fraction $\\varepsilon_{\\mathrm{i}}\\sim0.2$ of the upstream flow energy into downstream nonthermal ion energy. The maximum energy of nonthermal ions exhibits a Bohm scaling in time, as $E_{\\max}\\propto t$. A much smaller fraction $\\varepsilon_{\\mathrm{e}}\\ll0.1$ of the upstream flow energy goes into downstream nonthermal electrons in the Bell-dominated regime. On the other hand, Weibel-dominated shocks efficiently generate both nonthermal ions and electrons with $\\varepsilon_{\\mathrm{i}}\\sim\\varepsilon_{\\mathrm{e}}\\sim0.1$, albeit with a slower scaling for the maximum energy, $E_{\\mathrm{max}}\\propto t^{1/2}$. Our results are applicable to a wide range of trans-relativistic shocks, including the termination shocks of extragalactic jets, the late stages of gamma-ray burst afterglows, and shocks in fast blue optical transients.",
    "authors": [
      "Taiki Jikei",
      "Daniel Groselj",
      "Lorenzo Sironi"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03178",
    "title": "TDCOSMO. XXIV. Measurement of the Hubble constant from the doubly lensed quasar HE1104-1805",
    "abstract": "Time-delay cosmography leverages strongly lensed quasars to measure the Universe's current expansion rate, H_0, independently from other methods. While the latest TDCOSMO results relied mainly on quadruply lensed quasars, doubly lensed systems are far more common and offer precise time delays, potentially enlarging the usable sample by a factor of five and enabling percent-level constraints on H_0. We present the first TDCOSMO analysis of a doubly imaged source, HE1104-1805, including the measurement of the four necessary ingredients. First, by combining 17 years of data from the SMARTS, Euler and WFI telescopes, we measure a time delay of 176.3\\pm 10.8 days. Second, using MUSE data, we extract stellar velocity dispersion measurements in three radial bins with up to 5% precision. Third, employing F160W HST imaging for lens modelling and marginalising over various modelling choices, we measure the Fermat potential difference between the images. Fourth, using wide-field imaging, we measure the convergence added by objects not included in the lens modelling. Hence, we measure the time delay distance and the angular diameter distance to the deflector, favouring a power-law mass model over a baryonic and dark matter composite model. The measurement was performed blindly and yielded H_0 = 64.2^{+5.8}_{-5.0} x $\\lambda_{int} km s^{-1} Mpc^{-1}, where \\lambda_{int} is the internal mass sheet degeneracy parameter. This is in agreement with the TDCOSMO-2025 milestone and its precision for \\lambda_{int}=1 is comparable to that obtained with the best-observed quadruply lensed quasars (4-6%). This work is a stepping stone towards a precise measurement of H_0 using a large sample of doubly lensed quasars, supplementing the current sample. The next TDCOSMO milestone paper will include this system in its hierarchical analysis, constraining \\lambda_{int} and H_0 jointly with multiple lenses.",
    "authors": [
      "Eric Paic",
      "Frédéric Courbin",
      "Christopher D. Fassnacht",
      "Aymeric Galan",
      "Martin Millon",
      "Dominique Sluse",
      "Devon M. Williams",
      "Simon Birrer",
      "Elizabeth J. Buckley-Geer",
      "Michele Cappellari",
      "Frédéric Dux",
      "Xiang-Yu Huang",
      "Shawn Knabel",
      "Cameron Lemon",
      "Anowar J. Shajib",
      "Sherry H. Suyu",
      "TommasoTreu",
      "Kenneth C. Wong",
      "Lise Christensen",
      "Veronica Motta",
      "Alessandro Sonnenfeld"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03184",
    "title": "The Extent of Solar Energetic Particle Irradiation in the Sun's Protoplanetary Disk",
    "abstract": "Solar flares emit X rays and high-energy (MeV-GeV) ions (Solar Energetic Particles, or SEPs). Astronomical observations show solar mass-protostellar fluxes are a factor $\\Phi \\approx 3 \\times 10^2 - 3 \\times 10^3$ times higher than the present-day Sun. Constraining $\\Phi$ in the early solar system is important for modeling ionization in the Sun's protoplanetary disk, the extent of magnetorotational instability or magnetocentrifugal outflows, or even production of short-lived radionuclides. Recent interpretations of meteoritic data -- cosmogenic Ne in hibonite grains, initial $({}^{10}{\\rm Be}/{}^{9}{\\rm Be})_0$ ratios in Ca-rich, Al-rich inclusions (CAIs), or even inferences of live ${}^{7}{\\rm Be}$ in CAIs -- have suggested values $\\Phi > 10^5$, even as large as $\\Phi \\approx 6 \\times 10^6$, which would make the young Sun extraordinarily active, even for a protostar. We constrain $\\Phi$ by re-examining these data. We conclude: cosmogenic Ne was produced in hibonite grains as they resided in the disk; ${}^{36}{\\rm Cl}$ was created in Cl-poor grains after the disk dissipated; ${}^{10}{\\rm Be}$ was inherited from the molecular cloud, with almost no ($< 1\\%$) ${}^{10}{\\rm Be}$ created in the disk; and there is no evidence whatsoever for any live ${}^{7}{\\rm Be}$ in CAIs. We show these data are consistent with a value $\\Phi \\approx 3 \\times 10^3$ for the first $> 5$ Myr of the solar nebula. The early Sun evidently emitted a flux of X rays and SEPs not atypical for a protostar.",
    "authors": [
      "Steven J. Desch",
      "Ashley K. Herbst",
      "Richard L. Hervig",
      "Benjamin Jacobsen"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03192",
    "title": "New Method for Investigating the Presence of Extragalactic Magnetic Fields",
    "abstract": "The extragalactic magnetic field could be detected by searching for signatures of the electromagnetic cascade initiated by high-energy photons on the intergalactic radiation and deflected by the field. This process produces a time delay and an extended gamma-ray halo around the source, which are looked for. We propose a new signature of electromagnetic echoes: the asymmetry of the gamma-ray distribution around blazars. As a measure of asymmetry, we use the offset of the gamma-ray distribution to the location of the blazar. This offset is due to the tilt of the jet of the blazar relative to the line of sight. Using a subsample of the 10 brightest BL Lacs, we exclude the range of extragalactic magnetic fields from $10^{-16}$ to $10^{-14}$ G, assuming that these objects have maintained a constant average luminosity over hundreds of thousands of years.",
    "authors": [
      "Boris Stern",
      "Igor Tkachev"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03209",
    "title": "Interferometric Detection and Orbit Modeling of the Subcomponent in the Hot-dust System $κ$ Tuc A: A Low-mass Star on an Eccentric Orbit in a Hierarchical-quintuple System",
    "abstract": "The system $\\kappa$ Tuc A is part of a hierarchical-quintuple system and is a prime target for studies of hot-exozodiacal dust, because a time-variable near-infrared excess has been detected. We observed the system with the Multi Aperture mid-Infrared Spectroscopic Experiment (MATISSE) and GRAVITY at the Very Large Telescope Interferometer, and detected the stellar companion to the primary $\\kappa$ Tuc Aa that was previously inferred by astrometry, $\\kappa$ Tuc Ab. Its $L$-band flux ratio to the primary is 1.32% and its signature in the MATISSE closure phases is mostly smaller than +/- 2°, which makes $\\kappa$ Tuc Ab the highest-contrast companion ever detected with MATISSE closure phases. We verified with GRAVITY that relative astrometry with milliarcsecond precision can be retrieved from MATISSE closure phases. Using multiple epochs of observations, we obtain a full orbital solution for $\\kappa$ Tuc Ab. Its orbit has an eccentricity of 0.94 and a semi-major axis of 4.8au. The orbit of $\\kappa$ Tuc Ab and the orbit of the wider separation companion $\\kappa$ Tuc B are mutually inclined. Based on the measured flux ratio of $\\kappa$ Tuc Ab to Aa and their dynamical mass, we estimate the spectral type of $\\kappa$ Tuc Ab to be M3.5V to M4.5V. While the then unknown star $\\kappa$ Tuc Ab might have caused the putative detection of hot-exozodiacal dust around $\\kappa$ Tuc Aa in 2012 and 2014, this cannot be for the detection in 2019, giving rise to an intriguing system architecture. This motivates studies investigating the interplay of the low-mass star on an eccentric orbit, the hot-exozodiacal dust, and a possible planetesimal reservoir.",
    "authors": [
      "T. A. Stuber",
      "A. Mérand",
      "F. Kirchschlager",
      "S. Wolf",
      "G. Weible",
      "O. Absil",
      "T. D. Pearce",
      "G. Garreau",
      "J.-C. Augereau",
      "W. C. Danchi",
      "D. Defrère",
      "V. Faramaz-Gorka",
      "J. W. Isbell",
      "J. Kobus",
      "A. V. Krivov",
      "R. Laugier",
      "K. Ollmann",
      "R. G. Petrov",
      "P. Priolet",
      "J. P. Scott",
      "K. Tsishchankava",
      "S. Ertel"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03226",
    "title": "The DESI DR1 Peculiar Velocity Survey: Fundamental Plane Catalogue",
    "abstract": "Measurements of peculiar velocities in the local Universe are a powerful tool to study the nature of dark energy at low ($z < 0.1$) redshifts. Here we present the largest single set of $z<0.1$ peculiar velocity measurements to date, obtained using the Fundamental Plane (FP) of galaxies in the first data release (DR1) of the Dark Energy Spectroscopic Instrument (DESI). We describe the photometric and spectroscopic selection criteria used to define the sample, as well as extensive quality control checks on the photometry and velocity dispersion measurements. Additionally, we perform detailed systematics checks for the many analysis parameters in our pipeline. Our DESI DR1 catalogue contains FP-based distances and peculiar velocities for $98,292$ unique early-type galaxies, increasing the total number of $z < 0.1$ FP distances ever measured by a factor of $\\sim2$. We achieve a precision of $26\\%$ random error in our distance measurements which is comparable to previous surveys. A series of companion DESI papers use the distances and peculiar velocities presented in this paper to measure cosmological parameters.",
    "authors": [
      "C. E. Ross",
      "C. Howlett",
      "J. R. Lucey",
      "K. Said",
      "T. M. Davis",
      "J. Aguilar",
      "S. Ahlen",
      "A. J. Amsellem",
      "J. Bautista",
      "S. BenZvi",
      "D. Bianchi",
      "C. Blake",
      "D. Brooks",
      "A. Carr",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "B. Dey",
      "P. Doel",
      "K. Douglass",
      "S. Ferraro",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "J. Guy",
      "K. Honscheid",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "A. G. Kim",
      "A. Kremin",
      "O. Lahav",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "A. Leauthaud",
      "M. E. Levi",
      "P. Martini",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "A. Mu noz-Gutiérrez",
      "S. Nadathur",
      "N. Palanque-Delabrouille",
      "W. J. Percival",
      "C. Poppett",
      "F. Prada",
      "I. Pérez-Ràfols",
      "F. Qin",
      "G. Rossi",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "D. Sprayberry",
      "G. Tarlé",
      "R. J. Turner",
      "B. A. Weaver",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03227",
    "title": "The DESI DR1 Peculiar Velocity Survey: The Tully-Fisher Distance Catalog",
    "abstract": "We calibrate the Tully-Fisher relation (TFR) using observations of spiral galaxies taken during the first year (DR1) of the DESI galaxy redshift survey. The rotational velocities of 10,262 galaxies are measured at 0.4 R26 by comparing the redshifts at 0.4 R26 with those at the galaxy centers of spatially- resolved galaxies targeted as part of the DESI Peculiar Velocity Survey. The DESI DR1 TFR slope is calibrated by separating the spiral galaxies into redshift bins of width dz = 0.005 from 0.03 < z < 0.1 and jointly fitting the TFR across all bins. We find a slope of -7.22+/-0.01 AB mag in the r-band for the TFR, with an intrinsic scatter of 0.466+/-0.001 AB mag. We present a catalog of the distances and peculiar velocities to these 10,262 galaxies using our calibrated TFR. For cosmological analyses, we also present a clustering catalog and associated random catalogs using a subset of 6807 of the DESI DR1 TF galaxies.",
    "authors": [
      "K. Douglass",
      "S. BenZvi",
      "A. G. Kim",
      "S. Moore",
      "A. Carr",
      "J. Largett",
      "N. Ravi",
      "J. Aguilar",
      "S. Ahlen",
      "A. J. Amsellem",
      "J. Bautista",
      "D. Bianchi",
      "C. Blake",
      "D. Brooks",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "R. Demina",
      "P. Doel",
      "S. Ferraro",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztanaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "J. Guy",
      "H. K. Herrera-Alcantar",
      "K. Honscheid",
      "C. Howlett",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "A. Kremin",
      "O. Lahav",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "A. Leauthaud",
      "M. E. Levi",
      "M. Manera",
      "P. Martini",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "A. Munoz-Gutierrez",
      "S. Nadathur",
      "N. Palanque-Delabrouille",
      "A. Palmese",
      "W. J. Percival",
      "C. Poppett",
      "F. Prada",
      "I. Perez-Rafols",
      "F. Qin",
      "C. Ross",
      "G. Rossi",
      "K. Said",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "H. Seo",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarle",
      "R. J. Turner",
      "B. A. Weaver",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03228",
    "title": "The DESI DR1 Peculiar Velocity Survey: Mock Catalog",
    "abstract": "We describe the production of the official set of mock catalogs for the Dark Energy Spectroscopic Instrument Peculiar Velocity Survey (DESI-PV) Data Release 1 (DR1). Our mock catalogs reproduce the Bright Galaxy Survey number density and clustering at low redshift $(z<0.1)$ and the DESI PV samples of Fundamental plane and Tully-Fisher distances, from which we derive peculiar velocities. We carefully match mock and data properties and we mimic measurements of distance indicators and peculiar velocities, which follow the same statistical properties as real data. Mock samples of type-Ia supernovae also complement the other two distance indicators. Our 675 available mock realizations were used consistently by our three different methodologies described in our companion papers that measure the growth rate of structure $f\\sigma_8$ with DESI PV DR1. Those mocks allow us to perform precise tests of clustering models and uncertainty estimation to an unprecedented level of accuracy, and compute correlations between methodologies. The consensus value for the DESI DR1 PV growth rate measurement is $f\\sigma_8 = 0.450 \\pm 0.055$. This sample of mock catalogs represents the largest and most realistic set for cosmological measurements with peculiar velocities to date.",
    "authors": [
      "J. Bautista",
      "A. J. Amsellem",
      "V. Aronica",
      "S. BenZvi",
      "C. Blake",
      "A. Carr",
      "T. M. Davis",
      "K. Douglass",
      "T. Dumerchat",
      "C. Howlett",
      "Y. Lai",
      "A. Nguyen",
      "A. Palmese",
      "F. Qin",
      "C. Ravoux",
      "C. Ross",
      "K. Said",
      "R. J. Turner",
      "J. Aguilar",
      "S. Ahlen",
      "D. Bianchi",
      "D. Brooks",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "P. Doel",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "H. K. Herrera-Alcantar",
      "K. Honscheid",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "A. Kremin",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "A. Leauthaud",
      "M. Manera",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "A. Muñoz-Gutiérrez",
      "S. Nadathur",
      "W. J. Percival",
      "F. Prada",
      "I. Pérez-Ràfols",
      "G. Rossi",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "H. Seo",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarlé",
      "B. A. Weaver",
      "P. Zarrouk",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03229",
    "title": "The DESI DR1 Peculiar Velocity Survey: growth rate measurements from the maximum likelihood fields method",
    "abstract": "We present the constraint on the growth rate of structure from the combination of DESI DR1 BGS sample, Fundamental Plane, and Tully-Fisher peculiar velocity catalogues using the maximum likelihood fields method. The combined catalogue contains 415,523 galaxy redshifts and 76,616 peculiar velocity measurements. To handle the large amount of data in the DESI DR1 peculiar velocity catalogue, we significantly improve the computational efficiency by rewriting the algorithm with JAX. After removing outliers and Tully-Fisher galaxies that are affected by systematics, we find $f\\sigma_8 = 0.483_{-0.043}^{+0.080}(\\mathrm{stat}) \\pm 0.018(\\mathrm{sys})$, consistent within $1\\sigma$ with the power spectrum and correlation function analysis using the same dataset. Combining all three measurements with appropriate correlations, the consensus measurement is $f\\sigma_8 (z_{\\mathrm{eff}}=0.07) = 0.450\\pm0.055$, consistent with Planck $+\\Lambda$CDM cosmology $(f\\sigma_8 = 0.449 \\pm 0.008)$. Combining with the high redshift growth rate of structure measurements from DESI ShapeFit, the constraint on the growth index is $\\gamma = 0.58\\pm0.11$, consistent with GR.",
    "authors": [
      "Y. Lai",
      "C. Howlett",
      "J. Aguilar",
      "S. Ahlen",
      "A. J. Amsellem",
      "J. Bautista",
      "S. BenZvi",
      "D. Bianchi",
      "C. Blake",
      "D. Brooks",
      "A.Carr",
      "T. Claybaugh",
      "T. M. Davis",
      "A. de la Macorra",
      "P. Doel",
      "K. Douglass",
      "S. Ferraro",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "G. Gutierrez",
      "J. Guy",
      "H. K. Herrera-Alcantar",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "A. Kim",
      "D. Kirkby",
      "T. Kisner",
      "A. Kremin",
      "O. Lahav",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "A. Leauthaud",
      "M. E. Levi",
      "M. Manera",
      "P. Martini",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "A. Muñoz-Gutiérrez",
      "S. Nadathur",
      "W. J. Percival",
      "C. Poppett",
      "F. Prada",
      "I. Pérez-Ràfols",
      "F. Qin",
      "C. Ross",
      "G. Rossi",
      "K. Said",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "H. Seo",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarlé",
      "R. Turner",
      "B. A. Weaver",
      "P. Zarrouk",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03230",
    "title": "The DESI DR1 Peculiar Velocity Survey: growth rate measurements from galaxy and momentum correlation functions",
    "abstract": "Joint analysis of the local peculiar velocity and galaxy density fields offers a promising route to testing cosmological models of gravity. We present a measurement of the normalised growth rate of structure, $f\\sigma_8$, from the two-point correlations of velocity and density tracers from the DESI DR1 Peculiar Velocity and Bright Galaxy Surveys, the largest catalogues of their kind assembled to date. We fit the two-point correlation measurements with non-linear correlation function models, constructed from density and momentum power spectra generated using 1-loop Eulerian perturbation theory, and validate our methodology using representative mock catalogues. We find $f\\sigma_8 = 0.391^{+0.080}_{-0.081}$, consistent to within $1\\sigma$ with accompanying analyses of the same datasets using power spectrum and maximum-likelihood fields methods. Combining these growth rate results from different methods including appropriate correlations, we find a consensus determination $f\\sigma_8(z = 0.07) = 0.4497 \\pm 0.0548$, consistent with predictions from \\textit{Planck}$+\\Lambda$CDM cosmology. Jointly fitting to this consensus low-redshift growth rate and the DESI DR1 full-shape clustering dataset, we measure gravitational growth index $\\gamma_{\\rm L} = 0.580^{+0.110}_{-0.110}$, consistent with the prediction of general relativity.",
    "authors": [
      "R. J. Turner",
      "C. Blake",
      "F. Qin",
      "J. Aguilar",
      "S. Ahlen",
      "A. J. Amsellem",
      "J. Bautista",
      "S. BenZvi",
      "D. Bianchi",
      "D. Brooks",
      "A. Carr",
      "E. Chaussidon",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "P. Doel",
      "K. Douglass",
      "S. Ferraro",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "J. Guy",
      "H. K. Herrera-Alcantar",
      "K. Honscheid",
      "C. Howlett",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "R. Kehoe",
      "A. G. Kim",
      "D. Kirkby",
      "A. Kremin",
      "O. Lahav",
      "Y. Lai",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "A. Leauthaud",
      "M. E. Levi",
      "M. Manera",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "A. Muñoz-Gutiérrez",
      "S. Nadathur",
      "N. Palanque-Delabrouille",
      "W. J. Percival",
      "C. Poppett",
      "F. Prada",
      "I. Pérez-Ràfols",
      "C. Ross",
      "G. Rossi",
      "K. Said",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarlé",
      "B. A. Weaver",
      "P. Zarrouk",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03231",
    "title": "The DESI DR1 Peculiar Velocity Survey: Growth Rate Measurements from the Galaxy Power Spectrum",
    "abstract": "The large-scale structure of the Universe and its evolution encapsulate a wealth of cosmological information. A powerful means of unlocking this knowledge lies in measuring the auto-power spectrum and/or the cross-power spectrum of the galaxy density and momentum fields, followed by the estimation of cosmological parameters based on these spectrum measurements. In this study, we generalize the cross-power spectrum model to accommodate scenarios where the density and momentum fields are derived from distinct galaxy surveys. The growth rate of the large-scale structures of the Universe, commonly represented as $f\\sigma_8$, is extracted by jointly fitting the monopole and quadrupole moments of the auto-density power spectrum, the monopole of the auto-momentum power spectrum, and the dipole of the cross-power spectrum. Our estimators, theoretical models and parameter-fitting framework have been tested using mocks, confirming their robustness and accuracy in retrieving the fiducial growth rate from simulation. These techniques are then applied to analyze the power spectrum of the DESI Bright Galaxy Survey and Peculiar Velocity Survey, and the fit result of the growth rate is $f\\sigma_8=0.440^{+0.080}_{-0.096}$ at effective redshift $z_{\\rm eff}=0.07$. By synthesizing the fitting outcomes from correlation functions, maximum likelihood estimation and power spectrum, yields a consensus value of $f\\sigma_8(z_{\\rm eff}=0.07) = 0.450 ^{+0.055}_{-0.055}$, and correspondingly we obtain $\\gamma=0.580^{+0.110}_{-0.110}$, $\\Omega_\\mathrm{m}=0.301^{+0.011}_{-0.011}$ and $\\sigma_8=0.834^{+0.032}_{-0.032}$. The measured $f\\sigma_8$ and $\\gamma$ are consistent with the prediction of the $\\Lambda$ Cold Dark Matter Model and General Relativity.",
    "authors": [
      "F. Qin",
      "C. Blake",
      "C. Howlett",
      "R. J. Turner",
      "K. Lodha",
      "J. Bautista",
      "Y. Lai",
      "A. J. Amsellem",
      "J. Aguilar",
      "S. Ahlen",
      "D. Bianchi",
      "D. Brooks",
      "S. BenZvi",
      "A. Carr",
      "E. Chaussidon",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "K. Douglass",
      "P. Doel",
      "S. Ferraro",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "J. Guy",
      "H. K. Herrera-Alcantar",
      "K. Honscheid",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "A. G. Kim",
      "D. Kirkby",
      "T. Kisner",
      "A. Kremin",
      "O. Lahav",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "M. E. Levi",
      "M. Manera",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "A. Muñoz-Gutiérrez",
      "S. Nadathur",
      "N. Palanque-Delabrouille",
      "W. J. Percival",
      "C. Poppett",
      "F. Prada",
      "I. Perez-Rafols",
      "C. Ross",
      "G. Rossi",
      "E. Sanchez",
      "D. Schlegel",
      "K. Said",
      "M. Schubnell",
      "H. Seo",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarle",
      "B. A. Weaver",
      "P. Zarrouk",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03232",
    "title": "The DESI DR1 Peculiar Velocity Survey: global zero-point and $H_0$ constraints",
    "abstract": "The Dark Energy Spectroscopic Instrument (DESI) in its first Data Release (DR1) already provides more than 100,000 galaxies with relative distance measurements. The primary purpose of this paper is to perform the calibration of the zero-point for the DESI Fundamental Plane and Tully-Fisher relations, which allows us to measure the Hubble constant, $H_0$. This sample has a lower statistical uncertainty than any previously used to measure $H_0$, and we investigate the systematic uncertainties in absolute calibration that could limit the accuracy of that measurement. We improve upon the DESI Early Data Release Fundamental Plane $H_0$ measurement by a) using a group catalog to increase the number of calibrator galaxies and b) investigating alternative calibrators in the nearby universe. Our baseline measurement calibrates to the SH0ES/Pantheon+ type Ia supernovae, and finds $H_0=73.7\\pm 0.06\\;(\\text{stat.})\\pm 1.1\\;(\\text{syst.})$ km s$^{-1}$ Mpc$^{-1}$. Calibrating to surface brightness fluctuation (SBF) distances yields a similar $H_0$. We explore measurements using other calibrators, but these are currently less precise since the overlap with DESI peculiar velocity tracers is much smaller. In future data releases with an even larger peculiar velocity sample, we plan to calibrate directly to Cepheids and the tip of the red giant branch, which will enable the uncertainty to decrease towards a percent-level measurement of $H_0$. This will provide an alternative to supernovae as the Hubble flow sample for $H_0$ measurements.",
    "authors": [
      "A. Carr",
      "C. Howlett",
      "A. J. Amsellem",
      "Tamara M. Davis",
      "K. Said",
      "D. Parkinson",
      "A. Palmese",
      "J. Aguilar",
      "S. Ahlen",
      "J. Bautista",
      "S. BenZvi",
      "D. Bianchi",
      "C. Blake",
      "D. Brooks",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "P. Doel",
      "K. Douglass",
      "S. Ferraro",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "H. K. Herrera-Alcantar",
      "K. Honscheid",
      "D. Huterer",
      "M. Ishak",
      "R. Joyce",
      "A. G. Kim",
      "D. Kirkby",
      "A. Kremin",
      "O. Lahav",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "M. E. Levi",
      "M. Manera",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "S. Nadathur",
      "W. J. Percival",
      "F. Prada",
      "I. Pérez-Ràfols",
      "F. Qin",
      "C. Ross",
      "G. Rossi",
      "E. Sanchez",
      "D. Schlegel",
      "H. Seo",
      "D. Sprayberry",
      "G. Tarlé",
      "R. J. Turner",
      "B. A. Weaver",
      "P. Zarrouk",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03239",
    "title": "(Re)solving the complex multi-scale morphology and V-shaped SED of a newly discovered strongly-lensed Little Red Dot in Abell 383",
    "abstract": "We present a luminous Little Red Dot (LRD) at $z=6.027$, doubly imaged by the galaxy cluster Abell 383 and observed with JWST/NIRCam. The source shows the characteristic \"V-shaped\" SED and pronounced Balmer break that define the LRD population. Owing to its large magnifications, $\\mu\\sim11$ for image S1 and $\\mu\\sim7$ for S2, the system is exceptionally bright and highly stretched, providing a rare, spatially resolved view of an LRD. The images reveal a complex morphology with a compact red dot, a spatially offset blue dot, and faint emission bridging and surrounding the two. After correcting for lensing, we find that both dots are extremely small but resolved, with rest-frame UV sizes of $\\sim 20$ pc (red) and $\\sim60$ pc (blue). These compact dots are embedded in a more extended, line-dominated cloud traced most clearly in F356W ([OIII]+H$\\beta$), which reaches scales of order $\\sim$1 kpc. SED decomposition shows that the blue component has a flat UV continuum consistent with a young stellar population, whereas the red component has a steep red SED that can be interpreted as either an evolved stellar population with high stellar mass ($\\log M_\\star/M_\\odot>10$) or a reddened AGN. If this object is representative of the LRD population, our results imply that the V-shaped SEDs of LRDs do not arise from individual compact sources but instead from the superposition of two physically distinct components. Separated by only $\\sim300$ pc in the source plane, these components would blend into a single compact source in unlensed observations with the canonical LRD colors. This system therefore provides a rare opportunity to resolve the internal structure of an LRD and to gain direct insight into the physical nature of this population.",
    "authors": [
      "Josephine F.W. Baggen",
      "Pieter van Dokkum",
      "Ivo Labbé",
      "Gabriel Brammer"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03253",
    "title": "Fine-Scale Features of the Sun's Atmosphere: Spicules and Jets",
    "abstract": "We present an overview of fine-scale features in the Sun's atmosphere, with a focus on spicules and jets. We consider older and newer observations and theories for chromospheric spicules and coronal jets. We also consider the connection between these features and some other solar atmospheric phenomena. We then discuss the possibility that there is a continuum of jet-like features ranging from spicules to large-scale CME-producing eruptions, all driven by similar magnetic processes operating on differing corresponding size scales. Future observational and theoretical studies will help clarify further the nature of these solar events, and elucidate possible connections between them.",
    "authors": [
      "Alphonse C. Sterling"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03260",
    "title": "Spectral Characterization of a 90 GHz CLASS Pixel",
    "abstract": "The Cosmology Large Angular Scale Surveyor (CLASS) is an experiment designed to measure the polarization of the cosmic microwave background on large angular scales to probe cosmic reionization and search for the inflationary $B$-mode signal. CLASS is a multi-frequency ensemble of telescopes with bands centered at 40, 90, 150, and 220 GHz. Each telescope has arrays of feedhorn-coupled transition edge sensor bolometers at the focal plane. The frequency response is primarily defined by the on-chip bandpass filter with additional contributions coming from the feedhorn, orthomode transducer, and 180-degree hybrid. In this study, we compare simulations and measurements of the frequency response of single pixel witness devices in the 90 GHz band with and without the bandpass filter. For the first time, we can separate the effects of the bandpass filter from the other microwave components using Fourier transform spectroscopy and design splits of the pixel. The results show that the -3 dB band edges are at 80 GHz and 108 GHz. The measurements demonstrate a robust method for characterizing the spectral response of individual components, which is crucial for optimizing the performance of future detector arrays.",
    "authors": [
      "Gregory Jaehnig",
      "John Appel",
      "Sarah Marie Bruno",
      "Jake Connors",
      "Shannon M. Duff",
      "Naina Gupta",
      "Johannes Hubmayr",
      "Matthew A. Koc",
      "Tammy Lucas",
      "Tobias Marriage",
      "Lola Morales Perez",
      "Caleigh Ryan",
      "Jeff Van Lanen"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03264",
    "title": "Comparison of Ne-22 core and shell distilled WD detonations in AREPO",
    "abstract": "We present three-dimensional hydrodynamical simulations of detonations in $1.0 \\mathrm{M_{\\odot}}$ white dwarfs that have undergone $^{22} \\mathrm{Ne}$ distillation during crystallisation. These simulations, conducted with the moving-mesh code AREPO, aim to investigate the effects of chemical separation on the ejecta and spectra of such WDs undergoing thermonuclear explosions. The distillation process alters the internal chemical stratification of the star, concentrating neutron-rich material either in a central core or in an interior shell. We model both configurations as well as a homogeneous equivalent for each case with the same $^{22} \\mathrm{Ne}$ content distributed evenly at all radii. Despite similar $^{56} \\mathrm{Ni}$ yields between the core and shell models ($0.40$ and $0.45 \\mathrm{M_{\\odot}}$ respectively), the two models yield markedly different iron-group abundances. Both distilled models showed significantly enhanced production of $^{15} \\mathrm{N}$ via the decay of $^{15} \\mathrm{O}$. The $^{22} \\mathrm{Ne}$-core model produces enhanced amounts of stable neutron-rich iron-group isotopes such as $^{58} \\mathrm{Ni}$ and $^{54} \\mathrm{Fe}$. We highlight observational signatures associated with these differences, including potentially enhanced [$\\mathrm{Ni}_{\\rm II}$] lines in nebular spectra. Synthetic TARDIS spectra at early times show only moderate differences. Our results suggest that white dwarf distillation, a process linked to delayed cooling in the Gaia Q branch population, may leave detectable nucleosynthetic fingerprints in a subset of Type Ia supernovae. These findings open additional pathways to probe progenitor evolution and the role of crystallisation in shaping the diversity of thermonuclear transients.",
    "authors": [
      "Uri Pierre Burmester",
      "Lilia Ferrario",
      "Ivo R. Seitenzahl",
      "Simon Blouin"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03281",
    "title": "A Comprehensive JWST/NIRSpec Census of Broad-Line Active Galactic Nuclei: Faint, Tiny, but Highly Accreting Sources in the Remote Universe",
    "abstract": "We present a sample of 252 broad-line Active Galactic Nuclei (BLAGNs), incorporating 171 newly identified sources, spanning a redshift interval from $z$ = 0.8 to 7.2. We have analyzed spectroscopic data from the NIRSpec instrument aboard the James Webb Space Telescope, using the G140H, G140M, G235H, G235M, G395H, and G395M gratings to survey N $\\sim$ 80,000 galaxies for BLAGNs. Through emission-line fitting, using a sum of Gaussian models for {H$\\alpha$}, {H$\\beta$}, [N II] $\\lambda\\lambda6548, 6584$, and [O III] $ \\lambda\\lambda4959, 5007$, we separate AGN broad-line components from narrow-line emission. We find the detection rate of BLAGNs to be relatively consistent across our redshift range. Compared to typical low-$z$ AGNs ($z$ $\\lesssim$ 1), the high-$z$ BLAGNs are systematically fainter and less massive, yet they accrete more efficiently, with most showing Eddington ratios between 0.1 and 1.0. This confirms the rapid black hole growth during the early cosmic epochs. The detection of faint, low-mass BLAGNs at high redshift also helps bridge the observational gap between local supermassive black holes and remote luminous quasars, providing a more complete view of black hole-galaxy coevolution across cosmic time.",
    "authors": [
      "Caroline Baccus",
      "Xinfeng Xu"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03282",
    "title": "Surprisingly Large Doppler Shifts in Hinode EUV Imaging Spectrometer (EIS) Solar Spectra, Resulting from an Inconspicuous Small-scale Jet in EUV Images",
    "abstract": "Strong EUV lineshifts in solar spectra are generally indicative of highly dynamic and explosive events that are easily detected in comparable-wavelength EUV images, with the strongest such line shifts (several 100 km/s) occurring in solar flares. Here we present observations of exceptionally strong lineshifts detected in Hinode/EUV Imaging Spectrometer (EIS) spectra outside the time of a flare-like brightening, with 195 Ang blueshifts of ~200 km/s. Although the likely culprit is too weak to register in GOES Soft X-ray fluxes, EIS pinpoints the source at the edge of an active region. Solar Dynamics Observatory (SDO)/Atmospheric Imaging Assembly (AIA) images and Helioseismic and Magnetic Imager (HMI) magnetograms show a nondescript small-scale eruptive event at this location. We find this event likely to be an inconspicuous coronal jet, apparently triggered by converging/canceling magnetic flux patches, with plane-of-sky velocity ~159+-29 km/s. AIA and HMI observations of this faint transient feature, together with observations of a slightly brighter jetting event near the same location an hour earlier, suggest that the strong EIS Doppler shifts are indeed due to a coronal jet that is hard to detect in AIA images. These observations, together with other recent studies, show that EUV Doppler maps are a much more sensitive tool for detecting small-scale eruptions than are EUV images, and those eruptions are frequently triggered by magnetic flux cancelation episodes. Such-detected small-scale eruptions, that often produce small-scale coronal-jet-like features, might propagate into and help drive the solar wind.",
    "authors": [
      "Alphonse C. Sterling",
      "Louise K. Harra",
      "Navdeep K. Panesar",
      "Ronald L. Moore"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03308",
    "title": "Roman coronagraph simulations of exozodi observations in the presence of wavefront errors",
    "abstract": "The Coronagraph Instrument on board of the Nancy Grace Roman Space Telescope will demonstrate key technologies that will prepare the ground for the Habitable Worlds Observatory. The current predictions for the Roman Coronagraph's detection limit range from 1e-8 to a few 1e-9, which would allow for groundbreaking science, such as potentially imaging Jupiter-like planets. However, the performance of the instrument depends on many factors. Simulating images with varying optical error sources can help us connect instrument and observatory performance to science yield. Here we present corosims, a tool to simulate observations of astrophysical scenes with the Coronagraph with evolving errors. This tool wraps around the Coronagraph PROPER diffraction model and detector simulator. We use it to investigate the potential degeneracy between jitter-induced speckles and both hot and warm exozodi disk structures. First, we simulate observations of exozodi around Tau Ceti, with varying jitter. We predict that with nominal post-correction pointing jitter performance (~0.3 mas RMS), the Roman Coronagraph should be sensitive to 12x zodis worth of dust, assuming a face-on (worst case scenario) inclination. We further predict that its sensitivity degrades to 35x zodis if jitter on-target is 3x worse than the nominal value. This estimate assumes the best-modeled wavefront control and stability values from the project, including additional model uncertainty factors. We find that, while jitter hinders warm exozodi detection, jitter residuals are unlikely to result in a false positive. However, if a faint hot exozodi falls at small separation, it may not be distinguishable from jitter-induced speckle residuals of comparable brightness. Finally, we discuss the degeneracies induced between flux and separation retrieved near the inner working angle due the sharp edge of the Roman Coronagraph's focal plane mask.",
    "authors": [
      "Jorge Llop-Sayson",
      "Vanessa P. Bailey",
      "Justin Hom",
      "John Krist",
      "Bertrand Mennesson",
      "Samantha N. Hasler",
      "Alexandra Z. Greenbaum",
      "A J Eldorado Riggs",
      "Geoffrey Bryden"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03314",
    "title": "EFT of Dark Energy with Cosmic Chronometers: Reconstructing Background EFT Functions",
    "abstract": "The effective field theory (EFT) of dark energy provides a model-independent framework for studying cosmology within scalar-tensor theories. In this work, we explore how the time evolution of the cosmological background, inferred from cosmic chronometer measurements of the Hubble parameter, can be used to reconstruct the relevant EFT functions. Our approach enables the direct determination of these EFT functions from observational data without assuming any specific cosmological model. This makes it possible to test the background evolution of a wide range of dark energy models, including the $\\Lambda$CDM model. We further demonstrate how the reconstructed EFT functions can be applied to constrain concrete theories, such as the quintessence model.",
    "authors": [
      "Fumiya Okamatsu",
      "Kazufumi Takahashi"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03329",
    "title": "Push-broom Mapping of Galaxies and Supernova Remnants with the SPRITE CubeSat",
    "abstract": "Supernovae (SNe) enrich and energize the surrounding interstellar medium (ISM) and are a key mechanism in the galaxy feedback cycle. The heating of the ISM by supernova shocks, and its subsequent cooling is critical to future star formation. The cooling of the diffuse shock-heated ISM is dominated by ultraviolet (UV) emission lines. These cooling regions and interfaces have complex spatial structure on sub-parsec scales. Mapping this cooling process is essential to understanding the feedback cycle of galaxies, a major goal of the 2020 Astrophysics Decadal Survey. The Supernova remnants and Proxies for ReIonization Testbed Experiment (SPRITE) CubeSat Mission will house the first long-slit orbital spectrograph with sub-arcminute angular resolution covering far ultraviolet wavelengths (FUV; 1000 - 1750 angstroms) and access to the Lyman UV (lambda < 1216 angstroms). SPRITE aims to provide new insights into the stellar feedback that drives galaxy evolution by mapping key FUV emission lines at the interaction lines between supernova remnants (SNRs) and the ambient interstellar medium (ISM). SPRITE will also measure the ionizing escape from approximately 50 low-redshift (0.16 < z < 0.4) star-forming galaxies. Current models predict SPRITE capable of detecting strong O VI, O IV], and C IV emission lines with angular resolution from 10 - 20 arcseconds. The SPRITE SNR survey will use push-broom mapping of its long-slit on extended sources to produce the first large sample of sub-arcminute 3D data cubes of extended sources in the FUV. In this paper, we present simulated SPRITE observations of Large Magellanic Cloud (LMC) SNRs to demonstrate the efficacy of the SPRITE instrument ahead of launch and instrument commissioning. These models serve as critical planning tools and incorporate the final pre-flight predicted performance of the instrument and the early extended source data reduction pipeline.",
    "authors": [
      "Elena Carlson",
      "Brian Fleming",
      "Yi Hang Valerie Wong",
      "Briana Indahl",
      "Dmitry Vorobiev",
      "Maitland Bowen",
      "Donal O'Sullivan",
      "Kevin France",
      "Anne Jaskot",
      "Jason Tumlinson",
      "Sanchayeeta Borthakur",
      "Michael Rutkowski",
      "Stephan McCandliss",
      "Ravi Sankrit",
      "John M. O'Meara"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03331",
    "title": "Radio Detection of a Local Little Red Dot",
    "abstract": "Context. One of the most important discoveries by the James Webb Space Telescope (JWST) is the unexpected existence in the Early Universe (z > 4) of very large quantities of \"Little Red Dots\" (LRDs), compact luminous red galaxies of intriguing physical properties. Aims. We wish to know if LRDs may host accreting Intermediate/Supermassive Black Holes (IMBHs/SMBHs) that may power LRDs, and compare them with the effect of clusters of massive stars. The spectrum of radio emission (synchrotron vs thermal) can be used to know which between these two types of energy sources is the dominant one. Methods. So far LRDs at high redshifts have not been detected at radio wavelengths and it is not known why. Assuming this could be due to their large distances and/or present limitations of observational capabilities, we analyze here archive Very Large Array radio observations of two analog candidates of LRDs in the Local Universe (LLRDs) at redshifts z = 0.1 - 0.2. Results. The LLRD source J1047+0739 at z = 0.1682 is detected at 6.0 GHz in 2018 with the VLA-A of NRAO as a compact source with radii less than 0.2 arc sec (< 600 pc at d = 700 Mpc). Its flux density was 117$\\pm$8 $\\mu$Jy and its spectral index was -0.85, which is typical of optically-thin synchrotron emission. It is also detected at 5.0 GHz in 2010 with the VLA-C, showing a flux density of 43$\\pm$3 $\\mu$Jy. Conclusions. The observed flux densities can be provided by a radio luminous supernova. The increase in flux density over eight years can be explained as the result of two independent supernovae or as the radio re-brightening of a single one. Radio time monitoring of this and other LLRDs could help clarify the mystery of the radio silence of its cosmological counterparts.",
    "authors": [
      "L. F. Rodriguez",
      "I. F. Mirabel"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03332",
    "title": "A three-dimensional model for the reversal in the local large-scale interstellar magnetic field",
    "abstract": "We probe the three-dimensional geometry of the large-scale Galactic magnetic field within 1 kpc of the Sun using the Dominion Radio Astrophysical Observatory (DRAO) Global Magneto-Ionic Medium Survey (GMIMS) of the Northern Sky (DRAGONS). DRAGONS is a new full polarization survey of the Northern sky from 350 to 1030 MHz covering declinations -20° < $\\delta$ < 90° and a component of GMIMS. The first moment of the Faraday depth spectra produced from DRAGONS above 500 MHz reveals large-angular-scale Faraday depth structures with signs that alternate only once in the Southern Galactic hemisphere and twice in the Northern hemisphere, patterns shared by other Faraday rotation datasets. DRAGONS is the first survey to achieve high Faraday depth resolution while maintaining sensitivity to broad Faraday depth structures, enabling the first use of Galactic longitude-Faraday depth plots. These plots reveal Faraday-complex structures across the sky, indicating a slab-like scenario in which emission and Faraday rotation are mixed. This complexity is overlaid on the same large-scale Faraday depth patterns that appear in the first moment map. We model these patterns as a magnetic reversal slicing through the disk on a diagonal and passing above the Sun in Galactic coordinates. We describe this reversal as a plane with a normal vector parallel to the line directed along ($\\ell$, b) = (168.5°, -60°) and estimate its distance to be between 0.25 and 0.55 kpc. Our results show that much of the observed Faraday sky may be dominated by the local magnetic field configuration.",
    "authors": [
      "Rebecca A. Booth",
      "Anna Ordog",
      "Jo-Anne Brown",
      "T. L. Landecker",
      "Alex S. Hill",
      "Jennifer L. West",
      "Minjie Lei",
      "S. E. Clark",
      "Andrea Bracco",
      "John M. Dickey",
      "Ettore Carretti"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03348",
    "title": "Forecasts for lifetime and fraction of Decaying Dark Matter based on redshift distortions from Euclid and BOSS",
    "abstract": "In this work we forecast constraints on models of decaying dark matter (DCDM) by using redshift-space-distortion (RSD) measurements implemented in a Fisher information matrix. In particular, we focus on the fraction of unstable dark matter, $\\alpha_{\\mathrm{dcdm}}$ respect to the ordinary CDM component, and the decay rate, $\\Gamma_{\\mathrm{dcdm}}$ as the key parameters of the model. Fiducial values are derived from a MontePython MCMC analysis. The derivatives of the growth-related observable, $f\\sigma_8(z)$ with respect to the parameters are numerically around the fiducial model. For the Fisher analysis, we employ mock data designed for upcoming surveys, particularly Euclid and BOSS, where RSD measurements yield constraints on $f\\sigma_8.$ Our results show that when both stable and unstable components are allowed, constrains on the DCDM lifetime remain weak, with $\\tau_{\\mathrm{dcdm}}>1.18$ Gyr. In the limiting case of fully unstable dark matter ($\\alpha_{\\mathrm{dcdm}}=1$), the uncertainty improves to $\\tau_{\\mathrm{dcdm}}>235.89$ Gyr. Our findings highlight the potential of RSD probes in testing and complementing decaying dark matter scenarios.",
    "authors": [
      "Javier Juárez-Jiménez",
      "Ana A. Avilez-López"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03357",
    "title": "BEC vortices as an observational signature of ultra-light bosonic dark matter",
    "abstract": "Ultra-light bosonic dark matter (ULDM) is an interesting and promising dark matter candidate. While the wave-like nature of ULDM has been widely studied in the literature, we explore another distinctive feature of ULDM as Bose-Einstein Condensate (BEC) in this paper: the emergence of vortices in a rotating BEC-ULDM halos. Using numerical solution of the GPP equation, we demonstrate that a lattice of vortices ,underdensity columns that carry angular momentum, naturally forms in a ULDM halo under conditions similar to those of the Milky Way. Furthermore, we study the gravitational lensing by these vortices as a possible observational signature of BEC-ULDM. If the vortices are large enough and the halo's rotational axis align with the line of sight, regularly separated brightness anomalies can be produced, providing strong evidence for BEC-ULDM.",
    "authors": [
      "Rongzi Zhou",
      "Dylan M. H. Leung",
      "Jason S. C. Poon",
      "Ming-Chung Chu"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03364",
    "title": "The BAGLE Python Package for Bayesian Analysis of Gravitational Lensing Events",
    "abstract": "We present the open-source Python package, BAGLE (Bayesian Analysis of Gravitational Lensing Events), which enables modeling and joint fitting of photometric and astrometric data sets. We describe the model parameterizations and present the equations for microlensing events containing either a point-source, point-lens or a finite-source, point-lens geometry both with and without microlensing parallax due to the motion of the Earth or a satellite around the Sun. Conversions between different coordinate reference frames are also derived. We compare our model light curves to those from other papers and microlens modeling software, finding good agreement, although with some differences in finite-source models at a ~1% level detectable with upcoming observations from space-based facilities. We also use BAGLE to demonstrate the impact of changing lens mass, lens distance, and blended source flux fraction on photometric lightcurves and astrometric trajectories in preparation for upcoming Gaia data releases and the launch of the Nancy Grace Roman Space Telescope and its Galactic Bulge Time Domain Survey (GBTDS). In particular, we show that Roman GBTDS will detect significant microlensing parallax signals for events that are 2x shorter in duration than from ground-based surveys. Additionally, long-duration events with durations of $\\t_{E,\\odot} >$ 100 days will yield microlensing parallax uncertainties of ${\\sigma}_{\\pi_E} <$ 0.01 with Roman, enabling confident identification of isolated stellar-mass black holes that can be modeled both astrometrically and photometrically with BAGLE for precise mass determinations. BAGLE is an open-source code and community development is encouraged.",
    "authors": [
      "J. R. Lu",
      "M. Medford",
      "C.Y. Lam",
      "T.D. Bhadra",
      "M.J. Huston",
      "N.S. Abrams",
      "E. Broadberry",
      "J. Chen",
      "S.K. Terry",
      "N. Arredondo",
      "A. Scharf"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03385",
    "title": "Voyager 1 Data Reveals Signatures of the Local Gas and Cosmic-Ray Source Distributions",
    "abstract": "We investigate the effects of the nearby interstellar medium (ISM) on the locally measured cosmic-ray (CR) spectra. Using the GALPROP code we explore how variations in the local gas and source distributions affect spectral features at low energies. Comparing with recent Voyager 1 data taken in the local ISM, we show that for a realistic interstellar gas distribution, the nearest source of the low energy CR particles observed nearby the Solar system is constrained to be within the range ~150-200 pc distant. We find that the modelling supports the conclusion of Cummings et al. (2025) that there is a significant fraction of primary Boron in its observed spectrum at low energies. Our study shows that detailed modelling of the immediate Galactic environment is required to robustly infer Galactic CR propagation parameters from local measurements, and that accounting for nearby ISM structure can alleviate tensions between direct CR data and global propagation models.",
    "authors": [
      "Troy A. Porter",
      "Igor V. Moskalenko",
      "Alan C. Cummings",
      "Guðlaugur Jóhannesson"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03392",
    "title": "Modeling Binary Lenses and Sources with the BAGLE Python Package",
    "abstract": "Gravitational microlensing is a powerful tool that can be used to find and measure the mass of isolated and dark compact objects. In many microlensing events, the lens, the source, or both may be a binary system. Therefore, in this study we present lensing equations for binary source and lens models in the Bayesian Analysis of Gravitational Lensing Events (BAGLE) Python microlensing package. The new binary source and lens models in BAGLE account for the complete Keplerian orbit. BAGLE also includes binary models that approximate the orbital motion as linear or accelerating motion of the secondary companion; these are useful when the orbit has a very low eccentricity or the orbital period is much longer than the microlensing timescale. The model parameterizations based on these binary lensing equations will enable joint fitting of photometric and astrometric data sets. Consequently, binary microlensing events with complex astrometric trajectories can be used to break several microlensing degeneracies that plague photometry-only microlensing modeling. These binary models will be used to fit microlensing event data from the Vera C. Rubin Observatory, the Nancy Grace Roman Telescope, and other surveys.",
    "authors": [
      "T. Dex Bhadra",
      "J.R. Lu",
      "Natasha S. Abrams",
      "Andrew Scharf",
      "Edward Broadberry",
      "Casey Lam",
      "Macy J. Huston"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03411",
    "title": "Conformal Holographic Dark Energy",
    "abstract": "Recent results from the DESI collaboration suggest a preference for an evolving dark energy (DE) component rather than a cosmological constant, motivating the exploration of alternative models for the background expansion. These data also reveal tension in the inferred matter density parameter -lower in DESI and higher in Planck- as well as a neutrino mass posterior that approaches the lower bounds permitted by oscillation experiments. In this work, we propose and test a conformal holographic DE (CHDE) model in which the DE density depends on a power law of the conformal time, characterized by an exponent (n). This formulation introduces a single additional parameter relative to LambdaCDM and reduces to it in the limit n = 0. We confront the CHDE model with BAO, CMB, and supernova datasets, following the same combinations used by DESI, and perform parameter inference under both flat and non-flat cosmologies. Our analyses show that LambdaCDM is not favored as the best-fit model when using CMB data alone or in joint analyses including BAO and SNla, and it is disfavored at the 4.4 sigma level for non-flat model and 4.5 sigma for the flat model. We obtain consistent values of n= -0.28 to -0.32 with uncertainties less than +-0.1 across multiple data combinations. Similar to LambdaCDM, the CHDE model predicts a lower matter density when employing DESI data instead of Planck data. This, in turn, influences the neutrino mass constraints, yielding values close to the minimal allowed range. Despite these dataset-dependent tensions, both the flat and curved CHDE models remain compatible with neutrino mass constraints from terrestrial experiments and yield posterior distributions that peaks at positive values. This behavior avoids the issue encountered in the LambdaCDM model, where the posterior peaks at negative mass values.",
    "authors": [
      "Mario A. Rodríguez-Meza",
      "Jorge L. Cervantes-Cota",
      "Tonatiuh Matos"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03415",
    "title": "Building a Radio AGN Sample from Cosmic Morning -- The Radio High-Redshift Quasar Catalog (RHzQCat): I. Catalog from SDSS Quasars and Radio Surveys at $z > 3$",
    "abstract": "Radio-loud high-redshift quasars (RHRQs) provide crucial insights into the evolution of relativistic jets and their connection to the growth of supermassive black holes. Beyond the extensively studied population at $z \\ge 5$, the cosmic morning epoch ($3 \\lesssim z \\lesssim 5$) marks the peak of active galactic nucleus (AGN) activity and black hole accretion, yet remains relatively unexplored. In this work, we compiled the radio high-redshift quasar catalog (RHzQCat) by cross-matching the SDSS DR16Q catalog with four major radio surveys -- FIRST,NVSS, RACS, and GLEAM. Our tier-based cross-matching framework and visual validation ensured reliable source identification across surveys with diverse beam sizes. The catalog included 1629 reliable and 315 candidate RHRQs, with radio luminosities uniformly spanning $10^{25.5}$ -- $10^{29.3}$ W Hz$^{-1}$. About 95\\% of the confirmed sources exhibited compact morphologies, consistent with Doppler-boosted or young AGN populations at high redshifts. Our catalog increases the number of known RHRQs at $z\\ge3$ by an order of magnitude, representing the largest and most homogeneous catalog of radio quasars at cosmic morning, filling the observational gap between the early ($z>6$) and local Universe. It provides a robust reference for future statistical studies of jet evolution, AGN feedback, and cosmic magnetism with next-generation facilities such as the Square Kilometer Array (SKA).",
    "authors": [
      "Yingkang Zhang",
      "Ruqiu Lin",
      "Krisztina Perger",
      "Sándor Frey",
      "Tao An",
      "Xiang Ji",
      "Qiqi Wu",
      "Shilong Liao"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03433",
    "title": "A Deep Chandra X-ray Survey of a Luminous Quasar Sample at $z\\sim$ 7",
    "abstract": "We present new Chandra observations of seven luminous quasars at $z>6.5$. Combined with archival Chandra observations of all other known quasars, they form nearly complete X-ray observations of all currently known $z\\sim7$ quasars with $M_{1450}<-26.5$, except for J0313$-$1806 at $z=7.642$ and J0910$-$0414 at $z=6.636$. Together with existing ground-based NIR spectroscopy and ALMA observations, we investigate the correlations between X-ray emission (the X-ray luminosity $L_{\\rm X}$ and the optical/UV-to-X-ray spectral slope $\\alpha_{\\rm OX}$) and various quasar properties (rest-UV luminosity $L_{\\mathrm{2500\\ \\mathring{A}}}$, bolometric luminosity $L_{\\rm bol}$, C IV blueshift, and infrared luminosity $L_{\\rm IR}$). We find most $z>6.5$ quasars follow a similar $\\alpha_{\\rm OX}-L_{\\mathrm{2500\\ \\mathring{A}}}$ relation as $z\\sim1-6$ quasars, but also display a large scatter. We find a potential correlation between $\\alpha_{\\rm OX}$ and the C IV blueshift, suggesting a soft optical/UV-to-X-ray SED shape is frequently associated with fast disk winds. Furthermore, we analyze the X-ray spectrum of 11 quasars at $z>6.5$ with Chandra detection, and find the best-fit photon index $\\Gamma$ is $2.41\\pm0.27$, which is likely driven by high accretion rates of $z>6.5$ quasars. In addition, we find there are no significant correlations between either $L_{\\rm X}$ and $L_{\\rm IR}$, nor $L_{\\rm bol}$ and $L_{\\rm IR}$, suggesting no strong correlations between quasar luminosity and star formation luminosity for the most luminous quasars at $z>6.5$.",
    "authors": [
      "Xiangyu Jin",
      "Feige Wang",
      "Jinyi Yang",
      "Xiaohui Fan",
      "Fuyan Bian",
      "Jiang-Tao Li",
      "Weizhe Liu",
      "Yichen Liu",
      "Jianwei Lyu",
      "Maria Pudoka",
      "Wei Leong Tee",
      "Yunjing Wu",
      "Haowen Zhang",
      "Yongda Zhu"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03440",
    "title": "An Analysis of LIGO Glitches Using t-SNE During the First Part of the Fourth LIGO-Virgo-KAGRA Observing Run",
    "abstract": "This paper presents an analysis of noise transients observed in LIGO data during the first part of the fourth observing run, using the unsupervised machine learning technique t-distributed Stochastic Neighbor Embedding (t-SNE) to examine the behavior of glitch groups. Based on the t-SNE output, we apply Agglomerative Clustering in combination with the Silhouette Score to determine the optimal number of groups. We then track these groups over time and investigate correlations between their occurrence and environmental or instrumental conditions. At the Livingston observatory, the most common glitches during O4a were seasonal and associated with ground motion, whereas at Hanford, the most prevalent glitches were related to instrumental conditions.",
    "authors": [
      "Tabata Aira Ferreira",
      "Gabriela González",
      "Osvaldo Salas"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03443",
    "title": "Subgrid Mean-field Dynamo Model with Dynamical Quenching in General Relativistic Magnetohydrodynamic Simulations",
    "abstract": "Large-scale magnetic fields are relevant for a number of dynamical processes in accretion disks, including driving turbulence, reconnection events, and launching outflows. Numerical simulations have indicated that the initial strengths and configurations of the large-scale magnetic fields have a direct imprint on the outcome of an accretion disk evolution. To facilitate future self-consistent simulations that include intrinsic dynamo processes, we derive and implement a subgrid model of a helical large-scale dynamo with dynamical quenching in general-relativistic resistive magnetohydrodynamical simulations of geometrically thin accretion disks. By incorporating previous numerical and analytical results of helical dynamos, our model features only one input parameter, the viscosity parameter $\\alpha_\\text{SS}$. We demonstrate that our model can reproduce butterfly diagrams seen in previous local and global simulations. With rather aggressive parameter choice of $\\alpha_\\text{SS}=0.02$ and black hole spin $a_\\text{BH}=0.9375$, our thin-disk model launches weak collimated polar outflows with Lorentz factor $\\simeq 1.2$, but no polar outflow is present with less vigorous turbulence or less positive $a_\\text{BH}$. With negative $a_\\text{BH}$, we find the field configurations to appear more similar to Newtonian cases, whereas for positive $a_\\text{BH}$, the poloidal field loops become distorted and the cycle period becomes sporadic or even disappears. Moreover, we demonstrate how $\\alpha_\\text{SS}$ can avoid to be prescribed and instead be determined by the local plasma beta. Such a fully dynamical subgrid dynamo allows for self-consistent amplification of the large-scale magnetic fields.",
    "authors": [
      "Hongzhe Zhou",
      "Yosuke Mizuno",
      "Zhenyu Zhu"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03447",
    "title": "Neutrino-dominated relativistic shocked accretion flow around rotating black hole: implications for short gamma-ray bursts",
    "abstract": "We investigate the physical properties of the central engine powering gamma-ray bursts (GRBs), modelled as a stellar-mass black hole accreting via a neutrino-dominated accretion flow (NDAF). By solving the governing hydrodynamic equations, we obtain global transonic NDAF solutions featuring shock transitions and examine their role in powering GRB energetics. The NDAF solutions are explored over a broad range of black hole parameters, including its mass ($M_{\\rm BH}$) and spin ($a_{\\rm k}$), and accretion rate ($\\dot{M}$). We find that shocked NDAFs can naturally account for the observed diversity in GRB energy output. Incorporating results from numerical simulations of binary neutron star and black hole-neutron star mergers, we estimate the remnant black hole mass and spin parameters for the predicted range of post-merger disk mass ($M_{\\rm disk}$). Our analysis reveals that small-mass black holes with relatively low spin values can adequately reproduce the luminosities of short GRBs (SGRBs), whereas identical GRB luminosities can also be achieved for more massive black holes possessing higher spin values. Finally, we uncover a robust correlation between the black hole spin and disk mass such that $M_{\\rm disk}$ decreases with increasing $a_{\\rm k}$, remaining largely independent of the black hole mass ($M_{\\rm BH}$) powering GRBs.",
    "authors": [
      "Amit Kumar",
      "Sayan Chakrabarti",
      "Santabrata Das"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03456",
    "title": "Improving Accretion Diagnostics for Young Stellar Objects with Mid-infrared Hydrogen lines from JWST/MIRI",
    "abstract": "We present a comprehensive study of mid-infrared neutral hydrogen (H~\\textsc{i}) emission lines in 79 nearby (d $<$ 200 $pc$) young stars using JWST/MIRI. We aim to identify mid-infrared H~\\textsc{i} transitions that can serve as reliable accretion diagnostics in young stars, and evaluate their utility in deriving physical conditions of the accreting gas. We identify and measure 22 H~\\textsc{i} transitions in the MIRI wavelength regime (5-28 $\\mu m$) and perform LTE slab modelling to remove the H\\textsubscript{2}O contribution from selected H~\\textsc{i} transitions. We find that mid-IR H~\\textsc{i} line emission is spatially compact, even for sources with spatially extended [Ne~\\textsc{ii}] and [Fe~\\textsc{ii}] jets, suggesting minimal contamination from extended jet. Although Pfund~$\\alpha$ (H~\\textsc{i}~6--5) and Humphreys~$\\alpha$ (H~\\textsc{i}~7--6) are the strongest lines, they are blended with H$_2$O transitions. This blending necessitates additional processing to remove molecular contamination, thereby limiting their use as accretion diagnostics. Instead, we identify the H~\\textsc{i}~(8--6) at 7.502 $\\mu m$ and H~\\textsc{i}~(10--7) at 8.760 $\\mu m$ transitions as better alternatives, as they are largely unaffected by molecular contamination and offer a more reliable means of measuring accretion rates from MIRI spectra. We provide updated empirical relations for converting mid-IR H~\\textsc{i} line luminosities into accretion luminosity for 6 different H~\\textsc{i} lines in the MIRI wavelength range. Moreover, comparison of observed line ratios with theoretical models shows that MIR H~\\textsc{i} lines offer robust constraints on the hydrogen gas density in accretion columns, $n_\\mathrm{H} = $10$^{10.6}$ to 10$^{11.2}$ cm$^{-3}$ in most stars, with some stars exhibiting lower densities ($<10^{10}$~cm$^{-3}$), approaching the optically thin regime.",
    "authors": [
      "B Shridharan",
      "P Manoj",
      "Vinod Chandra Pathak",
      "Alessio Caratti O Garatti",
      "Bihan Banerjee",
      "Th. Henning",
      "I. Kamp",
      "E. van Dischoeck",
      "H. Tyagi",
      "R. Arun",
      "B. Mathew",
      "M. Güdel",
      "P.-O. Lagage"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03472",
    "title": "Quasi-linear theory of perpendicular ion heating by critically balanced turbulence",
    "abstract": "In collisionless astrophysical plasmas, turbulence mediates the partitioning of free energy among cascade channels and its dissipation into ion and electron heat. The resulting ion heating is often anisotropic, with ions observed to be preferentially heated perpendicular to the local magnetic field; understanding the mechanisms responsible for this heating is a key step in understanding the evolution of such plasmas. In this paper, we use the framework of quasi-linear theory to compute analytically the heating rates of ions interacting with turbulent, large-scale Alfvénic fluctuations. We show how the imbalance of the turbulence (the difference in energies between Alfvénic fluctuations travelling parallel and antiparallel to the magnetic field) modifies the spatiotemporal spectrum of these fluctuations, allowing the heating mechanism to transition between two commonly-studied mechanisms: stochastic heating in balanced turbulence to resonant-cyclotron heating in imbalanced turbulence. The resultant heating rate is found to have a general form regardless of the level of imbalance, exhibiting a suppression related to the conservation of the ions' magnetic moment at small turbulent amplitudes and recovering previous empirical results in a formal calculation. The results of this work help to consolidate our qualitative understanding of ion heating within astrophysical plasmas, as well as yielding specific quantitative predictions to analyse simulations and observations.",
    "authors": [
      "Zade Johnston",
      "Jonathan Squire"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03523",
    "title": "A 7 Day Multiwavelength Flare Campaign on AU Mic. IV: Quiescent Gyrosynchrotron and Gyroresonance Radiation from 12 to 25 GHz",
    "abstract": "We present an analysis of the radio quiescent data from a multiwavelength campaign of the active M-dwarf flare star AU Mic (dM1e) that occurred in October 2018. Using Ku-band data (12 to 18 GHz) from the Very Large Array and K-band data (17 to 25 GHz) from the Australia Telescope Compact Array, we find that the quiescent spectrum can be decomposed into two components: one falling with frequency and one that remains flat. The flat component has a relatively steady flux density of 0.64 $\\pm$ 0.14 mJy. The falling component varies in strength, but exhibits a spectral index of $\\alpha$ = $-0.88 \\pm 0.10$. The falling component is thus consistent with nonthermal, optically thin gyrosynchrotron radiation with a corresponding power-law index similar to flares from AU Mic. While a flat component may arise from thermal, optically thin free-free emission, the observed flux density and inferred mass-loss rate are both too large compared to previous stellar wind and X-ray emission theory and models, necessitating an alternative explanation. This flat component instead matches well with an optically thick gyroresonance component integrated over multiple source regions such that the composite spectra are reasonably flat. The persistence of these components across the rotational period suggests multiple source regions, which may help explain changes in flux density and persistent high-energy electrons.",
    "authors": [
      "Isaiah I. Tristan",
      "Rachel A. Osten",
      "Yuta Notsu",
      "Adam F. Kowalski",
      "Steven R. Cranmer"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03531",
    "title": "The helium common-envelope wind scenario for SN 2020eyj",
    "abstract": "SN 2020eyj is the first type Ia supernova (SN Ia) showing the signature of a compact helium-rich circumstellar material (CSM). Such a large CSM is difficult to explain in a single-degenerate scenario where the donor star is a helium star. Here we show that, under certain conditions, it is possible that the transfer of helium leads to a common envelope (CE) engulfing the system, similar to the common-envelope wind model proposed by Meng \\& Podsiadlowski (2017). If in such a helium common-envelope wind (HeCEW) model the initial white dwarf (WD) mass is larger than 1.1 $M_{\\rm \\odot}$ and the helium star more massive than 1.8 $M_{\\rm \\odot}$, the mass of a helium CE can be larger than 0.3 $M_{\\rm \\odot}$ prior to supernova explosion. The CE mass heavily depends on the initial parameters of the binary system. A dynamical CE ejection event could occur shortly before the supernova, and then our model may naturally explain the properties of SN 2020eyj, specifically the massive He-rich CSM, its dim peak brightness, low ejecta velocity and low birth rate.",
    "authors": [
      "Xiang-Cun Meng",
      "Philipp Podsiadlowski"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03533",
    "title": "Resolving the Multiple Component Outflows in PG 1211+143: I. The Fe-K Absorption Structure and UFO Forest",
    "abstract": "We present the initial high-resolution X-ray spectroscopic observations of the Fe-K absorption structure in the luminous nearby quasar PG 1211+143, utilizing the X-ray Imaging and Spectroscopy Mission (XRISM). The primary objective is to characterize the Fe-K absorption features due to Ultra-Fast Outflow (UFO) in this Eddington-luminosity source. Observations were conducted with XRISM's Resolve and Xtend instruments, complemented by simultaneous data from XMM-Newton and NuSTAR. A historically bright phase was captured. The Resolve spectra clearly reveal a prominent P Cygni profile and resolves the Fe-K absorption into six distinct velocity components, ranging from $v = -0.074c$ to $-0.405c$. A similar superposition of multiple UFOs has been reported in PDS~456, suggesting that such a ``UFO forest'' structure may be a common feature of near Eddington-luminosity sources. Some UFO components exhibit narrow line widths of approximately $\\sigma \\sim 200\\,\\mathrm{km\\,s^{-1}}$, which may indicate that the outflows have reached their terminal velocities, thereby resulting in a smaller velocity shear. The mass outflow rate is estimated to be $\\dot{M}_\\mathrm{out} \\sim 1~M_{\\odot}~\\text{yr}^{-1}$, which is of the order of the Eddington accretion rate. This suggests a physically plausible scenario where the outflow is a significant channel for mass ejection.",
    "authors": [
      "Misaki Mizumoto",
      "James N. Reeves",
      "Valentina Braito",
      "Ehud Behar",
      "Chris Done",
      "Kouichi Hagino",
      "Steven B. Kraemer",
      "Gabriele A. Matzeu",
      "Hirofumi Noda",
      "Mariko Nomura",
      "Shoji Ogawa",
      "Ken Ohsuga",
      "Atsushi Tanimoto",
      "Tracey J. Turner",
      "Yoshihiro Ueda",
      "Satoshi Yamada",
      "Sreeparna Ganguly",
      "Paolo Somenzi"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03550",
    "title": "Genetic Algorithm for Inferring Model Parameters for Flux Transport Dynamo Simulation",
    "abstract": "The Sun exhibits an 11-year cyclic variation, maintained by dynamo action in the solar interior. Mean-field flux transport dynamo models have successfully reproduced most of the features observed in solar cycles, while the model includes many free parameters, such as the speed of the meridional flow and the amplitude of the poloidal field generation. Inferring these free parameters is on demand because they correspond to the solar interior condition. We suggest a novel method for inferring the free parameters using a genetic algorithm. At each generation, we evaluate the fitness of our simulation against the observational data and optimize the parameters. We apply our method to the observed solar cycle data from 1723 to 2024 and successfully reproduce the observations from both qualitative and quantitative perspectives. We expect our method to be applicable to sunspot numbers, even those obtained from isotope data and historical documents, in the future, to better understand past solar interior dynamics.",
    "authors": [
      "Yuya Shimizu",
      "Hideyuki Hotta"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03552",
    "title": "Dynamical and Photometric Analysis of NGC 146 and King 14: Evidence for a Co-Moving, Unbound Cluster Pair",
    "abstract": "To understand the nature of the NGC 146-King 14 cluster pair, we conducted a detailed photometric, astrometric, and dynamical study using multiwavelength data from Gaia DR3, Pan-STARRS1, WISE, and TESS. Using a probabilistic approach, we identified 770 and 690 high-probability members of NGC 146 and King 14, respectively. Both clusters exhibit well-defined radial density profiles consistent with King models. We estimate the cluster ages as 20 $\\pm$ 5 Myr and 50 $\\pm$ 10 Myr from isochrone fitting, and distances of 2.98 $\\pm$ 0.33 kpc and 2.51 $\\pm$ 0.23 kpc from parallaxes after applying the Bailer-Jones criteria. The clusters show consistent mean proper motions. The mass function slopes (1.51 $\\pm$ 0.18 and 1.50 $\\pm$ 0.15) are close to the Salpeter value, and the extinction follows a normal Galactic reddening law (RV ~ 3.1). Three-dimensional mapping gives a projected separation of ~ 9 pc. Orbit integration using the galpy MWPotential2014 model shows that NGC 146 and King 14 move in nearly circular, disk-like orbits with similar mean orbital radii (Rm ~ 9 kpc) and orbital periods of roughly 255 Myr. A dynamical separation of ~ 32 pc indicates that both clusters share a common spatial and kinematic association, consistent with a co-moving pair. However, their relative velocity exceeds the escape velocity set by their combined mass, indicating they are not gravitationally bound. TESS light curves reveal seven variable stars, including $\\gamma$ Doradus, SPB stars, and eclipsing binaries, though only one is a likely member. Overall, the clusters likely formed within the same giant molecular cloud and now exist as an unbound co-moving pair.",
    "authors": [
      "D. Bisht",
      "Ing-Guey Jiang",
      "W. H. Elsanhoury",
      "K. Belwal",
      "D. C. Cınar",
      "A. Raj",
      "Shraddha Biswas",
      "Arvind K. Dattatrey",
      "Geeta Rangwal",
      "Devesh P. Sariya",
      "Mohit Singh Bisht",
      "Alok Durgapal"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03591",
    "title": "Statistical and Temporal Analysis of Multi-component Burst-clusters from the Repeating FRB 20190520B",
    "abstract": "Fast Radio Bursts (FRBs) are bright, millisecond-duration extragalactic radio transients that probe extreme astrophysical environments. Many FRBs exhibit multi-component structures, which encode information about their emission mechanisms or progenitor systems and thus provide important clues to their origins. In this work, we systematically analyze the burst morphology of FRB 20190520B and compare component distributions across four active FRBs observed with FAST: FRB 20121102A, FRB 20190520B, FRB 20201124A, and FRB 20240114A. We find that multi-component burst-clusters show spectral properties similar to single-peak bursts, and no periodicity is detected in their temporal behavior. The component-count distributions follow a power law, revealing scale-free behavior consistent with self-organized criticality (SOC) processes. Multi-component clusters account for 12-30% of all detected bursts, regardless of source activity, providing new insights into burst-to-burst variability and the physical processes driving FRB emission.",
    "authors": [
      "Jia-heng Zhang",
      "Chen-Hui Niu",
      "Yu-hao Zhu",
      "Di Li",
      "Wei-yang Wang",
      "Yi Feng",
      "Xin-ming Li",
      "Jia-rui Niu",
      "Pei Wang",
      "Yun-wei Yu",
      "Yong-kun Zhang",
      "Xiao-ping Zheng"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03611",
    "title": "The first out-of-ecliptic observations of the polar magnetic field of the Sun",
    "abstract": "Direct remote-sensing observations of the solar poles have been hindered by the restricted view obtained from the ecliptic plane. For the first time ever, Solar Orbiter with its remote-sensing instruments observed the poles of the Sun from out of the ecliptic in the Spring of 2025. Here we report the first measurements of the magnetic field of the solar poles taken when Solar Orbiter was at heliographic latitudes ranging between 14.9$^\\circ$ and 16.7$^\\circ$. The data-sets were collected by the High Resolution Telescope of the Polarimetric and Helioseismic Imager (SO/PHI-HRT) on board Solar Orbiter. Two sets of observations, approximately one month apart, for the south and north pole are considered in this work. The magnetic flux and flux density measured during these campaigns are reported as a function of the heliographic latitude observed by SO/PHI-HRT. The net fluxes show a different latitudinal distribution for the two polar caps. We also discuss the observed dependence of the measured fluxes on the viewing angle. These first results highlight the importance of high-resolution direct measurements of the polar field, paving the way to the high-latitude observations planned for SO/PHI-HRT in the coming years.",
    "authors": [
      "D. Calchetti",
      "S. K. Solanki",
      "J. Hirzberger",
      "G. Valori",
      "L. P. Chitta",
      "J. Blanco Blanco Rodríguez",
      "A. Giunta",
      "T. Grundy",
      "K. Albert",
      "T. Appourchaux",
      "F. J. Bailén",
      "L. R. Bellot Rubio",
      "A. Feller",
      "A. Gandorfer",
      "L. Gizon",
      "A. Korpi-Lagg",
      "X. Li",
      "A. Moreno Vacas",
      "T. Oba",
      "D. Orozco Suárez",
      "J. Schou",
      "U. Schühle",
      "J. Sinjan",
      "H. Strecker",
      "J. C. del Toro Iniesta",
      "A. Ulyanov",
      "R. Volkmer",
      "J. Woch"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03692",
    "title": "Long-term calibration and validation of stability of the Auger Engineering Radio Array using the diffuse Galactic radio emission",
    "abstract": "The Auger Engineering Radio Array (AERA) measures radio emission from high-energy extensive air showers. Consisting of 153 autonomous radio-detector stations spread over $17$\\,km$^2$, it detects radio waves in the frequency range of $30$ to $80$\\,MHz. Accurate characterization of the detector response is crucial for proper interpretation of the collected data. Previously, this was achieved through laboratory measurements of the analog chain and simulations and measurements of the antenna's directional response. In this paper, we perform an absolute calibration using the continuously monitored sidereal modulation of the diffuse Galactic radio emission. Calibration is done by comparing the average frequency spectra recorded by the stations with predictions from seven different models of the full radio sky, accounting for the system response, which includes the antenna, filters, and amplifiers. The analysis of the calibration constants over a period of seven years shows no relevant and no significant ageing effect in the AERA antennas. This result confirms the long-term stability of the detector stations and demonstrates the possibility for a radio detector to effectively monitor ageing effects of other detectors operating over extended periods.",
    "authors": [
      "Pierre Auger Collaboration",
      "A. Abdul Halim",
      "P. Abreu",
      "M. Aglietta",
      "I. Allekotte",
      "K. Almeida Cheminant",
      "R. Aloisio",
      "J. Alvarez-Muñiz",
      "A. Ambrosone",
      "J. Ammerman Yebra",
      "L. Anchordoqui",
      "B. Andrada",
      "L. Andrade Dourado",
      "L. Apollonio",
      "C. Aramo",
      "E. Arnone",
      "J.C. Arteaga Velázquez",
      "P. Assis",
      "G. Avila",
      "E. Avocone",
      "A. Bakalova",
      "Y. Balibrea",
      "A. Baluta",
      "F. Barbato",
      "A. Bartz Mocellin",
      "J.P. Behler",
      "C. Berat",
      "M.E. Bertaina",
      "M. Bianciotto",
      "P.L. Biermann",
      "V. Binet",
      "K. Bismark",
      "T. Bister",
      "J. Biteau",
      "J. Blazek",
      "J. Blümer",
      "M. Boháčová",
      "D. Boncioli",
      "C. Bonifazi",
      "N. Borodai",
      "J. Brack",
      "P.G. Brichetto Orquera",
      "A. Bueno",
      "S. Buitink",
      "M. Büsken",
      "A. Bwembya",
      "K.S. Caballero-Mora",
      "S. Cabana-Freire",
      "L. Caccianiga",
      "J. Caraça-Valente",
      "R. Caruso",
      "A. Castellina",
      "F. Catalani",
      "G. Cataldi",
      "L. Cazon",
      "M. Cerda",
      "B. Čermáková",
      "A. Cermenati",
      "K. Cerny",
      "J.A. Chinellato",
      "J. Chudoba",
      "L. Chytka",
      "R.W. Clay",
      "A.C. Cobos Cerutti",
      "R. Colalillo",
      "R. Conceição",
      "G. Consolati",
      "M. Conte",
      "F. Convenga",
      "D. Correia dos Santos",
      "P.J. Costa",
      "C.E. Covault",
      "M. Cristinziani",
      "C.S. Cruz Sanchez",
      "S. Dasso",
      "K. Daumiller",
      "B.R. Dawson",
      "R.M. de Almeida",
      "E.-T. de Boone",
      "B. de Errico",
      "J. de Jesús",
      "S.J. de Jong",
      "J.R.T. de Mello Neto",
      "I. De Mitri",
      "D. de Oliveira Franco",
      "F. de Palma",
      "V. de Souza",
      "E. De Vito",
      "A. Del Popolo",
      "O. Deligny",
      "N. Denner",
      "K. Denner Syrokvas",
      "L. Deval",
      "A. di Matteo",
      "C. Dobrigkeit",
      "J.C. D'Olivo",
      "L.M. Domingues Mendes",
      "Y. Dominguez Ballesteros",
      "Q. Dorosti",
      "R.C. dos Anjos"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03695",
    "title": "The ANDICAM-SOFI Near-infrared and Optical type Ia Supernova (ASNOS) sample: Description and data release",
    "abstract": "Type Ia supernovae (SNe Ia) provide the most robust means of measuring extragalactic distances. While most of the effort has focused on increasing the number of SNe Ia observed in the optical, near-infrared (NIR) observations remain scarce despite their advantages, that is, reduced dust extinction and a more intrinsic standard candle behavior, requiring little to no empirical corrections. Here, we present ASNOS (ANDICAM-SOFI Near-infrared and Optical type Ia Supernova), a dataset with sample size of 1,482 epochs in the $BVRIYJH$ filters from the ANDICAM instrument on the 1.3-meter SMARTS telescope at Cerro Tololo Inter-American Observatory, along with 125 $JHK$ epochs from the SOFI instrument on the 3.58-meter New Technology Telescope on the La Silla Observatory. Additionally, we incorporate optical forced photometry from the Zwicky Transient Facility and the Asteroid Terrestrial-impact Last Alert System. The sample comprises 41 SNe Ia in total, including 29 normal events, eight 1991T-like objects, and four peculiar subtypes, all located at redshifts $z < 0.085$. This paper provides a detailed overview of the ASNOS sample selection, data reduction, SN photometry, host-galaxy spectral energy distribution construction, both global and local, and SN light-curve fitting using three methods: SALT3-NIR, SNooPy, and BayeSN. A companion paper will present the cosmological analysis.",
    "authors": [
      "Kim Phan",
      "Lluís Galbany",
      "Tomás E. Müller-Bravo",
      "Subhash Bose",
      "Christopher R. Burns",
      "Maximilian D. Stritzinger",
      "Camilla T. G. Sørensen",
      "Chris Ashall",
      "Francisco J. Castander",
      "Cristina Jiménez Palau",
      "Joel Johansson",
      "Joseph P. Anderson",
      "Ken. C. Chambers",
      "Mariusz Gromadzki",
      "Priscila J. Pessi",
      "Ting-Wan Chen"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03700",
    "title": "Lightweight design and analysis of optical cover plate for exoplanet imaging coronagraph",
    "abstract": "In order to reduce the load mass and solve the problem that the aluminum alloy optical cover plate of exoplanet imaging coronagraph was easy to deform, based on the equal generation design method, this paper designed and determined the configuration of the carbon fiber optical cover plate. Through the simulation of layup by finite element analysis, this paper researched the influence of different layering angles and sequences on the stiffness of optical cover plate. Finally, the carbon fiber layup method was determined as [15/-75/-15/75]s. The dynamic response analysis show that all the indexes satisfy the system requirements, and verify the feasibility of carbon fiber optical cover plate.",
    "authors": [
      "Lingyi Kong",
      "Mingming Xu",
      "Wei Guo",
      "Jiangpei Dou",
      "Bo Chen",
      "Shu Jiang"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03702",
    "title": "Trapped fireshell (halo) of photons and pairs around black-hole horizon: source for ultra-high-energy particles",
    "abstract": "We study the Compton-rocket effect of multi-photon interacting with electrons in an opaque fireball (or fire spot) of photons and $e^-e^+$ pairs at temperature $T_\\gamma\\gg m_e$. We find the charged-particle acceleration and the avalanche runaway process, leading to a non-trivial probability of ultra-high-energy (UHE) electrons and protons, which subsequently produce very-high-energy (VHE) photons and neutrinos. We show such peculiar dynamics using the Gamma-Ray Burst central engine fireball, whose inner part inflows and forms a gravitationally trapped fireshell (halo) around a black hole. The halo is a metastable, cooling via UHE particle emissions and blackbody radiation. We calculate the UHE particle luminosity varying in time, and discuss the peculiar features of such produced UHE particles, which lead to VHE particles, in connection with possible numerical simulations, observations and experiments.",
    "authors": [
      "She-Sheng Xue"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03716",
    "title": "The broad-lined Type Ic supernova 2020lao reveals an energetic explosion with no central-engine signatures",
    "abstract": "We present early-time observations of the broad-lined Type Ic supernova SN 2020lao, including optical spectroscopy beginning about 48 hr after the inferred explosion and extending to about 100 days. The explosion epoch is constrained with power-law fits to the rising TESS and ZTF light curves, with the first ZTF detection only about 27 hr after explosion. The optical light curves show a rapid 8.8 day rise and a peak luminosity typical of SNe Ic-BL (Mr=-18.5 mag). Unlike some engine-driven events, SN 2020lao shows no early optical excess or afterglow. The lack of a shock-cooling signature in the TESS/ZTF data constrains the progenitor to a compact Wolf Rayet-like star with radius of only a few solar radii. The spectra resemble those of the X-ray flash SN 2006aj but with higher velocities. Arnett modeling of the bolometric light curve, combined with Fe II velocities, yields a nickel mass of about 0.2 solar masses, an ejecta mass of about 3.2 solar masses, and a kinetic energy of about 23x10^51 erg, corresponding to a high specific kinetic energy of about 7x10^51 erg per solar mass. Spectral-synthesis modeling broadly reproduces the photospheric spectra and suggests a somewhat lower but still large specific kinetic energy (about 5 x 10^51 erg per solar mass). Although SN 2020lao and SN 2006aj produced similar 56Ni masses, SN 2020lao exhibits specific kinetic energies larger by a factor of several. Published VLA and Swift/XRT non-detections show no radio or X-ray afterglow, placing strong limits on relativistic ejecta and dense circumstellar material. Given its high specific kinetic energy, the absence of early excess emission and the radio/X-ray non-detections imply that any jet was either far off-axis or choked; otherwise, SN 2020lao represents an extreme non-relativistic SN Ic-BL.",
    "authors": [
      "M. D. Stritzinger",
      "T. J. Moriya",
      "S. Bose",
      "P. A. Mazzali",
      "P. Lundqvist",
      "E. Karamehmetoglu",
      "L. S. Arndt",
      "C. Ashall",
      "L. Galbany",
      "W. B. Hoogendam",
      "E. Baron",
      "J. M. DerKacy",
      "N. Elias-Rosa",
      "E. Y. Hsiao",
      "P. Höflich",
      "E. Pian",
      "E. A. M. Jensen",
      "S. Moran",
      "A. Pastorello",
      "M. Shahbandeh",
      "G. Valerin"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03798",
    "title": "Gamma-ray astronomy from the ground - future perspectives",
    "abstract": "I provide a personal perspective on the future of the field of ground-based gamma-ray astronomy, on the occasion of the 2024 {\\it Gamma} conference in Milan. I discuss some of the scientific motivations for new instrumentation and the major new projects that are in development or already under construction, together with emerging concepts for instrumentation in the farther future. I stress the strong complementarity of the ground-level particle detector arrays, with their wide-field capabilities, and the more precise Cherenkov telescope arrays. The key science topics for the next decades require both approaches and both are developing rapidly towards major performance advances and full sky coverage. I will briefly outline the status and roles of the projects CTAO and SWGO which will dominate the next decade. Beyond these projects are several developments which might boost performance at both ends of the ground-based gamma-ray energy range, including the plenoscope approach at low energies and diverse approaches to ultra-high-energy gamma-ray astronomy; from lake-based instruments to arrays of very small Cherenkov telescopes. I will again briefly review these activities and how they may contribute long term.",
    "authors": [
      "Jim Hinton"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03824",
    "title": "The impact of our peculiar motion on primordial non-Gaussianity measurements using the LIGER4GAL framework",
    "abstract": "Current and forthcoming galaxy surveys will map the observable Universe with unprecedented depth, sky coverage, and precision. These maps are affected by relativistic redshift-space distortions (RSDs), which become increasingly relevant on ultra-large scales. Accurate modelling of these relativistic RSDs is essential to avoid systematic biases in key cosmological measurements, such as primordial non-Gaussianity (PNG). To address this, we introduce an updated implementation of the LIGER method, LIGER4GAL, which incorporates all linear-order relativistic RSDs directly at the tracer level of high-resolution N-body simulations. We demonstrate that LIGER4GAL improves upon previous iterations of the LIGER method by reproducing the expected non-linear clustering while maintaining accuracy for relativistic RSDs on large scales. We use the updated code to generate a DESI-like sample of luminous red galaxies from the Huge MultiDark Planck simulation. By measuring the power spectrum multipoles of this sample with and without the imprint of relativistic RSDs, we assess the impact of relativistic effects on measurements of the local PNG signal ($f_\\mathrm{nl}$). We find that the omission of the''finger-of-the-observer'' (sourced by the peculiar velocity of the observer) effect in the power spectrum modelling can bias measurements of $f_{\\rm nl}$ by more than $1$ ($0.25$) $ \\sigma_{f_{\\rm nl}}$ in 40% (80%) of the possible realizations of the universe if scales down to $k_\\mathrm{min} = 0.0015\\,h/\\mathrm{Mpc}$ are included.",
    "authors": [
      "Bartolomeo Bottazzi Baldi",
      "Mohamed Yousry Elkhashab",
      "Daniele Bertacca",
      "Cristiano Porciani"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03830",
    "title": "Magnetic activity on the young Sun: a case study of EK Draconis",
    "abstract": "Context. Young, solar analogue stars provide key insights into the early stages of stellar evolution, particularly in terms of magnetic activity and rotation. Their rapid rotation, high flaring rate, and enhanced surface activity make them ideal laboratories for testing stellar models or even the solar dynamo. Aims. Using long-term photometric data, we investigated the cyclic behaviour of EK Dra over the last century. We analyze its short- term activity based on 13 Transiting Exoplanet Survey Satellite (TESS) sectors. Applying Doppler imaging on high-resolution spectral data we investigate short and long-term spot evolution and surface differential rotation. Methods. We use Short-term Fourier-transform on a 120 years long archival photometric data in order to search for activity cycles. The short-term space photometry data is fitted with an analytic three-spot model, and we hand-select flares from it to analyze their phase and frequency distribution. Spectral synthesis is used to determine the astrophysical parameters of EK Dra. Using the iMap multi-line Doppler imaging code, we reconstruct 13 Doppler images. Differential rotation is derived by cross-correlating consecutive Doppler maps. Results. Long-term photometric data reveal a 10.7-12.1 year cycle that was persistently present for 120 years. In the more recent half of the light curve a 7.3-8.2 years-long signal is also visible. The distribution of the 142 flares in the TESS data shows no correlation with the rotational phase or with the spotted longitudes. The reconstructed Doppler images show a surface that varies from rotation to rotation, putting the lower limit of the spot lifetime between 10-15 days. Based on the cross-correlation of the Doppler maps, EK Dra has a solar-type differential rotation with a surface shear parameter of $\\alpha_{DR} = 0.030 \\pm 0.008$.",
    "authors": [
      "A. Görgei",
      "L. Kriskovics",
      "K. Vida",
      "B. Seli",
      "K. Oláh",
      "P. Sági",
      "A. Bódi",
      "S.P. Järvinen",
      "K.G. Strassmeier",
      "A. Pál",
      "Zs. Kővári"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03845",
    "title": "Tracing the Cosmic Evolution of the Cool Circumgalactic Medium of Luminous Red Galaxies with DESI Year 1 Data",
    "abstract": "We investigate the properties of the cool circumgalactic medium (CGM) of massive galaxies and their cosmic evolution. By using the year 1 dataset of luminous red galaxies (LRGs) and QSOs from the Dark Energy Spectroscopic Instrument survey, we construct a sample of approximately 600,000 galaxy-quasar pairs and measure the radial distribution and kinematics of the cool gas traced by Mg II absorption lines as a function of galaxy properties from redshift 0.4 to redshift 1.2. Our results show that the covering fraction of the cool gas around LRGs increases with redshift, following a trend similar to the global evolution of galaxy star formation rate. At small radii (< 0.3rvir), the covering fraction anti-correlates with stellar mass, suggesting that mass-dependent processes suppress the cool gas content in the inner region. In addition, we measure the gas dispersion by modeling the velocity distribution of absorbers with a narrow and a broad components -- sigma_n ~ 60 and sigma_b ~ 380 km/s -- and quantify their relative contributions. The results show that the broad component becomes more prominent in the outer region, and its relative importance in the central region grows with increasing stellar mass. Finally, we discuss possible origins of the cool gas around massive galaxies, including the contribution of satellite galaxies and the precipitation scenario.",
    "authors": [
      "Yu-Ling Chang",
      "Ting-Wen Lan",
      "J. Xavier Prochaska",
      "Malgorzata Siudek",
      "J. Aguilar",
      "S. Ahlen",
      "A. Anand",
      "D. Bianchi",
      "D. Brooks",
      "F. J. Castander",
      "T. Claybaugh",
      "A. de la Macorra",
      "P. Doel",
      "S. Ferraro",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztanaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "J. Guy",
      "K. Honscheid",
      "R. Joyce",
      "S. Juneau",
      "A. Kremin",
      "O. Lahav",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "M. E. Levi",
      "M. Manera",
      "A. Meisner",
      "R. Miquel",
      "S. Nadathur",
      "J. A. Newman",
      "W. J. Percival",
      "C. Poppett",
      "F. Prada",
      "I. Perez-Rafols",
      "G. Rossi",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "D. Sprayberry",
      "G. Tarle",
      "B. A. Weaver",
      "R. Zhou",
      "H. Zou"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03867",
    "title": "The Cosmological Dipole in Tilted Anisotropic Universes",
    "abstract": "There is tentative evidence for a mismatch between the rest frames of matter and the cosmic microwave background, the \"quasar dipole anomaly\". We consider such a dipole in tilted anisotropic models, for a range of scenarios and sources: spatial curvature, cosmic heat flux, large scale electromagnetic fields and a Khronon field. Crucially, we determine the ancillary effects on other cosmological observables in each of these models and we show that, apart from the case of the Khronon field, it is unlikely that one can obtain a dipole with the amplitude that is being observed unless one considers additional exotica.",
    "authors": [
      "Alicia Martín",
      "Constantinos Skordis",
      "Deaglan J. Bartlett",
      "Harry Desmond",
      "Pedro G. Ferreira",
      "Tariq Yasin"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03888",
    "title": "The anisotropy and magnetic field structure of neutron stars through gravitational wave",
    "abstract": "We investigate how gravitational wave (GW) observations can probe the internal physics of neutron stars by extending the Tolman-Oppenheimer-Volkoff framework to include pressure anisotropy and internal magnetic fields. Two representative magnetic field configurations, radial orientation dominated (RO) and transverse orientation dominated (TO), are implemented with strength and decay prescriptions. We found that both anisotropy and magnetic fields increase the maximum supported mass and modify the tidal deformability $\\Lambda$, thereby imprinting measurable signatures on GW signals. For the equal mass binary ($1.2M_\\odot$-$1.2M_\\odot$), anisotropy neutron star with RO magnetic field yield more compact stars and a larger shift in $\\Lambda$, allowing discrimination at signal-to-noise ratios (SNRs) as low as $\\sim18$ using the O4 power spectra density. TO fields produce weaker effects and require substantially higher SNRs for detection. In conclusion, we conclude that gravitational waves are capable of probing the internal structure of neutron stars.",
    "authors": [
      "Zhao-Wei Du",
      "Xi-Long Fan"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03892",
    "title": "Predictions of the LSST Solar System Yield: Neptune Trojans",
    "abstract": "The NSF-DOE Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST), beginning full operations in late 2025, will dramatically transform solar system science by vastly expanding discoveries and providing detailed characterization opportunities across all small body populations. This includes the co-orbiting 1:1 resonant Neptune Trojans, which are thought to be dynamically hot captures from the protoplanetary disk. Using the survey simulator $\\texttt{Sorcha}$, combined with the latest LSST cadence simulations, we present the very first predictions for the Neptune Trojan yield within the LSST. We forecast a model-dependent median number of $\\sim130-300$ discovered Neptune Trojans, and infer a notable 2:1 detection bias toward the recently emerged L5 cloud near the galactic plane versus the L4 cloud, reflecting the lower-cadence coverage in the Northern Ecliptic Spur region that suppresses L4 detections. The additionally simulated Science Validation survey will offer the very first early insights into this understudied cloud. Around 60\\% of detected main survey Neptune Trojans will meet stringent color light curve quality criteria, increasing the sample size more than fourfold compared to existing datasets. This enhanced sample will enable robust statistical analyses of Neptune Trojan color and size distributions, crucial for understanding their origins and relationship to the broader trans-Neptunian population. These comprehensive color measurements represent a major step forward in characterizing the Neptune Trojan population and will facilitate future targeted spectroscopic observations.",
    "authors": [
      "Joseph Murtagh",
      "Megan E. Schwamb",
      "Pedro H. Bernardinelli",
      "Hsing Wen Lin",
      "Jacob A. Kurlander",
      "Stephanie R. Merritt",
      "Samuel Cornwall",
      "Mario Jurić",
      "Grigori Fedorets",
      "Matthew J. Holman",
      "Siegfried Eggl",
      "R. Lynne Jones",
      "Peter Yoachim",
      "Joachim Moeyens",
      "Jeremy Kubica",
      "Drew Oldag",
      "Maxine West",
      "Colin Orion Chandler"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03910",
    "title": "X TrA through the eyes of MATISSE: More evidence of clumpy molecular layers around C-type asymptotic giant branch stars",
    "abstract": "Aims. The goal of this study is to further the understanding of the wind formation mechanism in asymptotic giant branch (AGB) stars through the analysis of the close environment (within a few stellar radii) of the carbon star X TrA. Methods. X TrA was observed for the first time with the Mid-Infrared SpectroScopic Experiment instrument (MATISSE) in the L and N bands in low spectral resolution mode (R=30), and its close surroundings were mapped in specific wavelength ranges corresponding to specific molecules ($C_2H_2$ and HCN, at 3.1 and 3.8 $\\mu$m) and dust (amorphous carbon and, for example, Sic at 11.3 $\\mu$m), via image reconstruction techniques. Results. The angular diameter of the star ranges from 10 mas in the L band pseudo-continuum (3.5 $\\mu$m) to 20 mas at 3.1 and 11.3 $\\mu$m. The reconstructed images show some mild elongated features (along the east-west direction) and asymmetric protrusions, which are most evident around 3.1 $\\mu$m. Imaging results highlight the clumpy nature of the circumstellar environment, starting from the photospheric region up to more distant layers. Conclusions. The angular diameters found for X TrA in the image data are in agreement with previous photospheric diameter estimates (following VLTI/MIDI 8-13 $\\mu$m observations), and their wavelength dependence is similar to values found for other carbon stars observed with MATISSE (R Scl and V Hya). The 3.1 $\\mu$m images presented here show highly asymmetric features, another case of a C-rich star with irregular morphologies close to the stellar disk; this supports the notion that the $C_2H_2+HCN$ abundance distribution usually originates from a clumpy layer around carbon stars.",
    "authors": [
      "V. Răstău",
      "C. Paladini",
      "J. Drevon",
      "J. Hron",
      "F. Kerschbaum",
      "M. Wittkowski",
      "J.P. Fonfria",
      "M. Montargès",
      "T. Khouri",
      "W. Vlemmings",
      "H. Olofsson",
      "K. Ohnaka",
      "J. Alonso-Hernandez",
      "C. Sánchez Contreras",
      "L. Velilla-Prieto",
      "W.C. Danchi",
      "G. Rau",
      "F. Lykou",
      "J. Sanchez-Bermudez",
      "B. Lopez",
      "S. Höfner",
      "B. Aringer",
      "L. Planquart",
      "P. Cruzalèbes",
      "G. Weigelt"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03938",
    "title": "The first 10years of the HAWC Gamma-Ray Observatory: science results",
    "abstract": "The High-Altitude Water Cherenkov (HAWC) Observatory, located on the slopes of the Sierra Negra volcano in Mexico, began operations in March 2015. Over the past decade, HAWC has enabled the exploration of a broad range of topics in high-energy astrophysics and particle physics, resulting in more than 90 peer-reviewed publications. These studies have significantly advanced our understanding of several previously unexplored and poorly understood phenomena in the TeV energy regime. The present work provides an overview of the key scientific contributions of HAWC during its first ten years of operation.",
    "authors": [
      "Anna Lia Longinotti",
      "HAWC Collaboration"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03940",
    "title": "Capture into Apsidal Resonance and the Decimation of Planets around In-spiraling Binaries",
    "abstract": "Transiting circumbinary planets (CBPs) are conspicuously rare, and entirely absent around stellar binaries with periods $\\leq 7$ days. Here, we exploit a secular resonance to stimulate the orbit of a CBP into strong, disruptive interactions with the host binary. The process requires no tertiary companion and is triggered when the general-relativistic precession of a tightening binary matches the Newtonian precession it induces in its companion planet. Adiabatic capture in this resonance sees the binary draining angular momentum from the CBP's orbit which grows steadily in eccentricity until destabilization, and eventual ejection or engulfment. We map this resonance in phase space, then investigate the dynamical outcomes of encounter in the course of tidally shrinking binaries. With the help of orbit averaged simulations of a suite of systems, we find that, around tightening binaries: eight out of ten CBPs encounter and are captured in the resonance; three out of four are `destroyed'; and survivors lurk on remote, low-transit-probability orbits. This suggests that the very process which forms tight binaries effectively clears the region where transiting CBPs could reside.",
    "authors": [
      "Mohammad Farhat",
      "Jihad Touma"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03957",
    "title": "Line Polarization of Si II $λ$6355 Å in Type Ia Supernovae: A New Statistical Approach to Probe the Explosion Physics and Diversity",
    "abstract": "Spectropolarimetry provides a unique probe of ejecta asphericities, offering direct insights into the underlying explosion physics of Type Ia supernovae (SNe Ia). We analyze the statistical properties of pre-maximum spectropolarimetric data for 24 SNe Ia observed with VLT/FORS, focusing on the Si II $\\lambda$6355 Åline. Previous studies have revealed a correlation between the peak Si II polarization degree and the expansion velocity. Here, we combine these observations with multi-dimensional non-LTE radiative transfer simulations. We consider two asphericity classes: (i) lopsided abundance distributions produced by off-center delayed-detonation transitions in near-$M_{Ch}$ white dwarfs or, for example, WD collisions (Class I), and (ii) global, axisymmetric density asphericities such as those arising from explosions of rapidly rotating WDs or mergers (Class II). Our model grid spans normal to subluminous SNe Ia and successfully reproduces the observed Si II velocity-polarization trend, with higher velocities associated with stronger asphericities. Consistent with observations, transitional SNe Ia and the faint end of the normal SNe Ia population show the highest Si II polarization and are best explained by Class I scenarios. In contrast, subluminous SNe Ia are dominated by Class II asphericities, characterized by lower Si II polarization but significant continuum polarization. The observed distribution of Si II polarization depends on both the observer's viewing angle $\\theta$ and the intrinsic asphericity. Statistical analysis of these spectropolarimetric snapshots enables the separation of Class I and Class II contributions and highlights the intrinsic diversity among SNe Ia. Our results imply viewing-angle-dependent luminosities in our local sample, which may have implications when using high-redshift SNe Ia as evidence for the need of non-standard cosmology.",
    "authors": [
      "Aleksandar Cikota",
      "Peter Hoeflich",
      "Dietrich Baade",
      "Ferdinando Patat",
      "Lifan Wang",
      "J. Craig Wheeler",
      "Yi Yang",
      "Elham Fereidouni",
      "Divya Mishra"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03959",
    "title": "Primary gravitational waves at high frequencies I: Origin of suppression in the power spectrum",
    "abstract": "[Abridged] The primary gravitational waves (PGWs) are generated in the early universe from the quantum vacuum during inflation. In slow roll inflation, the power spectrum (PS) of PGWs over large scales, which leave the Hubble radius during inflation, is nearly scale-invariant. However, over very small scales, which never leave the Hubble radius, the PS of PGWs behaves as k^2, where k denotes the wave number. We examine the PS of PGWs at such high wave numbers or frequencies when the PGWs are evolved post-inflation, through the epochs of radiation and matter domination. Firstly, we argue that the PS has to be regularized in order to truncate the unphysical k^2 rise at high frequencies. Assuming instantaneous transitions from inflation to the epochs of radiation and matter domination, we carry out the method of adiabatic regularization to arrive at the PS of PGWs over a wide range of frequencies. We show that the process of regularization truncates the k^2 rise and the PS of PGWs oscillates with a fixed amplitude about a vanishing mean value over small scales or, equivalently, at high frequencies. Secondly, we smooth the transition from inflation to radiation domination (to be precise, we smooth the 'effective potential' governing the equation of motion of PGWs) and examine the impact of the smoothing on the regularized PS of PGWs. With the help of a linear smoothing function, we explicitly show that the smoother transition leads to a power-law suppression in the amplitude of the oscillations (about the zero mean value) of the regularized PS of PGWs over small scales that never leave the Hubble radius during inflation. Our analysis indicates that, when transitions are involved, regularization as well as smooth transitions seem essential to ensure that the correlation functions of the PGWs in real space are well behaved. We discuss the directions in which our results need to be extended.",
    "authors": [
      "Alipriyo Hoory",
      "Jerome Martin",
      "Arnab Paul",
      "L. Sriramkumar"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03961",
    "title": "Further constraints on Jupiter's primordial structure",
    "abstract": "The primordial structure of Jupiter remains uncertain, yet it holds vital clues on the planet's formation and early evolution. Recent work used dynamical constraints from Jupiter's inner moons to determine its primordial state, thereby providing a novel, formation-era anchor point for interior modeling. Building on this approach, we combine these dynamical constraints with thermal evolution simulations to investigate which primordial structures are consistent with present-day Jupiter. We present 4,250 evolutionary models of the planetary structure, including compositional mixing and helium phase separation, spanning a broad range of initial entropies and composition profiles. We find that Jupiter's present-day structure is best explained by a warm ($4.98_{-2.57}^{+3.00}\\, \\mathrm{k_B\\, m_u^{-1}}$), metal-rich dilute core inherited from formation. To simultaneously satisfy constraints on Jupiter's primordial spin, however, its envelope must have been significantly warmer ($9.32_{-0.58}^{+0.48}\\, \\mathrm{k_B\\, m_u^{-1}}$) at the time of disk dispersal. We determine Jupiter's primordial radius to be $1.89_{-0.49}^{+0.40}\\, \\mathrm{R_J}$. These results provide new constraints on Jupiter's formation, suggesting that most heavy elements were accreted early during runaway gas accretion, and placing bounds on the energy dissipated during the accretion shock.",
    "authors": [
      "Henrik Knierim",
      "Konstantin Batygin",
      "Ravit Helled",
      "Luca Morf",
      "Fred C. Adams"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03965",
    "title": "Separating halo and disk stars in galaxies with Fuzzy Set Theory",
    "abstract": "Disk and halo stars are generally classified using several conventional methods, such as the Toomre diagram, sharp cuts in metallicity ([Fe/H]), vertical distance ($\\left|Z\\right|$) from the Galactic plane, or thresholds on the orbital circularity parameter ($\\epsilon$). However, all these methods rely on hard selection cuts, which either contaminate samples when relaxed or exclude genuine members when applied too strictly, leading to uncertain and biased classifications. We develop a flexible and reliable approach to classify disk and halo stars in galaxies by applying fuzzy set theory, which can overcome the limitations of traditional hard-cut selection methods. As a case study, we analyze one of the Milky Way/M31-like galaxies in the TNG50 catalogue. We consider multiple stellar properties as fuzzy variables and characterize their variations between disk and halo stars to construct the respective membership functions. These functions are then combined to assign each star a membership degree corresponding to its galactic component. Our fuzzy set approach provides a more realistic distinction between the disk and the halo stars. This method effectively reduces contamination and recovers genuine members that are often excluded by rigid selection criteria. The fuzzy set theory framework offers a robust alternative to conventional hard-cut methods, enabling more accurate and physically meaningful separation of stellar populations in galaxies.",
    "authors": [
      "Amit Mondal",
      "Biswajit Pandey"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03999",
    "title": "The Nuclear Star Cluster of M 74: a fossil record of the very early stages of a star-forming galaxy",
    "abstract": "Nuclear star clusters (NSC) are dense and compact stellar systems, of sizes of few parsecs, located at galactic centers. Their properties and formation mechanisms seem to be tightly linked to the evolution of the host galaxy, with potentially different formation channels for late- and early-type galaxies (respectively, LTGs and ETGs). While most observations target ETGs, here we focus on the NSC in M 74 (NGC 628), a relatively massive, gas-rich and star-forming spiral galaxy, part of the PHANGS survey. We analyzed the central arcmin of the PHANGS-MUSE mosaic, in which the NSC is not spatially resolved. We performed a two-dimensional spectro-photometric decomposition of the MUSE cube, employing a modified version of the C2D code, to disentangle the NSC from the host galaxy. Here we used three components: a bulge, a disk and a NSC approximated to the point spread function (PSF), obtaining three data cubes, one for each component. This allowed us to extract separately the age, metallicity and [Mg/Fe] abundance for the NSC and the host galaxy. Our results show a very old and metal-poor NSC, in contrast to the surrounding regions. While similar properties were found in NSCs hosted by galaxies of different masses and/or morphological types from M 74, they are somewhat unexpected for a relatively massive star-forming spiral galaxy. The spatially resolved stellar populations of the host galaxy display much younger (light-weighted) ages and higher metallicities, especially in the central region (${\\sim}500$ pc) surrounding the NSC. This suggests that this NSC formed a long time ago, and evolved passively until today, without any further growth. Our results show that the NSC was not involved in the active recent star-formation history of its host galaxy.",
    "authors": [
      "Francesca Pinna",
      "Nils Hoyer",
      "Jairo Méndez Abreu",
      "Adriana de Lorenzo Cáceres Rodriguez",
      "Nadine Neumayer",
      "Médéric Boquien",
      "Salvador Cardona Barrero",
      "Daniel A. Dale",
      "Ivan S. Gerasimov",
      "Kathryn Grasha",
      "Ralf S. Klessen",
      "Carlos Marrero de la Rosa",
      "Miguel Querejeta",
      "Thomas G. Williams",
      "Smita Mathur",
      "Eva Schinnerer"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04010",
    "title": "Hydrogen-Rich to Stripped-Envelope:Observational Continuity and Biases in CCSNe",
    "abstract": "Although historically classified into discrete subclasses, there is growing evidence that indicates that core-collapse supernovae (CCSNe) categories often overlap, reflecting continuous variations in progenitor structure, mass-loss history, and circumstellar environments rather than strictly distinct channels. In this review, we explore the proposed continua that link hydrogen-rich Type II SNe to stripped-envelope explosions (IIb-Ib-Ic), and that extend further into interaction-dominated and superluminous events. We discuss the physical processes-stellar winds, binary interaction, eruptive outbursts, and circumstellar interaction-that may produce graded outcomes across classes, while highlighting where observational evidence supports or challenges smooth transitions. We propose that CCSNe are better viewed as a multidimensional continuum of explosion outcomes, where traditional subclasses act as reference points rather than strict boundaries. Future progress will rely on large, homogeneous datasets and advanced modeling to disentangle true evolutionary sequences from apparent overlaps, ultimately connecting progenitor pathways to the observed diversity of explosions",
    "authors": [
      "Anjasha Gangopadhyay",
      "Priscila J. Pessi"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04011",
    "title": "Freeze-out and spectral running of primordial gravitational waves in viscous cosmology",
    "abstract": "We investigate the impact of shear viscosity on the propagation of primordial gravitational waves (pGW) after inflation. Without assuming a specific inflationary scenario we focus on the evolution of pGWs after they re-enter the horizon during a cosmological epoch characterized by the presence of shear viscosity. We show that shear viscosity introduces an additional damping term in the tensor equation, modifying both the transfer function and the energy density power spectrum. For a constant shear viscosity-to-Hubble ratio the transfer function acquires an extra red tilt, while a time-dependent viscosity leads to a running spectral index $\\Omega_\\text{GW}\\sim k^{n_\\text{eff}(k)}$ controlled by the time evolution of the mean free path of the viscous fluid. Our analysis provides a general framework to analytically quantify how shear viscosity can alter the primordial gravitational wave background in standard and non-standard post-inflationary scenarios. As a case study we evaluate the effect of viscosity of the electron-photon-baryon plasma, on both the transfer function and the normalized energy density, finding a $k$-dependent blue tilt due to gravitational wave freeze-out from the viscous phase. This effect corresponds to a fractional difference of order $10^{-3}$.",
    "authors": [
      "Giuseppe Fanizza",
      "Eliseo Pavone",
      "Luigi Tedesco"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04031",
    "title": "Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study",
    "abstract": "This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.",
    "authors": [
      "Yixuan Li",
      "Yuhao Lu",
      "Yang Liu",
      "Liang Li",
      "R. Ruffini",
      "Di Li",
      "Rong-Gen Cai",
      "Xiaoyan Zhu",
      "Wenbin Lin",
      "Yu Wang"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04042",
    "title": "Modeling of Rayleigh Scattering and Interstellar Polarization for Evolved Late-Type Stars",
    "abstract": "Evolved late-type stars are frequently identified as photometric and spectroscopic variables, such as Mira-type or semi-regular variable objects. These stars can also be polarimetrically variable, an indicator of non-spherical geometry for spatially unresolved sources. Departures from symmetry can arise in a number of ways, such as the presence of a binary companion (e.g., multiple illumination sources for scattered light), brightness variations in the stellar atmosphere (e.g., large convective cells), or aspherical circumstellar envelopes (e.g., disks or aspherical stellar winds). Common polarigenic opacities for cool stars include Rayleigh scattering and dust scattering. The classic wavelength dependence of lambda^-4 for Rayleigh single scattering is generally straightforward; however, that signature can be confounded by interstellar polarization (ISP). We explore strategies for interpreting polarimetric observations when the interstellar polarization (ISP) cannot be removed. We introduce a \"hybrid\" spectrum that includes both Rayleigh polarization for a stellar contribution and the Serkowski Law for an interstellar contribution. We find the polarization spectral slope can be more shallow than expected from Rayleigh scattering alone. For stellar variability, shorter wavelengths give higher amplitude changes when Rayleigh scattering dominates the interstellar signal. Quite anomalous slopes can occur over limited wavelength intervals if the stellar and interstellar position angles differ by 90 deg. Results of the models are discussed in the context of photopolarimetry methods, and an application is considered in terms of variable polarization from the carbon star, R Scl.",
    "authors": [
      "R Ignace",
      "C Erba",
      "K DeGennaro",
      "G Henson"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04043",
    "title": "The Nature of Nitrogen Enhanced High Redshift Galaxies",
    "abstract": "Recent JWST observations have revealed a population of high-redshift galaxies ($z\\gtrsim5$) exhibiting unexpectedly bright ultraviolet (UV) nitrogen emission lines. The strong N III] and N IV] features imply nitrogen-to-oxygen abundance ratios (N/O) as high as $-0.8 \\lesssim \\log(\\mathrm{N/O}) \\lesssim 0.4$ in these low-metallicity galaxies ($12+\\log(\\mathrm{O/H}) \\lesssim 8.2$), compared to the local value of $\\log(\\mathrm{N/O})\\approx-1.5$. If confirmed, this level of nitrogen enrichment challenges existing models of nucleosynthesis and galaxy evolution. However, the presence of active galactic nuclei (AGNs) can affect spectral diagnostics, and previous studies often excluded AGN contamination using photoionization models based on local N/O ratios. In this work, we compare nitrogen-enhanced AGN and H II region models to observed spectra of eight high-redshift galaxies to constrain their nitrogen abundance, excitation source, gas-phase metallicity, ionization parameter, and gas pressure, simultaneously. We find seven galaxies (GHZ9, GS 3073, GN-z9p4, CEERS-1019, GHZ2, GN-z11, and GS-z9-0) are best described by nitrogen-enhanced AGN models, while RXCJ2248-ID is best reproduced by the nitrogen-enhanced H II model. The presence of AGN does not significantly impact ($\\lesssim0.1\\,$dex) the derived N/O ratio. We also find that equivalent width (EW)-based diagrams are the most robust UV diagnostic diagrams to distinguish AGNs and star-forming galaxies for situations where the nitrogen abundance is varying. All nitrogen-enhanced galaxies have moderate to high gas pressure ($7.0\\leq\\log (P/k)\\leq9.8$) and high ionization parameter ($\\log(U)\\gtrsim-2.0$), indicating a dense and compact environment. We suggest that super star clusters containing Wolf-Rayet stars and massive stars are the most likely contributors to the elevated nitrogen abundance in these galaxies.",
    "authors": [
      "Peixin Zhu",
      "James Trussler",
      "Lisa J. Kewley"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04049",
    "title": "TT Arietis: New approach to the analysis of quasi-periodic oscillations",
    "abstract": "Context. TT Arietis (TT Ari) is a nova-like cataclysmic variable of the VY Scl subtype with light-curve variations on multiple timescales. In addition to the superhump modulation, quasi-periodic oscillations (QPOs) have been found. Aims. Our aim is to determine the occurrence, strength, and variability of QPOs in TT Ari based on more complete data than in previous works. Methods. The data were obtained during the high state of TT Ari in October 2012 by the MOST space telescope, covering a total of 361.2 hours of continuous observation. We searched for frequencies over subsets of time using a Fourier-like power spectrum and then added the frequencies together, forming groups. Results. Our method has revealed QPOs that occur in \"frequency groups\", which are events with a continuous oscillation of similar, constant or slowly variable frequency. We report a total of 160 frequency groups in the period range between 14 and 53 minutes (27 and 98 days-1), with two peaks in the power spectrum at 18.5 and 33.8 minutes (42.5 and 77.5 days-1). The duration of these frequency groups varies between 0.72 and 7.5 hours (average 2.8 hours) revealing between 3 and 18 complete cycles in the light curve. Most of them show significant frequency variations over the course of their duration. Sometimes two frequency groups occur simultaneously. An analysis with randomised data confirms that stochastic processes can only explain a fraction of the QPOs found. The occurrence of QPOs appears not to be related to the superhump phase.",
    "authors": [
      "I. Vega-Manubens",
      "N. Vogt",
      "A. Lopera-Mejía",
      "G. Aravena-Rojas",
      "P. A. Rojas Lobos"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04060",
    "title": "JWST Captures Growth of Aromatic Hydrocarbon Dust Particles in the Extremely Metal-poor Galaxy Sextans A",
    "abstract": "The mid-infrared spectrum of star-forming, high metallicity galaxies is dominated by emission features from aromatic and aliphatic bonds in small carbonaceous dust grains, often referred to as polycyclic aromatic hydrocarbons (PAHs). In metal-poor galaxies, the abundance of PAHs relative to the total dust sharply declines, but the origin of this deficit is unknown. We present JWST observations that detect and resolve emission from PAHs in the 7% Solar metallicity galaxy Sextans A, representing the lowest metallicity detection of PAH emission to date. In contrast to higher metallicity galaxies, the clumps of PAH emission are compact (0.5-1.5'' or 3-10 pc), which explains why PAH emission evaded detection by lower resolution instruments like Spitzer. Ratios between the 3.3, 7.7, and 11.3 $\\mu$m PAH features indicate that the PAH grains in Sextans A are small and neutral, with no evidence of significant processing from the hard radiation fields within the galaxy. These results favor inhibited grain growth over enhanced destruction as the origin of the low PAH abundance in Sextans A. The compact clumps of PAH emission are likely active sites of in-situ PAH growth within a dense, well-shielded phase of the interstellar medium. Our results show that PAHs can form and survive in extremely metal-poor environments common early in the evolution of the Universe.",
    "authors": [
      "Elizabeth J. Tarantino",
      "Julia Roman-Duval",
      "Karin M. Sandstrom",
      "J.-D. T. Smith",
      "Cory M. Whitcomb",
      "Bruce T. Draine",
      "Martha L. Boyer",
      "Jérémy Chastenet",
      "Ryan Chown",
      "Christopher J. R. Clark",
      "Karl D. Gordon",
      "Brandon S. Hensley",
      "Thomas S.-Y. Lai",
      "Christina W. Lindberg",
      "Kristen B. W. McQuinn",
      "Max J. B. Newman",
      "O. Grace Telford",
      "Dries Van De Putte",
      "Benjamin F. Williams"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04061",
    "title": "Multimessenger Constraints on Supermassive Dark Stars and Their Black Hole Remnants",
    "abstract": "Dark matter (DM) annihilation can power the first generation of stars as long lived dark stars (DSs) that grow to supermassive scales $M_{\\rm DS}\\gtrsim 10^{5} M_{\\odot}$ and eventually collapse into heavy black holes that could seed the supermassive black holes observed at high redshifts. We compute the diffuse electromagnetic emission from a cosmological population of such supermassive DSs and their black hole remnants, tracking the entire DS history and including thermal surface radiation, DM annihilation in adiabatically contracted halos as well as late-time emission from DM overdensity spikes around the resulting black holes. After accounting for photon attenuation, we find that DS related contributions can exceed the Fermi-LAT extragalactic $\\gamma$-ray background for thermal relic annihilation cross-sections and DM masses below $\\sim 1$ TeV. Our results constitute the first population integrated diffuse multimessenger constraints on supermassive DSs as progenitors of early black holes and demonstrate that diffuse photon and neutrino backgrounds offer a powerful and complementary avenue for probing the role of DM in the formation of the earliest massive structures.",
    "authors": [
      "Marco Manno",
      "Thomas Schwemberger",
      "Volodymyr Takhistov"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04075",
    "title": "On distance and velocity estimation in cosmology",
    "abstract": "Scatter in distance indicators introduces two conceptually distinct systematic biases when reconstructing peculiar velocity fields from redshifts and distances. The first is distance Malmquist bias (dMB) that affects individual distance estimates and can in principle be approximately corrected. The second is velocity Malmquist bias (vMB) that arises when constructing continuous velocity fields from scattered distance measurements: random scatter places galaxies at noisy spatial positions, introducing spurious velocity gradients that persist even when distances are corrected for dMB. Considering the Tully-Fisher relation as a concrete example, both inverse and forward formulations yield unbiased individual peculiar velocities for galaxies with the same true distance (the forward relation requires a selection-dependent correction), but neither eliminates vMB when galaxies are placed at their inferred distances. We develop a modified Wiener filter that properly encodes correlations between directly observed distance $d$ and true distance $r$ through the conditional probability $P(r|d)$, accounting for the distribution of true distances sampled by galaxies at observed distance $d$. Nonetheless, this modified filter yields suppressed amplitude estimates. Since machine learning autoencoders converge to the Wiener filter for Gaussian fields, they are unlikely to significantly improve velocity field estimation. We therefore argue that optimal reconstruction places galaxies at their observed redshifts rather than inferred distances; an approach effective when distance errors exceed $\\sigma_v/H_0$, a condition satisfied for most galaxies in typical surveys beyond the nearby volume.",
    "authors": [
      "Adi Nusser"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04080",
    "title": "The effect of baryons on the positions and velocities of satellite galaxies in the MTNG simulation",
    "abstract": "Mock galaxy catalogues are often constructed from dark-matter-only simulations based on the galaxy-halo connection. Although modern mocks can reproduce galaxy clustering to some extent, the absence of baryons affects the spatial and kinematic distributions of galaxies in ways that remain insufficiently quantified. We compare the positions and velocities of satellite galaxies in the MTNG hydrodynamic simulation with those in its dark-matter-only counterpart, assessing how baryonic effects influence galaxy clustering and contrasting them with the impact of galaxy selection, i.e. the dependence of clustering on sample definition. Using merger trees from both runs, we track satellite subhaloes until they become centrals, allowing us to match systems even when their z=0 positions differ. We then compute positional and velocity offsets as functions of halo mass and distance from the halo centre, and use these to construct a subhalo catalogue from the dark-matter-only simulation that reproduces the galaxy distribution in the hydrodynamic run. Satellites in the hydrodynamic simulation lie 3-4% closer to halo centres than in the dark-matter-only case, with an offset that is nearly constant with halo mass and increases toward smaller radii. Satellite velocities are also systematically higher in the dark-matter-only run. At scales of 0.1 Mpc/h, these spatial and kinematic differences produce 10-20% variations in clustering amplitude -corresponding to 1-3$\\sigma$ assuming DESI-like errors- though the impact decreases at larger scales. These baryonic effects are relevant for cosmological and lensing analyses and should be accounted for when building high-fidelity mocks. However, they remain smaller than the differences introduced by galaxy selection, which thus represents the dominant source of uncertainty when constructing mocks based on observable quantities.",
    "authors": [
      "Sergio Contreras",
      "Raul E. Angulo",
      "Sownak Bose",
      "Boryana Hadzhiyska",
      "Lars Hernquist",
      "Francisco Maion",
      "Ruediger Pakmor",
      "Volker Springel"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22804",
    "title": "Overlapping of photon rings in black hole imaging",
    "abstract": "In this paper, we investigate the overlapping of photon rings - higher-order images of a black hole's luminous environment, concentrated near the shadow boundary and expected to be resolved in future observations. We consider a broad class of static spherically symmetric spacetimes and geometrically thin equatorial accretion disk with a prescribed inner radius and infinite outer extent, viewed by a polar observer. Depending on the inner radius of the disk, the thickness of each photon ring varies, and the rings may or may not overlap. To characterize the overlapping, we introduce the radius of merging - the value of the disk's inner radius at which two photon rings of given orders begin to overlap. Since each radius of merging is labeled by two indices corresponding to the image orders, it becomes possible to arrange these radii in the form of an infinite-dimensional matrix where only the upper right-hand corner is filled. This matrix, which we call the \"matrix of merging\", is a signature of spacetime only, and, once known, it provides a qualitative understanding of the overlapping pattern for any chosen value of the inner radius of the disk. Remarkably, the matrix of merging exhibits several universal properties that hold for all spherically symmetric metrics and can be established even without explicit calculation of light trajectories. Based on these properties, we demonstrate that certain overlapping patterns are universally forbidden across all such spacetimes and for any inner radius of the disk. Examples for the Schwarzschild and Reissner-Nordström black holes are provided. The main application of our study is constraining the spacetime metric and the accretion model using observed photon ring overlaps.",
    "authors": [
      "Oleg Yu. Tsupko",
      "Fabio Aratore",
      "Volker Perlick"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03118",
    "title": "Probing for primordial black hole candidates in exoplanet search data",
    "abstract": "We have sifted through astrophysical data collected by various radial velocity and gravitational microlensing searches for exoplanets with the goal of identifying potential signs of the presence of primordial black holes (PBH). Our motivation is that those hypothesized remnants of inhomogeneous energetic fluctuations in the early universe, though too small for direct detection, are thought to have a mass range similar to that of planets. Thereby, if captured by stars, they could conceivably make their presence known through stellar wobbles picked up by means of Doppler spectroscopy in the radial velocity method, or alternatively through microlensing. In our analysis of such data, we have identified potential PBH contenders by ruling out any exoplanet candidates that have been detected through direct imaging or transit methods, as they would have sizes consistent with planets rather than PBHs. In particular we focus on the objects Kepler-21 Ac, HD 219134 f, Gliese 686 b, HR 5183 b, HD 20794 e, and Wolf 1061 d, each of which has been found using the radial velocity method but never imaged (either directly or through transit). We also examine the microlensing events MOA 2009-BLG-387L and OGLE-2016-BLG-1540, which offer promise as candidate PBHs. We present these as a representative, but not exclusive list, of potential PBH contenders. Furthermore, future imaging, especially focused on signals of planetary dimensions versus evaporation signatures, might clarify which of these are indeed exoplanets.",
    "authors": [
      "Paul Halpern",
      "Erik Cauley",
      "Max Stoltzmann",
      "Mauritz Wilshusen"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03119",
    "title": "An infrasound source analysis of the OSIRIS-REx sample return capsule hypersonic re-entry",
    "abstract": "The OSIRIS-REx sample return capsule hypersonic re-entry into the atmosphere is a rare opportunity to test a variety of sonic boom source models since the projectile dimensions are well characterized. While the as-flown flight path is unknown, the predicted flight path enables a rough approximation of the source Mach number and location. Six infrasound microphones deployed in the boom carpet along the predicted flight path recorded impulsive signals from the OSIRIS-REx re-entry. Using a suite of atmosphere profiles and the geometric acoustics approximation, we estimate locations with uncertainty estimates along the flight path from which the signals were emitted. Acoustic overpressure and signal duration predictions from Whitham's far field theory, Carlson's simplified sonic boom prediction method, and a drag-dominated hypersonic model are analyzed with uncertainty estimates from the location estimate. While the Carlson simplified sonic boom prediction method could be accurate, our preference is for the drag-dominated source model. Using this source model with an inviscid Burgers' equation solver for propagation, we obtained an excellent match to the recorded data. These results will help better inform future sample return capsule re-entry observation campaigns as well as contribute to a better understanding of high altitude infrasonic sources.",
    "authors": [
      "Jordan W. Bishop",
      "Philip Blom",
      "Chris Carr",
      "Jeremy Webster"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03133",
    "title": "A Thermal Relic Encyclopedia: Dark Matter Candidates Coupled to Quarks",
    "abstract": "Thermal freeze-out is a compelling framework for naturally generating the dark matter abundance. We systematically study a broad range of dark matter and mediator particle combinations that can viably realize thermal freeze-out, focusing on models in which the mediator couples to Standard Model quarks. In each case, we calculate the relic density and consider existing constraints from accelerators, cosmology, direct detection, and indirect detection over the full range of dark matter and mediator masses. We present an encyclopedic catalog of matrix elements, cross sections, and decay rates which can be used as a reference for future studies of dark matter phenomenology.",
    "authors": [
      "Dan Hooper",
      "Gordan Krnjaic",
      "Tanner Trickle",
      "Isaac R. Wang"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03152",
    "title": "Inferring black hole formation channels in GWTC-4.0 via parametric mass-spin correlations derived from first principles",
    "abstract": "We investigate the differences between several proposed formation scenarios for binary black holes (BBHs), including isolated stellar evolution, dynamical assembly in dense clusters and AGN disks, and primordial BHs. Our approach exploits the predicted spin features of each formation channel, and adopts parameterized models of the predicted correlations between the spin magnitudes (and orientations) and mass, inspired by first principles. Using hierarchical Bayesian inference on the recent GWTC-4.0 dataset, we compare these features across all models and assess how well each scenario explains the data. We find that the data strongly favor the presence of a positive correlation between mass and spin magnitude, in agreement with previous studies. Furthermore, the hierarchical scenario provides a better fit to the observations, due to the inclusion of second-generation mergers leading to higher spins at larger masses. The current dataset is not informative enough about spin orientation: the cluster (random orientations) and AGN (aligned orientations) scenarios have comparable Bayesian evidence. Finally, the mass-spin correlation predicted by the primordial scenario gives a poor fit to the data, and this scenario can only account for a subset of the observed events.",
    "authors": [
      "Emanuele Berti",
      "Francesco Crescimbeni",
      "Gabriele Franciolini",
      "Simone Mastrogiovanni",
      "Paolo Pani",
      "Grégoire Pierra"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03155",
    "title": "From scalar clouds around evaporating black holes to boson star",
    "abstract": "We study, for the first time, the evolution of a scalar cloud bound to an evaporating black hole. Our simulations of the associated Schrödinger-Poisson system for non-relativistic and spherically symmetric clouds reveal that a scalar cloud may (partially) survive as a self-gravitating boson star if the black hole evaporates adiabatically until its mass becomes less than one half of the cloud's mass. This yields a novel mechanism for boson star formation and shows that, as previously conjectured, bosonic dark matter production by light primordial black holes may result in micro-boson stars with very large occupation numbers, greatly enhancing their potential detectability even for very weakly interacting dark matter particles.",
    "authors": [
      "Daniel Neves",
      "João G. Rosa"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03206",
    "title": "Astrophysical Reaction Rates for Charged-Particle Induced Reactions on Proton-Rich Nuclides",
    "abstract": "Astrophysical reaction rates for reactions with proton-rich nuclides from stability to the proton dripline were calculated with an updated version of the SMARAGD statistical model (Hauser-Feshbach) code. Here, the focus was on reactions with protons or $\\alpha$ particles as required for nucleosynthesis in proton-rich matter. For completeness, also neutron-induced reactions are provided for the same set of targets. Some comments on dependencies of rates on various nuclear properties and on the appropriate way to compare to experiments are given. The new rate set for charged-particle induced reactions provides a better description of experimental data than previously widely used rates, especially for reactions involving $\\alpha$ particles.",
    "authors": [
      "Thomas Rauscher"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03271",
    "title": "Determining the Qibla Direction by Astronomical and Geometrical Methods",
    "abstract": "This paper investigates the determination of the Qibla direction using both astronomical and geometrical approaches. The study reviews historical and classical methods employed by Muslim scholars and astronomers including the use of instruments such as the astrolabe and compass. It further explores spherical trigonometry techniques to precisely calculate the Qibla azimuth from any given location on Earth. The research clarifies geometric constructions and presents a computational model implemented in C++ to facilitate accurate Qibla determination. This interdisciplinary analysis underscores the rich tradition of Islamic astronomy and geometry in solving practical religious requirements, providing both theoretical frameworks and practical algorithms for modern application.",
    "authors": [
      "Duaa Abdullah"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03484",
    "title": "Motion of a charged test particle around a static black hole in a monopole magnetic field",
    "abstract": "We study the motion of a charged test particle in the spacetime with a spherically symmetric black hole which is immersed in a monopole magnetic field. We show that the radial motion of the charged test particle is governed by completely the same equation as that in the case of no magnetic field. This result implies that the black hole will acquire the electric charge if it is surrounded by the collisionless plasma composed of protons and electrons which obey the Maxwell velocity distribution. The drastically different situation appears in the tangential motions of charged test particles due to the magnetic field. The trajectory of a charged test particle in the black hole with the magnetic field of the order of 10 Gauss near the black hole, is confined on a very thin cone as long as the specific angular momentum of the particle is not much larger than the gravitational radius of the black hole times the speed of light. This result leads to a possibility that a plasma lump can hover over the black hole and is very hot, in the monopole magnetic field.",
    "authors": [
      "Ken-ichi Nakao",
      "Yota Endo",
      "Hideki Ishihara",
      "Kenta Matsuo",
      "Kensuke Sueto",
      "Koudai Ueda",
      "Hirotaka Yoshino"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03529",
    "title": "Multi-probe analysis of strong-field effects in $f(Q)$ gravity",
    "abstract": "Covariant $f(Q)$ gravity is a viable extension of General Relativity, however its strong-field predictions remain largely untested. Using the static, spherically symmetric black-hole solutions of the theory, we confront it with the most stringent probes available: black-hole shadows, Event Horizon Telescope (EHT) measurements, S2-star precession, and strong gravitational lensing. We show that the two admissible solution branches behave very differently: Case~I produces negligible deviations from Schwarzschild solution, whereas Case~II yields significant, potentially observable corrections to the photon sphere and shadow size. From the EHT shadow diameters of M87* and Sgr~A*, we obtain tight bounds, which are further strengthened by strong-lensing coefficients. These results provide the sharpest strong-field constraints on covariant $f(Q)$ gravity to date, and point toward future tests using next-generation horizon-scale imaging and precision Galactic-center astrometry.",
    "authors": [
      "Mohsen Khodadi",
      "Behnam Pourhassan",
      "Emmanuel N. Saridakis"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03662",
    "title": "Gravitational Decays of Secluded Scalars and Graviton Dark Radiation",
    "abstract": "We discuss graviton dark radiation produced by the decay of a secluded scalar field that couples to the Standard Model (SM) only through gravity. Such scalar fields are long-lived, and their decay channels generically include gravitons. If such particles existed and dominated the early universe, a sizable branching ratio into gravitons would yield non-negligible dark radiation that significantly alters the subsequent thermal history of the universe. In this work, we focus on the dark glueball as a representative secluded hidden scalar and compare the decay rates into SM particles via a non-minimal coupling to gravity with those into gravitons, paying attention to how the breaking of conformal invariance affects the amount of graviton dark radiation. We find that decays into the SM are dominated by two-body decay channels into Higgs bosons and gluons. In particular, when the Higgs field has a large non-minimal coupling to gravity, the production of graviton dark radiation is naturally suppressed in the metric formalism, and the SM sector is preferentially reheated and energy transfer to other hidden sectors is suppressed. Finally, we present the expected gravitational-wave spectrum resulting from dark glueball domination.",
    "authors": [
      "Kazunori Nakayama",
      "Fuminobu Takahashi",
      "Juntaro Wada"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03713",
    "title": "A theory-agnostic hierarchical Bayesian framework for black-hole spectroscopy: a case study on GW250114 in Einstein-dilaton-Gauss-Bonnet gravity",
    "abstract": "Black-hole spectroscopy has emerged as a powerful probe of strong-field gravity in the era of gravitational-wave astronomy. In this context, many current tests of modified or extended gravity are implemented by searching for predicted signatures modeled as perturbative corrections to general-relativistic waveforms; however, this approach may introduce model-dependent systematics and limit applicability to broader classes of theories. To complement such methods, we develop a theory-agnostic hierarchical Bayesian framework that connects ringdown observations -- modeled as damped sinusoids -- directly with theoretical quasinormal mode spectra, performing the comparison at the spectral level rather than through theory-specific waveform matching. The framework incorporates a soft-truncation module to account for the finite domain of validity in the theory's parameter space and is equipped with quantitative diagnostics that identify stable analysis time windows. As an illustrative application, we implement the framework within Einstein-dilaton-Gauss-Bonnet gravity and apply it to the gravitational-wave event GW250114, finding that the resulting posterior for the dimensionless coupling $\\zeta$ is robust against prior assumptions yet remains only weakly informative over the range considered in this work. We further perform controlled ringdown injection studies across different values of $\\zeta$, confirming that nonzero couplings can be recovered while also indicating a potential systematic effect: Kerr-based priors in the $\\zeta$ inference may partially absorb spectral deviations arising in alternative theories of gravity. This work establishes a transparent and extensible foundation for future strong-field gravity tests, naturally compatible with the growing precision and modal resolution of next-generation gravitational-wave detectors.",
    "authors": [
      "Shitong Guo",
      "Yan-Gang Miao"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03801",
    "title": "A strategy for optimal material identification in solar dark photon absorption",
    "abstract": "Dark photons with masses in the 1-100 eV range can be produced in the Sun and subsequently absorbed in terrestrial detectors, offering a promising avenue for probing hidden-sector physics beyond the Standard Model. In this work, we develop a theoretically grounded strategy to identify optimal detector materials for solar dark photon absorption. Our strategy builds on a material-independent upper limit on the absorption rate, which we derive from Kramers-Kronig relations applied separately to the longitudinal and transverse dark photon modes. We show how the optimal material properties depend on the dark photon mass relative to the detector's plasma frequency, identifying the conditions under which a detector can saturate the theoretical upper limit. We then assess the performance of commonly used detector materials in light of these criteria and comment on the prospects of metamaterials featuring tunable plasma frequencies. Our results provide a general and model-independent framework to effectively guide the design of next-generation experiments targeting solar dark photons.",
    "authors": [
      "Theresa M. Backes",
      "Riccardo Catena",
      "Michael Krämer"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03823",
    "title": "Approximations and modifications of celestial dynamics tested on the three-body system",
    "abstract": "Large-scale simulations of celestial systems are based on approximations or modifications of classical dynamics. The approximations are with ``particle-mesh'' (PM) substitutions of the attractions from objects far away, or one modify the Newtonian accelerations (MOND) or the gravities (MOGA). The PM approximation and MOND modification of classical dynamics break the invariances of classical dynamics. The simple three-body system (TBS) is the simplest system to test the approximations and modifications of celestial dynamics, and it is easy to implement on a computer. Simulations of the TBS show that the PM approximation and MOND destabilize TBS. In contrast, the MOGA modification of gravity by replacing Newton's inverse square attraction with an inverse attraction for far-away interactions stabilizes the system. The PM approximation and the MOND modification of classical dynamics do not preserve the momentum and angular momentum of a conservative system exactly, and PM does not obey Newton's third law. Although the errors and shortcomings of these PM approximations and MOND modifications are small, they cause the instability of the regular dynamics.",
    "authors": [
      "Søren Toxvaerd"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03849",
    "title": "Bifurcations of Highly Inclined Near Halo Orbits using Moser Regularization",
    "abstract": "We study the bifurcation structure of highly inclined near halo orbits with close approaches to the light primary, in the circular restricted three-body problem (CR3BP). Using a Hamiltonian formulation together with Moser regularization, we develop a numerical framework for the continuation of periodic orbits and the computation of their Floquet multipliers which remains effective near collision. We describe vertical collision orbits and families emerging from its pitchfork, period-doubling, and period-tripling bifurcations in the limiting Hill's problem, including the halo and butterfly families. We continue these into the CR3BP using a perturbative framework via a symplectic scaling, and construct bifurcation graphs for representative systems (Saturn-Enceladus, Earth-Moon, Copenhagen) to identify common dynamical features. Conley-Zehnder indices are computed to classify the resulting families. Together, these results provide a coherent global picture of polar orbit architecture near the light primary, offering groundwork for future mission design, such as Enceladus plume sampling missions.",
    "authors": [
      "Chankyu Joung",
      "Dayung Koh",
      "Otto van Koert"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03889",
    "title": "Comparing land- and skyscapes in the three main manorial-conquered lands of the Canary Islands",
    "abstract": "This work is a study of the relationship between astronomy and landscape focused on the orientation of Christian churches of the three main Manorial (Señorío) Islands of the Canary archipelago (Spain): Lanzarote, La Gomera and Fuerteventura. As a background, we have the information provided by the texts of early Christian writers, which imposed that churches should be oriented towards the east [..]. The fieldwork that supports our comparative study is based on the measurement of the precise location coordinates, axis' azimuth and angular height of the horizon for most of the churches of the three islands, which amounts to about 120 sets of measurements. For the study of the sample, we have employed various analyses, both statistical, as well as calendric and orographic. Our results show that on all the islands, the pattern of double orientations is repeated, which contemplates the canonical tradition of orienting the altars of churches within the solar range (pointing either eastward or westward). Very few cases also occur where it is possible to identify constructions whose orientation follows solstitial patterns, perhaps as imitation of aboriginal worship. But this double pattern also includes a high proportion of churches with orientations far from this range. An example is Lanzarote and Fuerteventura, both islands subjected to the same flow of the prevailing trade winds in the region, but each with its own characteristics. Another example is given by the particular orography of deep ravines of La Gomera, which determines the orientation of the temples located in those geographical accidents. In this paper we show how the combination of elements of the land- and skyscape can, with a high degree of probability, offer a satisfactory explanation to the particular orientation of these insular centres of worship, which were built during the first decades after the European conquest.",
    "authors": [
      "Maria Florencia Muratore",
      "Alejandro Gangui",
      "Juan Antonio Belmonte",
      "Carmelo Cabrera"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04083",
    "title": "Screening of dipolar emission in two-scale Gauss-Bonnet gravity",
    "abstract": "We study black holes in shift-symmetric scalar Gauss-Bonnet gravity extended by a cubic Galileon interaction with a distinct energy scale. Introducing this hierarchy profoundly modifies the theory's phenomenology. The cubic interaction allows for smaller black holes, and can generate a screening mechanism near the horizon, making large Gauss-Bonnet couplings consistent with gravitational-wave bounds. Observable quantities such as the scalar charge, the innermost stable circular orbit, and its frequency are most affected for small black holes. The resulting multi-scale effective field theory remains technically natural and offers new avenues to probe gravity in the strong-field regime.",
    "authors": [
      "Farid Thaalba",
      "Leonardo Gualtieri",
      "Thomas P. Sotiriou",
      "Enrico Trincherini"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.01496",
    "title": "ORACLE: A Real-Time, Hierarchical, Deep-Learning Photometric Classifier for the LSST",
    "abstract": "We present ORACLE, the first hierarchical deep-learning model for real-time, context-aware classification of transient and variable astrophysical phenomena. ORACLE is a recurrent neural network with Gated Recurrent Units (GRUs), and has been trained using a custom hierarchical cross-entropy loss function to provide high-confidence classifications along an observationally-driven taxonomy with as little as a single photometric observation. Contextual information for each object, including host galaxy photometric redshift, offset, ellipticity and brightness, is concatenated to the light curve embedding and used to make a final prediction. Training on $\\sim$0.5M events from the Extended LSST Astronomical Time-Series Classification Challenge, we achieve a top-level (Transient vs Variable) macro-averaged precision of 0.96 using only 1 day of photometric observations after the first detection in addition to contextual information, for each event; this increases to $>$0.99 once 64 days of the light curve has been obtained, and 0.83 at 1024 days after first detection for 19-way classification (including supernova sub-types, active galactic nuclei, variable stars, microlensing events, and kilonovae). We also compare ORACLE with other state-of-the-art classifiers and report comparable performance for the 19-way classification task, in addition to delivering accurate top-level classifications much earlier. The code and model weights used in this work are publicly available at our associated GitHub repository ( this https URL ).",
    "authors": [
      "Ved G. Shah",
      "Alex Gagliano",
      "Konstantin Malanchev",
      "Gautham Narayan",
      "Alex I. Malz",
      "LSST Dark Energy Science Collaboration"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.07522",
    "title": "The Extraordinary Maser Flaring Event in the Massive Protostellar System NGC6334I: Multi-Epoch Milliarcsecond Resolution Investigation of the 6.7-GHz Methanol Masers",
    "abstract": "We report the first multi-epoch milliarcsecond resolution imaging of the 6.7-GHz class II methanol maser emission associated with the high-mass protocluster system NGC6334I. The observations covered a period of over 10 years in four epochs between March 2010 and March 2020. We confirmed for the first time the emergence of 6.7-GHz methanol maser emission associated with NGC6334I-MM1, which lies north of the previously known sites of class IImethanol masers, NGC6334-MM2 and MM3. The new maser emission was located close to the strongest (sub)millimetre source in NGC6334I-MM1, identified as MM1-B, which experienced a sudden increase in intensity in 2015, produced by an episodic accretion event. We are able to compare the location and intensity of the 6.7-GHz methanol maser emission among the epochs before, during, and after the flare, providing new insights into the relationship between maser flares and episodic accretion events in high-mass stars.",
    "authors": [
      "Jayender Kumar",
      "Simon P. Ellingsen",
      "Gabor Orosz",
      "Lucas J. Hyland",
      "Chris Phillips",
      "Cormac Reynolds",
      "Gordon MacLeod"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.12045",
    "title": "FIP Bias Evolution in an Emerging Active Region as observed in SPICE Synoptic Observations",
    "abstract": "We investigate the time evolution of relative elemental abundances in the context of the first ionization potential effect focusing on an active region. Our aim is to characterize this evolution in different types of solar active region structures as well as in different atmospheric layers. We wish to assert how the measured changes relate to different magnetic topologies by computing abundance enhancement in different conditions using the ponderomotive force model. Leveraging spectroscopic observations from the Spectral Imaging of the Coronal Environment instrument on board Solar Orbiter, we use extreme ultraviolet lines from ions formed across a broad temperature range--from the upper chromosphere to the low corona--and we perform relative abundance ratios following differential emission measure analysis. This methodology yields relative abundance maps from low, intermediate, and high first ionization potential elements. We obtain the temporal evolution of a number of abundance ratios for different structures on the Sun. We compare these results with the outcomes of the ponderomotive force model. We find good correlation between the model and our results, suggesting an Alfvén-wave driven fractionation of the plasma. Fan loops, loop footpoints and active region boundaries exhibit coronal abundances, while the active region core shows more photospheric-like composition. A slow and steady increase in the magnesium to neon relative first ionization potential bias values is observed, starting around 1.5 and increasing by about 50\\% after two days. The sulfur to oxygen evolution coupled with the model brings evidence of resonant waves fractionating the plasma in transition region structures.",
    "authors": [
      "T. Varesano",
      "D. M. Hassler",
      "N. Zambrana Prado",
      "J. M. Laming",
      "J. Plowman",
      "D.J. Knipp",
      "M. Molnar",
      "K. Barczynski",
      "SPICE consortium"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.13435",
    "title": "The radio afterglow of the ultra-long GRB 220627A",
    "abstract": "We present the discovery of the radio afterglow of the most distant ultra-long gamma-ray burst (GRB) detected to date, GRB~220627A at redshift $z=3.084$. Its prompt gamma-ray light curve shows a double-pulse profile, with the pulses separated by a period of quiescence lasting ${\\sim} 15$\\,min, leading to early speculation it could be a strongly gravitationally lensed GRB. However, our analysis of the \\textit{Fermi}/GBM spectra taken during the time intervals of both pulses show clear differences in their spectral energy distributions, disfavouring the lensing scenario. We observed the radio afterglow from 7 to 456\\,d post-burst: an initial, steep decay ($F_{\\nu} \\propto t^{-2}$) is followed by a shallower decline ($F_{\\nu} \\propto t^{-1/2}$) after ${\\sim} 20$\\,d. There are three scenarios that could explain these radio properties: (i) energy injection from an additional, slower ejecta component catching up to the external shock; (ii) a stratified density profile going as $n \\propto r^{-8/3}$; or alternatively, (iii) the presence of a slow, wide ejecta component in addition to a fast, narrow ejecta component. We also conducted an independent test of the lensing hypothesis via Very Long Baseline Interferometry (VLBI) observations at ${\\sim} 12$\\,d post-burst by searching, for the first time, for multiple images of the candidate lensed GRB afterglow. Our experiment highlighted the growing need for developments in real-time correlation capabilities for time-critical VLBI experiments, particularly as we advance towards the SKA and ngVLA era of radio astronomy.",
    "authors": [
      "James K. Leung",
      "Om Sharan Salafia",
      "Cristiana Spingola",
      "Giancarlo Ghirlanda",
      "Stefano Giarratana",
      "Marcello Giroletti",
      "Cormac Reynolds",
      "Ziteng Wang",
      "Tao An",
      "Adam Deller",
      "Maria R. Drout",
      "David L. Kaplan",
      "Emil Lenc",
      "Tara Murphy",
      "Miguel Perez-Torres",
      "Lauren Rhodes"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.23530",
    "title": "Exploring Young Stellar Variability with Gaia DR3 light curves",
    "abstract": "Context: Photometric variability is a defining characteristic of young stellar objects (YSO), which can be traced back to a range of physical processes taking place at different stages of young stars' formation and early evolution. Gaia's third Data Release (GDR3) has provided an unprecedented dataset of photometric time series, including 79375 light curves for YSO candidates. With its all-sky coverage, Gaia provides a unique opportunity for large-scale studies of YSO variability. Aims: Our goal was to characterise the GDR3 sample of YSO variables further and verify the recurrence of YSO variability modes due to accretion, extinction, rotation modulation, etc. By adapting the Q&M methodology for Gaia's sparse and long-term light curves, we seek to bridge the gap between low and high-cadence surveys' insights on YSO variability. Methods: We piloted the application of the asymmetry (M) and periodicity (Q) variability metrics to characterise YSO variability with Gaia light curves. Through refined sample selection, we identified sources with appropriate sampling for the Q&M methodology. We used the Generalised Lomb Scargle periodogram and structure functions to infer variability timescales. Results: We successfully derived Q&M indices for ~23000 sources in the GDR3 YSO sample. These variables were then classified into eight variability morphological classes. We linked morphological classes with physical mechanisms by using H$\\alpha$ as a proxy of accretion and $\\alpha_\\mathrm{IR}$-indices to gauge circumstellar material's presence. Conclusions: We demonstrate that the Q&M metrics can be successfully applied to Gaia's sparse time-series. We applied them to distinguish between the several variability modes. While our results are generally consistent with previous high-cadence, short-term studies, we find that GDR3's long timespan yields an enhanced variety of variability mechanisms.",
    "authors": [
      "Chloé Mas",
      "Julia Roquette",
      "Marc Audard",
      "Mate Madarász",
      "Gabor Marton",
      "David Hernandez",
      "Ilknur Gezer",
      "Odysseas Dionatos"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.18446",
    "title": "MROP: Modulated Rank-One Projections for compressive radio interferometric imaging",
    "abstract": "The emerging generation of radio-interferometric (RI) arrays are set to form images of the sky with a new regime of sensitivity and resolution. This implies a significant increase in visibility data volumes, which for single-frequency observations will scale as $\\mathcal{O}(Q^2B)$ for $Q$ antennas and $B$ short-time integration intervals (or batches), calling for efficient data dimensionality reduction techniques. This paper proposes a new approach to data compression during acquisition, coined modulated rank-one projection (MROP). MROP compresses the $Q\\times Q$ batchwise covariance matrix into a smaller number $P$ of random rank-one projections and compresses across time by trading $B$ for a smaller number $M$ of random modulations of the ROP measurement vectors. Firstly, we introduce a dual perspective on the MROP acquisition, which can either be understood as random beamforming, or as a post-correlation compression. Secondly, we analyse the noise statistics of MROPs and demonstrate that the random projections induce a uniform noise level across measurements independently of the visibility-weighting scheme used. Thirdly, we propose a detailed analysis of the memory and computational cost requirements across the data acquisition and image reconstruction stages, with comparison to state-of-the-art dimensionality reduction approaches. Finally, the MROP model is validated for monochromatic intensity imaging both in simulation and from real data, with comparison to the classical and baseline-dependent averaging (BDA) models, and using the uSARA optimisation algorithm for image formation. Our results suggest that the data size necessary to preserve imaging quality using MROPs is reduced to the order of image size, well below the original and BDA data sizes.",
    "authors": [
      "Olivier Leblanc",
      "Chung San Chu",
      "Laurent Jacques",
      "Yves Wiaux"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.08861",
    "title": "Marvelous Metals: Surveying the Circumgalactic Medium of Simulated Dwarf Galaxies",
    "abstract": "Dwarf galaxies are uniquely sensitive to energetic feedback processes and are known to experience substantial mass and metal loss from their disk. Here, we investigate the circumgalactic medium (CGM) of 64 isolated dwarf galaxies ($6.0<$log(M$_*/M_{\\odot}$)$<9.5$) at $z=0$ from the Marvel-ous Dwarfs and Marvelous Massive Dwarfs hydrodynamic simulations. Our galaxies produce column densities broadly consistent with current observations. We investigate these column densities in the context of mass and metal retention rates and the physical properties of the CGM. We find $48\\pm11\\%$ of all baryons within $R_{200c}$ reside in the CGM, with $\\sim70\\%$ of CGM mass existing in a warm gas phase, $10^{4.5}<T<10^{5.5}$ K that dominates beyond $r/R_{200c}\\sim0.5$. Further, the warm and cool ($10^{4.0}<T<10^{4.5}$ K) gas phases each retain $5-10\\%$ of metals formed by the dwarf galaxy. The significant fraction of mass and metals residing in the warm CGM phase provides an interpretation for the lack of observed low ion detections beyond $b/R_{200c}\\sim0.5$ at $z\\sim0$, as the majority of mass in this region exists in higher ions. We find a weak correlation between galaxy mass and total CGM metal retention despite the fraction of metals lost from the halo increasing from $\\sim10\\%$ to $>40\\%$ towards lower masses. Our findings highlight the CGM (primarily its warm component) as a key reservoir of mass and metals for dwarf galaxies across stellar masses and underscore its importance in understanding the baryon cycle in the low-mass regime. Finally, we provide individual galaxy properties of our full sample and quantify the fraction of ultraviolet observable mass to support future observational programs, particularly those aimed at performing a metal budget around dwarf galaxies.",
    "authors": [
      "Daniel R. Piacitelli",
      "Alyson M. Brooks",
      "Charlotte Christensen",
      "N. Nicole Sanchez",
      "Yakov Faerman",
      "Sijing Shen",
      "Akaxia Cruz",
      "Ben Keller",
      "Thomas R. Quinn",
      "James Wadsley"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.10133",
    "title": "$f$-mode oscillations of protoneutron stars",
    "abstract": "We investigate nonradial $f$-mode oscillations of protoneutron stars in full general relativity, employing equations of state described by the Brueckner-Hartree-Fock theory or the relativistic mean field model, while assuming isentropy and fixed lepton fractions for the internal structure. The validity of various universal relations for cold neutron stars involving $f$-mode characteristics and macroscopic properties of the star is confirmed for those isentropic protoneutron stars. Prospects of observations are also discussed. According to simulation results, we then model details of the thermal and trapping profiles in a PNS with the canonical mass. The corresponding $f$-mode frequencies and gravitational-wave strain amplitudes are presented. The validity of the universal relations during the evolution to the formation of a cold neutron star is confirmed.",
    "authors": [
      "Zi-Yue Zheng",
      "Ting-Ting Sun",
      "Huan Chen",
      "Jin-Biao Wei",
      "Xiao-Ping Zheng",
      "G. F. Burgio",
      "H.-J. Schulze"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.22709",
    "title": "Solving Milky Way-sized Systems with Haskap Pie: A Halo finding Algorithm with efficient Sampling, K-means clustering, tree-Assembly, Particle tracking, Python modules, Inter-code applicability, and Energy solving",
    "abstract": "We describe a new Python-based stand-alone halo finding algorithm, Haskap Pie, that combines several methods of halo finding and tracking into a single calculation. Our halo-finder flexibly solves halos for simulations produced by eight simulation codes (ART-I, ENZO, RAMSES, CHANGA, GADGET-3, GEAR, AREPO, and GIZMO) and for both zoom-in or full-box N-body or hydrodynamical simulations and includes a unified, robust set of pre-tuned parameters. When compared to Rockstar and Consistent Trees, our halo-finder tracks subhalos much longer and more consistently, produces halos with better constrained physical parameters, and returns a much denser halo mass function for halos with more than 100 particles. Our results also compare favorably to recently described specialized particle-tracking extensions to Rockstar. Haskap Pie is well-suited to a variety of studies of simulated galaxies and is particularly robust for a new generation of studies of merging and satellite galaxies. For our initial paper, we focus on describing our algorithm's ability to find and track halos and subhalos in complex Milky Way-sized halo systems.",
    "authors": [
      "Kirk S. S. Barrow",
      "Thinh Huu Nguyen",
      "Edward C. Skrabacz"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.14878",
    "title": "The isotropy of Hubble expansion in the early and late Universe",
    "abstract": "We test the isotropy of Hubble expansion by combining several probes for the first time, constructing full-sky maps of expansion rate variation using Type Ia supernovae, fundamental plane galaxies, and CMB temperature fluctuations. We find no hint of anisotropy or correlation between early- and late-Universe expansion across all systematic models. The 99% confidence upper limits on expansion rate anisotropy are 0.39% for low-redshift supernovae, 0.95% for high-redshift CMB, and 0.37% when combined at a 60-degree smoothing scale. A significant anomaly in the fundamental plane residual map may reflect systematics in the current DESI dataset, as evidenced by the absence of cross-correlation with other tracers and its correlation with spatial density variations.",
    "authors": [
      "Alan Junzhe Zhou",
      "Scott Dodelson",
      "Daniel Scolnic"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.15345",
    "title": "Unveiling the small-scale web around galaxies with miniJPAS and DESI",
    "abstract": "We present the first statistical observational study detecting filaments in the immediate surroundings of galaxies, i.e. the local web of galaxies. Simulations predict that cold gas, the fuel for star formation, is channeled through filamentary structures into galaxies. Yet, direct observational evidence for this process has been limited by the challenge of mapping the cosmic web at small scales. Using miniJPAS spectro-photometric data combined with spectroscopic DESI redshifts when available, we construct a high-density observational galaxy sample spanning 0.2<z<0.8. Local filaments are detected within a 3 Mpc physical radius of each galaxy with stellar mass M* >10^(10) Msun using all nearby galaxies as tracers, combined with a probabilistic adaptation of the DisPerSE algorithm designed to overcome limitations due to photometric redshift uncertainties. Our methodology is tested and validated using mock catalogues built with random forest models applied to a simulated lightcone. Besides recovering the expected increase in galaxy connectivity (defined as the number of filaments attached to a galaxy) with stellar mass, we show that our connectivity measurements agree with 3D reference estimates from the mock galaxies. Thanks to these filament reconstructions, we explore the relation between small-scale connectivity and galaxy star formation rate, finding a mild positive trend which needs to be confirmed by follow up studies with larger sample sizes. We propose galaxy connectivity to local filaments as a powerful and physically motivated metric of environment, offering new insights into the role of cosmic structure in galaxy evolution.",
    "authors": [
      "Daniela Galárraga-Espinosa",
      "Guinevere Kauffmann",
      "Silvia Bonoli",
      "Luisa Lucie-Smith",
      "Rosa M. González Delgado",
      "Elmo Tempel",
      "Raul Abramo",
      "Siddharta Gurung-López",
      "Valerio Marra",
      "Jailson Alcaniz",
      "Narciso Benitez",
      "Saulo Carneiro",
      "Javier Cenarro",
      "David Cristóbal-Hornillos",
      "Renato Dupke",
      "Alessandro Ederoclite",
      "Antonio Hernán-Caballero",
      "Carlos Hernández-Monteagudo",
      "Carlos López-Sanjuan",
      "Antonio Marín-Franch",
      "Claudia Mendes de Oliveira",
      "Mariano Moles",
      "Laerte Sodré Jr",
      "Keith Taylor",
      "Jesús Varela",
      "Hector Vázquez Ramió"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.01331",
    "title": "Supernova Ia Remnants with M dwarf surviving companions",
    "abstract": "We study the possibility that Type Ia supernovae might be produced by binary systems where the companion of the exploding white dwarf is an M-dwarf star. Such companion would appear as a runaway star, retaining its pre-explosion orbital velocity along with a kick imparted by the supernova ejecta. It might be rapidly rotating, from being tidally locked with the white dwarf prior to explosion in a very close binary. For this study, we perform a series of multidimensional hydrodynamic simulations to investigate the interaction between M-dwarf companions and SN ejecta, followed by post-impact stellar evolution modeling using the MESA code. Our initial models in the 3D simulations had high spin angular momenta and the effects of magnetic braking have been included. They very significantly reduce the final rotation. A surviving companion candidate, MV-G272, has recently been discovered in the supernova remnant G272.2-3.2, which is an 8.9$\\sigma$ proper motion outlier, although being slowly rotating. Our results show that the properties of this companion (luminosity, effective temperature, surface gravity) can be reproduced by our post-impact M-dwarf models. The slow rotation, which is a common characteristic with several proposed hypervelocity SN companions, can be explained by magnetic braking during the post-impact evolution, thus supporting the possibility that the MV-G272 star is the surviving companion of the Type Ia supernova now found as G272.2-3.2 SNR.",
    "authors": [
      "Kuo-Chuan Pan",
      "Pilar Ruiz-Lapuente",
      "Jonay I. González Hernández"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.06841",
    "title": "Cosmic baryon census with fast radio bursts and gravitational waves",
    "abstract": "The cosmic baryon density fraction ($\\Omega_{\\rm b}$) is intrinsically correlated with the Hubble constant ($H_0$) through the critical density of the Universe. In the context of the decade-long $H_0$ tension, the significant discrepancy between early- and late-Universe measurements of $H_0$ implies that fixing its value or imposing an external prior could bias the baryon census. To address this concern, we construct a late-Universe probe framework that unifies fast radio bursts (FRBs) and gravitational-wave (GW) standard sirens, which can respectively resolve the missing baryon problem and the $H_0$ tension through their dispersion measures and absolute luminosity distances. By combining $104$ localized FRBs with $47$ GW events, we obtain an $H_0$-free measurement of $\\Omega_{\\rm b}=0.0488\\pm0.0064$ ($1\\sigma$), in concordance with early-Universe observations of CMB + BBN. Although the current precision ($\\sim 13\\%$) is limited by sample size, the growing detections of both FRBs and GWs will make their synergy a powerful probe of low-redshift cosmology.",
    "authors": [
      "Ji-Guo Zhang",
      "Ji-Yu Song",
      "Ze-Wei Zhao",
      "Wan-Peng Sun",
      "Jing-Fei Zhang",
      "Xin Zhang"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.09085",
    "title": "Little Red Dots As Late-stage Quasi-stars",
    "abstract": "We argue that the \"Little Red Dots\" (LRDs) discovered with the James Webb Space Telescope are quasi-stars in their late stages of evolution. Quasi-stars are hypothetical objects predicted to form following the core collapse of supermassive stars, and consist of black holes accreting from massive envelopes at a super-Eddington rate. We show that models of late-stage quasi-stars, with black hole masses exceeding $\\sim 10\\%$ of the total, predict thermal and radiative properties that are insensitive to both black hole and envelope mass, and spectrally resemble LRDs. Specifically, we show that they are likely to exhibit reddish colors, a strong Balmer break, and possess conditions favorable to the production of Balmer lines that are broadened by electron scattering. Their huge electron column densities suppress any X-rays. Late-stage quasi-stars, with black hole masses $\\gtrsim 10^6 M_\\odot$, should dominate the overall quasi-star population. Their short predicted lifetimes (tens of Myr), coupled with the high observed comoving density of LRDs, suggest that most or all supermassive black holes go through a quasi-star/LRD phase during their formation and growth.",
    "authors": [
      "Mitchell C. Begelman",
      "Jason Dexter"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.16932",
    "title": "Constraints on a dark matter sub-halo near the Sun from pulsar timing",
    "abstract": "Using pulsar accelerations, we identify and constrain the properties of a dark matter sub-halo in the Galaxy for the first time from analyzing the acceleration field of binary and solitary pulsars. Our MCMC calculations show that this sub-halo has a mass of $2.45^{+1.07}_{-0.96} \\times 10^{7}~M_{\\odot}$ and is located at Galactocentric coordinates $X = 7.43^{+0.2}_{-0.12}~\\rm$ kpc, $Y = 0.38^{+0.11}_{-0.16} ~\\rm kpc$, $Z = 0.21^{+0.06}_{-0.11} ~\\rm kpc$, using flat, uninformative priors, where we have modeled the sub-halo as a compact object. The Bayes factors for the models are in the range of $\\sim$ 20-40, which indicates tentative evidence (though not yet decisive) for the sub-halo. Modeling the sub-halo with a NFW profile gives a sub-halo mass within the scale radius (0.1 kpc) of $0.48^{0.15}_{-0.16} \\times 10^{7} M_{\\odot}$, located at $X = 7.47^{+0.21}_{-0.14}$, $Y=0.38^{+0.11}_{-0.16}$, $Z=0.21^{+0.06}_{-0.11}$. We examine \\textit{Gaia} data and the atomic and molecular hydrogen data of our Galaxy and show that the measured deviation from a smooth potential cannot arise from the gas or the stars in our Galaxy. By analyzing the full sample of binary pulsars with available acceleration measurements, we find that massive (with mass $>10^{8}~M_{\\odot}~$) sub-halos are disfavored for the Milky Way within several kiloparsec of the Sun. Smaller sub-halos are beyond the reach of current direct acceleration measurements. The presence of a $\\sim 10^{7}~M_{\\odot}$ sub-halo within a few kpc of the Sun is potentially consistent with the expected number counts of sub-halos in the prevailing $\\Lambda$CDM paradigm, for a substantial sub-halo mass fraction. This work now provides a proof of principle for probing nearby, low-mass sub-halos, and has implications across many fields of astrophysics - from understanding the nature of dark matter to galaxy formation.",
    "authors": [
      "Sukanya Chakrabarti",
      "Philip Chang",
      "Stefano Profumo",
      "Peter Craig"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.05007",
    "title": "Coupled 1D Chemical Kinetic-Transport and 2D Hydrodynamic Modeling Supports a modest 1-1.5x Supersolar Oxygen Abundance in Jupiter's Atmosphere",
    "abstract": "Understanding the deep atmospheric composition of Jupiter provides critical constraints on its formation and the chemical evolution of the solar nebula. In this study, we combine one-dimensional thermochemical kinetic-transport modeling with two-dimensional hydrodynamic simulations to constrain Jupiter's deep oxygen abundance using carbon monoxide (CO) as a proxy tracer. Leveraging a comprehensive chemical network generated by Reaction Mechanism Generator (RMG), we assess the impact of updated reaction rates, including the often-neglected but thermochemically significant Hidaka reaction (CH3OH + H -> CH3 + H2O). Our 1D-2D coupled approach supports a modest supersolar oxygen enrichment of 1.0-1.5x the solar value. We also present a method for deriving Jupiter's eddy diffusion coefficient Kzz = 3e6 to 5e7 cm2/s) from 2D hydrodynamic simulations using the quasi steady-state approach. This method is applicable to exoplanet atmospheres, where Kzz remains highly uncertain despite its strong influence on atmospheric chemistry. Finally, our results imply a significantly elevated planetary carbon-to-oxygen (C/O) ratio of ~2.9, highlighting the importance of clarifying the mechanisms behind the preferential accretion of carbon-rich material during Jupiter's formation. By integrating thermochemical and hydrodynamic processes, our study offers a more complete framework for constraining chemical and dynamical processes in (exo)planetary atmospheres.",
    "authors": [
      "Jeehyun Yang",
      "Ali Hyder",
      "Renyu Hu",
      "Jonathan I. Lunine"
    ],
    "primary_category": "astro-ph.EP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.11596",
    "title": "Breaking the Strings: the signatures of Cosmic String Loop Fragmentation",
    "abstract": "We study the impact of fragmentation on the cosmic string loop number density, using an approach inspired by the three-scale model and a Boltzmann equation. We build a new formulation designed to be more amenable to numerical resolution and present two complementary numerical methods to obtain the full loop distribution including the effect of fragmentation and gravitational radiation. We show that fragmentation generically predicts a decay of the loop number density on large scales and a deviation from a pure power-law. We expect fragmentation to be crucial for the calibration of loop distribution models.",
    "authors": [
      "Pierre Auclair"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.03593",
    "title": "Unraveling the Nature of the Nuclear Transient AT2020adpi",
    "abstract": "Transient events associated with supermassive black holes provide rare opportunities to study accretion and the environments of supermassive black holes. We present a multiwavelength study of AT2020adpi (ZTF20acvfraq), a luminous optical/UV transient in the nucleus of the galaxy WISEA J231853.77$-$103505.6 ($z=0.26$) that exhibits the properties of an ambiguous nuclear transient. Near peak, its spectral energy distribution is well described by a power law ($\\lambda L_\\lambda \\propto \\lambda^{-\\alpha}$, $\\alpha = 0.44 \\pm 0.04$), with a maximum $g$-band luminosity of $(3.6 \\pm 0.6)\\times10^{44}$ erg s$^{-1}$, which is consistent with luminous AGN flares. We detect a strong mid-infrared flare ($L_\\mathrm{peak}^{\\mathrm{MIR}} = (2.3 \\pm 0.05)\\times10^{44}$ erg s$^{-1}$) delayed by $\\sim$210 rest-frame days, indicating a hot dust echo from material at $\\sim$0.2 pc. The optical and near-infrared spectra show broad H, He I, [OIII] lines, as well as narrow Fe II, and prominent Mg II, which is a combination not typical of TDEs. Taken together, these features suggest AT2020adpi is an ambiguous nuclear transient, where an accretion episode was triggered by stellar disruption of an accretion disk or instabilities within an active nucleus. This source demonstrates the need for careful multiwavelength analysis to distinguish between extreme AGN variability and TDEs.",
    "authors": [
      "Paarmita Pandey",
      "Jason Hinkle",
      "Christopher Kochanek",
      "Michael Tucker",
      "Mark Reynolds",
      "Jack Neustadt",
      "Todd Thompson",
      "Katie Auchettl",
      "Benjamin Shappee",
      "Aaron Do",
      "Dhvanil Desai",
      "W. Hoogendam",
      "C. Ashall",
      "Thomas Lowe",
      "Melissa Shahbandeh",
      "Anna Payne"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.08874",
    "title": "Characterizing Supernova Host Galaxies with FrankenBlast: A Scalable Tool for Transient Host Galaxy Association, Photometry, and Stellar Population Modeling",
    "abstract": "We present FrankenBlast, a customized and improved version of the Blast web application. FrankenBlast associates transients to their host galaxies, performs host photometry, and runs a innovative SED fitting code to constrain host stellar population properties--all within minutes per object. We test FrankenBlast on 14,432 supernovae (SNe), ~half of which are spectroscopically-classified, and are able to constrain host properties for 9262 events. When contrasting the host stellar masses ($M_*$), specific star formation rates (sSFR), and host dust extinction ($A_V$) between spectroscopically and photometrically-classified SNe Ia, Ib/c, II, and IIn, we determine that deviations in these distributions are primarily due to misclassified events contaminating the photometrically-classified sample. We further show that the higher redshifts of the photometrically-classified sample also force their $M_*$ and sSFR distributions to deviate from those of the spectroscopically-classified sample, as these properties are redshift-dependent. We compare host properties between spectroscopically-classified SN populations and determine if they primarily trace $M_*$ or SFR. We find that all SN populations seem to both depend on $M_*$ and SFR, with SNe II and IIn somewhat more SFR-dependent than SNe Ia and Ib/c, and SNe Ia more $M_*$-dependent than all other classes. We find the difference in the SNe Ib/c and II hosts the most intriguing and speculate that SNe Ib/c must be more dependent on higher $M_*$ and more evolved environments for the right conditions for progenitor formation. All data products and FrankenBlast are publicly available, along with a developing FrankenBlast version intended for Rubin Observatory science products.",
    "authors": [
      "Anya E. Nugent",
      "V. Ashley Villar",
      "Alex Gagliano",
      "David O. Jones",
      "Asaf Horowicz",
      "Kaylee de Soto",
      "Bingjie Wang",
      "Ben Margalit"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10319",
    "title": "The merger of spinning, accreting supermassive black hole binaries",
    "abstract": "Because they are likely to accrete substantial amounts of interstellar gas, merging supermassive binary black holes are expected to be strong multimessenger sources, radiating gravitational waves, photons from thermal gas, and photons from relativistic electrons energized by relativistic jets. Here we report on a numerical simulation that covers the late inspiral, merger, and initial postmerger phase of such a system where both black holes have the same mass and spin, and both spin axes are parallel to the orbital angular momentum. The simulation incorporates both 3D general relativistic magnetohydrodynamics and numerical relativity. The thermal photon power during the late inspiral, merger, and immediate postmerger phases is drawn from strong shocks rather than dissipation of turbulence inside a smoothly structured accretion disk as typically found around accreting single black holes. We find that the thermal photon and jet Poynting flux outputs are closely related in time, and we posit a mechanism that enforces this relation. The power radiated in both photons and jets diminishes gradually as merger is approached, but jumps sharply at merger to a noisy plateau. Such a distinct lightcurve should aid efforts to identify supermassive black hole mergers, with or without accompanying gravitational wave detections.",
    "authors": [
      "Lorenzo Ennoggi",
      "Manuela Campanelli",
      "Julian Krolik",
      "Scott C. Noble",
      "Yosef Zlochower",
      "Maria Chiara de Simone"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.24211",
    "title": "Far-infrared lines hidden in archival deep multi-wavelength surveys: Limits on [CII]-158$μ$m at $z \\sim 0.3-2.9$",
    "abstract": "Singly-ionized carbon is theorized to be the brightest emission line feature in star-forming galaxies, and hence an excellent tracer of the evolution of cosmic star formation. Archival maps from far-infrared and sub-millimeter surveys potentially contain the redshifted [CII]-158$\\mu$m, hidden in the much brighter continuum emission. We present a search for aggregate [CII]-158$\\mu$m line emission across the predicted peak of star formation history by tomographically stacking a high-completeness galaxy catalog on broadband deep maps of the COSMOS field and constraining residual excess emission after subtracting the continuum spectral energy distribution (SED). We obtain constraints on the sky-averaged [CII]-158$\\mu$m signal from the three Herschel/SPIRE maps: $11.8\\pm10.2$, $11.0\\pm8.7$, $9.6\\pm9.8$, and $9.2\\pm6.6$ $k$Jy/sr at redshifts $z\\sim 0.65$, $\\sim1.3$, $\\sim2.1$, and $\\sim2.6$ respectively, corresponding to $1-1.4\\sigma$ significance in each bin. Our $3\\sigma$ upper limits are in tension with past $z\\sim2.6$ results from cross-correlating SDSS-BOSS quasars with high-frequency Planck maps, and indicate a much less dramatic evolution ($\\sim\\times7.5$) of mean [CII] intensity across the peak of star formation history than collisional excitation models or frameworks calibrated to the tentative PlanckxBOSS measurement. We discuss this tension, particularly in the context of in-development surveys (TIM, EXCLAIM) that will map this [CII] at high redshift resolution. Having demonstrated stacking in broadband deep surveys as a complementary methodology to next-generation spectrometers for line intensity mapping, our novel methods can be extended to upcoming galaxy surveys such as Euclid, as well as to place upper limits on fainter atomic and molecular lines.",
    "authors": [
      "Shubh Agrawal",
      "James Aguirre",
      "Ryan Keenan"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25167",
    "title": "Vz-GAL: Probing Cold Molecular Gas in Dusty Star-forming Galaxies at z=1-6",
    "abstract": "We present the first results of V\\textit{z}-GAL, a high-redshift CO($J=1-0$) large survey with the Karl G. Jansky Very Large Array, targeting 92 \\textit{Herschel}-selected, infrared-luminous, dusty star-forming galaxies (DSFGs) at redshifts 1 to 6. These sources are selected based on having redshifts and mid/high-\\textit{J} CO transitions from the NOrthern Extended Millimeter Array \\zgal survey. We successfully detect CO($J=1-0$) emission in 90/92 galaxies at the expected positions and redshifts, including 9 tentative detections at $2\\sigma - 3\\sigma$ significance, and CO($J=2-1$) emission in 10 of these galaxies. The CO($J=1-0$) luminosities suggest apparent gas masses in the range $\\mu {M}_{\\rm H_2}$ = $(2-20) \\times {10}^{11}~(\\alpha_{CO}/{4.0})~\\mathrm{M_{\\odot}}$, which implies gas depletion times of $(50-600)$~Myr. These timescales show similar spread as local ULIRGs, suggesting a self-regulatory mechanism that maintains a consistent SFR per unit gas mass in starbursts across redshifts. To quantify the contribution of ``excitation correction\" factors to gas mass estimates, we calculate median CO line brightness temperature ratios of $r_{21}=0.88\\pm0.25$, $r_{31}=0.61\\pm0.22$, $r_{41}=0.49\\pm0.15$, $r_{51}=0.47\\pm0.13$, and $r_{61}=0.28\\pm0.13$. Accounting for these corrections results in a reduced scatter in `gas mass--star formation rate' relations. We also find a median log(${L}^{\\prime}_{\\mathrm{[CI]}(^{3}P_1 - ^{3}P_0)}/{L}^{\\prime}_{\\mathrm{CO}(J=1-0)})=-0.71\\pm0.12$ for a subsample of 23 sources, consistent with the ratios derived for local star-forming galaxies. Together, our findings are in agreement with common conditions in the cold gas reservoirs among star-forming galaxies over a broad range in star formation modes, efficiencies, and scales.",
    "authors": [
      "Prachi Prajapati",
      "Dominik Riechers",
      "Pierre Cox",
      "Axel Weiss",
      "Amelie Saintonge",
      "Bethany Jones",
      "Tom J. L. C. Bakx",
      "Stefano Berta",
      "Paul van der Werf",
      "Roberto Neri",
      "Kirsty M. Butler",
      "Asantha Cooray",
      "Diana Ismail",
      "Andrew J. Baker",
      "Edoardo Borsato",
      "Andrew Harris",
      "Rob Ivison",
      "Matthew Lehnert",
      "Lucia Marchetti",
      "Hugo Messias",
      "Alain Omont",
      "Catherine Vlahakis",
      "Chentao Yang"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.02257",
    "title": "Photometric stellar masses for galaxies in DESI Legacy Imaging Surveys",
    "abstract": "In many areas of extragalactic astrophysics, we need to convert the luminosity of a galaxy into its stellar mass. In this work, we aim to find a simple and effective formula to estimate the stellar mass from the images of galaxies delivered by the currently popular DESI Legacy Imaging Surveys. This survey provides an unsurpassed combination of a deep imaging with an extensive sky coverage in up to four photometric bands. We calibrated the sought formula against a sample of local galaxies observed by the Spitzer Survey of Stellar Structure in Galaxies (S$^4$G) that was directly dedicated to measure the stellar masses. For the absolute magnitudes $M_g$ and $M_r$ of a galaxy in the Legacy Surveys $g$ and $r$ bands, we find that the stellar masses can be estimated as $0.673M_g - 1.108M_r + 0.996$ with the scatter of 25\\%. Employing more complex functions does not improve the estimate appreciably, even after including the galaxy ellipticity, Sérsic index, or the magnitudes in different Legacy Surveys bands. Generally, measurements in $r$ band were the most helpful ones, while adding $z$-band measurements did not improve the mass estimate much. We provide a Python-based script \\texttt{photomass\\ this http URL } to automatically download images of any galaxy from the Legacy Surveys database, create image masks, generate GALFIT input files with well-assessed initial values, perform the GALFIT photometry, and calculate the stellar mass estimate. Additionally, we tuned another version of the formula to the magnitudes provided by the Siena Galaxy Atlas 2020 (SGA-2020) with a scatter of 29\\%. For both\\,--\\,our default and SGA-2020 formula, we offer two alternatives derived from different calibrations of S$^4$G masses that were based on different methods and assumptions.",
    "authors": [
      "Ivana Ebrová",
      "Michal Bílek",
      "Jiří Eliášek"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.23115",
    "title": "Luminosity Functions and Detectability of Binary Neutron Star Merger-nova Signals with Various Merger Remnants",
    "abstract": "With the rapid advancements in next-generation ground-based gravitational wave (GW) detectors, it is anticipated that $10^3$-$10^5$ binary neutron star (BNS) mergers per year will be detected, with a significant fraction accompanied by observable merger-nova signals through future sky surveys. Merger-novae are typically powered by the radioactive decay of heavy elements synthesized via the r-process. If the post-merger remnant is a long-lived rapid-rotating neutron star, the merger-nova can be significantly enhanced due to strong magnetized winds. In this paper, we generate mock BNS merger samples using binary population synthesis model and classify their post-merger remnants--black hole (BH) and magnetar, (i.e., long-lived supramassive NS and stable NS), based on results from numerical simulations. We then construct merger-nova radiation models to estimate their luminosity function. We find that the luminosity function may exhibit a distinctive triple-peak structure, with the relative positions and heights of these peaks depending on the equation of state (EOS) of the BNS. Furthermore, we estimate the average Target-of-Opportunity (ToO) detection efficiency $\\langle f_{\\rm eff} \\rangle$ with the Chinese Space Station Telescope (CSST) and find that due to possible enhanced luminosity, the largest source redshift with $\\langle f_{\\rm eff} \\rangle>0.1$ can be enlarged from $z_{\\rm s}\\sim 0.5$ to $z_{\\rm s}\\sim 1-1.5$. Besides, we also generate the detectable mass spectrum for merger-novae by $\\langle f_{\\rm eff}\\rangle$, which may provide insights to the ToO searching strategy.",
    "authors": [
      "Zhiwei Chen",
      "Youjun Lu",
      "Hao Ma",
      "Qingbo Chu"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.09648",
    "title": "Fractional Dynamics in Galactic Nuclei: Non-Local Transport, Transient Phenomena and the Nullification of the Schwarzschild Barrier",
    "abstract": "We investigate the application of fractional calculus to model stellar dynamics, focusing on Resonant Relaxation (RR) near a supermassive black hole (SMBH). Standard theories use the local Fokker-Planck (FP) equation, restricted to Gaussian processes under the Central Limit Theorem (CLT). We argue this is inadequate for RR. We demonstrate that gravitational interactions inherently produce infinite variance in stochastic torques, violating the CLT. Consequently, RR is governed by the Generalized Central Limit Theorem (GCLT) and constitutes a superdiffusive Lévy flight. We apply the space-fractional Fokker-Planck equation (FFPE), utilizing non-local operators, to explore resolutions to observational discrepancies. In transient regimes, the FFPE predicts immediate, linear flux ($\\Gamma(t) \\propto t$), consistent with high Tidal Disruption Event (TDE) rates in post-starburst galaxies, whereas local FP models predict significant exponential delay. Furthermore, we demonstrate analytically that non-local integral operators permit ``barrier jumping,'' bypassing bottlenecks like the Schwarzschild Barrier (SB), which local models interpret as severely suppressing Extreme Mass-Ratio Inspiral (EMRI) rates. We present proof-of-concept $N$-body simulations that confirm non-local RR transport, although the resolution must be improved to rule out enhanced Two-Body Relaxation in the small-N setup. The fractional framework offers a compelling alternative description for non-local transport, potentially resolving TDE and EMRI rate questions.",
    "authors": [
      "Pau Amaro Seoane"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.09858",
    "title": "Galaxy clusters from the DESI Legacy Imaging Surveys -- III. Star-forming fraction of brightest cluster galaxies",
    "abstract": "This study investigates the evolution of the star-forming fraction ($F_{\\mathrm{sf}}$) of Brightest Cluster Galaxies (BCGs) at $z<0.8$, using the galaxy clusters identified from the Legacy Imaging Surveys from the Dark Energy Spectroscopic Instrument (DESI). Star-forming galaxies are identified using the $g-z$ color, and $F_{\\mathrm{sf}}$ is measured as a function of redshift, cluster halo mass, and galaxy stellar mass. Field galaxies are used as a comparison sample to reduce selection effects. For BCGs, $F_{\\mathrm{sf}}$ increases with redshift, showing a slow rise below $z \\sim 0.4 - 0.5$ and a more rapid increase above this range. In contrast, $F_{\\mathrm{sf}}$ decreases with increasing cluster halo mass and BCG stellar mass. At the low stellar mass end, BCGs exhibit higher star-forming fractions than field galaxies, suggesting enhanced star formation likely fueled by cold gas accretion from the intracluster medium. Also, star-forming BCGs tend to show larger projected offsets from the optical cluster density peak than quenching BCGs, indicating ongoing assembly. The analysis of the specific star formation rate (sSFR) further indicates a transition in the dominant mechanism driving star formation in BCGs: cooling flows are likely responsible at low redshift, while gas-rich mergers play a greater role at higher redshift. The shift in dominance occurs around $z \\sim 0.5$, aligning with the steep rise in $F_{\\mathrm{sf}}$ of BCG.",
    "authors": [
      "Shufei Liu",
      "Hu Zou",
      "Jinfu Gou",
      "Weijian Guo",
      "Niu Li",
      "Wenxiong Li",
      "Gaurav Singh",
      "Haoming Song",
      "Jipeng Sui",
      "Xi Tan",
      "Yunao Xiao",
      "Jingyi Zhang",
      "Lu Feng"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.10794",
    "title": "The impact of supermassive black holes on exoplanet habitability: I. Spanning the natural mass range",
    "abstract": "While the influence of supermassive black hole (SMBH) activity on habitability has garnered attention, the specific effects of active galactic nuclei (AGN) winds, particularly ultrafast outflows (UFOs), on planetary atmospheres remain largely unexplored. This study aims to fill this gap by investigating the relationship between SMBH mass at the galactic center and exoplanetary habitability, given that SMBH masses are empirically confirmed to span approximately 5 orders of magnitude in galaxies. Through simplified models, we account for various results involving the relationships between the distance from the planet to the central SMBH and the mass of the SMBH. Specifically, we show that increased SMBH mass leads to higher atmospheric heating and elevated temperatures, greater molecular thermal velocities, and enhanced mass loss, all of which diminish with distance from the galactic center. Energy-driven winds consistently have a stronger impact than momentum-driven ones. Crucially, ozone depletion is shown to rise with SMBH mass and decrease with distance from the galactic center, with nearly complete ozone loss ($\\sim100\\%$) occurring across galactic scales for SMBHs $\\geq 10^8 M_\\odot$ in the energy-driven case. This study emphasizes that SMBH growth over cosmic time may have produced markedly different impacts on galactic habitability, depending on both the mass of the central black hole (BH) and the location of planetary systems within their host galaxies.",
    "authors": [
      "Jourdan Waas",
      "Eric S. Perlman",
      "Manasvi Lingam",
      "Emily Lohmann",
      "Jackson Kernan",
      "Francesco Tombesi",
      "Amedeo Balbi",
      "Alessandra Ambrifi"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.15482",
    "title": "Probing the disk-jet coupling in M87",
    "abstract": "Context. Recent GMVA observations of M 87 at event horizon scales revealed a ring-like structure which is 50% larger at 86 GHz than the ring observed by the Event Horizon Telescope at 230 GHz. Aims. In this paper, we study a possible origin of the increased ring size at 86 GHz. We specifically aim to study the role the nonthermal electron population plays in the observed event horizon scales. Methods. We carry out 3D general relativistic magnetohydrodynamic simulations followed by radiative transfer calculations. We incorporate into the latter synchrotron emission from both thermal and nonthermal electrons. To better compare our results to observations, we generate synthetic interferometric data adjusted to the properties of the observing arrays. We fit geometrical models to this data in Fourier space through Bayesian analysis to monitor the variable ring size and width over the simulated time span of years. Results. We find that the 86 GHz ring is always larger than the 230 GHz ring, which can be explained by the increased synchrotron self-absorption at 86 GHz and the mixed emission from both the accretion disk and the jet footpoints, as well as flux arcs ejected from a magnetized disk. We find agreement with the observations, particularly within the error range of the observational value of M/D for M 87. Conclusions. We show that state-of-the art 3D GRMHD simulations combined with thermal and nonthermal emitting particles can explain the observed frequency-dependent ring size in M 87. Importantly we found that MAD events triggered in the accretion disk can significantly increase the lower frequency ring sizes.",
    "authors": [
      "Ainara Saiz-Pérez",
      "Christian M. Fromm",
      "Yosuke Mizuno",
      "Matthias Kadler",
      "Karl Mannheim",
      "Ziri Younsi"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22243",
    "title": "Forecasting Primordial Non-Gaussianity from UNIONS Lyman-Break Galaxies and Planck CMB lensing",
    "abstract": "Primordial non-Gaussianities (PNGs), characterized by $f_{\\rm NL}^{\\rm loc}$, provide a powerful window into the physics of inflation. Cross-correlating high-redshift tracer samples with the CMB lensing potential offers a particularly robust probe of PNGs, mitigating imaging systematics that typically affect large-scale measurements from tracer auto-spectra. In this context, UNIONS enables the selection of $u$-dropout high-redshift Lyman-Break Galaxies (LBGs). We perform a MCMC-based forecast to estimate the uncertainties on $f_{\\rm NL}^{\\rm loc}$ and on a galaxy bias parameter, which captures our uncertainty in the tracer bias. From the angular cross-power spectrum between LBGs and Planck CMB lensing, we forecast $\\sigma(f_{\\rm NL}^{\\rm loc})=34$ for an idealized photometric sample of $r<24.3$ LBGs selected with a Random Forest classification algorithm from UNIONS-like $ugriz$ imaging, with a resulting surface density of $1,100$ deg$^{-2}$. This precision can be improved to $\\sigma(f_{\\rm NL}^{\\rm loc})=20$ after spectroscopic follow-up with DESI, during its next phase starting in 2029, DESI-II. We test a more realistic $u$-dropout LBG selection using early UNIONS data, which yields a denser sample of $r<24.2$ objects at $1,400$ deg$^{-2}$. From this sample, covering a larger footprint and expected to have a higher large-scale galaxy bias, we forecast $\\sigma(f_{\\rm NL}^{\\rm loc})=20$, with similar precision achievable after DESI spectroscopic follow-up. In addition, we perform preliminary validation of the redshift distribution using the clustering-redshift method with DESI DR1 data, confirming the calibration from deep, small-area photometric fields. However, accounting for uncertainties in the clustering-redshift distribution significantly degrades the $f_{\\rm NL}^{\\rm loc}$ constraining power.",
    "authors": [
      "Constantin Payerne",
      "William d'Assignies",
      "Christophe Yèche",
      "Hendrik Hildebrandt",
      "Dustin Lang",
      "Thomas de Boer"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02093",
    "title": "COSMOS-3D: Two obscured X-ray AGNs with hot dust and He I$λ$10830 absorption at z~3",
    "abstract": "We report the discovery of two broad-line X-ray AGNs cid_414 and cid_947 at z~3 that exhibit prominent He I$\\lambda$10830+ Pa$\\gamma$ emission and absorption, identified from the JWST Cycle 3 large GO treasury program COSMOS-3D using NIRCam F444W grism spectroscopy. Additional UV/optical line measurements (e.g., Ly$\\alpha$, Si IV, C IV) come from complementary COSMOS-field spectroscopy. Both sources are robustly detected in the mid-infrared, with detections in MIRI F1000W for both AGNs and an additional detection in MIRI F2100W for cid_414, indicating the presence of hot dust emission. The source cid_947 shows a higher He I$\\lambda$10830 absorption column density and X-ray-inferred $N_{\\rm H}$, and displays strong outflow signatures in He I, Si IV, and C IV with velocity offsets exceeding 5000 km/s. The source cid_414 shows a narrow Ly$\\alpha$ emission line with luminosity $\\log L_{\\rm Ly\\alpha}=42.49\\pm0.01~\\mathrm{erg~s^{-1}}$ and a higher intrinsic 2-10 keV X-ray luminosity. Host-galaxy decomposition and multi-component SED fitting indicate that cid_947 hosts a more massive black hole but lower star formation rate than cid_414. From simplified photoionization modeling, we infer that the dense absorbing gas has a characteristic size comparable to the nuclear broad-line region and is likely kinematically coupled to the obscuration associated with the dust torus. He I$\\lambda$1083 absorption has also been identified in several compact little red dots at similar redshifts. Together with the two AGNs reported here, these findings suggest that dense circumnuclear gas are plausibly prevalent at high redshift and plays an important role in regulating AGN obscuration and black hole--host co-evolution.",
    "authors": [
      "Zi-Jian Li",
      "Siwei Zou",
      "Jianwei Lyu",
      "Jaclyn B. Champagne",
      "Jia-Sheng Huang",
      "Cheng Cheng",
      "Shuqi Fu",
      "Zijian Zhang",
      "Danyang Jiang",
      "Khee-Gan Lee",
      "Feige Wang",
      "Xiaohui Fan",
      "Jinyi Yang",
      "Ruancun Li",
      "Hollis B. Akins",
      "Fuyan Bian",
      "Y. Sophia Dai",
      "Andreas L. Faisst",
      "Luis C. Ho",
      "Kohei Inayoshi",
      "Linhua Jiang",
      "Xiangyu Jin",
      "Koki Kakiichi",
      "Jeyhan S. Kartaltepe",
      "Zihao Li",
      "Weizhe Liu",
      "Jan-Torge Schindler",
      "Wei Leong Tee"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02269",
    "title": "The SPHINX M dwarf Spectral Grid. II. New Model Atmospheres and Spectra to Derive Fundamental Properties of mid-to-late type M-dwarfs",
    "abstract": "M-dwarfs are the most dominant stars in the Galaxy. Their interiors and atmospheres exhibit complex processes including dust condensation, convective feedback, and magnetic activity-driven heterogeneity. Standard stellar characterization methods often struggle to capture these coupled effects. Part I of this series introduced SPHINX I, a validated grid of self-consistent radiative-convective model atmospheres and spectra for M-dwarfs with up-to-date molecular opacities suitable for early-to-mid M-dwarfs. Here, we present SPHINX II, which extends the model grid to cover mid-to-late type M-dwarfs, including both gray and physically motivated condensate cloud treatments and shorter convective mixing lengths. We validate SPHINX II using 39 benchmark FGK+M binary systems observed with SpeX IRTF (Mann et al. 2014) and apply it to 32 mid-to-late-type M-dwarfs from the SpeX Prism Library. SPHINX II yields improved fits that are statistically consistent with empirical benchmarks, achieving precisions of 0.078 dex in metallicity and 0.13 dex in C/O. Across the model grid, condensate cloud mass peaks between 2100-2400 K, decreasing sharply toward both cooler and hotter temperatures. We find the onset of the cloud-free regime around 2900 K, and below 2100 K, we see formation of deep/buried clouds. As a case study, we also model Trappist-1 and show that even mass-limited silicate grains subtly modify its emergent spectrum, suppressing near-infrared flux and reddening the mid-infrared slope via shallow cloud formation near 1e-2 bar. In sum, SPHINX II provides an improved framework for constraining the fundamental properties of mid-to-late M-dwarfs.",
    "authors": [
      "Aishwarya R. Iyer",
      "Michael R. Line",
      "Philip S. Muirhead",
      "Jonathan J. Fortney",
      "Jacqueline K. Faherty"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02391",
    "title": "\"SNe Ia twins\" in the Hubble flow, and the determination of H0",
    "abstract": "We have applied our approach of using ''SNe Ia twins''in the Hubble flow to obtain distances to SNe Ia at z $>$ 0.015 and derive H$_{0}$. Our results, taking a single step between the low z domain and the Hubble flow, validate the three rung classical method. We find, however, that the full compilation of distances, both in Pantheon+ and in the Carnegie-Chicago Hubble Program (CCHP), contain some inaccurate values in the colors due to an underestimate of reddening by dust. This produces odd individual values for H$_{0}$ from single SNe Ia. On the average, those erroneous estimates do not affect the mean value of H$_{0}$, which is characterized by the bulk of well--modeled SNe Ia. Our sample of carefully addressed SNe Ia in the Hubble flow contains a dozen supernovae, for which the distances are determined with high accuracy. Three of these SNe Ia are of the Broad Line subtype and can be compared with SN 1989B in M66, a host galaxy with a unique convergence of the Cepheid distance determination and the Tip of the Red Giant Branch stars (TRGB) determination by the CCHP group. They point to a weighted average of H$_{0}$ $=$ 73.556 $\\pm$ 2.084 (stat) km s$^{-1}$ Mpc $^{-1}$. There is as well a very good agreement on the distances to NGC 7250 and NGC 5643 between those derived with Cepheids by SH0ES and those derived with the use of J-Asymptotic Giant Branch stars (JAGB stars) by the CCHP, which makes them very good anchors. The sample of 12 SNe Ia gives a value of H$_{0}$ $=$ 72.833 $\\pm$ 1.306(stat) $\\pm$ 1.151 (sys) km s$^{-1}$ Mpc$^{-1}$, when anchored in Cepheids, and of H$_{0}$ $=$ 72.388 $\\pm$ 1.272 (stat) $\\pm$ 1.015 (sys) km s$^{-1}$ Mpc$^{-1}$, when anchored in JAGBs by the CCHP. We take a mean of the two values of H$_{0}$ and obtain H$_{0}$ $=$ 72.610 $\\pm$ 1.289(stat) $\\pm$ 1.085 (sys) km s$^{-1}$ Mpc$^{-1}$.",
    "authors": [
      "Pilar Ruiz-Lapuente",
      "Antonio Quintana-Estellés",
      "Jonay I. González Hernández",
      "Andrea Pastorello"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02440",
    "title": "Evolution and Mass Dependence of UV-to-near-IR Color Gradients up to z=2.5 from HST+JWST",
    "abstract": "We present the redshift evolution of radial color gradients (in rest-frame ${\\textit{U}} - {\\textit{V}}$ and ${\\textit{V}} - {\\textit{J}}$) for galaxies in the range $0.5<$ z $<2.5$ and investigate their origin and dependence on stellar mass. We select $\\sim 10,200$ galaxies with stellar masses $M_\\star>10^{9.5}~{\\text{M}}_\\odot$ from publicly available JWST/NIRCam-selected catalogs. Using 2D Sérsic profile fits to account for PSF broadening, we perform spatially resolved SED fitting on HST and JWST/NIRCam photometry retrieving accurate rest-frame ${\\textit{U}} - {\\textit{V}}$ and ${\\textit{V}} - {\\textit{J}}$ color gradients within 2$R_\\text{e, F444W}$. Star-forming galaxies generally exhibit negative ${\\textit{V}} - {\\textit{J}}$ color gradients that are strongly mass and redshift dependent. For massive star-forming galaxies ($M_\\star>10^{10.5}~{\\text{M}}_\\odot$) at $z>1.5$ ${\\textit{V}} - {\\textit{J}}$ colors are $\\approx 0.5$ mag redder within the effective radius than outside, on average. We find that, at all redshifts and across the entire stellar mass range, ${\\textit{V}} - {\\textit{J}}$ gradients strongly correlate with global attenuation ($A_V$), suggesting that they predominantly trace dust attenuation gradients. Edge-on galaxies are redder and have stronger gradients at all $z$, although the correlation weakens at higher $z$. The ${\\textit{U}} - {\\textit{V}}$ and ${\\textit{V}} - {\\textit{J}}$ color gradients in the quiescent galaxy population, in contrast, are weakly negative (from $\\approx -0.1$ to $\\approx- 0.2$ mag), though significant, and show little or no dependence on stellar mass, redshift or axis ratio. The implication is that quiescent galaxies must be largely transparent, with low $A_V$, and color gradients mostly attributable to stellar population gradients.",
    "authors": [
      "Marco Martorano",
      "Arjen van der Wel",
      "Andrea Gebek",
      "Maarten Baes",
      "Eric F. Bell",
      "Gabriel Brammer",
      "Sharon E. Meidt",
      "Angelos Nersesian",
      "Katherine Whitaker",
      "Stijn Wuyts"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:1811.11125",
    "title": "Constraining ultra light fermionic dark matter with Milky-Way observations",
    "abstract": "The equation of state for a degenerate gas of fermions at zero temperature in the non-relativistic case is a polytrope, i.e. $p \\sim\\rho^{5/3}/m_F^{8/3}$. If dark matter is modeled by such a non-interacting fermion, this dependence in the mass of the fermion $m_F$ explains why if dark matter is very heavy the effective pressure of dark matter is negligible. Nevertheless, if the mass of the dark matter is very small, the effective pressure can be very large, and thus a system of self-gravitating fermions can be formed. In this work we model the dark matter halo of the Milky-Way by solving the Tolman-Oppenheimer-Volkoff equations, with the equation of state for a partially degenerate ultralight non-interacting fermion. We found that to fit the rotational velocity curve of the Milky-Way, the mass of the fermion should be in the range $31.5 ~\\mbox{eV} < m_F < 35~$eV at $90\\%$ C.L. Moreover, the central density is restricted to be in the range of $1.2 < \\rho_0<1.7$ GeV/cm$^3$ at $90\\%$ C.L. The fermionic dark matter halo has a very different profile as compared with the standard Navarro-Frenk-White profile, thus, the possible indirect signals for annihilating dark matter may change by orders of magnitude. We found bounds for the annihilation cross section in this case by using the Saggitarius A* spectral energy distribution.",
    "authors": [
      "J. Barranco",
      "A. Bernal",
      "D. Delepine"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2406.01705",
    "title": "Dark Matter",
    "abstract": "We review observational, experimental and theoretical results related to Dark Matter.",
    "authors": [
      "Marco Cirelli",
      "Alessandro Strumia",
      "Jure Zupan"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.01675",
    "title": "Hawking Radiation of Nonrelativistic Scalars: Applications to Pion and Axion Production",
    "abstract": "In studying secondary gamma-ray emissions from Primordial Black Holes (PBHs), the production of scalar particles like pions and axion-like particles (ALPs) via Hawking radiation is crucial. While previous analyses assumed relativistic production, asteroid-mass PBHs, relevant to upcoming experiments like AMEGO-X, likely produce pions and ALPs non-relativistically when their masses exceed 10 MeV. To account for mass dependence in Hawking radiation, we revisit the greybody factors for massive scalars from Schwarzschild black holes, revealing significant mass corrections to particle production rates compared to the projected AMEGO-X sensitivity. We highlight the importance of considering non-relativistic $\\pi^0$ production in interpreting PBH gamma-ray signals, essential for determining PBH properties. Additionally, we comment on the potential suppression of pion production due to form factor effects when producing extended objects via Hawking radiation. We also provide an example code for calculating the Hawking radiation spectrum of massive scalar particles.",
    "authors": [
      "Hao-Ran Cui",
      "Yuhsin Tsai",
      "Tao Xu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.19761",
    "title": "Applicability of multi-component study on Bayesian searches for targeted anisotropic stochastic gravitational-wave background",
    "abstract": "Stochastic background gravitational waves have not yet been detected by ground-based laser interferometric detectors, but recent improvements in detector sensitivity have raised considerable expectations for their eventual detection. Previous studies have introduced methods for exploring anisotropic background gravitational waves using Bayesian statistics. These studies represent a groundbreaking approach by offering physically motivated anisotropy mapping that is distinct from the Singular Value Decomposition regularization of the Fisher Information Matrix. However, they are limited by the use of a single model, which can introduce potential bias when dealing with complex data that may consist of a mixture of multiple models. Here, we demonstrate the bias introduced by a single-component model approach in the parametric interpretation of anisotropic stochastic gravitational-wave backgrounds, and we confirm that using multiple-component models can mitigate this bias.",
    "authors": [
      "Soichiro Kuwahara",
      "Leo Tsukada"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.09050",
    "title": "Late-time acceleration and structure formation in interacting $α$-attractor dark energy models",
    "abstract": "We investigate the cosmological dynamics of interacting dark energy within the framework of $\\alpha$-attractor models. Specifically, we analyze the associated autonomous system, focusing on its fixed points that represent dark energy and scaling solutions, along with their stability conditions. We employ center manifold theory to address cases where some fixed points display eigenvalues with zero and negative real parts. The model reveals attractors describing dark energy, enabling a smooth transition from the radiation-dominated era to the matter-dominated era, and ultimately into the dark-energy-dominated phase. Additionally, we identify a scaling matter solution capable of modifying the growth rate of matter perturbations during the matter-dominated epoch. Consequently, we study the evolution of matter perturbations by obtaining both analytical and numerical solutions to the density contrast evolution equation. Based on these results, we compute numerical solutions for the weighted growth rate $f\\sigma_{8}$, indicating that interacting $\\alpha$-attractor dark energy models may provide a better fit to structure formation data than the standard $\\Lambda$CDM scenario.",
    "authors": [
      "L. K. Duchaniya",
      "B. Mishra",
      "G. Otalora",
      "M. Gonzalez-Espinoza"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.20071",
    "title": "WIMP/FIMP dark matter and primordial black holes with memory burden effect",
    "abstract": "The lifetime of primordial black holes (PBHs), which formed in the early universe, can be extended by the memory burden effect. Light PBHs may exist today and be candidates for dark matter (DM). We assume that DM is made of thermally produced weakly interacting massive particles (WIMPs), WIMPs produced via the Hawking radiation of PBHs, and PBHs that survived Hawking evaporation via the memory burden effect. Feebly interacting massive particles (FIMPs) are alternatives to WIMPs. This paper shows that a small memory burden is preferable if the thermal production of WIMPs or FIMPs is much larger than the effect of PBH particle production via Hawking radiation. In addition, we show that the lower limit of the DM mass, called the warm DM (WDM) constraint, decreases with the memory burden effect of PBHs. Results suggest that the WDM constraint is more effective for FIMPs than for WIMPs.",
    "authors": [
      "Teruyuki Kitabayashi",
      "Amane Takeshita"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22356",
    "title": "Net Charge Accretion in Magnetized Kerr Black Holes",
    "abstract": "We investigate the charging process of a rotating Kerr black hole of mass $M$ and angular momentum $J$ immersed in a stationary, axisymmetric, asymptotically uniform magnetic field of strength $B_{0}$. In Wald's classic analysis (Wald 1974), which was based on the assumption of vanishing injection energy, the black hole was predicted to acquire a universal \"saturation charge\" $Q_{\\mathrm{w}}=2B_{0}J$. However, the physical mechanism that sets the saturation charge must ultimately be governed by the competition between the absorption rates of positively and negatively charged particles. Motivated by this observation, we revisit the problem in the framework of a simple accretion model, where two dilute, equivalent fluxes of charged particles of opposite signs are injected from infinity along the magnetic field lines. The problem then reduces to that of individual particle motion in the electromagnetic field of the magnetized Kerr black hole. Using a combination of numerical and analytical tools, we determine the domains of absorption and establish both lower and upper bounds on the corresponding absorption cross sections. At $Q=Q_\\mathrm{w}$ these bounds reveal a systematic difference between the two charge signs. In particular, for sufficiently strong magnetic fields, the lower bound on the absorption cross section for the \"attracted\" charge exceeds the upper bound for the \"repelled\" one. This charge accretion imbalance (which we find to become extreme at the limit of large $B_{0}$) indicates a persistent net charge accretion at $Q=Q_{\\mathrm{w}}$, implying that the actual saturation charge must differ from Wald's charge $Q_{\\mathrm{w}}$.",
    "authors": [
      "Ethan Berreby",
      "Avner Okun",
      "Shahar Hadar",
      "Amos Ori"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00102",
    "title": "Letelier black hole immersed in an electromagnetic universe",
    "abstract": "We investigate a static, spherically symmetric black hole solution surrounded by a cloud of strings and immersed in an electromagnetic universe. By deriving the event horizon from the lapse function, we demonstrate that both the string cloud parameter and the electromagnetic background parameter significantly modify the horizon radius compared to the Schwarzschild case. Consequently, thermodynamic quantities-including the Hawking temperature, Bekenstein-Hawking entropy, and heat capacity-become explicit functions of these additional parameters, with the heat capacity exhibiting divergences that signal phase transitions. We analyze the motion of massive test particles in this spacetime, deriving the effective potential and calculating the innermost stable circular orbit radius, which governs the inner edge of accretion disks and influences orbital stability. Scalar perturbations are examined through the associated effective potential, and quasinormal mode frequencies are computed using the sixth-order WKB approximation; the negative imaginary parts confirm the stability of the black hole under such perturbations. We also study the photon sphere structure, black hole shadow radius, and photon trajectories, showing how the interplay between string clouds and the electromagnetic background shapes the optical properties of this spacetime. Finally, we investigate weak gravitational lensing phenomena by deriving the deflection angle for both massive particles and photons using the Gauss-Bonnet theorem applied to the optical geometry. The results exhibit notable deviations from the Schwarzschild geometry, with the string cloud enhancing the deflection through a $(1-\\alpha)^{-1}$ factor while the electromagnetic parameter introduces competing corrections at second order.",
    "authors": [
      "Ahmad Al-Badawi",
      "Faizuddin Ahmed",
      "İzzet Sakallı"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03075",
    "title": "Kappa Entropy and its Thermodynamic Connection",
    "abstract": "Adopting a bottom-up perspective, we propose a novel two-parametric nonadditive entropy, $S_{\\kappa\\ell}$, associated with a Kappa-type power-law velocity distribution, $F_{\\kappa\\ell}(v)$, recently derived in the literature. By formulating an extended Neo-Boltzmannian microstate counting procedure and employing standard averaging techniques, we demonstrate that the fundamental laws of thermodynamics are preserved within this generalized power-law framework only whether $\\ell=-5/2$, regardless of the values assumed by the $\\kappa$-parameter.",
    "authors": [
      "J.A.S. Lima",
      "M. H. Benetti"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03108",
    "title": "Nonanalytic Fermi-liquid correction to the specific heat of RuO$_2$",
    "abstract": "The magnetic nature of the altermagnet candidate RuO$_2$ remains under debate. It has been recently shown from quantum oscillations and angle-resolved photoemission spectroscopy (ARPES) that the high-quality RuO$_2$ bulk single crystal is a paramagnetic metal. However, the low-temperature specific heat exhibits a clear deviation from the conventional $C(T)$=$\\gamma T$ + $\\beta T^3$ dependence; it is well described with nonanalytic Fermi-liquid correction for a clean paramagnetic metal: $C(T)$ = $\\gamma T$ + $\\beta T^3$ + $\\delta T^3 \\textrm{ln}(T/T^*)$. Correspondingly, the magnetic susceptibility is well fitted with the inclusion of $T^2\\textrm{ln}T$ term as well as $H^2\\mathrm{ln}H$ term. In contrast to the spin fluctuation mechanism applicable to some heavy-electron compounds with positive $\\delta$, RuO$_2$ shows negative $\\delta$ suggesting a different origin. The observation of such nonanalytic Fermi liquid corrections is attributable to the availability of an ultra-clean sample. The electronic specific heat, the magnetic susceptibility, and the $T^2$ coefficient in resistivity point to a weakly-correlated 3D Fermi-liquid state with a modest electron correlation, as supported by the Wilson and Kadowaki-Woods ratios.",
    "authors": [
      "Shubhankar Paul",
      "Atsutoshi Ikeda",
      "Hisakazu Matsuki",
      "Giordano Mattoni",
      "Jörg Schmalian",
      "Chanchal Sow",
      "Shingo Yonezawa",
      "Yoshiteru Maeno"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03137",
    "title": "Strain Response as a Probe of Spinons in Quantum Spin Liquids",
    "abstract": "Quantum spin liquids (QSLs) host emergent, fractionalized fermionic excitations that are charge-neutral. Identifying clear experimental signatures of these excitations remains a central challenge in the field of strongly correlated systems, as they do not couple to conventional electromagnetic probes. Here, we propose lattice strain as a powerful and tunable probe: Mechanical deformation of the lattice generates large pseudomagnetic fields, inducing pseudo-Landau levels that serve as distinctive spectroscopic signatures of these excitations. Using the Kitaev model on the honeycomb lattice, we show that distinct QSL phases exhibit strikingly different strain responses. The semimetallic Kitaev spin liquid and the gapped chiral spin liquid display pronounced Landau quantization and a diamagnetic-like response to strain, whereas the Majorana metal phase shows a paramagnetic-like response without forming Landau levels. These contrasting behaviors provide a direct route to experimentally identifying and distinguishing QSL phases hosting fractionalized excitations. We further outline how local resonant ultrasound spectroscopy can detect the strain-induced resonances associated with these responses, offering a practical pathway towards identifying fractionalized excitations in candidate materials.",
    "authors": [
      "Penghao Zhu",
      "Archisman Panigrahi",
      "Leonid Levitov",
      "Nandini Trivedi"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03147",
    "title": "$α$-RuCl$_3$ intercalated into graphite: a new three-dimensional platform for exotic quantum phases",
    "abstract": "Multilayer graphene with different stacking sequences has emerged as a powerful setting for correlated and topological phases. In parallel, progress in graphene heterostructures with magnetic or correlated materials-most notably the Kitaev candidate $\\alpha$-RuCl$_3$-has demonstrated charge transfer, magnetic proximity effects, and interfacial reconstruction, creating new opportunities for engineered quantum systems. Motivated by these developments, we explore a three-dimensional analogue in which $\\alpha$-RuCl$_3$ layers are inserted directly into the van der Waals gaps of graphite, forming an intercalated system. Here, we report the successful synthesis and comprehensive characterization of graphite intercalated with $\\alpha$-RuCl$_3$. Using a combination of X-ray diffraction, quantum oscillation measurements, and first-principles electronic structure calculations, we study the structural and electronic properties of these intercalated crystals. Our results demonstrate that graphite intercalated with $\\alpha$-RuCl$_3$ offers a robust route to develop three-dimensional materials with access to novel correlated and topological states.",
    "authors": [
      "Aleksandar Razpopov",
      "Shirin Mozaffari",
      "Takahiro Matsuoka",
      "Matthew Cothrine",
      "Nan Huang",
      "Roser Valentí",
      "David Mandrus"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03148",
    "title": "Proof that Momentum Mixing Hatsugai Kohmoto equals the Twisted Hubbard Model",
    "abstract": "We prove formally that the momentum-mixing Hatsugai-Kohmoto model (MMHK) is the Hubbard model with a twist. With this result in tow, we rely on the proof of Watanabe's that two models which differ by a twist must have the same bulk physics. Consequently, we have proven that MMHK=Hubbard in the charge sector.",
    "authors": [
      "Yuting Bai",
      "Philip W. Phillips"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03174",
    "title": "Interfacial Thermal Conductance Between a Polyethylene Glycol Polymer Chain and Water: A Molecular Dynamics Study",
    "abstract": "Understanding interfacial heat transfer between polymers and water is crucial for the design of biomaterials, drug delivery platforms, and nanofluidic systems. In this study, we employed all atom molecular dynamics (MD) simulations to quantify the interfacial thermal conductance between a polyethylene glycol (PEG) 36mer chain and explicit water over the temperature range of 280-350 K. To compare the conformational behavior of the PEG chain, we examined its radius of gyration and observed a temperature dependent chain collapse consistent with previous coarse grained models. By employing a transient non equilibrium MD approach, we imposed temperature difference across the interface and analyzed the energy relaxation behavior to compute heat transfer across the polymer water interfaces. Our results demonstrate that both temperature and interfacial interaction strength influence interfacial thermal conductance, with temperature playing the dominant role. Structural factors such as chain conformation and interfacial area were found to mediate the effect of interfacial interaction. Additional analysis of the vibrational density of states (VDOS) and the mean square displacement (MSD) reveal that vibrational coupling has minimal impact on thermal conductance across interfaces, whereas increased water thermal motion enhances energy transfer. These findings highlight the structural and dynamical origins of interfacial thermal conductance and provide atomistic insights into the tuning of interfacial heat transport in molecular systems through temperature and solvent interactions.",
    "authors": [
      "Shadi Babaei",
      "Yekta Cheraghali",
      "Claire Loison",
      "Ali Rajabpour",
      "Samy Merabia"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03179",
    "title": "Dipole Moments using Dirac-Coulomb-Breit Molecular Mean-Field Coupled Cluster Theory",
    "abstract": "Materials utilized by novel energy systems are often studied using weakly correlated mean-field theories. However, if these systems incorporate heavy elements or strongly correlated topological materials, relativistic effects must be included. Therefore, we present an unrestricted coupled-cluster with single and double excitation formalism (CCSD) within a molecular mean-field exact-two component framework (X2Cmmf) using a restricted Dirac-Hartree-Fock (DHF) reference state. Our mean-field transformation utilizes the one-electron, Dirac-Coulomb, Dirac-Coulomb-Gaunt and Dirac-Coulomb-Breit Hamiltonian. The code was bench-marked against DIRAC which also uses DHF-X2Cmmf accounting for the Dirac-Coulomb and Dirac-Coulomb-Gaunt Hamiltonian. The dipole moments of Li-H, and Cl-F were calculated using an approximate molecular to atomic basis transformation and compared to experiment. The CCSD energy showed agreement with DIRAC to around ten to the power of minus four Hartree and exhibited a small variation of the dipole moment with the introduction of higher order electron-electron interactions. This paper allows for study of relativistic processes within this mean-field approach and lays the foundation for future theoretical development of relativistic Coupled-Cluster Theory using a DHF reference state within this framework.",
    "authors": [
      "Luca Murg",
      "Christopher Lane",
      "Roxanne M. Tutchton"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03190",
    "title": "Computer Simulation of the Growth of a Metal-Organic Framework Proto-crystal at Constant Chemical Potential",
    "abstract": "Designing metal-organic frameworks (MOFs) synthesis protocols is currently largely driven by trial-and-error, since we lack fundamental understanding of the molecular level mechanisms that underlie their self-assembly processes. Previous works have studied the nucleation of MOFs, but their growth has never been studied by means of computer simulations, which provide molecular level detail. In this work, we combine constant chemical potential simulations with a particle insertion method to model the growth of the ZIF-8 MOF at varying synthesis temperatures and concentrations of the reactants. Non-classical growth mechanisms triggered by oligomer attachments were detected, with a higher predominance in the most concentrated setups. The newly formed layers preserve the pore-like density profile of the seed crystal but contain defective sites characterized by the presence of 3, 5 and 7 membered rings, typical of amorphous phases. Compared to the amorphous intermediate species obtained at the nucleation part of the self-assembly process previously investigated in our group [Chem. Mater., doi: https://doi.org/10.1021/acs.chemmater.5c02028 , 2025], larger-sized rings are more common in the grown layer. Moreover, these are favored by increasing reactant concentration and temperature, as is the degree of deviation with respect to the original crystal structure. We computed growth rates for the steady-state regime, and the non-linear tendency with respect to concentration leads us to hypothesize that in these conditions the growth is controlled by the adsorption rather than by the diffusion processes.",
    "authors": [
      "Sahar Andarzi Gargari",
      "Emilio Méndez",
      "Rocio Semino"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03198",
    "title": "Excitonic Theory of the Ultrafast Optical Response of 2D-Quantum-Confined Semiconductors at Elevated Densities",
    "abstract": "An excitonic approach to the ultrafast optical response of confined semiconductors at elevated densities below the Mott transition is presented. The theory is valid from the coherent regime, where coherent excitonic transitions and biexcitons dominate, to the incoherent regime, where excitonic occupations dominate. Numerical simulations of the $1s$ exciton dynamics during intense circularly polarized pump pulses in two different Coulomb-interaction regimes are performed for two-dimensional semiconductors: Moderate Coulomb interaction is compared with dominating Coulomb interaction with respect to the light-matter interaction strength. The different many-body contributions are disentangled and it is found, that excitonic Rabi oscillations in the Coulomb-dominated regime are considerably less strong. By also comparing circular and linear excitation in a MoSe$_2$ monolayer, it is found, that linear excitation creates a regime, where excitonic Rabi oscillations are almost completely suppressed.",
    "authors": [
      "Henry Mittenzwey",
      "Oliver Voigt",
      "Andreas Knorr"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03203",
    "title": "Digital-Alloy-Based Bragg Mirrors in High-Q Microcavities for Polariton Lasing",
    "abstract": "We present an approach to the molecular-beam epitaxy of high-Q planar GaAs-based microcavities in which the AlGaAs high-index layers of the distributed Bragg reflectors (DBRs) are replaced by short-period GaAs/AlAs superlattices (digital alloys) with similar optical properties. This design enables a significant reduction of interface roughness, precise control of the quarter-wavelength optical thickness and the effective Al content, suppression of the propagation of structural defects, and efficient tuning of intrinsic absorption at the polariton emission wavelength via optimization of the superlattice parameters. Using this approach, we fabricate a microcavity with a low polariton-lasing threshold of approximately 200 W/cm$^2$ and a high experimental quality factor of about 5.4 x $10^4$. This value exceeds by almost a factor of two the theoretical estimate obtained within an equivalent ternary-alloy model. We demonstrate that accurate modeling of the stop-band characteristics and the Q factor requires incorporating the modified electronic density of states in the superlattice, including quantum-confinement and excitonic effects.",
    "authors": [
      "V. A. Stolyarov",
      "A. S. Kurdyubov",
      "A. V. Trifonov",
      "M. Yu. Petrov",
      "I. V. Ignatiev",
      "V. A. Lovtcius",
      "S. A. Eliseev",
      "Yu. P. Efimov",
      "M. S. Lozhkin",
      "A. V. Kavokin"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03218",
    "title": "Tunable Thin Elasto-Drops",
    "abstract": "We present an experimental method to fabricate centimetric thin elastic capsules with highly uniform thickness and negligible bending stiffness using silicone elastomers. In our experiments, the capsules thickness is tunable at fabrication, while internal pressure and hoop (circumferential) stress are adjustable via hydrostatic inflation once the capsules are filled and immersed in water. Capsules mechanics are probed through hydro-elastic waves generated by weak mechanical perturbations at the capsule interface. By analyzing the surface wave dynamics in the Fourier domain, we extract the in-plane stress and demonstrate that the hydro-elastic waves are exclusively governed by hoop stress. This establishes a direct analogy with liquid drops characterised by an effective surface tension, allowing the capsules to be modeled as large-scale \"elasto-drops\" with an inflation and thickness tunable effective surface tension. Our work demonstrates that elasto-drops serve as a robust model system for parametric studies of large-scale liquid drops with experimentally adjustable surface tension.",
    "authors": [
      "Antonin Eddi",
      "Stéphane Perrard",
      "Jishen Zhang"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03252",
    "title": "Yielding in dense active matter",
    "abstract": "High-density granular active matter is a useful model for dense animal collectives and could be useful for designing reconfigurable materials that can flow or solidify on command. Recent work has demonstrated key similarities and differences between the mechanical response of dense active matter and its sheared passive counterpart, yet a constitutive law that predicts precisely how dense active matter flows or fails remains elusive. Here we study the yielding transition in dense active matter in the limit of slow driving and large persistence times, across a wide range of material preparations. Under shear, materials prepared to be very low energy or ultrastable are brittle, and well-described by elastoplastic constitutive laws. We show that under random active forcing, however, ultrastable materials are always ductile. We develop a modified elastoplastic model that captures and explains these observations, where the key parameter is the correlation length of the input active driving field. We also observe large parameter regimes where the plastic flow is surprisingly well-predicted by the input active driving field and not highly dependent on the structural disorder, suggesting new strategies for control.",
    "authors": [
      "Adil Ghaznavi",
      "Saverio Rossi",
      "Francesco Zamponi",
      "M. Lisa Manning"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03261",
    "title": "Analytical approach to the magneto-fluorescence of triplet excitons",
    "abstract": "The fluorescence of triplet excitons and color-centers is strongly dependent on magnetic field that mixes the zero field spin eigenstates that determine the radiative recombination rates back into the singlet ground state through spin-orbit coupling. For films of molecules, and polycristaline color-centers samples an average over molecular orientations has to be performed to model the magneto-fluorescence lineshapes. This limits our analytical understanding of the lineshapes and complicates the analysis of the fluorescence dependence on magnetic field. Here, we present a framework that allows to average over triplet molecular orientations analytically. Our approach achieves provides very accurate numerical routines computing precisely the averages matrix elements that appear in magneto-fluorescence and semi-analytical approximations that can be used to model experimental traces.",
    "authors": [
      "Yan Sun",
      "A.D. Chepelianskii"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03270",
    "title": "Curvature Potential Formulation for Thin Elastic Sheets",
    "abstract": "Thin elastic sheets appear in systems ranging from graphene to biological membranes, where phenomena such as wrinkling, folding, and thermal fluctuations originate from geometric nonlinearities. These effects are treated within weakly nonlinear theories, such as the Foppl-von Karman equations, which require small slopes and fail when deflections become large even if strains remain small. We introduce a methodological progress via a geometric reformulation of thin-sheet elasticity based on a stress potential and a curvature potential. This formulation preserves the structure of the classical equations while extending their validity to nonlinear, multivalued configurations, and geometrically frustrated states. The framework provides a unified description of thin-sheet mechanics in regimes inaccessible to existing theories and opens new possibilities for the study of elastic membranes and two-dimensional materials.",
    "authors": [
      "Yael Cohen",
      "Animesh Pandey",
      "Yafei Zhang",
      "Cy Maor",
      "Michael Moshe"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03283",
    "title": "Symmetry-Protected Bipolar Skin Effect and its Topological Breakdown in Disordered Non-Hermitian Systems",
    "abstract": "The interplay between non-Hermitian topology and disorder remains a central puzzle in open quantum systems. While the non-Hermitian skin effect (NHSE) is known to be robust against weak perturbations, its fate under strong disorder, particularly in the presence of spin-orbit coupling (SOC), is not fully understood. Here, we uncover a Z_2 topological bipolar skin effect in a non-Hermitian Rashba chain, where spin-up and spin-down eigenstates localize at opposite boundaries. By strictly computing the Lyapunov exponents and introducing a biorthogonal spin-separation index, we map the global phase diagram and reveal a hierarchical breakdown of topology. We demonstrate that the Z_2 skin effect is protected against moderate disorder but collapses into a trivial skin phase before the ultimate onset of Anderson localization. Our results establish a distinct regime of disorder-robust topological non-reciprocity, distinguishable from both the trivial bulk limit and the Anderson localized phase.",
    "authors": [
      "Ali Tozar"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03295",
    "title": "Novel phases in the Fe-Si-O system at terapascal pressures",
    "abstract": "The Fe-Si-O ternary system, central to modeling the interiors of terrestrial planets, remains poorly constrained at Terapascal (TPa) pressures characteristic of super-Earth mantles. Using a combination of crystal-structure prediction and ab initio calculations, we identify three ternary compounds stable near 1 TPa: P3 FeSiO4, P3 Fe4Si5O18, and P-3 FeSi2O6. The first two phases are thermodynamically stable at low temperatures, whereas P-3 FeSi2O6 becomes favored above approximately 2000 K. All three are metallic, paramagnetic, and adopt pseudo-binary arrangements derived from the FeO2 and SiO2 end-member structures. Their crystal structures emerge through substitutions of Fe for Si in Fe2P-type SiO2 or of Si for Fe in Pnma-type FeO2, the stable elemental oxides at ~1 TPa. This structural continuity suggests that Fe preferentially substitutes for Si in the canonical Mg-silicates expected at TPa pressures. Notably, these new pseudo-binaries accommodate Fe in six- and nine-fold coordination, in contrast to the eight-fold cubic coordination found in FeO at similar pressures. The thermodynamic conditions under which these phases form from FeO2 and SiO2 mixtures are clarified through quasi-harmonic free energy calculations. Their prevalence in super-Earth's mantles is found to depend on the abundance of FeO2, which may be generated by the dehydrogenation of FeOOH goethite as in the Earth's deep mantle. The existence of these phases implies a markedly different pattern of Fe incorporation in high-pressure Mg-silicates at TPa pressures, compared with the behavior inferred at the GPa pressures of the Earth's mantle.",
    "authors": [
      "Nan Huang",
      "Renata M. Wentzcovitch",
      "Zepeng Wu",
      "Feng Zheng",
      "Bingxin Wu",
      "Yang Sun",
      "Shunqing Wu"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03306",
    "title": "A Space-Charge-Limited van der Waals Spin Transistor",
    "abstract": "Integrating semiconducting and magnetic materials could combine transistor-like operation with nonvolatility and enable architectures such as logic-in-memory. Here, we employ correlated electrical transport and scanning nitrogen-vacancy (NV) center magnetic imaging to elucidate a spin transistor concept that amalgamates both vertical and lateral transport in a 2D antiferromagnetic semiconductor, distinct from purely vertical tunneling devices. Our device, based on a monolayer-bilayer junction in CrSBr, displays giant, gate-tunable magnetoresistance driven by the dual action of electrostatic doping on space-charge-limited lateral conduction and interlayer exchange coupling. Moreover, we visualize a field-trainable, layer-sharing effect that selects between coherent or domain-wall reversal at the spin-flip transition, enabling multilevel, memristive conductance states. These findings open opportunities for 2D magnetic semiconductors to address limitations in contemporary computing.",
    "authors": [
      "Thomas K. M. Graham",
      "Yu-Xuan Wang",
      "Niranjana Renjith Nair",
      "Kseniia Mosina",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Zdenek Sofer",
      "Brian B. Zhou"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03316",
    "title": "Symmetry Breaking of Current Response in Disordered Exclusion Processes",
    "abstract": "The bias-reversal symmetry -- where reversing an external bias inverts the current without changing its magnitude -- is a hallmark of nonequilibrium transport. While this property holds in homogeneous systems such as the asymmetric simple exclusion process, how disorder and its interplay with particle interactions affect this symmetry has remained unclear. Here, we establish a general criterion showing that the bias-reversal symmetry holds if and only if the local left-right bond-bias ratio is spatially uniform. Analytical and numerical analyses reveal that bond disorder preserves the symmetry beyond linear response, whereas site disorder breaks it through an interplay between heterogeneity and particle interactions. Our results demonstrate how environmental disorder and interparticle interactions cooperate to generate asymmetric transport, thereby providing a unified theoretical framework relevant to transport through biological and artificial nanochannels.",
    "authors": [
      "Issei Sakai",
      "Takuma Akimoto"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03355",
    "title": "Anomalous Hall effect in an amorphous antiferromagnet with inverted hysteresis",
    "abstract": "Stemming from antiferromagnetic coupling, exchange bias allows inverted hysteresis in a magnetic system. Such room temperature magnetic reversal has yet to be observed in an amorphous antiferromagnet. Furthermore, the impact of this exchange bias effect on its magnetoelectric transport behavior remains a mystery. Here we discovered a zero-field magnetization switching effect in an exchange-biased amorphous antiferromagnet with inverted magnetic hysteresis. This zero-field magnetic reversal was further evidenced by its inverted large anomalous Hall effect. Notably, this collective spin flipping at zero field can occur at room temperature or above room temperature, which may be associated with quantum interference effect due to thermal fluctuation enhanced disorder. Our experimental results offer a way to design room-temperature exchange-biased amorphous antiferromagnets with zero-field multi magnetic-states and large anomalous Hall effect, holding potential for low-power and high-density memory applications.",
    "authors": [
      "Xiangning Du",
      "Yuxiang Zhu",
      "Na Chen"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03365",
    "title": "Generative Refinement:A New Paradigm for Determining Single Crystal Structures Directly from HKL Data",
    "abstract": "Single-crystal X-ray diffraction (SC-XRD) is the gold standard technique to characterize crystal structures in solid state. Despite significant advances in automation for structure solution, the refinement stage still depends heavily on expert intervention and subjective judgment, limiting accessibility and scalability. Herein, we introduce RefrActor, an end-to-end deep learning framework that enables crystal structure determination directly from HKL data. By coupling a physics-informed reciprocal-space encoder (ReciEncoder) with a symmetry-aware diffusion-based generator (StruDiffuser), RefrActor produces fully refined atomic models without requiring initial structural guesses or manual input. Comprehensive evaluations on the GenRef-10k benchmark demonstrates that RefrActor achieves low R1-factors across diverse systems, including low-symmetry, light-atom, and heavy-atom crystals. Case studies further confirm that RefrActor can correctly resolve hydrogen positions, elemental assignments, and moderate disorder. This work establishes a new data-driven paradigm for autonomous crystallographic analysis, offering a foundation for fully automated, high-throughput crystal structure determination.",
    "authors": [
      "Wen-Lin Luo",
      "Yi Yuan",
      "Cheng-Hui Li",
      "Yue Zhao",
      "Jing-Lin Zuo"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03368",
    "title": "Short-Range Modulated Electron Lattice and d-Wave Superconductivity in Cuprates: A Phenomenological Ginzburg-Landau Framework",
    "abstract": "We develop a phenomenological Ginzburg-Landau (GL) framework for high-$T_c$ cuprates in which a short-range modulation of the electronic charge density couples to a $d$-wave superconducting condensate. The resulting modulated electron lattice (MEL) state is distinct from long-range static charge density wave order: it is short range, partially phase coherent, and linked to superconducting coherence. A preferred wave vector $q^{\\ast} \\approx 0.3$ reciprocal lattice units along the Cu-O bond direction emerges from the interplay between a momentum-dependent susceptibility and bond-stretching phonons, consistent with neutron and x-ray data on YBa$_2$Cu$_3$O$_{7-\\delta}$ and related cuprates. The GL free energy contains coupled $d$-wave superconducting and charge sectors with parameters constrained by optimally doped YBa$_2$Cu$_3$O$_{7-\\delta}$. We identify an MEL enhancement window in doping, temperature, MEL correlation length, and disorder where a coherence linked modulation enhances the superfluid stiffness. Classical Monte Carlo simulations yield an in-plane stiffness enhancement of order ten percent, which we treat as a qualitative prediction to be tested by self-consistent Bogoliubov de Gennes calculations. The MEL framework yields falsifiable experimental signatures. For scanning tunneling spectroscopy in Bi-based cuprates we highlight two predictions: the Fourier-transformed local density of states should exhibit a $q^{\\ast} \\approx 0.3$ peak whose spectral weight sharpens as superconducting phase coherence develops below $T_c$, in contrast to static charge scenarios, and the local gap magnitude $\\Delta(r)$ should correlate positively with the local MEL amplitude. The framework implies correlations between MEL correlation length, superfluid stiffness, disorder, and vortex pinning, and organizes cuprate observations into testable STM/STS predictions.",
    "authors": [
      "Jaehwahn Kim",
      "Davis A. Rens",
      "Waqas Khalid",
      "Hyunchul Kim"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03372",
    "title": "On the Accuracy of Atomic Resolution Electrostatic Measurements in 2D Materials",
    "abstract": "The use of differential phase contrast (DPC) in scanning transmission electron microscopy (STEM) has shown much promise for directly investigating the functional properties of a material system, leveraging the natural coupling between the electron probe and atomic-scale electric fields to map the electrostatic configuration within a sample. However, the high sensitivity of these measurements makes them particularly vulnerable to variations in both sample properties and the configuration of the instrument, stressing the need for robust methodologies to ensure more accurate analyses. In this work, the influence of key instrumental parameters - probe convergence angle, defocus and two-fold astigmatism - on atomic-resolution segmented-detector DPC-STEM measurements is evaluated through extensive image simulations. Results show that the limit of interpretability for a 21 mrad defocused probe is found at a magnitude of 4 nm, where electrostatic field magnitude can be underestimated by about 16 % in overfocus and just above 10 % in underfocus. Equivalent results for a 30 mrad probe demonstrate underestimated values around 30 % at overfocus and 20 % for underfocus, at a lower interpretability limit of 3 nm. Two-fold astigmatism introduces orientation dependent variations that surpass 40 % for magnitudes below 3 nm, but a reduction in sensitivity to the aberration is observed when oriented along detector-segment edges. Overall, the analysis confirms the sensitivity and usefulness of the scattergram-based method and underscores the importance of optimized instrumental alignment for accurate CoM based STEM imaging.",
    "authors": [
      "Rafael V. Ferreira",
      "Sebastian Calderon V.",
      "Paulo J. Ferreira"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03387",
    "title": "Tetragonal Fe2O: the stable iron oxide at Earth's core conditions",
    "abstract": "The Fe-O system is fundamental to understanding the composition and properties of the Earth's core. Recent studies have suggested the possible existence of stable, iron-rich FenO compounds at around 215 GPa. Here, we performed crystal-structure searches and fully anharmonic free-energy calculations to investigate the Fe-FeO system under inner-core conditions. We identified Fe2O as a stable phase and constructed its high P-T phase diagram. Fe2O undergoes a hexagonal-to-tetragonal transition with increasing pressure and temperature. It remains thermodynamically stable against decomposition into Fe and FeO from 200 to 400 GPa and at high temperatures. Although oxygen has been considered nearly absent in the inner core due to its limited solubility, these results suggest that oxygen can, in fact, be incorporated into the solid inner core in the form of an Fe+Fe2O mixture, and can match PREM densities for 53 mol% Fe2O. Our work has the potential to lead to a significant revision of the current understanding of the core's structure and composition.",
    "authors": [
      "Junjie Jiang",
      "Zhen Zhang",
      "Tongqi Wen",
      "Renata M. Wentzcovitch",
      "Yang Sun"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03390",
    "title": "Origin of shallow n-type doping in AlN and Al-rich AlGaN",
    "abstract": "Achieving efficient n-type doping in AlN, a representative ultrawide bandgap (UWBG) semiconductor, remains a longstanding challenge that limits its application in high-power electronics and deep-ultraviolet optoelectronics. Conventional dopants in AlN often introduce deep levels or form compensating complexes, leading to low free-carrier concentrations. In this work, we combine first-principles defect calculations with a structural search method tailored to explore metastable configurations to systematically investigate donor-type defects in AlN. Our results reveal that the aluminum interstitial ($Al_i$) can exhibit shallow-donor behavior in specific metastable configurations that were previously overlooked. This discovery expands the understanding of n-type dopability in AlN, and highlights the critical role of metastable defects in modulating electronic properties.",
    "authors": [
      "Yujie Liu",
      "Sieun Chae",
      "Emmanouil Kioupakis"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03395",
    "title": "Tensor renormalization group calculations of partition-function ratios",
    "abstract": "The behavior of dimensionless quantities defined as ratios of partition functions is analyzed to investigate phase transitions and critical phenomena. At criticality, the universal values of these ratios can be predicted from conformal field theory (CFT) through the modular-invariant partition functions on a torus. We perform numerical calculations using the bond-weighted tensor renormalization group for three two-dimensional models belonging to different universality classes: the Ising model, the three-state Potts model, and the four-state Potts model. The partition-function ratios obey the same finite-size scaling form as the Binder parameter, and their critical values agree well with the universal values predicted by CFT. In the four-state Potts model, we observe logarithmic corrections in the system-size dependence of these ratios.",
    "authors": [
      "Satoshi Morita",
      "Naoki Kawashima"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03407",
    "title": "Critical fluctuations of elastic moduli in jammed solids",
    "abstract": "We investigate sample-to-sample fluctuations of the shear modulus in ensembles of particle packings near the jamming transition. Unlike the average modulus, which exhibits distinct scaling behaviours depending on the interparticle potential, the fluctuations obey a critical exponent that is independent of the potential. Furthermore, this scaling behaviour has been confirmed in two-dimensional packings, indicating that it holds regardless of spatial dimension. Using this scaling law, we discuss the relationship predicted by heterogeneous-elasticity theory between elastic-modulus fluctuations and the Rayleigh scattering of sound waves across different pressures. Our numerical results provide a useful foundation for developing a unified theoretical description of the jamming critical phenomenon.",
    "authors": [
      "Kumpei Shiraishi",
      "Hideyuki Mizuno"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03435",
    "title": "Unconventional Magneto-Optical Effects in Altermagnets",
    "abstract": "The ideal altermagnets are a class of collinear, crystal-symmetry-enforced fully compensated magnets with nonrelativistic spin-split bands, in which contributions from Berry curvature to magneto-optical effects (MOEs) are strictly forbidden by an effective time-reversal symmetry. Here we show that, in such systems, MOEs are exclusively induced by the quantum metric and, in realistic altermagnets, are typically dominated by it. We refer to Berry-curvature-induced MOEs as conventional MOEs and to quantum-metric-dominated MOEs as unconventional MOEs. We derive general formulas that incorporate both Berry curvature and quantum metric for unconventional MOEs in altermagnets, enabling a quantitative evaluation of their respective contributions. Through symmetry analysis, we prove that ideal altermagnets are constrained to exhibit only unconventional MOEs. Using the three-dimensional canonical altermagnet MnTe and the emerging two-dimensional bilayer twisted altermagnet CrSBr as illustrative examples, we demonstrate that unconventional MOEs are prevalent in altermagnets. Our results establish altermagnets as a natural platform for quantum-metric-driven optical phenomena, substantially broadening the scope of MOEs and providing concrete predictions that can be tested in future experimental studies.",
    "authors": [
      "Yongpan Li",
      "Yichen Liu",
      "Cheng-Cheng Liu"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03436",
    "title": "Invariant fractocohesive length in thermally aged elastomers",
    "abstract": "The fractocohesive length - the ratio between fracture toughness and work-to-fracture - provides a material-specific length scale that characterizes the size-dependent fracture behavior of pristine elastomers. However, its relevance to thermally aged materials, where both toughness and work of fracture degrade dramatically, remains unexplored. Here, we demonstrate that despite severe thermal embrittlement, the fractocohesive length remains invariant throughout thermal aging, independent of temperature or duration. We verify this invariance experimentally for two elastomer systems (Styrene Butadiene Rubber and Silicone Rubber) at multiple aging temperatures for aging times up to eight weeks. This finding bridges a critical gap in fracture mechanics of aged polymers: while the evolution of work-to-fracture can be predicted from well-established constitutive models that track network changes (crosslink density and chain scission), the evolution of fracture toughness has lacked predictive frameworks. The invariance of fractocohesive length enables direct calculation of fracture toughness at any aging state from the predicted work of fracture, eliminating the need for extensive fracture testing on aged elastomers and providing a crucial missing link for computational fracture predictions in aged elastomeric components.",
    "authors": [
      "Aimane Najmeddine",
      "Santiago Marin",
      "Zhen Xu",
      "Connor Thompson",
      "Guoliang Liu",
      "Maryam Shakiba"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03478",
    "title": "Current switching behaviour mediated via hinge modes in higher order topological phase using altermagnets",
    "abstract": "We propose a theoretical framework to engineer hybrid-order and higher-order topological phases in three-dimensional topological insulators by coupling to $d$-wave altermagnets (AMs). Presence of only $d_{x^2-y^2}$-type AM drives the system into a hybrid-order topological phase where both first-order and second-order topological phases coexist. This phase is characterized by spectral analysis, low-energy surface theory, dipolar and quadrupolar winding numbers, and it's signature is further confirmed by two-terminal differential conductance calculations. Incorporation of the $d_{x^2-z^2}$-type AM drives the system into two second-order topological insulator phases hosting distinct type of hinge modes. They are also topologically characterized by spectral analysis, topological invariants, low-energy surface thoery, and transport calculations. Importantly, the localization and direction of propagation of these one-dimensional hinge modes are controllable by tuning the relative strengths of the alermagnetic exchange orders. We utilize this feature to propose a tunable current-switching behaviour mediated via the hinge modes. Our results establish AMs based hybrid structure as a versatile platform for controllable higher-order topology and hinge-mediated device applications.",
    "authors": [
      "Minakshi Subhadarshini",
      "Amartya Pal",
      "Arijit Saha"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03517",
    "title": "Layered XZnBi (X = Rb, Cs) with Pudding-Mold Bands, Complex Fermi Surfaces and Low Thermal Conductivity: A First-Principles Study of Thermoelectric Properties",
    "abstract": "Layered Zintl compounds exhibit significant tunability of thermoelectric (TE) parameters facilitated by their multiple elemental combinations and flexibility in stacking order within the layers. In this work, the effect of stacking order on TE properties of theoretically predicted layered Zintl compounds XZnBi (X = Rb, Cs) is studied using 1st-principles calculations and Boltzmann equations. The materials are semiconductors having moderate band gaps ranging from 0.44 to 0.52 eV. There exist six identical hole pockets for valence band maxima due to the crystal symmetry. This leads to high band degeneracy but simultaneously promotes intervalley scatterings. While as for conduction bands, the Fermi surface consists of a single but highly anisotropic, quasi-two dimensional electron pockets with cylindrical shape along z-axis. This kind of Fermi surface is a characteristic of a pudding mold band shape. It facilitates a unique combination of heavy and light electron masses, simultaneously optimizing Seebeck coefficient and electrical conductivity. At first, electronic transport coefficients are calculated using constant relaxation time approximation (CRTA) or electron-phonon coupling matrix elements (el-ph). The calculated relaxation times are then integrated with transport results to get the realistic values of TE parameters. The analysis of three-phonon scattering reveals low thermal conductivity ($k_{l}$) below 2 W/m/K in these compounds. The $k_{l}$ also depends on stacking order with the values of nearly half in AB stacking as compared to that of AA stacking. These combined factors lead to a high ZT at 900 K, reaching to a maximum of 2.42 using CRTA and 0.52 when el-ph are included. The study highlights the potential of XZnBi systems as promising TE materials as well as the critical roles of stacking and el-ph in accurately evaluating TE properties.",
    "authors": [
      "Aadil Fayaz Wani",
      "Nirma Kumari",
      "SuDong Park",
      "Byungki Ryu"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03526",
    "title": "Stretched Exponential Scaling of Parity-Restricted Energy Gaps in a Random Transverse-Field Ising Model",
    "abstract": "The success of a quantum annealing algorithm requires a polynomial scaling of the energy gap. Recently it was shown that a two-dimensional transverse-field Ising model on a square lattice with nearest-neighbor $\\pm J$ random coupling has a polynomial energy gap in the symmetric subspace of the parity operator [Nature 631, 749-754 (2024)], indicating the efficient preparation of its ground states by quantum annealing. However, it is not clear if this result can be generalized to other spin glass models with continuous or biased randomness. Here we prove that under general independent and identical distributions (i.i.d.) of the exchange energies, the energy gap of a one-dimensional random transverse-field Ising model follows a stretched exponential scaling even in the parity-restricted subspace. We discuss the implication of this result to quantum annealing problems.",
    "authors": [
      "G.-X. Tang",
      "J.-Z. Zhuang",
      "L.-M. Duan",
      "Y.-K. Wu"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03546",
    "title": "Static and dynamic properties of the frustrated spin-1/2 depleted-kagome antiferromagnet Cu$_7$(TeO$_3$)$_2$(SO$_4$)$_2$(OH)$_6$",
    "abstract": "The structural and magnetic properties of the two-dimensional spin-$1/2$ depleted-kagome compound Cu$_7$(TeO$_3$)$_2$(SO$_4$)$_2$(OH)$_6$ are investigated using x-ray diffraction, magnetization, heat capacity, and $^1$H Nuclear Magnetic Resonance (NMR) measurements. From the analysis of magnetic susceptibility, we found a large Curie-Weiss temperature [$\\theta_{\\rm CW} = -50(2)$ K] and the co-existence of antiferromagnetic and ferromagnetic interactions. The value of $\\theta_{\\rm CW}$ gives an estimate of the average nearest-neighbour antiferromagnetic interaction of $J/k_{\\rm B} \\simeq 66$ K. The NMR relaxation rates ($1/T_1$ and $1/T_2$) exhibit a peak, providing evidence for a magnetic long-range order at $T^*\\simeq 4$ K which appears to be canted antiferromagnetic type. Heat capacity also features a broad maximum at $T^*$ that moves towards higher temperatures with increasing magnetic field, reflecting defect induced Schottky anomaly. The frustration parameter $f_r = \\lvert \\theta_{\\rm CW} \\lvert/{T^{*}}\\simeq 12.5$ renders the compound a highly frustrated low-dimensional magnet.",
    "authors": [
      "K. U. Akshay",
      "Sebin J. Sebastian",
      "Q.-P. Ding",
      "Y. Furukawa",
      "R. Nath"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03588",
    "title": "Numerical simulation of coherent spin-shuttling in a QuBus with charged defects",
    "abstract": "Recent advances in coherent conveyor-mode spin qubit shuttling are paving the way for large-scale quantum computing platforms with qubit connectivity achieved by spin qubit shuttles. We developed a simulation tool to investigate numerically the impact of device imperfections on the spin-coherence of conveyor-mode shuttling in Si/SiGe. We simulate the quantum evolution of a mobile electron spin-qubit under the influence of sparse and singly charged point defects placed in the Si/SiGe heterostructure in close proximity to the shuttle lane. We consider different locations of a single charge defect with respect to the center of the shuttle lane, multiple orbital states of the electron in the shuttle with $g$-factor differences between the orbital levels, and orbital relaxation induced by electron-phonon interaction. With this simulation framework, we identify the critical defect density of charged point defects in the heterostructure for conveyor-mode spin qubit shuttle devices and quantify the impact of a single defect on the coherence of a qubit.",
    "authors": [
      "Nils Ciroth",
      "Arnau Sala",
      "Ran Xue",
      "Lasse Ermoneit",
      "Thomas Koprucki",
      "Markus Kantner",
      "Lars R. Schreiber"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03602",
    "title": "High Pressure and Compositionally Directed Route to a Hexagonal GeSn Alloy Class",
    "abstract": "Despite their electronic dominance, cubic diamond structured Si and Ge, are optoelectronically deficient. Recent work indicates, however, that a volume-expanded hexagonal Ge modification can exhibit intensely sought, superior optoelectronic characteristics. If larger Sn could form a hexagonal solid solution with Ge, this would achieve this expansion. But this was not expected because Ge and Sn are unreactive at ambient conditions, Sn does not have an ambient hexagonal symmetry, and only cubic or tetragonal binary modifications could be prepared under any conditions including thin film processing. This state of affairs is categorically changed here by subjecting Ge and Sn to pressures of 9 and 10 GPa and temperatures up to 1500 K using large-volume press methods. Synchrotron angle-dispersive X-ray diffraction, precession electron diffraction and chemical analysis using electron microscopy reveal ambient pressure recovery of hexagonal 2H, 4H and 6H Ge-Sn solid solutions (P63/mmc). Formation of this new binary materials landscape is correlated with Sn uptake, with the hexagonal symmetry being accessible below 21 atom % Sn and the cubic diamond symmetry at or above this value. The findings form fertile routes to advanced materials, by in tandem creating reactivity with pressure and directing production of needed crystal symmetries with composition, as well as opportunity to tune properties based on crystal symmetry, composition, and stacking sequence for optoelectronic applications. PubMed Disclaimer",
    "authors": [
      "George Serghiou",
      "Hans Josef Reichmann",
      "Gang Ji",
      "Laurence Nigay",
      "Jonathan P. Wright",
      "Daniel J. Frost",
      "Gus Calder"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03609",
    "title": "Hamiltonian Active Matter in Incompressible Fluid Membranes",
    "abstract": "Active proteins and membrane-bound motors exert force dipole flows along fluid interfaces and lipid bilayers. We develop a unified hydrodynamic and Hamiltonian framework for the interactions of pusher and puller dipoles embedded in an incompressible two-dimensional membrane supported by a shallow viscous subphase. Beginning from the screened Stokes equations of the membrane--subphase composite, we derive the real-space incompressible Green's tensor, obtain its near- and far-field asymptotics, and construct the resulting dipolar velocity and stream functions. Although generic dipoles reorient under the local membrane vorticity, we show that the far-field dipolar flow is vorticity-free; force-free motors therefore retain fixed orientation and obey a Hamiltonian dynamics in which the positions of $N$ dipoles evolve via an effective Hamiltonian built from the dipolar stream function. In the near field, where the flow possesses finite vorticity, a Hamiltonian formulation is recovered in the quenched-orientation limit. Exploiting this structure, we simulate ensembles of pusher and puller dipoles and compare the dynamics generated by the $1/r$ near-field kernel and the subphase screened $1/r^{3}$ far-field kernel. For identical dipoles, the far-field Hamiltonian produces rapid clustering from random initial conditions, whereas the near-field Hamiltonian suppresses collapse and yields extended, non-aggregating configurations.",
    "authors": [
      "Sneha Krishnan",
      "Rickmoy Samanta"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03618",
    "title": "Fermionic Critical Fluctuations: Potential Driver of Strange Metallicity and Violation of the Wiedemann-Franz Law in YbRh2Si2",
    "abstract": "Results of combined thermal and electrical transport measurements through the magnetic field-induced quantum critical point in the heavy-fermion compound YbRh2Si2 are revisited to explore the relationship between the strange-metal behavior, observed in both the electrical and electronic thermal resistivity, and the violation of the Wiedemann-Franz law in the zero-temperature limit. A new type of inelastic scattering center for the charge and heat carriers has been detected and ascribed to the small-to-large Fermi-surface fluctuations. These are operating in the vicinity of and at the Kondo-destroying quantum critical point as fermionic quantum critical fluctuations and are considered the primary driver of the strange-metal behavior and the violation of the Wiedemann-Franz law.",
    "authors": [
      "Frank Steglich"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03622",
    "title": "From fractional Chern insulators to topological electronic crystals in moiré MoTe2: quantum geometry tuning via remote layer",
    "abstract": "The quantum geometry of Bloch wavefunctions,encoded in the Berry curvature and quantum metric, is believed to be a decisive ingredient in stabilizing fractional quantum anomalous Hall (FQAH) effect(i.e., fractional Chern insulator, FCI, at zero magnetic field), against competing symmetry-breaking phases.A direct experimental demonstration of quantum geometry-driven switching between distinct correlated topological phases, however, has been lacking. Here, we report experimental evidence of such a switch in a high-quality 3.7 twisted MoTe2 (tMoTe2) device consisting of both A-A bilayer and A-AB trilayer regions. While composite Fermi liquid CFL/FQAH phases are established in A-A tMoTe2,the A-AB region-effectively an A-A moire bilayer proximitized by a remote B layer-develops a series of topological electronic crystal (TEC, also referred to as generalized QAH crystal, QAHC) states with integer quantized Hall conductance at commensurate fractional fillings v=1/2, 2/3, and an incommensurate filling factor v= this http URL electrostatic phase diagram is mapped out by combined transport and optical measurements, showing that these TEC states emerge within the first moir'e valence band prior to any charge transfer to the B layer. Exact diagonalization (ED) incorporating the remote-layer-induced intralayer potential demonstrates a transition from a CFL-like manifold in the A-A limit to a Chern number C=1 ground-state consistent with a TEC at v=1/2 , accompanied by the further breakdown of ideal band geometry. Our results provide experimental evidence of quantum geometry-tuned competition between FQAH/CFL and TEC phases in a moiré Chern band and pave the way for further exploring correlation-driven topological phenomena by tuning quantum geometry.",
    "authors": [
      "Feng Liu",
      "Fan Xu",
      "Cheng Xu",
      "Jiayi Li",
      "Zheng Sun",
      "Jiayong Xiao",
      "Ning Mao",
      "Xumin Chang",
      "Xinglin Tao",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Jinfeng Jia",
      "Ruidan Zhong",
      "Zhiwen Shi",
      "Shiyong Wang",
      "Guorui Chen",
      "Xiaoxue Liu",
      "Dong Qian",
      "Yang Zhang",
      "Tingxin Li",
      "Shengwei Jiang"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03642",
    "title": "Evaluation of Foundational Machine Learned Interatomic Potentials for Migration Barrier Predictions",
    "abstract": "Fast, and accurate prediction of ionic migration barriers ($E_m$) is crucial for designing next-generation battery materials that combine high energy density with facile ion transport. Given the computational costs associated with estimating $E_m$ using conventional density functional theory (DFT) based nudged elastic band (NEB) calculations, we benchmark the accuracy in $E_m$ and geometry predictions of five foundational machine learned interatomic potentials (MLIPs), which can potentially accelerate predictions of ionic transport. Specifically, we assess the accuracy of MACE-MP-0, Orb-v3, SevenNet, CHGNet, and M3GNet models, coupled with the NEB framework, against DFT-NEB-calculated $E_m$ across a diverse set of battery-relevant chemistries and structures. Notably, MACE-MP-0 and Orb-v3 exhibit the lowest mean absolute errors in $E_m$ predictions across the entire dataset and over data points that are not outliers, respectively. Importantly, Orb-v3 and SevenNet classify `good' versus `bad' ionic conductors with an accuracy of $>$82\\%, based on a threshold $E_m$ of 500~meV, indicating their utility in high-throughput screening approaches. Notably, intermediate images generated by MACE-MP-0 and SevenNet provide better initial guesses relative to conventional interpolation techniques in $>$71\\% of structures, offering a practical route to accelerate subsequent DFT-NEB relaxations. Finally, we observe that accurate $E_m$ predictions by MLIPs are not correlated with accurate (local) geometry predictions. Our work establishes the use-cases, accuracies, and limitations of foundational MLIPs in estimating $E_m$ and should serve as a base for accelerating the discovery of novel ionic conductors for batteries and beyond.",
    "authors": [
      "Achinthya Krishna Bheemaguli",
      "Penghao Xiao",
      "Gopalakrishnan Sai Gautam"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03647",
    "title": "Optimizing two-qubit gates for ultracold fermions in optical lattices",
    "abstract": "Ultracold neutral atoms in optical lattices are a promising platform for simulating the behavior of complex materials and implementing quantum gates. We optimize collision gates for fermionic Lithium atoms confined in a double-well potential, controlling the laser amplitude and keeping its relative phase constant. We obtain high-fidelity gates based on a one-dimensional confinement simulation. Our approach extends beyond earlier Fermi-Hubbard simulations by capturing a momentum dependence in the interaction energy. This leads to a higher interaction strength when atoms begin in separate subwells compared to the same subwell. This momentum dependence might limit the gate fidelity under realistic experimental conditions, but also enables tailored applications in quantum chemistry and quantum simulation by optimizing gates for each of these cases separately.",
    "authors": [
      "Jan A. P. Reuter",
      "Juhi Singh",
      "Tommaso Calarco",
      "Felix Motzoi",
      "Robert Zeier"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03649",
    "title": "DHICA ion-modified melanin based porous Si solar cell",
    "abstract": "This work studies photosensitivity and current-voltage characteristics under illumination of water-soluble eumelanin films based on DHICA tetramers and hybrid eumelanin/porous Si photovoltaic cells aimed at optimizing their characteristics. By using DMSO to dissolve melanin containing protonated carboxyl groups and to remove ammonium cations, it became possible to significantly reduce the ionic component of conductivity, thus improved the electron transport. It was found out that dissolution in DMSO provides a denser {\\pi}-{\\pi} stacking of DHICA tetramers, which led to a significant improvement in the photovoltaic cell parameters. In particular, the efficiency increased from 0.023 % to 4.4 % and the series resistance decreased from 119 {\\Omega} to 42.6 {\\Omega}. Modeling demonstrated that high-temperature annealing, which causes decarboxylation, leads to a structural rearrangement of tetramers from a Christmas tree-like configuration to a \"toothed helix\". At this, one of the planes partially straightens. This emphasizes the critical importance of the morphology of the organic layer for photogeneration of carriers in a heterojunction.",
    "authors": [
      "M. Semenenko",
      "T. Yu. Obukhova",
      "S. O. Kravchenko",
      "O. S. Pylypchuk",
      "O. Yu. Ostapenko",
      "T. O. Kuzmenko",
      "M. V. Voitovych",
      "S. Davidenko",
      "Ye. S. Davidenko",
      "S. S. Davidenko",
      "A. Sarikov"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03654",
    "title": "Tuning spin currents in collinear antiferromagnets and altermagnets",
    "abstract": "Spin current generation through non-relativistic spin splittings, found in uncompensated magnets and d-wave altermagnets, is desirable for low-power spintronics. Such spin currents, however, are symmetry forbidden in conventional collinear antiferromagnets and higher-order altermagnets. Using spin point group analysis, we demonstrate that finite spin currents can be induced in these materials via magnetoelectric, piezomagnetic, and piezomagnetoelectric-like couplings. We utilize electric fields, strain, and their combinations to drive symmetry-lowering phase transitions into uncompensated magnetic or d-wave altermagnetic states, thereby enabling finite spin conductivity in a broader class of magnetic materials. We further substantiate this framework using density functional theory and Boltzmann transport calculations on representative magnetic materials - KV2Se2O, RuF4 , Cr2O3 , FeS2 , and MnPSe3 - spanning these different cases. The charge-to-spin conversion ratio reaches up to almost 100% via uncompensated magnetism and about 40% via d-wave altermagnetism under realistic conditions, highlighting the effectiveness of this approach for efficient spin current generation.",
    "authors": [
      "Sajjan Sheoran",
      "Pratibha Dev"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03657",
    "title": "Nonrelativistic Functional Properties in Collinear Antiferromagnets Based on Multipole Representation Theory",
    "abstract": "In recent years, the concept of multipoles has been widely used to describe and classify various magnetic and electric responses in solids, providing a systematic way to identify symmetry-allowed or -forbidden physical responses. Conventionally, multipole classifications rely on the magnetic point group of a system, which inherently incorporates the effects of relativistic spin-orbit coupling because the spin orientation is supposed to follow the point-group transformation of the lattice. However, this approach becomes insufficient in situations where relativistic spin-orbit coupling is negligibly weak or where the spin and orbital (lattice) degrees of freedom are decoupled, thereby requiring a more comprehensive symmetry description. In this work, we introduce a multipole description on the basis of spin-point-group symmetries, enabling a systematic exploration of nonrelativistic phenomena that persist even without spin-orbit coupling in a collinear antiferromagnet. As an application, we theoretically demonstrate spin-current generation driven by elastic waves in a specific collinear antiferromagnet, fully independent of spin-orbit coupling.",
    "authors": [
      "Yuuki Ogawa",
      "Satoru Hayami"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03658",
    "title": "Enhancement of Tc in Oxide Superconductors: Double-Bridge Mechanism of High-Tc Superconductivity and Bose-Einstein Condensation of Cooper Pairs",
    "abstract": "The cuprate Hg0.8Tl0.2Ba2Ca2Cu3O8.33 exhibits the highest superconducting transition temperature Tc of 138K. Achieving superconductivity at even higher temperatures, up to room temperature, represents the ultimate dream of humanity. As temperature increases, Cooper pairs formed through weak electron-phonon coupling will be disintegrated by the thermal motion of electrons, severely limiting the enhancement of Tc. It is imperative to explore new strong-coupling pairing pictures and establish novel condensation mechanism of Cooper pairs at higher temperature. Based on our recently proposed groundbreaking idea of electron e- (hole h+) pairing bridged by oxygen O (metal M) atoms, namely, the eV-scale ionic-bond-driven atom-bridge (bridge-I) e--O-e- (h+-M-h+) strong-coupling itinerant Cooper pairing formed at pseudogap temperature T*>Tc in ionic oxide superconductors, we further discover that there is an attractive interaction between two Cooper pairs induced by the bridge atom (bridge-II) located between them. It is this attraction mediated by the bridge-II atoms that promotes all the Cooper pairs within the CuO2 plane to hold together and enter the superconducting state at Tc finally. Moreover, according to the Bose-Einstein condensation theory, we find that Tc is inversely proportional to the effective mass m* of Cooper pairs, directly proportional to n2/3s (ns: the density of Cooper pairs), and linearly increases with the scattering length a<0 due to attraction between two Cooper pairs. Therefore, according to our double-bridge mechanism of high-Tc superconductivity, increasing the attraction between Cooper pair and bridge-II atom, ensuring that ns takes the optimal value, and minimizing the effective mass of the Cooper pairs are the main approaches to enhancing Tc of ionic-bonded superconductors, which opens up a new avenue with clear direction for designing higher Tc superconductors.",
    "authors": [
      "Jun-jie Shi",
      "Juan Du",
      "Yao-hui Zhu"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03689",
    "title": "More is uncorrelated: Tuning the local correlations of SU($N$) Fermi-Hubbard systems via controlled symmetry breaking",
    "abstract": "Cold-atom experiments based on alkali-like atoms provide us with a tool to experimentally realize Hubbard models with a large number $N$ of components. The value of $N$ can be seen as a new handle to tune the properties of the system, leading to new physics both in the case of fully SU($N$) symmetric systems, or in the presence of controlled symmetry breaking. We focus on the Mott transition at global half filling and we characterize local correlations between particles complementing conventional estimates with the inter-flavor mutual information. We prove that these correlations have classical nature and, using Dynamical Mean-Field Theory, we show that the SU(4) system has significantly smaller correlations than the SU(2) counterpart. In the atomic limit we prove that increasing $N$ further decreases the strength of the correlations. This suggests that a controlled reduction of the symmetry, reducing the number of effective components, can be used to enhance the degree of correlation. We confirm this scenario solving the model for $N=4$ and gradually breaking the symmetry via a Raman field, revealing an evolution from the SU(4) to the SU(2) Mott transition as the symmetry-breaking term increases, with a sudden recovery of the large correlations of the SU(2) model at weak Raman coupling in the Mott state. By further exploring the interplay between energy repulsion and the Raman field, we obtain a rich phase diagram with three different phases -- a metal, a band insulator, and a Mott insulator -- all coexisting at a single tricritical point.",
    "authors": [
      "Edoardo Zavatti",
      "Gabriele Bellomia",
      "Samuele Giuli",
      "Matteo Ferraretto",
      "Massimo Capone"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03691",
    "title": "Terahertz light driven coherent excitation of a zone-folded Raman-active phonon mode in the Spin-Ladder System $α'$-NaV$_2$O$_5$",
    "abstract": "We investigate the out-of-equilibrium lattice dynamics in the spin-ladder system $\\alpha'$-NaV$_2$O$_5$ using intense terahertz (THz) pump and near-infrared (NIR) probe spectroscopy. When quasi-single-cycle THz pulses interact with $\\alpha'$-NaV$_2$O$_5$ in its low-temperature, dimerized charge-ordered phase, they induce coherent oscillations in the time domain at the zone-folded Raman-active phonon frequency of 1.85 THz. By combining pump-probe measurements with lattice dynamics modeling based on equation-of-motion approach, we propose that these oscillations arise from a nonlinear coupling between Raman-active and infrared (IR)-active phonon modes, with the latter being resonantly excited by the THz pulses. In contrast, excitation with NIR femtosecond laser pulses does not produce measurable vibrational dynamics, highlighting the unique potential of THz-driven, nonlinear light-matter interactions for the coherent and selective control of structural dynamics in quantum materials.",
    "authors": [
      "Flavio Giorgianni",
      "Martina Romani",
      "Pascal Puphal",
      "Masahiko Isobe",
      "Leonie Spitz",
      "Mariangela Cestelli Guidi",
      "Carlo Vicario",
      "Mattia Udina"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03698",
    "title": "DEM Simulations of Spheres Flowing Through a Hopper: Validation of Beverloo Law",
    "abstract": "This work presents a detailed investigation of the discharge behavior of spherical granular materials through a conical--cylindrical hopper using \\emph{Discrete Element Method (DEM)} simulations. The aim is to assess the applicability limits of the empirical \\emph{Beverloo law}. The system was modeled with a monodisperse particles whose mechanical properties correspond to the $Al_{95}Fe_2Cr_2Ti_1$ alloy, and interparticle contacts were described using the Hertz--Mindlin (no slip) model. The simulations systematically explored the influence of particle diameter ($d$) and bed height ($h$) on the resulting mass flow rate ($Q$). The results reveal the coexistence of transient and steady-state discharge regimes. Good agreement with the Beverloo scaling was observed for relatively small diameter ratios ($D/d = 10$) and sufficiently large bed heights, where the flow stabilizes rapidly. For larger $D/d$ ratios, the discharge rate decays exponentially, indicating a breakdown of the constant-hydrostatic-pressure assumption underlying the Beverloo model. A dimensionless criterion for the validity of the Beverloo law is proposed as $\\Pi_h = h/D > 2$, or equivalently $N = h/d > 20$. The quantitative agreement between DEM simulations and experimental measurements for polydisperse particle size distributions further validates the computational model and demonstrates its predictive capability for granular discharge in confined geometries.",
    "authors": [
      "Leticia M. V. da Silva",
      "Erlifas Moreira Rocha",
      "Piter Gargarella",
      "Pedro Augusto F. P. Moreira"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03705",
    "title": "Spin-flop driven interfacial tunneling magnetoresistance in an antiferromagnetic tunnel junction",
    "abstract": "The utilization of two-dimensional (2D) materials in magnetic tunnel junctions (MTJs) has shown excellent performance and rich physics. As for 2D antiferromagnets, the magnetic moments in different layers respond asynchronously and can be configured at various states under different magnetic fields, showing the possibility of efficient magnetic and electrical tunability. In this report, A-type antiferromagnetic (AFM) material (Fe0.5Co0.5)5GeTe2 (FCGT) works as electrodes to realize full van der Waals magnetic tunnel junctions. Owing to the interfacial effect, the even-layer FCGT, although with zero net magnetization, exhibits spin selectivity in MTJ architecture contributing to a tunneling magnetoresistance (TMR) reaching about 25% at a low operating current 1 nA at 100 K and persists near room temperature. Due to the surface spin-flop (SSF) effect in antiferromagnetic FCGT, the alternation flexibility between the volatile and nonvolatile memory behavior is achieved. The interfacial TMR can be tuned efficiently in amplitude and even sign under different bias currents and temperatures. These findings show precise magnetoelectric manipulation in MTJs based on 2D antiferromagnets and highlight the promise of 2D antiferromagnets for spintronic devices.",
    "authors": [
      "Xiaolin Ren",
      "Ruizi Liu",
      "Yiyang Zhang",
      "Yuting Liu",
      "Xuezhao Wu",
      "Kun Qian",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Qiming Shao"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03721",
    "title": "Experimental and Theoretical Revisit of Ca-H Superhydrides: Anharmonic Effects on Phase Stability and Superconductivity",
    "abstract": "The prediction of superconductivity above 200 K in CaH6 revolutionized research on hydrogen-rich superconductors, and subsequent experiments have verified this prediction, while unidentified peaks in XRD and the decrease in superconducting temperature upon decompression indicate that unresolved issues remain. In this work, we combine theory and experiment to construct an accurate temperature-pressure phase diagram of the Ca-H system and identify the stability ranges of the candidate superconducting phases by considering anharmonic effects. Our results demonstrate that type-I clathrate Ca8H46-delta structures become thermodynamically stable at 0 K when anharmonic effects are considered. Notably, we found that the previously predicted CaH6 phase achieves stability above 500 K, underscoring the significant role of temperature and anharmonic effects in stabilizing this intriguing high-pressure phase. Experimentally, we have successfully synthesized Ca8H46-delta phases at low temperatures, thereby validating our theoretical predictions. Our findings offer insights into the structure and superconducting mechanisms of hydrides.",
    "authors": [
      "Wenbo Zhao",
      "Qiushi Li",
      "Ying Sun",
      "Zefang Wang",
      "Hefei Li",
      "Hanyu Liu",
      "Hongbo Wang",
      "Yu Xie",
      "Yanming Ma"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03734",
    "title": "Revealing Nanoscale Molecular Organization in Liquid Crystals via Cryogenic Atom Probe Tomograph",
    "abstract": "While liquid crystals (LCs) have been extensively studied, obtaining a comprehensive nanoscale picture of their molecular organization remains challenging, as conventional techniques face an intrinsic trade-off between spatial and chemical resolution. Here, cryogenic atom probe tomography (cryo-APT) is introduced as a new analytical approach for LC materials, using 4'-Pentyl-4-cyanobiphenyl (5CB) and 4'-Octyl-4-cyanobiphenyl (8CB) as representative model compounds. This was enabled by a tailored cryogenic focused ion beam (cryo-FIB) protocol optimized for small organic molecules. The method enables controlled field evaporation of both intact molecules and diagnostic fragments, achieving over 90% molecular retention while preserving four characteristic dissociation patterns. By spatially correlating these fragmentation profiles with the local electric field derived from the tip geometry, we reveal field-directed dissociation pathways of CB molecules. In parallel, the distribution of intact molecular ions enables nanoscale visualization of material structure: we resolve homogeneous mixing of 5CB and 8CB in the nematic phase and directly observe the sub-nanometer crystalline layering in a supercooled 8CB sample, with contrast to the surrounding amorphous matrix suggesting the presence of a solid-liquid interface. This work establishes cryo-APT as a new powerful analytical platform for LC research and reveals its broad potential for application in soft matter systems.",
    "authors": [
      "Kuan Meng",
      "Kang'an Wang",
      "Sebastian Eich",
      "Pierre Nacke",
      "Johanna R. Bruckner",
      "Patrick Stender",
      "Frank Giesselmann",
      "Guido Schmitz"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03742",
    "title": "Magnetotransport and Carrier Dynamics in Quasi-One-Dimensional Antiferromagnet KMn$_6$Bi$_5$",
    "abstract": "Quasi-one-dimensional materials $A$Mn$_6$Bi$_5$ ($A$ = Na, K, Rb, Cs) exhibit unique electronic behaviors such as antiferromagnetism, charge density waves, and pressure-induced superconductivity. Thus, they serve as a suitable model system to investigate emergent quantum phenomena produced by the interactions among spin, charge, and lattice. Here we report the magnetotransport properties of KMn$_6$Bi$_5$, revealing a cascade of temperature-dependent carrier dynamics. Below 5 K, the system, despite its anisotropic electronic structure, could be effectively described by an isotropic two-band model and exhibits a large, non-saturating magnetoresistance ($\\propto B^{1.8}$). Upon warming, a crossover to a single-band regime occurs around 20 K, driven by the suppression of a hole pocket. Electron density recovers as antiferromagnetic gap openings gradually close from 25 to 70 K which is just below the N$\\mathrm{\\acute{e}}$el temperature. Within this temperature range, field-quenched spin fluctuations suppress magnetoresistance. Furthermore, we attribute the low-temperature resistivity upturn to the scaling behavior of magnetoresistance. These findings provide crucial insights into the interplay of dimensionality, magnetism, and electron correlations in quasi-one-dimensional magnetic semimetals.",
    "authors": [
      "Qi-Yuan Liu",
      "Chenfei Shi",
      "Zhaodi Lin",
      "Xiutong Deng",
      "Baojuan Kang",
      "Youguo Shi",
      "Gang Wang",
      "Rongrong Jia",
      "Jin-Ke Bao"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03780",
    "title": "Poly- and single-crystalline diamond nitrogen-induced TLS losses estimation with superconducting lumped elements micro-resonators",
    "abstract": "Research on diamond has intensified due to its exceptional thermal, optical, and mechanical properties, making it a key material in quantum technologies and high-power applications. Diamonds with engineered nitrogen-vacancy (NV) centers represent a very sensitive platform for quantum sensing, while high-optical quality diamond windows represent a fundamental safety component inside Electron Cyclotron Resonance Heating (ECRH) systems in nuclear fusion reactors. A major challenge is the development of ultra-low-loss, high-optical-quality single-crystal diamond substrates to meet growing demands for quantum coherence and power handling. Traditionally, dielectric losses ($\\tan \\delta$) in diamonds are evaluated using Fabry-Perot microwave resonators, in which the resonance quality factors Q of the cavity with and without the sample are compared. These devices are limited to resolutions around 10$^{-5}$ by the need to keep the resonator dimensions within a reasonable range. In contrast, superconducting thin-film micro-strip resonators, with Q factors exceeding 10$^6$, are stated to provide higher sensitivity for assessing ultra-low-loss materials. This study examines four diamond samples grown through different processes, analyzing their dielectric losses at extreme low temperatures (sub-Kelvin) within the Two-Level System (TLS) framework. Complementary Raman spectroscopy measurements allowed us not only to associate higher nitrogen content with increased losses, but also to investigate how the different growth process influence the way these defects are incorporated in the crystal lattice.",
    "authors": [
      "Francesco Mazzocchi",
      "Martin Neidig",
      "Hideaki Yamada",
      "Sebastian Kempf",
      "Dirk Strauss",
      "Theo Scherer"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03785",
    "title": "Interfacial Control of Orbital Occupancy and Spin State in LaCoO$_3$",
    "abstract": "Transition metal oxides exhibit a wide range of tunable electronic properties arising from the complex interplay of charge, spin, and lattice degrees of freedom, governed by their $d$ orbital configurations, making them particularly interesting for oxide electronics and (electro)catalysis. Perovskite oxide heterointerfaces offer a promising route to engineer these orbital states. In this work, we tune the Co $3d$ orbital occupancy in LaCoO$_3$ from a partial $d^7$ to a partial $d^5$ state through interfacial engineering with LaTiO$_3$, LaMnO$_3$, LaAlO$_3$ and LaNiO$_3$. Using X-ray absorption spectroscopy combined with charge transfer multiplet calculations, we identify differences in the Co valence and spin state for the series of oxide heterostructures. LaTiO$_3$ and LaMnO$_3$ interfaces result in interfacial charge transfer towards LaCoO$_3$, resulting in a partial $d^7$ orbital occupancy, while a LaNiO$_3$ interface results in a partial Co $d^5$ occupancy. Strikingly, a LaAlO$_3$ spacer layer between LaNiO$_3$ and LaCoO$_3$ results in a Co $d^6$ low spin state. These results indicate that the Co spin state, like the valence state, is governed by the interfacial environment. High-resolution scanning transmission electron microscopy imaging reveals a clear connection between strain and spin configuration, emphasizing the importance of structural control at oxide interfaces. Overall, this work demonstrates that interfacial engineering simultaneously governs orbital occupancy and spin state in correlated oxides, advancing spin-engineering strategies in correlated oxides and offering new insights for the rational design of functional oxide heterostructures.",
    "authors": [
      "Ellen M. Kiens",
      "Nicolas Gauquelin",
      "Arno Annys",
      "Emma van der Minne",
      "Iris C.G. van den Bosch",
      "Matthijs A. van Spronsen",
      "Zezhong Zhang",
      "Annick de Backer",
      "Sandra van Aert",
      "Jo Verbeeck",
      "Gertjan Koster",
      "Bastian Mei",
      "Frank M.F. de Groot",
      "Christoph Baeumer"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03797",
    "title": "Proximity-induced superconductivity in magnetic topological insulator films",
    "abstract": "Inducing superconducting correlations in magnetic topological insulators (MTIs) is emerging as a promising route toward the realization of topological superconductivity and Majorana modes. Here, we develop an analytical model for the proximity effect induced by an ordinary s-wave superconductor (SC) placed on top of a MTI thin film with finite thickness. Using a perturbative approach with respect to the electron tunneling between MTI and SC, we derive the leading-order correction to the anomalous Green's function and evaluate the position-dependent induced pairing as a function of all the system parameters. This framework allows us to resolve the spatial, spin, and momentum structure of the induced superconducting order parameter. In particular, we derive an explicit expression for the decay length of the pairing amplitude at the $k_x=k_y=0$ point, and show that increasing magnetization enhances the spin-polarized triplet components and the p-wave contributions of the anomalous Green's function. These findings highlight the interplay between topology, magnetism, and superconductivity in MTI films, providing analytical insight into the emergence of unconventional pairing symmetries relevant for the realization of Majorana modes in finite geometries.",
    "authors": [
      "Daniele Di Miceli",
      "Eduárd Zsurka",
      "Kristof Moors",
      "Llorenç Serra",
      "Thomas L. Schmidt"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03799",
    "title": "Remembrance of Tasks Past in Tunable Physical Networks",
    "abstract": "Sequential learning in physical networks is hindered by catastrophic forgetting, where training a new task erases solutions to earlier ones. We show that we can significantly enhance memory of previous tasks by introducing a hard threshold in the learning rule, allowing only edges with sufficiently large training signals to be altered. Thresholding confines tuning to the spatial vicinity of inputs and outputs for each task, effectively partitioning the network into weakly overlapping functional regions. Using simulations of tunable resistor networks, we demonstrate that this strategy enables robust memory of multiple sequential tasks while reducing the number of edges and the overall tuning cost. Our results hint at constrained training as a simple, local, and scalable mechanism to overcome catastrophic forgetting in tunable matter.",
    "authors": [
      "Purba Chatterjee",
      "Marcelo Guzman",
      "Andrea J. Liu"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03806",
    "title": "Highly Anisotropic Charge Dynamics and Spectral Weight Redistribution in the Trilayer Nickelate La$_{4}$Ni$_{3}$O$_{10}$",
    "abstract": "We study the $ab$-plane and $c$-axis charge dynamics of La$_{4}$Ni$_{3}$O$_{10}$ using optical spectroscopy. While a pronounced Drude profile, i.e. metallic response, is observed in the $ab$-plane optical conductivity $\\sigma_{1}^{ab}(\\omega)$, the $c$-axis optical spectra $\\sigma_{1}^{c}(\\omega)$ exhibit semiconducting behavior. The zero-frequency extrapolation of the optical conductivity $\\sigma_{1}(\\omega \\rightarrow 0) \\equiv 1/\\rho_{\\text{dc}}$ gives a resistivity anisotropy of $\\rho_{c}/\\rho_{ab} \\simeq 366$ at 300 K for La$_{4}$Ni$_{3}$O$_{10}$, which is much larger than the values in iron-based superconductors but comparable to those in high-$T_{c}$ cuprates. The interband response is also highly anisotropic, showing salient orbital selectivity for light polarized in the $ab$ plane and along the $c$ axis. The interband-transition peaks in both $\\sigma_{1}^{ab}(\\omega)$ and $\\sigma_{1}^{c}(\\omega)$ are located at lower energies compared to density-functional-theory predictions, signifying considerable electronic correlations. By investigating the spectral weight transfer, we find that in the pristine phase, Coulomb correlations have a marked impact on the charge dynamics of \\LNO, whereas in the density-wave state, a gap opens with the Ni-$d_{z^{2}}$ orbital being involved.",
    "authors": [
      "Zhe Liu",
      "Jie Li",
      "Deyuan Hu",
      "Bingke Ji",
      "Haoran Zhang",
      "Jiahao Hao",
      "Yaomin Dai",
      "Qing Li",
      "Mengjun Ou",
      "Bing Xu",
      "Yi Lu",
      "Meng Wang",
      "Hai-Hu Wen"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03814",
    "title": "Quantum geometric planar magnetotransport: a probe for magnetic geometry in altermagnets",
    "abstract": "Nonlinear and nonreciprocal transport phenomena provide a direct probe of band quantum geometry in noncentrosymmetric magnetic materials, such as the nonlinear Hall effect induced by the quantum metric dipole. In altermagnets, a recently discovered class of even-parity collinear magnets with $C_n\\mathcal{T}$ symmetry, conventional second-order responses are prohibited by an emergent $C_{2z}$ symmetry. In this work, we demonstrate that an in-plane magnetic field lifts this prohibition, inducing a planar magnetotransport that directly probes the intrinsic quantum geometry and the distinctive $C_n\\mathcal{T}$ nature of altermagnetic orders. We show that the field-dependent quantum geometric susceptibility generates versatile planar magnetotransport, including the planar Hall effects and nonreciprocal responses. Our work establishes distinctive signatures of altermagnetism in linear and nonlinear magnetotransport, providing a general framework for measuring quantum geometric responses and probing altermagnetic order.",
    "authors": [
      "Zhichun Ouyang",
      "Wei-Jing Dai",
      "Zi-Ting Sun",
      "Jin-Xin Hu",
      "K. T. Law"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03842",
    "title": "Super-hard and superconducting boron clathrates in the prediction of U-B compounds",
    "abstract": "The binary metal borides provide a promising platform for searching unique materials with superconductivity and super-hardness under high pressure, owing to the distinctive bonding characters of boron. In this work, combined the first-principles calculations and crystal structure predictions, we predicted 4 exotic stoichiometries and 8 unique U-B compounds under high pressure. The predicted compounds have layered or caged structure units and 4 of them host high hardness under ambient pressure. By removal of the U atoms, we predicted three meta-stable boron clathrates at ambient pressure. Remarkably, the Vickers hardness of the predicted C2/m-B6 is estimated to be 49-53 GPa, and the C2/m-B12 is superconducting with the Tc value of 16.12 K. Our calculations enrich the phase diagram of binary metal borides and boron allotropes, providing insights for the future theoretical and experimental studies on unique materials.",
    "authors": [
      "Juefei Wu",
      "Dexi Shao",
      "Junjie Wang",
      "Yu Han",
      "Bangshuai Zhu",
      "Cuiying Pei",
      "Qi Wang",
      "Jian Sun",
      "Yanpeng Qi"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03857",
    "title": "Classification of diffusion processes in dimension $d$ via the Carleman approach with applications to models involving additive, multiplicative or square-root noises",
    "abstract": "The Carleman approach is well-known in the field of deterministic classical dynamics as a method to replace a finite number $d$ of non-linear differential equations by an infinite-dimensional linear system. Here this approach is applied to a system of $d$ stochastic differential equations for $[x_1(t),..,x_d(t)]$ when the forces and the diffusion-matrix elements are polynomials, in order to write the linear system governing the dynamics of the averaged values ${\\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) ... x_d^{n_d}(t) )$ labelled by the $d$ integers $(n_1,..,n_d)$. The natural decomposition of the Carleman matrix into blocks associated to the global degree $n=n_1+n_2+..+n_d$ is useful to identify the models that have the simplest spectral decompositions in the bi-orthogonal basis of right and left eigenvectors. This analysis is then applied to models with a single noise per coordinate, that can be either additive or multiplicative or square-root, or with two types of noises per coordinate, with many examples in dimensions $d=1,2$. In $d=1$, the Carleman matrix governing the dynamics of the moments ${\\mathbb E} ( x^{n}(t) )$ is diagonal for the Geometric Brownian motion, while it is lower-triangular for the family of Pearson diffusions containing the Ornstein-Uhlenbeck and the Square-Root processes, as well as the Kesten, the Fisher-Snedecor and the Student processes that converge towards steady states with power-law-tails. In dimension $d=2$, the Carleman matrix governing the dynamics of the correlations ${\\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) )$ has a natural decomposition into blocks associated to the global degree $n=n_1+n_2$, and we discuss the simplest models where the Carleman matrix is either block-diagonal or block-lower-triangular or block-upper-triangular.",
    "authors": [
      "Cecile Monthus"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03863",
    "title": "Laser-induced modulation of conductance in graphene with magnetic barriers",
    "abstract": "We study how electrons move across a graphene sheet when it encounters two magnetic barriers with a region in between that is continuously driven by laser light. Rather than acting as a static obstacle, this illuminated middle section becomes a Floquet cavity that opens new transport channels through controlled photon absorption and emission. By combining Floquet theory with the transfer matrix method, we track electron transmission through both the main energy band and the emerging photon-assisted sidebands. We find that the laser does more than modify the potential--it reshapes how electrons interact between the magnetic barriers, enabling a switch from ordinary transmission to transport dominated by photon exchange. Because the magnetic field and the optical drive are applied to separate sections of the device, the system supports interference between cyclotron-filtered motion and discrete photon-pumping channels, producing Fano resonances and angle-dependent transmission zeros that cannot appear in double magnetic or double laser barrier systems alone. Under well-defined conditions, the distance between the magnetic barriers controls the coupling between Floquet channels, allowing highly tunable resonances and even perfect transmission, despite strong magnetic confinement. We also observe that low-energy carriers are efficiently blocked by the magnetic regions, while conductance steadily rises with energy until it reaches a clear saturation plateau. This hybrid design provides a versatile way to steer graphene electrons by balancing optical pumping and magnetic momentum filtering.",
    "authors": [
      "Rachid El Aitouni",
      "Miloud Mekkaoui",
      "Pablo Díaz",
      "David Laroze",
      "Ahmed Jellal"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03881",
    "title": "Resolving Structural Transitions in Lanthanide High-Entropy Oxides",
    "abstract": "We report a temperature-composition phase diagram for the chemically disordered and CeO2-LA2O3 high entropy oxides (HEOs), where LA denotes equimolar Y, La, Sm, and Pr, delineating stability regions for bixbyite, disordered fluorite, and intermediate vacancy-ordered fluorite phases. The diagram is constructed from a characterization package applied to bulk ceramics including X-ray diffraction (XRD), transmission electron microscopy (TEM) electron diffraction, Raman spectroscopy, energy-dispersive spectroscopy, X-ray absorption near-edge structure spectroscopy, and ultraviolet-visible spectroscopy, to quantify crystal structure at multiple length-scales, local coordination environments, and electronic structures across the formulation space. This comprehensive measurement suite is critical to identify boundaries between the closely related phases. For example, Raman scattering reveals local structural and defect environments unique to bixbyite local order that persist to ~50% Ce under equilibrium synthesis conditions but are invisible to XRD and TEM. We also report a companion thin film study to demonstrate that quenched kinetic energy from a physical deposition process can metastabilize the high symmetry, and thus high entropy, fluorite phase with only 20% Ce. This is noteworthy because electroneutrality constraints demand an exceptionally vacated oxygen sublattice; we estimate 16.7%, approaching that of delta-Bi2O3. Together, our equilibrium ceramics and far-from-equilibrium thin films show that when synthesis is coupled with rigorously chosen, multi-length-scale characterization, now one can identify the phase stability thermodynamic drivers and simultaneously derive practical guidelines for experimentally realizing targeted phases and structures - and thereby deliberately engineer properties in CeO2-LA2O3 HEOs, whose broad defect chemistries demand such an approach.",
    "authors": [
      "Billy E. Yang",
      "Saeed S. I. Almishal",
      "Sai Venkata Gayathri Ayyagari",
      "Mary Kathleen Caucci",
      "Gerald Bejger",
      "Christina M. Rost",
      "Nasim Alem",
      "Susan B. Sinnott",
      "Jon-Paul Maria"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03904",
    "title": "Speciation and hydration forces in sodium carbonate/bicarbonate aqueous solutions nanoconfined between mica sheets",
    "abstract": "The equilibrium between hydrated and hydrolysed forms of CO2 in water is central to a multitude of processes in geology, oceanography and biology. Chemistry of the carbonate system is well understood in bulk solution, however processes such as mineral weathering and biomineralisation frequently occur in nano-confined spaces where carbonate chemistry is less explored. For confined systems, the speciation equilibria are expected to tilt due to surface reactivity, electric fields and reduced configurational entropy. In this discussion paper we provide measurements of interaction force between negatively charged aluminosilicate (mica) sheets across aqueous carbonate/bicarbonate solutions confined to nanoscale films in equilibrium with a reservoir of the solution. By fitting the measurements to a Poisson-Boltzmann equation modified to account for charge regulation at the bounding walls, we discuss features of the bicarbonate speciation in confinement. We find that (i) the presence of bicarbonate in the bulk reservoir causes a repulsive excess pressure in the slit compared to pH-neutral salt solutions at the same concentration, arising from a higher (negative) effective charge on the mica surfaces; (ii) the electrostatic screening length is lower for solutions of Na2CO3 compared to NaHCO3 at the same bulk concentration, due to a shift in the speciation equilibria with pH and in accordance with Debye-Hückel theory; (iii) hydration forces are observed at distances below 2 nm with features of size 0.1 nm and 0.3 nm; this was reproducible across the various bicarbonate electrolytes studied, and contrasts with hydration forces of uniform step size measured in pH-neutral electrolytes.",
    "authors": [
      "Daria Turculet",
      "Shurui Miao",
      "Kieran Agg",
      "Susan Perkin"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03908",
    "title": "Visualization of vortex sheets and half quantum vortices in the chiral odd-parity superconductor UPt$_{3}$",
    "abstract": "Superconductivity is characterized by vanishing electrical resistance and magnetic flux expulsion. For conventional type II superconductors, the magnetic flux expulsion is incomplete in an applied magnetic field above a critical value and magnetic flux penetrates the bulk of the superconductor in discrete quantized magnetic flux tubes (vortices), each carrying a single quantum of flux (h/2e). Investigating the unconventional superconductor UPt$_{3}$ with a scanning superconducting quantum interference device (SQUID) microscope, we observed mobile half-quantum vortices together with one quantum vortices. Cooling the material under a higher magnetic field revealed the presence of lines of magnetic contrast resembling domain walls. These observations agree with theoretical predictions for chiral superconductivity with a two dimensional complex order-parameter with sheets of half-quantum vortices separating domains of opposite order-parameter chirality.",
    "authors": [
      "P. García-Campos",
      "V.O. Dolocan",
      "A. D. Huxley",
      "D. Aoki",
      "K. Hasselbach"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03917",
    "title": "A microscopic theory of Anderson localization of electrons in random lattices",
    "abstract": "The existence of Anderson localization, characterized by vanishing diffusion due to strong randomness, has been demonstrated in numerous ways. A systematic approach based on the Anderson quantum model of the Fermi gas in random lattices that can describe both diffusive and localized regimes has not yet been fully established. We build upon a recent publication \\cite{Janis:2025ab} and present a microscopic theory of disordered electrons covering both the metallic phase with extended Bloch waves and the localized phase where the propagating particle forms a quantum bound state with the hole left behind at the origin. The general theory provides a framework for constructing controlled approximations to one-particle and two-particle Green functions that satisfy the necessary conservation laws and causality requirements in the whole range of disorder strength. It is used explicitly to derive a local, mean-field-like approximation for the two-particle irreducible vertices, enabling quantitative analysis of the solution's properties in both metallic and localized phases, including critical behavior at the Anderson localization transition.",
    "authors": [
      "Václav Janiš"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03941",
    "title": "Influence of a generative parameter on the mechanical performance of topological interlocking assemblies of a hexagonal block",
    "abstract": "A topological interlocking assembly is an arrangement of blocks, where all blocks are kinematically constrained by their neighboring blocks and a fixed frame. This concept has been known for a long time, attracting recent interest due to its advantageous mechanical properties, such as reusability, redundancy and limited crack propagation. New mathematical methods enable the generation of vast numbers of new topologically interlocking blocks. A natural next question is the quantification of the mechanical performance of these new blocks. We conduct a numerical study of topological interlocking assemblies whose blocks are constructed based on the hexagonal grid. By varying a design parameter used in the generation of these blocks, we study its influence on the structural performance of the entire assembly. The results improve our understanding of the link between the block parameters and the mechanical performance. This enhances the ability to custom design blocks for certain mechanical requirements of the topological interlocking assemblies.",
    "authors": [
      "Lukas Schnelle",
      "Meike Weiß",
      "Reymond Akpanya",
      "Kai-Uwe Schröder",
      "Alice C. Niemeyer"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03950",
    "title": "Collective dynamics of trail-interacting particles",
    "abstract": "Trail interactions occur when past particle trajectories bias future motion, rendering the system out of thermodynamic equilibrium. While such systems are abundant in nature, their understanding is limited to the single-particle level or phenomenological mean-field theories. Here, we introduce a minimal model of many trail-interacting particles that extends this paradigm to the fluctuating collective level. Particles diffuse while depositing long-lasting repelling/attracting trails that act as a shared memory field, coupling their dynamics across time and space. Using stochastic density functional theory, we derive fluctuating hydrodynamic equations and analyze analytically and numerically the resulting behaviors. We show that memory, coupled with fluctuations, fundamentally reshapes collective dynamics; In the repulsive case, the particle density displays superdiffusive spreading characterized by transient clustering and ballistic motion; In the attractive case, the system condensates in finite time into frozen, localized states. Our results establish general principles for trail-interacting systems and reveal how persistent fields generate novel instabilities and self-organization.",
    "authors": [
      "Paul Pineau",
      "Samuel Bell",
      "Raphaël Voituriez",
      "Ram M. Adar"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03970",
    "title": "Non-radiative energy transfer between boron vacancies in hexagonal boron nitride and other 2D materials",
    "abstract": "Boron vacancies ($V_B^-$) in hexagonal boron nitride (hBN) have emerged as a promising platform for two-dimensional quantum sensors capable of operating at atomic-scale proximity. However, the mechanisms responsible for photoluminescence quenching in thin hBN sensing layers when placed in contact with absorptive materials remain largely unexplored. In this Letter, we investigate non-radiative Förster resonance energy transfer (FRET) between $V_B^-$ centers and either monolayer graphene or 2D semiconductors. Strikingly, we find that the FRET rate is negligible for hBN sensing layers thicker than 3 nm, highlighting the potential of $V_B^-$ centers for integration into ultra-thin quantum sensors within van der Waals heterostructures. Furthermore, we experimentally extract the intrinsic radiative decay rate of $V_B^-$ defects.",
    "authors": [
      "Fraunié Jules",
      "Mikhail M. Glazov",
      "Sébastien Roux",
      "Abraao Cefas Torres-Dias",
      "Cora Crunteanu-Stanescu",
      "Tom Fournier",
      "Maryam S. Dehaghani",
      "Tristan Clua-Provost",
      "Delphine Lagarde",
      "Laurent Lombez",
      "Xavier Marie",
      "Benjamin Lassagne",
      "Thomas Poirier",
      "James H. Edgar",
      "Vincent Jacques",
      "Cedric Robert"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04014",
    "title": "Construction of irreducible integrity basis for anisotropic hyperelasticity via structural tensors",
    "abstract": "We present a straightforward analytical-numerical methodology for determining polynomially complete and irreducible scalar-valued invariant sets for anisotropic hyperelasticity. By applying the proposed technique, we obtain irreducible integrity bases for all common anisotropies in hyperelasticity via the structural tensor concept, i.e., invariants are formed from a measure of deformation (symmetric 2nd order tensor) and a set of structural tensors describing the material's symmetry. Our work covers results for the 11 types of anisotropy that arise from the classical 7 crystal systems, as well as findings for 4 additional non-crystal anisotropies derived from the cylindrical, spherical, and icosahedral symmetry systems. Polynomial completeness and irreducibility of the proposed integrity bases are proven using the Molien series and, in addition, with established results for scalar-valued invariant sets from the literature. Furthermore, we derive relationships between a set of multiple structural tensors that specify a symmetry group and a description using only a single structural tensor. Both can be used to construct irreducible integrity bases by applying the proposed analytical-numerical method. The provided invariant sets are of great importance for modeling anisotropic materials via the structural tensor concept using both classical models as well as modern approaches based on machine learning. Alongside the results presented, this article also aims to provide an introductory overview of the complex field of modeling anisotropic materials.",
    "authors": [
      "Brain M. Riemer",
      "Jörg Brummund",
      "Karl A. Kalina",
      "Abel H. G. Milor",
      "Franz Dammaß",
      "Markus Kästner"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04029",
    "title": "Anisotropic Phonon Dynamics and Directional Transport in Actinide van der Waals Semiconductor USe$_3$",
    "abstract": "Direction-dependent charge transport and optical responses are characteristic of van der Waals (vdW) materials with strong in-plane anisotropy. While transition-metal trichalcogenides (TMTCs) exemplify this behavior, heavier analogs remain largely unexplored. In this study we examine USe$_3$ as an anisotropic vdW material and a heavier analog of the well-studied TMTCs. We reveal strong in-plane anisotropy using polarization-resolved Raman spectroscopy, investigate strain-induced shifts of phonon modes, and quantify direction-dependent charge-carrier mobility through transport measurements on field-effect devices. First-principles calculations based on density-functional theory corroborate our findings, providing a theoretical basis for our experimental observations. Casting USe$_3$ as an actinide analog of a TMTC establishes a platform for exploring low-dimensional semiconductors that combine strong in-plane anisotropy with f-electron physics.",
    "authors": [
      "Aljoscha Söll",
      "Valentino Jadrisko",
      "Sourav Dey",
      "Nassima Benchtaber",
      "Kalyan Sarkar",
      "Borna Radatovic",
      "Jan Luxa",
      "Fedor Lipilin",
      "Kseniia Mosina",
      "Vojtech Kundrat",
      "Jakub Zalesak",
      "Jana Vejpravova",
      "Martin Zacek",
      "Christoph Gadermaier",
      "José J. Baldoví",
      "Zdeněk Sofer"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04036",
    "title": "The Loss Landscape of Powder X-Ray Diffraction-Based Structure Optimization Is Too Rough for Gradient Descent",
    "abstract": "Solving crystal structures from powder X-ray diffraction (XRD) is a central challenge in materials characterization. In this work, we study the powder XRD-to-structure mapping using gradient descent optimization, with the goal of recovering the correct structure from moderately distorted initial states based solely on XRD similarity. We show that commonly used XRD similarity metrics result in a highly non-convex landscape, complicating direct optimization. Constraining the optimization to the ground-truth crystal family significantly improves recovery, yielding higher match rates and increased mutual information and correlation scores between structural similarity and XRD similarity. Nevertheless, the landscape may remain non-convex along certain symmetry axes. These findings suggest that symmetry-aware inductive biases could play a meaningful role in helping learning models navigate the inverse mapping from diffraction to structure.",
    "authors": [
      "Nofit Segal",
      "Akshay Subramanian",
      "Mingda Li",
      "Benjamin Kurt Miller",
      "Rafael Gomez-Bombarelli"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04037",
    "title": "Testing the Localization Landscape Theory on the Bethe Lattice",
    "abstract": "The Localization Landscape Theory (LLT) provides a classical picture of Anderson localization by introducing an effective confining potential whose percolation is proposed to coincide with the mobility edge. Although this proposal shows remarkable numerical agreement in three dimensions, its fundamental validity remains unsettled. Here we test the LLT analytically on the Bethe lattice, where both the Anderson localization transition and the LLT percolation problem are exactly solvable. We find that the two transitions do not coincide, and their critical behaviors differ markedly. In particular, LLT percolation displays standard mean-field percolation criticality that is fundamentally distinct from the peculiar critical behavior of the Anderson transition on the Bethe lattice. Our results provide an exact benchmark showing that, while geometrically intuitive, the LLT does not capture the true quantum critical properties of localization.",
    "authors": [
      "Lorenzo Tonetti",
      "Leticia F. Cugliandolo",
      "Marco Tarzia"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04041",
    "title": "Quantum theory of nonlinear phononics",
    "abstract": "The recent capability to use THz pulses to control the nuclear quantum degrees of freedom in crystals has opened promising avenues for the advanced manipulation of material properties. While numerical approaches exist for studying the time evolution of the quantum nuclear density matrix, an interpretable analytical framework to explicitly analyze the influence of quantum fluctuations on nuclear dynamics remains lacking. In this work, we present an analytical quantum theory of nonlinear phononics. This framework is a basis for deriving models of realistic materials, allowing for exact solutions of the nuclear time evolution with full consideration of quantum fluctuations. This is accomplished by treating for all possible third- and fourth-order phonon couplings and expressing forces as analytic functions of such fluctuations. We provide an analytic proof that, in general, a strong pulse displacing a phonon mode from equilibrium induces the quenching, or squeezing, of its quantum lattice fluctuations. This finding, which establishes a systematization of the mechanism observed in Ref. 1, introduces a new paradigm in nonlinear phononics, harnessing this cooling effect to drive symmetry breaking in quantum paraelectric materials.",
    "authors": [
      "Francesco Libbi",
      "Boris Kozinsky"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04045",
    "title": "Machine Learning Pipeline for Denoising Low Signal-To-Noise Ratio and Out-of-Distribution Transmission Electron Microscopy Datasets",
    "abstract": "High-resolution transmission electron microscopy (HRTEM) is crucial for observing material's structural and morphological evolution at Angstrom scales, but the electron beam can alter these processes. Devices such as CMOS-based direct-electron detectors operating in electron-counting mode can be utilized to substantially reduce the electron dosage. However, the resulting images often lead to low signal-to-noise ratio, which requires frame integration that sacrifices temporal resolution. Several machine learning (ML) models have been recently developed to successfully denoise HRTEM images. Yet, these models are often computationally expensive and their inference speeds on GPUs are outpaced by the imaging speed of advanced detectors, precluding in situ analysis. Furthermore, the performance of these denoising models on datasets with imaging conditions that deviate from the training datasets have not been evaluated. To mitigate these gaps, we propose a new self-supervised ML denoising pipeline specifically designed for time-series HRTEM images. This pipeline integrates a blind-spot convolution neural network with pre-processing and post-processing steps including drift correction and low-pass filtering. Results demonstrate that our model outperforms various other ML and non-ML denoising methods in noise reduction and contrast enhancement, leading to improved visual clarity of atomic features. Additionally, the model is drastically faster than U-Net-based ML models and demonstrates excellent out-of-distribution generalization. The model's computational inference speed is in the order of milliseconds per image, rendering it suitable for application in in-situ HRTEM experiments.",
    "authors": [
      "Brian Lee",
      "Meng Li",
      "Judith C Yang",
      "Dmitri N Zakharov",
      "Xiaohui Qu"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04050",
    "title": "High-order two-component fractional quantum Hall states around filling factor $ν= 1$",
    "abstract": "Two-component fractional quantum Hall (2C-FQH) states in electron bilayers have been known for decades, yet their experimental realization remained limited to low-order fractions. Here we report on several families of high-order 2C-FQH states that emerge when an in-plane magnetic field drives a controlled monolayer-to-bilayer transition in an ultra-high-mobility GaAs quantum well. These families of states proliferate symmetrically toward the filling factor $\\nu = 1$, from both $\\nu = 2/3$ and $\\nu = 4/3$, thereby respecting particle-hole symmetry. Surprisingly, many unbalanced states (with unequal layer fillings) are more robust than their parent balanced states, defying the expected hierarchy of Jain sequences. Our findings substantially expand the known landscape of 2C-FQH states, highlighting the unexpected richness of the bilayer quantum Hall regime and opening new routes for probing the interplay of symmetry, topology, and interactions in quantum Hall systems.",
    "authors": [
      "E. Bell",
      "K. W. Baldwin",
      "L. N. Pfeiffer",
      "K. W. West",
      "M. A. Zudov"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04055",
    "title": "Configurable antiferromagnetic domains and lateral exchange bias in atomically thin CrPS4",
    "abstract": "Interfacial exchange coupling between antiferromagnets (AFMs) and ferromagnets (FMs) crucially makes it possible to shift the FM hysteresis, known as exchange bias, and to switch AFM states. Two-dimensional magnets unlock opportunities to combine AFM and FM materials; however, the buried AFM-FM interfaces obtained by stacking remains challenging to understand. Here we demonstrate interfacial control via intralayer exchange coupling in the layered AFM CrPS$_4$, where connected even and odd layers realize pristine lateral interfaces between AFM-like and FM-like regions. We distinguish antiphase even-layer states by scanning nitrogen-vacancy centre (NV) magnetometry due to a weak surface magnetization. This surface magnetization enables control over the even-layer state, with different regions switching at distinct fields due to their own lateral couplings. We toggle three AFM domains adjacent to a FM-like region and demonstrate a tunable multilevel exchange bias. Our nanoscale visualization unveils the microscopic origins of exchange bias and advances single two-dimensional crystals for hybrid AFM-FM technologies.",
    "authors": [
      "Yu-Xuan Wang",
      "Thomas K. M. Graham",
      "Ricardo Rama-Eiroa",
      "Md Ariful Islam",
      "Mohammad H. Badarneh",
      "Rafael Nunes Gontijo",
      "Ganesh Prasad Tiwari",
      "Tibendra Adhikari",
      "Xin-Yue Zhang",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Claire Besson",
      "Elton J. G. Santos",
      "Zhong Lin",
      "Brian B. Zhou"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04056",
    "title": "Sign-Resolved Statistics and the Origin of Bias in Quantum Monte Carlo",
    "abstract": "Quantum simulations are a powerful tool for exploring strongly correlated many-body phenomena. Yet, their reach is limited by the fermion sign problem, which causes configuration weights to become negative, compromising statistical sampling. In auxiliary-field Quantum Monte Carlo calculations of the doped Hubbard model, neglecting the sign ${\\cal S}$ of the weight leads to qualitatively wrong results -- most notably, an apparent suppression rather than enhancement of $d$-wave pairing at low temperature. Here we approach the problem from a different perspective: instead of identifying negative-weight paths, we examine the statistics of measured observables in a sign-resolved manner. By analyzing histograms of key quantities (kinetic energy, antiferromagnetic structure factor, and pair susceptibilities) for configurations with ${\\cal S}=\\pm1$, we derive an exact relation linking the bias from ignoring the sign to the difference between sign-resolved means, $\\Delta\\mu$, and the average sign, $\\langle {\\cal S}\\rangle$. Our framework provides a precise diagnostic of the origin of measurement bias in Quantum Monte Carlo and clarifies why observables such as the $d$-wave susceptibility are especially sensitive to the sign problem.",
    "authors": [
      "Ryan Larson",
      "Rubem Mondaini",
      "Richard T. Scalettar"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04063",
    "title": "Transport evidence of surface states in magnetic topological insulator MnBi2Te4",
    "abstract": "Magnetic topological insulators can host chiral 1D edge channels at zero magnetic field, when a magnetic gap opens at the Dirac point in the band structure of 2D topological surface states, lead- ing to the quantum anomalous Hall effect in ultra-thin nanostructures. For thicker nanostructures, quantization is severely reduced by the co-existence of edge states with other quasi-particles, usually considered as bulk states. Yet, surface states also exist above the magnetic gap, but it remains difficult to identify electronic subbands by electrical measurements due to strong disorder. Here we unveil surface states in MnBi2Te4 nanostructures, using magneto-transport in very-high magnetic fields up to 55 T, giving evidence of Shubnikov-de-Haas oscillations above 40 T. A detailed analysis confirms the 2D nature of these quantum oscillations, thus establishing an alternative method to photoemission spectroscopy for the study of topological surface states in magnetic topological insulators, using Landau level spectroscopy.",
    "authors": [
      "Michael Wissmann",
      "Romain Giraud",
      "Börge Mehlhorn",
      "Maxime Leroux",
      "Mathieu Pierre",
      "Michel Goiran",
      "Walter Escoffier",
      "Bernd Büchner",
      "Anna Isaeva",
      "Joseph Dufouleur",
      "Louis Veyrat"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02202",
    "title": "Progress in quantum metrology and applications for optical atomic clocks",
    "abstract": "Quantum entanglement offers powerful opportunities for enhancing measurement sensitivity beyond classical limits, with optical atomic clocks serving as a leading platform for such advances. This chapter introduces the principles of entanglement-enhanced quantum metrology and explores their applications to timekeeping. We review the theoretical framework of quantum phase estimation, comparing frequentist and Bayesian approaches, and discuss paradigmatic entangled states such as spin-squeezed and GHZ states. Particular emphasis is placed on the challenges posed by decoherence, which constrain the practical advantages that can be realized in large-scale devices. The discussion then turns to frequency estimation in atomic clocks, highlighting how experimental constraints shape the translation of abstract quantum limits into real performance gains. Finally, we outline emerging directions of contemporary quantum metrology. Together, these developments underscore the increasingly close interplay between quantum information processing and precision metrology.",
    "authors": [
      "Raphael Kaubruegger",
      "Adam M. Kaufman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03050",
    "title": "Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling",
    "abstract": "Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.",
    "authors": [
      "Peter Hedström",
      "Victor Lamelas Cubero",
      "Jón Sigurdsson",
      "Viktor Österberg",
      "Satish Kolli",
      "Joakim Odqvist",
      "Ziyong Hou",
      "Wangzhong Mu",
      "Viswanadh Gowtham Arigela"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03135",
    "title": "Many-body symmetry-protected zero boundary modes of synthetic photo-magnonic crystals",
    "abstract": "The topological classification of insulators and superconductors, the \"ten-fold way\", is grounded on fermionic many-body symmetries and has had a dramatic impact on many fields of physics. Therefore, it seems equally important to investigate a similar approach for bosons as tightly analogous to the fermionic prototype as possible. There are, however, several obstacles coming from the fundamental physical differences between fermions and bosons. Here, we propose a potentially optimal way forward: a theory of free boson topology (topological classification and bulk-boundary correspondence) protected by bosonic many-body symmetry operations, namely, squeezing transformations, particle number, and bosonic time reversal. We identify two symmetry classes that are topologically non-trivial in one dimension. They include key models like the bosonic Kitaev chain, protected by a squeezing symmetry within our framework, and the celebrated bosonic SSH model, protected by a squeezing symmetry and particle number. To provide a robust experimental platform for testing our theory, we introduce a new quantum meta-material: photo-magnonic crystals. They consist of arrays of interconnected photo-magnonic cavities. They are remarkable for their experimental flexibility and natural affinity for displaying band topological physics at microwave frequencies. We engineer a many-body symmetry-protected topological photo-magnonic chain with boundary modes mandated by a Pfaffian invariant. Using an electromagnetic finite-element modelling, we simulate its reflection and transmission and identify experimental signatures of its boundary modes. The experimental tuning of the crystal to its symmetry-protected topological phase is also addressed. Our modelling of the photo-magnonic chain provides a thorough blueprint for its experimental realisation and the unambiguous observation of its exotic physics.",
    "authors": [
      "Alan Gardin",
      "Emilio Cobanera",
      "Giuseppe C. Tettamanzi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03149",
    "title": "A high-order regularized delta-Chebyshev method for computing spectral densities",
    "abstract": "We introduce a numerical method for computing spectral densities, and apply it to the evaluation of the local density of states (LDOS) of sparse Hamiltonians derived from tight-binding models. The approach, which we call the high-order delta-Chebyshev method, can be viewed as a variant of the popular regularized Chebyshev kernel polynomial method (KPM), but it uses a high-order accurate approximation of the $\\delta$-function to achieve rapid convergence to the thermodynamic limit for smooth spectral densities. The costly computational steps are identical to those for KPM, with high-order accuracy achieved by an inexpensive post-processing procedure. We apply the algorithm to tight-binding models of graphene and twisted bilayer graphene, demonstrating high-order convergence to the LDOS at non-singular points.",
    "authors": [
      "Jinjing Yi",
      "Daniel Massatt",
      "Andrew Horning",
      "Mitchell Luskin",
      "J. H. Pixley",
      "Jason Kaye"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03162",
    "title": "Classical Thermometry of Quantum Annealers",
    "abstract": "Quantum annealers are emerging as programmable, dynamical experimental platforms for probing strongly correlated spin systems. Yet key thermal assumptions, chiefly a Gibbs-distributed output ensemble, remain unverified in the large-scale regime. Here, we experimentally and quantitatively assess Gibbs sampling fidelity across system sizes spanning over three orders of magnitude. We explore a wide parameter space of coupling strengths, system sizes, annealing times, and D-wave hardware architectures. We find that the naively assumed scaling law for the effective temperature requires a non-negligible, coupling-independent offset that is robust across machines and parameter regimes, quantifying residual non-thermal effects that still conform to an effective Gibbs description. These non-idealities are further reflected in a systematic discrepancy between the physical temperature inferred from the sampled ensemble and the nominal cryogenic temperature of the device. Our results systematically assess the viability of quantum annealers as experimental platforms for probing classical thermodynamics, correct previous assumptions, and provide a physically grounded thermometry framework to benchmark these machines for future thermodynamic experiments.",
    "authors": [
      "George Grattan",
      "Pratik Sathe",
      "Cristiano Nisoli"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03167",
    "title": "Energy Reflection and Transmission of Interfaces in $T\\bar{T}$-deformed CFT",
    "abstract": "Conformal interfaces gluing a pair of two-dimensional conformal field theories enjoy a large degree of universality in terms of the coefficients of reflection and transmission of energy, that describe the scattering of conformal matter at the interface. In this article, we study these coefficients beyond conformality, by gluing a pair of $T\\bar T$-deformed 2D CFTs across an interface, which requires the condition $c_L \\mu_L = c_R \\mu_R $ to be obeyed. We show that, at least when the interface admits a holographic description, the $T\\bar T$ deformation of the CFTs can be extended to the interface. We propose a generalization of the linear matching condition in the universal sector of the undeformed ICFT to a non-linear one, which is captured by a universal antisymmetric \\emph{transmission function} of the incoming fluxes. We employ the flow equations of the $T\\bar T$-deformed CFTs to compute this function in two special classes of states, namely the non-equilibrium steady state (NESS) and scattering state. We show that the results can also be reproduced using holographic techniques in the bulk dual of these states.",
    "authors": [
      "Avik Banerjee",
      "Giuseppe Policastro"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03274",
    "title": "Excess work in counterdiabatic driving",
    "abstract": "Many years have passed since the conception of the quintessential method of shortcut to adiabaticity known as counterdiabatic driving (or transitionless quantum driving). Yet, this method appears to be energetically cost-free and thus continually challenges the task of quantifying the amount of energy it demands to be accomplished. This paper proposes that the energy cost of controlling a closed quantum system using the counterdiabatic method can also be assessed using the instantaneous excess work during the process and related quantities, as the time-averaged excess work. Starting from the Mandelstam-Tamm bound for driven dynamics, we have shown that the speed-up of counterdiabatic driving is linked with the spreading of energy between the eigenstates of the total Hamiltonian, which is necessarily accompanied by transitions between these eigenstates. Nonetheless, although excess work can be used to quantify energetically these transitions, it is well known that the excess work is zero throughout the entire process under counterdiabatic driving. To recover the excess work as an energetic cost quantifier for counterdiabatic driving, we will propose a different interpretation of the parameters of the counterdiabatic Hamiltonian, leading to an excess work different from zero. We have illustrated our findings with the Landau-Zener model.",
    "authors": [
      "Lucas P. Kamizaki",
      "Marcus V. S. Bonança"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03277",
    "title": "On-the-Fly Cavity-Molecular Dynamics of Vibrational Polaritons",
    "abstract": "In this work, we combine the density functional tight-binding (DFTB) approach with a light-matter Hamiltonian beyond the long-wavelength approximation to propagate the dynamics of vibrational polaritons formed by coupling molecular vibrations to confined radiation inside a Fabry-Pérot optical cavity. Here, we develop a parallelized propagation scheme with lightweight inter-CPU communication by exploiting the sparse nature of the light-matter interactions in the real space representation. We find that the computationally expensive Born charges required for our propagation can be replaced with the computationally inexpensive Mulliken charges to obtain qualitatively accurate linear spectra especially when the nonlinearity (arising from molecular vibrations) of the light-matter interaction term is not substantial. However, the same approach may not be suitable to be used for studying cavity modification of energy transport or chemical dynamics as this approximation leads to spurious heating of the light-matter hybrid system. We demonstrate the utility of this on-the-fly approach to compute angle resolved polaritonic spectra of water. We implement our approach as an open-source computational package, CavOTF, which is available on GitHub.",
    "authors": [
      "Sachith Wickramasinghe",
      "Amirhosein Amini",
      "Arkajit Mandal"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03341",
    "title": "Quench dynamics of the quantum XXZ chain with staggered interactions: Exact results and simulations on digital quantum computers",
    "abstract": "We investigate quench dynamics in the quantum $S=1/2$ XXZ antiferromagnetic chain with staggered and anisotropic interactions in the flat-band limit. Our quench protocol interchanges the odd- and even-bond strengths of a fully dimerized chain, enabling us to derive exact time-dependent states for arbitrary even system sizes by working in the Bell basis. We obtain closed-form, size-independent expressions for the von Neumann and second-order Rényi entanglement entropies. We further calculate exact Loschmidt echoes and the corresponding return rate functions across various anisotropies and system sizes, and identify Loschmidt zeros in finite chains. Our analysis reveals the precise conditions on the anisotropy parameter that govern the periodicity of the dynamical observables. In addition to the analytic study, we perform two types of numerical experiments on IBM-Q quantum devices. First, we use the Hadamard test to estimate the Bell-basis expansion coefficients and reconstruct the dynamical states, achieving accurate entanglement entropies and the Loschmidt echo for small systems. Second, we implement Trotter-error-free time-evolution circuits combined with randomized Pauli measurements. Post-processing via statistical correlations and classical shadows yields reliable estimates of the second-order Rényi entanglement entropy and the Loschmidt echo, showing satisfactory agreement with exact results.",
    "authors": [
      "Ching-Tai Huang",
      "Yu-Cheng Lin",
      "Ferenc Igloi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03362",
    "title": "Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits",
    "abstract": "Parametric amplification is essential for quantum measurement, enabling the amplification of weak microwave signals with minimal added noise. While Josephson-junction-based amplifiers have become standard in superconducting quantum circuits, their magnetic sensitivity, limited saturation power, and sub-kelvin operating requirements motivate the development of alternative nonlinear platforms. Here we demonstrate a two-mode kinetic-inductance parametric amplifier based on a pair of capacitively coupled Kerr-nonlinear resonators fabricated from NbTiN and NbN thin films. The distributed Kerr nonlinearity of these materials enables nondegenerate four-wave-mixing amplification with gains approaching 40 dB, gain-bandwidth products up to 6.9 MHz, and 1-dB compression powers two to three orders of magnitude higher than those of state-of-the-art Josephson amplifiers. A coupled-mode theoretical model accurately captures the pump-induced modification of the hybridized modes and quantitatively reproduces the observed signal and idler responses. The NbN device exhibits a significantly larger Kerr coefficient and superior gain-bandwidth performance, highlighting the advantages of high-kinetic-inductance materials. Our results establish coupled kinetic-inductance resonators as a robust platform for broadband, high-power, and magnetically resilient quantum-limited amplification, offering a scalable route for advanced readout in superconducting qubits, spin ensembles, quantum dots, and other microwave-quantum technologies.",
    "authors": [
      "Danial Davoudi",
      "Abdul Mohamed",
      "Shabir Barzanjeh"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03382",
    "title": "Structural and Dynamical Crossovers in Dense Electrolytes",
    "abstract": "Electrostatic interactions fundamentally govern the structure and transport of electrolytes. In concentrated electrolytes, however, electrostatic and steric correlations, together with ion-solvent coupling, give rise to complex behavior, such as underscreening, that remains challenging to explain despite extensive theoretical effort. Using molecular dynamics simulations of primitive electrolytes with and without space-filling solvent particles, we elucidate the structural and dynamical crossovers and their connection that emerge with increasing salt concentration. Explicit-solvent electrolytes exhibit a screening transition from a charge-dominated dilute regime to a density-dominated concentrated regime, accompanied by dynamical crossovers in ion self-diffusion and ion-pair lifetimes. These dynamical crossovers display a marked discontinuity, unlike the smoother variation of the screening crossover, which originates from short-range ion-counterion structures. Despite the pronounced growth of ionic clusters, their percolation transition does not appear to be directly coupled to the onset of these crossovers. Both structural and dynamical behaviors are found to depend sensitively on ion-solvent coupling: implicit-solvent electrolytes exhibit a screening transition between two charge-dominated regimes, accompanied by qualitatively distinct dynamical behavior. Finally, we demonstrate that the diffusion-corrected ion-pair lifetime provides a consistent descriptor linking ionic structure and dynamics across electrolyte systems.",
    "authors": [
      "Daehyeok Kim",
      "Taejin Kwon",
      "Jeongmin Kim"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03426",
    "title": "Zero-Waste Biorefinery: Pyrolysis of Fermentation Residues into Catalytic Biochar for Circular Biohydrogen Systems",
    "abstract": "This study presents a closed-loop biorefinery strategy that thermochemically upcycles fermentation residues (FRs) from photo-fermentative biohydrogen production (PFHP) into functional biochar catalysts, thereby enhancing the efficiency of the initial PFHP process. Four FRs derived from hydrothermal and ethylene glycol-pretreated corn stover were pyrolyzed at 700°C. Multi-model kinetic analyses revealed diffusion-controlled mechanisms with activation energies ranging from 157 to 278 kJ/mol, while thermodynamic profiling highlighted the influence of feedstock composition on reaction spontaneity and entropy. Pyrolysis effectively restored porosity compromised during fermentation, yielding biochar with tailored properties: microporous BC3 (185 m2/g) from oxygen-rich precursors and mesoporous BC4 (76.58 m2/g) from graphitized residues. When reintroduced into PFHP, BC3 maximized cumulative hydrogen yield (570 mL) via pH buffering, and BC4 achieved the highest production rate (14.91 mL/h) through electron shuttle mechanisms. The integrated process concurrently generated syngas, bio-oil, and catalytic biochar, enabling waste valorization, renewable energy output, and process enhancement within a circular bioeconomy framework.",
    "authors": [
      "Muhammad Shahzaib"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03530",
    "title": "Edge bits in average symmetry protected topological mixed state",
    "abstract": "Edge bit in an average symmetry protected topological (ASPT) mixed state is studied. The state is protected by one strong $Z_2$ and one weak (average) $Z_2$ symmetries. As analogous objects of pure symmetry protected topological (SPT) states, the ASPT possesses edge bits. In particular, the analogous operator response exists, that is, symmetry fractionalization. The fractionalization preserves the presence of the ASPT in the bulk, and the fractionalized edge operators acting on the edge bits of the ASPT. %analogous to the ones in the pure SPTs. In this work, based on the cluster model and by employing Choi mapping, we discuss generic features of the edge bits and numerically clarify the behavior of the edge bits and their robustness for varying decoherence and perturbative interactions. By using an operator-space mutual information (OSMI), we track the flow of quantum correlations between the two edges. Remarkably, even in the ASPT regime, a finite portion of the initial edge-to-edge correlation survives.",
    "authors": [
      "Yoshihito Kuno"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03748",
    "title": "Widefield Quantum Sensor for Vector Magnetic Field Imaging of Micromagnetic Structures",
    "abstract": "Many spintronic, magnetic-memory, and neuromorphic devices rely on spatially varying magnetic fields. Quantitatively imaging these fields with full vector information over extended areas remains a major challenge. Existing probes either offer nanoscale resolution at the cost of slow scanning, or widefield imaging with limited vector sensitivity or material constraints. Quantum sensing with nitrogen-vacancy (NV) centers in diamond promises to bridge this gap, but a practical camera-based vector magnetometry implementation on relevant microstructures has not been demonstrated. Here we adapt a commercial widefield microscope to implement a camera-compatible pulsed optically detected magnetic resonance protocol to reconstruct stray-field vectors from microscale devices. By resolving the Zeeman shifts of the four NV orientations, we reconstruct the stray-field vector generated by microfabricated permalloy structures that host multiple stable remanent states. Our implementation achieves a spatial resolution of $\\approx 0.52 ~\\mu\\mathrm{m}$ across an $83~\\mu\\mathrm{m} \\times 83~\\mu\\mathrm{m}$ field of view and a peak sensitivity of $ (828 \\pm 142)~\\mathrm{nT\\,Hz^{-1}}$, with acquisition times of only a few minutes. These results establish pulsed widefield NV magnetometry on standard microscopes as a practical and scalable tool for routine vector-resolved imaging of complex magnetic devices.",
    "authors": [
      "Orlando D. Cunha",
      "Filipe Camarneiro",
      "João P. Silva",
      "Hariharan Nhalil",
      "Ariel Zaig",
      "Lior Klein",
      "Jana B. Nieder"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03750",
    "title": "Universally Converging Representations of Matter Across Scientific Foundation Models",
    "abstract": "Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.",
    "authors": [
      "Sathya Edamadaka",
      "Soojung Yang",
      "Ju Li",
      "Rafael Gómez-Bombarelli"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03753",
    "title": "Real-Time Coupled Electron-Nuclear Dynamics of Chemical Bond Formation: Hydrogen Scattering from a Semiconductor Surface",
    "abstract": "A first-principles coupled electron-nuclear dynamics simulation based on real-time, time-dependent density functional theory and Ehrenfest dynamics quantitatively repro-duces bimodal translational energy loss and angular distributions observed in experiment for hydrogen atom scattering from Ge(111)-c(2*8). The theory elucidates a site-selective mechanism of electronically nonadiabatic energy transfer associated with the formation of different Ge-H bonds. When a hydrogen atom approaches a Ge rest-atom, it is strongly accelerated toward the potential minimum forming a transient Ge-H bond and then re-flected by the repulsive wall. This transient bond formation triggers an ultrafast electron transfer event from the rest-atom to an adjacent Ge-adatom, involving several crossings between valence and conduction bands of the substrate. Electronic equilibration is impos-sible within such a short time (Born-Oppenheimer failure) allowing the H-atom kinetic energy to be converted to inter-band electronic excitation of the substrate. H-atom colli-sions at other Ge atoms also form a transient bond but exhibit no electronic excitation, resulting in distinctly less efficient energy loss in scattered H-atoms. The nucle-ar-to-electronic energy transfer observed in this system reflects the electronic dynamics of covalent bond formation at a semiconductor surface, a mechanism that is quite distinct from previously identified nonadiabatic energy transfer mechanisms at metal surfaces mediated by electronic friction or transient negative ions.",
    "authors": [
      "Jialong Shi",
      "Lingjun Zhu",
      "Florian Nitz",
      "Oliver Bünermann",
      "Alec M. Wodtke",
      "Hua Guo",
      "Bin Jiang"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03850",
    "title": "Density of states of quantum systems from free probability theory: a brief overview",
    "abstract": "We provide a brief overview of approaches for calculating the density of states of quantum systems and random matrix Hamiltonians using the tools of free probability theory. For a given Hamiltonian of a quantum system or a generic random matrix Hamiltonian, which can be written as a sum of two non-commutating operators, one can obtain an expression for the density of states of the Hamiltonian from the known density of states of the two component operators by assuming that these operators are mutually free and by using the free additive convolution. In many examples of interacting quantum systems and random matrix models, this procedure is known to provide a reasonably accurate approximation to the exact numerical density of states. We review some of the examples that are known in the literature where this procedure works very well, and also discuss some of the limitations of this method in situations where the free probability approximation fails to provide a sufficiently accurate description of the exact density of states. Subsequently, we describe a perturbation scheme that can be developed from the subordination formulas for the Cauchy transform of the density of states and use it to obtain approximate analytical expressions for the density of states in various models, such as the Rosenzweig-Porter random matrix ensemble and the Anderson model with on-site disorder.",
    "authors": [
      "Keun-Young Kim",
      "Kuntal Pal"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03853",
    "title": "Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices",
    "abstract": "Extensive theoretical and experimental work has established high-fidelity electron shuttling in Si/SiGe systems, whereas demonstrations in Si/SiO2 (SiMOS) remain at an early stage. To help address this, we perform full 3D simulations of conveyor-belt charge shuttling in a realistic SiMOS device, building on earlier 2D modelling. We solve the Poisson and time-dependent Schrodinger equations for varying shuttling speeds and gate voltages, focusing on potential pitfalls of typical SiMOS devices such as oxide-interface roughness, gate fabrication imperfections, and charge defects along the transport path. The simulations reveal that for low clavier-gate voltages, the additional oxide screening in multi-layer gate architectures causes conveyor-belt shuttling to collapse to the bucket-brigade mode, inducing considerable orbital excitation in the process. Increasing the confinement restores conveyor-belt operation, which we find to be robust against interface roughness, gate misalignment, and charge defects buried in the oxide. However, our results indicate that defects located at the Si/SiO2-interface can induce considerable orbital excitation. For lower conveyor gate biases, positive defects in the transport channel can even capture passing electrons. Hence we identify key challenges and find operating regimes for reliable charge transport in SiMOS architectures.",
    "authors": [
      "Jack J. Turner",
      "Christian W. Binder",
      "Guido Burkard",
      "Andrew J. Fisher"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03898",
    "title": "Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method",
    "abstract": "The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size.",
    "authors": [
      "Yu Wang",
      "Martina Nibbi",
      "Maxine Luo",
      "Isabel Nha Minh Le",
      "Yanbin Chen",
      "J. Ignacio Cirac",
      "Christian Mendl"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03935",
    "title": "Thermodynamics of an Open $\\mathcal{PT-}$Symmetric Quantum System",
    "abstract": "For a subclass of a general $\\mathcal{PT}-$symmetric Hamiltonian obeying anti-commutation relation with its conjugate, a Hermitian basis is found that spans the bi-orthonormal energy eigenvectors. Using the modified projectors constructed from these eigenvectors, the generalized density matrix of the $\\mathcal{PT}-$symmetric evolution is calculated, and subsequently, ergotropy for a closed system is obtained. The $\\mathcal{PT}-$symmetric system, in an open system scenario, is studied to understand ergotropy under different regimes of non-Hermiticity of the Hamiltonian. The consistency of the three laws of thermodynamics for the $\\mathcal{PT}-$symmetric system in an open system scenario is also analyzed.",
    "authors": [
      "Baibhab Bose",
      "Devvrat Tiwari",
      "Subhashish Banerjee"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04024",
    "title": "Predicting parameters of a model cuprate superconductor using machine learning",
    "abstract": "The computational complexity of calculating phase diagrams for multi-parameter models significantly limits the ability to select parameters that correspond to experimental data. This work presents a machine learning method for solving the inverse problem - forecasting the parameters of a model Hamiltonian for a cuprate superconductor based on its phase diagram. A comparative study of three deep learning architectures was conducted: VGG, ResNet, and U-Net. The latter was adapted for regression tasks and demonstrated the best performance. Training the U-Net model was performed on an extensive dataset of phase diagrams calculated within the mean-field approximation, followed by validation on data obtained using a semi-classical heat bath algorithm for Monte Carlo simulations. It is shown that the model accurately predicts all considered Hamiltonian parameters, and areas of low prediction accuracy correspond to regions of parametric insensitivity in the phase diagrams. This allows for the extraction of physically interpretable patterns and validation of the significance of parameters for the system. The results confirm the promising potential of applying machine learning to analyze complex physical models in condensed matter physics.",
    "authors": [
      "V. A. Ulitko",
      "D. N. Yasinskaya",
      "S. A. Bezzubin",
      "A. A. Koshelev",
      "Y. D. Panov"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2309.05481",
    "title": "Photovoltaic potential of tin perovskites revealed through layer-by-layer investigation of optoelectronic and charge transport properties",
    "abstract": "Tin perovskites are the most promising environmentally friendly alternative to lead perovskites. Among tin perovskites, FASnI3 (CH4N2SnI3) shows optimum band gap, and easy processability. However, the performance of FASnI3 based solar cells is incomparable to lead perovskites for several reasons, including energy band mismatch between the perovskite absorber film and the charge transporting layers (CTLs) for both types of carriers, i.e., for electrons (ETLs) and holes (HTLs). However, the band diagrams in the literature are inconsistent, and the charge extraction dynamics are poorly understood. In this paper, we study the energy band positions of FASnI3 based perovskites using Kelvin probe (KP) and photoelectron yield spectroscopy (PYS) to provide a precise band diagram of the most used device stack. In addition, we analyze the defects within the current energetic landscape of tin perovskites. We uncover the role of bathocuproine (BCP) in enhancing the electron extraction at the fullerene C60/BCP interface. Furthermore, we used transient surface photovoltage (tr-SPV) for the first time for tin perovskites to understand the charge extraction dynamics of the most reported HTLs such as NiOx and PEDOT, and ETLs such as C60, ICBA, and PCBM. Finally, we used Hall effect, KP, and time-resolved photoluminescence (TRPL) to estimate an accurate value of the p-doping concentration in FASnI3 and showed a consistent result of 1.5 * 1017 cm-3. Our findings prove that the energetic system of tin halide perovskites is deformed and should be redesigned independently from lead perovskites to unlock the full potential of tin perovskites.",
    "authors": [
      "Mahmoud H. Aldamasy",
      "Artem Musiienko",
      "Marin Rusu",
      "Davide Regaldo",
      "Shengnan Zho",
      "Hannes Hampel",
      "Chiara Frasca",
      "Zafar Iqbal",
      "Thomas W. Gries",
      "Guixiang Li",
      "Ece Aktas",
      "Giuseppe Nasti",
      "Meng Li",
      "Jorge Pascual",
      "Noor Titan Putri Hartono",
      "Qiong Wang",
      "Thomas Unold",
      "Antonio Abate"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.01682",
    "title": "Conservation, crossing symmetry, and completeness in diagrammatic theories",
    "abstract": "The diagrammatic analysis of interacting particle assemblies harbors a fundamental mismatch between two of its main implementations: Phi-derivable (conserving) approximations and parquet (crossing symmetric) models. No termwise expansion, short of the exact theory itself, can be both conserving and crossing symmetric. This work applies the Kraichnan embedded-Hamiltonian formalism for strongly coupled systems to investigate consistency of the interplay between purely pair-mediated correlations and pair-irreducible ones. The approach sheds a different light on the issue of crossing symmetry versus conservation. In the process, the parquet equations acquire a different formulation.",
    "authors": [
      "Frederick Green"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.11339",
    "title": "Inner structure of the many-body localization transition and the fulfillment of the Harris criterion",
    "abstract": "We treat the disordered Heisenberg model in 1D as the standard model of many-body localization (MBL). Two new and independent order parameters stemming solely from the half-chain von Neumann entanglement entropy $S_{\\textrm{vN}}$ are introduced to probe the eigenstate phase transition in this model. From the symmetry-endowed entropy decomposition, they are the probability distribution deviation $|d(p_n)|$ and the von Neumann entropy $S_{\\textrm{vN}}^{n}(D_n\\!=\\!\\mbox{max})$ of the maximally dimensional symmetry subdivision. The finite-size scaling reveals that $\\{p_n\\}$ drives the localization transition, preceded by a thermalization breakdown transition governed by $\\{S_{\\textrm{vN}}^{n}\\}$. For the noninteracting case, these transitions coincide, but in the interacting circumstance they separate. Such separability creates an intermediate phase regime and discriminates between the Anderson and MBL transitions. One obstacle whose solution eludes the community to date concerns the violation of the Harris criterion in most numerical investigations of MBL. Upon elucidating the mutually independent measures comprising $S_{\\textrm{vN}}$, it becomes clear that the previous studies may lack the resolution to pinpoint thus potentially overlook the crucial internal structure of the transition. We show that after this necessary decomposition, the universal critical exponents for both transitions of $|d(p_n)|$ and $S_{\\textrm{vN}}^{n}(D_n\\!=\\!\\mbox{max})$ fulfill the Harris criterion: $\\nu\\approx2\\ (\\nu\\approx1.5)$ for quench (quasirandom) disorder. Our work puts forth symmetry combined with entanglement as an organization principle for the generic eigenstate matter and phase transition.",
    "authors": [
      "Jie Chen",
      "Chun Chen",
      "Xiaoqun Wang"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2404.14744",
    "title": "Resolving exciton and polariton multi-particle correlations in an optical microcavity in the strong coupling regime",
    "abstract": "Multi-particle correlations of exciton-polaritons and reservoir-excitons in the strong light-matter coupling regime dictate the quantum dynamics of optical microcavities. In this letter, we examine the many-body exciton-polariton dynamics in a Fabry-Pérot microcavity of a two-dimensional metal-halide semiconductor over timescales involving polariton ($\\ll 1$\\,ps) and exciton ($\\gg 1$\\,ps) scattering. We find enhanced exciton nonlinear dynamics in the microcavity versus the bare semiconductor, concomitant with ultrafast polariton scattering dynamics. We measure, by means of coherent spectroscopy, the coupling between exciton-polaritons, bright excitons, and reservoir-excitons that highlight the complex scattering landscape that fundamentally drives polariton condensation.",
    "authors": [
      "Victoria Quirós-Cordero",
      "Esteban Rojas-Gatjens",
      "Martín Gómez-Dominguez",
      "Hao Li",
      "Carlo A. R. Perini",
      "Natalie Stingelin",
      "Juan-Pablo Correa-Baena",
      "Eric R. Bittner",
      "Ajay Ram Srimath Kandada",
      "Carlos Silva-Acuña"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.02406",
    "title": "Observation of a supersolid phase in a spin-orbit coupled exciton-polariton Bose-Einstein condensate at room temperature",
    "abstract": "In Bose-Einstein condensates (BEC), spin-orbit coupling (SOC) produces supersolidity. It is a peculiar state of matter, which, in addition to the superfluid behaviour shows periodic density modulation typical for crystals. Here, we report the fabrication of a new type of optical microcavity allowing to achieve room-temperature supersolidity for a quantum fluid of light. The microcavity is filled with a nematic liquid crystal (LC) and two layers of the organic polymer MeLPPP hosting exciton resonances. We demonstrate exciton-polariton condensation in the two distinct degenerate minima of the dispersion created by the LC induced Rashba-Dresselhaus (RD) SOC. The condensate real-space distribution shows density stripes located randomly from one condensate realization to another despite the presence of a random disorder potential. This demonstrates the immunity of stripes against disorder (that is, superfluidity) and the spontaneous breaking of translational invariance. We also report the random appearance of vortices via the Kibble-Zurek mechanism, another smoking gun of superfluidity.",
    "authors": [
      "Marcin Muszyński",
      "Pavel Kokhanchik",
      "Rafał Mirek",
      "Darius Urbonas",
      "Pietro Tassan",
      "Piotr Kapuściński",
      "Przemysław Oliwa",
      "Ioannis Georgakilas",
      "Thilo Stöferle",
      "Rainer F. Mahrt",
      "Michael Forster",
      "Ullrich Scherf",
      "Dmitriy Dovzhenko",
      "Rafał Mazur",
      "Przemysław Morawiak",
      "Wiktor Piecek",
      "Przemysław Kula",
      "Barbara Piętka",
      "Dmitry Solnyshkov",
      "Guillaume Malpuech",
      "Jacek Szczytko"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.20132",
    "title": "Microscopic properties of fractional vortices and domain walls in three-band $s+is$ superconductors",
    "abstract": "Several experimental observations of objects carrying fractional flux quanta in superconductors were recently reported. Here, we provide microscopic solutions for vortices carrying a variable fraction of magnetic flux quantum and domain walls in a three-band $s + is$ superconductor and investigate their properties. We obtain solutions in a fully self-consistent treatment of a microscopic three-band Bogoliubov-de-Gennes model. This demonstrates the characteristic patterns for the magnetic field distribution. The microscopic formalism allows for calculating tunneling conductance that may be used to distinguish fractional vortices from conventional single flux quanta vortices in Scanning Tunneling Microscopy.",
    "authors": [
      "Igor Timoshuk",
      "Egor Babaev"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.08873",
    "title": "Coherent X-rays reveal anomalous molecular diffusion and cage effects in crowded protein solutions",
    "abstract": "Understanding protein motion within the cell is crucial for predicting reaction rates and macromolecular transport in the cytoplasm. A key question is how crowded environments affect protein dynamics through hydrodynamic and direct interactions at molecular length scales. Using megahertz X-ray Photon Correlation Spectroscopy (MHz-XPCS) at the European X-ray Free Electron Laser (EuXFEL), we investigate ferritin diffusion at microsecond time scales. Our results reveal anomalous diffusion, indicated by the non-exponential decay of the intensity autocorrelation function $g_2(q,t)$ at high concentrations. This behavior is consistent with the presence of cage-trapping in between the short- and long-time protein diffusion regimes. Modeling with the $\\delta\\gamma$-theory of hydrodynamically interacting colloidal spheres successfully reproduces the experimental data by including a scaling factor linked to the protein direct interactions. These findings offer new insights into the complex molecular motion in crowded protein solutions, with potential applications for optimizing ferritin-based drug delivery, where protein diffusion is the rate-limiting step.",
    "authors": [
      "Anita Girelli",
      "Maddalena Bin",
      "Mariia Filianina",
      "Michelle Dargasz",
      "Nimmi Das Anthuparambil",
      "Johannes Möller",
      "Alexey Zozulya",
      "Iason Andronis",
      "Sonja Timmermann",
      "Sharon Berkowicz",
      "Sebastian Retzbach",
      "Mario Reiser",
      "Agha Mohammad Raza",
      "Marvin Kowalski",
      "Mohammad Sayed Akhundzadeh",
      "Jenny Schrage",
      "Chang Hee Woo",
      "Maximilian D. Senft",
      "Lara Franziska Reichart",
      "Aliaksandr Leonau",
      "Prince Prabhu Rajaiah",
      "William Chèvremont",
      "Tilo Seydel",
      "Jörg Hallmann",
      "Angel Rodriguez-Fernandez",
      "Jan-Etienne Pudell",
      "Felix Brausse",
      "Ulrike Boesenberg",
      "James Wrigley",
      "Mohamed Youssef",
      "Wei Lu",
      "Wonhyuk Jo",
      "Roman Shayduk",
      "Trey Guest",
      "Anders Madsen",
      "Felix Lehmkühler",
      "Michael Paulus",
      "Fajun Zhang",
      "Frank Schreiber",
      "Christian Gutt",
      "Fivos Perakis"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.10643",
    "title": "A typical medium cluster approach for multi-branch phonon localization",
    "abstract": "The phenomenon of Anderson localization in various disordered media has sustained significant interest over many decades. Specifically, the Anderson localization of phonons has been viewed as a potential mechanism for creating fascinating thermal transport properties in materials. However, despite extensive work, the influence of the vector nature of phonons on the Anderson localization transition has not been well explored. In order to achieve such an understanding, we extend a recently developed phonon dynamical cluster approximation (DCA) and its typical medium variant (TMDCA) to investigate spectra and localization of multi-branch phonons in the presence of pure mass disorder. We validate the new formalism against several limiting cases and exact diagonalization results. A comparison of results for the single-branch versus multi-branch case shows that the vector nature of the phonons does not affect the Anderson transition of phonons significantly. The developed multi-branch TMDCA formalism can be employed for studying phonon localization in real materials.",
    "authors": [
      "Wasim Raja Mondal",
      "Tom Berlijn",
      "N. S. Vidhyadhiraja",
      "Hanna Terletska"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.17641",
    "title": "Mesoscale Modeling of an Active Colloid's Motion",
    "abstract": "This paper uses Cahn-Hilliard equations as a mesoscale model of the motion of active colloids. The model attempts to capture the driving mechanisms and qualitative behavior of the isotropic colloids originally proposed by J. Decayeaux in 2021. We compare our model against the single colloid behavior presented in that work, as well as against multi-colloid systems.",
    "authors": [
      "Matthew Dobson",
      "David Masse"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.05780",
    "title": "Orbital Current-Driven Magnetization Switching in a Magnetic Tunnel Junction",
    "abstract": "Spin-orbitronics, based on both spin and orbital angular momentum, presents a promising pathway for energy-efficient memory and logic devices. Recent studies have demonstrated the emergence of orbital currents in light transition metals such as Ti, Cr, and Zr, broadening the scope of spin-orbit torque (SOT). In particular, the orbital Hall effect, which arises independently of spin-obit coupling, has shown potential for enhancing torque efficiency in spintronic devices. However, the direct integration of orbital current into magnetic random-access memory (MRAM) remains unexplored. In this work, we design a light metal/heavy metal/ferromagnet multilayer structure and experimentally demonstrate magnetization switching by orbital current. Furthermore, we have realized a robust SOT-MRAM cell by incorporating a reference layer that is pinned by a synthetic antiferromagnetic structure. We observed a tunnel magnetoresistance of 66%, evident in both magnetic field and current-driven switching processes. Our findings underscore the potential for employing orbital current in designing next-generation spintronic devices.",
    "authors": [
      "Jingkai Xu",
      "Dongxing Zheng",
      "Meng Tang",
      "Chen Liu",
      "Bin He",
      "Man Yang",
      "Hao Li",
      "Yan Li",
      "Aitian Chen",
      "Senfu Zhang",
      "Ziqiang Qiu",
      "Xixiang Zhang"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.13501",
    "title": "Target search optimization by threshold resetting",
    "abstract": "We introduce a new class of first passage time optimization driven by threshold resetting, inspired by many natural processes where crossing a critical limit triggers failure, degradation or transition. In here, search agents are collectively reset when a threshold is reached, creating event-driven, system-coupled simultaneous resets that induce long-range interactions. We develop a unified framework to compute search times for these correlated stochastic processes, with ballistic- and diffusive- searchers as key examples uncovering diverse optimization behaviors. A cost function, akin to breakdown penalties, reveals that optimal resetting can forestall larger losses. This formalism generalizes to broader stochastic systems with multiple degrees of freedom.",
    "authors": [
      "Arup Biswas",
      "Satya N Majumdar",
      "Arnab Pal"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.19525",
    "title": "Spin-Depairing-Induced Exceptional Fermionic Superfluidity",
    "abstract": "We investigate the non-Hermitian (NH) attractive Hubbard model with spin depairing, which is a spin-resolved asymmetric hopping that nonreciprocally operates spins in the opposite direction. We find that spin depairing stabilizes a superfluid state unique to the NH system. This phase is characterized not only by a finite order parameter, but also by the emergence of exceptional points (EPs) in the momentum space - a feature that starkly contrasts with previously discussed NH fermionic superfluidity, where EPs are absent within the superfluid state and emerge only at the onset of the superfluid breakdown. We uncover the rich mechanism underlying this ``exceptional fermionic superfluidity'' by analyzing the interplay between EPs and the effective density of states of the complex energy dispersion. Furthermore, we reveal that the exceptional superfluid state breaks down induced by strong spin depairing on the cubic lattice, while it remains robust on the square lattice.",
    "authors": [
      "Soma Takemori",
      "Kazuki Yamamoto",
      "Akihisa Koga"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.06179",
    "title": "Advances in Phonons: From Band Topology to Phonon Chirality",
    "abstract": "Phonons are ubiquitous quasiparticles in solid state systems describing the quantized vibrations of a crystal lattice. Phonons play a central role in a wide range of physical phenomena, from transport to symmetry-breaking orders, such as charge density waves and superconductivity. {Traditionally treated as spin-0 bosons that obey Bose-Einstein statistics,} phonons have recently emerged as a fertile ground for exploring topological physics, spurred by the rapid development of topological band theory initially formulated for fermionic systems. {It is now understood that the phonon eigenstates, characterized by their eigenvalues and eigenvectors, can carry nontrivial topological invariants, including the Berry phase and Chern number. This new understanding opens up avenues to investigate the interplay between lattice dynamics, topology, and chirality in bosonic systems. In this article, we review recent theoretical and experimental advances in the field of topological phonons and circularly polarized phonons. We introduce foundational concepts, including the classification of phononic band structures, symmetry-protected topological phases, and the definition of topological invariants in bosonic systems. We emphasize the concept of phonon angular momentum and its fundamental connection to Weyl phonons in $\\mathcal{PT}$-breaking systems. Key experimental progresses on topological and circularly polarized phonons are discussed. We also outline outstanding challenges and promising directions for future research, such as the role of topology in phonon-mediated quasiparticle interactions and the manipulation of phonon angular momentum for potential applications in quantum technologies.}",
    "authors": [
      "Tiantian Zhang",
      "Yizhou Liu",
      "Hu Miao",
      "Shuichi Murakami"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.00686",
    "title": "Ballistic particle transport and Drude weight in gases",
    "abstract": "Owing to the fact that the particle current operator in non-relativistic gases is proportional to the total momentum operator, the particle transport in such systems is always ballistic and fully characterized by a Drude weight $\\Delta$. The Drude weight can be calculated within linear response theory. It is given by the formula $\\Delta = 2 \\pi D$, where $D$ is the density of the gas. This holds in any dimension and for every equilibrium ensemble, in particular for generalized Gibbs ensembles that describe possible equilibrium states of isolated integrable quantum systems. In the canonical ensemble case, the Drude weight can be equivalently obtained from a generalized susceptibility related to the fluctuations of the conserved particle current. Such susceptibility can be rigorously calculated for the integrable Lieb-Liniger Bose gas in any generalized Gibbs ensemble using a generalized Yang-Yang thermodynamic formalism. The resulting expression agrees with a prediction made within the context of generalized hydrodynamics. It also allows us to see explicitly that, within truly generalized Gibbs ensembles, the conductivity related with the particle current is not determined by the corresponding current-current auto-correlation function.",
    "authors": [
      "Frank Göhmann",
      "Andreas Klümper",
      "Karol K. Kozlowski"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.06237",
    "title": "Fermion parity switches imprinted in the photonic field of cavity embedded Kitaev chains",
    "abstract": "We study a finite-length Kitaev chain coupled to a single mode photonic cavity. The topological phase of the finite-length Kitaev chain is characterized by the presence of fermion parity switching points that correspond to the degeneracy between even and odd parity ground states. Using exact diagonalization, we compute the many-body energy spectrum of the electron-photon Hamiltonian and we find that the ground state in the topological phase of the Kitaev chain is only weakly affected by the cavity coupling. This is in contrast with the excited states showing strong dependence on the cavity frequency. We find that the photon number and the photonic field quadratures peak at values of the chemical potential corresponding to parity switching points revealing a property of the finite-length Kitaev chain in the topological phase. This later finding suggests that quantum optics experiments could be used to detect topological features of the Kitaev chain embedded into a photonic cavity. Moreover, calculations of photonic quadratures reveal squeezed states that are both captured by the exact diagonalization technique and mean field decoupling. However, the mean field approach fails to correctly capture the photonic probability in the odd photonic states.",
    "authors": [
      "Victor Fernandez Becerra",
      "Olesia Dmytruk"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.09611",
    "title": "Accelerating ground-state auxiliary-field quantum Monte Carlo simulations by delayed update and block force-bias update",
    "abstract": "Ground-state auxiliary-field quantum Monte Carlo (AFQMC) methods have become key numerical tools for studying quantum phases and phase transitions in interacting many-fermion systems. Despite the broad applicability, the efficiency of these algorithms is often limited by the bottleneck associated with the {\\it local update} of the field configuration. In this work, we propose two novel update schemes, the {\\it delayed update} and {\\it block force-bias update}, both of which can generally and efficiently accelerate ground-state AFQMC simulations. The {\\it delayed update}, with a predetermined delay rank, is an elegantly improved version of the {\\it local update}, accelerating the process by replacing multiple vector-vector outer products in the latter with a single matrix-matrix multiplication. The {\\it block force-bias update} is a block variant of the conventional force-bias update, which is a highly efficient scheme for dilute systems but suffers from the low acceptance ratio in lattice models. Our modified scheme maintains the high efficiency while offering flexible tuning of the acceptance ratio, controlled by the block size, for any desired fermion filling. We apply these two update schemes to both the standard and spin-orbit coupled two-dimensional Hubbard models, demonstrating their speedup over the {\\it local update} with respect to the delay rank and block size. We also explore their efficiencies across varying system sizes and model parameters. Our results identify a speedup of $\\sim$$8$ for systems with $\\sim$$1600$ lattice sites. Furthermore, we have investigated the broader applications as well as an application diagram of these update schemes to general correlated fermion systems.",
    "authors": [
      "Hao Du",
      "Yuan-Yao He"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.09783",
    "title": "Photo-induced directional transport in extended SSH chains",
    "abstract": "We investigate the current-voltage characteristics of an extended Su-Schrieffer-Heeger (SSH) chain under irradiation by arbitrarily polarized light, demonstrating its potential as a light-controlled rectifier. Irradiation of light induces anisotropy in the system, enabling directional current flow and active control of rectification behavior. Our analysis demonstrates that, under optimized light parameters, the rectification efficiency can exceed 90\\%. Moreover, the direction of rectification-whether positive or negative-can be precisely controlled by varying the polarization of the light, highlighting the potential for external optical control of electronic behavior. The effect of light irradiation is incorporated using the Floquet-Bloch ansatz combined with the minimal coupling scheme, while charge transport is computed through the nonequilibrium Green's function formalism within the Landauer-Büttiker framework.",
    "authors": [
      "Usham Harish Kumar Singha",
      "Kallol Mondal",
      "Sudin Ganguly",
      "Santanu K. Maiti"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.15478",
    "title": "Generalized Onsager reciprocal relations of charge and spin transport",
    "abstract": "In spin-orbit-coupled systems the charge and spin transport are generally coupled to each other, namely a charge current will induce a spin current and vice versa. In the presence of time-reversal symmetry $T$, the cross-coupling transport coefficients describing how one process affects the other are constrained by the famous Onsager reciprocal relations. In this paper, we generalize the Onsager reciprocal relations of charge and spin transport to systems that break the time-reversal symmetry but preserve a combined symmetry of $T$ and some other symmetry operation $O$. We show that the symmetry or antisymmetry of the cross-coupling transport coefficients remains in place provided that the operator $O$ meets certain conditions. Among many candidate systems where our generalized Onsager relations apply, we focus on a conceptually simple and experimentally realized model in cold atomic systems for explicit demonstration and use these relations to predict highly non-trivial transport phenomena that can be readily verified experimentally.",
    "authors": [
      "Guan-Hua Huang",
      "Hui Tang",
      "Shizhong Zhang",
      "Zhongbo Yan",
      "Zhigang Wu"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.21801",
    "title": "Angular Momentum Fluctuations in the Phonon Vacuum of Symmetric Crystals",
    "abstract": "Although time-reversal and inversion symmetry constrain the angular momentum of each phonon mode to vanish, we show that the vacuum state of crystals with such symmetries can nevertheless exhibit finite angular momentum fluctuations, {which persists at finite temperature}. These fluctuations arise from quantum coherence between nondegenerate, orthogonally polarized modes and are encoded in the off-diagonal components of the angular momentum operator. Their origin lies in the noncommutativity between the phonon Hamiltonian and angular momentum, which enables time-dependent rotational dynamics even in symmetric vacua. We provide intuitive insight into the coherence underlying this phenomenon by drawing an analogy with the beating between linearly polarized classical waves. Finally, we show that these angular momentum fluctuations produce distinct spectral signatures that can, in principle, be probed via established techniques sensitive to the polarization content and symmetry of lattice excitations, opening an uncharted avenue for accessing and leveraging rotational vacuum correlations in crystalline systems.",
    "authors": [
      "Rule Yi",
      "Violet Williams",
      "Benedetta Flebus"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.00560",
    "title": "Binding and spontaneous condensation of excitons in narrow-gap carbon nanotubes",
    "abstract": "Ultraclean, undoped carbon nanotubes are observed to be always insulating, even when the gap predicted by band theory is zero: the residual band gap is then thought to have a many-body origin. Here we theoretically show that the correlated insulator is excitonic in $all stable$ narrow-gap tubes irrespective of their size, thus extending our previous claim, limited to gapless (armchair) tubes [D.~Varsano, S.~Sorella, D.~Sangalli, M.~Barborini, S.~Corni, E.~Molinari, M.~Rontani, Nature Communications $\\mathbf{8}$, 1461 (2017)]. We derive the scaling law of the exciton binding energy with the tube radius and chirality, and compute self-consistently the fundamental transport gap of the excitonic insulator, by enhancing the two-band model with an accurate treatment of screening validated from first principles. Our findings point to the broader connection between the exciton length scale, dictated by structure, and the stability of the excitonic phase.",
    "authors": [
      "Giacomo Sesti",
      "Daniele Varsano",
      "Elisa Molinari",
      "Massimo Rontani"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.01280",
    "title": "BCS states and D-wave condensates in the 2D Hubbard model",
    "abstract": "We consider states of BCS form in the 2D Hubbard model which, starting from some arbitrary point in state space in the neighborhood of a Hartree-Fock ground state, are relaxed within that BCS ansatz to local minima of the energy. As in the Hartree-Fock approximation there are a vast number of local minima, nearly degenerate in energy. What is new, and unlike the conventional Hartree-Fock states, is that there is a region in parameter space where these local minima are clearly associated with d-wave condensates of the form $d_{x^2-y^2}$ in the underdoped region. There are, however, indications of $d_{xy}$ condensation in the overdoped region, at least in this approximation to the 2D Hubbard model.",
    "authors": [
      "Kazue Matsuyama",
      "Jeff Greensite"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.02336",
    "title": "Discontinuous percolation via suppression of neighboring clusters in a network",
    "abstract": "Our recent study on the Bethe lattice reported that a discontinuous percolation transition emerges as the number of occupied links increases and each node rewires its links to locally suppress the growth of neighboring clusters. However, since the Bethe lattice is a tree, a macroscopic cluster forms as an infinite spanning tree but does not contain a finite fraction of the nodes. In this paper, we study a bipartite network that can be regarded as a locally tree-like structure with long-range neighbors. In this network, each node in one of the two partitions is allowed to rewire its links to nodes in the other partition to suppress the growth of neighboring clusters. We observe a discontinuous percolation transition characterized by the emergence of a single macroscopic cluster containing a finite fraction of nodes, followed by critical behavior of the cluster size distribution. We also provide an analytical explanation of the underlying mechanism.",
    "authors": [
      "Young Sul Cho"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.08072",
    "title": "Electric and spin current vortices in altermagnets",
    "abstract": "Altermagnets constitute a class of collinear magnets with momentum-dependent spin splitting and vanishing net magnetization. Direct observation of the characteristic altermagnetic spin splitting, however, remains challenging. Indirect signatures can be obtained via transport studies, which so far have only considered homogeneous driving fields. We propose to leverage nonuniform electric fields and spin density gradients to probe the shape and the spin polarization of altermagnetic Fermi surfaces via transport measurements. By using both a semiclassical Boltzmann approach and a lattice Keldysh formalism, we show that altermagnets excite swirling electric and spin currents whose profiles depend on the relative orientation of altermagnetic lobes with respect to the sample boundaries. These currents can be measured via magnetometry techniques. Unlike previous proposals considering the hydrodynamic regime of transport, swirling currents are observed even in the Ohmic regime and rely exclusively on the altermagnetic spin splitting, with no swirls observed in ferromagnets. The electric and spin current vortices predicted here provide a different altermagnetic signature in an experimentally accessible setup.",
    "authors": [
      "Arsen Herasymchuk",
      "Karl Bergson Hallberg",
      "Erik Wegner Hodt",
      "Jacob Linder",
      "E.V. Gorbar",
      "Pavlo Sukhachov"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.12430",
    "title": "Electron-phonon-dominated charge-density-wave fluctuations in TiSe$_2$ accessed by ultrafast nonequilibrium dynamics",
    "abstract": "The complex phase diagram of 1T-TiSe2 consists of a charge density wave (CDW) below 200 K, and CDW fluctuations of still unknown origin at higher temperatures. Here, we use time-resolved extreme ultraviolet momentum microscopy and density functional perturbation theory to uncover the formation mechanism of CDW fluctuations and their spectral features at 295 K. We investigated the transient dynamics of fluctuations upon nonresonant ultrafast photoexcitation, and directly correlate it with the CDW soft-phonon hardening. Surprisingly, our results show that the coherent amplitude mode modulating ultrafast CDW recovery persists above TCDW, and reveal that CDW fluctuations are dominated by the electron-phonon interaction rather than excitonic correlations as commonly believed. Our findings on these microscopic CDW fluctuations clarify the complex interplay between electronic and lattice degrees of freedom at elevated temperatures and, therefore, could be useful in understanding the nature of the CDW phase transition in 1T-TiSe2 and similar quantum materials.",
    "authors": [
      "Sotirios Fragkos",
      "Hibiki Orio",
      "Nina Girotto Erhardt",
      "Akib Jabed",
      "Sarath Sasi",
      "Quentin Courtade",
      "Muthu P. T. Masilamani",
      "Maximilian Ünzelmann",
      "Florian Diekmann",
      "Baptiste Hildebrand",
      "Dominique Descamps",
      "Stéphane Petit",
      "Fabio Boschini",
      "Ján Minár",
      "Yann Mairesse",
      "Friedrich Reinert",
      "Kai Rossnagel",
      "Dino Novko",
      "Samuel Beaulieu",
      "Jakub Schusser"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.21362",
    "title": "Investigating the effects of local environment on nitrogen vacancies in high entropy metal nitrides",
    "abstract": "High entropy metal nitrides are an important material class in a variety of applications, and the role of nitrogen vacancies is of great importance for understanding their stability and mechanical properties. We study six different high entropy nitrides with eight different metal species to build a predictive model of the nitrogen vacancy formation energy. We construct sets of supercells that maximize the number of unique nitrogen environments for a given chemistry, and then use density-functional theory to calculate the energy density for all nitrogen sites, and the vacancy formation energies for the highest, lowest, and a median subset based on the energy densities. The energy density of nitrogen sites correlates with the vacancy formation energies, for binary, ternary and high entropy nitrides. A linear regression model predicts the vacancy formation energies using only the nearest-neighbor composition; across our eight metals, we find the largest vacancy formation energies next to Hf, then Zr, Ti, V, Cr, Ta, Nb, and the lowest near Mo. Additionally, we see that binary nitride data shows qualitatively similar vacancy formation energy trends for high entropy nitrides; however, the binary data alone is insufficient to predict the complex nitride behavior. Our model is both predictive and easily interpretable, and correlates with experimental data.",
    "authors": [
      "Charith R. DeSilva",
      "Matthew D. Witman",
      "Dallas R. Trinkle"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.00684",
    "title": "Screw Symmetry, Chiral Hydrodynamics and Odd Instability in Active Cholesterics",
    "abstract": "Active cholesterics are chiral in both their structure, which has continuous screw symmetry, and their active stresses, which include contributions from torque dipoles. Both expressions of chirality give rise to curl forces in the hydrodynamics, which we derive from the active Ericksen-Leslie equations using a geometric approach. This clarifies the hydrodynamics of continuous screw symmetry and provides an example of generalised odd elastic forces that originate from an equilibrium free energy. We discuss also the nonlinear structure of the active hydrodynamics in terms of the Eulerian displacement field of the cholesteric pseudolayers. For the active instability, screw symmetry generates a contribution of chiral activity to the linearised pseudolayer hydrodynamics that is absent in materials with chiral activity but achiral structure. When the two forms are sufficiently antagonistic, this term produces a new active instability with threshold and characteristic wavevector distinct from those of the active Helfrich-Hurault instability in chiral active smectics. Finally, we comment on the isotropic chiral hydrodynamics of materials with three-dimensional screw symmetry.",
    "authors": [
      "Gareth P. Alexander",
      "S. J. Kole",
      "Ananyo Maitra",
      "Sriram Ramaswamy"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.09436",
    "title": "Ultrafast Optical Evidence of Coexisting Density Waves in Bilayer Nickelate La$_3$Ni$_2$O$_7$",
    "abstract": "Utilizing ultrafast optical pump-probe spectroscopy, we investigate the coexistence and competition of electronic orders in the bilayer nickelate La$_3$Ni$_2$O$_7$. Our results reveal two coexisting density waves that can be selectively manipulated with light. We directly identify a spin-density wave (SDW) with electronic nematicity emerging below $T_{\\rm SDW}$ $\\approx$ 140 K by measuring its spin dynamics, and discover a distinct, nonmagnetic charge order appearing below $T_{\\rm DW}$ $\\approx$ 115 K. The central finding is the demonstration of differential optical control: the charge order is fragile, completely suppressed by a pump fluence of approximately 40 $\\mu$J/cm$^2$, while the SDW is remarkably robust, persisting to 200 $\\mu$J/cm$^2$. This work establishes a clear hierarchy in the stability of competing electronic orders and provides a powerful method for disentangling their interplay in quantum materials.",
    "authors": [
      "Qi-Yi Wu",
      "De-Yuan Hu",
      "Chen Zhang",
      "Mengwu Huo",
      "Hao Liu",
      "Bo Chen",
      "Ying Zhou",
      "Zhong-Tuo Fu",
      "Chun-Hui Lv",
      "Zi-Jie Xu",
      "Hai-Long Deng",
      "H. Y. Liu",
      "Jun Liu",
      "Yu-Xia Duan",
      "Meng Wang",
      "Jian-Qiao Meng"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.20779",
    "title": "A configuration interaction approach to solve the Anderson impurity model; applications to elemental Ce",
    "abstract": "Accurate calculations of strongly correlated materials remain a formidable challenge in condensed matter physics, particularly due to the computational demand of conventional methods. This paper presents an efficient solver for dynamical mean field theory using configuration interaction (CI). The method is shown to have improved efficiency compared to traditional, exact diagonalization approaches. Hence, it provides an accessible, open-source alternative that can be executed on standard laptop computers or on supercomputers. The solver is demonstrated on cerium in the $\\gamma$-, $\\alpha$- and $\\epsilon$-phases. An analysis of how the electronic structure of Ce evolves as function of lattice compression is made. It is argued that the electronic structure evolves from a localized nature of the 4f shell in $\\gamma$-Ce to an essentially itinerant nature of the 4f shell of $\\epsilon$-Ce. The transition between these two phases, as function of compression, can hence be seen as a Mott transition. However, this transition is intercepted by the strongly correlated $\\alpha$-phase of elemental Ce, for which the 4f shell forms a Kondo singlet.",
    "authors": [
      "Basile Herzog",
      "Patrik Thunström",
      "Olle Eriksson"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.12898",
    "title": "Random packing fraction of binary convex and similar hyperparticles with small size difference: Statistical geometry approaches to excluded volume",
    "abstract": "In this paper the random packing fraction of binary similar hyperparticles with small size difference in D-dimensional Euclidean space RD is studied using two statistical geometry approaches. These geometric approaches, concerning orientation geometry and integral geometry, yield the excluded volume of particle pairs. The excluded volume of rectangles, based on orientation geometry, in Euclidean space R2 is used to derive an explicit equation for the bidisperse packing fraction, which is compatible with the expression published previously. Next, the excluded volume of pairs of convex particles in D = 2, 3 and 4 resulting from integral geometry are presented. These excluded volumes are identical with the specific ones for (sphero-)cylinders (D = 3) and rectangles (D = 2), derived by orientation geometry. Furthermore, these excluded volumes contain geometric measures: particle volume, surface area, mean curvature and the second quermassintegral. This allows the derivation of closed-form and generic expressions for the random packing fraction of binary convex hyperparticles in Euclidean spaces R2 , R3 and R4.",
    "authors": [
      "H.J.H. Brouwers"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.21963",
    "title": "Nonlinear magnetization dynamics as a route to nonreciprocal phases, spin superfluidity, and analogue gravity",
    "abstract": "The identification of platforms with independently tunable nonlinearity and non-Hermiticity promises a quantitative route to far-from-equilibrium universality across many-body systems. Here we show that a conventional ferromagnetic multilayer realizes this paradigm: balancing a dc drive against Gilbert damping stabilizes a chiral spin-superfluid limit cycle that spontaneously breaks spacetime-translation symmetry. The resulting superflow is intrinsically nonreciprocal: long-wavelength magnons of opposite chirality acquire asymmetric dispersions and propagate direction-selectively, realizing a spin-superfluid diode. This asymmetry is flow-borne - it reflects broken Galilean invariance and requires neither structural asymmetry nor finely tuned gain-loss balance. Linearized dynamics in the comoving superfluid frame are intrinsically pseudo-Hermitian and, in the long-wavelength sector, can be mapped to a (1+1)D wave equation on curved spacetime. Spatial modulation of the drive enables the generation of sonic horizons that parametrically squeeze magnons and produce Hawking-like particle-hole emission. Our results establish a tabletop route from nonlinear dissipative-driven magnetization dynamics to nonreciprocal transport, nonequilibrium phase transitions, and analogue-gravity kinematics.",
    "authors": [
      "Vincent Flynn",
      "Benedetta Flebus"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.25747",
    "title": "When Heating Isn't Cooling in Reverse: Nosé-Hoover Thermostat Fluctuations from Equilibrium Symmetry to Nonequilibrium Asymmetry",
    "abstract": "Recent laboratory experiments suggest an intrinsic asymmetry between heating and cooling, with heating occurring more efficiently. Two decades earlier, molecular dynamics (MD) simulations had examined a related setup - heating one side of a computational cell while cooling the other via distinct thermostats. We revisit those calculations, recapitulating the underlying theory and showing that earlier MD results already hinted at the observed laboratory asymmetry. Recent realizations of a simple two-dimensional single-particle model, thermostatted in $x$ and $y$ at different temperatures, reproduces key features: at equilibrium, thermostat variables were identical, but under nonequilibrium conditions, the heating variable is weaker than the cooling one. At the same time, MD simulations from four decades ago by Evans and Holian reported a surprising skew in the Nose--Hoover thermostat variable $\\xi$ under equilibrium - indicating a statistical bias in energy injection versus extraction. We revisit those results with exact reproduction of their setup. We show that when (1) the center-of-mass velocity is set to zero, (2) integration is done carefully with finite differencing, and (3) sampling is sufficiently long, the distribution of $\\xi$ is symmetric and Gaussian with zero mean, as predicted by theory and validated by two independent error estimates. However, in the two-temperature cell, the distribution of thermostat variables become asymmetric, the cold bath requires significantly stronger damping than the hot bath requires anti-damping, with $\\langle \\xi_x \\rangle / \\langle \\xi_y \\rangle = -T_y/T_x$. This exact analytic relation links thermostat effort to thermal bias and the negative rate of change in the entropy of the system. These results identify the microscopic origin of heating-cooling asymmetry as a genuine nonequilibrium effect, consistent with experimental findings.",
    "authors": [
      "Hesam Arabzadeh",
      "Brad Lee Holian"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.01543",
    "title": "Predictive quantum vibrational spectra through active learning 4G-NNPs",
    "abstract": "Predictive simulation of vibrational spectra of complex condensed-phase and interface systems with thousands of degrees of freedom has long been a challenging task of modern condensed matter theory. In this work, fourth-generation high-dimensional committee neural network potentials (4G-HDCNNPs) are developed using active learning and query-by-committee, and introduced to the essential nuclear quantum effects (NQEs) as well as conformational entropy and anharmonicities from path integral (PI) molecular dynamics simulations. Using representative bulk water and air-water interface test cases, we demonstrate the accuracy of the developed framework in infrared spectral simulations. Specifically, by seamlessly integrating non-local charge transfer effects from 4G-HDCNNPs with the NQEs from PI methods, our introduced methodology yields accurate infrared spectra using predicted charges from the 4G-HDCNNP architecture without explicit training of dipole moments. The framework introduced in this work is simple and general, offering a practical paradigm for predictive spectral simulations of complex condensed phases and interfaces, free from empirical parameterizations and ad hoc fitting.",
    "authors": [
      "Md Omar Faruque",
      "Dil K. Limbu",
      "Nathan London",
      "Mohammad R. Momeni"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04739",
    "title": "Superexchanges and Charge Transfer in the La$_3$Ni$_2$O$_7$ Thin Films",
    "abstract": "The recent discovery of ambient-pressure superconductivity with $T_c$ above 40 K in La$_3$Ni$_2$O$_7$ thin films represents a significant advance in the field of nickelate superconductor. Motivated by the experimental reports, here we study an 11-band $d-p$ Hubbard model with tight-binding parameters derived from \\textit{ab initio} calculations, using large scale determinant quantum Monte Carlo and cellular dynamical mean-field theory. Our results reveal that the major superexchange couplings in La$_3$Ni$_2$O$_7$ thin films can be substantially weaker than in the bulk material at 29.5 Gpa. Specifically, the out-of-plane antiferromagnetic correlation between Ni$-d_{3z^2-r^2}$ orbitals is reduced by about 27\\% in film, while the in-plane magnetic correlations remain largely unaffected. We evaluate the corresponding antiferromagnetic coupling constants, $J_{\\perp}$ and $J_{\\parallel}$ using perturbation theory. With regard to charge transfer properties, we find that the biaxial compression in films reduces charge transfer gap. We also resolve the orbital distribution of doped holes and electrons among the in-plane (Ni$-d_{x^2-y^2}$ and O$-p_x/p_y$) and the out-of-plane (Ni$-d_{3z^2-r^2}$ and O$-p_z$) orbitals, uncovering a pronounced particle-hole asymmetry. Theses findings lay a groundwork for the study of low-energy $t-J$ model of La$_3$Ni$_2$O$_7$ films and provide key insights into the understanding of physical distinctions between the film and bulk bilayer nickelates.",
    "authors": [
      "Yuxun Zhong",
      "Wéi Wú",
      "Dao-Xin Yao"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.07334",
    "title": "Weak localization and universal conductance fluctuations in large area twisted bilayer graphene",
    "abstract": "We study diffusive magnetotransport in highly p-doped large area twisted bilayer graphene samples as a function of twist angle, crossing from 1° (below), to 20° (above) the van Hove singularity with 7° and 9° samples near the van Hove singularity. We report weak localization in twisted bilayer graphene for the first time. All samples exhibit weak localization, from which we extract the phase coherence length and intervalley scattering lengths, and from that determine that dephasing is caused by electron-electron scattering and intervalley scattering is caused by point defects. We observe signatures of universal conductance fluctuations in the 9° sample, which has high mobility and is near the van Hove singularity. Further improvements in sample quality and applications to large area moire materials will open new avenues to observe quantum interference effects.",
    "authors": [
      "Spenser Talkington",
      "Debarghya Mallick",
      "An-Hsi Chen",
      "Benjamin F. Mead",
      "Seong-Jun Yang",
      "Cheol-Joo Kim",
      "Shaffique Adam",
      "Liang Wu",
      "Matthew Brahlek",
      "Eugene J. Mele"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.08013",
    "title": "Algebraic to exponential decay of spatial correlations in one-dimensional and confined hard-core fluids: A Laplace-pole analysis",
    "abstract": "We derive the asymptotic behavior of the radial distribution function $g(x)$ for one-dimensional (1D) hard-rod systems and related quasi-one-dimensional geometries at high packing fractions using Laplace transform techniques and pole analysis. By identifying the poles and residues of the Laplace transform in the limit of small void fraction, we obtain compact representations of $g(x)$ in terms of the Jacobi elliptic theta function $\\theta_3$. This formulation naturally captures the two regimes governing the oscillatory decay toward unity: an intermediate algebraic decay and a long-distance exponential decay, consistent with previous results for the Tonks gas. Our approach provides a unified framework that (i) expresses $g(x)$ in a single well-tabulated special function, (ii) links spatial correlations directly to the pole structure in complex Laplace space, offering clear physical insight into decay rates and oscillation frequencies, and (iii) generalizes straightforwardly to 1D binary mixtures and confined hard-disk systems, where direct Gaussian decompositions are cumbersome. The equivalence between the theta-function representation and the Gaussian superposition of Bouzar and Messina [Phys. Rev. E 112, L042105 (2025)] is established via the Poisson summation formula, highlighting the versatility and conceptual advantages of the Laplace-pole framework.",
    "authors": [
      "Ana M. Montero",
      "Andrés Santos"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.21458",
    "title": "Enabling the bulk photovoltaic effect in centrosymmetric materials through an external electric field",
    "abstract": "We develop a practical approach to electrically tuning the nonlinear photoresponse of two-dimensional semiconductors by explicitly incorporating a static out-of-plane electric field into the electronic ground state prior to optical excitation, as a gate bias. The method is implemented by dressing a Wannier-interpolated Hamiltonian with the field through its position matrix elements, which allows the gate bias to modify orbital hybridization and band dispersion beyond perturbative treatments. Within the independent-particle approximation, the resulting second-order (shift) conductivity is evaluated for both centrosymmetric and non-centrosymmetric layered systems. Applied to MoS$_2$, the approach captures the emergence of a finite shift current in centrosymmetric bilayers and the tunability of intrinsic responses in polar structures. The shift conductivity rises linearly at small fields and saturates at higher intensities, reflecting the competition between the growing shift vector and the weakening interband coupling as resonant transitions move away from high-symmetry valleys. A Taylor expansion of the field-dressed conductivity connects this behavior to the third-order optical response, revealing a unified picture of field-induced nonlinearities. These results establish field dressing of Wannier Hamiltonians as a practical route to model and predict nonlinear photocurrents in layered materials.",
    "authors": [
      "Guilherme J. Inacio",
      "Juan José Esteve-Paredes",
      "Maurício F. C. Martins Quintela",
      "Wendel S. Paz",
      "Juan José Palacios"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22980",
    "title": "Interaction-Driven Chern Insulator at Zero Electric Field in ABCB-Stacked Tetralayer Graphene",
    "abstract": "ABCB-stacked tetralayer graphene, with intrinsic spontaneous polarization, offers a unique platform to explore electron correlation effects, whose interplay with spin-orbit coupling may engender topological phases. Here, employing a $\\mathbf{k}\\cdot\\mathbf{p}$ model with self-consistent Hartree-Fock calculations, we investigate its electronic ground states. Remarkably, we find that the intrinsic polarization, in conjunction with strong interactions ($U=8 \\text{ eV}$) and SOC, is sufficient to drive a $C=3$ quantum anomalous Hall state, obviating the need for an external electric field typical in ABCA stacks. Conversely, at moderate interactions ($U=6 \\text{ eV}$), a minimal electric field is necessary. Furthermore, calculations predict other correlation-driven metallic phases such as quarter- and three-quarter-filled states. These results establish that the synergy of intrinsic polarization, correlations, and SOC governs the rich topological phenomena, suggesting ABCB-stacked graphene as a highly tunable platform for exploring emergent topological phenomena.",
    "authors": [
      "Yulu Ren",
      "Yang Shen",
      "Chengyang Xu",
      "Wanfei Shan",
      "Weidong Luo"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01884",
    "title": "Onsager Condensation in Chiral Active Matter: Universality of Topological Gas Dynamics",
    "abstract": "We identify a thermodynamic phase transition in chiral active matter. Low-frequency disorder triggers global synchronisation and energy dissipation, while high disorder activates a topological heat pump, generating an inverse energy cascade. This drives the system towards an Onsager dipole, which can be arrested into a metastable vortex glass if dispersion is insufficient to overcome the defect lattice. We propose topological gas dynamics as a universality class governed by the interplay of active disorder and topological sorting, unifying active swarms and classical inviscid fluids.",
    "authors": [
      "Magnus F Ivarsen"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.18222",
    "title": "Kubo-Martin-Schwinger states of Path-structured Flow in Directed Brain Synaptic Networks",
    "abstract": "The brain's synaptic network, characterized by parallel connections and feedback loops, drives interaction pathways between neurons through a large system with infinitely many degrees of freedom. This system is best modeled by the graph C*-algebra of the underlying directed graph, the Toeplitz-Cuntz-Krieger (TCK) algebra, which captures the diversity of path-structured flow connectivity. Equipped with the gauge action, the TCK algebra defines an {\\em algebraic quantum system}, and here we demonstrate that its thermodynamic properties provide a natural framework for describing the dynamic mappings of potential flow pathways within the network. Specifically, the KMS states of this system represent the stationary distributions of a non-Markovian stochastic process with memory decay, capturing how influence propagates along exponentially weighted paths, and yield global statistical measures of neuronal interactions. Applied to the {\\em C. elegans} synaptic network, our framework reveals that neurolocomotor neurons emerge as the primary hubs of incoming path-structured flow at inverse temperatures where the entropy of KMS states peaks. This finding aligns with experimental evidence of the foundational role of locomotion in {\\em C. elegans} behavior, suggesting that functional centrality may arise from the topological embedding of neurons rather than solely from local physiological properties. Our results highlight the potential of algebraic quantum methods and graph algebras to uncover patterns of functional organization in complex systems and neuroscience.",
    "authors": [
      "El-kaïoum M. Moutuou",
      "Habib Benali"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.08356",
    "title": "Proposal for a Bell Test with Entangled Atoms of Different Mass",
    "abstract": "We propose a Bell test experiment using momentum-entangled atom pairs of different masses, specifically metastable helium isotopes 3He* and 4He*, though the method extends to other atom species. Entanglement is generated via collisions, after which the quantum states are manipulated using two independent atom interferometers, enabling precise phase control over each species. Numerical simulations predict a significant violation of Bell's inequality under realistic conditions. This proposal opens a new paradigm to study the intersection of quantum mechanics and gravity.",
    "authors": [
      "X. T. Yan",
      "S. Kannan",
      "Y. S. Athreya",
      "A. G. Truscott",
      "S. S. Hodgman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.02355",
    "title": "Hybrid confinement techniques for polariton simulators",
    "abstract": "Exciton-polariton III-V semiconductor microcavities provide a robust platform for emulating complex Hamiltonians, enabling topological photonics and quantum simulation for advanced photonic functionalities. Here, we introduce two novel fabrication techniques - etch-and-oversputter and deposit-and-oversputter - that overcome limitations of traditional photonic confinement. Both use structured, locally elongated semiconductor cavities to create deep, highly controllable potentials, while leveraging high-quality GaAs-based materials, which achieve excellent Q-factors. A sputtered all-dielectric top mirror introduces an innovative hybrid approach, simplifying fabrication while maintaining quality compared to deep ion etching. Utilizing a Kagome lattice as a benchmark, we show high-quality optical band structures previously inaccessible with deep etching. Furthermore, we study a two-dimensional breathing Kagome lattice and demonstrate polariton lasing from a zero-dimensional corner mode, confirming precise control over couplings and tight polariton localization. These methods enable fabrication of intricate lattices, including higher-order topological insulators, or on-chip quantum regimes utilizing the polariton blockade mechanism due to tight photonic confinement.",
    "authors": [
      "Johannes Düreth",
      "Philipp Gagel",
      "David Laibacher",
      "Oleg A. Egorov",
      "Simon Widmann",
      "Simon Betzold",
      "Monika Emmerling",
      "Siddhartha Dam",
      "Alexia Landry",
      "Christian G. Mayer",
      "Martin Kamp",
      "Aniela Woyciechowska",
      "Barbara Piętka",
      "Ulf Peschel",
      "Sven Höfling",
      "Sebastian Klembt"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.07112",
    "title": "Miniature work-to-work converter engine powered by motor protein",
    "abstract": "Designing a miniature microscale engine that can override the role of thermal fluctuations has remained elusive and is an important open challenge. Here we provide the design and theoretical framework for a unique information-based engine - a work-to-work converter - comprising a sub-micron size bead and motor protein-microtubule (MT) complex in an optical trap setup. We demonstrate how by implementing a simple motor protein state-dependent feedback protocol of the optical trap stiffness, this engine is able to harness and convert the movement of a motor protein into work output. Unlike other conventional microengines, the fidelity and performance of this engine is determined by the stochasticity of motor (un)binding characteristics. We obtain an analytical form of the work distribution function, average work output and average power output, providing quantitative predictions for engine performance which are validated by stochastic simulations. Remarkably, the average work output per cycle is at least an order of magnitude higher than the thermal fluctuations and supersedes the performance of other microscale engines realized so far.",
    "authors": [
      "Suraj Deshmukh",
      "Sougata Guha",
      "Basudha Roy",
      "Shivprasad Patil",
      "Arnab Saha",
      "Sudipto Muhuri"
    ],
    "primary_category": "physics.bio-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.02923",
    "title": "Stabilizer-Accelerated Quantum Many-Body Ground-State Estimation",
    "abstract": "We investigate how the stabilizer formalism, in particular highly-entangled stabilizer states, can be used to describe the emergence of many-body shape collectivity from individual constituents, in a symmetry-preserving and classically efficient way. The method that we adopt is based on determining an optimal separation of the Hamiltonian into a stabilizer component and a residual part inducing non-stabilizerness. The corresponding stabilizer ground state is efficiently prepared using techniques of graph states and stabilizer tableaux. We demonstrate this technique in context of the Lipkin-Meshkov-Glick model, a fully-connected spin system presenting a second order phase transition from spherical to deformed state. The resulting stabilizer ground state is found to capture to a large extent both bi-partite and collective multi-partite entanglement features of the exact solution in the region of large deformation. We also explore several methods for injecting non-stabilizerness into the system, including ADAPT-VQE, and imaginary-time evolution (ITE) techniques. Stabilizer ground states are found to accelerate ITE convergence due to a larger overlap with the exact ground state. While further investigations are required, the present work suggests that collective features may be associated with high but simple large-scale entanglement which can be captured by stabilizer states, while the interplay with single-particle motion may be responsible for inducing non-stabilizerness. This study motivates applications of the proposed approach to more realistic quantum many-body systems, whose stabilizer ground states can be used in combinations with powerful classical many-body techniques and/or quantum methods.",
    "authors": [
      "Caroline E. P. Robin"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.13689",
    "title": "Purely quantum memory in closed systems observed via imperfect measurements",
    "abstract": "The detection and quantification of non-Markovianity, a.k.a. memory, in quantum systems is a central problem in the theory of open quantum systems. There memory is as a result of the interaction between the system and its environment. Little is known, however, about memory effects induced by imperfect measurements on closed systems, where an entanglement with the environment is not possible. We investigate the emergence and characteristics of memory in closed systems observed via imperfect stroboscopic quantum measurements yielding coarse-grained outcomes. We consider ideal and two kinds of imperfect measurements: von Neumann measurements--the analogue of classical lumping--which destroy any coherence in the system, and genuinely quantum-lumping Lüders measurements preserving certain quantum correlations. Whereas the conditions for Markov dynamics under von Neumann lumping are the same as for classical dynamics, quantum-lumping requires stronger conditions, i.e. the absence of any detectable coherence. We introduce the concept of purely quantum memory having no classical counterpart. We illustrate our results with a quantum walk on a lattice and discuss their implications for dissipative dynamics and decoherence effects induced by more realistic measurements.",
    "authors": [
      "Jorge Tabanera-Bravo",
      "Aljaž Godec"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.23155",
    "title": "Homomorphism, substructure and ideal: Elementary but rigorous aspects of renormalization group or hierarchical structure of topological orders",
    "abstract": "We propose a general quantum Hamiltonian formalism of a renormalization group (RG) flow with an emphasis on generalized symmetry by interpreting the elementary relationship between homomorphism, quotient ring, and projection. In our formalism, the noninvertible nature of the ideal of a fusion ring realizing the generalized symmetry of an ultraviolet (UV) theory plays a fundamental role in determining condensation rules between anyons, resulting in the infrared (IR) theories. Our algebraic method applies to the domain wall problem in $2+1$ dimensional topologically ordered systems and the corresponding classification of $1+1$ dimensional gapped phase, for example. An ideal decomposition of a fusion ring provides a straightforward but strong constraint on the gapped phase with noninvertible symmetry and its symmetry-breaking (or emergent symmetry) patterns. Moreover, even in several specific homomorphisms connected under massless RG flows, less familiar homomorphisms appear, and we conjecture that they correspond to partially solvable models in recent literature. Our work demonstrates the fundamental significance of the abstract algebraic structure, ideal, for the RG in physics.",
    "authors": [
      "Yoshiki Fukusumi",
      "Yuma Furuta"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.03917",
    "title": "Quantum chemistry for solids made simple on the Clifford torus",
    "abstract": "We present a general theory to treat periodic solids with quantum-chemistry methods. It relies on two main developments: 1) the modeling of a solid as a Clifford torus which is a torus that is both periodic and flat and 2) the introduction of a periodic gaussian basis set that is compatible with the topology of the Clifford torus. We illustrate our approach by calculating the ground-state energy of a periodic chain of hydrogen atoms within both Hartree-Fock and coupled cluster theory. We demonstrate that our approach yields the correct ground-state energy in the thermodynamic limit by comparing it to the ground-state energy of a ring of hydrogen atoms in the same limit. Since equivalent ring-like calculations for three-dimensional solids are impossible, our approach is an excellent alternative to perform quantum-chemistry calculations of solids. Our Clifford formalism can be seamlessly combined with current implementations of quantum-chemistry methods designed for atoms and molecules to make them applicable to solids.",
    "authors": [
      "Amer Alrakik",
      "Gian Luigi Bendazzoli",
      "Stefano Evangelisti",
      "J. Arjan Berger"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.12295",
    "title": "Resonant dynamics of spin cluster in a periodically driven one-dimensional Rydberg lattice",
    "abstract": "Rydberg lattice under facilitation conditions can feature kinetic constraints, leading to ballistic and nonergodic behavior at different detuning intensities. Here, we demonstrate that a resonant driving field can achieve effects similar to those under facilitation conditions. We focus on the relaxation dynamics of spin clusters in a periodically driven Rydberg spin lattice. Through an effective Hamiltonian for the domain walls of the spin cluster, it is shown that when the driving frequency is resonant with the Rydberg interaction, the spin cluster exhibits ballistic expansion with half the spreading rate compared to the case of facilitation conditions. However, near the resonant point, the spin cluster displays confinement behavior of the Bloch-like oscillations. These results demonstrate the rich dynamic behaviors in the driven Rydberg spin lattices and may find applications in quantum state manipulation.",
    "authors": [
      "Jin-Qiu Xiong",
      "Yu-Hong Yan",
      "Xun-Da Jiang",
      "Yong-Yao Li",
      "Kun-Liang Zhang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.05588",
    "title": "Anomalous Magnetoresistance beyond the Jullière Model for Spin Selectivity in Chiral Molecules",
    "abstract": "The issue of anomalous high magnetoresistance, beyond the Jullière model, observed in nonmagnetic electrode-chiral molecular-ferromagnetic electrode devices has puzzled the community for a long time. Here, by considering the magnetic proximity effect which shifts the nonmagnetic-ferromagnetic interface toward chiral molecules, we show the anomalous high magnetoresistance beyond the spin polarization in ferromagnetic electrodes even in the very weak spin-orbit coupling. Our results are in excellent agreement with the experiments, demonstrating that the spin-orbit coupling plays a fundamental role in chiral-induced spin selectivity and the magnetic proximity effect can dramatically enhance the magnetoresistance. These results elucidate the interaction between chiral molecules and ferromagnetic electrodes and facilitate the design of chiral-based spintronic devices.",
    "authors": [
      "Tian-Yi Zhang",
      "Yue Mao",
      "Peng-Yi Liu",
      "Ai-Min Guo",
      "Qing-Feng Sun"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12178",
    "title": "All that structure matches does not glitter",
    "abstract": "Generative models for materials, especially inorganic crystals, hold potential to transform the theoretical prediction of novel compounds and structures. Advancement in this field depends on robust benchmarks and minimal, information-rich datasets that enable meaningful model evaluation. This paper critically examines common datasets and reported metrics for a crystal structure prediction task$\\unicode{x2014}$generating the most likely structures given the chemical composition of a material. We focus on three key issues: First, materials datasets should contain unique crystal structures; for example, we show that the widely-utilized carbon-24 dataset only contains $\\approx$40% unique structures. Second, materials datasets should not be split randomly if polymorphs of many different compositions are numerous, which we find to be the case for the perov-5 and MP-20 datasets. Third, benchmarks can mislead if used uncritically, e.g., reporting a match rate metric without considering the structural variety exhibited by identical building blocks. To address these oft-overlooked issues, we introduce several fixes. We provide revised versions of the carbon-24 dataset: one with duplicates removed, one deduplicated and split by number of atoms $N$, one with enantiomorphs, and two containing only identical structures but with different unit cells. We also propose new splits for datasets with polymorphs, ensuring that polymorphs are grouped within each split subset, setting a more sensible standard for benchmarking model performance. Finally, we present METRe and cRMSE, new model evaluation metrics that can correct existing issues with the match rate metric.",
    "authors": [
      "Maya M. Martirossyan",
      "Thomas Egg",
      "Philipp Hoellmer",
      "George Karypis",
      "Mark Transtrum",
      "Adrian Roitberg",
      "Mingjie Liu",
      "Richard G. Hennig",
      "Ellad B. Tadmor",
      "Stefano Martiniani"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.13941",
    "title": "Diffeomorphism invariant tensor networks for 3d gravity",
    "abstract": "Tensor networks prepare states that share many features of states in quantum gravity. However, standard constructions are not diffeomorphism invariant and do not support an algebra of non-commuting area operators. Recently, analogues of both problems were addressed in a tensor network discretization of topological field theories (TFT) with finite or compact gauge groups. Here, we extend this work towards gravity by generalizing to gauge groups that are discrete or continuous, compact or non-compact. Applied to $\\text{SL}(2,\\mathbb{R}) \\times \\text{SL}(2,\\mathbb{R})$ Chern-Simons theory, our construction can be interpreted as building states of three dimensional gravity with a negative cosmological constant. Our tensor networks prepare states that satisfy the constraints of Chern-Simons theory. In metric variables, this implies that the states we construct satisfy the Wheeler-DeWitt equation and momentum constraints, and so are diffeomorphism invariant.",
    "authors": [
      "Vijay Balasubramanian",
      "Charlie Cummings"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.18303",
    "title": "Hierarchical Deep Research with Local-Web RAG: Toward Automated System-Level Materials Discovery",
    "abstract": "We present a long-horizon, hierarchical deep research (DR) agent designed for complex materials and device discovery problems that exceed the scope of existing Machine Learning (ML) surrogates and closed-source commercial agents. Our framework instantiates a locally deployable DR instance that integrates local retrieval-augmented generation with large language model reasoners, enhanced by a Deep Tree of Research (DToR) mechanism that adaptively expands and prunes research branches to maximize coverage, depth, and coherence. We systematically evaluate across 27 nanomaterials/device topics using a large language model (LLM)-as-judge rubric with five web-enabled state-of-the-art models as jurors. In addition, we conduct dry-lab validations on five representative tasks, where human experts use domain simulations (e.g., density functional theory, DFT) to verify whether DR-agent proposals are actionable. Results show that our DR agent produces reports with quality comparable to--and often exceeding--those of commercial systems (ChatGPT-5-thinking/o3/o4-mini-high Deep Research) at a substantially lower cost, while enabling on-prem integration with local data and tools.",
    "authors": [
      "Rui Ding",
      "Rodrigo Pires Ferreira",
      "Yuxin Chen",
      "Junhong Chen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22114",
    "title": "Optical spin precession",
    "abstract": "Period-averaged electromagnetic spin angular momentum is a well-established quantity for monochromatic fields, governing phenomena such as light-matter interactions with chiral particles and spin-orbit coupling effects. In contrast, the spin angular momentum of non-monochromatic fields remains unexplored. Here, we extend the concept of optical spin to the domain of non-monochromatic electromagnetic fields. Through this formulation, we uncover the precessional dynamics of electromagnetic spin in specific polychromatic configurations, including the superposition of circularly and linearly polarized plane waves propagating orthogonally at different frequencies, as well as fields generated by a precessing magnetic dipole. We discover that the dynamics of the electromagnetic spin in these cases obeys a Landau-Lifshitz-like equation establishing a profound parallel between dynamics of magnetization and photonic spin.",
    "authors": [
      "Abanoub Mikhail",
      "Maxim Mazanov",
      "Ilya Deiry",
      "Mingzhao Song",
      "Ivan Iorsh",
      "Andrey Bogdanov"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03104",
    "title": "Tau--Function Multilinear Hierarchy of the Tomimatsu--Sato Spacetime: A Gravitational Realization of the YTSF Integrable Structure",
    "abstract": "The Tomimatsu--Sato (TS) family generalizes the Kerr black hole to higher multipole order $\\delta$ and has long been regarded as algebraically complicated without any clear integrability. We show instead that stationary axisymmetric vacuum Einstein equations, when the Ernst potential is written as a $\\tau$--ratio $\\mathcal{E}=\\tau_1/\\tau_0$, admit a universal decomposition of the Ernst numerator into a cubic part containing all second derivatives and a quartic \\emph{gradient envelope}. The cubic sector can be written in terms of $Z_3$--symmetric trilinear Hirota operators, revealing a hidden integrable structure. For $\\delta=2$, using the explicit Tomimatsu--Sato polynomials, we verify that this trilinear sector coincides with a Yu--Toda--Sasa--Fukuyama (YTSF) equation-type kernel. Thus the TS geometry forms a gravitational realization of a multilinear $\\tau$--function hierarchy in stationary axisymmetric general relativity.",
    "authors": [
      "Takeshi Fukuyama"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03118",
    "title": "Probing for primordial black hole candidates in exoplanet search data",
    "abstract": "We have sifted through astrophysical data collected by various radial velocity and gravitational microlensing searches for exoplanets with the goal of identifying potential signs of the presence of primordial black holes (PBH). Our motivation is that those hypothesized remnants of inhomogeneous energetic fluctuations in the early universe, though too small for direct detection, are thought to have a mass range similar to that of planets. Thereby, if captured by stars, they could conceivably make their presence known through stellar wobbles picked up by means of Doppler spectroscopy in the radial velocity method, or alternatively through microlensing. In our analysis of such data, we have identified potential PBH contenders by ruling out any exoplanet candidates that have been detected through direct imaging or transit methods, as they would have sizes consistent with planets rather than PBHs. In particular we focus on the objects Kepler-21 Ac, HD 219134 f, Gliese 686 b, HR 5183 b, HD 20794 e, and Wolf 1061 d, each of which has been found using the radial velocity method but never imaged (either directly or through transit). We also examine the microlensing events MOA 2009-BLG-387L and OGLE-2016-BLG-1540, which offer promise as candidate PBHs. We present these as a representative, but not exclusive list, of potential PBH contenders. Furthermore, future imaging, especially focused on signals of planetary dimensions versus evaporation signatures, might clarify which of these are indeed exoplanets.",
    "authors": [
      "Paul Halpern",
      "Erik Cauley",
      "Max Stoltzmann",
      "Mauritz Wilshusen"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03152",
    "title": "Inferring black hole formation channels in GWTC-4.0 via parametric mass-spin correlations derived from first principles",
    "abstract": "We investigate the differences between several proposed formation scenarios for binary black holes (BBHs), including isolated stellar evolution, dynamical assembly in dense clusters and AGN disks, and primordial BHs. Our approach exploits the predicted spin features of each formation channel, and adopts parameterized models of the predicted correlations between the spin magnitudes (and orientations) and mass, inspired by first principles. Using hierarchical Bayesian inference on the recent GWTC-4.0 dataset, we compare these features across all models and assess how well each scenario explains the data. We find that the data strongly favor the presence of a positive correlation between mass and spin magnitude, in agreement with previous studies. Furthermore, the hierarchical scenario provides a better fit to the observations, due to the inclusion of second-generation mergers leading to higher spins at larger masses. The current dataset is not informative enough about spin orientation: the cluster (random orientations) and AGN (aligned orientations) scenarios have comparable Bayesian evidence. Finally, the mass-spin correlation predicted by the primordial scenario gives a poor fit to the data, and this scenario can only account for a subset of the observed events.",
    "authors": [
      "Emanuele Berti",
      "Francesco Crescimbeni",
      "Gabriele Franciolini",
      "Simone Mastrogiovanni",
      "Paolo Pani",
      "Grégoire Pierra"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03155",
    "title": "From scalar clouds around evaporating black holes to boson star",
    "abstract": "We study, for the first time, the evolution of a scalar cloud bound to an evaporating black hole. Our simulations of the associated Schrödinger-Poisson system for non-relativistic and spherically symmetric clouds reveal that a scalar cloud may (partially) survive as a self-gravitating boson star if the black hole evaporates adiabatically until its mass becomes less than one half of the cloud's mass. This yields a novel mechanism for boson star formation and shows that, as previously conjectured, bosonic dark matter production by light primordial black holes may result in micro-boson stars with very large occupation numbers, greatly enhancing their potential detectability even for very weakly interacting dark matter particles.",
    "authors": [
      "Daniel Neves",
      "João G. Rosa"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03251",
    "title": "Many Worlds in Theory Space: A Quantum Origin for the Constants of Nature",
    "abstract": "Many of the numbers appearing in the laws of physics, such as the strength of electromagnetism or the masses of elementary particles, must lie in precise ranges for stars, planets, and chemistry to exist. Why the universe has such these values is one of the deepest questions in science. Here we propose that these constants arise from quantum mechanics itself. By enlarging the configuration space of quantum cosmology, we treat the constants of nature as part of the wavefunction of the universe. The universal wavefunction contains support for many possible sets of constants, and early-universe processes cause these possibilities to decohere into distinct classical universes. Our universe is one such branch, compatible with complexity and life. We defined the Grand Hilbert Space as the direct sum of U-sectors, each representing a distinct set of physical laws. We derived the Meta-Wheeler--DeWitt equation, which governs the dynamics of the theory parameters. We showed that in the Planck era, the kinetic terms for these parameters are active, creating a state of primordial coherence where the laws of physics effectively fluctuate. This formalism offers a quantitative tool for high-energy physics. We proposed that the total integrated amplitude over theory space serves as a Bayesian evidence metric, allowing for the statistical comparison of rival microscopic theories based on their fertility in generating habitable sectors. Finally, this work makes a specific, falsifiable prediction: there will never be a successful, purely mathematical derivation of the Standard Model parameters.",
    "authors": [
      "Edward J Shaya"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03380",
    "title": "Constraints on Reversing the Thermodynamic Arrow of Time from Black Hole Thermodynamics, Wormholes, and Time-Symmetric Quantum Mechanics",
    "abstract": "Can the thermodynamic arrow of time in a single universe be reversed, even temporarily, within semiclassical gravity without invoking additional universes or branches? We address this question in a single, connected spacetime where quantum field theory is coupled to classical general relativity, and where black holes, traversable wormholes, and time-symmetric or retrocausal formulations of quantum mechanics might naively appear to open channels for entropy export or cancellation. After distinguishing fine-grained, coarse-grained, and generalized gravitational entropy, and formulating a cosmological coarse-grained entropy, we treat black hole evaporation, wormholes constrained by quantum energy inequalities, and two-time boundary-value frameworks (including absorber-type and two-state-vector formalisms) within a common information-theoretic language. We then introduce a \"Global Entropy Transport\" (GET) framework and derive a sectoral inequality that bounds the net decrease of matter-plus-radiation entropy in terms of changes in horizon area and correlation (mutual-information) terms, assuming the generalized second law and modern focusing and energy conditions. Within this framework, black holes, wormholes, and retrocausal protocols can at most redistribute entropy among matter, radiation, and gravitational sectors and reshape the local pattern of entropy production. They do not, under current semiclassical, holographic, and statistical-mechanical constraints, permit a genuine reversal of the universal thermodynamic arrow in a single connected universe.",
    "authors": [
      "Kevin Song",
      "John Zhang"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03484",
    "title": "Motion of a charged test particle around a static black hole in a monopole magnetic field",
    "abstract": "We study the motion of a charged test particle in the spacetime with a spherically symmetric black hole which is immersed in a monopole magnetic field. We show that the radial motion of the charged test particle is governed by completely the same equation as that in the case of no magnetic field. This result implies that the black hole will acquire the electric charge if it is surrounded by the collisionless plasma composed of protons and electrons which obey the Maxwell velocity distribution. The drastically different situation appears in the tangential motions of charged test particles due to the magnetic field. The trajectory of a charged test particle in the black hole with the magnetic field of the order of 10 Gauss near the black hole, is confined on a very thin cone as long as the specific angular momentum of the particle is not much larger than the gravitational radius of the black hole times the speed of light. This result leads to a possibility that a plasma lump can hover over the black hole and is very hot, in the monopole magnetic field.",
    "authors": [
      "Ken-ichi Nakao",
      "Yota Endo",
      "Hideki Ishihara",
      "Kenta Matsuo",
      "Kensuke Sueto",
      "Koudai Ueda",
      "Hirotaka Yoshino"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03529",
    "title": "Multi-probe analysis of strong-field effects in $f(Q)$ gravity",
    "abstract": "Covariant $f(Q)$ gravity is a viable extension of General Relativity, however its strong-field predictions remain largely untested. Using the static, spherically symmetric black-hole solutions of the theory, we confront it with the most stringent probes available: black-hole shadows, Event Horizon Telescope (EHT) measurements, S2-star precession, and strong gravitational lensing. We show that the two admissible solution branches behave very differently: Case~I produces negligible deviations from Schwarzschild solution, whereas Case~II yields significant, potentially observable corrections to the photon sphere and shadow size. From the EHT shadow diameters of M87* and Sgr~A*, we obtain tight bounds, which are further strengthened by strong-lensing coefficients. These results provide the sharpest strong-field constraints on covariant $f(Q)$ gravity to date, and point toward future tests using next-generation horizon-scale imaging and precision Galactic-center astrometry.",
    "authors": [
      "Mohsen Khodadi",
      "Behnam Pourhassan",
      "Emmanuel N. Saridakis"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03561",
    "title": "Feeding a Kerr black hole with quantized vortices",
    "abstract": "By solving a nonlinear Klein-Gordon equation in Kerr geometry, we uncover new phenomena and key characteristics of quantized vortices in quantum fluids near a Kerr black hole. The formation of these vortices induces rotational or turbulent flows, which profoundly alter the fluid properties and revise those dark matter models describing axion condensates, ultralight boson clouds, and other scalar fields in the vicinity of spinning black holes. As macroscopic, quantum, and topological defects, these vortices can stably orbit the black hole over extended periods, establishing their viability as novel probes for investigating black hole physics. For instance, we calculate the angular velocities of orbiting vortices to quantitatively characterize the frame-dragging effect, a classic prediction of general relativity. Additionally, we observe that relatively large vortices are accreted onto the black hole, wrapping around it while undergoing splitting and reconnecting processes. In quantum fluids with high vortex densities, turbulent flows emerge, accompanied by the formation of a vortex boundary layer near the event horizon. Beyond the ergosphere, we find vortex emissions and energetic outbursts, which may provide crucial insights into analogous astrophysical events recently discovered by the XRISM satellite.",
    "authors": [
      "Shilong Jin",
      "Xiaofei Zhao",
      "Yong Zhang",
      "Chi Xiong"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03645",
    "title": "Gauge Symmetries, Contact Reduction, and Singular Field Theories",
    "abstract": "The reduction of dynamical systems which are invariant under changes of global scale is well-understood, for classical theories of particles, and fields. The excision of the superfluous degree of freedom describing such a scale leads to a dynamically-equivalent theory, which is frictional in nature. In this article, we extend the formalism to physical models, of both particles and fields, described by singular Lagrangians. Our treatment of classical field theory is based on the manifestly covariant Hamilton De-Donder Weyl formalism, in which the Lagrangian density is introduced as a bundle morphism on the pre-multisymplectic velocity phase space $J^1E$. The results obtained are subsequently applied to a number of physically-motivated examples, as well as a discussion presented on the implications of our work for classical General Relativity.",
    "authors": [
      "Callum Bell",
      "David Sloan"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03668",
    "title": "Spherical accretion onto higher-dimensional Reissner-Nordström Black Hole",
    "abstract": "We obtain relativistic solutions of spherically symmetric accretion by a dynamical analysis of a generalised Hamiltonian for higher-dimensional Reissner-Nordström (RN) Black Hole (BH). We consider two different fluids namely, an isotropic fluid and a non-linear polytropic fluid to analyse the critical points in a higher-dimensional RN BH. The flow dynamics of the fluids are studied in different spacetime dimensions in the framework of Hamiltonian formalism. The isotropic fluid is found to have both transonic and non-transonic flow behaviour, but in the case of polytropic fluid, the flow behaviour is found to exhibit only non-transonic flow, determined by a critical point that is related to the local sound speed. The critical radius is found to change with the spacetime dimensions. Starting from the usual four dimensions it is noted that as the dimension increases the critical radius decreases, attains a minimum at a specific dimension ($D>4$) and thereafter increases again. The mass accretion rate for isotropic fluid is determined using Hamiltonian formalism. The maximum mass accretion rate for RN BH with different equations of state parameters is studied in addition to spacetime dimensions. The flow behaviour and mass accretion rate for a change in BH charge is also studied analytically. It is noted that the maximum mass accretion rate in a higher-dimensional Schwarzschild BH is the lowest, which however, increases with the increase in charge parameter in a higher-dimensional RN BH.",
    "authors": [
      "Bibhash Das",
      "Anirban Chanda",
      "Bikash Chandra Paul"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03713",
    "title": "A theory-agnostic hierarchical Bayesian framework for black-hole spectroscopy: a case study on GW250114 in Einstein-dilaton-Gauss-Bonnet gravity",
    "abstract": "Black-hole spectroscopy has emerged as a powerful probe of strong-field gravity in the era of gravitational-wave astronomy. In this context, many current tests of modified or extended gravity are implemented by searching for predicted signatures modeled as perturbative corrections to general-relativistic waveforms; however, this approach may introduce model-dependent systematics and limit applicability to broader classes of theories. To complement such methods, we develop a theory-agnostic hierarchical Bayesian framework that connects ringdown observations -- modeled as damped sinusoids -- directly with theoretical quasinormal mode spectra, performing the comparison at the spectral level rather than through theory-specific waveform matching. The framework incorporates a soft-truncation module to account for the finite domain of validity in the theory's parameter space and is equipped with quantitative diagnostics that identify stable analysis time windows. As an illustrative application, we implement the framework within Einstein-dilaton-Gauss-Bonnet gravity and apply it to the gravitational-wave event GW250114, finding that the resulting posterior for the dimensionless coupling $\\zeta$ is robust against prior assumptions yet remains only weakly informative over the range considered in this work. We further perform controlled ringdown injection studies across different values of $\\zeta$, confirming that nonzero couplings can be recovered while also indicating a potential systematic effect: Kerr-based priors in the $\\zeta$ inference may partially absorb spectral deviations arising in alternative theories of gravity. This work establishes a transparent and extensible foundation for future strong-field gravity tests, naturally compatible with the growing precision and modal resolution of next-generation gravitational-wave detectors.",
    "authors": [
      "Shitong Guo",
      "Yan-Gang Miao"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03823",
    "title": "Approximations and modifications of celestial dynamics tested on the three-body system",
    "abstract": "Large-scale simulations of celestial systems are based on approximations or modifications of classical dynamics. The approximations are with ``particle-mesh'' (PM) substitutions of the attractions from objects far away, or one modify the Newtonian accelerations (MOND) or the gravities (MOGA). The PM approximation and MOND modification of classical dynamics break the invariances of classical dynamics. The simple three-body system (TBS) is the simplest system to test the approximations and modifications of celestial dynamics, and it is easy to implement on a computer. Simulations of the TBS show that the PM approximation and MOND destabilize TBS. In contrast, the MOGA modification of gravity by replacing Newton's inverse square attraction with an inverse attraction for far-away interactions stabilizes the system. The PM approximation and the MOND modification of classical dynamics do not preserve the momentum and angular momentum of a conservative system exactly, and PM does not obey Newton's third law. Although the errors and shortcomings of these PM approximations and MOND modifications are small, they cause the instability of the regular dynamics.",
    "authors": [
      "Søren Toxvaerd"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03832",
    "title": "Some perspective of thermodynamical and optical properties of black holes in Maxwell-dilaton-dRGT-like massive gravity",
    "abstract": "Motivated by integrating the dilaton field (as a UV correction) with dRGT-like massive gravity (as an IR correction) into Einstein gravity, we investigate the thermodynamic and optical properties of black holes within this gravitational framework. We begin by reviewing the black hole solutions in Maxwell-dilaton-dRGT-like massive gravity, followed by an analysis of how various parameters influence on the asymptotical behavior of the spacetime and the event horizon of these black holes. In the subsequent section, we examine the conserved and thermodynamic quantities associated with these black holes, paying particular attention to the effects of parameters like $\\beta$, $\\alpha$, and the massive parameters ($\\eta_{1}$ and $\\eta_{2}$) on their local stability by simultaneously evaluating the heat capacity and temperature. We also adopt an alternative method to study phase transitions using geometrothermodynamics. Furthermore, we explore how the parameters of Maxwell-dilaton-dRGT-like massive gravity impacts the optical characteristics and radiative behavior of black holes. In particular, we analyze the effects of the dilaton coupling constant ($\\alpha$), charge ($q$), the massive gravity parameter ($\\eta_1$), and the graviton mass ($m_g$) on the radius of the photon sphere and the resulting black hole shadow. Moreover, the theoretical shadow radius is compared to the observational data from $Sgr A^*$. Additionally, we investigate the energy emission rate of these black holes, revealing that these parameters substantially influence the emission peak.",
    "authors": [
      "B. Eslam Panah. N. Heidari",
      "M. Soleimani"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03855",
    "title": "Fractional Holographic Dark Energy Driven Reconstruction of $f(Q)$ Gravity and its Cosmological Implications",
    "abstract": "In order to explain the late-time acceleration of the Universe, we present a reconstructed version of the $f(Q)$ gravity theory in this work, which is inspired by the integrating the fractional holographic dark energy with the Hubble horizon as the infrared cutoff. This reconstructed $f(Q)$ gravity model shows a geometrically motivated dark energy component and naturally recovers General Relativity in the appropriate limit. The free parameters of the model are constrained using the latest DESI BAO data, previous BAO compilations (P-BAO), and cosmic chronometer (CC) datasets through a Markov Chain Monte Carlo (MCMC) analysis. The reconstructed Hubble parameter $H(z)$ exhibits excellent consistency with observational data, with high values of $R^2$ and low values of $\\chi^2_{\\min}$, AIC, and BIC, confirming the model's strong statistical performance relative to $\\Lambda$CDM. With current $q(0) \\in [-0.40, -0.32]$ and a transition redshift $z_{\\text{tr}} \\sim 0.56$--$0.72$, the dynamical diagnostics show a smooth transition from a decelerated to an accelerated phase. While the $Om(z)$ diagnostic exhibits a negative slope, indicating that the model is not $\\Lambda$CDM, the effective equation-of-state parameter $\\omega_{\\text{eff}}(z)$ stays within the quintessence regime ($-1 < \\omega_{\\text{eff}} < -1/3$). The analysis of classical energy conditions shows that the WEC, DEC, and NEC are satisfied throughout the cosmic evolution, with a violation of the SEC at lower-redshift, which is consistent with late-time acceleration. Linear homogeneous perturbation analysis further confirms the model's dynamical stability. Conclusively, the FHDE-inspired reconstructed $f(Q)$ gravity provides a stable, observationally compatible, and geometrically motivated alternative to $\\Lambda$CDM, that successfully describes the late-time cosmic acceleration within the symmetric teleparallel framework.",
    "authors": [
      "Rajdeep Mazumdar",
      "Kalyan Malakar",
      "Kalyan Bhuyan"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03896",
    "title": "Shadow geometry of Kerr MOG naked singularity and analysis of accretion disk luminosity",
    "abstract": "Naked singularities are hypothetical astrophysical entities featuring gravitational singularities without event horizons. In this study, we analyze the shadow properties of Kerr Modified Gravity (Kerr MOG) naked singularities (KMNSs). We show that the KMNS shadow can appear closed, open, or even vanish, depending on the dimensionless spin parameter a, the modified gravity parameter alpha, and the observer's inclination angle. We identify the critical conditions under which the KMNS shadow develops a gap, a unique feature not present in BH shadows. We analyze the properties of a thin accretion disk surrounding a KMNS, within the framework of MOG characterized by the parameter alpha. The study includes a detailed examination of the spacetime geometry and the equations of motion for test particles. In addition, we adopt a simplified model for the disk's radiative flux, temperature distribution, and spectral luminosity. Our analysis primarily focuses on the flux distribution of the accretion disk around KMNS with identical mass but varying spin and MOG deformation parameters. This allows us to explore how modifications in rotation and the MOG parameter alpha influence the radiative properties of the disk. Further, these observational signatures may serve as effective tools for clearly distinguishing KMNS from standard Kerr naked singularities (KNSs), where the MOG parameter alpha = 0",
    "authors": [
      "Saira Yasmin",
      "Mubasher Jamil"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03919",
    "title": "Primordial Gravitational Wave Birefringence in a de Sitter Background with Chern-Simons Coupling",
    "abstract": "In this work, we investigate tensor perturbations in a de Sitter background within the framework of Chern-Simons modified gravity. We introduce transverse-traceless perturbations and analyze how the Chern-Simons Cotton tensor induces parity-violating modifications to gravitational wave propagation, while the Pontryagin density vanishes at linear order. Using a mode decomposition of the scalar background field, we derive the sub- and super-horizon limits of the wave equations and uncover chiral corrections in the dispersion relations of tensor modes. The resulting birefringence exhibits both amplitude and velocity components, alternating with the phase of the scalar field. Particular solutions sourced by the scalar background show helicity-dependent amplification and a characteristic scaling of the radiated flux that reduces smoothly to the Minkowski limit. The accumulated phase difference between right- and left-handed modes grows quadratically inside the horizon and becomes frozen outside, leaving a permanent parity-violating imprint in the primordial tensor spectrum. Finally, by promoting the Chern-Simons field to a massive dark matter candidate, we demonstrate how its mass-dependent dynamics connect gravitational birefringence to axion-like dark matter phenomenology.",
    "authors": [
      "Abhishek Rout",
      "Brett Altschul"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04083",
    "title": "Screening of dipolar emission in two-scale Gauss-Bonnet gravity",
    "abstract": "We study black holes in shift-symmetric scalar Gauss-Bonnet gravity extended by a cubic Galileon interaction with a distinct energy scale. Introducing this hierarchy profoundly modifies the theory's phenomenology. The cubic interaction allows for smaller black holes, and can generate a screening mechanism near the horizon, making large Gauss-Bonnet couplings consistent with gravitational-wave bounds. Observable quantities such as the scalar charge, the innermost stable circular orbit, and its frequency are most affected for small black holes. The resulting multi-scale effective field theory remains technically natural and offers new avenues to probe gravity in the strong-field regime.",
    "authors": [
      "Farid Thaalba",
      "Leonardo Gualtieri",
      "Thomas P. Sotiriou",
      "Enrico Trincherini"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03142",
    "title": "Topological Einstein gravity as Kodaira-Spencer gravity",
    "abstract": "As a contribution towards quantizing three-dimensional gravity, we show at the classical level that Euclidean three-dimensional Einstein gravity with a negative cosmological constant is uplifted to the $SU(2)$-invariant sector of Kodaira-Spencer gravity on a Calabi-Yau three-fold. Kodaira-Spencer gravity appears in the target space description of the B-model topological string theory and describes deformations of a complex structure. We prove that given a reference solution of Einstein gravity in the first-order formulation, a second off-shell configuration uplifts to a unique complex structure deformation in six dimensions. If the configuration satisfies Einstein's equations, the complex structure deformation is integrable, i.e. a solution of Kodaira-Spencer gravity. We demonstrate the uplift explicitly for Bañados solutions. Our construction embeds three-dimensional gravity into topological string theory and AdS$_3$/CFT$_2$ duality into twisted holography.",
    "authors": [
      "Johanna Erdmenger",
      "Jonathan Karl",
      "Jani Kastikainen",
      "René Meyer",
      "Henri Scheppach"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03161",
    "title": "A New Type of Saddle in Euclidean IKKT Matrix Model and Its Effective Geometry",
    "abstract": "We study the equation of motion of the Euclidean IKKT matrix model, and realize a new type of classical saddle that only exists in $N\\rightarrow\\infty$ limit. Under the assumption that the matrices are the generators of $\\mathfrak{so}(n,m)$, we identify a unique solution, that is, $\\mathfrak{so}(1,3)$. Even though it has $6$ generators and thus $6$ non-zero matrices, they are not independent due to the $2$ Casimir constraints in $\\mathfrak{so}(1,3)$. Exploiting the Lie-algebraic structure and the Casimir constraints, we derive the effective metric that a test probe propagates on. The resulting effective metric exhibits an $SO(3)$ symmetry, matching the spatial symmetry of our universe.",
    "authors": [
      "Henry Liao",
      "Reishi Maeta"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03167",
    "title": "Energy Reflection and Transmission of Interfaces in $T\\bar{T}$-deformed CFT",
    "abstract": "Conformal interfaces gluing a pair of two-dimensional conformal field theories enjoy a large degree of universality in terms of the coefficients of reflection and transmission of energy, that describe the scattering of conformal matter at the interface. In this article, we study these coefficients beyond conformality, by gluing a pair of $T\\bar T$-deformed 2D CFTs across an interface, which requires the condition $c_L \\mu_L = c_R \\mu_R $ to be obeyed. We show that, at least when the interface admits a holographic description, the $T\\bar T$ deformation of the CFTs can be extended to the interface. We propose a generalization of the linear matching condition in the universal sector of the undeformed ICFT to a non-linear one, which is captured by a universal antisymmetric \\emph{transmission function} of the incoming fluxes. We employ the flow equations of the $T\\bar T$-deformed CFTs to compute this function in two special classes of states, namely the non-equilibrium steady state (NESS) and scattering state. We show that the results can also be reproduced using holographic techniques in the bulk dual of these states.",
    "authors": [
      "Avik Banerjee",
      "Giuseppe Policastro"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03314",
    "title": "EFT of Dark Energy with Cosmic Chronometers: Reconstructing Background EFT Functions",
    "abstract": "The effective field theory (EFT) of dark energy provides a model-independent framework for studying cosmology within scalar-tensor theories. In this work, we explore how the time evolution of the cosmological background, inferred from cosmic chronometer measurements of the Hubble parameter, can be used to reconstruct the relevant EFT functions. Our approach enables the direct determination of these EFT functions from observational data without assuming any specific cosmological model. This makes it possible to test the background evolution of a wide range of dark energy models, including the $\\Lambda$CDM model. We further demonstrate how the reconstructed EFT functions can be applied to constrain concrete theories, such as the quintessence model.",
    "authors": [
      "Fumiya Okamatsu",
      "Kazufumi Takahashi"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03440",
    "title": "An Analysis of LIGO Glitches Using t-SNE During the First Part of the Fourth LIGO-Virgo-KAGRA Observing Run",
    "abstract": "This paper presents an analysis of noise transients observed in LIGO data during the first part of the fourth observing run, using the unsupervised machine learning technique t-distributed Stochastic Neighbor Embedding (t-SNE) to examine the behavior of glitch groups. Based on the t-SNE output, we apply Agglomerative Clustering in combination with the Silhouette Score to determine the optimal number of groups. We then track these groups over time and investigate correlations between their occurrence and environmental or instrumental conditions. At the Livingston observatory, the most common glitches during O4a were seasonal and associated with ground motion, whereas at Hanford, the most prevalent glitches were related to instrumental conditions.",
    "authors": [
      "Tabata Aira Ferreira",
      "Gabriela González",
      "Osvaldo Salas"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03496",
    "title": "Constraint-Preserving High-Order Compact OEDG Method for Spherically Symmetric Einstein-Euler System",
    "abstract": "Numerical simulation of the spherically symmetric Einstein--Euler (EE) system faces severe challenges due to the stringent physical admissibility constraints of relativistic fluids and the geometric singularities inherent in metric evolution. This paper proposes a high-order Constraint-Preserving (CP) compact Oscillation-Eliminating Discontinuous Galerkin (cOEDG) method specifically tailored to address these difficulties. The method integrates a scale-invariant oscillation-eliminating mechanism [M. Peng, Z. Sun, K. Wu, Math. Comp., 94: 1147--1198, 2025] into a compact Runge--Kutta DG framework. By characterizing the convex invariant region of the hydrodynamic subsystem with general barotropic equations of state, we prove that the proposed scheme preserves physical realizability (specifically, positive density and subluminal velocity) directly in terms of conservative variables, thereby eliminating the need for complex primitive-variable checks. To ensure the geometric validity of the spacetime, we introduce a bijective transformation of the metric potentials. Rather than evolving the constrained metric components directly, the scheme advances unconstrained auxiliary variables whose inverse mapping automatically enforces strict positivity and asymptotic bounds without any limiters. Combined with a compatible high-order boundary treatment, the resulting CPcOEDG method exhibits robust stability and design-order accuracy in capturing strong gravity-fluid interactions, as demonstrated by simulations of black hole accretion and relativistic shock waves.",
    "authors": [
      "Yuchen Huang",
      "Manting Peng",
      "Kailiang Wu"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03867",
    "title": "The Cosmological Dipole in Tilted Anisotropic Universes",
    "abstract": "There is tentative evidence for a mismatch between the rest frames of matter and the cosmic microwave background, the \"quasar dipole anomaly\". We consider such a dipole in tilted anisotropic models, for a range of scenarios and sources: spatial curvature, cosmic heat flux, large scale electromagnetic fields and a Khronon field. Crucially, we determine the ancillary effects on other cosmological observables in each of these models and we show that, apart from the case of the Khronon field, it is unlikely that one can obtain a dipole with the amplitude that is being observed unless one considers additional exotica.",
    "authors": [
      "Alicia Martín",
      "Constantinos Skordis",
      "Deaglan J. Bartlett",
      "Harry Desmond",
      "Pedro G. Ferreira",
      "Tariq Yasin"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03888",
    "title": "The anisotropy and magnetic field structure of neutron stars through gravitational wave",
    "abstract": "We investigate how gravitational wave (GW) observations can probe the internal physics of neutron stars by extending the Tolman-Oppenheimer-Volkoff framework to include pressure anisotropy and internal magnetic fields. Two representative magnetic field configurations, radial orientation dominated (RO) and transverse orientation dominated (TO), are implemented with strength and decay prescriptions. We found that both anisotropy and magnetic fields increase the maximum supported mass and modify the tidal deformability $\\Lambda$, thereby imprinting measurable signatures on GW signals. For the equal mass binary ($1.2M_\\odot$-$1.2M_\\odot$), anisotropy neutron star with RO magnetic field yield more compact stars and a larger shift in $\\Lambda$, allowing discrimination at signal-to-noise ratios (SNRs) as low as $\\sim18$ using the O4 power spectra density. TO fields produce weaker effects and require substantially higher SNRs for detection. In conclusion, we conclude that gravitational waves are capable of probing the internal structure of neutron stars.",
    "authors": [
      "Zhao-Wei Du",
      "Xi-Long Fan"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03959",
    "title": "Primary gravitational waves at high frequencies I: Origin of suppression in the power spectrum",
    "abstract": "[Abridged] The primary gravitational waves (PGWs) are generated in the early universe from the quantum vacuum during inflation. In slow roll inflation, the power spectrum (PS) of PGWs over large scales, which leave the Hubble radius during inflation, is nearly scale-invariant. However, over very small scales, which never leave the Hubble radius, the PS of PGWs behaves as k^2, where k denotes the wave number. We examine the PS of PGWs at such high wave numbers or frequencies when the PGWs are evolved post-inflation, through the epochs of radiation and matter domination. Firstly, we argue that the PS has to be regularized in order to truncate the unphysical k^2 rise at high frequencies. Assuming instantaneous transitions from inflation to the epochs of radiation and matter domination, we carry out the method of adiabatic regularization to arrive at the PS of PGWs over a wide range of frequencies. We show that the process of regularization truncates the k^2 rise and the PS of PGWs oscillates with a fixed amplitude about a vanishing mean value over small scales or, equivalently, at high frequencies. Secondly, we smooth the transition from inflation to radiation domination (to be precise, we smooth the 'effective potential' governing the equation of motion of PGWs) and examine the impact of the smoothing on the regularized PS of PGWs. With the help of a linear smoothing function, we explicitly show that the smoother transition leads to a power-law suppression in the amplitude of the oscillations (about the zero mean value) of the regularized PS of PGWs over small scales that never leave the Hubble radius during inflation. Our analysis indicates that, when transitions are involved, regularization as well as smooth transitions seem essential to ensure that the correlation functions of the PGWs in real space are well behaved. We discuss the directions in which our results need to be extended.",
    "authors": [
      "Alipriyo Hoory",
      "Jerome Martin",
      "Arnab Paul",
      "L. Sriramkumar"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04002",
    "title": "Dynamical Love Numbers for Black Holes and Beyond from Shell Effective Field Theory",
    "abstract": "We construct a novel effective field theory for a compact body coupled to gravity, whose key feature is that the dynamics of gravitational perturbations is explicitly determined by known solutions in black hole perturbation theory in four dimensions. In this way, the physics of gravitational perturbations in curved space are already encoded in the effective field theory, thus bypassing the need for the higher-order calculations that constitute a major hurdle in standard approaches. Concretely, we model the compact body as a spherical shell, whose finite size regulates short-distance divergences in four dimensions and whose tidal responses are described by higher-dimensional operators. As an application, we consider scalar perturbations and derive new results for scalar Love numbers through ${\\cal O} (G^9)$ for Schwarzschild black holes and for generic compact bodies. Finally, our analysis reveals an intriguing structure of the scalar black-hole Love numbers in terms of the Riemann zeta function, which we conjecture to hold to all orders.",
    "authors": [
      "Dimitrios Kosmopoulos",
      "Davide Perrone",
      "Mikhail Solon"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04011",
    "title": "Freeze-out and spectral running of primordial gravitational waves in viscous cosmology",
    "abstract": "We investigate the impact of shear viscosity on the propagation of primordial gravitational waves (pGW) after inflation. Without assuming a specific inflationary scenario we focus on the evolution of pGWs after they re-enter the horizon during a cosmological epoch characterized by the presence of shear viscosity. We show that shear viscosity introduces an additional damping term in the tensor equation, modifying both the transfer function and the energy density power spectrum. For a constant shear viscosity-to-Hubble ratio the transfer function acquires an extra red tilt, while a time-dependent viscosity leads to a running spectral index $\\Omega_\\text{GW}\\sim k^{n_\\text{eff}(k)}$ controlled by the time evolution of the mean free path of the viscous fluid. Our analysis provides a general framework to analytically quantify how shear viscosity can alter the primordial gravitational wave background in standard and non-standard post-inflationary scenarios. As a case study we evaluate the effect of viscosity of the electron-photon-baryon plasma, on both the transfer function and the normalized energy density, finding a $k$-dependent blue tilt due to gravitational wave freeze-out from the viscous phase. This effect corresponds to a fractional difference of order $10^{-3}$.",
    "authors": [
      "Giuseppe Fanizza",
      "Eliseo Pavone",
      "Luigi Tedesco"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.04659",
    "title": "Gaussian beams and caustic avoidance in gravitational optics",
    "abstract": "In this study, we consider a beam summation method adapted from the semiclassical regime of quantum mechanics to study the classical properties of thin light bundles in gravity. In Newtonian paraxial optics, this method has been shown to encapsulate the wave properties of the light beams. In our case, the wave function assigned to the light bundle can be viewed as a coarse-grained description that captures information about the dynamics of superposed bundles within the geometric optics regime. We investigate two solutions of the null bundle wave function that differ by their origin: (i) a point source and (ii) a finite source. It is shown that while the wave function in the point source case contains the same information as the standard thin null bundle framework, the finite source case corresponds to a Gaussian beam. The novel aspect of this work arises from our geometric construction of covariant Gaussian beams, which can be applied in any spacetime. Additionally, the effects of a finite source on cosmological distances are discussed. With this framework, one can model light propagation from coherent sources while avoiding the mathematical singularities of the standard thin null bundle formalism. We explicitly demonstrate the caustic-avoidance property of Gaussian beams in the analytically tractable example of a Barriola-Vilenkin monopole spacetime.",
    "authors": [
      "Nezihe Uzun"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.07049",
    "title": "Quantization of electromagnetic field in the Schwarzschild spacetime",
    "abstract": "We discuss the problem of canonical quantization of electromagnetic field in the Schwarzschild spacetime. It is shown that a consistent procedure of canonical quantization of the field can be carried out without taking into account the internal region of the black hole. We prove that there exists a unitary gauge, which can be viewed as a combination of the Coulomb and Poincare gauges and is compatible with the field equations. The solutions corresponding to the stationary one-particle states of the electromagnetic field are studied, the canonical commutation relations and the Hamiltonian of the quantized electromagnetic field are obtained.",
    "authors": [
      "Vadim Egorov",
      "Mikhail Smolyakov",
      "Igor Volobuev"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.06075",
    "title": "Barrow Cosmology and Big-Bang Nucleosynthesis",
    "abstract": "Using thermodynamics-gravity conjecture, we present the formal derivation of the modified Friedmann equations inspired by the Barrow entropy, $S\\sim A ^{1+\\delta/2}$, where $0\\leq\\delta\\leq 1$ is the Barrow exponent and $A$ is the horizon area. We then constrain the exponent $\\delta$ by using Big-Bang Nucleosynthesis (BBN) observational data. In order to impose the upper bound on the Barrow exponent $\\delta$, we set the observational bound on $\\left| \\frac{\\delta T_f} {T_f }\\right|$. We find out that the Barrow parameter $\\delta$ should be around $ \\delta \\simeq 0.01$ in order not to spoil the BBN era. Next we derive the bound on the Barrow exponent $\\delta$ in a different approach in which we analyze the effects of Barrow cosmology on the primordial abundances of light elements i.e. Helium $_{}^{4}\\textit{He}$, Deuterium $D$ and Lithium $_{}^{7}\\textit{Li}$. We observe that the deviation from standard Bekenstein-Hawking expression is small as expected. Additionally we present the relation between cosmic time $t$ and temperature $T$ in the context of modified Barrow cosmology. We confirm that the temperature of the early universe increases as the Barrow exponent $\\delta$ (fractal structure of the horizon) increases, too.",
    "authors": [
      "Ahmad Sheykhi",
      "Ava Shahbazi Sooraki"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.19761",
    "title": "Applicability of multi-component study on Bayesian searches for targeted anisotropic stochastic gravitational-wave background",
    "abstract": "Stochastic background gravitational waves have not yet been detected by ground-based laser interferometric detectors, but recent improvements in detector sensitivity have raised considerable expectations for their eventual detection. Previous studies have introduced methods for exploring anisotropic background gravitational waves using Bayesian statistics. These studies represent a groundbreaking approach by offering physically motivated anisotropy mapping that is distinct from the Singular Value Decomposition regularization of the Fisher Information Matrix. However, they are limited by the use of a single model, which can introduce potential bias when dealing with complex data that may consist of a mixture of multiple models. Here, we demonstrate the bias introduced by a single-component model approach in the parametric interpretation of anisotropic stochastic gravitational-wave backgrounds, and we confirm that using multiple-component models can mitigate this bias.",
    "authors": [
      "Soichiro Kuwahara",
      "Leo Tsukada"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.09050",
    "title": "Late-time acceleration and structure formation in interacting $α$-attractor dark energy models",
    "abstract": "We investigate the cosmological dynamics of interacting dark energy within the framework of $\\alpha$-attractor models. Specifically, we analyze the associated autonomous system, focusing on its fixed points that represent dark energy and scaling solutions, along with their stability conditions. We employ center manifold theory to address cases where some fixed points display eigenvalues with zero and negative real parts. The model reveals attractors describing dark energy, enabling a smooth transition from the radiation-dominated era to the matter-dominated era, and ultimately into the dark-energy-dominated phase. Additionally, we identify a scaling matter solution capable of modifying the growth rate of matter perturbations during the matter-dominated epoch. Consequently, we study the evolution of matter perturbations by obtaining both analytical and numerical solutions to the density contrast evolution equation. Based on these results, we compute numerical solutions for the weighted growth rate $f\\sigma_{8}$, indicating that interacting $\\alpha$-attractor dark energy models may provide a better fit to structure formation data than the standard $\\Lambda$CDM scenario.",
    "authors": [
      "L. K. Duchaniya",
      "B. Mishra",
      "G. Otalora",
      "M. Gonzalez-Espinoza"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22356",
    "title": "Net Charge Accretion in Magnetized Kerr Black Holes",
    "abstract": "We investigate the charging process of a rotating Kerr black hole of mass $M$ and angular momentum $J$ immersed in a stationary, axisymmetric, asymptotically uniform magnetic field of strength $B_{0}$. In Wald's classic analysis (Wald 1974), which was based on the assumption of vanishing injection energy, the black hole was predicted to acquire a universal \"saturation charge\" $Q_{\\mathrm{w}}=2B_{0}J$. However, the physical mechanism that sets the saturation charge must ultimately be governed by the competition between the absorption rates of positively and negatively charged particles. Motivated by this observation, we revisit the problem in the framework of a simple accretion model, where two dilute, equivalent fluxes of charged particles of opposite signs are injected from infinity along the magnetic field lines. The problem then reduces to that of individual particle motion in the electromagnetic field of the magnetized Kerr black hole. Using a combination of numerical and analytical tools, we determine the domains of absorption and establish both lower and upper bounds on the corresponding absorption cross sections. At $Q=Q_\\mathrm{w}$ these bounds reveal a systematic difference between the two charge signs. In particular, for sufficiently strong magnetic fields, the lower bound on the absorption cross section for the \"attracted\" charge exceeds the upper bound for the \"repelled\" one. This charge accretion imbalance (which we find to become extreme at the limit of large $B_{0}$) indicates a persistent net charge accretion at $Q=Q_{\\mathrm{w}}$, implying that the actual saturation charge must differ from Wald's charge $Q_{\\mathrm{w}}$.",
    "authors": [
      "Ethan Berreby",
      "Avner Okun",
      "Shahar Hadar",
      "Amos Ori"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00102",
    "title": "Letelier black hole immersed in an electromagnetic universe",
    "abstract": "We investigate a static, spherically symmetric black hole solution surrounded by a cloud of strings and immersed in an electromagnetic universe. By deriving the event horizon from the lapse function, we demonstrate that both the string cloud parameter and the electromagnetic background parameter significantly modify the horizon radius compared to the Schwarzschild case. Consequently, thermodynamic quantities-including the Hawking temperature, Bekenstein-Hawking entropy, and heat capacity-become explicit functions of these additional parameters, with the heat capacity exhibiting divergences that signal phase transitions. We analyze the motion of massive test particles in this spacetime, deriving the effective potential and calculating the innermost stable circular orbit radius, which governs the inner edge of accretion disks and influences orbital stability. Scalar perturbations are examined through the associated effective potential, and quasinormal mode frequencies are computed using the sixth-order WKB approximation; the negative imaginary parts confirm the stability of the black hole under such perturbations. We also study the photon sphere structure, black hole shadow radius, and photon trajectories, showing how the interplay between string clouds and the electromagnetic background shapes the optical properties of this spacetime. Finally, we investigate weak gravitational lensing phenomena by deriving the deflection angle for both massive particles and photons using the Gauss-Bonnet theorem applied to the optical geometry. The results exhibit notable deviations from the Schwarzschild geometry, with the string cloud enhancing the deflection through a $(1-\\alpha)^{-1}$ factor while the electromagnetic parameter introduces competing corrections at second order.",
    "authors": [
      "Ahmad Al-Badawi",
      "Faizuddin Ahmed",
      "İzzet Sakallı"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.02592",
    "title": "Unified equation for massless spin fields and new definitions of key spin coefficients",
    "abstract": "Whether studying gravitational waves from extreme mass ratio inspirals or exploring the analogy between massless spin-particle waves, black hole perturbation theory proves indispensable. At the heart of developing a universal perturbation framework for such problems lies the challenge of formulating a coordinate-independent, unified wave equation that is universally applicable to any black hole spacetime. This paper resolves this central issue in type-D spacetimes by establishing a new definition of spin coefficients. Specifically, we introduce a new definition for the spin coefficients $\\rho$, $\\mu$, $\\tau$, and $\\pi$, which are defined as the directional derivatives of the logarithm of a generating function along the null tetrad ($l^{\\mu}$, $n^{\\mu}$, $m^{\\mu}$, $\\bar{m}^{\\mu}$), respectively. This is the first discovery that these spin coefficients are interconnected through a generating function. Using the newly defined spin coefficients, we find that the field equations for massless particles with spins 0, 1/2, 1, 3/2, and 2 in arbitrary type-D black hole spacetimes can be described by a single unified equation. This finding is particularly surprising, as unifying these field equations is already a significant challenge in flat spacetime, let alone in the intricate spacetime around black holes. Consequently, this work will inevitably prompt a re-examination of the shared characteristics among various types of particles in black hole spacetimes. Meanwhile, we verify the correctness of the new definition for the spin coefficients, and provide the explicit form of the unified equation for nearly all known type-D black hole backgrounds. This lays a solid foundation not only for studying gravitational waves from extreme mass ratio inspirals but also for exploring the analogy between massless spin-particle waves in any type-D black hole background.",
    "authors": [
      "Zhong-Heng Li"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.10668",
    "title": "Analyzing the general conditions for modulus stabilization in a warped braneworld",
    "abstract": "In braneworld scenarios with compact extra dimensions, the modulus field typically remains undetermined without an appropriate stabilization mechanism. A common approach introduces a bulk scalar field that generates an effective potential for the modulus with a stable minimum. In this work, we explore some novel aspects of such stabilization mechanisms. We study how the bulk scalar profile influences the stabilization procedure. Following the approach of Chacko et al. [1], we analyze several representative cases using methods of singular perturbation theory. We identify a consistent relationship between the structure of the bulk potential and the emergence of a stabilized modulus, and outline the general conditions that any bulk potential must satisfy to enable stabilization. In this context, we also examine a potential connection between geometric consistency conditions - specifically, the \"brane world sum rules\" - and the stabilized value of the modulus. In some scenarios where stabilization occurs, we find that these sum rules can offer additional constraints on the modulus, providing a complementary perspective on its determination. Taken together, these results offer a broader perspective on the mechanisms that govern modulus stabilization in higher-dimensional warped geometries.",
    "authors": [
      "Soham Bhattacharyya",
      "Soumitra SenGupta"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.10133",
    "title": "$f$-mode oscillations of protoneutron stars",
    "abstract": "We investigate nonradial $f$-mode oscillations of protoneutron stars in full general relativity, employing equations of state described by the Brueckner-Hartree-Fock theory or the relativistic mean field model, while assuming isentropy and fixed lepton fractions for the internal structure. The validity of various universal relations for cold neutron stars involving $f$-mode characteristics and macroscopic properties of the star is confirmed for those isentropic protoneutron stars. Prospects of observations are also discussed. According to simulation results, we then model details of the thermal and trapping profiles in a PNS with the canonical mass. The corresponding $f$-mode frequencies and gravitational-wave strain amplitudes are presented. The validity of the universal relations during the evolution to the formation of a cold neutron star is confirmed.",
    "authors": [
      "Zi-Yue Zheng",
      "Ting-Ting Sun",
      "Huan Chen",
      "Jin-Biao Wei",
      "Xiao-Ping Zheng",
      "G. F. Burgio",
      "H.-J. Schulze"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.11052",
    "title": "Dynamical Stability and Critical Exponents of the Neutral (S-type) Gubser-Rocha Model with Momentum Dissipation",
    "abstract": "The (S-type) Gubser-Rocha model is a holographic model that shows the linear dependence of the entropy density on the temperature. With an appropriate choice of the boundary action, this model exhibits a continuous phase transition in the neutral limit. In this paper, we investigate several aspects of this phase transition. Firstly, we show that the critical exponents of the phase transition match those in the mean-field percolation theory. Subsequently, we also investigate the dynamical stability, and the emergence of the Nambu-Goldstone modes by analyzing the quasinormal modes of the perturbation fields. The dynamical stability agrees with the thermodynamic stability. In addition, we find that there is an emergent Nambu-Goldstone mode in the broken phase of the S-type model.",
    "authors": [
      "Shuta Ishigaki"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.06841",
    "title": "Cosmic baryon census with fast radio bursts and gravitational waves",
    "abstract": "The cosmic baryon density fraction ($\\Omega_{\\rm b}$) is intrinsically correlated with the Hubble constant ($H_0$) through the critical density of the Universe. In the context of the decade-long $H_0$ tension, the significant discrepancy between early- and late-Universe measurements of $H_0$ implies that fixing its value or imposing an external prior could bias the baryon census. To address this concern, we construct a late-Universe probe framework that unifies fast radio bursts (FRBs) and gravitational-wave (GW) standard sirens, which can respectively resolve the missing baryon problem and the $H_0$ tension through their dispersion measures and absolute luminosity distances. By combining $104$ localized FRBs with $47$ GW events, we obtain an $H_0$-free measurement of $\\Omega_{\\rm b}=0.0488\\pm0.0064$ ($1\\sigma$), in concordance with early-Universe observations of CMB + BBN. Although the current precision ($\\sim 13\\%$) is limited by sample size, the growing detections of both FRBs and GWs will make their synergy a powerful probe of low-redshift cosmology.",
    "authors": [
      "Ji-Guo Zhang",
      "Ji-Yu Song",
      "Ze-Wei Zhao",
      "Wan-Peng Sun",
      "Jing-Fei Zhang",
      "Xin Zhang"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.11596",
    "title": "Breaking the Strings: the signatures of Cosmic String Loop Fragmentation",
    "abstract": "We study the impact of fragmentation on the cosmic string loop number density, using an approach inspired by the three-scale model and a Boltzmann equation. We build a new formulation designed to be more amenable to numerical resolution and present two complementary numerical methods to obtain the full loop distribution including the effect of fragmentation and gravitational radiation. We show that fragmentation generically predicts a decay of the loop number density on large scales and a deviation from a pure power-law. We expect fragmentation to be crucial for the calibration of loop distribution models.",
    "authors": [
      "Pierre Auclair"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.16880",
    "title": "Thermal nature of the causal diamond horizon: A hidden property of the inertial propagator",
    "abstract": "Inspired by the novel idea proposed by T.~Padmanabhan in \\textit{Phys.\\ Rev.\\ D 100, 045024 (2019)}, we develop a method to uncover the hidden thermal properties of the inertial Feynman propagator in Minkowski spacetime in a causally consistent manner. This, in turn, enables a coherent interpretation based on future-directed propagation. In our approach, the Fourier transform is implemented following the convention used in the analysis of vacuum fluctuations. As a result, future-directed propagation across causal horizons can be consistently interpreted, from the perspective of an observer confined to a causally disconnected region, as the emission of scalar quanta at the past horizon and their absorption at the future horizon. Moreover, we find that the ratio between emission and absorption processes reproduces the characteristic Boltzmann factor of a thermal ensemble. We first apply this analysis to a causal diamond of length $2\\alpha$, performing a detailed study of the near-horizon geometry and thereby obtaining the temperature associated with the thermal behavior of the Minkowski vacuum as perceived by an observer with finite lifetime $2\\alpha$. For completeness, we also apply the method to the right Rindler wedge, recovering the well-known Unruh temperature, $T = a/(2\\pi)$. Our results demonstrate that thermality can emerge directly from causal structure, independently of acceleration or gravity, with causal diamonds encoding intrinsic thermodynamic behavior in quantum field theory.",
    "authors": [
      "Nada Eissa",
      "Carlos R. Ordóñez",
      "Gustavo Valdivia-Mera"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10319",
    "title": "The merger of spinning, accreting supermassive black hole binaries",
    "abstract": "Because they are likely to accrete substantial amounts of interstellar gas, merging supermassive binary black holes are expected to be strong multimessenger sources, radiating gravitational waves, photons from thermal gas, and photons from relativistic electrons energized by relativistic jets. Here we report on a numerical simulation that covers the late inspiral, merger, and initial postmerger phase of such a system where both black holes have the same mass and spin, and both spin axes are parallel to the orbital angular momentum. The simulation incorporates both 3D general relativistic magnetohydrodynamics and numerical relativity. The thermal photon power during the late inspiral, merger, and immediate postmerger phases is drawn from strong shocks rather than dissipation of turbulence inside a smoothly structured accretion disk as typically found around accreting single black holes. We find that the thermal photon and jet Poynting flux outputs are closely related in time, and we posit a mechanism that enforces this relation. The power radiated in both photons and jets diminishes gradually as merger is approached, but jumps sharply at merger to a noisy plateau. Such a distinct lightcurve should aid efforts to identify supermassive black hole mergers, with or without accompanying gravitational wave detections.",
    "authors": [
      "Lorenzo Ennoggi",
      "Manuela Campanelli",
      "Julian Krolik",
      "Scott C. Noble",
      "Yosef Zlochower",
      "Maria Chiara de Simone"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.09648",
    "title": "Fractional Dynamics in Galactic Nuclei: Non-Local Transport, Transient Phenomena and the Nullification of the Schwarzschild Barrier",
    "abstract": "We investigate the application of fractional calculus to model stellar dynamics, focusing on Resonant Relaxation (RR) near a supermassive black hole (SMBH). Standard theories use the local Fokker-Planck (FP) equation, restricted to Gaussian processes under the Central Limit Theorem (CLT). We argue this is inadequate for RR. We demonstrate that gravitational interactions inherently produce infinite variance in stochastic torques, violating the CLT. Consequently, RR is governed by the Generalized Central Limit Theorem (GCLT) and constitutes a superdiffusive Lévy flight. We apply the space-fractional Fokker-Planck equation (FFPE), utilizing non-local operators, to explore resolutions to observational discrepancies. In transient regimes, the FFPE predicts immediate, linear flux ($\\Gamma(t) \\propto t$), consistent with high Tidal Disruption Event (TDE) rates in post-starburst galaxies, whereas local FP models predict significant exponential delay. Furthermore, we demonstrate analytically that non-local integral operators permit ``barrier jumping,'' bypassing bottlenecks like the Schwarzschild Barrier (SB), which local models interpret as severely suppressing Extreme Mass-Ratio Inspiral (EMRI) rates. We present proof-of-concept $N$-body simulations that confirm non-local RR transport, although the resolution must be improved to rule out enhanced Two-Body Relaxation in the small-N setup. The fractional framework offers a compelling alternative description for non-local transport, potentially resolving TDE and EMRI rate questions.",
    "authors": [
      "Pau Amaro Seoane"
    ],
    "primary_category": "astro-ph.GA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.15482",
    "title": "Probing the disk-jet coupling in M87",
    "abstract": "Context. Recent GMVA observations of M 87 at event horizon scales revealed a ring-like structure which is 50% larger at 86 GHz than the ring observed by the Event Horizon Telescope at 230 GHz. Aims. In this paper, we study a possible origin of the increased ring size at 86 GHz. We specifically aim to study the role the nonthermal electron population plays in the observed event horizon scales. Methods. We carry out 3D general relativistic magnetohydrodynamic simulations followed by radiative transfer calculations. We incorporate into the latter synchrotron emission from both thermal and nonthermal electrons. To better compare our results to observations, we generate synthetic interferometric data adjusted to the properties of the observing arrays. We fit geometrical models to this data in Fourier space through Bayesian analysis to monitor the variable ring size and width over the simulated time span of years. Results. We find that the 86 GHz ring is always larger than the 230 GHz ring, which can be explained by the increased synchrotron self-absorption at 86 GHz and the mixed emission from both the accretion disk and the jet footpoints, as well as flux arcs ejected from a magnetized disk. We find agreement with the observations, particularly within the error range of the observational value of M/D for M 87. Conclusions. We show that state-of-the art 3D GRMHD simulations combined with thermal and nonthermal emitting particles can explain the observed frequency-dependent ring size in M 87. Importantly we found that MAD events triggered in the accretion disk can significantly increase the lower frequency ring sizes.",
    "authors": [
      "Ainara Saiz-Pérez",
      "Christian M. Fromm",
      "Yosuke Mizuno",
      "Matthias Kadler",
      "Karl Mannheim",
      "Ziri Younsi"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.19210",
    "title": "SL(2N,C) Hyperunification: Dynamical Tetrads, Induced Gravity, and Composite Families",
    "abstract": "A four-dimensional gauge--gravity unification based on the local $SL(2N,\\mathbb{C})$ symmetry is developed in a universal Yang--Mills-type setting. The accompanying tetrads are promoted to dynamical fields, and their invertibility condition is interpreted as a nonlinear sigma-model-type length constraint. This triggers tetrad condensation and spontaneously breaks $SL(2N,\\mathbb{C})$ down to $SL(2,\\mathbb{C})\\times SU(N)$, effectively filtering out unobserved non-compact directions. A special ghost-free curvature-squared Lagrangian provides a consistent quadratic sector for all gauge fields involved, while an Einstein--Cartan linear-curvature term is shown to arise radiatively from fermion loops. The matter sector points to a deeper elementarity of $SL(2N,\\mathbb{C})$ spinors, which can be identified with preon constituents whose bound states form the observed quarks and leptons. Anomaly matching between preons and composites singles out $SL(16,\\mathbb{C})$, accommodating precisely three composite quark--lepton families. The theory thus links non-compact unification, induced gravity, and fermion family structure within a single framework.",
    "authors": [
      "J. L. Chkareuli"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03431",
    "title": "New high-statistics measurement of the $π^0 \\to e^+e^-γ$ Dalitz decay at the Mainz Microtron",
    "abstract": "The Dalitz decay $\\pi^0 \\to e^+e^-\\gamma$ has been measured with the highest statistical accuracy obtained so far in the $\\gamma p\\to \\pi^0 p$ reaction with the A2 tagged-photon facility at the Mainz Microtron, MAMI. The value of the slope parameter for the $\\pi^0$ electromagnetic transition form factor, $a_\\pi=0.0315\\pm 0.0026_{\\mathrm{stat}}\\pm 0.0010_{\\mathrm{syst}}$, is obtained from the analysis of $2.4\\times10^6$ $\\pi^0 \\to e^+e^-\\gamma$ observed decays. Within experimental uncertainties, it is in agreement with existing measurements and theoretical calculations, with its own uncertainty being smaller than previous results based on the analysis of $\\pi^0\\to e^+e^-\\gamma$ decays.",
    "authors": [
      "S. Prakhov",
      "L. Heijkenskjöld",
      "S. Abt",
      "P. Achenbach",
      "P. Adlarson",
      "F. Afzal",
      "Z. Ahmed",
      "K. Altangerel",
      "J. R. M. Annand",
      "M. Bashkanov",
      "R. Beck",
      "M. Biroth",
      "N. S. Borisov",
      "A. Braghieri",
      "W. J. Briscoe",
      "F. Cividini",
      "C. Collicott",
      "S. Costanza",
      "A. Denig",
      "M. Dieterle",
      "A. S. Dolzhikov",
      "E. J. Downie",
      "P. Drexler",
      "S. Fegan",
      "S. Gardner",
      "D. Ghosal",
      "D. I. Glazier",
      "I. Gorodnov",
      "W. Gradl",
      "M. Günther",
      "G. M. Gurevich",
      "D. Hornidge",
      "G. M. Huber",
      "A. Käser",
      "V. L. Kashevarov",
      "S. J. D. Kay",
      "M. Korolija",
      "B. Krusche",
      "A. Lazarev",
      "K. Livingston",
      "S. Lutterer",
      "I. J. D. MacGregor",
      "D. M. Manley",
      "P. P. Martel",
      "R. Miskimen",
      "M. Mocanu",
      "E. Mornacchi",
      "C. Mullen",
      "A. Neganov",
      "A. Neiser",
      "M. Ostrick",
      "P. B. Otte",
      "D. Paudyal",
      "P. Pedroni",
      "A. Powell",
      "E. Rickert",
      "T. Rostomyan",
      "V. Sokhoyan",
      "K. Spieker",
      "O. Steffen",
      "I. I. Strakovsky",
      "Th. Strub",
      "I. Supek",
      "M. Thiel",
      "A. Thomas",
      "Yu. A. Usov",
      "S. Wagner",
      "D. P. Watts",
      "D. Werthmüller",
      "J. Wettig",
      "M. Wolfes",
      "N. Zachariou"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03877",
    "title": "Measurement of the hyperon weak radiative decay $Ξ^0\\toγΣ^0$ at BESIII",
    "abstract": "The hyperon weak radiative decay $\\Xi^0\\to\\gamma\\Sigma^0$ is measured via the process $J/\\psi\\to\\Xi^0\\bar\\Xi^0$. The absolute branching fraction of $\\Xi^0\\to\\gamma\\Sigma^0$ is determined to be $(3.69\\pm 0.21_{\\text{stat}}\\pm0.12_{\\text{syst}})\\times 10^{-3}$, based on $(10.087\\pm 0.044)\\times 10^{9}$ $J/\\psi$ events collected with the BESIII detector operating at the BEPCII collider. The decay asymmetry parameter is measured, with a complete angular analysis of the cascade decay chain, to be $\\alpha_{\\gamma} = -0.807\\pm 0.095_{\\text{stat}}\\pm 0.011_{\\text{syst}}$.",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "M. R. An",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "J. F. Chang",
      "T. T. Chang",
      "W. L. Chang",
      "G. R. Che",
      "G. Chelkov",
      "C. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "W. S. Cheng",
      "S. K. Choi",
      "X. Chu",
      "G. Cibinetto",
      "S. C. Coen",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Z. H. Duan",
      "P. Egorov",
      "Y. H. Fan",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "K Fischer",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "Y. N. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03949",
    "title": "Performance and efficiency of a transformer-based quark/gluon jet tagger in the ATLAS experiment",
    "abstract": "A deep-learning approach based on the transformer architecture is developed to distinguish between jets originating from quarks and gluons. The algorithm operates on jets with transverse momentum $p_{\\text{T}} > 20$ and pseudorapidity $|\\eta| < 4.5$ and takes as input several properties derived from the jet constituents, using information from the ATLAS detector's tracker and calorimeter. The algorithm's performance is evaluated by analyzing dijet data events from proton-proton collisions at $\\sqrt{s} = 13$ and $13.6$ TeV during Run 2 and Run 3 of the Large Hadron Collider. Two methods are used to obtain distributions from quark- or gluon-initiated jets in data: a matrix method fully based on Monte Carlo simulation and a new approach named `jet topics' which has less dependence on the modelling of the physics process under study. The quark and gluon identification efficiencies measured in data for the 50% quark-identification-efficiency working point vary from the simulated ones for quark-initiated (gluon-initiated) jets by factors of 0.88-1.30 (0.61-1.05) with uncertainties of 10%-70% (10%-95%). The uncertainties estimated with the jet topics method are smaller than those estimated with the matrix method, with up to 20% less systematic uncertainty in some phase-space regions. The advances in jet identification reported here provide a robust tool for precision Standard Model measurements and searches for new physics at the LHC.",
    "authors": [
      "ATLAS Collaboration"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03133",
    "title": "A Thermal Relic Encyclopedia: Dark Matter Candidates Coupled to Quarks",
    "abstract": "Thermal freeze-out is a compelling framework for naturally generating the dark matter abundance. We systematically study a broad range of dark matter and mediator particle combinations that can viably realize thermal freeze-out, focusing on models in which the mediator couples to Standard Model quarks. In each case, we calculate the relic density and consider existing constraints from accelerators, cosmology, direct detection, and indirect detection over the full range of dark matter and mediator masses. We present an encyclopedic catalog of matrix elements, cross sections, and decay rates which can be used as a reference for future studies of dark matter phenomenology.",
    "authors": [
      "Dan Hooper",
      "Gordan Krnjaic",
      "Tanner Trickle",
      "Isaac R. Wang"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03220",
    "title": "New physics in toponium's shadow?",
    "abstract": "ATLAS and CMS have recently reported enhancements in the top-antitop production rate near threshold, a region where non-perturbative QCD dynamics associated with toponium formation become relevant. We investigate how this behaviour is modified in the presence of a neutral pseudoscalar that couples to gluons and top quarks, using an effective description that consistently incorporates perturbative Standard Model and new physics contributions, their interference and non-perturbative threshold effects. We show that the combined effect of those ingredients markedly shapes the viable region of the pseudoscalar parameter space, particularly for narrow resonances with masses close to twice the top mass. While Standard Model threshold effects could explain a sizeable part of the measured enhancements, the current data remain compatible with additional contributions from pseudoscalar interactions.",
    "authors": [
      "Thomas Flacke",
      "Benjamin Fuks",
      "Dongchan Kim",
      "Jinheung Kim",
      "Seung J. Lee",
      "Léandre Munoz-Aillaud"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03493",
    "title": "Precision Measurements of Kinematic Scan for Fluctuations of (Net-)proton Multiplicity Distributions in Au+Au Collisions from RHIC-STAR",
    "abstract": "This work presents measurements of the rapidity-window dependence of event-by-event net-proton cumulants and proton factorial cumulants in Au+Au collisions at $\\sqrt{s_\\mathrm{NN}}=$7.7 -- 27 GeV, using high-statistics data from RHIC BES-II. Protons and antiprotons are identified with improved detector performance within $0.4<p_\\mathrm{T}<2.0$ GeV/$c$ and $|y|<0.6$, enabling a wide coverage in momentum space to probe long-range correlations near the QCD critical point. In the most central collisions, the proton number $\\kappa_2/\\kappa_1$ and $\\kappa_3/\\kappa_1$ exhibit power-law scaling with the rapidity window, but with exponents below the theoretical expectation, suggesting that the critical point, if it exists, may lie at higher baryon densities. A finite-size scaling analysis of the susceptibility and Binder cumulant study points out a critical baryon chemical potential region in 550 -- 650 MeV.",
    "authors": [
      "Yige Huang",
      "STAR Collaboration"
    ],
    "primary_category": "nucl-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03829",
    "title": "First Experimental Demonstration of Machine Learning-Based Tuning on the PSI Injector 2 Cyclotron",
    "abstract": "Reliable operation of high-power proton cyclotrons is a critical requirement for Accelerator Driven Systems (ADS) and other large-scale applications. Beam tuning in such machines is traditionally performed manually, a process that can be slow, non-optimal, and difficult to execute in the presence of faults or changing conditions. To address this, we developed and deployed a machine learning (ML) based tuning framework on the Injector 2 cyclotron at PSI, chosen as an ideal testbed for high-power operation. The system combined a tailored reinforcement learning algorithm with real-time diagnostics and control, and incorporated accelerator-physics inspired adaptations such as an overshoot strategy that reduced magnetic field settling times by nearly a factor of six. Over an extensive 12-day operational test campaign, relatively long in the context of real-time ML experiments, the ML agent successfully tuned the machine across multiple operating points, achieving convergence within hours and maintaining stable beam extraction with reduced losses. Beyond initial tuning, the system was also operated in evaluation mode overnight, where it autonomously monitored and corrected the machine to compensate for drifts, demonstrating robustness and long-term stability. Crucially, the learned policy generalized reliably from low-current training to higher-current operation, underscoring its scalability. These results constitute the first demonstration of ML-assisted tuning on a high-power cyclotron, with direct relevance to ADS-class drivers.",
    "authors": [
      "M. Haj Tahar",
      "W. Joho",
      "E. Solodko",
      "M. Bocchio",
      "S. Marquie",
      "M. Busch",
      "A. Barchetti",
      "J. Grillenberger",
      "J. Snuverink",
      "M. Schneider"
    ],
    "primary_category": "physics.acc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04052",
    "title": "Post-Cold War Diaspora of Russian Particle Physicists",
    "abstract": "While the migration of scientists from the Soviet Union to the West occurred at a modest pace during the 1970s and 1980s, the dissolution of the USSR in 1991 and the ensuing economic and social hardships precipitated a massive exodus that amounted to a true brain drain. The international physics community, particularly in Europe and the United States, absorbed a substantial influx of specialists in nuclear, high-energy, and accelerator physics, including both seasoned scientists and engineers as well as promising graduate students and postdoctoral fellows. Many of these emigre researchers went on to assume leadership positions, drive major experimental and theoretical initiatives, and achieve scientific distinction that equaled or even surpassed their accomplishments at home. In this article we explore the defining features of this post Cold War scientific diaspora, assess its impact on Russia research infrastructure and capabilities, and evaluate its enduring contributions to global particle physics collaborations and discoveries.",
    "authors": [
      "Vladimir Shiltsev"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.20551",
    "title": "Observation of the singly Cabibbo suppressed decay $D^0\\to b_1(1235)^- e^+ν_e$ and evidence for $D^+\\to b_1(1235)^0 e^+ν_e$",
    "abstract": "By analyzing a data sample of $e^+e^-$ collisions with center-of-mass energy $\\sqrt{s}=3.773$~GeV, corresponding to an integrated luminosity of $7.9~\\rm {fb}^{-1}$ collected with the BESIII detector operating at the BEPCII collider, we study semileptonic decays of the $D^{0(+)}$ mesons into the axial-vector meson $b_1(1235)$ via the decay $b_1(1235)\\to \\omega\\pi$. The decay $D^0\\to b_1(1235)^-e^{+}\\nu_{e}$ is observed with a significance of 5.2$\\sigma$ after considering systematic uncertainty, while evidence for the decay $D^+\\to b_1(1235)^0 e^+\\nu_e$ is obtained with a 3.1$\\sigma$ significance. The product branching fractions are determined to be ${\\mathcal B}(D^0\\to b_{1}(1235)^-e^{+}\\nu_{e})\\times {\\mathcal B} (b_1(1235)^-\\to \\omega \\pi^-) = (0.72\\pm0.18^{+0.06}_{-0.08})\\times10^{-4}$ and ${\\mathcal B}(D^+\\to b_{1}(1235)^0e^{+}\\nu_{e})\\times {\\mathcal B} (b_1(1235)^0~\\to \\omega \\pi^0) = (1.16\\pm0.44\\pm0.16)\\times10^{-4}$, where the first uncertainties are statistical and the second systematic. The ratio of their partial decay widths is determined to be $\\frac{\\Gamma(D^0\\to b_{1}(1235)^-e^{+}\\nu_{e})}{2\\Gamma(D^+\\to b_{1}(1235)^0e^{+}\\nu_{e})}=0.78\\pm0.19^{+0.04}_{-0.05}$, which is consistent with unity, predicted by isospin invariance, within uncertainties.",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "O. Afedulidis",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "H.-R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "X. Y. Chai",
      "J. F. Chang",
      "G. R. Che",
      "Y. Z. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. Y. Chen",
      "S. K. Choi",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.08387",
    "title": "Transformer Neural Networks in the Measurement of $t\\bar{t}H$ Production in the $H\\,{\\to}\\,b\\bar{b}$ Decay Channel with ATLAS",
    "abstract": "A measurement of Higgs boson production in association with a top quark pair in the bottom anti-bottom Higgs boson decay channel and leptonic final states is presented. The analysis uses $140\\,\\mathrm{fb}^{-1}$ of $13\\,\\mathrm{TeV}$ proton proton collision data collected by the ATLAS detector at the Large Hadron Collider. A particular focus is placed on the role played by transformer neural networks in discriminating signal and background processes via multi-class discriminants and in reconstructing the Higgs boson transverse momentum. These powerful multi-variate analysis techniques significantly improve the analysis over a previous measurement using the same dataset. Overall, an excess of 4.6 (5.4) standard deviations over the background-only hypothesis was observed (expected).",
    "authors": [
      "Chris Scheulen"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.05665",
    "title": "Search for $γ$H production and constraints on the Yukawa couplings of light quarks to the Higgs boson",
    "abstract": "A search for $\\gamma$H production is performed with data from the CMS experiment at the LHC corresponding to an integrated luminosity of 138 fb$^{-1}$ at a proton-proton center-of-mass collision energy of 13 TeV. The analysis focuses on the topology of a boosted Higgs boson recoiling against a high-energy photon. The final states of H $\\to$ $\\mathrm{b\\bar{b}}$ and H $\\to$ 4$\\ell$ are analyzed. This study examines effective HZ$\\gamma$ and H$\\gamma\\gamma$ anomalous couplings within the context of an effective field theory. In this approach, the production cross section is constrained to be $\\sigma_{\\gamma\\text{H}}$ $\\lt$ 16.4 fb at 95% confidence level (CL). Simultaneous constraints on four anomalous couplings involving HZ$\\gamma$ and H$\\gamma\\gamma$ are provided. Additionally, the production rate for H $\\to$ 4$\\ell$ is examined to assess potential enhancements in the Yukawa couplings between light quarks and the Higgs boson. Assuming the standard model values for the Yukawa couplings of the bottom and top quarks, the following simultaneous constraints are obtained: $\\kappa_\\text{u}$ = (0.0 $\\pm$ 1.5) $\\times$ 10$^{3}$, $\\kappa_\\text{d}$ = (0.0 $^{+6.7}_{-6.8}$) $\\times$ 10$^{2}$, $\\kappa_\\text{s}$ = 0 $^{+30}_{-32}$, and $\\kappa_\\text{c}$ = 0.0 $^{+2.3}_{-2.8}$. This rules out the hypothesis that up- or down-type quarks in the first or second generation have the same Yukawa couplings as those in the third generation, with a CL greater than 95%.",
    "authors": [
      "CMS Collaboration"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13515",
    "title": "Probing scalar-neutrino and scalar-dark-matter interactions with PandaX-4T",
    "abstract": "Scalar-mediated interactions may exist among neutrinos, dark matter particles, or between the two. Double $\\beta$-decay experiments provide a powerful tool to probe such exotic interactions. Using $^{136}$Xe double $\\beta$-decay data from PandaX-4T, we perform the first direct spectral search in the energy range of 20 to 2800~keV, setting the most stringent limits to date on scalar-mediated neutrino self-interactions for mediator masses below 2~MeV$/c^2$. These results place significant constraints on models invoking such interactions to alleviate the Hubble Tension. Assuming the same scalar also mediates dark matter self-interactions, constraints on the dark matter-scalar interactions can be placed in conjunction with cosmological constraints.",
    "authors": [
      "PandaX Collaboration",
      "Tao Li",
      "Zihao Bo",
      "Wei Chen",
      "Xun Chen",
      "Yunhua Chen",
      "Chen Cheng",
      "Xiangyi Cui",
      "Manna Deng",
      "Yingjie Fan",
      "Deqing Fang",
      "Xuanye Fu",
      "Zhixing Gao",
      "Yujie Ge",
      "Lisheng Geng",
      "Karl Giboni",
      "Xunan Guo",
      "Xuyuan Guo",
      "Zichao Guo",
      "Chencheng Han",
      "Ke Han",
      "Changda He",
      "Jinrong He",
      "Houqi Huang",
      "Junting Huang",
      "Yule Huang",
      "Ruquan Hou",
      "Xiangdong Ji",
      "Yonglin Ju",
      "Xiaorun Lan",
      "Chenxiang Li",
      "Jiafu Li",
      "Mingchuan Li",
      "Peiyuan Li",
      "Shuaijie Li",
      "Tao Li",
      "Yangdong Li",
      "Zhiyuan Li",
      "Qing Lin",
      "Jianglai Liu",
      "Yuanchun Liu",
      "Congcong Lu",
      "Xiaoying Lu",
      "Lingyin Luo",
      "Yunyang Luo",
      "Yugang Ma",
      "Yajun Mao",
      "Yue Meng",
      "Binyu Pang",
      "Ningchun Qi",
      "Zhicheng Qian",
      "Xiangxiang Ren",
      "Dong Shan",
      "Xiaofeng Shang",
      "Xiyuan Shao",
      "Guofang Shen",
      "Manbin Shen",
      "Wenliang Sun",
      "Xuyan Sun",
      "Yi Tao",
      "Yueqiang Tian",
      "Yuxin Tian",
      "Anqing Wang",
      "Guanbo Wang",
      "Hao Wang",
      "Haoyu Wang",
      "Jiamin Wang",
      "Lei Wang",
      "Meng Wang",
      "Qiuhong Wang",
      "Shaobo Wang",
      "Shibo Wang",
      "Siguang Wang",
      "Wei Wang",
      "Xu Wang",
      "Zhou Wang",
      "Yuehuan Wei",
      "Weihao Wu",
      "Yuan Wu",
      "Mengjiao Xiao",
      "Xiang Xiao",
      "Yuhan Xie",
      "Kaizhi Xiong",
      "Jianqin Xu",
      "Yifan Xu",
      "Shunyu Yao",
      "Binbin Yan",
      "Xiyu Yan",
      "Yong Yang",
      "Peihua Ye",
      "Chunxu Yu",
      "Ying Yuan",
      "Zhe Yuan",
      "Youhui Yun",
      "Xinning Zeng",
      "Minzhen Zhang",
      "Peng Zhang",
      "Shibo Zhang",
      "Siyuan Zhang",
      "Shu Zhang"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00328",
    "title": "Observation of the rare baryonic decay $B^{+}\\rightarrow p \\bar{\\itΛ}$ and measurement of its weak decay parameter",
    "abstract": "The first observation of the decay $B^{+}\\rightarrow p \\bar{\\it{\\Lambda}}$ is presented, using proton-proton collision data collected by the LHCb experiment between 2016 and 2018 at a center-of-mass energy of 13 TeV, corresponding to an integrated luminosity of $5.4\\,\\mathrm{fb}^{-1}$. The signal significance exceeds seven standard deviations. Using the $B^{+} \\rightarrow K^{\\mathrm{0}}_{\\mathrm{S}} \\pi^{+}$ decay as a normalization channel, the branching fraction is measured and combined with previous LHCb results based on data collected at 7 and 8 TeV in 2011 and 2012, yielding $\\mathcal{B}(B^{+}\\rightarrow p \\bar{\\it{\\Lambda}})=(1.24\\pm 0.17\\pm 0.05\\pm 0.03)\\times 10^{-7}$, where the first uncertainty is statistical, the second is systematic, and the third comes from the uncertainty on the branching fraction of the normalization channel. The $B^{+}\\rightarrow p \\bar{\\it{\\Lambda}}$ weak decay parameter is measured to be $\\alpha_B = 0.87_{-0.29}^{+0.26} \\pm 0.09$, indicating the presence of comparable S-wave and P-wave decay amplitudes.",
    "authors": [
      "LHCb collaboration",
      "R. Aaij",
      "A.S.W. Abdelmotteleb",
      "C. Abellan Beteta",
      "F. Abudinén",
      "T. Ackernley",
      "A. A. Adefisoye",
      "B. Adeva",
      "M. Adinolfi",
      "P. Adlarson",
      "C. Agapopoulou",
      "C.A. Aidala",
      "Z. Ajaltouni",
      "S. Akar",
      "K. Akiba",
      "P. Albicocco",
      "J. Albrecht",
      "R. Aleksiejunas",
      "F. Alessio",
      "P. Alvarez Cartelle",
      "R. Amalric",
      "S. Amato",
      "J.L. Amey",
      "Y. Amhis",
      "L. An",
      "L. Anderlini",
      "M. Andersson",
      "P. Andreola",
      "M. Andreotti",
      "S. Andres Estrada",
      "A. Anelli",
      "D. Ao",
      "C. Arata",
      "F. Archilli",
      "Z. Areg",
      "M. Argenton",
      "S. Arguedas Cuendis",
      "L. Arnone",
      "A. Artamonov",
      "M. Artuso",
      "E. Aslanides",
      "R. Ataíde Da Silva",
      "M. Atzeni",
      "B. Audurier",
      "J. A. Authier",
      "D. Bacher",
      "I. Bachiller Perea",
      "S. Bachmann",
      "M. Bachmayer",
      "J.J. Back",
      "P. Baladron Rodriguez",
      "V. Balagura",
      "A. Balboni",
      "W. Baldini",
      "Z. Baldwin",
      "L. Balzani",
      "H. Bao",
      "J. Baptista de Souza Leite",
      "C. Barbero Pretel",
      "M. Barbetti",
      "I. R. Barbosa",
      "R.J. Barlow",
      "M. Barnyakov",
      "S. Barsuk",
      "W. Barter",
      "J. Bartz",
      "S. Bashir",
      "B. Batsukh",
      "P. B. Battista",
      "A. Bay",
      "A. Beck",
      "M. Becker",
      "F. Bedeschi",
      "I.B. Bediaga",
      "N. A. Behling",
      "S. Belin",
      "A. Bellavista",
      "K. Belous",
      "I. Belov",
      "I. Belyaev",
      "G. Benane",
      "G. Bencivenni",
      "E. Ben-Haim",
      "A. Berezhnoy",
      "R. Bernet",
      "S. Bernet Andres",
      "A. Bertolin",
      "F. Betti",
      "J. Bex",
      "O. Bezshyyko",
      "S. Bhattacharya",
      "J. Bhom",
      "M.S. Bieker",
      "N.V. Biesuz",
      "A. Biolchini",
      "M. Birch",
      "F.C.R. Bishop",
      "A. Bitadze",
      "A. Bizzeti",
      "T. Blake"
    ],
    "primary_category": "hep-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2306.10540",
    "title": "Search for Lepton Flavor Violating Signals at the Future Electron-Proton Colliders",
    "abstract": "The search for lepton flavor violation (LFV) is a powerful probe to look for new physics beyond the Standard Model. We explored the possibility of searches for LFV $Z$ boson couplings to electron and muon pairs at the upcoming electron-proton colliders, namely the Large Hadron Electron Collider (LHeC) and the Future Circular lepton-hadron Collider (FCC-eh). We employed the study via a single muon plus an associated jet channel to search for the LFV signal. We used a multivariate technique to obtain an improved signal-background analysis. By using the condition on nonobservation of any significant deviation of the signal over the expected background, we provide an upper limit on the LFV $Z$ boson coupling and corresponding branching ratio (BR). We find that an upper limit of up to $1.13\\times 10^{-7}$ and $4.64 \\times 10^{-8}$ can be set on BR($Z\\to e \\mu$) at 95\\% confidence level (C.L.) with one year run of LHeC and FCC-eh, respectively, if the LFV coupling is governed by vector or axial-vector coupling. For tensor or axial-tensor coupling, these limits can be improved up to $2.34\\times 10^{-8}$ and $5.02\\times 10^{-9}$ for LHeC and FCC-eh machines, respectively, at 95\\% C.L. The projected numbers improve significantly over the existing limit of $2.62\\times 10^{-7}$ set by ATLAS.",
    "authors": [
      "Anjan Kumar Barik",
      "Atri Dey",
      "Tousik Samui"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.11288",
    "title": "Generalized Parton Distributions from Lattice QCD with Asymmetric Momentum Transfer: Tensor Case",
    "abstract": "The calculation of generalized parton distributions (GPDs) in lattice QCD was traditionally done by calculating matrix elements in the symmetric frame. Recent advancements have significantly reduced computational costs by calculating these matrix elements in the asymmetric frame, allowing us to choose the momentum transfer to be in either the initial or final states only. The theoretical methodology requires a new parametrization of the matrix element to obtain Lorentz-invariant amplitudes, which are then related to the GPDs. The formulation and implementation of this approach have already been established for the unpolarized and helicity GPDs. Building upon this idea, we extend this formulation to the four leading-twist quark transversity GPDs ($H_T$, $E_T$, $\\widetilde{H}_T$, $\\widetilde{E}_T$). We also present numerical results for zero skewness using an $N_f=2+1+1$ ensemble of twisted mass fermions with a clover improvement. The light quark masses employed in these calculations correspond to a pion mass of about 260 MeV. Furthermore, we include a comparison between the symmetric and asymmetric frame calculations to demonstrate frame independence of the Lorentz-invariant amplitudes. Analysis of the matrix elements in the asymmetric frame is performed at several values of the momentum transfer squared, $-t$, ranging from 0.17 GeV$^2$ to 2.29 GeV$^2$.",
    "authors": [
      "Shohini Bhattacharya",
      "Krzysztof Cichy",
      "Martha Constantinou",
      "Andreas Metz",
      "Joshua Miller",
      "Peter Petreczky",
      "Fernanda Steffens"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20315",
    "title": "Understanding the correlation between elliptic and triangular flow",
    "abstract": "The relative correlation between the magnitudes of elliptic flow ($v_2$) and triangular flow ($v_3$) has been accurately measured in nucleus-nucleus collisions at the LHC collider. As a function of the centrality of the collision, it changes sign and varies non-monotonically. We show that this is naturally explained by two combined effects. The first effect is a skewness in initial-state fluctuations, which is quantified by the correlation between the geometry-driven elliptic deformation in the reaction plane and the fluctuation-driven triangularity $\\varepsilon_3$. We introduce an intensive measure of this skewness, which is generically of order unity and depends weakly on the system size and centrality. We evaluate its magnitude using Monte Carlo simulations of the initial state, which show that it is sensitive to the nucleon width. The second effect is the fluctuation of impact parameter relative to centrality classifiers used by experiment. The ATLAS collaboration uses two different centrality classifiers, the multiplicity $N_{ch}$ and the transverse energy $E_T$. We fit both sets of results for Pb+Pb collisions up to $\\approx 40\\%$ centrality with a single parameter, the intensive mixed skewness. Its value inferred from experiment agrees with theoretical expectations.",
    "authors": [
      "Mubarak Alqahtani",
      "Jean-Yves Ollitrault"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.13043",
    "title": "Born-Oppenheimer EFT: a unified description of ordinary and exotic quarkonia",
    "abstract": "We show how the Born-Oppenheimer effective field theory (BOEFT) provides a unified description of ordinary and exotic quarkonia grounded on the non-relativistic expansions of QCD and supplemented with lattice QCD inputs. We apply BOEFT to tetraquarks, pentaquarks, quarkonium hybrids and to assess threshold effects in the quarkonium spectrum.",
    "authors": [
      "Antonio Vairo"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13997",
    "title": "Light-Front Transverse Nucleon Charge and Magnetisation Densities",
    "abstract": "Nucleon elastic electromagnetic form factors obtained using both the three-body and quark + fully-interacting-diquark pictures of nucleon structure are employed to calculate an array of light-front transverse densities for the proton and neutron and their dressed valence-quark constituents, viz. flavour separations of the proton and neutron results. These two complementary descriptions of nucleon structure deliver mutually compatible predictions, which match expectations based on modern parametrisations of available data, where such are available. Amongst other things, it is found that transverse-plane valence $u$- and $d$-quark Dirac radii are practically indistinguishable; but regarding kindred Pauli radii, the $d$ quark value is roughly 10% greater than that of the $u$-quark. Moreover, magnetically, the valence $d$ quark is far more active than the valence $u$ quark, probably because it has much greater orbital angular momentum. Both pictures of nucleon structure agree in predicting that, in a polarised nucleon, the transverse-plane charge densities are no longer rotationally invariant. Instead, for a $+\\hat x$ polarised nucleon, positive charge is displaced in the $+\\hat y$ direction, with the opposite effect for negative charge.",
    "authors": [
      "Z.-N. Xu",
      "Z.-Q. Yao",
      "P. Cheng",
      "C. D. Roberts",
      "J. Rodriguez-Quintero",
      "J. Segovia"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.15391",
    "title": "Neutrinoless Double Beta Decay in Light of JUNO First Data",
    "abstract": "The first results from the JUNO reactor neutrino oscillation experiment improve our knowledge of neutrino masses and mixing parameters, especially the solar angle $\\theta_s \\equiv \\theta_{12}$ and the solar mass squared difference $\\Delta m^2_s \\equiv \\Delta m^2_{21}$. We discuss the implications of these results on neutrinoless double beta decay by itself and in combination with the global fit of neutrino oscillation experiments, the JUNO first data, and cosmological constraints on the neutrino mass sum. For the effective mass $\\langle m_{ee} \\rangle$, the uncertainties in its lower limits for both mass orderings and upper limits for the normal ordering are largely reduced. Since the cosmological CMB and DESI BAO data put a stringent constraint on the neutrino mass scale, we also show how the probability distribution of both the real and imaginary parts of the effective mass $\\langle m_{ee} \\rangle$ on the complex plane is affected. Especially, the funnel region with $|\\langle m_{ee} \\rangle| \\lesssim 1$\\,meV receives larger chance to happen. Correspondingly, the chance of determining the two Majorana CP phases simultaneously in this region also increases with reduced uncertainty.",
    "authors": [
      "Shao-Feng Ge",
      "Chui-Fan Kong",
      "Manfred Lindner",
      "João Paulo Pinheiro"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00172",
    "title": "Enhancing the sensitivity to neutrino oscillation parameters using synergy between T2K, NO$ν$A and JUNO",
    "abstract": "We study the impact of combining the present NO$\\nu$A and T2K data with simulated data from the JUNO experiment on the determination of the leptonic CP phase and the neutrino mass hierarchy. The current NO$\\nu$A data exhibit a hierarchy--$\\delta_{\\rm CP}$ degeneracy, admitting both normal hierarchy (NH) with $\\delta_{\\rm CP} \\in [0,180^\\circ]$, and inverted hierarchy (IH) with $\\delta_{\\rm CP} \\in [180^\\circ,360^\\circ]$ solutions at comparable significance, while T2K prefers $\\delta_{\\rm CP}\\simeq 270^\\circ$ for both hierarchies, leading to a $2\\sigma$ tension between the two experiments for normal hierarchy. Using detailed GLoBES simulations, we show that future JUNO data with excellent hierarchy sensitivity, can lift the hierarchy--$\\delta_{\\rm CP}$ degeneracy in NO$\\nu$A and strengthen the hierarchy reach of T2K in spite of having no $\\delta_{\\rm CP}$ sensitivity. Allowing the hierarchy to be a free parameter in the fit, if the true ordering is IH, JUNO aligns the NO$\\nu$A and T2K allowed regions and resolves their present tension; if NH is true, the tension continues to persist. We also show that JUNO's precise measurement of $|\\Delta_{31}|$ leads to improved constraints on $\\sin^2\\theta_{23}$ and $\\delta_{\\rm CP}$ for normal mass hierarchy in NO$\\nu$A even though JUNO itself is insensitive to these parameters. Finally, updated solar parameter measurements from JUNO's first data release further enhance the combined precision. Our results demonstrate that JUNO plays a crucial synergistic role in the global neutrino oscillation programme, enabling a more robust determination of the mass ordering and improving the sensitivity to the CP phase when combined with long-baseline data.",
    "authors": [
      "Srubabati Goswami",
      "Aman Gupta",
      "Ushak Rahaman",
      "Sushant K. Raut"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04070",
    "title": "On the angular momentum and free energy of rotating gluon plasma",
    "abstract": "We study the free energy and the angular momentum of rotating hot gluon matter using first-principle numerical simulations of the $\\textrm{SU}(3)$ lattice Yang-Mills theory. We calculate the specific moment of inertia and the specific deformation of the gluon matter as, respectively, the leading and next-to-leading terms in a series in angular velocity over a broad range of temperatures and various spatial boundary conditions. We show that the specific deformation, similarly to the moment of inertia, takes negative values in a phenomenologically interesting region of temperatures above the phase transition and turns positive at higher temperatures.",
    "authors": [
      "V. Braguta",
      "M. Chernodub",
      "E. Eremeev",
      "I. Kudrov",
      "A. Roenko",
      "D. Sychev"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03395",
    "title": "Tensor renormalization group calculations of partition-function ratios",
    "abstract": "The behavior of dimensionless quantities defined as ratios of partition functions is analyzed to investigate phase transitions and critical phenomena. At criticality, the universal values of these ratios can be predicted from conformal field theory (CFT) through the modular-invariant partition functions on a torus. We perform numerical calculations using the bond-weighted tensor renormalization group for three two-dimensional models belonging to different universality classes: the Ising model, the three-state Potts model, and the four-state Potts model. The partition-function ratios obey the same finite-size scaling form as the Binder parameter, and their critical values agree well with the universal values predicted by CFT. In the four-state Potts model, we observe logarithmic corrections in the system-size dependence of these ratios.",
    "authors": [
      "Satoshi Morita",
      "Naoki Kawashima"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.11288",
    "title": "Generalized Parton Distributions from Lattice QCD with Asymmetric Momentum Transfer: Tensor Case",
    "abstract": "The calculation of generalized parton distributions (GPDs) in lattice QCD was traditionally done by calculating matrix elements in the symmetric frame. Recent advancements have significantly reduced computational costs by calculating these matrix elements in the asymmetric frame, allowing us to choose the momentum transfer to be in either the initial or final states only. The theoretical methodology requires a new parametrization of the matrix element to obtain Lorentz-invariant amplitudes, which are then related to the GPDs. The formulation and implementation of this approach have already been established for the unpolarized and helicity GPDs. Building upon this idea, we extend this formulation to the four leading-twist quark transversity GPDs ($H_T$, $E_T$, $\\widetilde{H}_T$, $\\widetilde{E}_T$). We also present numerical results for zero skewness using an $N_f=2+1+1$ ensemble of twisted mass fermions with a clover improvement. The light quark masses employed in these calculations correspond to a pion mass of about 260 MeV. Furthermore, we include a comparison between the symmetric and asymmetric frame calculations to demonstrate frame independence of the Lorentz-invariant amplitudes. Analysis of the matrix elements in the asymmetric frame is performed at several values of the momentum transfer squared, $-t$, ranging from 0.17 GeV$^2$ to 2.29 GeV$^2$.",
    "authors": [
      "Shohini Bhattacharya",
      "Krzysztof Cichy",
      "Martha Constantinou",
      "Andreas Metz",
      "Joshua Miller",
      "Peter Petreczky",
      "Fernanda Steffens"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13997",
    "title": "Light-Front Transverse Nucleon Charge and Magnetisation Densities",
    "abstract": "Nucleon elastic electromagnetic form factors obtained using both the three-body and quark + fully-interacting-diquark pictures of nucleon structure are employed to calculate an array of light-front transverse densities for the proton and neutron and their dressed valence-quark constituents, viz. flavour separations of the proton and neutron results. These two complementary descriptions of nucleon structure deliver mutually compatible predictions, which match expectations based on modern parametrisations of available data, where such are available. Amongst other things, it is found that transverse-plane valence $u$- and $d$-quark Dirac radii are practically indistinguishable; but regarding kindred Pauli radii, the $d$ quark value is roughly 10% greater than that of the $u$-quark. Moreover, magnetically, the valence $d$ quark is far more active than the valence $u$ quark, probably because it has much greater orbital angular momentum. Both pictures of nucleon structure agree in predicting that, in a polarised nucleon, the transverse-plane charge densities are no longer rotationally invariant. Instead, for a $+\\hat x$ polarised nucleon, positive charge is displaced in the $+\\hat y$ direction, with the opposite effect for negative charge.",
    "authors": [
      "Z.-N. Xu",
      "Z.-Q. Yao",
      "P. Cheng",
      "C. D. Roberts",
      "J. Rodriguez-Quintero",
      "J. Segovia"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03133",
    "title": "A Thermal Relic Encyclopedia: Dark Matter Candidates Coupled to Quarks",
    "abstract": "Thermal freeze-out is a compelling framework for naturally generating the dark matter abundance. We systematically study a broad range of dark matter and mediator particle combinations that can viably realize thermal freeze-out, focusing on models in which the mediator couples to Standard Model quarks. In each case, we calculate the relic density and consider existing constraints from accelerators, cosmology, direct detection, and indirect detection over the full range of dark matter and mediator masses. We present an encyclopedic catalog of matrix elements, cross sections, and decay rates which can be used as a reference for future studies of dark matter phenomenology.",
    "authors": [
      "Dan Hooper",
      "Gordan Krnjaic",
      "Tanner Trickle",
      "Isaac R. Wang"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03144",
    "title": "Muon collider probes of the gluonic quartic gauge couplings",
    "abstract": "We investigate the dimension-8 gluonic quartic gauge couplings (gQGCs) at future high-energy muon colliders through the process $\\mu^{+}\\mu^{-}\\!\\to gg\\gamma$. Using detailed event simulation and optimized kinematic selections, we derive projected sensitivities to the Wilson coefficients and their associated new-physics scales, showing that muon colliders can probe deep into the multi-TeV regime and significantly surpass current LHC bounds. We further present the positivity bounds on those Wilson coefficients, as theoretical constraints from the fundamental principles of quantum field theory. Our results establish $\\mu^{+}\\mu^{-}\\!\\to gg\\gamma$ as one of the most sensitive probes of dimension-8 new physics at future muon colliders.",
    "authors": [
      "Yu-Chen Guo",
      "Peng-Cheng Lu",
      "Tong Arthur Wu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03153",
    "title": "Heavy Long-lived Dark Vector Via a Gluonic Portal",
    "abstract": "We study a dark gauge boson $ Z' $ that exclusively couples to the QCD gluons through higher dimensional operators. These operators are generated from integrating out of heavy ultraviolet resonances carrying both QCD and dark gauge charges. With $ SU(3)_C $ gauge invariance, charge and parity symmetries preserved, we find that the leading effective operators are restricted to have the form of $ Z'GGG $ and $ Z'Z'GG $ at dimension-eight, which can naturally render the $Z^\\prime$ particle long-lived, and serve as a viable dark matter candidate. We investigate the phenomenology of these operators with both collider experiments and cosmological observation, without and with the assumption that this dark gauge boson plays the role of the dominant dark matter component. For an unstable $Z'$, we show that depending on its lifetime, it can be probed by various observables up to ultraviolet physics scale around $10^9$ GeV. For $Z'$ being dark matter, we find that $m_{Z^\\prime} \\gtrsim 1 $ TeV is consistent with the thermal freeze-out scenario. In contrast, in the freeze-in scenario, the extremely small couplings leave the relevant parameter space largely unconstrained by current experiments.",
    "authors": [
      "Xiaoyong Chu",
      "Qiyuan Gao",
      "Hongkai Liu",
      "Teng Ma",
      "Chengjie Yang"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03157",
    "title": "Effective Field Theory Perspective On King Non-linearity",
    "abstract": "Precision spectroscopic measurements of isotope shifts have recently reached a high level of accuracy. Tests of King non-linearity (NL) along isotope chains have been proposed as a tool to search for fifth-force mediators. At the same time, these tests can potentially teach us about the structure of heavy nuclei at unprecedented precision, where King NL has already been observed in several systems. A robust interpretation of the existing data, however, is hampered by incomplete control over the Standard Model (SM) contributions. We develop a systematic effective field theory framework, matching the SM onto scalar non-relativistic QED in the infinite nuclear mass limit and then onto quantum-mechanical potentials. This approach organizes all nuclear effects into a small set of Wilson coefficients and cleanly separates short- and long-distance physics. We show that the commonly used treatment of the $\\langle r^2\\rangle^2$ term needs to be reconsidered, as it arises only at second-order in perturbation theory, and we derive the long-range $1/r^4$ potential from nuclear polarizability. Applying the framework to hydrogen-like systems, we provide a transparent classification of SM sources of King NL relevant for current and future isotope-shift experiments. The formalism can be applied to learn about the shape of the heavy scalar nuclei at a higher level of precision and detail than what was previously attainable.",
    "authors": [
      "Benoît Assi",
      "Sam Carey",
      "Sebastian Jäger",
      "Gabriel Lee",
      "Gil Paz",
      "Gilad Perez",
      "Jure Zupan"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03220",
    "title": "New physics in toponium's shadow?",
    "abstract": "ATLAS and CMS have recently reported enhancements in the top-antitop production rate near threshold, a region where non-perturbative QCD dynamics associated with toponium formation become relevant. We investigate how this behaviour is modified in the presence of a neutral pseudoscalar that couples to gluons and top quarks, using an effective description that consistently incorporates perturbative Standard Model and new physics contributions, their interference and non-perturbative threshold effects. We show that the combined effect of those ingredients markedly shapes the viable region of the pseudoscalar parameter space, particularly for narrow resonances with masses close to twice the top mass. While Standard Model threshold effects could explain a sizeable part of the measured enhancements, the current data remain compatible with additional contributions from pseudoscalar interactions.",
    "authors": [
      "Thomas Flacke",
      "Benjamin Fuks",
      "Dongchan Kim",
      "Jinheung Kim",
      "Seung J. Lee",
      "Léandre Munoz-Aillaud"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03263",
    "title": "NNLO+NNLL Predictions for Heavy-Jet Mass and C-parameter in Higgs Decays to Quarks and Gluons",
    "abstract": "We consider the resummation of large logarithmic corrections arising in the two-particle limit at next-to-next-to-leading logarithmic (NNLL) accuracy for the heavy-jet mass and $C$-parameter distributions in the decay of a Higgs boson to quarks and gluons: $H\\to b\\bar{b}$, $H\\to c\\bar{c}$, and $H\\to gg$. We demonstrate how the matched NNLO+NNLL results clarify the relative contributions of key hadronic Higgs-decay channels ($H\\to b\\bar{b}$, $H\\to c\\bar{c}$, $H\\to gg$) yielding reduced uncertainties for both event-shape observables -- especially for heavy-jet mass -- while revealing substantial effects that shift the $C$-parameter peak in gluonic decays.",
    "authors": [
      "Elliot Fox",
      "Aude Gehrmann-De Ridder",
      "Thomas Gehrmann",
      "Nigel Glover",
      "Matteo Marcoli",
      "Christian T. Preuss"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03302",
    "title": "Lepton number violation from Higgs/$Z$ decays into a pair of right-handed neutrinos",
    "abstract": "We explore signatures of Lepton Number Violation (LNV) from decays of the discovered Higgs ($h$) and Z bosons into a pair of Right-Handed Neutrinos (RHNs). Due to the Majorana nature of RHNs, the final state can be the same-sign dilepton plus jets leading to 2 units of LNV. As a simple but plausible scenario, we investigate such a signal in models with a new $U(1)_X$ gauge symmetry which naturally introduces three RHNs for gauge anomaly cancellation, and is spontaneously broken down by a vacuum expectation value of an isospin singlet scalar field ($\\phi$). In this scenario, $h$ and the Z boson can decay into a pair of RHNs via the $h$-$\\phi$ mixing and the $Z$-$Z'$ mixing with $Z'$ being a new massive gauge boson, respectively. Estimating the LNV signal and corresponding backgrounds for the $\\ell^{\\pm} \\ell^{\\pm} 4j$ final states, we find bounds on the $h$-$\\phi$ mixing and the $Z$-$Z^\\prime$ mixing as a function of a mass of RHNs at Higgs factories, e.g., at High-Luminosity LHC with $\\sqrt{s}=$ 14 TeV, future $e^-e^+$ colliders at $\\sqrt{s}=$ 250 GeV, muon colliders at $\\sqrt{s}=$ 125 GeV as well as at Z factories, e.g., CEPC and FCC-ee at $\\sqrt{s}=$ 91.2 GeV. We also discuss limits on the scalar mixing at $e^-\\mu^+$ and $\\mu^+ \\mu^+$ collisions ($\\mu$TRISTAN) with $\\sqrt{s}=$346 GeV/775 GeV and 2 TeV, respectively.",
    "authors": [
      "Arindam Das",
      "Takaaki Nomura",
      "Kei Yagyu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03567",
    "title": "Probing the Electroweak Phase Transition in the Dark Sector",
    "abstract": "We study an extension of the Standard Model with a dark SU(2) gauge group, where a dark scalar doublet interacts with the Standard Model Higgs through a portal coupling, inducing mixing after symmetry breaking. A custodial symmetry ensures the stability of the dark gauge bosons, making them viable dark matter candidates. Scanning the parameter space of the model under collider and astrophysical constraints, we find regions that yield the observed relic density and strong first-order phase transitions. The resulting gravitational-wave signals fall within the reach of upcoming space-based detectors.",
    "authors": [
      "Maimoona Razzaq",
      "Nico Benincasa",
      "Luigi Delle Rose",
      "Luca Panizzi"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03614",
    "title": "Real-time evolution of critical modes in the QCD phase diagram",
    "abstract": "A QCD-assisted relaxation dynamic model for the critical mode of the critical end point (CEP) in the QCD phase diagram is developed, which allows us to investigate the critical slowing down effect quantitatively in the QCD phase diagram, especially in the proximity of the CEP, without any phenomenological parameters. The relaxation time from nonequilibrium to equilibrium in the QCD phase diagram is extracted from the Langevin simulations of the QCD-assisted relaxation dynamic model. It is found that in a narrow region along the phase boundary radiated from the CEP, the relaxation time is enhanced significantly. Outside this narrow region, the relaxation time drops drastically, which implies that the dynamic critical region is small in the QCD phase diagram. We also find that the effects of critical slowing down are mild on the chemical freeze-out curves.",
    "authors": [
      "Yang-yang Tan",
      "Shi Yin",
      "Yong-rui Chen",
      "Chuang Huang",
      "Wei-jie Fu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03662",
    "title": "Gravitational Decays of Secluded Scalars and Graviton Dark Radiation",
    "abstract": "We discuss graviton dark radiation produced by the decay of a secluded scalar field that couples to the Standard Model (SM) only through gravity. Such scalar fields are long-lived, and their decay channels generically include gravitons. If such particles existed and dominated the early universe, a sizable branching ratio into gravitons would yield non-negligible dark radiation that significantly alters the subsequent thermal history of the universe. In this work, we focus on the dark glueball as a representative secluded hidden scalar and compare the decay rates into SM particles via a non-minimal coupling to gravity with those into gravitons, paying attention to how the breaking of conformal invariance affects the amount of graviton dark radiation. We find that decays into the SM are dominated by two-body decay channels into Higgs bosons and gluons. In particular, when the Higgs field has a large non-minimal coupling to gravity, the production of graviton dark radiation is naturally suppressed in the metric formalism, and the SM sector is preferentially reheated and energy transfer to other hidden sectors is suppressed. Finally, we present the expected gravitational-wave spectrum resulting from dark glueball domination.",
    "authors": [
      "Kazunori Nakayama",
      "Fuminobu Takahashi",
      "Juntaro Wada"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03725",
    "title": "Probing Azimuthal Alignment in Heavy-Ion Collisions: Clusterization Effects",
    "abstract": "The influence of kinematic constraints and event selection on the emergence of the alignment phenomenon observed in cosmic-ray experiments is studied within the HYDJET++ model. It is demonstrated that the high degree of alignment, previously identified for realistic values of the transverse momentum disbalance of the most energetic particles, is also observed at the level of the most energetic clusters. In high-multiplicity events, the clustering procedure plays a crucial role in resolving individual particle groups on the detection plane, allowing a more accurate characterization of alignment patterns. These results highlight the combined effects of cluster formation and momentum conservation in shaping the observed azimuthal correlations.",
    "authors": [
      "Aleksei Nikolskii",
      "Igor Lokhtin",
      "Alexander Snigirev"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03800",
    "title": "Hidden-charm and -bottom tetraquark states with $J^{PC}=1^{-+}$ via QCD sum rules",
    "abstract": "We investigate the $1^{-+}$ hidden-charm and hidden-bottom tetraquark states within the framework of QCD sum rules. The mass spectra are computed by including condensates up to dimension eight in the operator product expansion. Our results indicate the possible existence of four $1^{-+}$ hidden-charm tetraquark states, with predicted masses of $(4.83 \\pm 0.15)$ GeV, $(4.88 \\pm 0.18)$ GeV, $(4.72 \\pm 0.16)$ GeV, and $(4.79 \\pm 0.12)$ GeV, while their hidden-bottom counterparts are estimated to have masses of $(11.08 \\pm 0.16)$ GeV, $(11.16 \\pm 0.14)$ GeV, $(10.99 \\pm 0.16)$ GeV, and $(11.03 \\pm 0.15)$ GeV, respectively. We also analyze the possible decay modes of these tetraquark states, which may be accessible in future experiments at BESIII, Belle~II, and LHCb. These findings provide valuable guidance for the experimental search for exotic $1^{-+}$ tetraquark states in both the charm and bottom sectors.",
    "authors": [
      "Bing-Dong Wan",
      "Yan Zhang",
      "Jun-Hao Zhang",
      "Ming-Yang Yuan"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03801",
    "title": "A strategy for optimal material identification in solar dark photon absorption",
    "abstract": "Dark photons with masses in the 1-100 eV range can be produced in the Sun and subsequently absorbed in terrestrial detectors, offering a promising avenue for probing hidden-sector physics beyond the Standard Model. In this work, we develop a theoretically grounded strategy to identify optimal detector materials for solar dark photon absorption. Our strategy builds on a material-independent upper limit on the absorption rate, which we derive from Kramers-Kronig relations applied separately to the longitudinal and transverse dark photon modes. We show how the optimal material properties depend on the dark photon mass relative to the detector's plasma frequency, identifying the conditions under which a detector can saturate the theoretical upper limit. We then assess the performance of commonly used detector materials in light of these criteria and comment on the prospects of metamaterials featuring tunable plasma frequencies. Our results provide a general and model-independent framework to effectively guide the design of next-generation experiments targeting solar dark photons.",
    "authors": [
      "Theresa M. Backes",
      "Riccardo Catena",
      "Michael Krämer"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03809",
    "title": "Discrete flavour and CP symmetries in light of JUNO and neutrino global fit",
    "abstract": "Working within the reference three-neutrino mixing framework, we confront the lepton mixing predictions derived using non-Abelian discrete flavour and CP symmetries with the firs JUNO data on the solar neutrino mixing parameters $\\sin^2\\theta_{12}$ and with the results of the latest global neutrino data analysis. We focus on symmetry breaking patterns for which the lepton PMNS mixing matrix depends only on one or two free real parameters. Performing a comprehensive statistical analyses in each of the considered cases, we report the best fit values, the $3\\sigma$ C.L. allowed ranges and the $\\chi^2$-distributions of the lepton mixing observables - the three mixing angles and the three CP-violation phases. We find that the JUNO measurements can disfavour or rule out a number of the mixing patterns associated with specific types of breakings of the discrete flavour and CP symmetries. The synergy of JUNO, DUNE and T2HK data can provide an exhaustive test of the considered approach to lepton mixing based on non-Abelian discrete lepton flavour symmetries combined with the CP symmetry.",
    "authors": [
      "Gui-Jun Ding",
      "Cai-Chang Li",
      "Jun-Nan Lu",
      "S. T. Petcov"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03810",
    "title": "Production of charged Higgs bosons associated with CP-even Higgs bosons at future multi--TeV muon colliders",
    "abstract": "We report the first results for charged Higgs boson production associated with CP-even Higgses at future multi--TeV muon colliders within the scenario of the Type-Y Two-Higgs-Doublet Model (THDM). The valid parameter regions in the Type-Y THDM are first updated, and based on the allowed parameter space, all two-body decay channels of the charged Higgs boson are then computed with the help of {\\tt H-COUP}. Both production processes $\\mu^- \\mu^+ \\to H^\\pm H^\\mp h, H^\\pm H^\\mp H \\to t\\bar{t} b\\bar{b} h, t\\bar{t} b\\bar{b}H$ are scanned over the constrained parameter space of the considered model. The production cross sections can reach $\\sim 0.5$ fb in several regions of the parameter space. The results provide an opportunity to probe charged Higgs bosons produced in association with the heavy CP-even Higgses at the high integrated luminosities proposed for future multi--TeV muon colliders. Furthermore, we evaluate the signal significances for $\\mu^- \\mu^+ \\to H^\\pm H^\\mp h \\to t\\bar{t} b\\bar{b} h \\to t\\bar{t} b\\bar{b} b\\bar{b}$ with respect to the Standard Model backgrounds. We also estimate the significances by including the top quark decay into leptons and bottom quarks and considering $b$-tagging. Thanks to the high integrated luminosities anticipated at future multi--TeV muon colliders,we find that the signal significances can exceed $\\sim 3\\sigma$ at several benchmark points selected in the viable parameter space of the Type-Y THDM.",
    "authors": [
      "Quang Hoang-Minh Pham",
      "Khoa Ngo-Thanh Ho",
      "Khiem Hong Phan"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03894",
    "title": "Kinetic Mixing and Axial Charges in the Parity-Doublet Model",
    "abstract": "The standard parity doublet model with its mass-mixing mechanism fails to describe the axial charge $g_A$ of the nucleon. While $g_A = 1$ in the original Gell-Mann--Levy model, which reproduces the Adler-Bell-Jackiw anomaly of QCD, in the presence of a chirally invariant baryon mass the mass mixing leads to $g_A < 1 $ whereas phenomenologically it is about 1.28. We propose to remedy this problem by introducing kinetic-mixing terms corresponding to meson-baryon derivative couplings, similar in spirit to the two-mixing-angle scenario of the $\\eta$-$\\eta'$ mixing. This extended parity doublet model contains five parameters in the effective baryonic Lagrangian. Three of them can be determined by using the empirical results for the axial charge of the nucleon together with the masses of the nucleon and its parity partner, the $N^*(1535)$ resonance. We discuss various options how to determine the remaining parameters, touching upon the mass of both parity partners if the chiral condensate is put to zero; the mass of the nucleon in the chiral limit; and the values of meson-baryon coupling constants related to the decays of the resonance to pion-nucleon and sigma-nucleon.",
    "authors": [
      "Christian Kummer",
      "Stefan Leupold",
      "Lorenz von Smekal"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03954",
    "title": "Jet Production at NNLO: Exploring a New Scheme",
    "abstract": "We consider dijet production in $e^+e^-$ collisions and in $H\\to b{\\bar b}$ decays at next-to-next-to-leading order (NNLO) in perturbative QCD. A new non-local subtraction scheme is applied, for the first time, to obtain the fully differential cross section for these benchmark processes. We discuss and explicitly evaluate the perturbative ingredients needed in the computation, and we compare the performance of different slicing variables to obtain the NNLO corrections.",
    "authors": [
      "Luca Buonocore",
      "Massimiliano Grazzini",
      "Flavio Guadagni",
      "Jürg Haag",
      "Stefan Kallweit",
      "Luca Rottoli"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04001",
    "title": "Superexotic $K^{*+}D^{*+}K^{*+}$ bound state",
    "abstract": "We study a system made from $K^{*+}D^{*+}K^{*+}$ with charge $3$, isospin $I=3/2$, spin $J=3$, and a quark content of $c\\bar d \\bar s u \\bar s u$, which make it highly exotic relative to the standard $q\\bar q$ structure of mesons. The interaction of the three body system is obtained starting from a cluster of $K^{*+}D^{*+}$ in $I=1$ and $J=2$, that in different works has been found bound, and adding to it an extra $K^{*+}$ with spin aligned with those of the vectors of the cluster. We find that the $K^* K^*$ interaction in $I=1$ and $J=2$ is repulsive, but its strength is small compared to that of $K^{*+}D^{*+}$ in $I=1$ and $J=2$, such that we find a three body state bound by about $100 \\, \\rm MeV$ with respect to the mass of a $K^{*+}$ and the $K^{*+} D^{*+}$ cluster. The width of the state, of about $10\\, \\rm MeV$, is much smaller than the binding, which facilitates its observation. We suggest to find that state by measuring the invariant mass of $K D K^*$, something feasible in present experimental facilities.",
    "authors": [
      "Wen-Hao Jia",
      "Pei-Shen Su",
      "Wei-Hong Liang",
      "Raquel Molina",
      "Eulogio Oset"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04064",
    "title": "New insights into two-loop running in effective field theories",
    "abstract": "We show that, by viewing a 4D effective-field theory as the infrared (IR) limit of the compactified version in 5D, we can compute two-loop anomalous dimensions without gauge-breaking counter-terms, IR re-arrangement or geometric methods. The ultraviolet (UV) divergences in 4D are read from the IR ones in the matching from 5D to 4D. We use this approach to cross-check recent results in the literature, as well as to compute novel two-loop anomalous dimensions in the SMEFT to dimension eight and certain critical exponents in the charged fixed point of the Abelian Higgs model at large number of flavors.",
    "authors": [
      "Mikael Chala",
      "Javier López Miras"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04079",
    "title": "Flavour and precision probes of a class of scotogenic models",
    "abstract": "We address the phenomenological impact of a well-motivated class of scotogenic models regarding flavour and electroweak precision observables. For the case of a ``T1-2-A'' variant, we carry out a full computation of the next-to-leading order corrections to leptonic Higgs and $Z$-boson decays. We revisit previously drawn conclusions on operator dominance and constraints on the parameter space in view of the evolution regarding $\\Delta a_\\mu$. Finally, we consider the role of $H \\to \\mu\\mu$ decays (and other flavour conserving Higgs decays), as well as precision observables in probing this class of models at future colliders.",
    "authors": [
      "A. Darricau",
      "H. Lee",
      "J. Orloff",
      "A. M. Teixeira"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.19010",
    "title": "Constraints on Axion-Like Particles from VERITAS Observations of a Flaring Radio Galaxy in the Perseus Cluster",
    "abstract": "Background: Axion-like particles (ALPs) are hypothetical particles that emerge in numerous theoretical extensions to the Standard Model. Their coupling to electromagnetic field implies that ALPs would mix with photons in the presence of external magnetic fields. As ALP phenomenology is governed by the mass and strength of its coupling, there is a subset of this parameter space in which this mixing would be expected to leave an imprint on the spectra of TeV gamma-ray sources. Data: In 2017, the VERITAS gamma-ray observatory recorded the second day of a dramatic flare of the radio galaxy NGC 1275, embedded at the center of the Perseus galaxy cluster. This serendipitous locale provides a spatially-extended magnetic field of strength O(10$\\mu$G) through which escaping photons traverse, making it an excellent target to study ALPs. Methods: We analyze the VERITAS data of NGC 1275's 2017 flare with the gammapy analysis package. Extensive fitting and modeling are performed to ultimately conduct a likelihood analysis used to search for any evidence of a preference for ALPs and to explore the confidence with which constraints can be set. We adopt the CLs method for this study for its conservative approach to setting limits in regimes where the search has limited sensitivity. Results: No evidence for the existence of ALPs is found, and no combination of mass and coupling strength can be excluded at or above 95% confidence level. We provide a map showing the strength of our exclusions in the mass and coupling parameter space. The strongest exclusions are found in the mass range $2 \\times 10^{-7}$eV $\\lesssim m_a \\lesssim 4 \\times 10^{-7}$eV and at the coupling strength of $g_{a\\gamma} \\gtrsim 3 \\times 10^{-11}$ GeV$^{-1}$ up to 80% confidence level, which are consistent with previous studies. Conclusions: We find the CLs method to be a trustworthy approach, and advocate for its...",
    "authors": [
      "C. B. Adams",
      "A. Archer",
      "P. Bangale",
      "J. T. Bartkoske",
      "W. Benbow",
      "Y. Chen",
      "J. L. Christiansen",
      "A. J. Chromey",
      "A. Duerr",
      "M. Errando",
      "M. Escobar Godoy",
      "J. Escudero Pedrosa",
      "S. Feldman",
      "Q. Feng",
      "S. Filbert",
      "L. Fortson",
      "A. Furniss",
      "W. Hanlon",
      "O. Hervet",
      "C. E. Hinrichs",
      "J. Holder",
      "Z. Hughes",
      "T. B. Humensky",
      "M. Iskakova",
      "W. Jin",
      "P. Kaaret",
      "M. Kertzman",
      "M. Kherlakian",
      "D. Kieda",
      "T. K. Kleiner",
      "N. Korzoun",
      "F. Krennrich",
      "S. Kumar",
      "S. Kundu",
      "M. J. Lang",
      "M. Lundy",
      "P. Moriarty",
      "R. Mukherjee",
      "W. Ning",
      "R. A. Ong",
      "A. Pandey",
      "M. Pohl",
      "E. Pueschel",
      "J. Quinn",
      "P. L. Rabinowitz",
      "K. Ragan",
      "P. T. Reynolds",
      "D. Ribeiro",
      "E. Roache",
      "C. Rulten",
      "I. Sadeh",
      "L. Saha",
      "M. Santander",
      "G. H. Sembroski",
      "R. Shang",
      "D. Tak",
      "A. K. Talluri",
      "J. V. Tucci",
      "J. Valverde",
      "V. V. Vassiliev",
      "D. A. Williams",
      "S. L. Wong",
      "J. Woo",
      "T. Yoshikoshi",
      "M. Meyer"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03152",
    "title": "Inferring black hole formation channels in GWTC-4.0 via parametric mass-spin correlations derived from first principles",
    "abstract": "We investigate the differences between several proposed formation scenarios for binary black holes (BBHs), including isolated stellar evolution, dynamical assembly in dense clusters and AGN disks, and primordial BHs. Our approach exploits the predicted spin features of each formation channel, and adopts parameterized models of the predicted correlations between the spin magnitudes (and orientations) and mass, inspired by first principles. Using hierarchical Bayesian inference on the recent GWTC-4.0 dataset, we compare these features across all models and assess how well each scenario explains the data. We find that the data strongly favor the presence of a positive correlation between mass and spin magnitude, in agreement with previous studies. Furthermore, the hierarchical scenario provides a better fit to the observations, due to the inclusion of second-generation mergers leading to higher spins at larger masses. The current dataset is not informative enough about spin orientation: the cluster (random orientations) and AGN (aligned orientations) scenarios have comparable Bayesian evidence. Finally, the mass-spin correlation predicted by the primordial scenario gives a poor fit to the data, and this scenario can only account for a subset of the observed events.",
    "authors": [
      "Emanuele Berti",
      "Francesco Crescimbeni",
      "Gabriele Franciolini",
      "Simone Mastrogiovanni",
      "Paolo Pani",
      "Grégoire Pierra"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03702",
    "title": "Trapped fireshell (halo) of photons and pairs around black-hole horizon: source for ultra-high-energy particles",
    "abstract": "We study the Compton-rocket effect of multi-photon interacting with electrons in an opaque fireball (or fire spot) of photons and $e^-e^+$ pairs at temperature $T_\\gamma\\gg m_e$. We find the charged-particle acceleration and the avalanche runaway process, leading to a non-trivial probability of ultra-high-energy (UHE) electrons and protons, which subsequently produce very-high-energy (VHE) photons and neutrinos. We show such peculiar dynamics using the Gamma-Ray Burst central engine fireball, whose inner part inflows and forms a gravitationally trapped fireshell (halo) around a black hole. The halo is a metastable, cooling via UHE particle emissions and blackbody radiation. We calculate the UHE particle luminosity varying in time, and discuss the peculiar features of such produced UHE particles, which lead to VHE particles, in connection with possible numerical simulations, observations and experiments.",
    "authors": [
      "She-Sheng Xue"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04011",
    "title": "Freeze-out and spectral running of primordial gravitational waves in viscous cosmology",
    "abstract": "We investigate the impact of shear viscosity on the propagation of primordial gravitational waves (pGW) after inflation. Without assuming a specific inflationary scenario we focus on the evolution of pGWs after they re-enter the horizon during a cosmological epoch characterized by the presence of shear viscosity. We show that shear viscosity introduces an additional damping term in the tensor equation, modifying both the transfer function and the energy density power spectrum. For a constant shear viscosity-to-Hubble ratio the transfer function acquires an extra red tilt, while a time-dependent viscosity leads to a running spectral index $\\Omega_\\text{GW}\\sim k^{n_\\text{eff}(k)}$ controlled by the time evolution of the mean free path of the viscous fluid. Our analysis provides a general framework to analytically quantify how shear viscosity can alter the primordial gravitational wave background in standard and non-standard post-inflationary scenarios. As a case study we evaluate the effect of viscosity of the electron-photon-baryon plasma, on both the transfer function and the normalized energy density, finding a $k$-dependent blue tilt due to gravitational wave freeze-out from the viscous phase. This effect corresponds to a fractional difference of order $10^{-3}$.",
    "authors": [
      "Giuseppe Fanizza",
      "Eliseo Pavone",
      "Luigi Tedesco"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04061",
    "title": "Multimessenger Constraints on Supermassive Dark Stars and Their Black Hole Remnants",
    "abstract": "Dark matter (DM) annihilation can power the first generation of stars as long lived dark stars (DSs) that grow to supermassive scales $M_{\\rm DS}\\gtrsim 10^{5} M_{\\odot}$ and eventually collapse into heavy black holes that could seed the supermassive black holes observed at high redshifts. We compute the diffuse electromagnetic emission from a cosmological population of such supermassive DSs and their black hole remnants, tracking the entire DS history and including thermal surface radiation, DM annihilation in adiabatically contracted halos as well as late-time emission from DM overdensity spikes around the resulting black holes. After accounting for photon attenuation, we find that DS related contributions can exceed the Fermi-LAT extragalactic $\\gamma$-ray background for thermal relic annihilation cross-sections and DM masses below $\\sim 1$ TeV. Our results constitute the first population integrated diffuse multimessenger constraints on supermassive DSs as progenitors of early black holes and demonstrate that diffuse photon and neutrino backgrounds offer a powerful and complementary avenue for probing the role of DM in the formation of the earliest massive structures.",
    "authors": [
      "Marco Manno",
      "Thomas Schwemberger",
      "Volodymyr Takhistov"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04070",
    "title": "On the angular momentum and free energy of rotating gluon plasma",
    "abstract": "We study the free energy and the angular momentum of rotating hot gluon matter using first-principle numerical simulations of the $\\textrm{SU}(3)$ lattice Yang-Mills theory. We calculate the specific moment of inertia and the specific deformation of the gluon matter as, respectively, the leading and next-to-leading terms in a series in angular velocity over a broad range of temperatures and various spatial boundary conditions. We show that the specific deformation, similarly to the moment of inertia, takes negative values in a phenomenologically interesting region of temperatures above the phase transition and turns positive at higher temperatures.",
    "authors": [
      "V. Braguta",
      "M. Chernodub",
      "E. Eremeev",
      "I. Kudrov",
      "A. Roenko",
      "D. Sychev"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:1811.11125",
    "title": "Constraining ultra light fermionic dark matter with Milky-Way observations",
    "abstract": "The equation of state for a degenerate gas of fermions at zero temperature in the non-relativistic case is a polytrope, i.e. $p \\sim\\rho^{5/3}/m_F^{8/3}$. If dark matter is modeled by such a non-interacting fermion, this dependence in the mass of the fermion $m_F$ explains why if dark matter is very heavy the effective pressure of dark matter is negligible. Nevertheless, if the mass of the dark matter is very small, the effective pressure can be very large, and thus a system of self-gravitating fermions can be formed. In this work we model the dark matter halo of the Milky-Way by solving the Tolman-Oppenheimer-Volkoff equations, with the equation of state for a partially degenerate ultralight non-interacting fermion. We found that to fit the rotational velocity curve of the Milky-Way, the mass of the fermion should be in the range $31.5 ~\\mbox{eV} < m_F < 35~$eV at $90\\%$ C.L. Moreover, the central density is restricted to be in the range of $1.2 < \\rho_0<1.7$ GeV/cm$^3$ at $90\\%$ C.L. The fermionic dark matter halo has a very different profile as compared with the standard Navarro-Frenk-White profile, thus, the possible indirect signals for annihilating dark matter may change by orders of magnitude. We found bounds for the annihilation cross section in this case by using the Saggitarius A* spectral energy distribution.",
    "authors": [
      "J. Barranco",
      "A. Bernal",
      "D. Delepine"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2101.00308",
    "title": "On the evaluation of two-loop electroweak box diagrams for $e^+e^- \\to HZ$ production",
    "abstract": "Precision studies of the Higgs boson at future $e^+e^-$ colliders can help to shed light on fundamental questions related to electroweak symmetry breaking, baryogenesis, the hierarchy problem, and dark matter. The main production process, $e^+e^- \\to HZ$, will need to be controlled with sub-percent precision, which requires the inclusion of next-to-next-to-leading order (NNLO) electroweak corrections. The most challenging class of diagrams are planar and non-planar double-box topologies with multiple massive propagators in the loops. This article proposes a technique for computing these diagrams numerically, by transforming one of the sub-loops through the use of Feynman parameters and a dispersion relation, while standard one-loop formulae can be used for the other sub-loop. This approach can be extended to deal with tensor integrals. The resulting numerical integrals can be evaluated in minutes on a single CPU core, to achieve about 0.1% relative precision.",
    "authors": [
      "Qian Song",
      "Ayres Freitas"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2306.10540",
    "title": "Search for Lepton Flavor Violating Signals at the Future Electron-Proton Colliders",
    "abstract": "The search for lepton flavor violation (LFV) is a powerful probe to look for new physics beyond the Standard Model. We explored the possibility of searches for LFV $Z$ boson couplings to electron and muon pairs at the upcoming electron-proton colliders, namely the Large Hadron Electron Collider (LHeC) and the Future Circular lepton-hadron Collider (FCC-eh). We employed the study via a single muon plus an associated jet channel to search for the LFV signal. We used a multivariate technique to obtain an improved signal-background analysis. By using the condition on nonobservation of any significant deviation of the signal over the expected background, we provide an upper limit on the LFV $Z$ boson coupling and corresponding branching ratio (BR). We find that an upper limit of up to $1.13\\times 10^{-7}$ and $4.64 \\times 10^{-8}$ can be set on BR($Z\\to e \\mu$) at 95\\% confidence level (C.L.) with one year run of LHeC and FCC-eh, respectively, if the LFV coupling is governed by vector or axial-vector coupling. For tensor or axial-tensor coupling, these limits can be improved up to $2.34\\times 10^{-8}$ and $5.02\\times 10^{-9}$ for LHeC and FCC-eh machines, respectively, at 95\\% C.L. The projected numbers improve significantly over the existing limit of $2.62\\times 10^{-7}$ set by ATLAS.",
    "authors": [
      "Anjan Kumar Barik",
      "Atri Dey",
      "Tousik Samui"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2406.01705",
    "title": "Dark Matter",
    "abstract": "We review observational, experimental and theoretical results related to Dark Matter.",
    "authors": [
      "Marco Cirelli",
      "Alessandro Strumia",
      "Jure Zupan"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.01675",
    "title": "Hawking Radiation of Nonrelativistic Scalars: Applications to Pion and Axion Production",
    "abstract": "In studying secondary gamma-ray emissions from Primordial Black Holes (PBHs), the production of scalar particles like pions and axion-like particles (ALPs) via Hawking radiation is crucial. While previous analyses assumed relativistic production, asteroid-mass PBHs, relevant to upcoming experiments like AMEGO-X, likely produce pions and ALPs non-relativistically when their masses exceed 10 MeV. To account for mass dependence in Hawking radiation, we revisit the greybody factors for massive scalars from Schwarzschild black holes, revealing significant mass corrections to particle production rates compared to the projected AMEGO-X sensitivity. We highlight the importance of considering non-relativistic $\\pi^0$ production in interpreting PBH gamma-ray signals, essential for determining PBH properties. Additionally, we comment on the potential suppression of pion production due to form factor effects when producing extended objects via Hawking radiation. We also provide an example code for calculating the Hawking radiation spectrum of massive scalar particles.",
    "authors": [
      "Hao-Ran Cui",
      "Yuhsin Tsai",
      "Tao Xu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.13150",
    "title": "A Field Guide to Event-Shape Observables Using Optimal Transport",
    "abstract": "We lay out the phenomenological behavior of event-shape observables evaluated by solving optimal transport problems between collider events and reference geometries -- which we name 'manifold distances' -- to provide guidance regarding their use in future studies. This discussion considers several choices related to the metric used to quantify these distances. We explore the differences between the various options, using a combination of analytical studies and simulated minimum-bias and multi-jet events. Making judicious choices when defining the metric and reference geometry can improve sensitivity to interesting signal features and reduce sensitivity to non-perturbative effects in QCD. The goal of this article is to provide a 'field guide' that can inform how choices made when defining a manifold distance can be tailored for the analysis at-hand.",
    "authors": [
      "Cari Cesarotti",
      "Matt LeBlanc"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.06530",
    "title": "A Classical Interpretation of the Nonrelativistic Quark Potential Model: Color Charge Definition and the Meson Mass-Radius Relationship",
    "abstract": "Quantum Chromodynamics (QCD) is the fundamental theory describing quark interactions, and various quark models based on QCD have been widely used to study the properties of hadrons, including their structures and mass spectra. However, unlike Quantum Electrodynamics (QED) and the Bohr model of the hydrogen atom, there is no direct classical analogy for hadronic this http URL paper presents a classical interpretation of the nonrelativistic quark potential model, providing a more intuitive and visualizable description of strong interactions through the quantitative formulation of color charge and color this http URL , we establish the relationship between meson mass and its structural radius in the nonrelativistic framework and estimate the key parameters of our model using available data from $\\eta_b(1S)$ and $\\Upsilon(1S)$. We then extend this relationship to a broader range of excited meson states, obtaining structural radii that show good agreement with the root mean square (RMS) radius or charge radius predicted by QCD calculations.",
    "authors": [
      "ZhiGuang Tan",
      "YouNeng Guo",
      "ShengJie Wang",
      "Hua Zheng"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.10668",
    "title": "Analyzing the general conditions for modulus stabilization in a warped braneworld",
    "abstract": "In braneworld scenarios with compact extra dimensions, the modulus field typically remains undetermined without an appropriate stabilization mechanism. A common approach introduces a bulk scalar field that generates an effective potential for the modulus with a stable minimum. In this work, we explore some novel aspects of such stabilization mechanisms. We study how the bulk scalar profile influences the stabilization procedure. Following the approach of Chacko et al. [1], we analyze several representative cases using methods of singular perturbation theory. We identify a consistent relationship between the structure of the bulk potential and the emergence of a stabilized modulus, and outline the general conditions that any bulk potential must satisfy to enable stabilization. In this context, we also examine a potential connection between geometric consistency conditions - specifically, the \"brane world sum rules\" - and the stabilized value of the modulus. In some scenarios where stabilization occurs, we find that these sum rules can offer additional constraints on the modulus, providing a complementary perspective on its determination. Taken together, these results offer a broader perspective on the mechanisms that govern modulus stabilization in higher-dimensional warped geometries.",
    "authors": [
      "Soham Bhattacharyya",
      "Soumitra SenGupta"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.13649",
    "title": "Next-to-leading-order QCD calculations of $B \\to A$ form factors with higher-twist corrections",
    "abstract": "Applying the light-cone sum rules (LCSR) approach, the next-to-leading-order (NLO) corrections to $B \\to A$ form factors are calculated with the twist-two and twist-three $B$ meson light-cone distribution amplitudes (LCDAs) at leading power in $\\Lambda / m_b$. At one-loop level, the vacuum-to-$B$-meson correlation functions defined with interpolating currents for the $p$-wave axial-vector meson are factorized into short-distance coefficients and the distribution amplitudes (DAs) of the $B$ meson, among which the hard coefficients for A0-type currents and $\\mu$ dependent jet functions entering correlation functions $\\Pi_{\\mu,\\|}^{(T+\\tilde{T})}$, $\\Pi_{\\delta\\mu,\\perp}^{(V-A)}$ and $\\Pi_{\\delta\\mu,\\perp}^{(T+\\tilde{T})}$ are identical to the corresponding ones of $B \\to V$ in SCET. In addition, $\\Pi_{\\mu,\\|}^{(V-A)}$ and $\\Pi_{\\mu,\\|}^{(T+\\tilde{T})}$ coincide with the results of $B\\to \\pi,K$ under the limit $m_q \\to 0$ up to one-loop accuracy. Then the subleading power corrections to $B \\to A$ form factors are computed with the higher-twist $B$ meson LCDAs at tree level up to the twist-six accuracy. Furthermore, we predict the $q^2$ dependence of $B \\to A$ form factors via the Bourrely-Caprini-Lellouch (BCL) $z$-series expanding parameterization to compute several physical observables including branching ratios of semileptonic $B\\to A \\ell \\bar{\\nu}_{\\ell} $ and $B\\to A \\nu_{\\ell} \\bar{\\nu}_{\\ell} $ processes, transverse asymmetries, forward-backward asymmetries and lepton flavor universality observables employing the given mixing angles $\\theta_K=-34^\\circ$, $\\theta_{1_{P_1}}=28^\\circ$, $\\theta_{3_{P_1}}=23^\\circ$. We also compare our theory calculations with the results from other methods.",
    "authors": [
      "Fang-Zhou Di",
      "Yu-Hao Liu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.07510",
    "title": "Towards a test of the Born rule in high-energy collisions",
    "abstract": "We consider how the Born rule, a fundamental principle of quantum mechanics, can be tested for particles created on the shortest timescales ($\\sim10^{-25}\\,\\mathrm{s}$) currently accessible at high-energy colliders. We focus on targeted tests of the Born rule for spin or polarisation probabilities, which offer a particularly clean experimental signal, and which can be described by a simple hidden-variables model of two-state systems proposed by Bell. These probabilities test a remarkable feature of the quantum formalism, whereby expectation values for incompatible experiments are linearly related. Born-rule violations can be parameterised by nonlinear expectation values for quantum measurements of spin or polarisation, along with anomalies in ensemble averages, which may then be constrained by experiment. Notable experiments considered here include the recent detection of single photons from top-quark decay, and the indirect measurement of tau-lepton polarisation. Repurposing these experiments as tests of the Born rule, however, presents several challenges, which are discussed in this paper.",
    "authors": [
      "Antony Valentini",
      "Mira Varma"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.02639",
    "title": "Neutrino mass model at a three-loop level from a non-holomorphic modular $A_4$ symmetry",
    "abstract": "We study a three-loop induced neutrino mass scenario from a non-holomorphic modular $A_4$ flavor symmetry and reach the minimum scenario leading predictions of the lepton masses, mixing angles, and Dirac and Majorana phases, which are shown through the chi square analyses. In addition, we discuss the lepton flavor violations, muon anomalous magnetic moment, lepton universality, and relic density of the dark matter candidate. And, we find that we need to extend our model if we satisfy the observed relic density of dark matter within the limit of perturbation where it can be done by adding one singlet scalar boson without changing predictions in neutrino sector.",
    "authors": [
      "Takaaki Nomura",
      "Hiroshi Okada"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.20071",
    "title": "WIMP/FIMP dark matter and primordial black holes with memory burden effect",
    "abstract": "The lifetime of primordial black holes (PBHs), which formed in the early universe, can be extended by the memory burden effect. Light PBHs may exist today and be candidates for dark matter (DM). We assume that DM is made of thermally produced weakly interacting massive particles (WIMPs), WIMPs produced via the Hawking radiation of PBHs, and PBHs that survived Hawking evaporation via the memory burden effect. Feebly interacting massive particles (FIMPs) are alternatives to WIMPs. This paper shows that a small memory burden is preferable if the thermal production of WIMPs or FIMPs is much larger than the effect of PBH particle production via Hawking radiation. In addition, we show that the lower limit of the DM mass, called the warm DM (WDM) constraint, decreases with the memory burden effect of PBHs. Results suggest that the WDM constraint is more effective for FIMPs than for WIMPs.",
    "authors": [
      "Teruyuki Kitabayashi",
      "Amane Takeshita"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.03157",
    "title": "Relativistic Axion with Nonrelativistic Momenta: A Robust Bound on Minimal ALP Dark Matter",
    "abstract": "The axion-like particle (ALP), a pseudo Nambu-Goldstone boson that couples to two photons, has been studied extensively in recent years as a dark matter candidate. For initial field configurations in a minimal ALP model explaining the observed dark matter abundance, we need the potential height to exceed the ALP energy density at redshift $z\\approx 5.5\\times 10^{6}$ leading to: $$ f_{\\phi}\\gtrsim4\\times10^{13}\\,{GeV}\\,\\biggl(\\frac{10^{-18}\\,eV}{m_{\\phi}}\\biggr), $$ where $m_{\\phi}$ and $f_{\\phi}$ denote the ALP mass and decay constant, respectively. This bound is known for the ALP dark matter dominated by the homogeneous zero-momentum mode, under the requirement that coherent oscillations begin early enough to satisfy the late-forming dark matter constraint. One loop hole to evade this limit may be to introduce a large amount of the non-relativistic modes of the ALP with non-vanishing momenta. Here we show that the same limit remains valid even if nonzero-momentum modes dominate. Interestingly, when $nonrelativistic$ gradient modes prevail, the ALP behaves $relativistic$ radiation rather than matter, if it violates the limit. Moreover, if the typical momentum is sufficiently small, Baumkuchen-like domain walls form, which play an important role in understanding the transition.",
    "authors": [
      "Yuma Narita",
      "Wen Yin"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.19828",
    "title": "Bounds reach of a future circular collider on the parameters of a minimal Baryon-Lepton symmetric model",
    "abstract": "This paper investigates the physics potential of the proton-proton Future Circular Collider (FCC-hh) in the search for a new heavy gauge boson, Z', within the framework of the minimal Baryon-Lepton (B-L) symmetric model. We examine the exclusion limits on the mass of the Z' boson for various sets of coupling constants, utilizing leptonic decays, specifically into charged lepton pairs (electron and muon). Using the DARKCAST framework, we compare the parameter constraints derived from previous experiments with the expected reach of the FCC-hh, providing insights into the collider sensitivity and potential to probe new physics beyond the Standard Model.",
    "authors": [
      "Marlon P. Brade",
      "Jeremiah D. Juevesano",
      "Dennis C. Arogancia",
      "Jan Mickelle V. Maratas"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.13043",
    "title": "Born-Oppenheimer EFT: a unified description of ordinary and exotic quarkonia",
    "abstract": "We show how the Born-Oppenheimer effective field theory (BOEFT) provides a unified description of ordinary and exotic quarkonia grounded on the non-relativistic expansions of QCD and supplemented with lattice QCD inputs. We apply BOEFT to tetraquarks, pentaquarks, quarkonium hybrids and to assess threshold effects in the quarkonium spectrum.",
    "authors": [
      "Antonio Vairo"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.14524",
    "title": "Linear seesaw leptogenesis before/after electroweak symmetry breaking",
    "abstract": "The linear seesaw (LSS) model provides a natural framework for generating small neutrino masses at low energy scales, thereby offering promising testability prospects. However, in generic LSS models, the exact mass degeneracy (before the electroweak symmetry breaking) between the two sterile neutrinos that form a Dirac pair precludes the generation of CP asymmetries from their interplay, posing a significant challenge to explaining the observed baryon (or lepton) asymmetry of the Universe via the leptogenesis mechanism. In this work, we explore two well-motivated approaches to generate a suitable mass splitting for the two sterile neutrinos that form a Dirac pair, and consequently naturally realize a resonantly enhanced generation of baryon (and lepton) asymmetry. First, we demonstrate that the renormalization group evolution effects can naturally induce the desired mass splitting for the sterile neutrinos, resulting in a successful generation of the observed baryon asymmetry of the Universe. Second, motivated by the recent result from the EMPRESS collaboration that indicates the possible existence of a large lepton asymmetry of the Universe, we explore the possibility that a large lepton asymmetry might naturally follow from the electroweak symmetry breaking which automatically induces the desired mass splitting for the sterile neutrinos.",
    "authors": [
      "Yan Shao",
      "Zhen-hua Zhao"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04005",
    "title": "Validating a Machine Learning Approach to Identify Quenched Jets in Heavy-Ion Collisions",
    "abstract": "Jet quenching is a phenomenon in heavy-ion collisions arising from jet interactions with the quark-gluon plasma (QGP). Its study is complicated by the interplay of multiple physics processes that affect jet observables. In addition, detector effects may influence the results and must be accounted for when identifying quenched jets. We employ a Long Short-Term Memory (LSTM) neural network trained on jet substructure, incorporating parton shower history, to predict jet-by-jet quenching levels. Using photon-jet samples from the \\textsc{Jewel} event generator, we show that the LSTM predictions strongly correlate with true jet energy loss. This validates that the model effectively learns the features of jet-QGP interaction. We simulate detector effects using \\textsc{Delphes} simulation framework and demonstrate that the method identifies quenching effects in a realistic environment. We test the approach with photon-jet momentum imbalance, jet fragmentation function, and jet shape, which were not included in the training, confirming its ability to distinguish true quenching features.",
    "authors": [
      "Yilun Wu",
      "Yi Chen",
      "Julia Velkovska"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13997",
    "title": "Light-Front Transverse Nucleon Charge and Magnetisation Densities",
    "abstract": "Nucleon elastic electromagnetic form factors obtained using both the three-body and quark + fully-interacting-diquark pictures of nucleon structure are employed to calculate an array of light-front transverse densities for the proton and neutron and their dressed valence-quark constituents, viz. flavour separations of the proton and neutron results. These two complementary descriptions of nucleon structure deliver mutually compatible predictions, which match expectations based on modern parametrisations of available data, where such are available. Amongst other things, it is found that transverse-plane valence $u$- and $d$-quark Dirac radii are practically indistinguishable; but regarding kindred Pauli radii, the $d$ quark value is roughly 10% greater than that of the $u$-quark. Moreover, magnetically, the valence $d$ quark is far more active than the valence $u$ quark, probably because it has much greater orbital angular momentum. Both pictures of nucleon structure agree in predicting that, in a polarised nucleon, the transverse-plane charge densities are no longer rotationally invariant. Instead, for a $+\\hat x$ polarised nucleon, positive charge is displaced in the $+\\hat y$ direction, with the opposite effect for negative charge.",
    "authors": [
      "Z.-N. Xu",
      "Z.-Q. Yao",
      "P. Cheng",
      "C. D. Roberts",
      "J. Rodriguez-Quintero",
      "J. Segovia"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.15391",
    "title": "Neutrinoless Double Beta Decay in Light of JUNO First Data",
    "abstract": "The first results from the JUNO reactor neutrino oscillation experiment improve our knowledge of neutrino masses and mixing parameters, especially the solar angle $\\theta_s \\equiv \\theta_{12}$ and the solar mass squared difference $\\Delta m^2_s \\equiv \\Delta m^2_{21}$. We discuss the implications of these results on neutrinoless double beta decay by itself and in combination with the global fit of neutrino oscillation experiments, the JUNO first data, and cosmological constraints on the neutrino mass sum. For the effective mass $\\langle m_{ee} \\rangle$, the uncertainties in its lower limits for both mass orderings and upper limits for the normal ordering are largely reduced. Since the cosmological CMB and DESI BAO data put a stringent constraint on the neutrino mass scale, we also show how the probability distribution of both the real and imaginary parts of the effective mass $\\langle m_{ee} \\rangle$ on the complex plane is affected. Especially, the funnel region with $|\\langle m_{ee} \\rangle| \\lesssim 1$\\,meV receives larger chance to happen. Correspondingly, the chance of determining the two Majorana CP phases simultaneously in this region also increases with reduced uncertainty.",
    "authors": [
      "Shao-Feng Ge",
      "Chui-Fan Kong",
      "Manfred Lindner",
      "João Paulo Pinheiro"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00172",
    "title": "Enhancing the sensitivity to neutrino oscillation parameters using synergy between T2K, NO$ν$A and JUNO",
    "abstract": "We study the impact of combining the present NO$\\nu$A and T2K data with simulated data from the JUNO experiment on the determination of the leptonic CP phase and the neutrino mass hierarchy. The current NO$\\nu$A data exhibit a hierarchy--$\\delta_{\\rm CP}$ degeneracy, admitting both normal hierarchy (NH) with $\\delta_{\\rm CP} \\in [0,180^\\circ]$, and inverted hierarchy (IH) with $\\delta_{\\rm CP} \\in [180^\\circ,360^\\circ]$ solutions at comparable significance, while T2K prefers $\\delta_{\\rm CP}\\simeq 270^\\circ$ for both hierarchies, leading to a $2\\sigma$ tension between the two experiments for normal hierarchy. Using detailed GLoBES simulations, we show that future JUNO data with excellent hierarchy sensitivity, can lift the hierarchy--$\\delta_{\\rm CP}$ degeneracy in NO$\\nu$A and strengthen the hierarchy reach of T2K in spite of having no $\\delta_{\\rm CP}$ sensitivity. Allowing the hierarchy to be a free parameter in the fit, if the true ordering is IH, JUNO aligns the NO$\\nu$A and T2K allowed regions and resolves their present tension; if NH is true, the tension continues to persist. We also show that JUNO's precise measurement of $|\\Delta_{31}|$ leads to improved constraints on $\\sin^2\\theta_{23}$ and $\\delta_{\\rm CP}$ for normal mass hierarchy in NO$\\nu$A even though JUNO itself is insensitive to these parameters. Finally, updated solar parameter measurements from JUNO's first data release further enhance the combined precision. Our results demonstrate that JUNO plays a crucial synergistic role in the global neutrino oscillation programme, enabling a more robust determination of the mass ordering and improving the sensitivity to the CP phase when combined with long-baseline data.",
    "authors": [
      "Srubabati Goswami",
      "Aman Gupta",
      "Ushak Rahaman",
      "Sushant K. Raut"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.14435",
    "title": "Two-Loop Master Integrals for Mixed QCD-EW Corrections to $gg \\to H$ Through $\\mathcal{O}(ε^2)$",
    "abstract": "We consider mixed strong-electroweak corrections to Higgs production via gluon fusion, in which the Higgs boson couples to the top quark. Using the method of differential equations, we compute all of the master integrals that contribute to this process at two loops through $\\mathcal{O}(\\epsilon^2)$ in the dimensional regularization parameter $\\epsilon = (d-4)/2$, keeping full analytic dependence on the top quark, Higgs, W, and Z boson masses. We present the results for these master integrals in terms of iterated integrals whose kernels depend on elliptic curves.",
    "authors": [
      "Robin Marzucca",
      "Andrew J. McLeod",
      "Christoph Nega"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.19226",
    "title": "Light dilaton near critical points in top-down holography",
    "abstract": "We study a class of UV-complete, strongly coupled, confining three-dimensional field theories, that exhibit a novel stabilisation mechanism for the mass of the lightest scalar composite state, relying on the existence of a critical point. The theories admit a holographic dual description in terms of regular backgrounds in eleven-dimensional supergravity. Their phase diagram includes a line of first-order phase transitions ending at the critical point, where the transition becomes of second order. We calculate the mass spectrum of bound states of the field theory, by considering fluctuations around the background solutions, and find that, near the critical point, a hierarchy of scales develops, such that one state becomes parametrically light. We identify this state as the dilaton, the pseudo-Nambu-Goldstone boson associated with the spontaneous breaking of approximate scale invariance. This stabilisation mechanism might be exploited to address hierarchy problems in particle and astroparticle physics.",
    "authors": [
      "Daniel Elander",
      "Antón F. Faedo",
      "Maurizio Piai",
      "Ronnie Rodgers",
      "Javier G. Subils"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.11288",
    "title": "Generalized Parton Distributions from Lattice QCD with Asymmetric Momentum Transfer: Tensor Case",
    "abstract": "The calculation of generalized parton distributions (GPDs) in lattice QCD was traditionally done by calculating matrix elements in the symmetric frame. Recent advancements have significantly reduced computational costs by calculating these matrix elements in the asymmetric frame, allowing us to choose the momentum transfer to be in either the initial or final states only. The theoretical methodology requires a new parametrization of the matrix element to obtain Lorentz-invariant amplitudes, which are then related to the GPDs. The formulation and implementation of this approach have already been established for the unpolarized and helicity GPDs. Building upon this idea, we extend this formulation to the four leading-twist quark transversity GPDs ($H_T$, $E_T$, $\\widetilde{H}_T$, $\\widetilde{E}_T$). We also present numerical results for zero skewness using an $N_f=2+1+1$ ensemble of twisted mass fermions with a clover improvement. The light quark masses employed in these calculations correspond to a pion mass of about 260 MeV. Furthermore, we include a comparison between the symmetric and asymmetric frame calculations to demonstrate frame independence of the Lorentz-invariant amplitudes. Analysis of the matrix elements in the asymmetric frame is performed at several values of the momentum transfer squared, $-t$, ranging from 0.17 GeV$^2$ to 2.29 GeV$^2$.",
    "authors": [
      "Shohini Bhattacharya",
      "Krzysztof Cichy",
      "Martha Constantinou",
      "Andreas Metz",
      "Joshua Miller",
      "Peter Petreczky",
      "Fernanda Steffens"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.06841",
    "title": "Cosmic baryon census with fast radio bursts and gravitational waves",
    "abstract": "The cosmic baryon density fraction ($\\Omega_{\\rm b}$) is intrinsically correlated with the Hubble constant ($H_0$) through the critical density of the Universe. In the context of the decade-long $H_0$ tension, the significant discrepancy between early- and late-Universe measurements of $H_0$ implies that fixing its value or imposing an external prior could bias the baryon census. To address this concern, we construct a late-Universe probe framework that unifies fast radio bursts (FRBs) and gravitational-wave (GW) standard sirens, which can respectively resolve the missing baryon problem and the $H_0$ tension through their dispersion measures and absolute luminosity distances. By combining $104$ localized FRBs with $47$ GW events, we obtain an $H_0$-free measurement of $\\Omega_{\\rm b}=0.0488\\pm0.0064$ ($1\\sigma$), in concordance with early-Universe observations of CMB + BBN. Although the current precision ($\\sim 13\\%$) is limited by sample size, the growing detections of both FRBs and GWs will make their synergy a powerful probe of low-redshift cosmology.",
    "authors": [
      "Ji-Guo Zhang",
      "Ji-Yu Song",
      "Ze-Wei Zhao",
      "Wan-Peng Sun",
      "Jing-Fei Zhang",
      "Xin Zhang"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20315",
    "title": "Understanding the correlation between elliptic and triangular flow",
    "abstract": "The relative correlation between the magnitudes of elliptic flow ($v_2$) and triangular flow ($v_3$) has been accurately measured in nucleus-nucleus collisions at the LHC collider. As a function of the centrality of the collision, it changes sign and varies non-monotonically. We show that this is naturally explained by two combined effects. The first effect is a skewness in initial-state fluctuations, which is quantified by the correlation between the geometry-driven elliptic deformation in the reaction plane and the fluctuation-driven triangularity $\\varepsilon_3$. We introduce an intensive measure of this skewness, which is generically of order unity and depends weakly on the system size and centrality. We evaluate its magnitude using Monte Carlo simulations of the initial state, which show that it is sensitive to the nucleon width. The second effect is the fluctuation of impact parameter relative to centrality classifiers used by experiment. The ATLAS collaboration uses two different centrality classifiers, the multiplicity $N_{ch}$ and the transverse energy $E_T$. We fit both sets of results for Pb+Pb collisions up to $\\approx 40\\%$ centrality with a single parameter, the intensive mixed skewness. Its value inferred from experiment agrees with theoretical expectations.",
    "authors": [
      "Mubarak Alqahtani",
      "Jean-Yves Ollitrault"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.21195",
    "title": "Radiation of \"breathing\" vortex electron packets in magnetic field",
    "abstract": "When a vortex electron with an orbital angular momentum (OAM) enters a magnetic field, its quantum state is described with a nonstationary Laguerre-Gaussian (NSLG) state rather than with a stationary Landau state. A key feature of these NSLG states is oscillations of the electron wave packet's root-mean-square (r.m.s.) radius, similar to betatron oscillations. Classically, such an oscillating charge distribution is expected to emit photons. This raises a critical question: does this radiation carry away OAM, leading to a loss of the electron's vorticity? To investigate this, we solve Maxwell's equations using the charge and current densities derived from an electron in the NSLG state. We calculate the total radiated power and the angular momentum of the emitted field, quantifying the rate at which a vortex electron loses its energy and OAM while propagating in a longitudinal magnetic field. We find both the radiated power and the angular momentum losses to be negligible indicating that linear accelerators (linacs) appear to be a prominent tool for maintaining vorticity of relativistic vortex electrons and other charged particles, at least in the quasi-classical approximation.",
    "authors": [
      "G. V. Zmaga",
      "G. K. Sizykh",
      "D. V. Grosman",
      "Qi Meng",
      "Liping Zou",
      "Pengming Zhang",
      "D. V. Karlovets"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.19210",
    "title": "SL(2N,C) Hyperunification: Dynamical Tetrads, Induced Gravity, and Composite Families",
    "abstract": "A four-dimensional gauge--gravity unification based on the local $SL(2N,\\mathbb{C})$ symmetry is developed in a universal Yang--Mills-type setting. The accompanying tetrads are promoted to dynamical fields, and their invertibility condition is interpreted as a nonlinear sigma-model-type length constraint. This triggers tetrad condensation and spontaneously breaks $SL(2N,\\mathbb{C})$ down to $SL(2,\\mathbb{C})\\times SU(N)$, effectively filtering out unobserved non-compact directions. A special ghost-free curvature-squared Lagrangian provides a consistent quadratic sector for all gauge fields involved, while an Einstein--Cartan linear-curvature term is shown to arise radiatively from fermion loops. The matter sector points to a deeper elementarity of $SL(2N,\\mathbb{C})$ spinors, which can be identified with preon constituents whose bound states form the observed quarks and leptons. Anomaly matching between preons and composites singles out $SL(16,\\mathbb{C})$, accommodating precisely three composite quark--lepton families. The theory thus links non-compact unification, induced gravity, and fermion family structure within a single framework.",
    "authors": [
      "J. L. Chkareuli"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03142",
    "title": "Topological Einstein gravity as Kodaira-Spencer gravity",
    "abstract": "As a contribution towards quantizing three-dimensional gravity, we show at the classical level that Euclidean three-dimensional Einstein gravity with a negative cosmological constant is uplifted to the $SU(2)$-invariant sector of Kodaira-Spencer gravity on a Calabi-Yau three-fold. Kodaira-Spencer gravity appears in the target space description of the B-model topological string theory and describes deformations of a complex structure. We prove that given a reference solution of Einstein gravity in the first-order formulation, a second off-shell configuration uplifts to a unique complex structure deformation in six dimensions. If the configuration satisfies Einstein's equations, the complex structure deformation is integrable, i.e. a solution of Kodaira-Spencer gravity. We demonstrate the uplift explicitly for Bañados solutions. Our construction embeds three-dimensional gravity into topological string theory and AdS$_3$/CFT$_2$ duality into twisted holography.",
    "authors": [
      "Johanna Erdmenger",
      "Jonathan Karl",
      "Jani Kastikainen",
      "René Meyer",
      "Henri Scheppach"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03146",
    "title": "Homotopy transfer for massive Kaluza-Klein modes",
    "abstract": "We develop techniques to treat massive Kaluza-Klein modes to arbitrary order in perturbation theory. The Higgs mechanism that renders the higher Kaluza-Klein modes massive is displayed. To this end we give an algorithm in perturbation theory that yields new fields with the following characteristics: they are gauge invariant under all higher-mode gauge transformations, which are broken, but they transform covariantly under the zero-mode gauge transformations, which are unbroken. We employ the formulation of field theory in terms of $L_{\\infty}$ algebras together with their homotopy transfer, which here maps the gauge redundant fields of gravity to gauge invariant fields. We illustrate these results, as a proof of concept, for Kaluza-Klein theory on a torus. In an accompanying paper these results will be applied to a large class of generalized Scherk-Schwarz backgrounds in exceptional field theory.",
    "authors": [
      "Camille Eloy",
      "Olaf Hohm",
      "Camilla Lavino",
      "Henning Samtleben",
      "Yehudi Simon"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03161",
    "title": "A New Type of Saddle in Euclidean IKKT Matrix Model and Its Effective Geometry",
    "abstract": "We study the equation of motion of the Euclidean IKKT matrix model, and realize a new type of classical saddle that only exists in $N\\rightarrow\\infty$ limit. Under the assumption that the matrices are the generators of $\\mathfrak{so}(n,m)$, we identify a unique solution, that is, $\\mathfrak{so}(1,3)$. Even though it has $6$ generators and thus $6$ non-zero matrices, they are not independent due to the $2$ Casimir constraints in $\\mathfrak{so}(1,3)$. Exploiting the Lie-algebraic structure and the Casimir constraints, we derive the effective metric that a test probe propagates on. The resulting effective metric exhibits an $SO(3)$ symmetry, matching the spatial symmetry of our universe.",
    "authors": [
      "Henry Liao",
      "Reishi Maeta"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03163",
    "title": "Matrix Quantum Mechanics and Entanglement Entropy: A Review",
    "abstract": "We review aspects of entanglement entropy in the quantum mechanics of $N\\times N$ matrices, i.e. matrix quantum mechanics (MQM), at large $N$. In doing so we review standard models of MQM and their relation to string theory, D-brane physics, and emergent non-commutative geometries. We overview, in generality, definitions of subsystems and entanglement entropies in theories with gauge redundancy and discuss the additional structure required for definining subsystems in MQMs possessing a $U(N)$ gauge redundancy. In connecting these subsystems to non-commutative geometry, we review several works on `target space entanglement,' and entanglement in non-commutative field theories, highlighting the conditions in which target space entanglement entropy displays an `area law' at large $N$. We summarize several example calculations of entanglement entropy in non-commutative geometries and MQMs. We review recent work in connecting the area law entanglement of MQM to the Ryu-Takayanagi formula, highlighting the conditions in which $U(N)$ invariance implies a minimal area formula for the entanglement entropy at large $N$. Finally, we make comments on open questions and research directions.",
    "authors": [
      "Jackson R. Fliss",
      "Alexander Frenkel"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03167",
    "title": "Energy Reflection and Transmission of Interfaces in $T\\bar{T}$-deformed CFT",
    "abstract": "Conformal interfaces gluing a pair of two-dimensional conformal field theories enjoy a large degree of universality in terms of the coefficients of reflection and transmission of energy, that describe the scattering of conformal matter at the interface. In this article, we study these coefficients beyond conformality, by gluing a pair of $T\\bar T$-deformed 2D CFTs across an interface, which requires the condition $c_L \\mu_L = c_R \\mu_R $ to be obeyed. We show that, at least when the interface admits a holographic description, the $T\\bar T$ deformation of the CFTs can be extended to the interface. We propose a generalization of the linear matching condition in the universal sector of the undeformed ICFT to a non-linear one, which is captured by a universal antisymmetric \\emph{transmission function} of the incoming fluxes. We employ the flow equations of the $T\\bar T$-deformed CFTs to compute this function in two special classes of states, namely the non-equilibrium steady state (NESS) and scattering state. We show that the results can also be reproduced using holographic techniques in the bulk dual of these states.",
    "authors": [
      "Avik Banerjee",
      "Giuseppe Policastro"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03170",
    "title": "(Anti)-de Sitter with leaky boundaries and corners",
    "abstract": "We construct charges for four-dimensional spacetimes with a non-vanishing cosmological constant, including charges that are not conserved because of a leaky boundary and charges associated with corner terms in the symplectic current. The construction leads to manifestly finite charges for any choice of boundary conditions, and reveals new charges in partial Bondi gauge for an enlarged class of field configurations which are not fully on-shell, including a Weyl charge for conformal boundary conditions. In addition, we generalize the variational principle for AdS$_4$ gravity with Dirichlet boundary conditions to a wedge of spacetime where the conformal boundary includes a corner. The boundary data is completely general, with no conditions restricting time dependence or the determinant of the metric. The Ward identities associated with boundary diffeomorphisms are shown to reproduce the evolution equations for the mass and angular momentum of fully on-shell field configurations.",
    "authors": [
      "Robert McNees",
      "Céline Zwikel"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03172",
    "title": "On the Virasoro Crossing Kernels at Rational Central Charge",
    "abstract": "We report novel analytic results for the Virasoro modular and fusion kernels relevant to 2d conformal field theories (CFTs), 3d topological field theories (TQFTs), and the representation theory of certain quantum groups. For all rational values of the parameter $b^2\\in\\mathbb{Q}^{\\times}$ -- corresponding in 2d CFT to all rational central charge values in the domain $(-\\infty,1]\\cup[25,\\infty)$ -- we establish two main results. First, in the domain $c\\in\\mathbb{Q}_{[25,\\infty)}$ we show that the modular and fusion kernels derived by Teschner and Teschner-Vartanov respectively can be expressed as a linear combination of two functions, which (i) are themselves admissible crossing kernels, (ii) have square-root branch point singularities in the Liouville momenta, (iii) are not reflection-symmetric in the Liouville momenta. These features illustrate that the space of solutions to the basic shift relations determining these kernels is broader than previously assumed. Second, in the domain $c\\in\\mathbb{Q}_{(-\\infty,1]}$ we derive for the first time the physical modular and fusion kernels for generic values of the Liouville momenta. These can again be written as a linear combination of two other admissible kernels but overall, and unlike the Teschner and Teschner-Vartanov solutions for $c\\geq 25$, they possess square-root branch point singularities. As a corollary, we demonstrate that timelike Liouville theory at $c\\in\\mathbb{Q}_{(-\\infty,1]}$ is crossing symmetric and modular covariant. Surprisingly, the crossing kernels at any $b^2\\in\\mathbb{Q}^{\\times}$ behave as if they were semiclassical and one-loop exact, and we discuss the interpretation of this fact in the context of the 2d conformal bootstrap and the 3d TQFT that captures pure 3d gravity with negative cosmological constant.",
    "authors": [
      "Julien Roussillon",
      "Ioannis Tsiares"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03217",
    "title": "Generalized Yang-Mills theory: Interpolating between SDYM and YM",
    "abstract": "We construct a generalized Yang-Mills (YM) theory with two real couplings, interpolating continuously between the Self-Dual Yang-Mills (SDYM) limit (also called Chalmers-Siegel theory) and physical Yang-Mills theory. The kinetic coupling $\\epsilon$ controls local fluctuations and anti-instanton weight, while the topological coupling $g$ controls the instanton weight. Both couplings are asymptotically free. We derive an exact all-order relation between the beta functions of the two couplings, revealing a Renormalization Group invariant, a new dimensionless expansion parameter $\\Lambda_\\epsilon / \\Lambda_g$ into the study of YM theory. In the SDYM limit, the vacuum is populated by a finite density of topological defects, yet local correlators decay algebraically, consistent with a non-unitary conformal field theory. We confirm this mechanism via compactification on arbitrary size $\\mathbb{R}^3 \\times S^1$, where the vacuum maps to a non-interacting ideal gas of monopole-instantons. As the kinetic coupling is turned on, a mass gap and confinement scale emerge.",
    "authors": [
      "Tolga Domurcukgül",
      "Hao Geng",
      "Mendel Nguyen",
      "Mithat Ünsal"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03473",
    "title": "AMSB in $Sp(N_c)$ Gauge Theories",
    "abstract": "We present a careful study of the chiral symmetry breaking minima and other potential minima in supersymmetric symplectic QCD ($Sp(N_c)$ with $N_f$ flavors) perturbed by Anomaly Mediated Supersymmetry Breaking (AMSB). Although the case of $N_f = N_c +1$ requires particular care due to the inherently strongly coupled nature of the quantum modified moduli space, we are able to show that all $Sp(N_c)$ theories to which AMSB can be applied ($N_f < 3(N_c + 1)$) possess stable chiral symmetry breaking minima, which are plausibly continuously connected to the vacua of QCD-like $Sp(N_c)$ theories for large SUSY breaking, and are protected from runaways to incalculable minima.",
    "authors": [
      "Digvijay Roy Varier",
      "Zijian Gu",
      "Bea Noether",
      "Hitoshi Murayama"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03677",
    "title": "From AdS correlators to Carrollian amplitudes with the scattering equation",
    "abstract": "The scattering equations relate massless scattering kinematics to marked points on a Riemann sphere, and underpin remarkable formulae for the full tree-level S-matrices of many interesting QFTs, including cubic biadjoint scalars, Yang-Mills theory and general relativity. The scattering equations arise from worldsheet correlators of ambitwistor string theories, which has enabled their generalisation to anti-de Sitter (AdS) space in certain cases. In this paper, we use the scattering equations and ambitwistor strings to prove the correspondence between an appropriate flat limit of boundary correlators in AdS and Carrollian scattering amplitudes -- massless amplitudes written in position space on the null conformal boundary -- for any number of external states and spacetime dimensions in tree-level, cubic scalar theories. We first derive the Carrollian version of the scattering equations in Minkowski space and their associated Carrollian amplitude formulae, by direct Fourier transform from momentum space and from ambitwistor strings with a Carrollian basis of vertex operators. We then take the flat limit of known formulae for all tree-level boundary correlators of cubic scalar theories in AdS, recovering the Carrollian amplitudes in flat space. In the special case of AdS$_3$, we also make some comments on the flat space limit of spinning boundary correlators.",
    "authors": [
      "Tim Adamo",
      "Iustin Surubaru",
      "Bin Zhu"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03944",
    "title": "Functorial properties of Schwinger-DeWitt expansion and Mellin-Barnes representation",
    "abstract": "We consider integral kernels for functions $f(\\hat F)$ of a minimal second-order differential operator $\\hat F(\\nabla)$ on a curved spacetime. We show that they can be expanded in a functional series, analogous to the DeWitt expansion for the heat kernel, by integrating the latter term-by-term. This procedure leads to a separation of two types of data: all information about the bundle geometry and the operator $\\hat F(\\nabla)$ is still contained in the standard HaMiDeW coefficients $\\hat a_k[F | x,x']$ (we call this property ``off-diagonal functoriality''), while information about the function $f$ is encoded in some new scalar functions $\\mathbb{B}_\\alpha[f | \\sigma]$ and $\\mathbb{W}_\\alpha[f | \\sigma, m^2]$, which we call basis and complete massive kernels, respectively. These objects are calculated for operator functions of the form $\\exp(-\\tau\\hat F^\\nu)/(\\hat F^\\mu + \\lambda)$ as multiple Mellin--Barnes integrals. The article also discusses subtle issues such as the validity of the term-by-term integration, the regularization of IR divergent integrals, and the physical interpretation of the resulting expansions.",
    "authors": [
      "Andrei O. Barvinsky",
      "Alexey E. Kalugin",
      "Władysław Wachowski"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04002",
    "title": "Dynamical Love Numbers for Black Holes and Beyond from Shell Effective Field Theory",
    "abstract": "We construct a novel effective field theory for a compact body coupled to gravity, whose key feature is that the dynamics of gravitational perturbations is explicitly determined by known solutions in black hole perturbation theory in four dimensions. In this way, the physics of gravitational perturbations in curved space are already encoded in the effective field theory, thus bypassing the need for the higher-order calculations that constitute a major hurdle in standard approaches. Concretely, we model the compact body as a spherical shell, whose finite size regulates short-distance divergences in four dimensions and whose tidal responses are described by higher-dimensional operators. As an application, we consider scalar perturbations and derive new results for scalar Love numbers through ${\\cal O} (G^9)$ for Schwarzschild black holes and for generic compact bodies. Finally, our analysis reveals an intriguing structure of the scalar black-hole Love numbers in terms of the Riemann zeta function, which we conjecture to hold to all orders.",
    "authors": [
      "Dimitrios Kosmopoulos",
      "Davide Perrone",
      "Mikhail Solon"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04057",
    "title": "Extremal couplings and gluon scattering in M-theory",
    "abstract": "We consider M-theory on the backgrounds AdS$_4\\times S^7/\\mathbb{Z}_{N_f}$ and AdS$_7\\times S^4/\\mathbb{Z}_2$, which have fixed point locii AdS$_{d+1}\\times S^3$ for $d=3,6$. These theories are holographically dual to certain CFTs in $d=3,6$ with eight supercharges. We compute the bulk cubic couplings between graviton KK modes and gluon KK modes living on the fixed points of these theories, which are generically extremal. We use these couplings to compute the graviton exchange term that appears in the strong coupling expansion of holographic correlators of gluon KK modes $\\langle 22pp\\rangle$ in these theories, and check that it matches the expected flat space limit. We express the answer in terms of a new reduced correlator solution to the superconformal Ward identities, which we derive for all CFTs with eight supercharges in $3\\leq d\\leq6$.",
    "authors": [
      "Shai M. Chester",
      "Rishi Mouland",
      "Jesse van Muiden",
      "Clément Virally"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04067",
    "title": "The Potency of Nilpotence",
    "abstract": "The dynamics of N=1 SUSY gauge theories with matter in adjoint and fundamental representations and the superpotentials given by Arnold's ADE singularities has been extensively studied in the literature. It was also conjectured that supersymmetric models with $W_{A_k}$, $W_{D_{k+2}}$ and $W_{E_7}$ superpotentials possess a dual description. In this paper we revisit the analysis of the moduli space of $A_k$ and $D_{k+2}$ models by considering the duality along nilpotent directions on the moduli space. While our analysis provides additional evidence for the duality conjecture in $W_{A_k}$ models, we show that the duality conjecture fails for the $W_{D_{k+2}}$ models.",
    "authors": [
      "Eric Bryan",
      "Arvind Rajaraman",
      "Yuri Shirman"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.03937",
    "title": "Unveiling the different scaling regimes of the one-dimensional Kardar-Parisi-Zhang--Burgers equation using the functional renormalisation group",
    "abstract": "The Kardar-Parisi-Zhang (KPZ) equation is a celebrated non-linear stochastic equation featuring non-equilibrium scaling. Although in one dimension, its statistical properties are very well understood, a new scaling regime has been reported in recent numerical simulations. This new regime is characterised by a dynamical exponent $z=1$, markedly different from the expected one $z=3/2$ for the KPZ universality class, and it emerges when approaching the inviscid limit. The origin of this scaling has been traced down to the existence of a new fixed point, termed the inviscid Burgers (IB) fixed point, which was uncovered using the functional renormalisation group (FRG). The FRG equations can be solved analytically in the asymptotic regime of vanishing viscosity and large momenta, showing that indeed $z=1$ exactly at the IB fixed point. In this work, we set up an advanced method to numerically solve the full FRG flow equations in a certain approximation, which allows us to determine in a unified way the correlation function over the whole range of momenta, not restricted to some particular regime. We analyse the crossover between the different fixed points, and quantitatively determine the extent of the IB regime.",
    "authors": [
      "Liubov Gosteva",
      "Nicolás Wschebor",
      "Léonie Canet"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03104",
    "title": "Tau--Function Multilinear Hierarchy of the Tomimatsu--Sato Spacetime: A Gravitational Realization of the YTSF Integrable Structure",
    "abstract": "The Tomimatsu--Sato (TS) family generalizes the Kerr black hole to higher multipole order $\\delta$ and has long been regarded as algebraically complicated without any clear integrability. We show instead that stationary axisymmetric vacuum Einstein equations, when the Ernst potential is written as a $\\tau$--ratio $\\mathcal{E}=\\tau_1/\\tau_0$, admit a universal decomposition of the Ernst numerator into a cubic part containing all second derivatives and a quartic \\emph{gradient envelope}. The cubic sector can be written in terms of $Z_3$--symmetric trilinear Hirota operators, revealing a hidden integrable structure. For $\\delta=2$, using the explicit Tomimatsu--Sato polynomials, we verify that this trilinear sector coincides with a Yu--Toda--Sasa--Fukuyama (YTSF) equation-type kernel. Thus the TS geometry forms a gravitational realization of a multilinear $\\tau$--function hierarchy in stationary axisymmetric general relativity.",
    "authors": [
      "Takeshi Fukuyama"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03155",
    "title": "From scalar clouds around evaporating black holes to boson star",
    "abstract": "We study, for the first time, the evolution of a scalar cloud bound to an evaporating black hole. Our simulations of the associated Schrödinger-Poisson system for non-relativistic and spherically symmetric clouds reveal that a scalar cloud may (partially) survive as a self-gravitating boson star if the black hole evaporates adiabatically until its mass becomes less than one half of the cloud's mass. This yields a novel mechanism for boson star formation and shows that, as previously conjectured, bosonic dark matter production by light primordial black holes may result in micro-boson stars with very large occupation numbers, greatly enhancing their potential detectability even for very weakly interacting dark matter particles.",
    "authors": [
      "Daniel Neves",
      "João G. Rosa"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03171",
    "title": "A Mathematical Introduction to Geometric Quantization",
    "abstract": "These notes are based on a series of lectures by Kadri İlker Berktav from May 2024 to November 2024, providing a detailed exposition of geometric quantization formalism and its essential components. They are organized into three parts: background in symplectic geometry, basics of geometric quantization formalism, and an application related to Edward Witten's work in knot theory and topology.",
    "authors": [
      "Kadri İlker Berktav",
      "Burak Oğuz",
      "Ömer Önder",
      "Yunus Emre Sargut",
      "Başar Deniz Sevinç",
      "Deniz Nazif Taştan"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03295",
    "title": "Novel phases in the Fe-Si-O system at terapascal pressures",
    "abstract": "The Fe-Si-O ternary system, central to modeling the interiors of terrestrial planets, remains poorly constrained at Terapascal (TPa) pressures characteristic of super-Earth mantles. Using a combination of crystal-structure prediction and ab initio calculations, we identify three ternary compounds stable near 1 TPa: P3 FeSiO4, P3 Fe4Si5O18, and P-3 FeSi2O6. The first two phases are thermodynamically stable at low temperatures, whereas P-3 FeSi2O6 becomes favored above approximately 2000 K. All three are metallic, paramagnetic, and adopt pseudo-binary arrangements derived from the FeO2 and SiO2 end-member structures. Their crystal structures emerge through substitutions of Fe for Si in Fe2P-type SiO2 or of Si for Fe in Pnma-type FeO2, the stable elemental oxides at ~1 TPa. This structural continuity suggests that Fe preferentially substitutes for Si in the canonical Mg-silicates expected at TPa pressures. Notably, these new pseudo-binaries accommodate Fe in six- and nine-fold coordination, in contrast to the eight-fold cubic coordination found in FeO at similar pressures. The thermodynamic conditions under which these phases form from FeO2 and SiO2 mixtures are clarified through quasi-harmonic free energy calculations. Their prevalence in super-Earth's mantles is found to depend on the abundance of FeO2, which may be generated by the dehydrogenation of FeOOH goethite as in the Earth's deep mantle. The existence of these phases implies a markedly different pattern of Fe incorporation in high-pressure Mg-silicates at TPa pressures, compared with the behavior inferred at the GPa pressures of the Earth's mantle.",
    "authors": [
      "Nan Huang",
      "Renata M. Wentzcovitch",
      "Zepeng Wu",
      "Feng Zheng",
      "Bingxin Wu",
      "Yang Sun",
      "Shunqing Wu"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03314",
    "title": "EFT of Dark Energy with Cosmic Chronometers: Reconstructing Background EFT Functions",
    "abstract": "The effective field theory (EFT) of dark energy provides a model-independent framework for studying cosmology within scalar-tensor theories. In this work, we explore how the time evolution of the cosmological background, inferred from cosmic chronometer measurements of the Hubble parameter, can be used to reconstruct the relevant EFT functions. Our approach enables the direct determination of these EFT functions from observational data without assuming any specific cosmological model. This makes it possible to test the background evolution of a wide range of dark energy models, including the $\\Lambda$CDM model. We further demonstrate how the reconstructed EFT functions can be applied to constrain concrete theories, such as the quintessence model.",
    "authors": [
      "Fumiya Okamatsu",
      "Kazufumi Takahashi"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03529",
    "title": "Multi-probe analysis of strong-field effects in $f(Q)$ gravity",
    "abstract": "Covariant $f(Q)$ gravity is a viable extension of General Relativity, however its strong-field predictions remain largely untested. Using the static, spherically symmetric black-hole solutions of the theory, we confront it with the most stringent probes available: black-hole shadows, Event Horizon Telescope (EHT) measurements, S2-star precession, and strong gravitational lensing. We show that the two admissible solution branches behave very differently: Case~I produces negligible deviations from Schwarzschild solution, whereas Case~II yields significant, potentially observable corrections to the photon sphere and shadow size. From the EHT shadow diameters of M87* and Sgr~A*, we obtain tight bounds, which are further strengthened by strong-lensing coefficients. These results provide the sharpest strong-field constraints on covariant $f(Q)$ gravity to date, and point toward future tests using next-generation horizon-scale imaging and precision Galactic-center astrometry.",
    "authors": [
      "Mohsen Khodadi",
      "Behnam Pourhassan",
      "Emmanuel N. Saridakis"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03645",
    "title": "Gauge Symmetries, Contact Reduction, and Singular Field Theories",
    "abstract": "The reduction of dynamical systems which are invariant under changes of global scale is well-understood, for classical theories of particles, and fields. The excision of the superfluous degree of freedom describing such a scale leads to a dynamically-equivalent theory, which is frictional in nature. In this article, we extend the formalism to physical models, of both particles and fields, described by singular Lagrangians. Our treatment of classical field theory is based on the manifestly covariant Hamilton De-Donder Weyl formalism, in which the Lagrangian density is introduced as a bundle morphism on the pre-multisymplectic velocity phase space $J^1E$. The results obtained are subsequently applied to a number of physically-motivated examples, as well as a discussion presented on the implications of our work for classical General Relativity.",
    "authors": [
      "Callum Bell",
      "David Sloan"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03662",
    "title": "Gravitational Decays of Secluded Scalars and Graviton Dark Radiation",
    "abstract": "We discuss graviton dark radiation produced by the decay of a secluded scalar field that couples to the Standard Model (SM) only through gravity. Such scalar fields are long-lived, and their decay channels generically include gravitons. If such particles existed and dominated the early universe, a sizable branching ratio into gravitons would yield non-negligible dark radiation that significantly alters the subsequent thermal history of the universe. In this work, we focus on the dark glueball as a representative secluded hidden scalar and compare the decay rates into SM particles via a non-minimal coupling to gravity with those into gravitons, paying attention to how the breaking of conformal invariance affects the amount of graviton dark radiation. We find that decays into the SM are dominated by two-body decay channels into Higgs bosons and gluons. In particular, when the Higgs field has a large non-minimal coupling to gravity, the production of graviton dark radiation is naturally suppressed in the metric formalism, and the SM sector is preferentially reheated and energy transfer to other hidden sectors is suppressed. Finally, we present the expected gravitational-wave spectrum resulting from dark glueball domination.",
    "authors": [
      "Kazunori Nakayama",
      "Fuminobu Takahashi",
      "Juntaro Wada"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03668",
    "title": "Spherical accretion onto higher-dimensional Reissner-Nordström Black Hole",
    "abstract": "We obtain relativistic solutions of spherically symmetric accretion by a dynamical analysis of a generalised Hamiltonian for higher-dimensional Reissner-Nordström (RN) Black Hole (BH). We consider two different fluids namely, an isotropic fluid and a non-linear polytropic fluid to analyse the critical points in a higher-dimensional RN BH. The flow dynamics of the fluids are studied in different spacetime dimensions in the framework of Hamiltonian formalism. The isotropic fluid is found to have both transonic and non-transonic flow behaviour, but in the case of polytropic fluid, the flow behaviour is found to exhibit only non-transonic flow, determined by a critical point that is related to the local sound speed. The critical radius is found to change with the spacetime dimensions. Starting from the usual four dimensions it is noted that as the dimension increases the critical radius decreases, attains a minimum at a specific dimension ($D>4$) and thereafter increases again. The mass accretion rate for isotropic fluid is determined using Hamiltonian formalism. The maximum mass accretion rate for RN BH with different equations of state parameters is studied in addition to spacetime dimensions. The flow behaviour and mass accretion rate for a change in BH charge is also studied analytically. It is noted that the maximum mass accretion rate in a higher-dimensional Schwarzschild BH is the lowest, which however, increases with the increase in charge parameter in a higher-dimensional RN BH.",
    "authors": [
      "Bibhash Das",
      "Anirban Chanda",
      "Bikash Chandra Paul"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03725",
    "title": "Probing Azimuthal Alignment in Heavy-Ion Collisions: Clusterization Effects",
    "abstract": "The influence of kinematic constraints and event selection on the emergence of the alignment phenomenon observed in cosmic-ray experiments is studied within the HYDJET++ model. It is demonstrated that the high degree of alignment, previously identified for realistic values of the transverse momentum disbalance of the most energetic particles, is also observed at the level of the most energetic clusters. In high-multiplicity events, the clustering procedure plays a crucial role in resolving individual particle groups on the detection plane, allowing a more accurate characterization of alignment patterns. These results highlight the combined effects of cluster formation and momentum conservation in shaping the observed azimuthal correlations.",
    "authors": [
      "Aleksei Nikolskii",
      "Igor Lokhtin",
      "Alexander Snigirev"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03832",
    "title": "Some perspective of thermodynamical and optical properties of black holes in Maxwell-dilaton-dRGT-like massive gravity",
    "abstract": "Motivated by integrating the dilaton field (as a UV correction) with dRGT-like massive gravity (as an IR correction) into Einstein gravity, we investigate the thermodynamic and optical properties of black holes within this gravitational framework. We begin by reviewing the black hole solutions in Maxwell-dilaton-dRGT-like massive gravity, followed by an analysis of how various parameters influence on the asymptotical behavior of the spacetime and the event horizon of these black holes. In the subsequent section, we examine the conserved and thermodynamic quantities associated with these black holes, paying particular attention to the effects of parameters like $\\beta$, $\\alpha$, and the massive parameters ($\\eta_{1}$ and $\\eta_{2}$) on their local stability by simultaneously evaluating the heat capacity and temperature. We also adopt an alternative method to study phase transitions using geometrothermodynamics. Furthermore, we explore how the parameters of Maxwell-dilaton-dRGT-like massive gravity impacts the optical characteristics and radiative behavior of black holes. In particular, we analyze the effects of the dilaton coupling constant ($\\alpha$), charge ($q$), the massive gravity parameter ($\\eta_1$), and the graviton mass ($m_g$) on the radius of the photon sphere and the resulting black hole shadow. Moreover, the theoretical shadow radius is compared to the observational data from $Sgr A^*$. Additionally, we investigate the energy emission rate of these black holes, revealing that these parameters substantially influence the emission peak.",
    "authors": [
      "B. Eslam Panah. N. Heidari",
      "M. Soleimani"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03876",
    "title": "Generalized Beth--Uhlenbeck entropy formula from the $Φ-$derivable approach",
    "abstract": "We derive a generalized Beth-Uhlenbeck formula for the entropy of a dense fermion system with strong two-particle correlations, including scattering states and bound states. We work within the $\\Phi-$derivable approach to the thermodynamic potential. The formula takes the form of an energy-momentum integral over a statistical distribution function times a unique spectral density. In the near mass-shell limit, the spectral density reduces, contrary to naïve expectations, not to a Lorentzian but rather to a \"squared Lorentzian\" shape. The relation of the Beth-Uhlenbeck formula to the $\\Phi$-derivable approach is exact at the two-loop level for $\\Phi$. The formalism we develop, which extends the Beth-Uhlenbeck approach beyond the low-density limit, includes Mott dissociation of bound states, in accordance with Levinson's theorem, and the self-consistent back reaction of correlations in the fermion propagation. We discuss applications to further systems, such as quark matter and nuclear matter.",
    "authors": [
      "David Blaschke",
      "Gerd Röpke",
      "Gordon Baym"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03919",
    "title": "Primordial Gravitational Wave Birefringence in a de Sitter Background with Chern-Simons Coupling",
    "abstract": "In this work, we investigate tensor perturbations in a de Sitter background within the framework of Chern-Simons modified gravity. We introduce transverse-traceless perturbations and analyze how the Chern-Simons Cotton tensor induces parity-violating modifications to gravitational wave propagation, while the Pontryagin density vanishes at linear order. Using a mode decomposition of the scalar background field, we derive the sub- and super-horizon limits of the wave equations and uncover chiral corrections in the dispersion relations of tensor modes. The resulting birefringence exhibits both amplitude and velocity components, alternating with the phase of the scalar field. Particular solutions sourced by the scalar background show helicity-dependent amplification and a characteristic scaling of the radiated flux that reduces smoothly to the Minkowski limit. The accumulated phase difference between right- and left-handed modes grows quadratically inside the horizon and becomes frozen outside, leaving a permanent parity-violating imprint in the primordial tensor spectrum. Finally, by promoting the Chern-Simons field to a massive dark matter candidate, we demonstrate how its mass-dependent dynamics connect gravitational birefringence to axion-like dark matter phenomenology.",
    "authors": [
      "Abhishek Rout",
      "Brett Altschul"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03959",
    "title": "Primary gravitational waves at high frequencies I: Origin of suppression in the power spectrum",
    "abstract": "[Abridged] The primary gravitational waves (PGWs) are generated in the early universe from the quantum vacuum during inflation. In slow roll inflation, the power spectrum (PS) of PGWs over large scales, which leave the Hubble radius during inflation, is nearly scale-invariant. However, over very small scales, which never leave the Hubble radius, the PS of PGWs behaves as k^2, where k denotes the wave number. We examine the PS of PGWs at such high wave numbers or frequencies when the PGWs are evolved post-inflation, through the epochs of radiation and matter domination. Firstly, we argue that the PS has to be regularized in order to truncate the unphysical k^2 rise at high frequencies. Assuming instantaneous transitions from inflation to the epochs of radiation and matter domination, we carry out the method of adiabatic regularization to arrive at the PS of PGWs over a wide range of frequencies. We show that the process of regularization truncates the k^2 rise and the PS of PGWs oscillates with a fixed amplitude about a vanishing mean value over small scales or, equivalently, at high frequencies. Secondly, we smooth the transition from inflation to radiation domination (to be precise, we smooth the 'effective potential' governing the equation of motion of PGWs) and examine the impact of the smoothing on the regularized PS of PGWs. With the help of a linear smoothing function, we explicitly show that the smoother transition leads to a power-law suppression in the amplitude of the oscillations (about the zero mean value) of the regularized PS of PGWs over small scales that never leave the Hubble radius during inflation. Our analysis indicates that, when transitions are involved, regularization as well as smooth transitions seem essential to ensure that the correlation functions of the PGWs in real space are well behaved. We discuss the directions in which our results need to be extended.",
    "authors": [
      "Alipriyo Hoory",
      "Jerome Martin",
      "Arnab Paul",
      "L. Sriramkumar"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04011",
    "title": "Freeze-out and spectral running of primordial gravitational waves in viscous cosmology",
    "abstract": "We investigate the impact of shear viscosity on the propagation of primordial gravitational waves (pGW) after inflation. Without assuming a specific inflationary scenario we focus on the evolution of pGWs after they re-enter the horizon during a cosmological epoch characterized by the presence of shear viscosity. We show that shear viscosity introduces an additional damping term in the tensor equation, modifying both the transfer function and the energy density power spectrum. For a constant shear viscosity-to-Hubble ratio the transfer function acquires an extra red tilt, while a time-dependent viscosity leads to a running spectral index $\\Omega_\\text{GW}\\sim k^{n_\\text{eff}(k)}$ controlled by the time evolution of the mean free path of the viscous fluid. Our analysis provides a general framework to analytically quantify how shear viscosity can alter the primordial gravitational wave background in standard and non-standard post-inflationary scenarios. As a case study we evaluate the effect of viscosity of the electron-photon-baryon plasma, on both the transfer function and the normalized energy density, finding a $k$-dependent blue tilt due to gravitational wave freeze-out from the viscous phase. This effect corresponds to a fractional difference of order $10^{-3}$.",
    "authors": [
      "Giuseppe Fanizza",
      "Eliseo Pavone",
      "Luigi Tedesco"
    ],
    "primary_category": "astro-ph.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04064",
    "title": "New insights into two-loop running in effective field theories",
    "abstract": "We show that, by viewing a 4D effective-field theory as the infrared (IR) limit of the compactified version in 5D, we can compute two-loop anomalous dimensions without gauge-breaking counter-terms, IR re-arrangement or geometric methods. The ultraviolet (UV) divergences in 4D are read from the IR ones in the matching from 5D to 4D. We use this approach to cross-check recent results in the literature, as well as to compute novel two-loop anomalous dimensions in the SMEFT to dimension eight and certain critical exponents in the charged fixed point of the Abelian Higgs model at large number of flavors.",
    "authors": [
      "Mikael Chala",
      "Javier López Miras"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04070",
    "title": "On the angular momentum and free energy of rotating gluon plasma",
    "abstract": "We study the free energy and the angular momentum of rotating hot gluon matter using first-principle numerical simulations of the $\\textrm{SU}(3)$ lattice Yang-Mills theory. We calculate the specific moment of inertia and the specific deformation of the gluon matter as, respectively, the leading and next-to-leading terms in a series in angular velocity over a broad range of temperatures and various spatial boundary conditions. We show that the specific deformation, similarly to the moment of inertia, takes negative values in a phenomenologically interesting region of temperatures above the phase transition and turns positive at higher temperatures.",
    "authors": [
      "V. Braguta",
      "M. Chernodub",
      "E. Eremeev",
      "I. Kudrov",
      "A. Roenko",
      "D. Sychev"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04083",
    "title": "Screening of dipolar emission in two-scale Gauss-Bonnet gravity",
    "abstract": "We study black holes in shift-symmetric scalar Gauss-Bonnet gravity extended by a cubic Galileon interaction with a distinct energy scale. Introducing this hierarchy profoundly modifies the theory's phenomenology. The cubic interaction allows for smaller black holes, and can generate a screening mechanism near the horizon, making large Gauss-Bonnet couplings consistent with gravitational-wave bounds. Observable quantities such as the scalar charge, the innermost stable circular orbit, and its frequency are most affected for small black holes. The resulting multi-scale effective field theory remains technically natural and offers new avenues to probe gravity in the strong-field regime.",
    "authors": [
      "Farid Thaalba",
      "Leonardo Gualtieri",
      "Thomas P. Sotiriou",
      "Enrico Trincherini"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.19290",
    "title": "Trivalent Feynman Diagrams as a Flag",
    "abstract": "By identifying each standard flag with a trivalent Feynman diagram, the corresponding propagators can be read directly from the flag itself. Within the flag representation, the kinematic Jacobi identity (equivalently, the residue theorem on moduli spaces) admits a natural interpretation as the equivalence between a complete flag and its gapped counterpart. Using flags together with Orlik-Solomon algebras, we reconstruct the intersection numbers of twisted cocycles, thereby obtaining the bi-adjoint amplitude. Moreover, employing flag simplices enables the construction of the Z-amplitude in the alpha' -> 0 limit. By further examining pairings of specific flags, we also recover the Cachazo-He-Yuan (CHY) representation of the bi-adjoint amplitude.",
    "authors": [
      "Lili Yang"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.14435",
    "title": "Two-Loop Master Integrals for Mixed QCD-EW Corrections to $gg \\to H$ Through $\\mathcal{O}(ε^2)$",
    "abstract": "We consider mixed strong-electroweak corrections to Higgs production via gluon fusion, in which the Higgs boson couples to the top quark. Using the method of differential equations, we compute all of the master integrals that contribute to this process at two loops through $\\mathcal{O}(\\epsilon^2)$ in the dimensional regularization parameter $\\epsilon = (d-4)/2$, keeping full analytic dependence on the top quark, Higgs, W, and Z boson masses. We present the results for these master integrals in terms of iterated integrals whose kernels depend on elliptic curves.",
    "authors": [
      "Robin Marzucca",
      "Andrew J. McLeod",
      "Christoph Nega"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.19226",
    "title": "Light dilaton near critical points in top-down holography",
    "abstract": "We study a class of UV-complete, strongly coupled, confining three-dimensional field theories, that exhibit a novel stabilisation mechanism for the mass of the lightest scalar composite state, relying on the existence of a critical point. The theories admit a holographic dual description in terms of regular backgrounds in eleven-dimensional supergravity. Their phase diagram includes a line of first-order phase transitions ending at the critical point, where the transition becomes of second order. We calculate the mass spectrum of bound states of the field theory, by considering fluctuations around the background solutions, and find that, near the critical point, a hierarchy of scales develops, such that one state becomes parametrically light. We identify this state as the dilaton, the pseudo-Nambu-Goldstone boson associated with the spontaneous breaking of approximate scale invariance. This stabilisation mechanism might be exploited to address hierarchy problems in particle and astroparticle physics.",
    "authors": [
      "Daniel Elander",
      "Antón F. Faedo",
      "Maurizio Piai",
      "Ronnie Rodgers",
      "Javier G. Subils"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.02592",
    "title": "Unified equation for massless spin fields and new definitions of key spin coefficients",
    "abstract": "Whether studying gravitational waves from extreme mass ratio inspirals or exploring the analogy between massless spin-particle waves, black hole perturbation theory proves indispensable. At the heart of developing a universal perturbation framework for such problems lies the challenge of formulating a coordinate-independent, unified wave equation that is universally applicable to any black hole spacetime. This paper resolves this central issue in type-D spacetimes by establishing a new definition of spin coefficients. Specifically, we introduce a new definition for the spin coefficients $\\rho$, $\\mu$, $\\tau$, and $\\pi$, which are defined as the directional derivatives of the logarithm of a generating function along the null tetrad ($l^{\\mu}$, $n^{\\mu}$, $m^{\\mu}$, $\\bar{m}^{\\mu}$), respectively. This is the first discovery that these spin coefficients are interconnected through a generating function. Using the newly defined spin coefficients, we find that the field equations for massless particles with spins 0, 1/2, 1, 3/2, and 2 in arbitrary type-D black hole spacetimes can be described by a single unified equation. This finding is particularly surprising, as unifying these field equations is already a significant challenge in flat spacetime, let alone in the intricate spacetime around black holes. Consequently, this work will inevitably prompt a re-examination of the shared characteristics among various types of particles in black hole spacetimes. Meanwhile, we verify the correctness of the new definition for the spin coefficients, and provide the explicit form of the unified equation for nearly all known type-D black hole backgrounds. This lays a solid foundation not only for studying gravitational waves from extreme mass ratio inspirals but also for exploring the analogy between massless spin-particle waves in any type-D black hole background.",
    "authors": [
      "Zhong-Heng Li"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.11052",
    "title": "Dynamical Stability and Critical Exponents of the Neutral (S-type) Gubser-Rocha Model with Momentum Dissipation",
    "abstract": "The (S-type) Gubser-Rocha model is a holographic model that shows the linear dependence of the entropy density on the temperature. With an appropriate choice of the boundary action, this model exhibits a continuous phase transition in the neutral limit. In this paper, we investigate several aspects of this phase transition. Firstly, we show that the critical exponents of the phase transition match those in the mean-field percolation theory. Subsequently, we also investigate the dynamical stability, and the emergence of the Nambu-Goldstone modes by analyzing the quasinormal modes of the perturbation fields. The dynamical stability agrees with the thermodynamic stability. In addition, we find that there is an emergent Nambu-Goldstone mode in the broken phase of the S-type model.",
    "authors": [
      "Shuta Ishigaki"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.23155",
    "title": "Homomorphism, substructure and ideal: Elementary but rigorous aspects of renormalization group or hierarchical structure of topological orders",
    "abstract": "We propose a general quantum Hamiltonian formalism of a renormalization group (RG) flow with an emphasis on generalized symmetry by interpreting the elementary relationship between homomorphism, quotient ring, and projection. In our formalism, the noninvertible nature of the ideal of a fusion ring realizing the generalized symmetry of an ultraviolet (UV) theory plays a fundamental role in determining condensation rules between anyons, resulting in the infrared (IR) theories. Our algebraic method applies to the domain wall problem in $2+1$ dimensional topologically ordered systems and the corresponding classification of $1+1$ dimensional gapped phase, for example. An ideal decomposition of a fusion ring provides a straightforward but strong constraint on the gapped phase with noninvertible symmetry and its symmetry-breaking (or emergent symmetry) patterns. Moreover, even in several specific homomorphisms connected under massless RG flows, less familiar homomorphisms appear, and we conjecture that they correspond to partially solvable models in recent literature. Our work demonstrates the fundamental significance of the abstract algebraic structure, ideal, for the RG in physics.",
    "authors": [
      "Yoshiki Fukusumi",
      "Yuma Furuta"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.16880",
    "title": "Thermal nature of the causal diamond horizon: A hidden property of the inertial propagator",
    "abstract": "Inspired by the novel idea proposed by T.~Padmanabhan in \\textit{Phys.\\ Rev.\\ D 100, 045024 (2019)}, we develop a method to uncover the hidden thermal properties of the inertial Feynman propagator in Minkowski spacetime in a causally consistent manner. This, in turn, enables a coherent interpretation based on future-directed propagation. In our approach, the Fourier transform is implemented following the convention used in the analysis of vacuum fluctuations. As a result, future-directed propagation across causal horizons can be consistently interpreted, from the perspective of an observer confined to a causally disconnected region, as the emission of scalar quanta at the past horizon and their absorption at the future horizon. Moreover, we find that the ratio between emission and absorption processes reproduces the characteristic Boltzmann factor of a thermal ensemble. We first apply this analysis to a causal diamond of length $2\\alpha$, performing a detailed study of the near-horizon geometry and thereby obtaining the temperature associated with the thermal behavior of the Minkowski vacuum as perceived by an observer with finite lifetime $2\\alpha$. For completeness, we also apply the method to the right Rindler wedge, recovering the well-known Unruh temperature, $T = a/(2\\pi)$. Our results demonstrate that thermality can emerge directly from causal structure, independently of acceleration or gravity, with causal diamonds encoding intrinsic thermodynamic behavior in quantum field theory.",
    "authors": [
      "Nada Eissa",
      "Carlos R. Ordóñez",
      "Gustavo Valdivia-Mera"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10365",
    "title": "An emergent higher-form symmetry from type IIB superstring theory",
    "abstract": "We investigate a higher-form symmetry in type IIB superstring theory, which possesses an ${\\rm SL}(2,\\mathbb{Z})$ symmetry. From the point of view of the low-energy effective field theory, the ${\\rm SL}(2,\\mathbb{Z})$ symmetry is treated as a gauge symmetry. Hence, an $8$-form global symmetry $\\mathbb{Z}_{12}^{[8]}$ emerges as a quantum symmetry. In this paper, we present an explicit construction of the topological operator associated with the $\\mathbb{Z}_{12}^{[8]}$ symmetry. In this construction, the discriminant $\\Delta(\\tau)$ plays a central role. As a result, it becomes manifest that $\\mathbb{Z}_{12}^{[8]}$ is the solitonic symmetry of $7$-branes. Furthermore, taking into account the extensions of the duality group, we also discuss what global symmetries emerge when considering not ${\\rm SL}(2,\\mathbb{Z})$ but ${\\rm Mp}(2,\\mathbb{Z})$, ${\\rm GL}(2,\\mathbb{Z})$, and ${\\rm Pin}^+({\\rm GL}(2,\\mathbb{Z}))={\\rm GL}^+(2,\\mathbb{Z})$.",
    "authors": [
      "Naoto Kan",
      "Masashi Kawahira",
      "Hiroki Wada"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.17239",
    "title": "Renormalization of massless fields in the $(1,0)\\oplus(0,1)$ representation",
    "abstract": "We study the one-loop renormalization of self-interacting massless fields in the $(1,0)\\oplus(0,1)$ representation of the Restricted Lorentz Group. We work with a general model that represents the entire class of parity-invariant self-interacting massless theories that can be defined in this representation. It consists of a general free Lagrangian that reproduces the massless limit of three theories previously studied in the literature: the Joos-Weinberg, the Shay-Good/Hammer-McDonald-Pursey, and the Klein-Gordon-like one, as particular cases; along with an interacting Lagrangian containing all the independent dimension-4 parity-invariant self-interactions available in this representation. The model is found to be renormalizable.",
    "authors": [
      "Armando de la C. Rangel-Pantoja",
      "M. Napsuciale",
      "Carlos A. Vaquera-Araujo"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.01556",
    "title": "Stringy algebras, stretched horizons, and quantum-connected wormholes",
    "abstract": "While the supergravity limit of AdS/CFT has been extensively explored, the regime in which stringy dynamics dominate, characterized by the emergence of an infinite tower of higher-spin massive modes, is far less understood. In this work, we leverage techniques from algebraic quantum field theory to investigate the extent to which hallmark features of bulk gravity survive at finite string tension and the emergence of intrinsically stringy phenomena. Working in the $g_s\\rightarrow 0$ limit, we model excited string modes as free particles and demonstrate that the resulting Hagedorn spectrum leads to the breakdown of the split property, a strengthening of the locality principle, for regions that are within a string length of each other. We propose that this leads to a precise algebraic definition of stretched horizons and stretched quantum extremal surfaces. When stretched horizons exist, there is an associated nontrivial horizon $\\star$-algebra. Furthermore, applying the algebraic ER=EPR proposal leads to the emergence of type III von Neumann factors, which provide an intriguing characterization of how such regions can have a quantum Einstein-Rosen bridge even if they are geometrically disjoint.",
    "authors": [
      "Aidan Herderschee",
      "Jonah Kudler-Flam"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.13941",
    "title": "Diffeomorphism invariant tensor networks for 3d gravity",
    "abstract": "Tensor networks prepare states that share many features of states in quantum gravity. However, standard constructions are not diffeomorphism invariant and do not support an algebra of non-commuting area operators. Recently, analogues of both problems were addressed in a tensor network discretization of topological field theories (TFT) with finite or compact gauge groups. Here, we extend this work towards gravity by generalizing to gauge groups that are discrete or continuous, compact or non-compact. Applied to $\\text{SL}(2,\\mathbb{R}) \\times \\text{SL}(2,\\mathbb{R})$ Chern-Simons theory, our construction can be interpreted as building states of three dimensional gravity with a negative cosmological constant. Our tensor networks prepare states that satisfy the constraints of Chern-Simons theory. In metric variables, this implies that the states we construct satisfy the Wheeler-DeWitt equation and momentum constraints, and so are diffeomorphism invariant.",
    "authors": [
      "Vijay Balasubramanian",
      "Charlie Cummings"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.19210",
    "title": "SL(2N,C) Hyperunification: Dynamical Tetrads, Induced Gravity, and Composite Families",
    "abstract": "A four-dimensional gauge--gravity unification based on the local $SL(2N,\\mathbb{C})$ symmetry is developed in a universal Yang--Mills-type setting. The accompanying tetrads are promoted to dynamical fields, and their invertibility condition is interpreted as a nonlinear sigma-model-type length constraint. This triggers tetrad condensation and spontaneously breaks $SL(2N,\\mathbb{C})$ down to $SL(2,\\mathbb{C})\\times SU(N)$, effectively filtering out unobserved non-compact directions. A special ghost-free curvature-squared Lagrangian provides a consistent quadratic sector for all gauge fields involved, while an Einstein--Cartan linear-curvature term is shown to arise radiatively from fermion loops. The matter sector points to a deeper elementarity of $SL(2N,\\mathbb{C})$ spinors, which can be identified with preon constituents whose bound states form the observed quarks and leptons. Anomaly matching between preons and composites singles out $SL(16,\\mathbb{C})$, accommodating precisely three composite quark--lepton families. The theory thus links non-compact unification, induced gravity, and fermion family structure within a single framework.",
    "authors": [
      "J. L. Chkareuli"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01271",
    "title": "Perturbative corrections to soft photon theorems for massless scalar QED in de Sitter spacetime",
    "abstract": "The perturbative corrections to soft photon theorems with massive scalars in de Sitter spacetime were computed in [JHEP10(2023)055]. However, the massless limit of the scalar modes is ill-defined in their work. It therefore is ambiguous to take the massless limit of the soft factors. In this paper, we derive the massless scalar modes in $d$-dimensional de Sitter spacetime and use it to compute the perturbative corrections to the leading and sub-leading soft photon theorems. Our framework corresponds to tree level scattering of massless scalars followed by an emission of a soft photon in a compact region of the static patch of de Sitter. We show that our results are consistent with [JHEP10(2023)055] in the massless limit and we comment on the universality of our results.",
    "authors": [
      "Pratik Chattopadhyay"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.07049",
    "title": "Quantization of electromagnetic field in the Schwarzschild spacetime",
    "abstract": "We discuss the problem of canonical quantization of electromagnetic field in the Schwarzschild spacetime. It is shown that a consistent procedure of canonical quantization of the field can be carried out without taking into account the internal region of the black hole. We prove that there exists a unitary gauge, which can be viewed as a combination of the Coulomb and Poincare gauges and is compatible with the field equations. The solutions corresponding to the stationary one-particle states of the electromagnetic field are studied, the canonical commutation relations and the Hamiltonian of the quantized electromagnetic field are obtained.",
    "authors": [
      "Vadim Egorov",
      "Mikhail Smolyakov",
      "Igor Volobuev"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.06075",
    "title": "Barrow Cosmology and Big-Bang Nucleosynthesis",
    "abstract": "Using thermodynamics-gravity conjecture, we present the formal derivation of the modified Friedmann equations inspired by the Barrow entropy, $S\\sim A ^{1+\\delta/2}$, where $0\\leq\\delta\\leq 1$ is the Barrow exponent and $A$ is the horizon area. We then constrain the exponent $\\delta$ by using Big-Bang Nucleosynthesis (BBN) observational data. In order to impose the upper bound on the Barrow exponent $\\delta$, we set the observational bound on $\\left| \\frac{\\delta T_f} {T_f }\\right|$. We find out that the Barrow parameter $\\delta$ should be around $ \\delta \\simeq 0.01$ in order not to spoil the BBN era. Next we derive the bound on the Barrow exponent $\\delta$ in a different approach in which we analyze the effects of Barrow cosmology on the primordial abundances of light elements i.e. Helium $_{}^{4}\\textit{He}$, Deuterium $D$ and Lithium $_{}^{7}\\textit{Li}$. We observe that the deviation from standard Bekenstein-Hawking expression is small as expected. Additionally we present the relation between cosmic time $t$ and temperature $T$ in the context of modified Barrow cosmology. We confirm that the temperature of the early universe increases as the Barrow exponent $\\delta$ (fractal structure of the horizon) increases, too.",
    "authors": [
      "Ahmad Sheykhi",
      "Ava Shahbazi Sooraki"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.09050",
    "title": "Late-time acceleration and structure formation in interacting $α$-attractor dark energy models",
    "abstract": "We investigate the cosmological dynamics of interacting dark energy within the framework of $\\alpha$-attractor models. Specifically, we analyze the associated autonomous system, focusing on its fixed points that represent dark energy and scaling solutions, along with their stability conditions. We employ center manifold theory to address cases where some fixed points display eigenvalues with zero and negative real parts. The model reveals attractors describing dark energy, enabling a smooth transition from the radiation-dominated era to the matter-dominated era, and ultimately into the dark-energy-dominated phase. Additionally, we identify a scaling matter solution capable of modifying the growth rate of matter perturbations during the matter-dominated epoch. Consequently, we study the evolution of matter perturbations by obtaining both analytical and numerical solutions to the density contrast evolution equation. Based on these results, we compute numerical solutions for the weighted growth rate $f\\sigma_{8}$, indicating that interacting $\\alpha$-attractor dark energy models may provide a better fit to structure formation data than the standard $\\Lambda$CDM scenario.",
    "authors": [
      "L. K. Duchaniya",
      "B. Mishra",
      "G. Otalora",
      "M. Gonzalez-Espinoza"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.10668",
    "title": "Analyzing the general conditions for modulus stabilization in a warped braneworld",
    "abstract": "In braneworld scenarios with compact extra dimensions, the modulus field typically remains undetermined without an appropriate stabilization mechanism. A common approach introduces a bulk scalar field that generates an effective potential for the modulus with a stable minimum. In this work, we explore some novel aspects of such stabilization mechanisms. We study how the bulk scalar profile influences the stabilization procedure. Following the approach of Chacko et al. [1], we analyze several representative cases using methods of singular perturbation theory. We identify a consistent relationship between the structure of the bulk potential and the emergence of a stabilized modulus, and outline the general conditions that any bulk potential must satisfy to enable stabilization. In this context, we also examine a potential connection between geometric consistency conditions - specifically, the \"brane world sum rules\" - and the stabilized value of the modulus. In some scenarios where stabilization occurs, we find that these sum rules can offer additional constraints on the modulus, providing a complementary perspective on its determination. Taken together, these results offer a broader perspective on the mechanisms that govern modulus stabilization in higher-dimensional warped geometries.",
    "authors": [
      "Soham Bhattacharyya",
      "Soumitra SenGupta"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.07510",
    "title": "Towards a test of the Born rule in high-energy collisions",
    "abstract": "We consider how the Born rule, a fundamental principle of quantum mechanics, can be tested for particles created on the shortest timescales ($\\sim10^{-25}\\,\\mathrm{s}$) currently accessible at high-energy colliders. We focus on targeted tests of the Born rule for spin or polarisation probabilities, which offer a particularly clean experimental signal, and which can be described by a simple hidden-variables model of two-state systems proposed by Bell. These probabilities test a remarkable feature of the quantum formalism, whereby expectation values for incompatible experiments are linearly related. Born-rule violations can be parameterised by nonlinear expectation values for quantum measurements of spin or polarisation, along with anomalies in ensemble averages, which may then be constrained by experiment. Notable experiments considered here include the recent detection of single photons from top-quark decay, and the indirect measurement of tau-lepton polarisation. Repurposing these experiments as tests of the Born rule, however, presents several challenges, which are discussed in this paper.",
    "authors": [
      "Antony Valentini",
      "Mira Varma"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.11288",
    "title": "Generalized Parton Distributions from Lattice QCD with Asymmetric Momentum Transfer: Tensor Case",
    "abstract": "The calculation of generalized parton distributions (GPDs) in lattice QCD was traditionally done by calculating matrix elements in the symmetric frame. Recent advancements have significantly reduced computational costs by calculating these matrix elements in the asymmetric frame, allowing us to choose the momentum transfer to be in either the initial or final states only. The theoretical methodology requires a new parametrization of the matrix element to obtain Lorentz-invariant amplitudes, which are then related to the GPDs. The formulation and implementation of this approach have already been established for the unpolarized and helicity GPDs. Building upon this idea, we extend this formulation to the four leading-twist quark transversity GPDs ($H_T$, $E_T$, $\\widetilde{H}_T$, $\\widetilde{E}_T$). We also present numerical results for zero skewness using an $N_f=2+1+1$ ensemble of twisted mass fermions with a clover improvement. The light quark masses employed in these calculations correspond to a pion mass of about 260 MeV. Furthermore, we include a comparison between the symmetric and asymmetric frame calculations to demonstrate frame independence of the Lorentz-invariant amplitudes. Analysis of the matrix elements in the asymmetric frame is performed at several values of the momentum transfer squared, $-t$, ranging from 0.17 GeV$^2$ to 2.29 GeV$^2$.",
    "authors": [
      "Shohini Bhattacharya",
      "Krzysztof Cichy",
      "Martha Constantinou",
      "Andreas Metz",
      "Joshua Miller",
      "Peter Petreczky",
      "Fernanda Steffens"
    ],
    "primary_category": "hep-lat",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00102",
    "title": "Letelier black hole immersed in an electromagnetic universe",
    "abstract": "We investigate a static, spherically symmetric black hole solution surrounded by a cloud of strings and immersed in an electromagnetic universe. By deriving the event horizon from the lapse function, we demonstrate that both the string cloud parameter and the electromagnetic background parameter significantly modify the horizon radius compared to the Schwarzschild case. Consequently, thermodynamic quantities-including the Hawking temperature, Bekenstein-Hawking entropy, and heat capacity-become explicit functions of these additional parameters, with the heat capacity exhibiting divergences that signal phase transitions. We analyze the motion of massive test particles in this spacetime, deriving the effective potential and calculating the innermost stable circular orbit radius, which governs the inner edge of accretion disks and influences orbital stability. Scalar perturbations are examined through the associated effective potential, and quasinormal mode frequencies are computed using the sixth-order WKB approximation; the negative imaginary parts confirm the stability of the black hole under such perturbations. We also study the photon sphere structure, black hole shadow radius, and photon trajectories, showing how the interplay between string clouds and the electromagnetic background shapes the optical properties of this spacetime. Finally, we investigate weak gravitational lensing phenomena by deriving the deflection angle for both massive particles and photons using the Gauss-Bonnet theorem applied to the optical geometry. The results exhibit notable deviations from the Schwarzschild geometry, with the string cloud enhancing the deflection through a $(1-\\alpha)^{-1}$ factor while the electromagnetic parameter introduces competing corrections at second order.",
    "authors": [
      "Ahmad Al-Badawi",
      "Faizuddin Ahmed",
      "İzzet Sakallı"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00172",
    "title": "Enhancing the sensitivity to neutrino oscillation parameters using synergy between T2K, NO$ν$A and JUNO",
    "abstract": "We study the impact of combining the present NO$\\nu$A and T2K data with simulated data from the JUNO experiment on the determination of the leptonic CP phase and the neutrino mass hierarchy. The current NO$\\nu$A data exhibit a hierarchy--$\\delta_{\\rm CP}$ degeneracy, admitting both normal hierarchy (NH) with $\\delta_{\\rm CP} \\in [0,180^\\circ]$, and inverted hierarchy (IH) with $\\delta_{\\rm CP} \\in [180^\\circ,360^\\circ]$ solutions at comparable significance, while T2K prefers $\\delta_{\\rm CP}\\simeq 270^\\circ$ for both hierarchies, leading to a $2\\sigma$ tension between the two experiments for normal hierarchy. Using detailed GLoBES simulations, we show that future JUNO data with excellent hierarchy sensitivity, can lift the hierarchy--$\\delta_{\\rm CP}$ degeneracy in NO$\\nu$A and strengthen the hierarchy reach of T2K in spite of having no $\\delta_{\\rm CP}$ sensitivity. Allowing the hierarchy to be a free parameter in the fit, if the true ordering is IH, JUNO aligns the NO$\\nu$A and T2K allowed regions and resolves their present tension; if NH is true, the tension continues to persist. We also show that JUNO's precise measurement of $|\\Delta_{31}|$ leads to improved constraints on $\\sin^2\\theta_{23}$ and $\\delta_{\\rm CP}$ for normal mass hierarchy in NO$\\nu$A even though JUNO itself is insensitive to these parameters. Finally, updated solar parameter measurements from JUNO's first data release further enhance the combined precision. Our results demonstrate that JUNO plays a crucial synergistic role in the global neutrino oscillation programme, enabling a more robust determination of the mass ordering and improving the sensitivity to the CP phase when combined with long-baseline data.",
    "authors": [
      "Srubabati Goswami",
      "Aman Gupta",
      "Ushak Rahaman",
      "Sushant K. Raut"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03171",
    "title": "A Mathematical Introduction to Geometric Quantization",
    "abstract": "These notes are based on a series of lectures by Kadri İlker Berktav from May 2024 to November 2024, providing a detailed exposition of geometric quantization formalism and its essential components. They are organized into three parts: background in symplectic geometry, basics of geometric quantization formalism, and an application related to Edward Witten's work in knot theory and topology.",
    "authors": [
      "Kadri İlker Berktav",
      "Burak Oğuz",
      "Ömer Önder",
      "Yunus Emre Sargut",
      "Başar Deniz Sevinç",
      "Deniz Nazif Taştan"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03181",
    "title": "Three-dimensional third medium contact model for hyperelastic contact and pneumatically actuated systems",
    "abstract": "This work presents a comprehensive three-dimensional third-medium contact framework for modeling complex contact interactions in hyperelastic solids and pneumatically actuated systems. The proposed third-medium formulation embeds a fictitious medium (or third medium) between potentially interacting bodies, enabling a unified and robust treatment of hyperelastic contact and self-contact without the need for discretization of the contact interface. Unlike the widely studied two-dimensional problem, this paper extends the new regularization term given in Reference \\cite{TMCWriggers2} to three-dimensional problems and ensures element quality in a third medium. Due to the need for higher-order elements for the regularization term, this paper details the linearization process of this problem within the finite element framework. In addition, pneumatically actuated systems are considered by introducing a pneumatic term to represent pneumatic loading (pressure or suction) and inducing contact caused by internal inflation. This approach is suitable for complex hyperelastic contact and self-contact, and has potential applications in the fields of soft robotics and flexible mechanisms. The framework is developed in a fully three-dimensional setting, making it also suitable for isogeometric methods and meshless methods. Several benchmark and application-level simulations demonstrate the accuracy, robustness, and versatility of the proposed approach. The results highlight the capability of the three-dimensional third-medium model to handle challenging nonlinear contact scenarios relevant to soft materials, soft actuators, and emerging multifunctional structures.",
    "authors": [
      "Bing-Bing Xu",
      "Tianju Xue",
      "Peter Wriggers"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03205",
    "title": "A discontinuous Galerkin approach for simulating graphene-based electron devices via the Boltzmann transport equation",
    "abstract": "Electron devices based on graphene have lately received a considerable interest; in fact, they could represent the ultimate miniaturization, since the active area is only one atom tick. However, the gapless dispersion relation of graphene at the Dirac points limits the possibility of using pristine graphene instead of traditional semiconductors in Field Effect Transistors (FET). For such a reason very accurate simulations are needed. In Nastasi & Romano, IEEE TED (2021) a graphene field effect transistor (GFET) has been proposed and simulated adopting a drift-diffusion model. Here, electron devices whose active area is made of monolayer graphene are simulated adopting as mathematical model the semiclassical Boltzmann transport equations (BTEs) in the bipolar case, coupled with the Poisson equation for the electric field. The system is solved by means of a discontinuous Galerkin (DG) approach (see Cockburn & Shu, J. Comp. Phys. (1998); Hesthaven & Warburton, 2008) with linear elements in the spatial coordinate and constant approximation for the wave-vector space, discretized with a polar mesh. The correct physical range for the distribution function is preserved with the maximum-principle-satisfying scheme introduced in Zhang & Shu, J. Comp. Phys. (2010). The adopted method reveals very robust and possesses a good degree of accuracy, making it particularly well suited for capturing the complex charge transport dynamics inherent to graphene-based devices. The results for suspended monolayer graphene and GFET constitute benchmark solutions for a rigorous assessment of the validity of macroscopic models, such as drift-diffusion and hydrodynamic ones.",
    "authors": [
      "Giovanni Nastasi",
      "Vittorio Romano"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03455",
    "title": "Solutions to Open WDVV Equations for the Universal Whitham Hierarchy",
    "abstract": "In this paper, we construct a pair of solutions to the open WDVV equations associated with the infinite-dimensional Frobenius manifolds that underlie the genus-zero universal Whitham hierarchy, and for the resulting flat F-manifolds, we explicitly construct their principal hierarchies. We further demonstrate that this construction is compatible with finite-dimensional reductions, yielding solutions for Frobenius manifolds associated with general rational superpotentials and those subject to a $\\mathbb{Z}_{2}$-symmetry reduction. In particular, the polynomial solutions derived by Basalaev and Buryak via open Saito theory for A- and D-type singularities are recovered as special cases.",
    "authors": [
      "Shilin Ma"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03469",
    "title": "The magnetic inverse problem for two stacked layers of sources",
    "abstract": "We present calculations that reconstruct electronic current densities in two stacked layers at known depths, using magnetic field data. Solving this inverse problem requires knowledge of the magnetic field in two planes -- one above both current layers, one below -- corresponding to non-invasive measurements of the field. We corroborate the accuracy of current density reconstruction from the resulting system of equations using a numerical simulation. This method is anticipated to be applicable to non-destructive current imaging for quality assurance in a range of applications featuring two-layer geometries, including printed circuit boards, capacitors, fuel cells, and battery cells; we focus particularly here on battery cells, due to their rapidly increasing relevance for automotive applications. This method also offers a framework for generalising the model to more than two layers in future work.",
    "authors": [
      "Michael T. M. Woodley",
      "Thomas Coussens",
      "William Evans",
      "Matthew Withers",
      "Leigh Page",
      "Daniel Nightingale",
      "Denilson Nicolau",
      "Gary Kendall",
      "Fedja Orucevic",
      "Peter Kruger"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03504",
    "title": "Optical Caustics as Lagrangian Singularities: Classification and Geometric Structure",
    "abstract": "This paper develops a rigorous mathematical framework for light propagation by constructing the optical phase space with its symplectic structure and the extended phase space with its contact structure. We prove that light rays in three-dimensional Euclidean space correspond to Reeb orbits in a five-dimensional contact manifold, which are then projected onto a four-dimensional symplectic manifold via symplectic reduction. Leveraging the advantages of phase space, we provide a rigorous definition of caustic surfaces as singularities of the Lagrangian submanifold projection and derive explicit expressions for caustic surfaces in convex lens systems. Furthermore, based on singularity theory, we present a complete classification of stable caustic surfaces and establish a correspondence with classical Seidel aberration theory. Building upon this theory, we propose a method of \\emph{topological optical correction} that overcomes the limitations of traditional optimization algorithms in dealing with complex caustic structures. This work provides a new mathematical paradigm for the design and correction of high-precision optical systems.",
    "authors": [
      "Rongqi Shang",
      "Donglin Ma"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04066",
    "title": "Instantaneous Sobolev Regularization for Dissipative Bosonic Dynamics",
    "abstract": "We investigate quantum Markov semigroups on bosonic Fock space and identify a broad class of infinite-dimensional dissipative evolutions that exhibit instantaneous Sobolev-regularization. Motivated by stability problems in quantum computation, we show that for certain Lindblad operators that are polynomials of creation and annihilation operators, the resulting dynamics immediately transform any initial state into one with finite expectation in all powers of the number operator. A key application is in the bosonic cat code, where we obtain explicit estimates in the trace norm for the speed of convergence. These estimates sharpen existing perturbative bounds at both short and long times, offering new analytic tools for assessing stability and error suppression in bosonic quantum information processing. For example, we improve the strong exponential convergence of the (shifted) $2$-photon dissipation to its fixed point to the uniform topology.",
    "authors": [
      "Pablo Costa Rico",
      "Paul Gondolf",
      "Tim Möbus"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03142",
    "title": "Topological Einstein gravity as Kodaira-Spencer gravity",
    "abstract": "As a contribution towards quantizing three-dimensional gravity, we show at the classical level that Euclidean three-dimensional Einstein gravity with a negative cosmological constant is uplifted to the $SU(2)$-invariant sector of Kodaira-Spencer gravity on a Calabi-Yau three-fold. Kodaira-Spencer gravity appears in the target space description of the B-model topological string theory and describes deformations of a complex structure. We prove that given a reference solution of Einstein gravity in the first-order formulation, a second off-shell configuration uplifts to a unique complex structure deformation in six dimensions. If the configuration satisfies Einstein's equations, the complex structure deformation is integrable, i.e. a solution of Kodaira-Spencer gravity. We demonstrate the uplift explicitly for Bañados solutions. Our construction embeds three-dimensional gravity into topological string theory and AdS$_3$/CFT$_2$ duality into twisted holography.",
    "authors": [
      "Johanna Erdmenger",
      "Jonathan Karl",
      "Jani Kastikainen",
      "René Meyer",
      "Henri Scheppach"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03148",
    "title": "Proof that Momentum Mixing Hatsugai Kohmoto equals the Twisted Hubbard Model",
    "abstract": "We prove formally that the momentum-mixing Hatsugai-Kohmoto model (MMHK) is the Hubbard model with a twist. With this result in tow, we rely on the proof of Watanabe's that two models which differ by a twist must have the same bulk physics. Consequently, we have proven that MMHK=Hubbard in the charge sector.",
    "authors": [
      "Yuting Bai",
      "Philip W. Phillips"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03172",
    "title": "On the Virasoro Crossing Kernels at Rational Central Charge",
    "abstract": "We report novel analytic results for the Virasoro modular and fusion kernels relevant to 2d conformal field theories (CFTs), 3d topological field theories (TQFTs), and the representation theory of certain quantum groups. For all rational values of the parameter $b^2\\in\\mathbb{Q}^{\\times}$ -- corresponding in 2d CFT to all rational central charge values in the domain $(-\\infty,1]\\cup[25,\\infty)$ -- we establish two main results. First, in the domain $c\\in\\mathbb{Q}_{[25,\\infty)}$ we show that the modular and fusion kernels derived by Teschner and Teschner-Vartanov respectively can be expressed as a linear combination of two functions, which (i) are themselves admissible crossing kernels, (ii) have square-root branch point singularities in the Liouville momenta, (iii) are not reflection-symmetric in the Liouville momenta. These features illustrate that the space of solutions to the basic shift relations determining these kernels is broader than previously assumed. Second, in the domain $c\\in\\mathbb{Q}_{(-\\infty,1]}$ we derive for the first time the physical modular and fusion kernels for generic values of the Liouville momenta. These can again be written as a linear combination of two other admissible kernels but overall, and unlike the Teschner and Teschner-Vartanov solutions for $c\\geq 25$, they possess square-root branch point singularities. As a corollary, we demonstrate that timelike Liouville theory at $c\\in\\mathbb{Q}_{(-\\infty,1]}$ is crossing symmetric and modular covariant. Surprisingly, the crossing kernels at any $b^2\\in\\mathbb{Q}^{\\times}$ behave as if they were semiclassical and one-loop exact, and we discuss the interpretation of this fact in the context of the 2d conformal bootstrap and the 3d TQFT that captures pure 3d gravity with negative cosmological constant.",
    "authors": [
      "Julien Roussillon",
      "Ioannis Tsiares"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03185",
    "title": "Nonlinear diffusion limit of non-local interactions on a sphere",
    "abstract": "We study an aggregation PDE with competing attractive and repulsive forces on a sphere of arbitrary dimension. In particular, we consider the limit of strongly localized repulsion with a constant attraction term. We prove convergence of solutions of such a system to solutions of the aggregation-diffusion equation with a porous-medium-type diffusion term. The proof combines variational techniques with elements of harmonic analysis on a sphere. In particular, we characterize the square root of the convolution operator in terms of the spherical harmonics, which allows us to overcome difficulties arising due to the convolution on a sphere being non-commutative. The study is motivated by the toy model of transformers introduced by Geshkovski et al. (2025); and we discuss the applicability of the results to this model.",
    "authors": [
      "Mark A. Peletier",
      "Anna Shalova"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03240",
    "title": "Models of Flow through Porous Media of Polar Fluids with Pressure-Dependent Viscosity",
    "abstract": "Equations governing the flow of a polar fluid, with pressure-dependent Newtonian viscosity, through a variable-porosity medium are developed. Averaged equations are obtained using intrinsic volume averaging. A drag function is introduced to account for the interactions of the fluid with the porous matrix. Darcy and Forchheimer generalized terms are included in the model equations for both granular and consolidated media to account for the effects of the porous microstructure.",
    "authors": [
      "M.H. Hamdan",
      "D.C. Roach"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03249",
    "title": "Computing Equilibrium Points of Electrostatic Potentials",
    "abstract": "We study the computation of equilibrium points of electrostatic potentials: locations in space where the electrostatic force arising from a collection of charged particles vanishes. This is a novel scenario of optimization in which solutions are guaranteed to exist due to a nonconstructive argument, but gradient descent is unreliable due to the presence of singularities. We present an algorithm based on piecewise approximation of the potential function by Taylor series. The main insight is to divide the domain into a grid with variable coarseness, where grid cells are exponentially smaller in regions where the function changes rapidly compared to regions where it changes slowly. Our algorithm finds approximate equilibrium points in time poly-logarithmic in the approximation parameter, but these points are not guaranteed to be close to exact solutions. Nevertheless, we show that such points can be computed efficiently under a mild assumption that we call \"strong non-degeneracy\". We complement these algorithmic results by studying a generalization of this problem and showing that it is CLS-hard and in PPAD, leaving its precise classification as an intriguing open problem.",
    "authors": [
      "Abheek Ghosh",
      "Paul W. Goldberg",
      "Alexandros Hollender"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03270",
    "title": "Curvature Potential Formulation for Thin Elastic Sheets",
    "abstract": "Thin elastic sheets appear in systems ranging from graphene to biological membranes, where phenomena such as wrinkling, folding, and thermal fluctuations originate from geometric nonlinearities. These effects are treated within weakly nonlinear theories, such as the Foppl-von Karman equations, which require small slopes and fail when deflections become large even if strains remain small. We introduce a methodological progress via a geometric reformulation of thin-sheet elasticity based on a stress potential and a curvature potential. This formulation preserves the structure of the classical equations while extending their validity to nonlinear, multivalued configurations, and geometrically frustrated states. The framework provides a unified description of thin-sheet mechanics in regimes inaccessible to existing theories and opens new possibilities for the study of elastic membranes and two-dimensional materials.",
    "authors": [
      "Yael Cohen",
      "Animesh Pandey",
      "Yafei Zhang",
      "Cy Maor",
      "Michael Moshe"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03309",
    "title": "Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates",
    "abstract": "Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.",
    "authors": [
      "Aniruddha Bora",
      "Shixuan Zhang",
      "Khemraj Shukla",
      "Bryce Harrop",
      "George Em. Karniadakis",
      "L. Ruby Leung"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03378",
    "title": "On Bridging Analyticity and Sparseness in Hyperdissipative Navier-Stokes Systems",
    "abstract": "We study the three-dimensional hyper-dissipative Navier-Stokes system in the near-critical regime below the Lions threshold. Leveraging a quantified analyticity-sparseness gap, we introduce a time-weighted bridge inequality across derivative levels and a focused-extremizer hypothesis capturing peak concentration at a fixed point. Together with a harmonic-measure contraction on one-dimensional sparse sets, these mechanisms enforce quantitative decay of high-derivative $L^{\\infty}-$norms and rule out blow-up. Under scale-refined, slowly varying time weights, solutions extend analytically past the prospective singular time, thereby refining the analyticity-sparseness framework, complementing recent exclusions of rapid-rate blow-up scenarios, and remaining consistent with recent non-uniqueness results.",
    "authors": [
      "Moses Patson Phiri"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03408",
    "title": "A Linear Structure from Magnetic-Dipole Systems and Its Geometry",
    "abstract": "We investigate a class of algebras on $\\mathbb{R}^3$ arising and generalized from the algebraic structure of magnetic gradient fields induced by systems of synchronous magnets with identical dipole moments (i.e., $\\mathbf{M}_i=\\mathbf{M},\\,\\forall i$). We show that when there is a $2$ dimensional sub-algebra, the linear structure associated to such an algebra admits a certain type of decompositions, which allows the locating of the dipole moment $\\bar{\\mathbf{M}}$ that yields the strongest translational force(s) on a test magnet $\\mathfrak{m}$. Upper bounds to the strength of this magnetic force are then established.",
    "authors": [
      "Bohuan Lin",
      "Fengping Li",
      "Zhengya Zhang"
    ],
    "primary_category": "math.RA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03587",
    "title": "The Dirichlet-to-Neumann map on asymptotically anti-de Sitter spaces and holography",
    "abstract": "We consider the Klein-Gordon equation on asymptotically anti-de Sitter spacetimes, and show that the forward Dirichlet-to-Neumann map (or scattering matrix) is a fractional power of the boundary wave operator modulo lower order terms in the sense of paired Lagrangian distributions. We use it to show that, outside of a countable set of mass parameters, the Dirichlet-to-Neumann map determines the Taylor series of the bulk metric at the boundary, and hence allows the recovery of a real analytic metric or Einstein metric modulo isometries. Furthermore, we prove a Lorentzian version of the Graham-Zworski theorem relating poles of the Dirichlet-to-Neumann map to conformally invariant powers of the boundary wave operator.",
    "authors": [
      "Alberto Enciso",
      "Gunther Uhlmann",
      "Michał Wrochna"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03624",
    "title": "Elastic scattering problems by penetrable obstacles with embedded objects",
    "abstract": "This paper considers 3-D elastic scattering problems by penetrable obstacles with embedded objects. The well-posedness of transmission problem is proved by employing integral equation method. Then the Inverse Problems , which is to recover the obstacle by the far-field pattern measurement, is considered. It is shown that the inhomogeneous penetrable obstacle can be uniquely determined from the far-field pattern at a fixed frequency.",
    "authors": [
      "Chun Liu",
      "Jiaqing Yang",
      "Bo Zhang"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03633",
    "title": "A Stone-Weierstrass approximation theorem for monotone functions",
    "abstract": "We present an approximation theorem for continuous non-decreasing functions on compact preordered spaces, leading to an algebraic characterization of their corresponding function spaces. As an application, we prove that the family of positive non-decreasing rational functions with non-negative coefficients can uniformly approximate all continuous non-decreasing functions on compact intervals. An explicit approximation formula of this type is provided.",
    "authors": [
      "Ettore Minguzzi"
    ],
    "primary_category": "math.FA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03645",
    "title": "Gauge Symmetries, Contact Reduction, and Singular Field Theories",
    "abstract": "The reduction of dynamical systems which are invariant under changes of global scale is well-understood, for classical theories of particles, and fields. The excision of the superfluous degree of freedom describing such a scale leads to a dynamically-equivalent theory, which is frictional in nature. In this article, we extend the formalism to physical models, of both particles and fields, described by singular Lagrangians. Our treatment of classical field theory is based on the manifestly covariant Hamilton De-Donder Weyl formalism, in which the Lagrangian density is introduced as a bundle morphism on the pre-multisymplectic velocity phase space $J^1E$. The results obtained are subsequently applied to a number of physically-motivated examples, as well as a discussion presented on the implications of our work for classical General Relativity.",
    "authors": [
      "Callum Bell",
      "David Sloan"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03660",
    "title": "Linking Aneurysmal Geometry and Hemodynamics Using Computational Fluid Dynamics",
    "abstract": "The development and progression of abdominal aortic aneurysms (AAA) are related to complex flow patterns and wall-shear-driven mechanobiological stimuli, yet the quantitative relationship between aneurysmal geometry and hemodynamics remains poorly defined. In this study, we conducted a comprehensive hemodynamic analysis of 74 patient-specific abdominal aortas, representing one of the largest Computational Fluid Dynamics (CFD) cohorts reported to date. A multiscale framework coupling 0D-1D systemic circulation models with 3D stabilized finite-element simulations is used to generate physiologically consistent boundary conditions and high-fidelity flow fields. From each model, we extract Time Averaged Wall Shear Stress (TAWSS), Oscillatory Shear Index (OSI), Relative Residence Time (RRT) and Local Normalized Helicity (LNH) indicators alongside an extended set of geometric descriptors characterizing diameter, curvature and torsion. This study provides a clear and comprehensive view of how aneurysm shape influences blood-flow behavior, supported by one of the largest systematically analyzed CFD datasets of AAAs to date. Our results show that specific geometric features reliably shape shear-stress patterns, suggesting that these geometry-driven flow signatures could serve as valuable biomarkers for patient-specific risk assessment. Together, these insights highlight the potential of incorporating detailed geometric descriptors into future models that aim to predict AAA growth and rupture.",
    "authors": [
      "Spyridon C. Katsoudas",
      "Konstantina C. Kyriakoudi",
      "Grigorios T. Chrimatopoulos",
      "Panagiotis D. Linardopoulos",
      "Christoforos T. Chrimatopoulos",
      "Anastasios A. Raptis",
      "Konstantinos G. Moulakakis",
      "John D. Kakisis",
      "Christos G. Manopoulos",
      "Michail A. Xenos",
      "Efstratios E. Tzirtzilakis"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03773",
    "title": "Counter-examples to the fractal Weyl law for semiclassical resonances",
    "abstract": "Under general assumptions, the numbers of semiclassical resonances is known to be bounded from above by a negative power of $h$ which is given by the fractal dimension of the trapped set. In this paper we provide examples of operators with much less resonances, showing that these upper bounds are not always sharp.",
    "authors": [
      "Jean-Francois Bony",
      "Setsuro Fujiie",
      "Thierry Ramond",
      "Maher Zerzeri"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03808",
    "title": "Solution of the Electric Field Integral Equation Using a Hybrid Quantum-Classical Scheme: Investigation of Accuracy and Efficiency",
    "abstract": "Conventional classical solvers are commonly used for solving matrix equation systems resulting from the discretization of SIEs in computational electromagnetics (CEM). However, the memory requirement would become a bottleneck for classical computing as the electromagentic problems become much larger. As an alternative, quantum computing has a natural \"parallelization\" advantage with much lower storage complexity due to the superposition and entanglement in quantum mechanics. Even though several quantum algorithms have been applied for the SIEs-based methods in the literature, the size of the matrix equation systems solvable using them is still limited. In this work, we use a hybrid quantum-classical scheme to solve the EFIE for analyzing electromagentic scattering from three-dimensional (3D) perfect electrically conducting objects with arbitrary shapes in CEM for the first time. Instead of directly solving the original EFIE matrix equation system using the quantum algorithms, the hybrid scheme first designs the preconditioned linear system and then uses a double-layer iterative strategy for its solution, where the external iteration layer builds subspace matrix equation systems with smaller dimension and the internal iteration layer solves the smaller systems using the quantum algorithms. Two representative quantum algorithms, HHL and VQLS, are considered in this work, which are executed on the quantum simulator and quantum computer platforms. We present the theoretical time complexity analysis of the hybrid quantum-classical scheme and perform numerical experiments to investigate the accuracy and efficiency of the hybrid scheme. The results show that the computational complexity of the hybrid VQLS-classical scheme is lower than the conventional fast solvers in classical computing, which indicates the hybrid scheme is more promising for analyzing large-scale electromagnetic problems.",
    "authors": [
      "Rui Chen",
      "Teng-Yang Ma",
      "Meng-Han Dou",
      "Chao-Fu Wang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03831",
    "title": "Spectral properties of the Frechet derivatives of stratified steady Stokes waves",
    "abstract": "We consider stratified steady water waves in a two dimensional channel. Our main subject is spectral properties of the Frechet derivatives of steady water Stokes waves. One of main results is the absence of subharmonic water waves in a neighborhood of a Stokes wave. The main assumption is formulated in terms of the eigenvalues of the Frechet derivative evaluated at this wave and considered in the class of periodic solutions of the same period. The first eigenvalue is always negative. We show that if the second eigenvalue is positive then there are no waves with multiple periods in a neighborhood of the Stokes wave.",
    "authors": [
      "Vladimir Kozlov"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03860",
    "title": "Infinitesimal deformations of Lie algebroid pairs",
    "abstract": "We study infinitesimal deformations of Lie algebroid pairs in the category of smooth manifolds enriched with a local Artinian algebra. Given a Lie algebroid pair $(L,A)$, i.e. a Lie algebroid $L$ together with a Lie subalgebroid $A$, we investigate isomorphism classes of infinitesimal deformations of $(L,A)$ modulo automorphisms from exponentials of derivations of $L$ and those from the exponentials of inner derivations of $L$, respectively. For the associated two deformation functors, we find the associated governing $L_\\infty$-algebras in the sense of extended deformation theory. Furthermore, when $(L,A)$ is a matched Lie pair, i.e. the quotient $L/A$ is also a Lie subalgebroid of $L$, we investigate isomorphism classes of infinitesimal deformations modulo automorphisms from exponentials of derivations along the normal direction $L/A$. The extended deformation theory of the associated deformation functor recovers the formal deformation theory of complex structures and that of transversely holomorphic foliations.",
    "authors": [
      "Dadi Ni",
      "Zhuo Chen",
      "Chuangqiang Hu",
      "Maosong Xiang"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03950",
    "title": "Collective dynamics of trail-interacting particles",
    "abstract": "Trail interactions occur when past particle trajectories bias future motion, rendering the system out of thermodynamic equilibrium. While such systems are abundant in nature, their understanding is limited to the single-particle level or phenomenological mean-field theories. Here, we introduce a minimal model of many trail-interacting particles that extends this paradigm to the fluctuating collective level. Particles diffuse while depositing long-lasting repelling/attracting trails that act as a shared memory field, coupling their dynamics across time and space. Using stochastic density functional theory, we derive fluctuating hydrodynamic equations and analyze analytically and numerically the resulting behaviors. We show that memory, coupled with fluctuations, fundamentally reshapes collective dynamics; In the repulsive case, the particle density displays superdiffusive spreading characterized by transient clustering and ballistic motion; In the attractive case, the system condensates in finite time into frozen, localized states. Our results establish general principles for trail-interacting systems and reveal how persistent fields generate novel instabilities and self-organization.",
    "authors": [
      "Paul Pineau",
      "Samuel Bell",
      "Raphaël Voituriez",
      "Ram M. Adar"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.08113",
    "title": "Feynman Graph Integrals on $\\mathbb{C}^d$",
    "abstract": "We introduce a type of graph integrals which are holomorphic analogs of configuration space integrals. We prove their (ultraviolet) finiteness by considering a compactification of the moduli space of graphs with metrics, and study their failure to be holomorphic.",
    "authors": [
      "Minghao Wang"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.24750",
    "title": "The critical temperature $T_{cr}$(Ising) is DS-computable",
    "abstract": "We show that the Dobrushin-Shlosman conditions CV for the uniqueness of the Gibbs state provide the exact value for the critical temperature of the d-dimensional Ising model.",
    "authors": [
      "Senya Shlosman"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.14727",
    "title": "Distances between pure quantum states induced by a distance matrix",
    "abstract": "With the help of a given distance matrix of size $n$, we construct an infinite family of distances $d_p$ (where $p \\geq 2$) on the complex projective space $\\mathbb{P}(\\mathbb{C}^n)$ modelling the space of pure states of an $n$-level quantum system. The construction can be seen as providing a natural way to isometrically embed any given finite metric space into the space of pure quantum states 'spanned' upon it. In order to show that the maps $d_p$ are indeed distance functions -- in particular, that they satisfy the triangle inequality -- we employ methods of analysis, multilinear algebra and convex geometry, obtaining a nontrivial auxiliary convexity result in the process. The paper significantly extends earlier work, resolving an important question about the geometry of quantum state space imposed by the quantum Wasserstein distances and solidifying the foundation for applications of distances $d_p$ in quantum information science.",
    "authors": [
      "Tomasz Miller",
      "Rafał Bistroń"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.12797",
    "title": "Moderate deviations in first-passage percolation for bounded weights",
    "abstract": "We investigate the moderate and large deviations in first-passage percolation (FPP) with bounded weights on $\\mathbb{Z}^d$ for $d \\geq 2$. Write $T(\\mathbf{x}, \\mathbf{y})$ for the first-passage time and denote by $\\mu(\\mathbf{u})$ the time constant in direction $\\mathbf{u}$. In this paper, we establish that, if one assumes that the sublinear error term $T(\\mathbf{0}, N\\mathbf{u}) - N\\mu(\\mathbf{u})$ is of order $N^\\chi$, then under some unverified (but widely believed) assumptions, for $\\chi < a < 1$, \\begin{align*} &\\mathbb{P}\\bigl(T(\\mathbf{0}, N\\mathbf{u}) > N\\mu(\\mathbf{u}) + N^a\\bigr) = \\exp{\\Big(-\\,N^{\\frac{d(1+o(1))}{1-\\chi}(a-\\chi)}\\Big)},\\end{align*} \\begin{align*} &\\mathbb{P}\\bigl(T(\\mathbf{0}, N\\mathbf{u}) < N\\mu(\\mathbf{u}) - N^a\\bigr) = \\exp{\\Big(-\\,N^{\\frac{1+o(1)}{1-\\chi}(a-\\chi)}\\Big)}, \\end{align*} with accompanying estimates in the borderline case $a=1$. Moreover, the exponents $\\frac{d}{1-\\chi}$ and $\\frac{1}{1-\\chi}$ also appear in the asymptotic behavior near $0$ of the rate functions for upper and lower tail large deviations. Notably, some of our estimates are established rigorously without relying on any unverified assumptions. Our main results highlight the interplay between fluctuations and the decay rates of large deviations, and bridge the gap between these two regimes. A key ingredient of our proof is an improved concentration via multi-scale analysis for several moderate deviation estimates, a phenomenon that has previously appeared in the contexts of two-dimensional last-passage percolation and two-dimensional rotationally invariant FPP.",
    "authors": [
      "Wai-Kit Lam",
      "Shuta Nakajima"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.00686",
    "title": "Ballistic particle transport and Drude weight in gases",
    "abstract": "Owing to the fact that the particle current operator in non-relativistic gases is proportional to the total momentum operator, the particle transport in such systems is always ballistic and fully characterized by a Drude weight $\\Delta$. The Drude weight can be calculated within linear response theory. It is given by the formula $\\Delta = 2 \\pi D$, where $D$ is the density of the gas. This holds in any dimension and for every equilibrium ensemble, in particular for generalized Gibbs ensembles that describe possible equilibrium states of isolated integrable quantum systems. In the canonical ensemble case, the Drude weight can be equivalently obtained from a generalized susceptibility related to the fluctuations of the conserved particle current. Such susceptibility can be rigorously calculated for the integrable Lieb-Liniger Bose gas in any generalized Gibbs ensemble using a generalized Yang-Yang thermodynamic formalism. The resulting expression agrees with a prediction made within the context of generalized hydrodynamics. It also allows us to see explicitly that, within truly generalized Gibbs ensembles, the conductivity related with the particle current is not determined by the corresponding current-current auto-correlation function.",
    "authors": [
      "Frank Göhmann",
      "Andreas Klümper",
      "Karol K. Kozlowski"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.23155",
    "title": "Homomorphism, substructure and ideal: Elementary but rigorous aspects of renormalization group or hierarchical structure of topological orders",
    "abstract": "We propose a general quantum Hamiltonian formalism of a renormalization group (RG) flow with an emphasis on generalized symmetry by interpreting the elementary relationship between homomorphism, quotient ring, and projection. In our formalism, the noninvertible nature of the ideal of a fusion ring realizing the generalized symmetry of an ultraviolet (UV) theory plays a fundamental role in determining condensation rules between anyons, resulting in the infrared (IR) theories. Our algebraic method applies to the domain wall problem in $2+1$ dimensional topologically ordered systems and the corresponding classification of $1+1$ dimensional gapped phase, for example. An ideal decomposition of a fusion ring provides a straightforward but strong constraint on the gapped phase with noninvertible symmetry and its symmetry-breaking (or emergent symmetry) patterns. Moreover, even in several specific homomorphisms connected under massless RG flows, less familiar homomorphisms appear, and we conjecture that they correspond to partially solvable models in recent literature. Our work demonstrates the fundamental significance of the abstract algebraic structure, ideal, for the RG in physics.",
    "authors": [
      "Yoshiki Fukusumi",
      "Yuma Furuta"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00856",
    "title": "On dissipation operators of Quantum Optics",
    "abstract": "We consider dissipation operators used in Quantum Optics for the description of quantum spontaneous emission in the context of damped driven Jaynes-Cummings equations. The equations describe quantised one-mode Maxwell field coupled to a two-level molecule. Our main result is the symmetry and nonpositivity of basic dissipation operator of Quantum Optics.",
    "authors": [
      "A.I. Komech",
      "E.A. Kopylova"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00913",
    "title": "Do quantum linear solvers offer advantage for networks-based system of linear equations?",
    "abstract": "In this exploratory numerical study, we assess the suitability of Quantum Linear Solvers (QLSs) toward providing a quantum advantage for Networks-based Linear System Problems (NLSPs). NLSPs naturally arise from graphs, and are of importance as they are connected to real-world applications. The achievable advantage with a QLS for an NLSP depends on the interplay between the scaling of condition number and sparsity of matrices associated with the graph family considered, as well as system size growth. We analyze 50 graph families and identify that within the scope of our study, only 4% of them exhibit prospects for an exponential advantage with the Harrow-Hassidim-Lloyd (HHL) algorithm relative to an efficient classical solver (best graphs), while about 20% of them show a polynomial advantage (better graphs). Furthermore, we report that some graph families graduate from offering no advantage with HHL to promising a polynomial advantage with improved algorithms such as the Childs-Kothari-Somma algorithm, while some other graph families exhibit futile exponential advantage. We introduce a unified graph superfamily and show the existence of infinite best and better graphs in it. We also conjecture the conditions under which one may visually examine a graph family and guess the prospects for an advantage. Finally, we very briefly touch upon some practical issues that may arise even if the aforementioned graph theoretic requirements are satisfied, including quantum hardware challenges.",
    "authors": [
      "Disha Shetty",
      "Supriyo Dutta",
      "Palak Chawla",
      "Akshaya Jayashankar",
      "Jordi Riu",
      "Jan Nogue",
      "K. Sugisaki",
      "V. S. Prasannaa"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22742",
    "title": "Non-local Dirichlet forms, Gibbs measures, and a Hodge theorem for Cantor sets",
    "abstract": "In this paper I study properties of the generators $\\triangle_\\gamma$ of non-local Dirichlet forms $\\mathcal{E}^\\mu_\\gamma$ on ultrametric spaces which are the path space of simple stationary Bratteli diagrams. The measures used to define the Dirichlet forms are taken to be the Gibbs measures $\\mu_\\psi$ associated to Hölder continuous potentials $\\psi$ for one-sided shifts. I also define a cohomology $H_{lc}(X_B)$ for $X_B$ which can be seen as dual to the homology of Bowen and Franks. Besides studying spectral properties of $\\triangle_\\gamma$, I show that for $\\gamma$ large enough (with sharp bounds depending on the diagram and the measure theoretic entropy $h_{\\mu_\\psi}$ of $\\mu_\\psi$) there is a unique harmonic representative of any class $c\\in H_{lc}(X_B)$.",
    "authors": [
      "Rodrigo Treviño"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03403",
    "title": "Transient chaos and Rayleigh particle escape out of a time modulated optical trap",
    "abstract": "We consider Rayleigh particles in a periodically modulated optical trap formed by two counter-propagating Gaussian beams. It is shown that for certain values of parameters the system exhibits transient chaos which manifests itself in particle acceleration and subsequent directional ejection out of the trap. The escape flights are terminated at the distance of hundreds wavelengths from the trap centrum and the particles return to the trap under the action of the Stokes force. The particle escape is shown to be a threshold effect that can be potentially employed for particle sorting.",
    "authors": [
      "E.N. Bulgakov",
      "K.N. Pichugin",
      "D.N. Maksimov"
    ],
    "primary_category": "nlin.CD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03600",
    "title": "Explosive synchronization in networks of Type-I neurons with electrical synapses",
    "abstract": "Explosive synchronization (ES), which was observed in the scale-free network of the Kuramoto model, has been studied widely in the oscillator model. However, investigations of ES in neuronal networks, in spite of their importance in neuroscience, are limited and restricted to specific models. In this work, we explore the nature of the transition to synchronization in a class of neurons, namely Type-I neurons. Leveraging the mapping between Type-I neurons and the Kuramoto model, we investigate whether the conditions known to induce ES in the Kuramoto model also do so in Type-I neurons. The neurons are coupled through electrical synapses and placed on a scale-free and star networks with complete and partial degree-frequency correlation conditions. Our simulations show ES in networks of Quadratic Integrate and Fire (QIF) neurons, the normal form of Type-I neurons, under weak heterogeneity. We further confirm this phenomenon in networks of Morris-Lecar neurons, in the regime of Type-I excitability, under similar conditions to the QIF neurons. Thus, this work establishes a set of universal conditions that allows ES to arise in Type-I neurons.",
    "authors": [
      "Akshay S Harish",
      "Gaurav Dar"
    ],
    "primary_category": "nlin.AO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03871",
    "title": "Adaptive Parameter Control Using AAN for Lower Limb Rehabilitation Exoskeletons",
    "abstract": "Exoskeletons play a crucial role in assisting patients with varying mobility levels during rehabilitation. However, existing control strategies face challenges such as imprecise trajectory tracking, interaction torque oscillations, and limited adaptability to diverse patient conditions. To address these issues, this paper proposes an assist-as-needed (AAN) control algorithm that integrates a human-robot coupling dynamics model, a human torque-momentum observer (HTMO), and an adaptive parameter controller (APC). The algorithm first employs inverse dynamics to compute the joint torques required for the rehabilitation trajectory. The HTMO then estimates the torque exerted by the patient's joints and determines the torque error, which the exoskeleton compensates for via a spring-damper system, ultimately generating the target trajectory. Finally, the APC ensures adaptive assistive control. The proposed method is validated for its effectiveness in MATLAB/Simulink.",
    "authors": [
      "Zheng Sun",
      "Wenkong Wang",
      "Zizhong Wei",
      "Xin Ma"
    ],
    "primary_category": "nlin.CD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03344",
    "title": "Optical feedback induced irregular and chaotic dynamics in terahertz quantum cascade laser combs",
    "abstract": "In this work, we systematically investigate the optical feedback dynamics of terahertz (THz) frequency combs generated from quantum cascade lasers (QCLs) using the effective semiconductor Maxwell-Bloch equations (ESMBEs). Starting from a free-running comb state at low bias (1.3Ith), we identify clear bifurcation routes as the external feedback is increased. In the weak feedback regime (C<1), the frequency comb operation remains stable; as feedback increases to the moderate feedback regime (1<C<2.4), the system transitions through frequency splitting into period-one (P1) oscillations around each comb, followed by higher-order bifurcations (P2, P4, P8). Within the range 2.4<C<13.86, only combs with P1 states are observed, with the split frequency increasing continuously with feedback strength. In the strong feedback regime (C>13.86), complex feedback dynamics re-emerged but with significantly reduced complexity compared with the weak feedback regime. More interestingly, we show that optical feedback can induce chaotic THz emission at higher bias current conditions (>1.6Ith), when the free-running laser output (C=0) is originally a stable frequency comb. The resulting chaotic dynamics, characterized by broadband spectra and large positive Lyapunov exponents, are shown to depend strongly on the linewidth enhancement factor. Although THz QCLs widely considered as ultrastable under external perturbations, this work provides the first detailed report of chaotic dynamics and routes to chaos in THz QCLs under optical feedback. These findings not only deepen the understanding of nonlinear dynamics in THz QCLs but also open new possibilities for exploiting applications of chaotic light in THz sensing, imaging and secure communications.",
    "authors": [
      "Xiaoqiong Qi",
      "Carlo Silvestri",
      "Thomas Taimre",
      "Aleksandar D. Rakic"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.13544",
    "title": "Controlled manipulation of solitons in a recirculating fiber loop using external potentials",
    "abstract": "Optical solitons are self-sustained wave packets that propagate without distortion due to a balance between dispersion and nonlinearity. Their unique stability underpins key photonic applications while also playing a central role in nonlinear wave physics. However, real-time control over soliton dynamics in non-dissipative systems remains a major challenge, limiting their practical applications in photonic systems. Here, we introduce a fiber-based platform for soliton manipulation, by creating programmable external potentials through synchronous arbitrary phase modulation in a recirculating optical fiber loop. We demonstrate precise soliton trapping, parametric excitation, and coupled multi-soliton interactions, revealing particle-like behavior in excellent agreement with a Hamiltonian description in which solitons are treated as interacting classical particles. The strong analogy with matter-wave solitons in Bose-Einstein condensates highlights the broader implications of our approach, which provides a versatile experimental tool for the study of nonlinear wave dynamics and engineered soliton manipulation.",
    "authors": [
      "François Copie",
      "Pierre Suret",
      "Stéphane Randoux"
    ],
    "primary_category": "nlin.PS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.11189",
    "title": "Deterministic coherence and anti-coherence resonances in two coupled Lorenz oscillators: numerical study versus experiment",
    "abstract": "We demonstrate the deterministic coherence and anti-coherence resonance phenomena in two coupled identical chaotic Lorenz oscillators. Both effects are found to occur simultaneously when varying the coupling strength. In particular, the occurrence of deterministic coherence resonance is revealed by analysing time realizations $x(t)$ and $y(t)$ of both oscillators, whereas the anti-coherence resonance is identified when considering oscillations $z(t)$ at the same parameter values. Both resonances are observed when the coupling strength does not exceed a threshold value corresponding to complete synchronization of the interacting chaotic oscillators. In such a case, the coupled oscillators exhibit the hyperchaotic dynamics associated with the on-off intermittency. The highlighted effects are studied in numerical simulations and confirmed in physical experiments, showing an excellent correspondence and disclosing thereby the robustness of the observed phenomena.",
    "authors": [
      "Pavel S. Komkov",
      "Ol'ga I. Moskalenko",
      "Vladimir V. Semenov",
      "Sergei V. Grishin"
    ],
    "primary_category": "nlin.CD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.19860",
    "title": "Diversity mitigates polarization and consensus in opinion dynamics",
    "abstract": "We study the opinion dynamics in a population by considering a variant of Kuramoto model where the phase of an oscillator represents the opinion of an individual on a single topic. Two extreme phases separated by $\\pi$ represent opposing views. Any other phase is considered as an intermediate opinion between the two extremes. The interaction (or attitude) between two individuals depends on the difference between their opinions and can be positive (attractive) or negative (repulsive) based on the defined thresholds. We investigate the opinion dynamics when these thresholds are varied. We observe explosive transition from a bipolarized state to a consensus state with the existence of scattered and tri-polarized states at low values of threshold parameter. The system exhibits multistability between various states in a sizeable parameter region. These transitions and multistability are studied in populations with different degrees of diversity represented by the width of conviction distribution. We found that a more homogeneous population has greater tendency to exhibit bipolarized, tri-polarized and clustered states while a diverse population helps mitigate polarization among individuals by reaching to a consensus sooner. Ott-Antonsen analysis is used to analyse the system's long term macroscopic behaviour and verify the numerical results. We also study the effects of neutral individuals that do not interact with others or do not change their attitude on opinion formation, nature of transitions and multistability. Furthermore, we apply our model to language data to study the assimilation of diverse languages in India and compare the results with those obtained from model equations.",
    "authors": [
      "Sidharth Pradhan",
      "Sangeeta Rani Ujjwal"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03493",
    "title": "Precision Measurements of Kinematic Scan for Fluctuations of (Net-)proton Multiplicity Distributions in Au+Au Collisions from RHIC-STAR",
    "abstract": "This work presents measurements of the rapidity-window dependence of event-by-event net-proton cumulants and proton factorial cumulants in Au+Au collisions at $\\sqrt{s_\\mathrm{NN}}=$7.7 -- 27 GeV, using high-statistics data from RHIC BES-II. Protons and antiprotons are identified with improved detector performance within $0.4<p_\\mathrm{T}<2.0$ GeV/$c$ and $|y|<0.6$, enabling a wide coverage in momentum space to probe long-range correlations near the QCD critical point. In the most central collisions, the proton number $\\kappa_2/\\kappa_1$ and $\\kappa_3/\\kappa_1$ exhibit power-law scaling with the rapidity window, but with exponents below the theoretical expectation, suggesting that the critical point, if it exists, may lie at higher baryon densities. A finite-size scaling analysis of the susceptibility and Binder cumulant study points out a critical baryon chemical potential region in 550 -- 650 MeV.",
    "authors": [
      "Yige Huang",
      "STAR Collaboration"
    ],
    "primary_category": "nucl-ex",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03711",
    "title": "Compton suppressed scintillation spectrometer based on a cluster of 9$\\times$CeBr$_{3}$-NaI(Tl) phoswich detectors",
    "abstract": "Measurements of the characteristics of an Compton suppressed spectrometer consisting of 9$\\times$CeBr$_{3}$-NaI(Tl) phoswich detectors surrounded by four CsI(Tl) scintillation detectors intended for suppressing the Compton component of the spectrum have been carried out. Measurements were performed using gamma and neutron radiation sources. Key parameters of the spectrometer have been determined: the suppression factor of the Compton part of the $\\gamma$-spectrum, as well as the dependencies of the neutron detection efficiency on their energy at various detection threshold values.",
    "authors": [
      "Mark Povolotskiy",
      "Yuri Sobolev",
      "Sergei Stukalov"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20315",
    "title": "Understanding the correlation between elliptic and triangular flow",
    "abstract": "The relative correlation between the magnitudes of elliptic flow ($v_2$) and triangular flow ($v_3$) has been accurately measured in nucleus-nucleus collisions at the LHC collider. As a function of the centrality of the collision, it changes sign and varies non-monotonically. We show that this is naturally explained by two combined effects. The first effect is a skewness in initial-state fluctuations, which is quantified by the correlation between the geometry-driven elliptic deformation in the reaction plane and the fluctuation-driven triangularity $\\varepsilon_3$. We introduce an intensive measure of this skewness, which is generically of order unity and depends weakly on the system size and centrality. We evaluate its magnitude using Monte Carlo simulations of the initial state, which show that it is sensitive to the nucleon width. The second effect is the fluctuation of impact parameter relative to centrality classifiers used by experiment. The ATLAS collaboration uses two different centrality classifiers, the multiplicity $N_{ch}$ and the transverse energy $E_T$. We fit both sets of results for Pb+Pb collisions up to $\\approx 40\\%$ centrality with a single parameter, the intensive mixed skewness. Its value inferred from experiment agrees with theoretical expectations.",
    "authors": [
      "Mubarak Alqahtani",
      "Jean-Yves Ollitrault"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04005",
    "title": "Validating a Machine Learning Approach to Identify Quenched Jets in Heavy-Ion Collisions",
    "abstract": "Jet quenching is a phenomenon in heavy-ion collisions arising from jet interactions with the quark-gluon plasma (QGP). Its study is complicated by the interplay of multiple physics processes that affect jet observables. In addition, detector effects may influence the results and must be accounted for when identifying quenched jets. We employ a Long Short-Term Memory (LSTM) neural network trained on jet substructure, incorporating parton shower history, to predict jet-by-jet quenching levels. Using photon-jet samples from the \\textsc{Jewel} event generator, we show that the LSTM predictions strongly correlate with true jet energy loss. This validates that the model effectively learns the features of jet-QGP interaction. We simulate detector effects using \\textsc{Delphes} simulation framework and demonstrate that the method identifies quenching effects in a realistic environment. We test the approach with photon-jet momentum imbalance, jet fragmentation function, and jet shape, which were not included in the training, confirming its ability to distinguish true quenching features.",
    "authors": [
      "Yilun Wu",
      "Yi Chen",
      "Julia Velkovska"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13997",
    "title": "Light-Front Transverse Nucleon Charge and Magnetisation Densities",
    "abstract": "Nucleon elastic electromagnetic form factors obtained using both the three-body and quark + fully-interacting-diquark pictures of nucleon structure are employed to calculate an array of light-front transverse densities for the proton and neutron and their dressed valence-quark constituents, viz. flavour separations of the proton and neutron results. These two complementary descriptions of nucleon structure deliver mutually compatible predictions, which match expectations based on modern parametrisations of available data, where such are available. Amongst other things, it is found that transverse-plane valence $u$- and $d$-quark Dirac radii are practically indistinguishable; but regarding kindred Pauli radii, the $d$ quark value is roughly 10% greater than that of the $u$-quark. Moreover, magnetically, the valence $d$ quark is far more active than the valence $u$ quark, probably because it has much greater orbital angular momentum. Both pictures of nucleon structure agree in predicting that, in a polarised nucleon, the transverse-plane charge densities are no longer rotationally invariant. Instead, for a $+\\hat x$ polarised nucleon, positive charge is displaced in the $+\\hat y$ direction, with the opposite effect for negative charge.",
    "authors": [
      "Z.-N. Xu",
      "Z.-Q. Yao",
      "P. Cheng",
      "C. D. Roberts",
      "J. Rodriguez-Quintero",
      "J. Segovia"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03206",
    "title": "Astrophysical Reaction Rates for Charged-Particle Induced Reactions on Proton-Rich Nuclides",
    "abstract": "Astrophysical reaction rates for reactions with proton-rich nuclides from stability to the proton dripline were calculated with an updated version of the SMARAGD statistical model (Hauser-Feshbach) code. Here, the focus was on reactions with protons or $\\alpha$ particles as required for nucleosynthesis in proton-rich matter. For completeness, also neutron-induced reactions are provided for the same set of targets. Some comments on dependencies of rates on various nuclear properties and on the appropriate way to compare to experiments are given. The new rate set for charged-particle induced reactions provides a better description of experimental data than previously widely used rates, especially for reactions involving $\\alpha$ particles.",
    "authors": [
      "Thomas Rauscher"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03675",
    "title": "Initial state and evolution of hot and dense medium produced in isobaric collisions at 200A GeV at RHIC",
    "abstract": "Isobaric collisions provide a unique opportunity to investigate how variations in the charge to mass ratio affect the final state observables produced in relativistic heavy ion collisions. Most importantly, isobaric systems that differ in their nuclear structure offer valuable insights into the underlying nuclear geometries, making them powerful tools to probe the role of nuclear structure using heavy ion collisions. We study the initial state and evolution of the hot and dense medium formed in Ru+Ru and Zr+Zr collisions at 200A GeV at RHIC using a relativistic hydrodynamical model. The initial geometry of the two isobaric collisions is found to influence the evolution of the hot and dense medium produced. The sensitivity of photon production, charged particle spectra and anisotropic flow coefficients ($v_n$) to the initial geometry, including different orientations of the isobaric set have been studied in detail. Significant variations in anisotropic flow of photons and hadrons are observed, highlighting the role of nuclear deformation in shaping final state observables. Moreover, photon anisotropic flow is found to be considerably more sensitive to the initial state than charged particle anisotropic flow, indicating that photon measurements in isobaric collisions have strong potential to constrain initial state modeling and improve our understanding of QGP properties in such systems.",
    "authors": [
      "Amit Paul",
      "Rupa Chatterjee"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03776",
    "title": "Impact of octupole deformation on the nuclear electromagnetic response",
    "abstract": "Background: Properties of giant dipole resonances (GDRs), along with other nuclear resonances, provide valuable tools for refining theoretical models as they reflect collective features of nuclear matter. Among such collective phenomena is octupole deformation, whose impact on resonance features, however, is less studied. Purpose: Investigate the effect of reflection-symmetry-breaking octupole deformation on electric and magnetic transition strengths in atomic nuclei. Methods: Calculations were performed using linear response theory with the iterative finite amplitude method (FAM) to solve quasiparticle random phase approximation (QRPA)-type equations. Underlying ground-state solutions were obtained within the framework of axially symmetric Skyrme-Hartree-Fock-Bogoliubov (HFB) using three different Skyrme functionals. Results: Electric and magnetic multipole responses were calculated for octupole-deformed even-even Rn, Ra, Th, U, Pu, and Cm isotopes. Calculations were performed on top of two distinct deformed ground-state solutions: one constrained to conserve parity, and the other allowing parity breaking. Sum rules were calculated from $M1$ transition strengths and compared with the expected correlations to certain ground-state properties. Conclusions: Based on our results, the octupole deformation has only a modest effect on the transition strengths in the resonances. In turn, $M1$ transition strengths have a greater effect at lower energies (0-8 MeV), which encourages further investigation. Isoscalar $E3$ transition strength was confirmed to have a significant contribution from the rotational Nambu-Goldstone (NG) mode in the parity-breaking HFB solution, and thus, removing it was found necessary.",
    "authors": [
      "Manu Kanerva",
      "Markus Kortelainen"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03876",
    "title": "Generalized Beth--Uhlenbeck entropy formula from the $Φ-$derivable approach",
    "abstract": "We derive a generalized Beth-Uhlenbeck formula for the entropy of a dense fermion system with strong two-particle correlations, including scattering states and bound states. We work within the $\\Phi-$derivable approach to the thermodynamic potential. The formula takes the form of an energy-momentum integral over a statistical distribution function times a unique spectral density. In the near mass-shell limit, the spectral density reduces, contrary to naïve expectations, not to a Lorentzian but rather to a \"squared Lorentzian\" shape. The relation of the Beth-Uhlenbeck formula to the $\\Phi$-derivable approach is exact at the two-loop level for $\\Phi$. The formalism we develop, which extends the Beth-Uhlenbeck approach beyond the low-density limit, includes Mott dissociation of bound states, in accordance with Levinson's theorem, and the self-consistent back reaction of correlations in the fermion propagation. We discuss applications to further systems, such as quark matter and nuclear matter.",
    "authors": [
      "David Blaschke",
      "Gerd Röpke",
      "Gordon Baym"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03157",
    "title": "Effective Field Theory Perspective On King Non-linearity",
    "abstract": "Precision spectroscopic measurements of isotope shifts have recently reached a high level of accuracy. Tests of King non-linearity (NL) along isotope chains have been proposed as a tool to search for fifth-force mediators. At the same time, these tests can potentially teach us about the structure of heavy nuclei at unprecedented precision, where King NL has already been observed in several systems. A robust interpretation of the existing data, however, is hampered by incomplete control over the Standard Model (SM) contributions. We develop a systematic effective field theory framework, matching the SM onto scalar non-relativistic QED in the infinite nuclear mass limit and then onto quantum-mechanical potentials. This approach organizes all nuclear effects into a small set of Wilson coefficients and cleanly separates short- and long-distance physics. We show that the commonly used treatment of the $\\langle r^2\\rangle^2$ term needs to be reconsidered, as it arises only at second-order in perturbation theory, and we derive the long-range $1/r^4$ potential from nuclear polarizability. Applying the framework to hydrogen-like systems, we provide a transparent classification of SM sources of King NL relevant for current and future isotope-shift experiments. The formalism can be applied to learn about the shape of the heavy scalar nuclei at a higher level of precision and detail than what was previously attainable.",
    "authors": [
      "Benoît Assi",
      "Sam Carey",
      "Sebastian Jäger",
      "Gabriel Lee",
      "Gil Paz",
      "Gilad Perez",
      "Jure Zupan"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03614",
    "title": "Real-time evolution of critical modes in the QCD phase diagram",
    "abstract": "A QCD-assisted relaxation dynamic model for the critical mode of the critical end point (CEP) in the QCD phase diagram is developed, which allows us to investigate the critical slowing down effect quantitatively in the QCD phase diagram, especially in the proximity of the CEP, without any phenomenological parameters. The relaxation time from nonequilibrium to equilibrium in the QCD phase diagram is extracted from the Langevin simulations of the QCD-assisted relaxation dynamic model. It is found that in a narrow region along the phase boundary radiated from the CEP, the relaxation time is enhanced significantly. Outside this narrow region, the relaxation time drops drastically, which implies that the dynamic critical region is small in the QCD phase diagram. We also find that the effects of critical slowing down are mild on the chemical freeze-out curves.",
    "authors": [
      "Yang-yang Tan",
      "Shi Yin",
      "Yong-rui Chen",
      "Chuang Huang",
      "Wei-jie Fu"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03894",
    "title": "Kinetic Mixing and Axial Charges in the Parity-Doublet Model",
    "abstract": "The standard parity doublet model with its mass-mixing mechanism fails to describe the axial charge $g_A$ of the nucleon. While $g_A = 1$ in the original Gell-Mann--Levy model, which reproduces the Adler-Bell-Jackiw anomaly of QCD, in the presence of a chirally invariant baryon mass the mass mixing leads to $g_A < 1 $ whereas phenomenologically it is about 1.28. We propose to remedy this problem by introducing kinetic-mixing terms corresponding to meson-baryon derivative couplings, similar in spirit to the two-mixing-angle scenario of the $\\eta$-$\\eta'$ mixing. This extended parity doublet model contains five parameters in the effective baryonic Lagrangian. Three of them can be determined by using the empirical results for the axial charge of the nucleon together with the masses of the nucleon and its parity partner, the $N^*(1535)$ resonance. We discuss various options how to determine the remaining parameters, touching upon the mass of both parity partners if the chiral condensate is put to zero; the mass of the nucleon in the chiral limit; and the values of meson-baryon coupling constants related to the decays of the resonance to pion-nucleon and sigma-nucleon.",
    "authors": [
      "Christian Kummer",
      "Stefan Leupold",
      "Lorenz von Smekal"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.16587",
    "title": "Effect of spin polarization on transport and thermodynamic properties",
    "abstract": "Spin polarization provides a novel probe of the rotational properties of the quark-gluon plasma (QGP) formed in relativistic heavy-ion collisions. We investigate the effective transport and thermodynamic coefficients in non-central O+O collisions, employing a parton distribution function that incorporates spin polarization induced by thermal vorticity. Within a kinetic theory framework, we find that the magnitude of the squared speed of sound ($c_s^2$) is only weakly modified by spin polarization, whereas the specific shear viscosity ($\\eta/s$), specific bulk viscosity ($\\zeta/s$), and mean free path ($\\lambda$) show substantial changes. When spin polarization is included, both $c_s^2$ and $\\zeta/s$ develop a nonmonotonic dependence on the collision energy, with an inflection point near $\\sqrt{s_{NN}}=27$ GeV, corresponding to an average parton chemical potential of $\\langle\\mu_p\\rangle=0.021$ GeV. These results suggest that spin polarization may serve as a useful probe for constraining the effective equation of state of QCD matter.",
    "authors": [
      "De-Xian Wei"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20315",
    "title": "Understanding the correlation between elliptic and triangular flow",
    "abstract": "The relative correlation between the magnitudes of elliptic flow ($v_2$) and triangular flow ($v_3$) has been accurately measured in nucleus-nucleus collisions at the LHC collider. As a function of the centrality of the collision, it changes sign and varies non-monotonically. We show that this is naturally explained by two combined effects. The first effect is a skewness in initial-state fluctuations, which is quantified by the correlation between the geometry-driven elliptic deformation in the reaction plane and the fluctuation-driven triangularity $\\varepsilon_3$. We introduce an intensive measure of this skewness, which is generically of order unity and depends weakly on the system size and centrality. We evaluate its magnitude using Monte Carlo simulations of the initial state, which show that it is sensitive to the nucleon width. The second effect is the fluctuation of impact parameter relative to centrality classifiers used by experiment. The ATLAS collaboration uses two different centrality classifiers, the multiplicity $N_{ch}$ and the transverse energy $E_T$. We fit both sets of results for Pb+Pb collisions up to $\\approx 40\\%$ centrality with a single parameter, the intensive mixed skewness. Its value inferred from experiment agrees with theoretical expectations.",
    "authors": [
      "Mubarak Alqahtani",
      "Jean-Yves Ollitrault"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.01682",
    "title": "Conservation, crossing symmetry, and completeness in diagrammatic theories",
    "abstract": "The diagrammatic analysis of interacting particle assemblies harbors a fundamental mismatch between two of its main implementations: Phi-derivable (conserving) approximations and parquet (crossing symmetric) models. No termwise expansion, short of the exact theory itself, can be both conserving and crossing symmetric. This work applies the Kraichnan embedded-Hamiltonian formalism for strongly coupled systems to investigate consistency of the interplay between purely pair-mediated correlations and pair-irreducible ones. The approach sheds a different light on the issue of crossing symmetry versus conservation. In the process, the parquet equations acquire a different formulation.",
    "authors": [
      "Frederick Green"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.02923",
    "title": "Stabilizer-Accelerated Quantum Many-Body Ground-State Estimation",
    "abstract": "We investigate how the stabilizer formalism, in particular highly-entangled stabilizer states, can be used to describe the emergence of many-body shape collectivity from individual constituents, in a symmetry-preserving and classically efficient way. The method that we adopt is based on determining an optimal separation of the Hamiltonian into a stabilizer component and a residual part inducing non-stabilizerness. The corresponding stabilizer ground state is efficiently prepared using techniques of graph states and stabilizer tableaux. We demonstrate this technique in context of the Lipkin-Meshkov-Glick model, a fully-connected spin system presenting a second order phase transition from spherical to deformed state. The resulting stabilizer ground state is found to capture to a large extent both bi-partite and collective multi-partite entanglement features of the exact solution in the region of large deformation. We also explore several methods for injecting non-stabilizerness into the system, including ADAPT-VQE, and imaginary-time evolution (ITE) techniques. Stabilizer ground states are found to accelerate ITE convergence due to a larger overlap with the exact ground state. While further investigations are required, the present work suggests that collective features may be associated with high but simple large-scale entanglement which can be captured by stabilizer states, while the interplay with single-particle motion may be responsible for inducing non-stabilizerness. This study motivates applications of the proposed approach to more realistic quantum many-body systems, whose stabilizer ground states can be used in combinations with powerful classical many-body techniques and/or quantum methods.",
    "authors": [
      "Caroline E. P. Robin"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13997",
    "title": "Light-Front Transverse Nucleon Charge and Magnetisation Densities",
    "abstract": "Nucleon elastic electromagnetic form factors obtained using both the three-body and quark + fully-interacting-diquark pictures of nucleon structure are employed to calculate an array of light-front transverse densities for the proton and neutron and their dressed valence-quark constituents, viz. flavour separations of the proton and neutron results. These two complementary descriptions of nucleon structure deliver mutually compatible predictions, which match expectations based on modern parametrisations of available data, where such are available. Amongst other things, it is found that transverse-plane valence $u$- and $d$-quark Dirac radii are practically indistinguishable; but regarding kindred Pauli radii, the $d$ quark value is roughly 10% greater than that of the $u$-quark. Moreover, magnetically, the valence $d$ quark is far more active than the valence $u$ quark, probably because it has much greater orbital angular momentum. Both pictures of nucleon structure agree in predicting that, in a polarised nucleon, the transverse-plane charge densities are no longer rotationally invariant. Instead, for a $+\\hat x$ polarised nucleon, positive charge is displaced in the $+\\hat y$ direction, with the opposite effect for negative charge.",
    "authors": [
      "Z.-N. Xu",
      "Z.-Q. Yao",
      "P. Cheng",
      "C. D. Roberts",
      "J. Rodriguez-Quintero",
      "J. Segovia"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03051",
    "title": "Harmonic Extension for Multiscale Analysis and Modeling Near Boundaries, with an Ocean Application",
    "abstract": "Treatment of fields near domain boundaries is a long-standing problem in signal processing that has come into renewed focus following recent efforts in convolution-based multiscale coarse-graining and in machine-learned parameterizations due to ocean boundary artifacts. Here, we propose a general method for extending fields beyond the domain boundaries by solving a Laplace boundary-value problem. Construction of the harmonic extension is well-posed, including uniqueness, and is consistent with the boundary conditions by design. The formulation applies to irregular boundaries such as discretized coastlines. The harmonic extension is physically desirable since it has minimum spatial variability among all admissible extensions satisfying the boundary conditions. The method is simple to implement using well-established numerical approaches, and is broadly applicable to extending oceanic variables over land boundaries. Other applications include machine learning parametrization and subgrid modeling of wall-bounded flows and multiphase flows. We demonstrate the method by extending sea-surface temperature (SST) over land using fixed temperature (Dirichlet) and no-flux (Neumann) boundary conditions: the land-filled solution is smooth with SST values between the coastal minimum and maximum.",
    "authors": [
      "Benjamin A. Storer",
      "Mehrnoush Kharghani",
      "Alistair Adcroft",
      "Hussein Aluie"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03066",
    "title": "The Iris Illusion in the Tropical Sky Seen Through Two Decades of Aura MLS Ice Water Contents",
    "abstract": "I analyzed ice water content (IWC) data from the Aura Microwave Limb Sounder (MLS) and sea surface temperature (SST) data from NOAA's Optimum Interpolation SST (OISST) product from 2004 to 2024. Using these data, I derived monthly infrared (IR) leakage over the tropics and computed derivatives of both the IR leakage and tropical SST time series from 2005 to 2023. These two derivatives produced a Pearson correlation of -0.49, indicating that IR leakage decreases when SST increases. This behavior contradicts the trend predicted by the Iris hypothesis, suggesting that tropical cirrus clouds strengthen, rather than weaken, as the ocean warms.",
    "authors": [
      "Yiguo Zhang"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03080",
    "title": "AtomDisc: An Atom-level Tokenizer that Boosts Molecular LLMs and Reveals Structure--Property Associations",
    "abstract": "Advances in large language models (LLMs) are accelerating discovery in molecular science. However, adapting molecular information to the serialized, token-based processing of LLMs remains a key challenge. Compared to other representations, molecular graphs explicitly encode atomic connectivity and local topological environments, which are key determinants of atomic behavior and molecular properties. Despite recent efforts to tokenize overall molecular topology, there still lacks effective fine-grained tokenization of local atomic environments, which are critical for determining sophisticated chemical properties and reactivity. To address these issues, we introduce AtomDisc, a novel framework that quantizes atom-level local environments into structure-aware tokens embedded directly in LLM's token space. Our experiments show that AtomDisc, in a data-driven way, can distinguish chemically meaningful structural features that reveal structure-property associations. Equipping LLMs with AtomDisc tokens injects an interpretable inductive bias that delivers state-of-the-art performance on property prediction and molecular generation. Our methodology and findings can pave the way for constructing more powerful molecular LLMs aimed at mechanistic insight and complex chemical reasoning.",
    "authors": [
      "Mingxu Zhang",
      "Dazhong Shen",
      "Ying Sun"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03081",
    "title": "Calibrating Geophysical Predictions under Constrained Probabilistic Distributions",
    "abstract": "Machine learning (ML) has shown significant promise in studying complex geophysical dynamical systems, including turbulence and climate processes. Such systems often display sensitive dependence on initial conditions, reflected in positive Lyapunov exponents, where even small perturbations in short-term forecasts can lead to large deviations in long-term outcomes. Thus, meaningful inference requires not only accurate short-term predictions, but also consistency with the system's long-term attractor that is captured by the marginal distribution of state variables. Existing approaches attempt to address this challenge by incorporating spatial and temporal dependence, but these strategies become impractical when data are extremely sparse. In this work, we show that prior knowledge of marginal distributions offers valuable complementary information to short-term observations, motivating a distribution-informed learning framework. We introduce a calibration algorithm based on normalization and the Kernelized Stein Discrepancy (KSD) to enhance ML predictions. The method here employs KSD within a reproducing kernel Hilbert space to calibrate model outputs, improving their fidelity to known physical distributions. This not only sharpens pointwise predictions but also enforces consistency with non-local statistical structures rooted in physical principles. Through synthetic experiments-spanning offline climatological CO2 fluxes and online quasi-geostrophic flow simulations-we demonstrate the robustness and broad utility of the proposed framework.",
    "authors": [
      "Zhewen Hou",
      "Jiajin Sun",
      "Subashree Venkatasubramanian",
      "Peter Jin",
      "Shuolin Li",
      "Tian Zheng"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03090",
    "title": "Digital Surfactant",
    "abstract": "Surfactants play an important role in determining the cleaning performance and stability of detergents. However, the design of new surfactants using traditional methods is often time-consuming, complex, and largely based on trial and error. Recent studies have incorporated data-driven and computational approaches to generate new surfactants and predict properties of surfactants, but most of these approaches either optimize on a single property or train on a small number of surfactants. In this work, we investigate the generative capabilities of an existing graph diffusion based inverse design model and a transformer based molecule optimization model, for non-ionic surfactants. We train both models to generate non-ionic surfactants based on single- and multi-property values, predict the same properties o using trained property predictor models for generated molecules, and validate a few them using molecular dynamics simulations. Our results reveal that the inverse design model is better at generating a diverse set of molecules, while the transformer is better at generating molecules which satisfy input property constraints better. We also observe that molecules generated using single property condition, on average, satisfy the input property condition better when compared to molecules generated using multiple property conditions. From molecular dynamics simulations, we observe that the predicted properties of the selected molecules are close to the simulated results concluding that both methods are capable of generating surfactants that actually satisfy input property condtions.",
    "authors": [
      "Sayeedul I. Sheikh",
      "V. Subhasree Navya",
      "Riya Sharma",
      "Sudip Roy",
      "Jayant K. Singh"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03106",
    "title": "A portable LED-based diamond magnetometer for outreach and teaching labs",
    "abstract": "We present a compact, low-cost version of an NV center diamond magnetometer which replaces the standard green laser with a high-power LED. This modification improves safety, reduces cost, and allows the green excitation and red photoluminescence to be viewed directly during demonstrations. The device is simple to assemble and suitable for outreach activities and undergraduate laboratories. We show that it can produce ODMR spectra and respond to nearby magnetic objects, with a sensitivity on the order of 1 $\\mu$T/$\\sqrt{\\text{Hz}}$. Supplementary material provides details of the construction and suggestions for student investigations to support use in teaching laboratories.",
    "authors": [
      "Hollis Williams",
      "Alex Newman",
      "Stuart Graham",
      "Colin Stephen",
      "Gavin Morley"
    ],
    "primary_category": "physics.ed-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03119",
    "title": "An infrasound source analysis of the OSIRIS-REx sample return capsule hypersonic re-entry",
    "abstract": "The OSIRIS-REx sample return capsule hypersonic re-entry into the atmosphere is a rare opportunity to test a variety of sonic boom source models since the projectile dimensions are well characterized. While the as-flown flight path is unknown, the predicted flight path enables a rough approximation of the source Mach number and location. Six infrasound microphones deployed in the boom carpet along the predicted flight path recorded impulsive signals from the OSIRIS-REx re-entry. Using a suite of atmosphere profiles and the geometric acoustics approximation, we estimate locations with uncertainty estimates along the flight path from which the signals were emitted. Acoustic overpressure and signal duration predictions from Whitham's far field theory, Carlson's simplified sonic boom prediction method, and a drag-dominated hypersonic model are analyzed with uncertainty estimates from the location estimate. While the Carlson simplified sonic boom prediction method could be accurate, our preference is for the drag-dominated source model. Using this source model with an inviscid Burgers' equation solver for propagation, we obtained an excellent match to the recorded data. These results will help better inform future sample return capsule re-entry observation campaigns as well as contribute to a better understanding of high altitude infrasonic sources.",
    "authors": [
      "Jordan W. Bishop",
      "Philip Blom",
      "Chris Carr",
      "Jeremy Webster"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03149",
    "title": "A high-order regularized delta-Chebyshev method for computing spectral densities",
    "abstract": "We introduce a numerical method for computing spectral densities, and apply it to the evaluation of the local density of states (LDOS) of sparse Hamiltonians derived from tight-binding models. The approach, which we call the high-order delta-Chebyshev method, can be viewed as a variant of the popular regularized Chebyshev kernel polynomial method (KPM), but it uses a high-order accurate approximation of the $\\delta$-function to achieve rapid convergence to the thermodynamic limit for smooth spectral densities. The costly computational steps are identical to those for KPM, with high-order accuracy achieved by an inexpensive post-processing procedure. We apply the algorithm to tight-binding models of graphene and twisted bilayer graphene, demonstrating high-order convergence to the LDOS at non-singular points.",
    "authors": [
      "Jinjing Yi",
      "Daniel Massatt",
      "Andrew Horning",
      "Mitchell Luskin",
      "J. H. Pixley",
      "Jason Kaye"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03165",
    "title": "Energetic-particle orbits near rational flux surfaces in stellarators: I. Passing particles",
    "abstract": "Recent simulations have shown that, even when the magnetic field of a stellarator possesses nested toroidal flux surfaces, the orbits of passing energetic particles can exhibit islands. These 'drift islands' arise near rational flux surfaces, where they are likely to enhance alpha-particle transport -- flattening the alpha density profile locally -- unless they can be avoided by suitable design of the stellarator magnetic field. To investigate how this might be achieved, we derive an equation for the drift-island shape in a general stellarator. This result follows from the solution to a more fundamental problem: that of calculating the orbits of passing particles near a rational flux surface. We show that these orbits are determined by conservation of an adiabatic invariant associated with the closed rational-surface field lines. We use this 'transit adiabatic invariant' to prove that there are no drift islands, for all passing particles, if and only if the magnetic field satisfies a weaker version of the Cary-Shasharina condition for omnigeneity; we call such magnetic fields 'cyclometric'. The drift-island width scales as $\\sim (\\rho_\\star\\delta/s)^{1/2} a$ ($\\rho_\\star$ is the normalized gyroradius, $\\delta$ is the deviation from cyclometry, $s$ is the magnetic shear, and $a$ is the minor radius), so large drift islands could arise in low-shear stellarators that are insufficiently cyclometric. To ensure accurate results for very energetic particles, we compute higher-order corrections to the transit invariant. Our calculations agree extremely well with ASCOT5 guiding-centre and full-orbit simulations of alpha particles in reactor-scale equilibria, even at $3.5\\text{MeV}$. Finally, we show how our results can also be derived using Hamiltonian perturbation theory, which provides a systematic framework for calculating passing-particle orbits on both rational and irrational surfaces.",
    "authors": [
      "Thomas E. Foster",
      "Felix I. Parra",
      "Roscoe B. White",
      "José Luis Velasco",
      "Iván Calvo",
      "Elizabeth J. Paul"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03183",
    "title": "Role of boundary conditions and wall orientation on the transport of settling inertial particles in wall-bounded flows",
    "abstract": "Gravitational settling affects particle transport in turbulent flows in two ways; explicitly, by introducing a finite settling velocity, and implicitly, by modifying how the particles interact with the flow field. For wall-bounded flows, when the wall is horizontal (gravity perpendicular to the wall) both the explicit and implicit effects of settling impact the particle transport towards the wall, whereas when the wall is vertical (gravity parallel to the wall) only the implicit effect plays a role. Surprisingly, it was recently demonstrated that even when the settling parameter $Sv$ is very small, settling can play a very significant role in controlling the near-wall transport in a horizontal channel. In this paper, we use direct numerical simulations to explore how this finding is affected by the particle boundary conditions and whether it also occurs in vertical channels where only the implicit effect of settling plays a role. We show that the sensitivity of the particle transport to $Sv$ depends upon the particle boundary conditions, with elastic-collisions (that generate a zero mean particle flux) and absorbing-wall conditions (that generate a negative mean particle flux) exhibiting qualitatively and quantitatively different sensitivities to $Sv$. It is found that for vertical channels the impact of settling on the particle transport is in fact negligible if $Sv$ is small, and only becomes significant when $Sv\\geq O(1)$. Finally, we examine the physical mechanisms governing the settling velocity of particles in vertical channel flows, and find that low-speed streaks can play a significant role in suppressing the settling velocity of the particles near the walls, in contrast to the core region where the preferential sweeping mechanism leads to an enhancement of their settling velocity.",
    "authors": [
      "Y. Zhang",
      "D.H. Richter",
      "A.D. Bragg"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03216",
    "title": "Kaleidoscopic Scintillation Event Imaging",
    "abstract": "Scintillators are transparent materials that interact with high-energy particles and emit visible light as a result. They are used in state of the art methods of measuring high-energy particles and radiation sources. Most existing methods use fast single-pixel detectors to detect and time scintillation events. Cameras provide spatial resolution but can only capture an average over many events, making it difficult to image the events associated with an individual particle. Emerging single-photon avalanche diode cameras combine speed and spatial resolution to enable capturing images of individual events. This allows us to use machine vision techniques to analyze events, enabling new types of detectors. The main challenge is the very low brightness of the events. Techniques have to work with a very limited number of photons. We propose a kaleidoscopic scintillator to increase light collection in a single-photon camera while preserving the event's spatial information. The kaleidoscopic geometry creates mirror reflections of the event in known locations for a given event location that are captured by the camera. We introduce theory for imaging an event in a kaleidoscopic scintillator and an algorithm to estimate the event's 3D position. We find that the kaleidoscopic scintillator design provides sufficient light collection to perform high-resolution event measurements for advanced radiation imaging techniques using a commercial CMOS single-photon camera. Code and data are available at this https URL .",
    "authors": [
      "Alex Bocchieri",
      "John Mamish",
      "David Appleyard",
      "Andreas Velten"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03224",
    "title": "Modeling and simulation of electrodiffusion in dense reconstructions of cerebral tissue",
    "abstract": "Excitable tissue is fundamental to brain function, yet its study is complicated by extreme morphological complexity and the physiological processes governing its dynamics. Consequently, detailed computational modeling of this tissue represents a formidable task, requiring both efficient numerical methods and robust implementations. Meanwhile, efficient and robust methods for image segmentation and meshing are needed to provide realistic geometries for which numerical solutions are tractable. Here, we present a computational framework that models electrodiffusion in excitable cerebral tissue, together with realistic geometries generated from electron microscopy data. To demonstrate a possible application of the framework, we simulate electrodiffusive dynamics in cerebral tissue during neuronal activity. Our results and findings highlight the numerical and computational challenges associated with modeling and simulation of electrodiffusion and other multiphysics in dense reconstructions of cerebral tissue.",
    "authors": [
      "Halvor Herlyng",
      "Marius Causemann",
      "Gaute T. Einevoll",
      "Ada J. Ellingsrud",
      "Geir Halnes",
      "Marie E. Rognes"
    ],
    "primary_category": "physics.med-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03236",
    "title": "Real-Time Adaptive Feedback Control of a Supersonic Dual-Stream Jet",
    "abstract": "Adaptive control is applied to a supersonic dual-stream jet flow comprised of Mach 1.6 core and Mach 1.0 bypass streams that mix to form a supersonic shear layer. The vortices shed are the source of a high-frequency tone that persists throughout the flow. The intricate flow dynamics motivates the need for an elaborate and efficient actuation system to suppress the tone and weaken the propagating shock train. The present work utilizes online dynamic mode decomposition, which estimates the system dynamics as a locally linear evolution. Snapshot matrices are constructed using sensor measurements, facilitating economical and real-time computations, which are continuously updated and used in a feedback control model. Adaptive control is found to efficiently target the resonant tone with little disturbance to the mean features. The framework is not sensitive to sensor placements, enabling actuator design under physically realizable spatial locations in practical implementation. To reflect physical limitations, constraints are imposed on the controller model. It is found that the restricted controller yields greater vortex suppression due to repeated transitory stabilization of the shear layer instability. Statistical analysis reveals intermittent low-pressure events are responsible for the characteristic frequency, which are largely suppressed by adaptive feedback control.",
    "authors": [
      "Melissa Yeung",
      "Yiyang Sun"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03240",
    "title": "Models of Flow through Porous Media of Polar Fluids with Pressure-Dependent Viscosity",
    "abstract": "Equations governing the flow of a polar fluid, with pressure-dependent Newtonian viscosity, through a variable-porosity medium are developed. Averaged equations are obtained using intrinsic volume averaging. A drag function is introduced to account for the interactions of the fluid with the porous matrix. Darcy and Forchheimer generalized terms are included in the model equations for both granular and consolidated media to account for the effects of the porous microstructure.",
    "authors": [
      "M.H. Hamdan",
      "D.C. Roach"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03258",
    "title": "Isolating Balanced Ocean Dynamics in SWOT Data",
    "abstract": "The Surface Water and Ocean Topography (SWOT) mission provides two-dimensional sea surface height (SSH) maps at unprecedented resolution, but its signal is a combination of balanced meso- and submesoscale turbulence, unbalanced internal waves, and small-scale noise. Interpreting the meso- and submesoscale flow features captured by SWOT requires a careful isolation of the balanced signal. We present a statistical method to do so in regions where internal-wave signals are negligible, such as western boundary current regions and the Southern Ocean. Our method assumes Gaussian statistics for both the balanced flow and the noise, which we infer by fitting parametric models to the observed SSH wavenumber spectrum. Using these inferred parameters, we perform a Bayesian inversion to reconstruct swath-aligned SSH maps that fill the nadir gap. We evaluate the method using synthetic data from a high-resolution simulation with realistic SWOT-like noise added. Comparisons with the underlying model data show that our reconstruction successfully removes small-scale noise while preserving meso- and submesoscale eddies, fronts, and filaments down to a feature scale of 10km. The comparison also demonstrates that the posterior uncertainty is a reliable estimate of the error.",
    "authors": [
      "Jack William Skinner",
      "Jörn Callies",
      "Albion Lawrence",
      "Xihan Zhang"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03269",
    "title": "Understanding cold electron impact on parallel-propagating whistler chorus waves via moment-based quasilinear theory",
    "abstract": "Earth's magnetosphere hosts a wide range of collisionless particle populations that interact through various wave-particle processes. Among these, cold electrons, with energies below 100eV, often dominate the plasma density but remain poorly characterized due to measurement challenges such as spacecraft charging and photoelectron contamination. Understanding the contribution of these cold populations to wave-particle interaction is of significant interest. Recent kinetic simulations identified a secondary drift-driven instability in which parallel-propagating whistler-mode chorus waves excite oblique electrostatic whistler waves near the resonance cone and Bernstein-mode turbulence. These secondary modes enable a new channel of energy transfer from the parallel-propagating whistler wave to the cold electrons. In this work, we develop a moment-based quasilinear theory of the secondary instabilities to quantify such energy exchange. Our results show that these secondary instabilities persist for a wide range of parameters and, in many cases, lead to nearly complete damping of the primary wave. Such secondary instability might limit the amplitude of parallel-propagating whistler waves in Earth's magnetosphere and might explain why high-amplitude oblique whistler or electron Bernstein waves are rarely observed simultaneously with high-amplitude field-aligned whistler waves in the inner magnetosphere.",
    "authors": [
      "Opal Issan",
      "Vadim Roytershteyn",
      "Gian Luca Delzanno",
      "Salomon Janhunen"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03271",
    "title": "Determining the Qibla Direction by Astronomical and Geometrical Methods",
    "abstract": "This paper investigates the determination of the Qibla direction using both astronomical and geometrical approaches. The study reviews historical and classical methods employed by Muslim scholars and astronomers including the use of instruments such as the astrolabe and compass. It further explores spherical trigonometry techniques to precisely calculate the Qibla azimuth from any given location on Earth. The research clarifies geometric constructions and presents a computational model implemented in C++ to facilitate accurate Qibla determination. This interdisciplinary analysis underscores the rich tradition of Islamic astronomy and geometry in solving practical religious requirements, providing both theoretical frameworks and practical algorithms for modern application.",
    "authors": [
      "Duaa Abdullah"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03277",
    "title": "On-the-Fly Cavity-Molecular Dynamics of Vibrational Polaritons",
    "abstract": "In this work, we combine the density functional tight-binding (DFTB) approach with a light-matter Hamiltonian beyond the long-wavelength approximation to propagate the dynamics of vibrational polaritons formed by coupling molecular vibrations to confined radiation inside a Fabry-Pérot optical cavity. Here, we develop a parallelized propagation scheme with lightweight inter-CPU communication by exploiting the sparse nature of the light-matter interactions in the real space representation. We find that the computationally expensive Born charges required for our propagation can be replaced with the computationally inexpensive Mulliken charges to obtain qualitatively accurate linear spectra especially when the nonlinearity (arising from molecular vibrations) of the light-matter interaction term is not substantial. However, the same approach may not be suitable to be used for studying cavity modification of energy transport or chemical dynamics as this approximation leads to spurious heating of the light-matter hybrid system. We demonstrate the utility of this on-the-fly approach to compute angle resolved polaritonic spectra of water. We implement our approach as an open-source computational package, CavOTF, which is available on GitHub.",
    "authors": [
      "Sachith Wickramasinghe",
      "Amirhosein Amini",
      "Arkajit Mandal"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03315",
    "title": "Self-Tuning Dynamic Explicit Modal Filtering Based on Local Flow Characteristics for Large-Eddy Simulation",
    "abstract": "This work improves upon our previously introduced explicit dynamic modal filter (DEMF) within the framework of the discontinuous Galerkin spectral element method (DGSEM) by introducing a mechanism for self-tuning of the model parameters. The new self-tuning dynamic explicit modal filter (STDEMF) also extends the methodology for obtaining modal values from nodal values beyond Chebyshev grids and polynomials to general collocation points and orthogonal polynomial bases by leveraging orthogonality. The generated modes are used to remove the built-up energy due to unresolved sub-grid scales (SGS) in large-eddy simulation (LES) of turbulent flows. The STDEMF improves the performance of DEMF in two ways. First, the filter kernel applied to the modes is adapted from a cut-off kernel to a hyperbolic tangent shape, which automatically adjusts the model for different polynomial orders. Second, the cut-off mode is computed dynamically for each element as a function of local flow characteristics, including the local Kolmogorov length scale and the second invariants of the strain and rotation rate tensors. The suggested formulation for the cut-off mode treats unresolved elements distinctly and improves performance by avoiding under- or over-dissipation. Moreover, the cut-off mode evolves over time within the same element as turbulent characteristics vary. The model is evaluated on three flows, homogeneous isotropic decaying, the Taylor-Green vortex, and periodic channel flow, each with distinct turbulent characteristics. Comparisons of the results show that the STDEMF model outperforms the DEMF model and the Smagorinsky eddy viscosity model.",
    "authors": [
      "Mohammadmahdi Ranjbar",
      "Ali Mostafavi",
      "Farzad Mashayek"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03344",
    "title": "Optical feedback induced irregular and chaotic dynamics in terahertz quantum cascade laser combs",
    "abstract": "In this work, we systematically investigate the optical feedback dynamics of terahertz (THz) frequency combs generated from quantum cascade lasers (QCLs) using the effective semiconductor Maxwell-Bloch equations (ESMBEs). Starting from a free-running comb state at low bias (1.3Ith), we identify clear bifurcation routes as the external feedback is increased. In the weak feedback regime (C<1), the frequency comb operation remains stable; as feedback increases to the moderate feedback regime (1<C<2.4), the system transitions through frequency splitting into period-one (P1) oscillations around each comb, followed by higher-order bifurcations (P2, P4, P8). Within the range 2.4<C<13.86, only combs with P1 states are observed, with the split frequency increasing continuously with feedback strength. In the strong feedback regime (C>13.86), complex feedback dynamics re-emerged but with significantly reduced complexity compared with the weak feedback regime. More interestingly, we show that optical feedback can induce chaotic THz emission at higher bias current conditions (>1.6Ith), when the free-running laser output (C=0) is originally a stable frequency comb. The resulting chaotic dynamics, characterized by broadband spectra and large positive Lyapunov exponents, are shown to depend strongly on the linewidth enhancement factor. Although THz QCLs widely considered as ultrastable under external perturbations, this work provides the first detailed report of chaotic dynamics and routes to chaos in THz QCLs under optical feedback. These findings not only deepen the understanding of nonlinear dynamics in THz QCLs but also open new possibilities for exploiting applications of chaotic light in THz sensing, imaging and secure communications.",
    "authors": [
      "Xiaoqiong Qi",
      "Carlo Silvestri",
      "Thomas Taimre",
      "Aleksandar D. Rakic"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03379",
    "title": "Microbubble implosions in finite hollow spheres",
    "abstract": "Microbubble implosion (MBI) is a recently proposed novel mechanism with many interesting and exciting potential applications. MBI predicts that the inner layers of a spherical target with a hollow cavity can be compressed into a core with a density 105 times that of the solid density. Furthermore, this ultra-compressed core mostly consists of ions. This leads to the generation of ultra-high electric fields, which may be applicable to gamma-ray lensing or pair creation. However, MBI has yet to be studied for finite hollow spheres whose electrons are free to redistribute themselves after being given an initial temperature. This paper studies MBI under finite sphere conditions. Using an elec- tron distribution model, the electron distribution after receiving an initial temperature is studied. Then, the optimal parameters required to fill a hollow cavity with electrons are calculated. The dynamics of MBI is simulated using a hybrid one-dimensional code. The simulation demonstrates that MBI occurs even for finite spheres, and high-density compression is still achievable with this setup. It also shows the opti- mal target structure, which maximizes ion flashing.",
    "authors": [
      "M. A. H. Zosa",
      "M. Murakami"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03382",
    "title": "Structural and Dynamical Crossovers in Dense Electrolytes",
    "abstract": "Electrostatic interactions fundamentally govern the structure and transport of electrolytes. In concentrated electrolytes, however, electrostatic and steric correlations, together with ion-solvent coupling, give rise to complex behavior, such as underscreening, that remains challenging to explain despite extensive theoretical effort. Using molecular dynamics simulations of primitive electrolytes with and without space-filling solvent particles, we elucidate the structural and dynamical crossovers and their connection that emerge with increasing salt concentration. Explicit-solvent electrolytes exhibit a screening transition from a charge-dominated dilute regime to a density-dominated concentrated regime, accompanied by dynamical crossovers in ion self-diffusion and ion-pair lifetimes. These dynamical crossovers display a marked discontinuity, unlike the smoother variation of the screening crossover, which originates from short-range ion-counterion structures. Despite the pronounced growth of ionic clusters, their percolation transition does not appear to be directly coupled to the onset of these crossovers. Both structural and dynamical behaviors are found to depend sensitively on ion-solvent coupling: implicit-solvent electrolytes exhibit a screening transition between two charge-dominated regimes, accompanied by qualitatively distinct dynamical behavior. Finally, we demonstrate that the diffusion-corrected ion-pair lifetime provides a consistent descriptor linking ionic structure and dynamics across electrolyte systems.",
    "authors": [
      "Daehyeok Kim",
      "Taejin Kwon",
      "Jeongmin Kim"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03388",
    "title": "Magnetic field amplification driven by the gyro motion of charged particles",
    "abstract": "Spontaneous magnetic field generation plays important role in laser-plasma interactions. Strong quasi-static magnetic fields affect the thermal conductivity and the plasma dynamics, particularly in the case of ultra intense laser where the magnetic part of Lorentz force becomes as significant as the electric part. Kinetic simulations of giga-gauss magnetic field amplification via a laser irradiated microtube structure reveal the dynamics of charged particle implosions and the mechanism of magnetic field growth. A giga-gauss magnetic field is generated and amplified with the opposite polarity to the seed magnetic field. The spot size of the field is comparable to the laser wavelength, and the lifetime is hundreds of femtoseconds. An analytical model is presented to explain the underlying physics. This study should aid in designing future experiments.",
    "authors": [
      "Y-J. Gu",
      "M. Murakami"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03414",
    "title": "Linear stability of nanofluid boundary-layer flow over a flat plate",
    "abstract": "The linear stability of nanofluid boundary-layer flow over a flat plate is investigated using a two-phase model that incorporates Brownian motion and thermophoresis, building upon the earlier work of Buongiorno (2006). Solutions to the steady boundary-layer equations reveal a thin nanoparticle concentration layer near the plate surface, with a characteristic thickness of $O({\\Rey}^{-1/2}{Sc}^{-1/3})$, for a Reynolds number $\\Rey$ and Schmidt number $Sc$. When Brownian motion and thermophoresis are neglected, this nanoparticle concentration layer disappears, resulting in a uniform concentration across the boundary layer. Neutral stability curves and critical conditions for the onset of the Tollmien--Schlichting wave are computed for a range of nanoparticle materials and volume concentrations. Results indicate that while the effects of Brownian motion and thermophoresis are negligible, the impact of nanoparticle density is significant. Denser nanoparticles, such as silver (Ag) and copper (Cu), destabilise the Tollmien--Schlichting wave, whereas lighter nanoparticles, like aluminium (Al) and silicon (Si), establish a small stabilising effect. Additionally, stability characteristics are influenced by the viscosity model. Finally, a high-Reynolds number asymptotic analysis is undertaken for the lower branch of the neutral stability curve.",
    "authors": [
      "Christian Thomas",
      "Sharon O. Stephen",
      "Jitesh. S. B. Gajjar",
      "Paul T. Griffiths"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03426",
    "title": "Zero-Waste Biorefinery: Pyrolysis of Fermentation Residues into Catalytic Biochar for Circular Biohydrogen Systems",
    "abstract": "This study presents a closed-loop biorefinery strategy that thermochemically upcycles fermentation residues (FRs) from photo-fermentative biohydrogen production (PFHP) into functional biochar catalysts, thereby enhancing the efficiency of the initial PFHP process. Four FRs derived from hydrothermal and ethylene glycol-pretreated corn stover were pyrolyzed at 700°C. Multi-model kinetic analyses revealed diffusion-controlled mechanisms with activation energies ranging from 157 to 278 kJ/mol, while thermodynamic profiling highlighted the influence of feedstock composition on reaction spontaneity and entropy. Pyrolysis effectively restored porosity compromised during fermentation, yielding biochar with tailored properties: microporous BC3 (185 m2/g) from oxygen-rich precursors and mesoporous BC4 (76.58 m2/g) from graphitized residues. When reintroduced into PFHP, BC3 maximized cumulative hydrogen yield (570 mL) via pH buffering, and BC4 achieved the highest production rate (14.91 mL/h) through electron shuttle mechanisms. The integrated process concurrently generated syngas, bio-oil, and catalytic biochar, enabling waste valorization, renewable energy output, and process enhancement within a circular bioeconomy framework.",
    "authors": [
      "Muhammad Shahzaib"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03446",
    "title": "A novel multiscale modelling for the hemodynamics in retinal microcirculation with an analytic solution for the capillary-tissue coupled system",
    "abstract": "Mathematical modelling of the microcirculatory hemodynamics in the retina is an essential tool for understanding various diseases of the retina, yet remains challenging due to the multiscale nature of the retinal vasculature and its coupling to surrounding tissue. To address this, we develop a multiscale model that couples retinal vasculature across scales with interstitial tissue. Our model combines the one-dimensional (1D) model for arteries and veins with the coupled Darcy equations for capillaries and tissue. The model uses an analytic solution for capillary-tissue coupled system that provides a simple interpretation of the results along with much faster computation. The analytic solution implies a dynamic coupling condition that links the capillary bed with upstream arterial and downstream venous flows. The model is mathematically robust, demonstrated through analysis of the solution's truncation error and convergence. Its predictive accuracy is verified against experimental data and other models, making it useful in interpreting experimental results. Finally, the role of various parameters in controlling retinal hemodynamics is explored.",
    "authors": [
      "Chang Lin",
      "Zilong Song",
      "Bob Eisenburg",
      "Shixin Xu",
      "Huaxiong Huang"
    ],
    "primary_category": "physics.bio-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03539",
    "title": "Real-Time Control and Automation Framework for Acousto-Holographic Microscopy",
    "abstract": "Manual operation of microscopes for repetitive tasks in cell biology is a significant bottleneck, consuming invaluable expert time, and introducing human error. Automation is essential, and while Digital Holographic Microscopy (DHM) offers powerful, label-free quantitative phase imaging (QPI), its inherently noisy and low-contrast holograms make robust autofocus and object detection challenging. We present the design, integration, and validation of a fully automated closed-loop DHM system engineered for high-throughput mechanical characterization of biological cells. The system integrates automated serpentine scanning, real-time YOLO-based object detection, and a high-performance, multi-threaded software architecture using pinned memory and SPSC queues. This design enables the GPU-accelerated reconstruction pipeline to run fully in parallel with the 50 fps data acquisition, adding no sequential overhead. A key contribution is the validation of a robust, multi-stage holographic autofocus strategy; we demonstrate that a selected metric (based on a low-pass filter and standard deviation) provides reliable focusing for noisy holograms where conventional methods (e.g., Tenengrad, Laplacian) fail entirely. Performance analysis of the complete system identifies the 2.23-second autofocus operation-not reconstruction-as the primary throughput bottleneck, resulting in a 9.62-second analysis time per object. This work delivers a complete functional platform for autonomous DHM screening and provides a clear, data-driven path for future optimization, proposing a hybrid brightfield imaging modality to address current bottlenecks.",
    "authors": [
      "Hasan Berkay Abdioğlu",
      "Yağmur Işık",
      "Mustafa İsmail İnal",
      "Nehir Serin",
      "Kerem Bayer",
      "Muhammed Furkan Koşar",
      "Taha Ünal",
      "Hüseyin Üvet"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03559",
    "title": "Postseismicity of slow-slip doublets discerned on the outermost of the Nankai Trough subduction megathrust",
    "abstract": "Despite dissimilar slip rates, slow earthquakes are faulting as ordinary earthquakes are. It is therefore physically natural that slow earthquakes also cause postseismic motions similarly to ordinary earthquakes, even though coseismic and postseismic slips remain undifferentiated for slow earthquakes. We pursue the slow-earthquake postseismicity based on the analysis of a fault slip beneath the Bungo Channel, the westernmost region of the Nankai Trough subduction zone in southwestern Japan. Its 2010 long-term slow slip event (SSE) was mispredicted by physics-based models, which concludes that the initial acceleration of this SSE was too abrupt for a slow variant of a fault rupture. We identify that a mispredicted GNSS signal evolves logarithmically in time, preceded by minor signals that evolve exponentially, lasting about two years west and about half a year east. By performing sparse inverse modeling on the GNSS, we have estimated that exponential slips occur at the same depth, bracketing a logarithmic slip that occurs beneath the channel. The regions of exponential slips match repeating slow-slip regions, and deep tremors synchronize exclusively with the logarithmic slip. This source complexity can be explained as a neighboring rupture doublet and its afterslip and aftershocks by the known mechanics of ordinary earthquakes. If slow earthquakes have a dual origin in exponentially nucleating slow rupture and logarithmically decelerating postseismic creep, it is possible to pick the slow earthquake nuclei that could accelerate into megathrust catastrophes.",
    "authors": [
      "Dye SK Sato",
      "Takane Hori",
      "Takeshi Iinuma",
      "Masayuki Kano",
      "Yusuke Tanaka"
    ],
    "primary_category": "physics.geo-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03589",
    "title": "Fast directional transport of Leidenfrost droplets on spiked surfaces",
    "abstract": "The Leidenfrost effect enables droplets to levitate above a solid surface, significantly reducing the resistance to droplet motion. In this study, a spiked surface is utilized to achieve fast directional transport of Leidenfrost droplets, with a maximum average speed reaching 8.36 m per second over a 10 cm distance,far exceeding the previously reported maximum speeds for droplet transport. When a droplet falls onto a substrate heated above the Leidenfrost temperature, it becomes trapped between spikes and levitates. The sides and bottom surface of the droplet undergo vaporization, creating a gas film between the solid wall and the droplet. However, this gas film is unstable and prone to rupture at certain points, causing the droplet to come into contact with the solid surface. Therefore, the droplets undergo violent boiling, leading to intense compression and bursting into smaller daughter droplets, which are then propelled rapidly along the substrate. Additionally, the asymmetric geometry of the spikes ensures that droplets move unidirectionally along the longitudinal direction. This study proposes a novel droplet self-propulsion mechanism, pioneering new strategies for enhancing droplet transport speed..",
    "authors": [
      "Kai-Xin Hu",
      "Dong-Xu Duan",
      "Yin-Jiang Chen",
      "Dan Wu",
      "Qi-Sheng Chen"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03603",
    "title": "Multi-peak vector soliton families in defocusing Kerr resonators",
    "abstract": "We report the existence of multi-peaked vector soliton families in normally dispersive passive Kerr resonators. Through cross-phase modulation between two orthogonal polarization components, each peak becomes tightly interlocked, enabling robust localization of the entire wave packet in defocusing cavities. Analysis using snakes-and-ladder diagrams demonstrates the diversity of these vector soliton families, which include dark-bright multi-peak solitons, flat-topped solitons, and modulation instability patterns, among others. Furthermore, stability analysis based on the coupled Lugiato-Lefever equations reveals that specific combinations of parameters can sustain stable vector cavity solitons, whose peak numbers can be continuously tuned by adding appropriate perturbations. These findings significantly expand the scope of soliton dynamics and optical frequency comb generation in pumped-dissipative systems, independent of dispersion conditions.",
    "authors": [
      "Pengxiang Wang",
      "Carlos Mas-Arabi",
      "Gian-Luca Oppo",
      "Yiqing Xu",
      "Miro Erkintalo",
      "Stephane Coen",
      "Bertrand Kibler",
      "Julien Fatome",
      "Gang Xu"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03613",
    "title": "Drag reduction via separation control using plasma actuators on a truck cabin side",
    "abstract": "We investigated the drag reduction on a heavy-duty vehicle by means of dielectric-barrier discharge plasma actuators located on the A-pillars. An experimental campaign is carried out on a generalized truck model, the Ground Transportation System (GTS). Measurements were performed for several values of the side-wind angle, up to 7.5°. Actuation was performed individually on the leeward and windward side as well as simultaneously. We measured both axial and side force components with a load cell. A laminar separation bubble on both sides of the truck's cabin is identified with particle image velocimetry. The plasma actuators effectively reduce the axial force on the GTS, and higher force reduction is achieved with symmetric actuation. The leeward actuation is found to have a greater control authority than the windward one; at large side-wind angle the latter has a negligible effect on the axial force. Concerning the side force, the leeward actuation produces a drop in its magnitude while windward actuation produces an increase. Interestingly, actuating symmetrically also augments the side force. The plasma actuator causes a reduction in the length and width of the separation bubble on the cabin side, reducing the apparent frontal area of the truck and thus its drag. Under side wind conditions, the leeward actuator has stronger authority since reduces the size of the larger separation bubble. The side force is also weakened via the diminution of the larger recirculation region, reducing its lateral suction force.",
    "authors": [
      "Lucas Schneeberger",
      "Stefano Discetti",
      "Andrea Ianiro"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03655",
    "title": "V-Reactor Dynamics: Dual Chaotic System and Rewriting the Antiviral Response History",
    "abstract": "The COVID-19 pandemic revealed a key vulnerability: our failure to anticipate novel viral threats. Moving beyond descriptive virology, we introduce V-Reactor Dynamics (V-Dynamics), a physics-based framework modeling host-virus interaction as a synchronized dual chaotic system. This paradigm predicts viral evolution, immune response, transmission, and virulence through equations governed by the parameter reactivity ($\\rho$). It quantifies infection phases, peak ($\\rho>0$), plateau ($\\rho\\approx0$), clearance ($\\rho<0$), transmission, and modality via $\\rho/\\ell$ (Reactivity/Generation time). Retrospectively, it correctly predicted SARS-CoV-2's higher transmissibility versus SARS-CoV's lethality and forecasted Omicron waves, exposing the lockdown-socioeconomic cost trade-off. We introduce measurable constants, viral replication, immune evasion, and drug absorption cross sections, derived from in vitro virion interactions. These quantum mechanical analogues relate to $\\rho$ and $\\ell$, enabling pre-outbreak predictive surveillance.V-Dynamics reveals a duality: microscopic chaos in viral production and macroscopic chaos in population transmission, linked by a scaling law. The sign of $\\rho$, tied to the Lyapunov Exponent, dictates pandemic trajectory ($\\rho>0$ for outbreak, $\\rho<0$ for termination), offering a control mechanism. By unifying kinetics, cross-scale dynamics, and chaos theory, this framework provides a quantitative roadmap to preempt future pandemics.",
    "authors": [
      "Yong-Shou Chen"
    ],
    "primary_category": "physics.bio-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03660",
    "title": "Linking Aneurysmal Geometry and Hemodynamics Using Computational Fluid Dynamics",
    "abstract": "The development and progression of abdominal aortic aneurysms (AAA) are related to complex flow patterns and wall-shear-driven mechanobiological stimuli, yet the quantitative relationship between aneurysmal geometry and hemodynamics remains poorly defined. In this study, we conducted a comprehensive hemodynamic analysis of 74 patient-specific abdominal aortas, representing one of the largest Computational Fluid Dynamics (CFD) cohorts reported to date. A multiscale framework coupling 0D-1D systemic circulation models with 3D stabilized finite-element simulations is used to generate physiologically consistent boundary conditions and high-fidelity flow fields. From each model, we extract Time Averaged Wall Shear Stress (TAWSS), Oscillatory Shear Index (OSI), Relative Residence Time (RRT) and Local Normalized Helicity (LNH) indicators alongside an extended set of geometric descriptors characterizing diameter, curvature and torsion. This study provides a clear and comprehensive view of how aneurysm shape influences blood-flow behavior, supported by one of the largest systematically analyzed CFD datasets of AAAs to date. Our results show that specific geometric features reliably shape shear-stress patterns, suggesting that these geometry-driven flow signatures could serve as valuable biomarkers for patient-specific risk assessment. Together, these insights highlight the potential of incorporating detailed geometric descriptors into future models that aim to predict AAA growth and rupture.",
    "authors": [
      "Spyridon C. Katsoudas",
      "Konstantina C. Kyriakoudi",
      "Grigorios T. Chrimatopoulos",
      "Panagiotis D. Linardopoulos",
      "Christoforos T. Chrimatopoulos",
      "Anastasios A. Raptis",
      "Konstantinos G. Moulakakis",
      "John D. Kakisis",
      "Christos G. Manopoulos",
      "Michail A. Xenos",
      "Efstratios E. Tzirtzilakis"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03665",
    "title": "Photonic time stretch fieldoscopy: single-shot electric field detection at near-petahertz bandwidth",
    "abstract": "Accessing the electric field of light with petahertz bandwidths in ambient air is a rapidly advancing frontier, essential for probing ultrafast dynamics driven by classical or quantum ultrashort pulses. Near-petahertz fieldoscopy has recently demonstrated sub-cycle access to light-matter interactions, enabling label-free spectro-microscopy of liquids and solids with unprecedented spatiotemporal resolution, detection sensitivity, and dynamic range. However, current implementations still rely on temporal scanning and averaging over many laser pulses. Here, we introduce photonic time-stretch fieldoscopy, enabling single-shot electric-field detection at near-petahertz frequencies. Numerical results demonstrate that integrating fieldoscopy with a nonlinear time lens enables the real-time acquisition of ultrashort optical waveforms with a detection bandwidth approaching petahertz. The resulting large temporal aperture and attosecond resolution allow direct single-shot detection of transient electric fields generated in solid or liquid samples. This concept opens new avenues for petahertz electronics, ultrafast spectro-microscopy, and the study of dynamic, non-repetitive optical phenomena",
    "authors": [
      "Steffen Gommel",
      "Kilian Scheffter",
      "Andreas Herbst",
      "Anchit Srivastava",
      "Hanieh Fattahi"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03706",
    "title": "Consistent Projection of Langevin Dynamics: Preserving Thermodynamics and Kinetics in Coarse-Grained Models",
    "abstract": "Coarse graining (CG) is an important task for efficient modeling and simulation of complex multi-scale systems, such as the conformational dynamics of biomolecules. This work presents a projection-based coarse-graining formalism for general underdamped Langevin dynamics. Following the Zwanzig projection approach, we derive a closed-form expression for the coarse grained dynamics. In addition, we show how the generator Extended Dynamic Mode Decomposition (gEDMD) method, which was developed in the context of Koopman operator methods, can be used to model the CG dynamics and evaluate its kinetic properties, such as transition timescales. Finally, we combine our approach with thermodynamic interpolation (TI), a generative approach to transform samples between thermodynamic conditions, to extend the scope of the approach across thermodynamic states without repeated numerical simulations. Using a two-dimensional model system, we demonstrate that the proposed method allows to accurately capture the thermodynamic and kinetic properties of the full-space model.",
    "authors": [
      "Vahid Nateghi",
      "Lara Neureither",
      "Selma Moqvist",
      "Carsten Hartmann",
      "Simon Olsson",
      "Feliks Nüske"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03710",
    "title": "Tailoring the morphology of ultrathin bismuth films around percolation for thickness-optimized optical cavities",
    "abstract": "Ultrathin bismuth films (<10 nm) are emerging candidates for advanced applications in photonics. It has been shown that Bi-based subwavelength optical cavities show outstanding features, including broad tuneable resonances for structural color generation and broadband perfect absorption for light harvesting. While current devices are based on continuous Bi films, integrating ultrathin films around the percolation threshold with a tailored morphology promises to enable more compact devices with a wider tunability range and/or enhanced optical response. In this context, we report the tailoring of the morphology and UV-Vis-NIR effective optical dielectric function ( $\\varepsilon$= $\\varepsilon_1$+i$\\varepsilon_2$) of ultrathin Bi films around the percolation threshold. Just below percolation, the films effective optical permittivity $\\varepsilon_1$ differs markedly from that of a continuous film, as it turns from negative to positive while its effective optical loss $\\varepsilon_2$ is reduced. We showcase the relevance of such dielectric tunability for the design of enhanced subwavelength optical cavities operating in the NIR and visible regions. In particular, we show that discontinuous near-percolation films enable designing optimized cavities for efficient colour generation with a thickness almost 3 times smaller than what was previously achieved for continuous films.",
    "authors": [
      "Fernando Chacon-Sanchez",
      "Johann Toudert",
      "Rosalía Serna"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03711",
    "title": "Compton suppressed scintillation spectrometer based on a cluster of 9$\\times$CeBr$_{3}$-NaI(Tl) phoswich detectors",
    "abstract": "Measurements of the characteristics of an Compton suppressed spectrometer consisting of 9$\\times$CeBr$_{3}$-NaI(Tl) phoswich detectors surrounded by four CsI(Tl) scintillation detectors intended for suppressing the Compton component of the spectrum have been carried out. Measurements were performed using gamma and neutron radiation sources. Key parameters of the spectrometer have been determined: the suppression factor of the Compton part of the $\\gamma$-spectrum, as well as the dependencies of the neutron detection efficiency on their energy at various detection threshold values.",
    "authors": [
      "Mark Povolotskiy",
      "Yuri Sobolev",
      "Sergei Stukalov"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03753",
    "title": "Real-Time Coupled Electron-Nuclear Dynamics of Chemical Bond Formation: Hydrogen Scattering from a Semiconductor Surface",
    "abstract": "A first-principles coupled electron-nuclear dynamics simulation based on real-time, time-dependent density functional theory and Ehrenfest dynamics quantitatively repro-duces bimodal translational energy loss and angular distributions observed in experiment for hydrogen atom scattering from Ge(111)-c(2*8). The theory elucidates a site-selective mechanism of electronically nonadiabatic energy transfer associated with the formation of different Ge-H bonds. When a hydrogen atom approaches a Ge rest-atom, it is strongly accelerated toward the potential minimum forming a transient Ge-H bond and then re-flected by the repulsive wall. This transient bond formation triggers an ultrafast electron transfer event from the rest-atom to an adjacent Ge-adatom, involving several crossings between valence and conduction bands of the substrate. Electronic equilibration is impos-sible within such a short time (Born-Oppenheimer failure) allowing the H-atom kinetic energy to be converted to inter-band electronic excitation of the substrate. H-atom colli-sions at other Ge atoms also form a transient bond but exhibit no electronic excitation, resulting in distinctly less efficient energy loss in scattered H-atoms. The nucle-ar-to-electronic energy transfer observed in this system reflects the electronic dynamics of covalent bond formation at a semiconductor surface, a mechanism that is quite distinct from previously identified nonadiabatic energy transfer mechanisms at metal surfaces mediated by electronic friction or transient negative ions.",
    "authors": [
      "Jialong Shi",
      "Lingjun Zhu",
      "Florian Nitz",
      "Oliver Bünermann",
      "Alec M. Wodtke",
      "Hua Guo",
      "Bin Jiang"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03770",
    "title": "Quantum Simulations of Opinion Dynamics",
    "abstract": "Quantum computing offers powerful new approaches for modeling complex social phenomena. Here, we propose and demonstrate quantum simulations of opinion dynamics, leveraging quantum superposition, measurement-induced state collapse, and entanglement to model realistic psychological and social processes. Specifically, we develop quantum models of opinion dynamics, solving exactly and simulating on IBM Quantum hardware. Our results, based on quantum devices and validated with practical quantum circuits, illustrate how quantum effects can enhance understanding of consensus formation, polarization, and collective decision-making. These findings pave the way for further exploration into quantum-enhanced social modeling, highlighting the potential of near-term quantum computers for simulating collective behavior in complex systems.",
    "authors": [
      "Xingyu Guo",
      "Xiaoyang Wang",
      "Lingxiao Wang"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03811",
    "title": "Studying the GRAiNITA concept: first test beam results",
    "abstract": "Data collected over a two-day period in June 2024 at the CERN SPS H9 test beam using a small-scale GRAiNITA prototype have been analyzed to characterize the detector's energy resolution performance. The measurements allow for a first estimate of the constant term associated with detector non-uniformity. Although the evaluation is limited by the small prototype size and the use of pion beams, the results indicate that the non-uniformity-related constant term is significantly below 1%. Furthermore, the test-beam data confirm that the contribution to the energy resolution arising from photo-electron statistics is approximately 1%/sqrt(E). These findings validate the expected calorimetric performance of the GRAiNITA concept and provide important input for the design and optimization of future full-scale detectors.",
    "authors": [
      "Sergey Barsuk",
      "Oleg Bezshyyko",
      "Ianina Boiaryntseva",
      "Andrey Boyarintsev",
      "Dominique Breton",
      "Herve Chanal",
      "Alexander M. Dubovik",
      "Larysa Golinka-Bezshyyko",
      "Carlos Dominguez Goncalves",
      "Yingrui Hou",
      "Giulia Hull",
      "Miktat Imre",
      "Denys Klekots",
      "Jacques Lefrancois",
      "Jihane Maalmi",
      "Magali Magne",
      "Bernard Mathon",
      "Stéphane Monteil",
      "Sebastien Olmo",
      "David Picard",
      "Marie-Helene Schune",
      "Irina Tupitsyna",
      "Mykhailo Yeresko"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03820",
    "title": "Terahertz emission from interdigitated photoconductive antennas based on Ge-on-Si",
    "abstract": "An interdigitated photoconductive antenna (i-PCA) for terahertz (THz) emission with a novel metal-insulator-semiconductor interface is designed with the aim of developing compact and scalable THz devices. The photoconductive material is an amorphous germanium (Ge) film deposited using DC magnetron sputtering. The antenna electrodes are composed of gold-germanium (AuGe). With the integration of a silicon dioxide (SiO2) layer that acts as an electrical mask on alternate active areas, we present a simple approach to fabricate a large-area i-PCA. Along with a simplified fabrication compared to other existing designs, our approach increases the electrical robustness of the emitter and reduces the inactive gap area on the device. The i-PCA is capable of THz emission up to 2.5 THz and 36 dB signal-to-noise ratio (SNR), and is promising for applications in CMOS technologies.",
    "authors": [
      "Dhanashree Chemate",
      "Abhishek Singh",
      "Ruturaj Puranik",
      "Utkarsh Pandey",
      "Dipti Gupta",
      "Siddhartha P. Duttagupta",
      "Shriganesh S. Prabhu"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03826",
    "title": "Recent Developments of the VOXES Von Hamos X-ray Spectrometer for Laboratory XES and XAS Studies",
    "abstract": "VOXES is a Von Hamos X-ray spectrometer developed at the INFN National Laboratories of Frascati for high-resolution laboratory X-ray spectroscopy in the 5--20~keV range. It uses curved mosaic crystals and motorized positioning stages to perform wavelength-dispersive X-ray fluorescence (WD-XRF) with sub-10~eV tunable resolution for extended and dilute samples. Recent developments include the integration of an energy-dispersive X-ray fluorescence (ED-XRF) line based on a silicon pin-diode detector, which enables flux monitoring and simultaneous ED and WD measurements. In addition, a dedicated liquid-sample holder has been introduced, and a Y-shaped support geometry, crucial for switching to a transmission layout, provides mechanical compatibility with laboratory XAS, now under implementation. These upgrades expand the versatility and automation of VOXES, strengthening its role as a table-top platform for laboratory X-ray spectroscopy.",
    "authors": [
      "Simone Manti",
      "Alberto Clozza",
      "Gabriel Moskal",
      "Kristian Piscicchia",
      "Diana Sirghi",
      "Florin Sirghi",
      "Catalina Curceanu",
      "Alessandro Scordo"
    ],
    "primary_category": "physics.app-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03829",
    "title": "First Experimental Demonstration of Machine Learning-Based Tuning on the PSI Injector 2 Cyclotron",
    "abstract": "Reliable operation of high-power proton cyclotrons is a critical requirement for Accelerator Driven Systems (ADS) and other large-scale applications. Beam tuning in such machines is traditionally performed manually, a process that can be slow, non-optimal, and difficult to execute in the presence of faults or changing conditions. To address this, we developed and deployed a machine learning (ML) based tuning framework on the Injector 2 cyclotron at PSI, chosen as an ideal testbed for high-power operation. The system combined a tailored reinforcement learning algorithm with real-time diagnostics and control, and incorporated accelerator-physics inspired adaptations such as an overshoot strategy that reduced magnetic field settling times by nearly a factor of six. Over an extensive 12-day operational test campaign, relatively long in the context of real-time ML experiments, the ML agent successfully tuned the machine across multiple operating points, achieving convergence within hours and maintaining stable beam extraction with reduced losses. Beyond initial tuning, the system was also operated in evaluation mode overnight, where it autonomously monitored and corrected the machine to compensate for drifts, demonstrating robustness and long-term stability. Crucially, the learned policy generalized reliably from low-current training to higher-current operation, underscoring its scalability. These results constitute the first demonstration of ML-assisted tuning on a high-power cyclotron, with direct relevance to ADS-class drivers.",
    "authors": [
      "M. Haj Tahar",
      "W. Joho",
      "E. Solodko",
      "M. Bocchio",
      "S. Marquie",
      "M. Busch",
      "A. Barchetti",
      "J. Grillenberger",
      "J. Snuverink",
      "M. Schneider"
    ],
    "primary_category": "physics.acc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03833",
    "title": "Shell formation and two-dimensional nanofriction in three-dimensional ion Coulomb crystals",
    "abstract": "Self-organized three-dimensional (3D) ion Coulomb crystals in linear Paul traps naturally form concentric shells that provide a curved, atomically resolved interface for studying two-dimensional (2D) nanofriction. Building on prior work that used 2D ion crystals to investigate one-dimensional (1D) nanofriction and orientational melting, we leverage this foundation to extend friction studies from linear ion chains and planar rings to 3D shell structures. Using molecular-dynamics simulations, we first map shell formation as a function of ion number $N$ and the trapping aspect ratio, yielding a simple relation that can aid ion-number estimation in experiments. We compute a Peierls--Nabarro-type energy landscape for the rotation of the outer shell against the inner core, showing drastic changes in the effective energy barrier up to a factor of about 60 with only small changes in $N$. Using dynamical simulations, we apply rotational torques to the outer shell of selected systems and show that small changes in $N$ impact the commensurability between shells and can, in some cases, induce a hysteretic response due to torque-induced metastable states. We find that spatially varying coupling to the inner-core corrugation can create coexisting fast and slow moving domains within the rotating outer shell, realizing multidimensional friction where intra-shell shear and inter-shell nanofriction act simultaneously. Our results have implications for stabilizing many-body systems and for the development of ultra-low-friction nanomechanical devices such as ion-based nanorotors and torque sensors.",
    "authors": [
      "L.-A. Rüffert",
      "T. E. Mehlstäubler"
    ],
    "primary_category": "physics.atom-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03841",
    "title": "Intermittency from Instanton Calculus at the Transition to Turbulence and Fusion Rules",
    "abstract": "Understanding intermittency of turbulent systems from the underlying differential equations is an outstanding problem in fluid dynamics. Here, in the example of Burgers turbulence, we introduce a method that yields structure function exponents by combining instanton calculus and fusion rule predictions. We use instantons to evaluate velocity gradient (VG) moments at the onset of intermittency, and then infer scaling exponents in fully developed turbulence via fusion rules. We show that the method captures the phase transition at $\\mathrm{Re}_\\lambda \\approx 1$ in the VG moment scaling, highlight the necessity of including fluctuations around instantons, and discuss future extensions.",
    "authors": [
      "Timo Schorlepp",
      "Rainer Grauer"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03856",
    "title": "Solar Wind Penetration into Dusty Magnetospheres creates Electrostatic Waves and Structures",
    "abstract": "The low frequency electrostatic perturbations have been investigated in a bi ion plasma in the background of static dust. It is shown that the field aligned shear flow of both the ions produce low frequency electrostatic instabilities and create nonlinear structures, the double layers and the solitons. The general theoretical model is applied to the magnetospheres of Jupiter (with positively charged dust) and Saturn (with negatively charged dust) which have oxygen ions in addition to protons. This model predicts the existence of extremely low frequency electrostatic waves with real frequencies of the order of a milli Hertz (mHz) to several mHz and this range of frequencies have been reported in literature for these plasma environments. The estimated width of the nonlinear structures vary from a few hundred meters to a few kilometers. These structures are similar to that observed in the oxygen and oxygen hydrogen plasmas in Earth's upper ionosphere which is free from dust.",
    "authors": [
      "Usman Saeed",
      "Shaukat Ali Shan",
      "Hamid Saleem"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03858",
    "title": "Comparing time and frequency domain numerical methods with Born-Rytov approximations for far-field electromagnetic scattering from single biological cells",
    "abstract": "The Born-Rytov approximation estimates effective refractive index of biological cells from measurements of scattered light intensity, polarization and phase. Effective refractive index is useful for estimating a biological cell's dry mass, volume, and internal morphology directly from its elastic light scattering pattern. This work compares the Born-Rytov approximation with analytical, Yee-lattice finite-difference time-domain, and discrete-dipole approximations to Maxwell's equations in the cases of electromagnetic scattering from a sphere and a tomographic reconstruction of Saccharomyces cerevisiae. Practical advantages and limitations of each numerical method are compared for modeling electromagnetic scattering of both near-field intensity and the far-field projected intensity, in terms of accuracy, memory, and compute time. When compared with a commercial software implementation of the Yee-lattice finite-difference time domain method, the Born-Rytov scattering approximation and discrete dipole approximation show better agreement with the far-field light scattering pattern from Saccharomyces cerevisiae.",
    "authors": [
      "Cael Warner"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03875",
    "title": "Stratification, turbulence organization, and pressure-strain effects on surface-layer turbulence anisotropy",
    "abstract": "At large scales, the Reynolds stress tensor exhibits notable anisotropy, a key feature of all wall-bounded turbulent flows. Yet, how the drivers of this anisotropy evolve with shearing and thermal stratification in the atmospheric surface layer (ASL) remains a daunting challenge for theory and models alike. Here, the velocity variance budgets are used to explore the evolution of anisotropy in the daytime ASL close to the surface, region known to be problematic for large eddy simulations. A special focus is placed on the importance of slow and rapid pressure-strain correlations and the role of transport on partitioning the turbulent kinetic energy among the velocity components. Results obtained from near-surface observations of four datasets over flat and horizontally homogeneous terrain show persistent anisotropy over a wide range of flux Richardson numbers $R_{if}$ and wall-normal distances, and highlight the importance of different processes in three distinct flow regimes, roughly related to dynamic ($|R_{if}|\\ll1$), dynamic-convective ($|R_{if}|\\sim1$) and convective ($|R_{if}|\\gg1$) regimes of the ASL. In particular, close to the surface in the dynamic-convective regime, a drop in wall-normal velocity variance and a substantial increase of spanwise velocity variance are shown to result from the increasing role of pressure transport and rapid distortion, related to turbulence organization. This behaviour is not captured by the classic Rotta closure but requires the inclusion of both rapid pressure-strain and transport terms. In all regimes wall blocking is found to influence turbulence close to the surface, thus requiring the adoption of an anisotropic Rotta model to accommodate its effects.",
    "authors": [
      "Ivana Stiperski",
      "Gabriel G. Katul",
      "Elie Bou-Zeid",
      "Marc Calaf"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03889",
    "title": "Comparing land- and skyscapes in the three main manorial-conquered lands of the Canary Islands",
    "abstract": "This work is a study of the relationship between astronomy and landscape focused on the orientation of Christian churches of the three main Manorial (Señorío) Islands of the Canary archipelago (Spain): Lanzarote, La Gomera and Fuerteventura. As a background, we have the information provided by the texts of early Christian writers, which imposed that churches should be oriented towards the east [..]. The fieldwork that supports our comparative study is based on the measurement of the precise location coordinates, axis' azimuth and angular height of the horizon for most of the churches of the three islands, which amounts to about 120 sets of measurements. For the study of the sample, we have employed various analyses, both statistical, as well as calendric and orographic. Our results show that on all the islands, the pattern of double orientations is repeated, which contemplates the canonical tradition of orienting the altars of churches within the solar range (pointing either eastward or westward). Very few cases also occur where it is possible to identify constructions whose orientation follows solstitial patterns, perhaps as imitation of aboriginal worship. But this double pattern also includes a high proportion of churches with orientations far from this range. An example is Lanzarote and Fuerteventura, both islands subjected to the same flow of the prevailing trade winds in the region, but each with its own characteristics. Another example is given by the particular orography of deep ravines of La Gomera, which determines the orientation of the temples located in those geographical accidents. In this paper we show how the combination of elements of the land- and skyscape can, with a high degree of probability, offer a satisfactory explanation to the particular orientation of these insular centres of worship, which were built during the first decades after the European conquest.",
    "authors": [
      "Maria Florencia Muratore",
      "Alejandro Gangui",
      "Juan Antonio Belmonte",
      "Carmelo Cabrera"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03890",
    "title": "The May 2024 Storm: dayside magnetopause and cusps in simulated soft X-Rays",
    "abstract": "The coronal mass ejection (CME) arriving at Earth on May 10, 2024 caused the most intense geomagnetic storm in the last two decades, and resulted in highly unusual magnetopause and cusp dynamics. We simulate soft X-Ray emission due to solar wind charge exchange with exospheric neutrals to image the global dayside dynamics, focusing on the impact of a dense CME current sheet during the storm main phase. The magnetopause moves inward to ~ 4 RE, and at the same time, the two cusps manifest as nearly parallel emission ridges in X-Ray. As the interplanetary magnetic field reverses, the cusp ridges move to higher latitudes for ~ 10 minutes after the reversal. The X-Ray emission can be detected by imagers to be flown on future missions to provide a global picture of the magnetopause and cusps with quantitative determination of their locations",
    "authors": [
      "J. Ng",
      "L.-J. Chen",
      "B. Burkholder",
      "D. Sibeck",
      "F. S. Porter",
      "K. H. Pham",
      "V. G. Merkin",
      "H. Connor",
      "J. W. Bonnell",
      "S. Petrinec",
      "Y. Zou",
      "B. Alterman",
      "G. Cucho-Padin"
    ],
    "primary_category": "physics.space-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03900",
    "title": "Errors in PDH offset locking due to spurious spectral features",
    "abstract": "The Pound-Drever-Hall (PDH) technique is widely used to stabilize the frequency of lasers. Here we report on a routinely underestimated source of error in PDH offset-locking: a shift in the lock point due to the unintended interaction between residual optical sidebands and higher-order spatial modes in misaligned Fabry-Perot cavities. Significant frequency deviations-up to 50% of the cavity linewidth-can arise when the optical offset is obtained from a sinusoidally driven EOM. We measure this deviation experimentally, find agreement with a simple model, and show how a spectrally-pure frequency offset can reduce the deviation by an order of magnitude. Our findings draw attention to a systematic effect of importance to precision optical spectroscopy, optical clocks, and quantum information science.",
    "authors": [
      "Roame A. Hildebrand",
      "Wance Wang",
      "Connor Goham",
      "Alessandro Restelli",
      "Joseph W. Britton"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03914",
    "title": "Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale",
    "abstract": "Efficient simulation of complex plasma dynamics is crucial for advancing fusion energy research. Particle-in-Cell (PIC) Monte Carlo (MC) simulations provide insights into plasma behavior, including turbulence and confinement, which are essential for optimizing fusion reactor performance. Transitioning to exascale simulations introduces significant challenges, with traditional file input/output (I/O) inefficiencies remaining a key bottleneck. This work advances BIT1, an electrostatic PIC MC code, by improving the particle mover with OpenMP task-based parallelism, integrating the openPMD streaming API, and enabling in-memory data streaming with ADIOS2's Sustainable Staging Transport (SST) engine to enhance I/O performance, computational efficiency, and system storage utilization. We employ profiling tools such as gprof, perf, IPM and Darshan, which provide insights into computation, communication, and I/O operations. We implement time-dependent data checkpointing with the openPMD API enabling seamless data movement and in-situ visualization for real-time analysis without interrupting the simulation. We demonstrate improvements in simulation runtime, data accessibility and real-time insights by comparing traditional file I/O with the ADIOS2 BP4 and SST backends. The proposed hybrid BIT1 openPMD SST enhancement introduces a new paradigm for real-time scientific discovery in plasma simulations, enabling faster insights and more efficient use of exascale computing resources.",
    "authors": [
      "Jeremy J. Williams",
      "Stefan Costea",
      "Daniel Medeiros",
      "Jordy Trilaksono",
      "Pratibha Hegde",
      "David Tskhakaya",
      "Leon Kos",
      "Ales Podolnik",
      "Jakub Hromadka",
      "Kevin A. Huck",
      "Allen D. Malony",
      "Frank Jenko",
      "Erwin Laure",
      "Stefano Markidis"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03920",
    "title": "Passive Silicon Nitride On-Chip Polarimetry: Precise Polarization Detection with Imperfect Components",
    "abstract": "Polarization is a fundamental property of light that carries distinct and valuable information. Consequently, its precise measurement is crucial for numerous applications, including biomedical imaging, remote sensing, and optical communication. Since polarization cannot be measured directly, it is typically inferred by converting it into intensity signals using dedicated optical elements. Conventional approaches, however, predominantly rely on bulky optical components, leading to considerably high fabrication costs and limited integration density. Here, we introduce a passive photonic integrated circuit capable of precisely determining the polarization state of visible free-space light. An silicon nitride on-chip architecture employing a compact polarization-splitting grating coupler and a set of passive interferometers encodes the polarization information into intensity signals, allowing conventional detectors to accurately reconstruct the polarization state. With increasing compactness of photonic components, however, susceptibility to fabrication tolerances as well as intrinsic design constraints increases, potentially leading to non\\-/ideal behaviour. To address this, we introduce a robust calibration procedure that enables precise measurements even in the presence of imperfections. The chip design, combined with the calibration procedure, offers a robust, small-footprint, and high-speed approach to polarimetry, enabling a wide range of applications.",
    "authors": [
      "Christoph Stockinger",
      "Natale G. Pruiti",
      "Isaac Tribaldo",
      "Jörg S. Eismann",
      "Marc Sorel",
      "Peter Banzer"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03921",
    "title": "Demonstration of a Raman Velocity Filter in Collinear Laser Spectroscopy: Towards Applications for sub-ppm High-Voltage Measurements",
    "abstract": "Raman transitions have a wide range of applications in atomic physics and have recently been proposed as a means for improving high-precision high-voltage measurements. Here, we present a theoretical analysis and a first experimental demonstration of $5s\\,^2\\mathrm{S}_{1/2} \\rightarrow 4d\\,^2\\mathrm{D}_{3/2,5/2}$ Raman transitions in $^{88}$Sr$^+$ ions in collinear laser spectroscopy. For the theoretical description the three-level system is reduced to an effective two-level system, in order to estimate the experimental parameters, while the role of the spatial laser intensity distribution in combination with the radial extension of the ion beam are elucidated by performing simulations of the full four-level system. Experimentally, we realized the first velocity-selective Raman transition in collinear laser spectroscopy. Using a $^{88}$Sr$^+$ ion beam, we demonstrate a reduction in the energy width to less than $200\\,$meV, which is about an order of magnitude reduction compared to the usage of an optical dipole transition as in previous works. We also investigate two-photon Rabi oscillations and show that their observed collapse is consistent with the simulations.",
    "authors": [
      "Julien Spahn",
      "Hendrik Bodnar",
      "Kristian König",
      "Wilfried Nörtershäuser"
    ],
    "primary_category": "physics.atom-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03942",
    "title": "Accounting for Solar Radiation Pressure in the Hamiltonian Normal Form of the Elliptic Restricted Three-Body Problem",
    "abstract": "Hamiltonian normal forms allow for the analytical approximation of center manifold trajectories and their invariant manifolds through the separation of the saddle and center subspaces that make up the dynamics at the collinear libration points within the elliptic restricted three-body problem. The circular restricted three-body problem is a special case of the elliptic problem-- one that does not take into account the eccentricity of the true orbits of the primaries and thus provides a dynamical model of varying accuracy depending on the true anomaly of the primaries. This paper first shows that the normal forms of the elliptic problem offer nearly identical trajectory characterization capabilities to those of the circular problem and then demonstrates the difference in fidelity by comparing the circular and elliptic normal form representations of ephemeris data for the James Webb Space Telescope. Furthermore, methodology for including solar radiation pressure within the normal form is introduced, and the same ephemeris data is used to demonstrate the resulting increase in fidelity of the dynamical model.",
    "authors": [
      "Carson Hunsberger",
      "David Schwab",
      "Roshan Eapen",
      "Puneet Singla"
    ],
    "primary_category": "physics.space-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03966",
    "title": "A CMOS+X Spiking Neuron With On-Chip Machine Learning",
    "abstract": "We present the design and numerical simulation of a spiking neuron capable of on-chip machine learning. Built within the CMOS+X framework, the spiking neuron consists of an NMOS transistor combined with a magnetic tunnel junction (MTJ). This NMOS+MTJ unit, when simulated in the industry-standard circuit simulation software LTspice, reproduces multiple functions of a biological neuron, including threshold spiking, latency, refractory periods, synaptic integration, inhibition, and adaptation. These behaviors arise from the intrinsic magnetization dynamics of the MTJ and do not require any additional control circuitry. By interconnecting the NMOS+MTJ neurons, we construct a model of an analog multilayer network that learns through spike-timing-dependent weight updates derived from a gradient-descent rule, with both training and inference modeled in the analog domain. The simulated CMOS+X network achieves reliable spike propagation and successful training on a nonlinear task, indicating a feasible path toward compact, low-power, in-memory neuromorphic hardware for edge applications.",
    "authors": [
      "Steven Louis",
      "Matthew Blake Abramson",
      "Hannah Bradley",
      "Cody Trevillian",
      "Gene David Nelson",
      "Andrei Slavin",
      "Artem Litvinenko",
      "Jason Gorski",
      "Ilya N. Krivorotov",
      "Darrin Hanna",
      "Vasyl Tyberkevych"
    ],
    "primary_category": "physics.app-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03969",
    "title": "Vortex Dynamics from Burst-and-Coast Motion of Anguilliform and Carangiform Swimmers",
    "abstract": "Fish perform various propulsive maneuvers while swimming by generating traveling waves along their bodies and producing thrust through tail strokes. Anguilliform swimmers spread motion along the body, while carangiform swimmers' motion is more prominent near their tails. Many species also switch between continuous undulation and intermittent swimming, such as burst-and-coast maneuver, which can save energy but can also change the wake structure and hydrodynamic forces. Our current study aims at explaining} how duty cycle (DC), undulatory gaits, and Strouhal number (St), shape the near-body vortices, overall wakes, and the hydrodynamic forces. We carry out three-dimensional simulations at Re = 3000 for flows around an eel (anguilliform) and a Jack Fish (carangiform) for DC = 0.2-1.0 and St = 0.30 and 0.40. Our results reveal that the burst-and-coast motion for both swimmer produce bow-shaped wakes, the two rows of which on the sides approach each other to form a more coherent wake as DC is increased to 1.0 that corresponds to the wake of continuously undulating swimmers. It is also found that the intermittent motion at a higher Strouhal number produces more drag, contrary to the continuous undulatory kinematics. We further investigate this behavior by quantifying the strengths of vortices produced around the two swimmers and their instantaneous kinematic metrics. A detailed analysis for the role of different body sections in the production of unsteady streamwise forces is also presented. These insights provide important connections between the swimmers' physiologies, their kinematics, and the governing vortex dynamics to attain certain hydrodynamic metrics for designing next-generation autonomous bio-inspired underwater robots.",
    "authors": [
      "Zahra Maleksabet",
      "Maham Kamran",
      "Ali Tarokh",
      "Muhammad Saif Ullah Khalid"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03974",
    "title": "Refining Machine Learning Potentials through Thermodynamic Theory of Phase Transitions",
    "abstract": "Foundational Machine Learning Potentials can resolve the accuracy and transferability limitations of classical force fields. They enable microscopic insights into material behavior through Molecular Dynamics simulations, which can crucially expedite material design and discovery. However, insufficiently broad and systematically biased reference data affect the predictive quality of the learned models. Often, these models exhibit significant deviations from experimentally observed phase transition temperatures, in the order of several hundred kelvins. Thus, fine-tuning is necessary to achieve adequate accuracy in many practical problems. This work proposes a fine-tuning strategy via top-down learning, directly correcting the wrongly predicted transition temperatures to match the experimental reference data. Our approach leverages the Differentiable Trajectory Reweighting algorithm to minimize the free energy differences between phases at the experimental target pressures and temperatures. We demonstrate that our approach can accurately correct the phase diagram of pure Titanium in a pressure range of up to 5 GPa, matching the experimental reference within tenths of kelvins and improving the liquid-state diffusion constant. Our approach is model-agnostic, applicable to multi-component systems with solid-solid and solid-liquid transitions, and compliant with top-down training on other experimental properties. Therefore, our approach can serve as an essential step towards highly accurate application-specific and foundational machine learning potentials.",
    "authors": [
      "Paul Fuchs",
      "Julija Zavadlav"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03980",
    "title": "Quantum Diplomacy within the Southeast Asia Quantum Ecosystem",
    "abstract": "Amid the International Year of Quantum Science and Technology 2025 (IYQ 2025), a significant portion of global funding has been dedicated to various quantum initiatives, with over 30 countries announcing their respective quantum strategies. Within the Southeast Asia context, Singapore, Thailand, and the Philippines have launched their respective quantum strategies and roadmaps. Meanwhile, six out of eleven Southeast Asia countries have expressed interest in formulating a regional quantum ecosystem to pursue a set of common goals. Quantum technologies, though still in their infancy within the second quantum revolution, have advanced rapidly in recent years. Due to their dual-use nature, quantum technologies are considered emerging and disruptive, often raising concerns from the cybersecurity perspective. While several discussions regarding Malaysia's quantum initiative and strategy are ongoing, it is vital to broaden the conversation and position Malaysia within the regional ecosystem. This paper provides an overview of Malaysia's quantum landscape and a summary of the regional initiatives since the establishment of Southeast Asia Quantum Network. We then analyse Malaysia's strengths in quantum research and provide four recommendations to strengthen the regional ecosystem.",
    "authors": [
      "Pak Shen Choong",
      "Nurisya Mohd Shah",
      "Yung Szen Yap"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03985",
    "title": "Negative Index Makes a Perfect Time-Domain Lens, Generating Slow Playback of Ultrafast Events",
    "abstract": "We explore the effects of incorporating negative index materials into the physics of time-varying media and find that changing the refractive index from positive to negative creates a perfect time-reversed wave: a perfect time-domain lens. Unlike other mechanisms of phase conjugation, the perfect time-domain lens time-reverses both the propagating waves and the evanescent part of the spectrum. Moreover, we find that the time-reversed wave can be slowed down or accelerated, depending on the refractive index ratio. We show that this effect remains strong even when the refractive index varies arbitrarily slow, in sharp contradistinction to time-reflection which necessitates large index changes at sub-cycle rates. This is the first avenue found to yield significant negative-frequency waves using a temporal interface without the need for sub-cycle modulation or impedance matching. The effect can be used to record extreme ultrafast information and subsequently play it backwards at a slow rate, and vice-versa.",
    "authors": [
      "Oded Schiller",
      "Yonatan Plotnik",
      "Guy Bartal",
      "Mordechai Segev"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03993",
    "title": "Needle beams and structured space-time wavepackets",
    "abstract": "Recent research on needle beams and space-time wavepackets (STWPs) is presented. Quasi-nondiffracting STWPs propagate at stable spatial and temporal localization over extended distances. In a simple model, STWPs are interpreted as being composed of differential needle beams. Simulations indicate that pulsed Bessel-like needle beams can reach higher spectral and temporal homogeneity compared to spatio-spectrally shaped focused Gaussian beams. The interference of femtosecond needle beam arrays leads to nondiffracting self-imaging in space and time. High-speed switching of STWPs with combined optical systems, orbital angular momentum generation with self-torque and other emerging fields of research are addressed",
    "authors": [
      "Ruediger Grunwald",
      "Martin Bock"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03997",
    "title": "Comment on \"Monochromatization interaction region optics design for direct s-channel Higgs production at FCC-ee\"",
    "abstract": "The original article [1] can be logically divided into two parts: 1) the selection of main parameters for monochromatization and 2) interaction region optics design; the comment pertains only to the first part. The authors of [1] state that \"The purpose of this paper is to report on the development of realistic IR optics designs for monochromatization at the FCC-ee\". However, the proposed parameters do not seem very realistic and raise many questions.",
    "authors": [
      "Dmitry Shatilov"
    ],
    "primary_category": "physics.acc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03998",
    "title": "Respiration Rate Sensor Based on Fiber Cavity Attenuated Phase Shift Spectroscopy",
    "abstract": "Respiratory rate (RR) is a vital sign with significant diagnostic value. Existing RR monitors often suffer from baseline drift over time, breaths can be occluded by limb or body movements, and many systems struggle to resolve shallow or extreme thoracic motion. Here, we propose a novel RR-monitoring sensor based on fiber-cavity attenuated phase-shift spectroscopy~(CAPS). The sensor comprises a fiber cavity whose portion is embedded into a flexible chest binder in a sinusoidal-like pattern, which the patient wears. Thoracic expansion and contraction during breathing modulate the cavity, and RR is extracted through CAPS measurements. Our sensor exhibits high reproducibility, strong sensitivity to strain and pressure induced by chest movements, inherent resistance to baseline drift, and the ability to detect body movements. The system achieves a root-mean-square error of 0.91 breaths per minute relative to the ground truth, across RR values ranging from 8 to 44 breaths per minute, when tested on multiple subjects in various postures, including sitting, supine, prone, and lateral positions. We anticipate that this work will contribute to the development of comprehensive optical fiber-based sleep monitoring systems.",
    "authors": [
      "Muhammad Fahd Ibrahim",
      "Shazreen Rashid",
      "Noor-ul-Amin Nazir",
      "M. Imran Cheema"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04024",
    "title": "Predicting parameters of a model cuprate superconductor using machine learning",
    "abstract": "The computational complexity of calculating phase diagrams for multi-parameter models significantly limits the ability to select parameters that correspond to experimental data. This work presents a machine learning method for solving the inverse problem - forecasting the parameters of a model Hamiltonian for a cuprate superconductor based on its phase diagram. A comparative study of three deep learning architectures was conducted: VGG, ResNet, and U-Net. The latter was adapted for regression tasks and demonstrated the best performance. Training the U-Net model was performed on an extensive dataset of phase diagrams calculated within the mean-field approximation, followed by validation on data obtained using a semi-classical heat bath algorithm for Monte Carlo simulations. It is shown that the model accurately predicts all considered Hamiltonian parameters, and areas of low prediction accuracy correspond to regions of parametric insensitivity in the phase diagrams. This allows for the extraction of physically interpretable patterns and validation of the significance of parameters for the system. The results confirm the promising potential of applying machine learning to analyze complex physical models in condensed matter physics.",
    "authors": [
      "V. A. Ulitko",
      "D. N. Yasinskaya",
      "S. A. Bezzubin",
      "A. A. Koshelev",
      "Y. D. Panov"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04027",
    "title": "Teaching Using Immersion - Explaining Magnetism and Eclipses in a Planetarium Dome",
    "abstract": "Previously we have shown that three-dimensional concepts are more readily learned in a three-dimensional context. Although VR headsets are growing in popularity, they only provide a quite limited field of view, and each person in a group may be viewing a different direction or a different time in the visualization. By using instead a fullsphere movie (VR360) in a planetarium dome instead of a headset, you can \"share the VR\"(TM) and specify which half of the sphere your audience is looking at. You can pause the movie, ask questions using a clicker system, display the results, and move on if the subject is mastered or explain more if items are not understood. This paper shows the results of teaching magnetism in a dome theater, showing that both students and teachers nearly double their understanding of magnetism topics after one viewing. We also created seven animations explaining eclipses that were distributed free to nearly 200 planetariums. Listing of concepts learned by teachers in our live eclipse program are shown.",
    "authors": [
      "Patricia H Reiff",
      "Carolyn Sumners"
    ],
    "primary_category": "physics.ed-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04033",
    "title": "Demonstration of KV-Class \\b{eta}-Ga2O3 Trench Junction Barrier Schottky Diodes with SpaceModulated Junction Termination Extension",
    "abstract": "In this work, we report on the design and fabrication of p-NiO/Ga2O3 trench junction barrier schottky diodes (JBSD) integrated with space-modulated junction termination extension (SM-JTE) and compare the performance with planar Ni/Ga2O3 schottky diodes (SBDs) and p-NiO/Ga2O3 heterojunction diodes (HJDs). The JBSDs achieved breakdown voltages exceeding 1.8 kV along with low leakage currents (<10-2 A/cm2), while displaying low turn on voltage (VON) of ~1V, which is similar to that of planar Ni/Ga2O3 SBDs. The fabricated devices showed excellent forward characteristics with low differential on-resistance (Ron,sp) ranging from 4-10.5 m{\\Omega}-cm2, for fin width between 0.6- 1.25 microns. Best performing device with fin width of 0.85{\\mu}m showed a unipolar figure of merit (FOM) of ~0.7GW/cm2. This work showcases the benefits of trench JBS design along with SM-JTE edge-termination for efficient high-performance kilovolt-class \\b{eta}- Ga2O3 diodes.",
    "authors": [
      "Advait Gilankar",
      "Julian Gervassi-Saga",
      "Martha R. McCartney",
      "Nabasindhu Das",
      "David Malcolm McComas",
      "David J. Smith",
      "Nidhin Kurian Kalarickal"
    ],
    "primary_category": "physics.app-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04052",
    "title": "Post-Cold War Diaspora of Russian Particle Physicists",
    "abstract": "While the migration of scientists from the Soviet Union to the West occurred at a modest pace during the 1970s and 1980s, the dissolution of the USSR in 1991 and the ensuing economic and social hardships precipitated a massive exodus that amounted to a true brain drain. The international physics community, particularly in Europe and the United States, absorbed a substantial influx of specialists in nuclear, high-energy, and accelerator physics, including both seasoned scientists and engineers as well as promising graduate students and postdoctoral fellows. Many of these emigre researchers went on to assume leadership positions, drive major experimental and theoretical initiatives, and achieve scientific distinction that equaled or even surpassed their accomplishments at home. In this article we explore the defining features of this post Cold War scientific diaspora, assess its impact on Russia research infrastructure and capabilities, and evaluate its enduring contributions to global particle physics collaborations and discoveries.",
    "authors": [
      "Vladimir Shiltsev"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04073",
    "title": "Noise-induced stop-and-go traffic dynamics: Modelling and control",
    "abstract": "This contribution investigates an original stochastic approach for the emergence of stop-and-go waves in traffic flow, a collective phenomenon with significant safety and environmental implications. Using a stable nonlinear car-following model, the study shows that minimal white Gaussian noise can destabilise the flow, leading to a phase transition from laminar to periodic dynamics through a nonlinear instability phenomenon, analogous to Kapitza's pendulum. Furthermore, a simple linear transformation of the model, which amplifies the response and introduces a positive acceleration bias, counteracts noise-induced effects and recovers the stability of uniform solutions. The findings are supported by simulations, offering new insights into the modelling and mitigation of oscillatory traffic dynamics.",
    "authors": [
      "Raphael Korbmacher",
      "Parthib Khound",
      "Antoine Tordeux",
      "Frank Gronwald"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.03937",
    "title": "Unveiling the different scaling regimes of the one-dimensional Kardar-Parisi-Zhang--Burgers equation using the functional renormalisation group",
    "abstract": "The Kardar-Parisi-Zhang (KPZ) equation is a celebrated non-linear stochastic equation featuring non-equilibrium scaling. Although in one dimension, its statistical properties are very well understood, a new scaling regime has been reported in recent numerical simulations. This new regime is characterised by a dynamical exponent $z=1$, markedly different from the expected one $z=3/2$ for the KPZ universality class, and it emerges when approaching the inviscid limit. The origin of this scaling has been traced down to the existence of a new fixed point, termed the inviscid Burgers (IB) fixed point, which was uncovered using the functional renormalisation group (FRG). The FRG equations can be solved analytically in the asymptotic regime of vanishing viscosity and large momenta, showing that indeed $z=1$ exactly at the IB fixed point. In this work, we set up an advanced method to numerically solve the full FRG flow equations in a certain approximation, which allows us to determine in a unified way the correlation function over the whole range of momenta, not restricted to some particular regime. We analyse the crossover between the different fixed points, and quantitatively determine the extent of the IB regime.",
    "authors": [
      "Liubov Gosteva",
      "Nicolás Wschebor",
      "Léonie Canet"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02202",
    "title": "Progress in quantum metrology and applications for optical atomic clocks",
    "abstract": "Quantum entanglement offers powerful opportunities for enhancing measurement sensitivity beyond classical limits, with optical atomic clocks serving as a leading platform for such advances. This chapter introduces the principles of entanglement-enhanced quantum metrology and explores their applications to timekeeping. We review the theoretical framework of quantum phase estimation, comparing frequentist and Bayesian approaches, and discuss paradigmatic entangled states such as spin-squeezed and GHZ states. Particular emphasis is placed on the challenges posed by decoherence, which constrain the practical advantages that can be realized in large-scale devices. The discussion then turns to frequency estimation in atomic clocks, highlighting how experimental constraints shape the translation of abstract quantum limits into real performance gains. Finally, we outline emerging directions of contemporary quantum metrology. Together, these developments underscore the increasingly close interplay between quantum information processing and precision metrology.",
    "authors": [
      "Raphael Kaubruegger",
      "Adam M. Kaufman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03050",
    "title": "Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling",
    "abstract": "Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.",
    "authors": [
      "Peter Hedström",
      "Victor Lamelas Cubero",
      "Jón Sigurdsson",
      "Viktor Österberg",
      "Satish Kolli",
      "Joakim Odqvist",
      "Ziyong Hou",
      "Wangzhong Mu",
      "Viswanadh Gowtham Arigela"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03054",
    "title": "Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research",
    "abstract": "Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.",
    "authors": [
      "Ciro Benito Raggio",
      "Lucia Migliorelli",
      "Nils Skupien",
      "Mathias Krohmer Zabaleta",
      "Oliver Blanck",
      "Francesco Cicone",
      "Giuseppe Lucio Cascini",
      "Paolo Zaffino",
      "Maria Francesca Spadea"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03061",
    "title": "Accumulated Local Effects and Graph Neural Networks for link prediction",
    "abstract": "We investigate how Accumulated Local Effects (ALE), a model-agnostic explanation method, can be adapted to visualize the influence of node feature values in link prediction tasks using Graph Neural Networks (GNNs), specifically Graph Convolutional Networks and Graph Attention Networks. A key challenge addressed in this work is the complex interactions of nodes during message passing within GNN layers, complicating the direct application of ALE. Since a straightforward solution of modifying only one node at once substantially increases computation time, we propose an approximate method that mitigates this challenge. Our findings reveal that although the approximate method offers computational efficiency, the exact method yields more stable explanations, particularly when smaller data subsets are used. However, the explanations produced with the approximate method are not significantly different from the ones obtained with the exact method. Additionally, we analyze how varying parameters affect the accuracy of ALE estimation for both approaches.",
    "authors": [
      "Paulina Kaczyńska",
      "Julian Sienkiewicz",
      "Dominik Ślęzak"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03114",
    "title": "Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data",
    "abstract": "The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.",
    "authors": [
      "Srijani Mukherjee",
      "Laurent Vuillon",
      "Liliane Bou Nassif",
      "Stéphanie Giroux-Julien",
      "Hervé Pabiou",
      "Denys Dutykh",
      "Ionnasis Tsanakas"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03120",
    "title": "Enhanced slow magnetic-Coriolis waves with magnetic field orthogonal to rotation axis",
    "abstract": "We consider an isolated Gaussian velocity vortex perturbation in an otherwise quiescent, electrically conducting, and rotating fluid permeated by a uniform magnetic field $\\bf{B}$. Studies suggest a presence of strong azimuthal wave motions on the timescale of centuries within the Earth's liquid outer core at higher latitudes. To understand these long-period oscillations, we focus on magnetostrophic waves, a slow component of magnetic-Coriolis waves with $\\bf{B}$ orthogonally aligned with the rotation vector $\\bf{\\Omega}$, which replicate the field lines in the azimuthal direction. We present an analytical solution to the magnetic-Coriolis wave equation in Cartesian coordinates. Later, with numerical solution, we validate our analytical estimates and show that magnetostrophic waves travel relatively faster along the magnetic field when $\\bf{B} \\perp \\bf{\\Omega}$ compared with the case when both are aligned. The study confirms that with a magnetic field $\\bf{B}$ orthogonally aligned to the rotation vector $\\bf{\\Omega}$, wave vectors satisfying the condition $\\bf{\\Omega}\\cdot\\bf{k} \\approx 0$, travel with Alfvén velocities along the magnetic field lines as a component of inertial-Alfvén waves. The timescales on which Alfvén waves travel are relatively short, and it is also less likely that inertial-Alfvén waves will be sustained inside the core at higher latitudes \\citep{Davidson2017}. This study shows that, excluding the inertial-Alfvén waves contribution ($k_z\\neq 0$), there exists intensified magnetostrophic wave propagation when $\\bf{B} \\perp \\bf{\\Omega}$, which can explain the strong periodic oscillations on the time scales of centuries along the azimuthal field at higher latitudes. Results show persistence of the magnetostrophic waves despite the lower Lehnert number $Le$, suggesting the plausible existence of a low-intensity azimuthal magnetic field in the Earth's core.",
    "authors": [
      "Raviraj Narayan Shinde",
      "Ghanesh Narasimhan"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03127",
    "title": "Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra",
    "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at this https URL .",
    "authors": [
      "Ziyu Xiong",
      "Yichi Zhang",
      "Foyez Alauddin",
      "Chu Xin Cheng",
      "Joon Soo An",
      "Mohammad R. Seyedsayamdost",
      "Ellen D. Zhong"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03177",
    "title": "Magic of the Well: assessing quantum resources of fluid dynamics data",
    "abstract": "We investigate the quantum resource requirements of a dataset generated from simulations of two-dimensional, periodic, incompressible shear flow, aimed at training machine learning models. By measuring entanglement and non-stabilizerness on MPS-encoded functions, we estimate the computational complexity encountered by a stabilizer or a tensor network solver applied to Computational Fluid Dynamics (CFD) simulations across different flow regimes. Our analysis reveals that, under specific initial conditions, the shear width identifies a transition between resource-efficient and resource-intensive regimes for non-trivial evolution. Furthermore, we find that the two resources qualitatively track each other in time, and that the mesh resolution along with the sign structure play a crucial role in determining the resource content of the encoded state. These findings offer useful guidelines for the development of scalable, quantum-inspired approaches to fluid dynamics.",
    "authors": [
      "Antonio Francesco Mello",
      "Mario Collura",
      "E. Miles Stoudenmire",
      "Ryan Levy"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03190",
    "title": "Computer Simulation of the Growth of a Metal-Organic Framework Proto-crystal at Constant Chemical Potential",
    "abstract": "Designing metal-organic frameworks (MOFs) synthesis protocols is currently largely driven by trial-and-error, since we lack fundamental understanding of the molecular level mechanisms that underlie their self-assembly processes. Previous works have studied the nucleation of MOFs, but their growth has never been studied by means of computer simulations, which provide molecular level detail. In this work, we combine constant chemical potential simulations with a particle insertion method to model the growth of the ZIF-8 MOF at varying synthesis temperatures and concentrations of the reactants. Non-classical growth mechanisms triggered by oligomer attachments were detected, with a higher predominance in the most concentrated setups. The newly formed layers preserve the pore-like density profile of the seed crystal but contain defective sites characterized by the presence of 3, 5 and 7 membered rings, typical of amorphous phases. Compared to the amorphous intermediate species obtained at the nucleation part of the self-assembly process previously investigated in our group [Chem. Mater., doi: https://doi.org/10.1021/acs.chemmater.5c02028 , 2025], larger-sized rings are more common in the grown layer. Moreover, these are favored by increasing reactant concentration and temperature, as is the degree of deviation with respect to the original crystal structure. We computed growth rates for the steady-state regime, and the non-linear tendency with respect to concentration leads us to hypothesize that in these conditions the growth is controlled by the adsorption rather than by the diffusion processes.",
    "authors": [
      "Sahar Andarzi Gargari",
      "Emilio Méndez",
      "Rocio Semino"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03218",
    "title": "Tunable Thin Elasto-Drops",
    "abstract": "We present an experimental method to fabricate centimetric thin elastic capsules with highly uniform thickness and negligible bending stiffness using silicone elastomers. In our experiments, the capsules thickness is tunable at fabrication, while internal pressure and hoop (circumferential) stress are adjustable via hydrostatic inflation once the capsules are filled and immersed in water. Capsules mechanics are probed through hydro-elastic waves generated by weak mechanical perturbations at the capsule interface. By analyzing the surface wave dynamics in the Fourier domain, we extract the in-plane stress and demonstrate that the hydro-elastic waves are exclusively governed by hoop stress. This establishes a direct analogy with liquid drops characterised by an effective surface tension, allowing the capsules to be modeled as large-scale \"elasto-drops\" with an inflation and thickness tunable effective surface tension. Our work demonstrates that elasto-drops serve as a robust model system for parametric studies of large-scale liquid drops with experimentally adjustable surface tension.",
    "authors": [
      "Antonin Eddi",
      "Stéphane Perrard",
      "Jishen Zhang"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03290",
    "title": "ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics",
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.",
    "authors": [
      "Julian Evan Chrisnanto",
      "Nurfauzi Fadillah",
      "Yulison Herry Chrisnanto"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03330",
    "title": "Simpson variational integrator for nonlinear systems: a tutorial on the Lagrange top",
    "abstract": "This contribution presents an integration method based on the Simpson quadrature. The integrator is designed for finite-dimensional nonlinear mechanical systems that derive from variational principles. The action is discretized using quadratic finite elements interpolation of the state and Simpson's quadrature, leading to discrete motion equations. The scheme is implicit, symplectic, and fourth-order accurate. The proposed integrator is compared with the implicit midpoint variational integrator on two examples of systems with inseparable Hamiltonians. First, the example of the nonlinear double pendulum illustrates how the method can be applied to multibody systems. The analytical solution of the Lagrange top is then used as a reference to analyze accuracy, convergence, and precision of the numerical method. A reduced Lagrange top system is also proposed and solved with a classical fourth-order method. Its solution is compared with the Simpson solution of the complete system, and the convergence order of the difference between both is consistent with the order of the classical method.",
    "authors": [
      "Juan Antonio Rojas-Quintero",
      "François Dubois",
      "Frédéric Jourdan"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03333",
    "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State",
    "abstract": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.",
    "authors": [
      "Xun Tang",
      "Haoxuan Chen",
      "Yuehaw Khoo",
      "Lexing Ying"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03355",
    "title": "Anomalous Hall effect in an amorphous antiferromagnet with inverted hysteresis",
    "abstract": "Stemming from antiferromagnetic coupling, exchange bias allows inverted hysteresis in a magnetic system. Such room temperature magnetic reversal has yet to be observed in an amorphous antiferromagnet. Furthermore, the impact of this exchange bias effect on its magnetoelectric transport behavior remains a mystery. Here we discovered a zero-field magnetization switching effect in an exchange-biased amorphous antiferromagnet with inverted magnetic hysteresis. This zero-field magnetic reversal was further evidenced by its inverted large anomalous Hall effect. Notably, this collective spin flipping at zero field can occur at room temperature or above room temperature, which may be associated with quantum interference effect due to thermal fluctuation enhanced disorder. Our experimental results offer a way to design room-temperature exchange-biased amorphous antiferromagnets with zero-field multi magnetic-states and large anomalous Hall effect, holding potential for low-power and high-density memory applications.",
    "authors": [
      "Xiangning Du",
      "Yuxiang Zhu",
      "Na Chen"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03365",
    "title": "Generative Refinement:A New Paradigm for Determining Single Crystal Structures Directly from HKL Data",
    "abstract": "Single-crystal X-ray diffraction (SC-XRD) is the gold standard technique to characterize crystal structures in solid state. Despite significant advances in automation for structure solution, the refinement stage still depends heavily on expert intervention and subjective judgment, limiting accessibility and scalability. Herein, we introduce RefrActor, an end-to-end deep learning framework that enables crystal structure determination directly from HKL data. By coupling a physics-informed reciprocal-space encoder (ReciEncoder) with a symmetry-aware diffusion-based generator (StruDiffuser), RefrActor produces fully refined atomic models without requiring initial structural guesses or manual input. Comprehensive evaluations on the GenRef-10k benchmark demonstrates that RefrActor achieves low R1-factors across diverse systems, including low-symmetry, light-atom, and heavy-atom crystals. Case studies further confirm that RefrActor can correctly resolve hydrogen positions, elemental assignments, and moderate disorder. This work establishes a new data-driven paradigm for autonomous crystallographic analysis, offering a foundation for fully automated, high-throughput crystal structure determination.",
    "authors": [
      "Wen-Lin Luo",
      "Yi Yuan",
      "Cheng-Hui Li",
      "Yue Zhao",
      "Jing-Lin Zuo"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03368",
    "title": "Short-Range Modulated Electron Lattice and d-Wave Superconductivity in Cuprates: A Phenomenological Ginzburg-Landau Framework",
    "abstract": "We develop a phenomenological Ginzburg-Landau (GL) framework for high-$T_c$ cuprates in which a short-range modulation of the electronic charge density couples to a $d$-wave superconducting condensate. The resulting modulated electron lattice (MEL) state is distinct from long-range static charge density wave order: it is short range, partially phase coherent, and linked to superconducting coherence. A preferred wave vector $q^{\\ast} \\approx 0.3$ reciprocal lattice units along the Cu-O bond direction emerges from the interplay between a momentum-dependent susceptibility and bond-stretching phonons, consistent with neutron and x-ray data on YBa$_2$Cu$_3$O$_{7-\\delta}$ and related cuprates. The GL free energy contains coupled $d$-wave superconducting and charge sectors with parameters constrained by optimally doped YBa$_2$Cu$_3$O$_{7-\\delta}$. We identify an MEL enhancement window in doping, temperature, MEL correlation length, and disorder where a coherence linked modulation enhances the superfluid stiffness. Classical Monte Carlo simulations yield an in-plane stiffness enhancement of order ten percent, which we treat as a qualitative prediction to be tested by self-consistent Bogoliubov de Gennes calculations. The MEL framework yields falsifiable experimental signatures. For scanning tunneling spectroscopy in Bi-based cuprates we highlight two predictions: the Fourier-transformed local density of states should exhibit a $q^{\\ast} \\approx 0.3$ peak whose spectral weight sharpens as superconducting phase coherence develops below $T_c$, in contrast to static charge scenarios, and the local gap magnitude $\\Delta(r)$ should correlate positively with the local MEL amplitude. The framework implies correlations between MEL correlation length, superfluid stiffness, disorder, and vortex pinning, and organizes cuprate observations into testable STM/STS predictions.",
    "authors": [
      "Jaehwahn Kim",
      "Davis A. Rens",
      "Waqas Khalid",
      "Hyunchul Kim"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03372",
    "title": "On the Accuracy of Atomic Resolution Electrostatic Measurements in 2D Materials",
    "abstract": "The use of differential phase contrast (DPC) in scanning transmission electron microscopy (STEM) has shown much promise for directly investigating the functional properties of a material system, leveraging the natural coupling between the electron probe and atomic-scale electric fields to map the electrostatic configuration within a sample. However, the high sensitivity of these measurements makes them particularly vulnerable to variations in both sample properties and the configuration of the instrument, stressing the need for robust methodologies to ensure more accurate analyses. In this work, the influence of key instrumental parameters - probe convergence angle, defocus and two-fold astigmatism - on atomic-resolution segmented-detector DPC-STEM measurements is evaluated through extensive image simulations. Results show that the limit of interpretability for a 21 mrad defocused probe is found at a magnitude of 4 nm, where electrostatic field magnitude can be underestimated by about 16 % in overfocus and just above 10 % in underfocus. Equivalent results for a 30 mrad probe demonstrate underestimated values around 30 % at overfocus and 20 % for underfocus, at a lower interpretability limit of 3 nm. Two-fold astigmatism introduces orientation dependent variations that surpass 40 % for magnitudes below 3 nm, but a reduction in sensitivity to the aberration is observed when oriented along detector-segment edges. Overall, the analysis confirms the sensitivity and usefulness of the scattergram-based method and underscores the importance of optimized instrumental alignment for accurate CoM based STEM imaging.",
    "authors": [
      "Rafael V. Ferreira",
      "Sebastian Calderon V.",
      "Paulo J. Ferreira"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03387",
    "title": "Tetragonal Fe2O: the stable iron oxide at Earth's core conditions",
    "abstract": "The Fe-O system is fundamental to understanding the composition and properties of the Earth's core. Recent studies have suggested the possible existence of stable, iron-rich FenO compounds at around 215 GPa. Here, we performed crystal-structure searches and fully anharmonic free-energy calculations to investigate the Fe-FeO system under inner-core conditions. We identified Fe2O as a stable phase and constructed its high P-T phase diagram. Fe2O undergoes a hexagonal-to-tetragonal transition with increasing pressure and temperature. It remains thermodynamically stable against decomposition into Fe and FeO from 200 to 400 GPa and at high temperatures. Although oxygen has been considered nearly absent in the inner core due to its limited solubility, these results suggest that oxygen can, in fact, be incorporated into the solid inner core in the form of an Fe+Fe2O mixture, and can match PREM densities for 53 mol% Fe2O. Our work has the potential to lead to a significant revision of the current understanding of the core's structure and composition.",
    "authors": [
      "Junjie Jiang",
      "Zhen Zhang",
      "Tongqi Wen",
      "Renata M. Wentzcovitch",
      "Yang Sun"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03435",
    "title": "Unconventional Magneto-Optical Effects in Altermagnets",
    "abstract": "The ideal altermagnets are a class of collinear, crystal-symmetry-enforced fully compensated magnets with nonrelativistic spin-split bands, in which contributions from Berry curvature to magneto-optical effects (MOEs) are strictly forbidden by an effective time-reversal symmetry. Here we show that, in such systems, MOEs are exclusively induced by the quantum metric and, in realistic altermagnets, are typically dominated by it. We refer to Berry-curvature-induced MOEs as conventional MOEs and to quantum-metric-dominated MOEs as unconventional MOEs. We derive general formulas that incorporate both Berry curvature and quantum metric for unconventional MOEs in altermagnets, enabling a quantitative evaluation of their respective contributions. Through symmetry analysis, we prove that ideal altermagnets are constrained to exhibit only unconventional MOEs. Using the three-dimensional canonical altermagnet MnTe and the emerging two-dimensional bilayer twisted altermagnet CrSBr as illustrative examples, we demonstrate that unconventional MOEs are prevalent in altermagnets. Our results establish altermagnets as a natural platform for quantum-metric-driven optical phenomena, substantially broadening the scope of MOEs and providing concrete predictions that can be tested in future experimental studies.",
    "authors": [
      "Yongpan Li",
      "Yichen Liu",
      "Cheng-Cheng Liu"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03443",
    "title": "Subgrid Mean-field Dynamo Model with Dynamical Quenching in General Relativistic Magnetohydrodynamic Simulations",
    "abstract": "Large-scale magnetic fields are relevant for a number of dynamical processes in accretion disks, including driving turbulence, reconnection events, and launching outflows. Numerical simulations have indicated that the initial strengths and configurations of the large-scale magnetic fields have a direct imprint on the outcome of an accretion disk evolution. To facilitate future self-consistent simulations that include intrinsic dynamo processes, we derive and implement a subgrid model of a helical large-scale dynamo with dynamical quenching in general-relativistic resistive magnetohydrodynamical simulations of geometrically thin accretion disks. By incorporating previous numerical and analytical results of helical dynamos, our model features only one input parameter, the viscosity parameter $\\alpha_\\text{SS}$. We demonstrate that our model can reproduce butterfly diagrams seen in previous local and global simulations. With rather aggressive parameter choice of $\\alpha_\\text{SS}=0.02$ and black hole spin $a_\\text{BH}=0.9375$, our thin-disk model launches weak collimated polar outflows with Lorentz factor $\\simeq 1.2$, but no polar outflow is present with less vigorous turbulence or less positive $a_\\text{BH}$. With negative $a_\\text{BH}$, we find the field configurations to appear more similar to Newtonian cases, whereas for positive $a_\\text{BH}$, the poloidal field loops become distorted and the cycle period becomes sporadic or even disappears. Moreover, we demonstrate how $\\alpha_\\text{SS}$ can avoid to be prescribed and instead be determined by the local plasma beta. Such a fully dynamical subgrid dynamo allows for self-consistent amplification of the large-scale magnetic fields.",
    "authors": [
      "Hongzhe Zhou",
      "Yosuke Mizuno",
      "Zhenyu Zhu"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03472",
    "title": "Quasi-linear theory of perpendicular ion heating by critically balanced turbulence",
    "abstract": "In collisionless astrophysical plasmas, turbulence mediates the partitioning of free energy among cascade channels and its dissipation into ion and electron heat. The resulting ion heating is often anisotropic, with ions observed to be preferentially heated perpendicular to the local magnetic field; understanding the mechanisms responsible for this heating is a key step in understanding the evolution of such plasmas. In this paper, we use the framework of quasi-linear theory to compute analytically the heating rates of ions interacting with turbulent, large-scale Alfvénic fluctuations. We show how the imbalance of the turbulence (the difference in energies between Alfvénic fluctuations travelling parallel and antiparallel to the magnetic field) modifies the spatiotemporal spectrum of these fluctuations, allowing the heating mechanism to transition between two commonly-studied mechanisms: stochastic heating in balanced turbulence to resonant-cyclotron heating in imbalanced turbulence. The resultant heating rate is found to have a general form regardless of the level of imbalance, exhibiting a suppression related to the conservation of the ions' magnetic moment at small turbulent amplitudes and recovering previous empirical results in a formal calculation. The results of this work help to consolidate our qualitative understanding of ion heating within astrophysical plasmas, as well as yielding specific quantitative predictions to analyse simulations and observations.",
    "authors": [
      "Zade Johnston",
      "Jonathan Squire"
    ],
    "primary_category": "astro-ph.SR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03476",
    "title": "ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms",
    "abstract": "Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop\" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.",
    "authors": [
      "Juan Diego Toscano",
      "Daniel T. Chen",
      "George Em Karniadakis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03496",
    "title": "Constraint-Preserving High-Order Compact OEDG Method for Spherically Symmetric Einstein-Euler System",
    "abstract": "Numerical simulation of the spherically symmetric Einstein--Euler (EE) system faces severe challenges due to the stringent physical admissibility constraints of relativistic fluids and the geometric singularities inherent in metric evolution. This paper proposes a high-order Constraint-Preserving (CP) compact Oscillation-Eliminating Discontinuous Galerkin (cOEDG) method specifically tailored to address these difficulties. The method integrates a scale-invariant oscillation-eliminating mechanism [M. Peng, Z. Sun, K. Wu, Math. Comp., 94: 1147--1198, 2025] into a compact Runge--Kutta DG framework. By characterizing the convex invariant region of the hydrodynamic subsystem with general barotropic equations of state, we prove that the proposed scheme preserves physical realizability (specifically, positive density and subluminal velocity) directly in terms of conservative variables, thereby eliminating the need for complex primitive-variable checks. To ensure the geometric validity of the spacetime, we introduce a bijective transformation of the metric potentials. Rather than evolving the constrained metric components directly, the scheme advances unconstrained auxiliary variables whose inverse mapping automatically enforces strict positivity and asymptotic bounds without any limiters. Combined with a compatible high-order boundary treatment, the resulting CPcOEDG method exhibits robust stability and design-order accuracy in capturing strong gravity-fluid interactions, as demonstrated by simulations of black hole accretion and relativistic shock waves.",
    "authors": [
      "Yuchen Huang",
      "Manting Peng",
      "Kailiang Wu"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03609",
    "title": "Hamiltonian Active Matter in Incompressible Fluid Membranes",
    "abstract": "Active proteins and membrane-bound motors exert force dipole flows along fluid interfaces and lipid bilayers. We develop a unified hydrodynamic and Hamiltonian framework for the interactions of pusher and puller dipoles embedded in an incompressible two-dimensional membrane supported by a shallow viscous subphase. Beginning from the screened Stokes equations of the membrane--subphase composite, we derive the real-space incompressible Green's tensor, obtain its near- and far-field asymptotics, and construct the resulting dipolar velocity and stream functions. Although generic dipoles reorient under the local membrane vorticity, we show that the far-field dipolar flow is vorticity-free; force-free motors therefore retain fixed orientation and obey a Hamiltonian dynamics in which the positions of $N$ dipoles evolve via an effective Hamiltonian built from the dipolar stream function. In the near field, where the flow possesses finite vorticity, a Hamiltonian formulation is recovered in the quenched-orientation limit. Exploiting this structure, we simulate ensembles of pusher and puller dipoles and compare the dynamics generated by the $1/r$ near-field kernel and the subphase screened $1/r^{3}$ far-field kernel. For identical dipoles, the far-field Hamiltonian produces rapid clustering from random initial conditions, whereas the near-field Hamiltonian suppresses collapse and yields extended, non-aggregating configurations.",
    "authors": [
      "Sneha Krishnan",
      "Rickmoy Samanta"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03623",
    "title": "The promising potential of vision language models for the generation of textual weather forecasts",
    "abstract": "Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.",
    "authors": [
      "Edward C. C. Steele",
      "Dinesh Mane",
      "Emilio Monti",
      "Luis Orus",
      "Rebecca Chantrill-Cheyette",
      "Matthew Couch",
      "Kirstine I. Dale",
      "Simon Eaton",
      "Govindarajan Rangarajan",
      "Amir Majlesi",
      "Steven Ramsdale",
      "Michael Sharpe",
      "Craig Smith",
      "Jonathan Smith",
      "Rebecca Yates",
      "Holly Ellis",
      "Charles Ewen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03653",
    "title": "Conditional updates of neural network weights for increased out of training performance",
    "abstract": "This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.",
    "authors": [
      "Jan Saynisch-Wagner",
      "Saran Rajendran Sari"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03705",
    "title": "Spin-flop driven interfacial tunneling magnetoresistance in an antiferromagnetic tunnel junction",
    "abstract": "The utilization of two-dimensional (2D) materials in magnetic tunnel junctions (MTJs) has shown excellent performance and rich physics. As for 2D antiferromagnets, the magnetic moments in different layers respond asynchronously and can be configured at various states under different magnetic fields, showing the possibility of efficient magnetic and electrical tunability. In this report, A-type antiferromagnetic (AFM) material (Fe0.5Co0.5)5GeTe2 (FCGT) works as electrodes to realize full van der Waals magnetic tunnel junctions. Owing to the interfacial effect, the even-layer FCGT, although with zero net magnetization, exhibits spin selectivity in MTJ architecture contributing to a tunneling magnetoresistance (TMR) reaching about 25% at a low operating current 1 nA at 100 K and persists near room temperature. Due to the surface spin-flop (SSF) effect in antiferromagnetic FCGT, the alternation flexibility between the volatile and nonvolatile memory behavior is achieved. The interfacial TMR can be tuned efficiently in amplitude and even sign under different bias currents and temperatures. These findings show precise magnetoelectric manipulation in MTJs based on 2D antiferromagnets and highlight the promise of 2D antiferromagnets for spintronic devices.",
    "authors": [
      "Xiaolin Ren",
      "Ruizi Liu",
      "Yiyang Zhang",
      "Yuting Liu",
      "Xuezhao Wu",
      "Kun Qian",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Qiming Shao"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03734",
    "title": "Revealing Nanoscale Molecular Organization in Liquid Crystals via Cryogenic Atom Probe Tomograph",
    "abstract": "While liquid crystals (LCs) have been extensively studied, obtaining a comprehensive nanoscale picture of their molecular organization remains challenging, as conventional techniques face an intrinsic trade-off between spatial and chemical resolution. Here, cryogenic atom probe tomography (cryo-APT) is introduced as a new analytical approach for LC materials, using 4'-Pentyl-4-cyanobiphenyl (5CB) and 4'-Octyl-4-cyanobiphenyl (8CB) as representative model compounds. This was enabled by a tailored cryogenic focused ion beam (cryo-FIB) protocol optimized for small organic molecules. The method enables controlled field evaporation of both intact molecules and diagnostic fragments, achieving over 90% molecular retention while preserving four characteristic dissociation patterns. By spatially correlating these fragmentation profiles with the local electric field derived from the tip geometry, we reveal field-directed dissociation pathways of CB molecules. In parallel, the distribution of intact molecular ions enables nanoscale visualization of material structure: we resolve homogeneous mixing of 5CB and 8CB in the nematic phase and directly observe the sub-nanometer crystalline layering in a supercooled 8CB sample, with contrast to the surrounding amorphous matrix suggesting the presence of a solid-liquid interface. This work establishes cryo-APT as a new powerful analytical platform for LC research and reveals its broad potential for application in soft matter systems.",
    "authors": [
      "Kuan Meng",
      "Kang'an Wang",
      "Sebastian Eich",
      "Pierre Nacke",
      "Johanna R. Bruckner",
      "Patrick Stender",
      "Frank Giesselmann",
      "Guido Schmitz"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03758",
    "title": "An end-to-end quantum algorithm for nonlinear fluid dynamics with bounded quantum advantage",
    "abstract": "Computational fluid dynamics (CFD) is a cornerstone of classical scientific computing, and there is growing interest in whether quantum computers can accelerate such simulations. To date, the existing proposals for fault-tolerant quantum algorithms for CFD have almost exclusively been based on the Carleman embedding method, used to encode nonlinearities on a quantum computer. In this work, we begin by showing that these proposals suffer from a range of severe bottlenecks that negate conjectured quantum advantages: lack of convergence of the Carleman method, prohibitive time-stepping requirements, unfavorable condition number scaling, and inefficient data extraction. With these roadblocks clearly identified, we develop a novel algorithm for the incompressible lattice Boltzmann equation that circumvents these obstacles, and then provide a detailed analysis of our algorithm, including all potential sources of algorithmic complexity, as well as gate count estimates. We find that for an end-to-end problem, a modest quantum advantage may be preserved for selected observables in the high-error-tolerance regime. We lower bound the Reynolds number scaling of our quantum algorithm in dimension $D$ at Kolmogorov microscale resolution with $O(\\mathrm{Re}^{\\frac{3}{4}(1+\\frac{D}{2})} \\times q_M)$, where $q_M$ is a multiplicative overhead for data extraction with $q_M = O(\\mathrm{Re}^{\\frac{3}{8}})$ for the drag force. This upper bounds the scaling improvement over classical algorithms by $O(\\mathrm{Re}^{\\frac{3D}{8}})$. However, our numerical investigations suggest a lower speedup, with a scaling estimate of $O(\\mathrm{Re}^{1.936} \\times q_M)$ for $D=2$. Our results give robust evidence that small, but nontrivial, quantum advantages can be achieved in the context of CFD, and motivate the need for additional rigorous end-to-end quantum algorithm development.",
    "authors": [
      "David Jennings",
      "Kamil Korzekwa",
      "Matteo Lostaglio",
      "Richard Ashworth",
      "Emanuele Marsili",
      "Stephen Rolston"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03766",
    "title": "Inaccessibility in Public Transit Networks",
    "abstract": "The study of networks derived from infrastructure systems has received considerable attention, yet the accessibility of such systems, particularly within public transit networks, remains comparatively underexplored. Accessibility encompasses a broad range of considerations, from infrastructure-based features such as elevators and step-free access to spatial factors such as the geographic distribution of accessible stations. In this work, we investigate infrastructure-based accessibility in two major transit systems: the London Underground and the New York City Subway. We construct network models in which nodes represent accessible stations and edges represent adjacency along transit lines. Using tools from network analysis, we examine the structural properties of these accessibility networks, including clustering patterns and the spatial distribution of accessible nodes. We further employ centrality measures to identify stations that serve as major accessible hubs. Finally, we analyze socioeconomic and tourism-related variables to assess the influence of neighborhood wealth and popularity on the prevalence of accessible stations. Our findings highlight significant disparities in accessibility across both systems and demonstrate the utility of mathematical and network-theoretic methods in understanding and improving modern transit infrastructure.",
    "authors": [
      "Katherine Betz"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03780",
    "title": "Poly- and single-crystalline diamond nitrogen-induced TLS losses estimation with superconducting lumped elements micro-resonators",
    "abstract": "Research on diamond has intensified due to its exceptional thermal, optical, and mechanical properties, making it a key material in quantum technologies and high-power applications. Diamonds with engineered nitrogen-vacancy (NV) centers represent a very sensitive platform for quantum sensing, while high-optical quality diamond windows represent a fundamental safety component inside Electron Cyclotron Resonance Heating (ECRH) systems in nuclear fusion reactors. A major challenge is the development of ultra-low-loss, high-optical-quality single-crystal diamond substrates to meet growing demands for quantum coherence and power handling. Traditionally, dielectric losses ($\\tan \\delta$) in diamonds are evaluated using Fabry-Perot microwave resonators, in which the resonance quality factors Q of the cavity with and without the sample are compared. These devices are limited to resolutions around 10$^{-5}$ by the need to keep the resonator dimensions within a reasonable range. In contrast, superconducting thin-film micro-strip resonators, with Q factors exceeding 10$^6$, are stated to provide higher sensitivity for assessing ultra-low-loss materials. This study examines four diamond samples grown through different processes, analyzing their dielectric losses at extreme low temperatures (sub-Kelvin) within the Two-Level System (TLS) framework. Complementary Raman spectroscopy measurements allowed us not only to associate higher nitrogen content with increased losses, but also to investigate how the different growth process influence the way these defects are incorporated in the crystal lattice.",
    "authors": [
      "Francesco Mazzocchi",
      "Martin Neidig",
      "Hideaki Yamada",
      "Sebastian Kempf",
      "Dirk Strauss",
      "Theo Scherer"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03876",
    "title": "Generalized Beth--Uhlenbeck entropy formula from the $Φ-$derivable approach",
    "abstract": "We derive a generalized Beth-Uhlenbeck formula for the entropy of a dense fermion system with strong two-particle correlations, including scattering states and bound states. We work within the $\\Phi-$derivable approach to the thermodynamic potential. The formula takes the form of an energy-momentum integral over a statistical distribution function times a unique spectral density. In the near mass-shell limit, the spectral density reduces, contrary to naïve expectations, not to a Lorentzian but rather to a \"squared Lorentzian\" shape. The relation of the Beth-Uhlenbeck formula to the $\\Phi$-derivable approach is exact at the two-loop level for $\\Phi$. The formalism we develop, which extends the Beth-Uhlenbeck approach beyond the low-density limit, includes Mott dissociation of bound states, in accordance with Levinson's theorem, and the self-consistent back reaction of correlations in the fermion propagation. We discuss applications to further systems, such as quark matter and nuclear matter.",
    "authors": [
      "David Blaschke",
      "Gerd Röpke",
      "Gordon Baym"
    ],
    "primary_category": "nucl-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03923",
    "title": "Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations",
    "abstract": "Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.",
    "authors": [
      "Xiang Rao",
      "Yina Liu",
      "Yuxuan Shen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03990",
    "title": "Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder",
    "abstract": "Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV.",
    "authors": [
      "Soha Ilbeigi",
      "Ashkan Bagherzadeh",
      "Alireza Sharifi"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2404.08459",
    "title": "Observation of Fine Structure in Channeling of Particles in Bent Crystals",
    "abstract": "We observed highly efficient manipulation of the 530 MeV positron beam at Mainz Microtron via bent crystals. The low beam divergence revealed a fine structure in the angular distribution of channeled particles. A compact analytical model, supported by Monte Carlo including multiple scattering, accounts for the measurements. We established a criterion for designing a crystal with reduced angular spread of channeled particles for beam manipulation at any energy. This finding is particularly useful in view of applications of channeling to the highest energies.",
    "authors": [
      "A. Mazzolari",
      "H. Backe",
      "L. Bandiera",
      "N. Canale",
      "D. De Salvador",
      "P. Drexler",
      "V. Guidi",
      "P. Klag",
      "W. Lauth",
      "L. Malagutti",
      "R. Negrello",
      "G. Paternò",
      "M. Romagnoni",
      "F. Sgarbossa",
      "A. Sytov",
      "V. Tikhomirov",
      "D. Valzani"
    ],
    "primary_category": "physics.acc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.04711",
    "title": "Robust pore-resolved CFD through porous monoliths reconstructed by micro-computed tomography: From digitization to flow prediction",
    "abstract": "Porous media are ubiquitous in energy storage and conversion, catalysis, biomechanics, hydrogeology, as well as many other fields. These materials possess high surface-to-volume ratios and their complex channels can restrict and guide the flow. However, optimizing design parameters for specific applications remains challenging due to the intricate structure of porous media. Pore-resolved CFD reveals the effects of their structure on flow characteristics, but is limited by the performance of mesh generation algorithms for such complex geometries. To alleviate this issue, we use a sharp immersed boundary method which enables usage of Cartesian, non-conformal grids, within a massively parallel finite element framework. This method preserves the order convergence of the scheme and allows for adaptive mesh refinement (AMR). We introduce a radial basis function-based representation of solids that allows to solve the flow through complex geometries with precision. We verify the method using the method of manufactured solutions. We validate it using pressure drop measurements through porous silicone monoliths digitized by X-ray computed microtomography, for pore Reynolds numbers up to 30. Simulations are conducted using grids of 200M cells distributed over 8k cores, which would require 16 times more cells without AMR. Results reveal that pore network structure is the principal factor describing pressure evolution and that preferential channels are dominant at this scale. In this work, we demonstrate a robust and efficient workflow for pore-resolved simulations of porous monoliths. This work bridges the gap between sub-millimetric flow and macroscopic properties, which will open the door to design and optimize processes through the usage of physics-based digital twins of complex porous media.",
    "authors": [
      "Olivier Guévremont",
      "Lucka Barbeau",
      "Vaiana Moreau",
      "Federico Galli",
      "Nick Virgilio",
      "Bruno Blais"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.11709",
    "title": "SynradG4: A Geant4-Based Extension for Synchrotron Radiation Background Studies in the ePIC Detector at the Electron-Ion Collider",
    "abstract": "The Electron-Ion Collider (EIC) will operate at high luminosity with multi-GeV, high-current electron beams, resulting in substantial synchrotron radiation (SR) emission in the electron storage ring (ESR). A detailed understanding of SR photon transport in the complex three-dimensional interaction region (IR) geometry is critical for estimating backgrounds in the ePIC detector and for developing effective shielding and masking strategies. This paper presents SynradG4, an EIC-specific extension of Geant4 designed for fast photon tracking in vacuum using established SR reflection and rough surface scattering models. SynradG4 integrates the photon reflection models of Synrad+ within the Geant4 geometry and field framework, while disabling all bulk matter interactions to achieve high-statistics transport through the 50-m-long IR vacuum system. Absorbed photon coordinates are then passed to a second-stage DD4hep simulation, where full electromagnetic processes such as photoabsorption, Compton scattering, Rayleigh scattering, and fluorescence are enabled for propagation through the beam pipe and detector materials. SynradG4 is not intended to replace general SR simulation codes; rather, it complements them by providing the workflow and geometry integration capabilities needed for EIC-specific background studies. Benchmark tests against Synrad+, Synrad3D, and the native Geant4 X-ray reflection model demonstrate excellent agreement for specular and diffuse reflection regimes. Using the full IR geometry and machine lattice, we present the first SR background estimates for the ePIC detector and evaluate the impact of potential SR masks.",
    "authors": [
      "Andrii Natochii"
    ],
    "primary_category": "physics.acc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.02355",
    "title": "Hybrid confinement techniques for polariton simulators",
    "abstract": "Exciton-polariton III-V semiconductor microcavities provide a robust platform for emulating complex Hamiltonians, enabling topological photonics and quantum simulation for advanced photonic functionalities. Here, we introduce two novel fabrication techniques - etch-and-oversputter and deposit-and-oversputter - that overcome limitations of traditional photonic confinement. Both use structured, locally elongated semiconductor cavities to create deep, highly controllable potentials, while leveraging high-quality GaAs-based materials, which achieve excellent Q-factors. A sputtered all-dielectric top mirror introduces an innovative hybrid approach, simplifying fabrication while maintaining quality compared to deep ion etching. Utilizing a Kagome lattice as a benchmark, we show high-quality optical band structures previously inaccessible with deep etching. Furthermore, we study a two-dimensional breathing Kagome lattice and demonstrate polariton lasing from a zero-dimensional corner mode, confirming precise control over couplings and tight polariton localization. These methods enable fabrication of intricate lattices, including higher-order topological insulators, or on-chip quantum regimes utilizing the polariton blockade mechanism due to tight photonic confinement.",
    "authors": [
      "Johannes Düreth",
      "Philipp Gagel",
      "David Laibacher",
      "Oleg A. Egorov",
      "Simon Widmann",
      "Simon Betzold",
      "Monika Emmerling",
      "Siddhartha Dam",
      "Alexia Landry",
      "Christian G. Mayer",
      "Martin Kamp",
      "Aniela Woyciechowska",
      "Barbara Piętka",
      "Ulf Peschel",
      "Sven Höfling",
      "Sebastian Klembt"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.07112",
    "title": "Miniature work-to-work converter engine powered by motor protein",
    "abstract": "Designing a miniature microscale engine that can override the role of thermal fluctuations has remained elusive and is an important open challenge. Here we provide the design and theoretical framework for a unique information-based engine - a work-to-work converter - comprising a sub-micron size bead and motor protein-microtubule (MT) complex in an optical trap setup. We demonstrate how by implementing a simple motor protein state-dependent feedback protocol of the optical trap stiffness, this engine is able to harness and convert the movement of a motor protein into work output. Unlike other conventional microengines, the fidelity and performance of this engine is determined by the stochasticity of motor (un)binding characteristics. We obtain an analytical form of the work distribution function, average work output and average power output, providing quantitative predictions for engine performance which are validated by stochastic simulations. Remarkably, the average work output per cycle is at least an order of magnitude higher than the thermal fluctuations and supersedes the performance of other microscale engines realized so far.",
    "authors": [
      "Suraj Deshmukh",
      "Sougata Guha",
      "Basudha Roy",
      "Shivprasad Patil",
      "Arnab Saha",
      "Sudipto Muhuri"
    ],
    "primary_category": "physics.bio-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.13126",
    "title": "Machine-learning-based simulation of turbulent flows over periodic hills using a hybrid U-Net and Fourier neural operator framework",
    "abstract": "Simulating massively separated turbulent flows over bodies is one of the major applications for large-eddy simulation (LES). In the current work, we propose a machine-learning-based LES framework for the rapid simulation of turbulent flows over periodic hills using a hybrid U-Net and Fourier neural operator (HUFNO) framework. The newly proposed HUFNO model integrates the strengths of both the convolutional neural network (CNN) and Fourier neural operator (FNO) in a novel way that the FNO is applied in the periodic directions of the flow field while the non-periodicity is handled by the CNN-based U-Net framework. In the numerical tests, compared to the original FNO and the U-Net framework, the HUFNO model shows a higher accuracy in the predictions of the velocity field and Reynolds stresses. Further numerical experiments in the LES show that the HUFNO framework outperforms the traditional Smagorinsky (SMAG) model and the wall-adapted local eddy-viscosity (WALE) model in the predictions of the turbulence statistics, the energy spectrum, the invariant characteristics of velocity gradients, the wall stresses and the flow separation structures, with much lower computational cost. Importantly, the accuracy and efficiency are transferable to unseen initial conditions, Reynolds number and hill shapes, underscoring its great potentials for the fast prediction of strongly separated turbulent flows over curved boundaries.",
    "authors": [
      "Yunpeng Wang",
      "Huiyu Yang",
      "Zelong Yuan",
      "Zhijie Li",
      "Wenhui Peng",
      "Jianchun Wang"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.10485",
    "title": "Symbolic Learning of Topological Bands in Photonic Crystals",
    "abstract": "Topological photonic crystals (PhCs) that support disorder-resistant modes, protected degeneracies, and robust transport have recently been explored for applications in waveguiding, optical isolation, light trapping, and lasing. However, designing PhCs with prescribed topological properties remains challenging because of the highly nonlinear mapping from the continuous real-space design of PhCs to the discrete output space of band topology. Here, we introduce a machine learning approach to address this problem, employing Kolmogorov--Arnold networks (KANs) to predict and inversely design the band symmetries of two-dimensional PhCs with two-fold rotational (C2) symmetry. We show that a single-hidden-layer KAN, trained on a dataset of C2-symmetric unit cells, achieves high accuracy in classifying the topological classes of the lowest lying bands. We use the symbolic regression capabilities of KANs to extract algebraic formulas that express the topological classes directly in terms of the Fourier components of the dielectric function. These formulas not only retain the full predictive power of the network but also provide novel insights and enable deterministic inverse design. Using this approach, we generate photonic crystals with target topological bands, achieving high accuracy even for high-contrast, experimentally realizable structures beyond the training domain.",
    "authors": [
      "Ali Ghorashi",
      "Sachin Vaidya",
      "Ziming Liu",
      "Charlotte Loh",
      "Thomas Christensen",
      "Max Tegmark",
      "Marin Soljačić"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.01022",
    "title": "Modelling and synthesizing turbulence with multi-scale coherent vortices",
    "abstract": "Turbulence is a complex system exhibiting both universal statistical features and prominent coherent structures. We model turbulence using coherent vortices distributed within a multi-scale statistical framework, termed `woven turbulence'. These entangled vortices are generated based on fractional Brownian bridges, with scale-dependent parameters set by dimensional analysis and geometric similarity. By integrating statistical and structural modeling, our approach naturally captures both the universal statistical features of turbulence and its coherent vortex structures. The spatial filling fraction of vortices in woven turbulence, termed `vortex density', is tunable, enabling us to investigate the statistical-structural interaction and uncover two concise physical insights of turbulence. First, the invariance of the hierarchical vortex density across scales corresponds to Kolmogorov's $-5/3$ law in the inertial range. Second, there exists a critical total vortex density at which the intermittency of woven turbulence closely matches that of real turbulence, and this critical density converges to a finite value in the inviscid limit. Deviating from this critical density reveals a negative correlation between intermittency and total vortex density. In addition, woven turbulence also serves as a fast turbulence synthesis method, requiring only the Taylor-Reynolds number as input and exhibiting an extremely low computational cost proportional to the grid size. It generates instantaneous turbulent fields at Taylor-Reynolds numbers of order $10^3$ on $4096^3$ grid points, with computational cost over five orders of magnitude lower than that of direct numerical simulation.",
    "authors": [
      "Zishuo Han",
      "Weiyu Shen",
      "Yue Yang"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.13350",
    "title": "Formation of abiogenic hydrocarbons in supercritical fluids under Earth's upper mantle conditions",
    "abstract": "The formation of hydrocarbons in Earth's interior has traditionally been considered to have biogenic origins; however, growing evidence suggests that some hydrocarbons may instead originate abiotically in the deep carbon cycle. It is widely expected that the Fisher-Tropsch-type (FTT) process, which typically refers to the conversion of inorganic carbon to organic matter in geological settings,may also happen in Earth's interior, but the absence of industrial catalysts and aqueous conditions in deep environments suggest that the FTT process can be very different from that in the chemical industry. Here, we performed extensive \\textit{ab initio} molecular dynamics (AIMD) simulations ($>$ 2.4 ns) to investigate the FTT synthesis in dry mixture and in aqueous solutions at 10-13 GPa and 1000-1400 this http URL found that large hydrocarbon-related species containing C, O, and H($>$C$_2$) are abiotically synthesized via the polymerization of CO without any catalyst. Supercritical water, commonly found in the deep Earth, does not prevent organic molecule formation but restricts product size and carbon this http URL studies reveal a previously unrecognized abiogenic route for hydrocarbon synthesis in mantle geofluids. These carbon-containing fluids could potentially migrate from depth to shallower crustal reservoirs, thereby influencing Earth's surface carbon budget.",
    "authors": [
      "Nore Stolte",
      "Tao Li",
      "Ding Pan"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.06473",
    "title": "Optoelectronic Physical Unclonable Functions and Reservoir-Inspired Computation with Low Symmetry Integrated Photonics",
    "abstract": "Emerging applications of photonics in computing, sensing, and security increasingly demand complex input-output behaviors, including highly nonlinear transformations of optical signals. Traditional photonic systems rely on highly structured components with symmetric geometries and low-entropy modal responses to achieve predictable and analytically describable behavior. To achieve expressive functionality, this paradigm often requires large networks of fabrication-sensitive interferometers or resonators and substantial hardware error correction to restore deterministic operation. Here we demonstrate an alternative paradigm rooted in low-symmetry, disordered integrated photonic circuits, which provide intrinsically enhanced modal diversity and spectral complexity, enabling highly nonlinear transformations of input signals into information-rich outputs. Our devices, physically unclonable moire quasicrystal interferometers integrated on a silicon photonics platform, exhibit aperiodic and reconfigurable spectral responses and are characterized by analyticity breaking and erasable mutual information. Using dynamic thermo-optic control to drive their complex spectral dynamics, we demonstrate that these devices function as reconfigurable physical unclonable functions (rPUFs). We also highlight their ability to perform high-dimensional input-output transformations, emulating reservoir-inspired information processing in a compact photonic platform. This work bridges the gap between engineered and natural complexity in photonic systems, revealing new opportunities for scalable, energy-efficient, and information-dense optoelectronics with applications in secure communications, hardware security, advanced sensing, and optical information processing. Our results establish low-symmetry integrated photonics as a powerful resource for complex signal manipulation in photonic systems.",
    "authors": [
      "Farhan Bin Tarik",
      "Yingjie Lao",
      "Mustafa Hammood",
      "Jonathan Barnes",
      "Madeline Mahanloo",
      "Lukas Chrostowski",
      "Taufiquar Khan",
      "Judson D. Ryckman"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20431",
    "title": "On the surface Bloch waves in truncated periodic media: scalar-wave primer",
    "abstract": "Much like their counterparts in homogenous elastic solids, waves in periodic media can be broadly classified into Floquet-Bloch body waves, and evanescent surface waves. Our goal is to elucidate the latter boundary layers, termed surface Bloch (SB) waves, affiliated with rational surface cuts and homogeneous Neumann data. To this end we adopt a two-dimensional (2D) scalar wave equation with periodic coefficients (describing anticline shear waves in phonoic crystals) as a test bed and develop a unit cell-of-periodicity-based, reduced order model of the SB waves that is capable of describing both their dispersion, waveforms, and ``skin depth''. The centerpiece of our analysis is a quadratic eigenvalue problem (QEP) for the effective unit cell of periodicity -- deriving from a geometric interplay between the mother Bravais lattice and orientation of the surface cut -- that seeks the complex wavenumber normal to the cut plane given (i) the excitation frequency and (ii) wavenumber in the direction of the cut plane. In this way the sought boundary layer is derived via superposition of the evanescent QEP eigenstates, whose relative amplitudes are obtained by imposing the homogeneous boundary condition. With the QEP eigenspectrum at hand, evaluation of an SB wave -- in terms of both dispersion characteristics and evanescent waveforms -- entails only a low-dimensional eigenvalue problem. This feature caters for rapid exploration of the effect of (periodic) surface undulations, and so enables manipulation of the SB waves via optimal design of the surface cut. Our analysis also includes an account for the power flow and ``skin depth'' of a surface Bloch wave, both of which are critical for the energetic relevance of boundary layers.",
    "authors": [
      "Bojan B. Guzina",
      "Shixu Meng",
      "Prasanna Salasiya",
      "Long Nguyen"
    ],
    "primary_category": "physics.app-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.21612",
    "title": "First use of large area SiPM matrices coupled with NaI(Tl) scintillating crystal for low energy dark matter search",
    "abstract": "The long-standing claim of dark matter detection by the DAMA experiment remains a crucial open question in astroparticle physics. A key step towards its independent verification is the development of NaI(Tl)-based detectors with improved sensitivity at low energies. The majority of NaI(Tl)-based experiments rely on conventional photomultiplier tubes (PMTs) as single photon detectors, which present technological limitations in terms of light collection, intrinsic radioactivity and a high noise contribution at keV energies. ASTAROTH is an R&D project developing a NaI(Tl)-based detector where the scintillation light is read out by silicon photomultipliers (SiPM) matrices. SiPMs exhibit high photon detection efficiency, negligible radioactivity, and, most importantly, a dark noise nearly two orders of magnitude lower than PMTs, when operated at cryogenic temperature. To this end, ASTAROTH features a custom-designed cryostat based on a bath of cryogenic fluid, able to safely operate the detector and the read-out electronics down to about 80K. We report the first experimental characterization of 360 g NaI(Tl) detector read out by a large area (5 cm x 5 cm) SiPM matrix. The photoelectron yield obtained with a preliminary configuration is 7.2 photoelectrons/keV, which is rather promising, also in light of several planned developments. The signal-to-noise ratio and the energy threshold attainable with SiPMs is expected to improve the sensitivity for dark matter searches beyond the reach of current-generation PMT-based detectors. This result is the first proof of the viability of this technology and sets a milestone toward the design of future large-scale experiments.",
    "authors": [
      "Edoardo Martinenghi",
      "Valerio Toso",
      "Fabrizio Bruno Armani",
      "Andrea Castoldi",
      "Giuseppe di Carlo",
      "Luca Frontini",
      "Niccolò Gallice",
      "Chiara Guazzoni",
      "Valentino Liberali",
      "Alberto Stabile",
      "Valeria Trabattoni",
      "Andrea Zani",
      "Davide D'Angelo"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.20299",
    "title": "Magnetic Centrifuge Effects in Ultrafast Laser Ablation Plasmas",
    "abstract": "A self-consistent model is developed to explain the anomalously large enrichment of nickel isotopes observed in ablation plumes from ultrafast laser irradiation of solid surfaces. The model is based on the spontaneous creation of a magnetic centrifuge in the ablation plume and the associated cyclotron rotation of plasma ions with effective rotation rates on the order of $10^9$ radians per second. Mass separation occurs around the radial coordinate of cylindrical symmetry with longitudinal axis normal to the ablating surface. A Gaussian shaped radial magnetic field $B_{eff}$ is extracted for Ni isotopes which is shown to be a combination of an axial $B_z$ component and a second contribution $B_{ibw}$ that represents the equivalent of an effective magnetic field contributing to the isotopic separation due to broad spectrum Ion Bernstein Waves providing electrostatic acceleration to the cyclotron orbits. These IBWs are also responsible for a profound resonance of enrichment observed for certain specific charge states. In addition to cyclotron rotation of ions, a rigid rotor model is also presented that is associated with the hydrodynamic rotation of the entire plasma and is shown to be of little consequence for the isotope enrichment. Cyclotron rotation and IBWs dominate the process.",
    "authors": [
      "Peter P. Pronko",
      "Paul A. Van Rompay"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.02361",
    "title": "Probing the partition function for temperature-dependent potentials with nested sampling",
    "abstract": "Thermodynamic properties can be in principle derived from the partition function, which, in many-atom systems, is hard to evaluate as it involves a sum on the accessible microscopic states. Recently, the partition function has been computed via nested sampling, relying on Bayesian statistics, which is able to provide the density of states as a function of the energy in a single run, independently of the temperature. This appealing property is lost whenever the potential energy that appears in the partition function is temperature-dependent: for instance, mean-field effective potential energies or the quantum partition function in the path-integral formalism. For these cases, the nested sampling must be carried out at each temperature, which results in a massive increase of computational time. Here, we introduce and implement a new method, that is based on an extended partition function where the temperature is considered as an additional parameter to be sampled. The extended partition function can be evaluated by nested sampling in a single run, so to restore this highly desirable property even for temperature-dependent effective potential energies. We apply this original method to compute the quantum partition function for harmonic potentials and Lennard-Jones clusters at low temperatures and show that it outperforms the straightforward application of nested sampling for each temperature within several temperature ranges.",
    "authors": [
      "Lune Maillard",
      "Philippe Depondt",
      "Fabio Finocchi",
      "Simon Huppert",
      "Thomas Plé",
      "Julien Salomon",
      "Martino Trassinelli"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.05588",
    "title": "Anomalous Magnetoresistance beyond the Jullière Model for Spin Selectivity in Chiral Molecules",
    "abstract": "The issue of anomalous high magnetoresistance, beyond the Jullière model, observed in nonmagnetic electrode-chiral molecular-ferromagnetic electrode devices has puzzled the community for a long time. Here, by considering the magnetic proximity effect which shifts the nonmagnetic-ferromagnetic interface toward chiral molecules, we show the anomalous high magnetoresistance beyond the spin polarization in ferromagnetic electrodes even in the very weak spin-orbit coupling. Our results are in excellent agreement with the experiments, demonstrating that the spin-orbit coupling plays a fundamental role in chiral-induced spin selectivity and the magnetic proximity effect can dramatically enhance the magnetoresistance. These results elucidate the interaction between chiral molecules and ferromagnetic electrodes and facilitate the design of chiral-based spintronic devices.",
    "authors": [
      "Tian-Yi Zhang",
      "Yue Mao",
      "Peng-Yi Liu",
      "Ai-Min Guo",
      "Qing-Feng Sun"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.07223",
    "title": "Readout noise of digital frequency multiplexed TES detectors for CUPID",
    "abstract": "Superconducting transition-edge sensor (TES) detectors have been the standard in Cosmic Microwave Background experiments for almost two decades and are now being adapted for use in nuclear physics, such as neutrinoless double beta decay searches. In this paper we focus on a new high-bandwidth frequency multiplexed TES readout system developed for CUPID, a neutrinoless double beta decay experiment that will replace CUORE. In order to achieve the high energy resolution requirements for CUPID, the readout noise of the system must be kept to a minimum. Low TES operating resistance and long wiring between the readout SQUID and the warm electronics are needed for CUPID, prompting a careful consideration of the design parameters of this application of frequency multiplexing. In this work, we characterize the readout noise of the newly designed frequency multiplexed TES readout system for CUPID and construct a noise model to understand it. We find that current sharing between the SQUID coil impedance and other branches of the circuit, as well as the long output wiring, worsen the readout noise of the system. To meet noise requirements, a SQUID with a low input inductance, high transimpedance and/or low dynamic impedance is needed, and the wiring capacitance should be kept as small as possible. Alternatively, the option of adding a cryogenic low-noise amplifier at the output of the SQUID should be explored.",
    "authors": [
      "Michel Adamič",
      "Joseph Camilleri",
      "Chiara Capelli",
      "Matt Dobbs",
      "Tucker Elleflot",
      "Yury G. Kolomensky",
      "Daniel Mayer",
      "Joshua Montgomery",
      "Valentine Novosad",
      "Vivek Singh",
      "Graeme Smecher",
      "Aritoki Suzuki",
      "Bradford Welliver"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.09010",
    "title": "Cryogenic geometric anti-spring vibration isolation system",
    "abstract": "The combination of low temperature and low vibration levels is key for ultrasensitive sensing applications such as scanning probe microscopy, large-mass quantum mechanics, and gravitational wave detection. Unfortunately, closed-cycle cryostats using pulse tube or GM coolers introduce strong low-frequency vibrations starting at 1 Hz. Mass-spring systems allow passive isolation, but for low-frequency applications the required spring constants and masses become impractical. Blade-based geometric anti-spring systems are compact isolators that operate from sub-Hz frequencies, but have not been demonstrated at cryogenic temperatures. Here, we characterize a geometric anti-spring system tuned to operate at cryogenic temperatures. Our cryogenic filter uses radially arranged titanium blade springs whose effective spring constant can be tuned in-situ using a magnetic actuator. Our system achieves a vertical resonance frequency of 185 mHz at 7K, which allows reduction of vibrations at the problematic 1 Hz cooler frequency by an order of magnitude.",
    "authors": [
      "L. Feenstra",
      "S. Domínguez-Calderón",
      "K. van Oosten",
      "H.S.M. Bohemen",
      "T. Benschop",
      "M. Brinkman",
      "M. Li",
      "E. Hennes",
      "R. Cornelissen",
      "B.J. Hensen",
      "A. Bertolini",
      "M.P. Allan"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12861",
    "title": "Augmenting a pure and hybrid vertical equilibrium scheme via data-driven surrogate modelling",
    "abstract": "Vertical equilibrium (VE) models have been introduced as computationally efficient alternatives to traditional mass and momentum balance equations for fluid flow in porous media. Since VE models are only accurate in regions where phase equilibrium holds, while traditional simulations are computationally demanding, hybrid methods have been proposed to combine the accuracy of the full-dimensional approach with the efficiency of VE model. However, coupling both models introduces computational overhead that can make hybrid simulations slower than fully traditional ones. To address this, we introduce data-driven surrogates to predict the gas plume distance and coarse-level mobilities in the VE model, as well as predictors to accelerate the coupling scheme. We focus on surrogate models with short inference times to minimize computational overhead during frequent function calls. The proposed approach preserves key physical properties, such as mass conservation, while substantially reducing simulation runtimes. Overall, combining data-driven methods with the hybrid VE scheme yields an enhanced model that outperforms traditional simulations in speed while introducing only negligible errors.",
    "authors": [
      "Ivan Buntic",
      "Bernd Flemisch"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.19860",
    "title": "Diversity mitigates polarization and consensus in opinion dynamics",
    "abstract": "We study the opinion dynamics in a population by considering a variant of Kuramoto model where the phase of an oscillator represents the opinion of an individual on a single topic. Two extreme phases separated by $\\pi$ represent opposing views. Any other phase is considered as an intermediate opinion between the two extremes. The interaction (or attitude) between two individuals depends on the difference between their opinions and can be positive (attractive) or negative (repulsive) based on the defined thresholds. We investigate the opinion dynamics when these thresholds are varied. We observe explosive transition from a bipolarized state to a consensus state with the existence of scattered and tri-polarized states at low values of threshold parameter. The system exhibits multistability between various states in a sizeable parameter region. These transitions and multistability are studied in populations with different degrees of diversity represented by the width of conviction distribution. We found that a more homogeneous population has greater tendency to exhibit bipolarized, tri-polarized and clustered states while a diverse population helps mitigate polarization among individuals by reaching to a consensus sooner. Ott-Antonsen analysis is used to analyse the system's long term macroscopic behaviour and verify the numerical results. We also study the effects of neutral individuals that do not interact with others or do not change their attitude on opinion formation, nature of transitions and multistability. Furthermore, we apply our model to language data to study the assimilation of diverse languages in India and compare the results with those obtained from model equations.",
    "authors": [
      "Sidharth Pradhan",
      "Sangeeta Rani Ujjwal"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25505",
    "title": "High fidelity CNOT gates in photonic integrated circuits using composite segmented directional couplers",
    "abstract": "Integrated photonic circuits are a promising platform for scalable quantum information processing, but their performance is often constrained by component sensitivity to fabrication imperfections. Directional couplers, which are crucial building blocks for integrated quantum logic gates, are particularly prone to such limitations, with strong dependence on geometric and spectral parameters which reduces gate fidelity. Here, we demonstrate that composite segmented directional couplers (CSDC) offer a fabrication-tolerant alternative that enhances gate fidelity without active tuning. We design and fabricate a fully integrated photonic controlled-NOT (CNOT) gate using both uniform and composite coupler variants and compare their performance via simulation, classical characterization, and quantum two-photon interference. The composite design reduces the average error probability by nearly a factor of two and decreases variability fivefold. The residual error is primarily limited by photon indistinguishability. Classical matrix reconstruction confirms improved agreement with the ideal CNOT operation. These results establish CSDCs as compact, passive, and foundry-compatible building blocks for robust scalable quantum photonic circuits.",
    "authors": [
      "Jonatan Piasetzky",
      "Amit Rotem",
      "Yuval Warshavsky",
      "Yehonatan Drori",
      "Khen Cohen",
      "Yaron Oz",
      "Haim Suchowski"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.10788",
    "title": "A formalism for giant Goos-Hänchen shift in metasurface sensors with phase singularity",
    "abstract": "The Goos-Hänchen (GH) shift becomes giant in resonant photonic structures, making it promising for refractive index sensors with ultimate sensitivities. We provide here a complete formalism to analytically describe the GH shift and its associated sensitivity around the critical coupling regime in photonic structures. This analytical framework quantitatively connects physical parameters such as the quality factor, the angular dispersion, the beam size and the phase singularity to the GH shift. We numerically confirm this theory in two practical designs: a surface plasmon resonance sensor and a Bloch surface wave (BSW) metasurface sensor. Coupling our theory with numerical simulations, we design a BSW metasurface whose GH sensitivity ($10^{13} \\mu m/RIU$) is more than 5 orders of magnitude higher than the current state-of-the this http URL also reveal that the main practical limitation to reach ultimate GH sensitivities is the beam size. However, taking into account realistic beam sizes and introducing engineering dispersion for the metasurface, we calculate limits of detection for GH sensors as low as $10^{-13} RIU$ that still surpass current sensors. These results open the way for new sensing application needing high sensitivity and low limit of detection.",
    "authors": [
      "Lotfi Berguiga",
      "Sébastien Cueff",
      "Lydie Ferrier",
      "Fabien Mandorlo",
      "Taha Benyattou",
      "Xavier Letartre",
      "Cécile Jamois"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.14159",
    "title": "Musical consonance: a review of theory and evidence on perception and preference of auditory roughness in humans and other animals",
    "abstract": "The origins of consonance in human music has long been contested, and today there are three primary hypotheses: aversion to roughness, preference for harmonicity, and learned preferences from cultural exposure. While the evidence is currently insufficient to disentangle the contributions of these hypotheses, I propose several reasons why roughness is an especially promising area for future study. The aim of this review is to summarize and critically evaluate roughness theory and models, experimental data, to highlight areas that deserve further research. I identify 2 key areas: There are fundamental issues with the definition and interpretation of results due to tautology in the definition of roughness, and the lack of independence in empirical measurements. Despite extensive model development, there are many duplications and models have issues with data quality and overfitting. Future theory development should aim for model simplicity, and extra assumptions, features and parameters should be evaluated systematically. Model evaluation should aim to maximise the breadth of stimuli that are predicted.",
    "authors": [
      "John M. McBride"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.15637",
    "title": "Genesis of Horizontal Electric Field in Bilayer Hydrophobic Core",
    "abstract": "For over a century, the electric field of biological membranes has been regarded as a one-dimensional quantity, defined solely by the component normal to the bilayer (E_VERT). Here, we challenge this conventional view by developing a device that generates a horizontal electric field within the hydrophobic core of a lipid bilayer (E_HORZ). The device incorporates micrometre-scale electrodes embedded within the bilayer's torus, enabling the steady generation of E_HORZ. Applied E_HORZ selectively and reversibly accelerates the slow inactivation of a voltage-gated potassium channel, while leaving activation essentially unchanged. Physical considerations reveal that E_HORZ naturally arises wherever membrane potential varies spatially, such as at the wavefront of an action potential, implying that it is inherent to many physiological processes. This E_HORZ system provides experimental access to fully three-dimensional membrane electric fields, revealing previously overlooked dimension of membrane bioelectricity.",
    "authors": [
      "Maki Komiya",
      "Madoka Sato",
      "Teng Ma",
      "Hironori Kageyama",
      "Tatsuya Nomoto",
      "Takahisa Maki",
      "Masayuki Iwamoto",
      "Miyu Terashima",
      "Daiki Ando",
      "Takaya Watanabe",
      "Yoshikazu Shimada",
      "Daisuke Tadaki",
      "Hideaki Yamamoto",
      "Yuzuru Tozawa",
      "Ryugo Tero",
      "Albert Marti",
      "Jordi Madrenas",
      "Shigeru Kubota",
      "Fumihiko Hirose",
      "Michio Niwano",
      "Shigetoshi Oiki",
      "Ayumi Hirano-Iwata"
    ],
    "primary_category": "physics.bio-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.01214",
    "title": "Diffusion Models Bridge Deep Learning and Physics in ENSO Forecasting",
    "abstract": "Accurate long-range forecasting of the El \\Nino-Southern Oscillation (ENSO) is vital for global climate prediction and disaster risk management. Yet, limited understanding of ENSO's physical mechanisms constrains both numerical and deep learning approaches, which often struggle to balance predictive accuracy with physical interpretability. Here, we introduce a data driven model for ENSO prediction based on conditional diffusion model. By constructing a probabilistic mapping from historical to future states using higher-order Markov chain, our model explicitly quantifies intrinsic uncertainty. The approach achieves extending lead times of state-of-the-art methods, resolving early development signals of the spring predictability barrier, and faithfully reproducing the spatiotemporal evolution of historical extreme events. The most striking implication is that our analysis reveals that the reverse diffusion process inherently encodes the classical recharge-discharge mechanism, with its operational dynamics exhibiting remarkable consistency with the governing principles of the van der Pol oscillator equation. These findings establish diffusion models as a new paradigm for ENSO forecasting, offering not only superior probabilistic skill but also a physically grounded theoretical framework that bridges data-driven prediction with deterministic dynamical systems, thereby advancing the study of complex geophysical processes.",
    "authors": [
      "Weifeng Xu",
      "Xiang Zhu",
      "Xiaoyong Li",
      "Qiang Yao",
      "Xiaoli Ren",
      "Kefeng Deng",
      "Song Wu",
      "Chengcheng Shao",
      "Xiaolong Xu",
      "Juan Zhao",
      "Chengwu Zhao",
      "Jianping Cao",
      "Jingnan Wang",
      "Wuxin Wang",
      "Qixiu Li",
      "Xiaori Gao",
      "Xinrong Wu",
      "Huizan Wang",
      "Xiaoqun Cao",
      "Weiming Zhang",
      "Junqiang Song",
      "Kaijun Ren"
    ],
    "primary_category": "physics.geo-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.01955",
    "title": "Dynamic Estimates of Displacement in Disaster Regions: A Policy-driven framework triangulating data",
    "abstract": "While traditional data systems remain fundamental to humanitarian response, they often lack the real-time responsiveness and spatial precision needed to capture increasingly complex patterns of displacement. Internal displacement reached an unprecedented 83.4 million people by the end of 2024, underscoring the urgent need for innovative, data driven approaches to monitor and understand population movements. This report examines how integrating traditional data sources with emerging digital trace data, such as mobile phone GPS and social media activity, can enhance the accuracy, responsiveness, and granularity of displacement monitoring. Drawing on lessons from recent crises, including the escalation of the war in Ukraine and the 2022 floods in Pakistan, the report presents a structured pilot effort that tests the triangulation of multiple data streams to produce more robust and reliable displacement estimates. Statistical indicators derived from digital trace data are benchmarked against the International Organisation for Migration, Displacement Tracking Matrix datasets, to assess their validity, transparency, and scalability. The findings demonstrate how triangulated data approaches can deliver real-time, high-resolution insights into population movements, improving humanitarian resource allocation and intervention planning. The report includes a scalable framework for crisis monitoring that leverages digital innovation to strengthen humanitarian data systems and support evidence-based decision-making in complex emergencies.",
    "authors": [
      "Elisabetta Pietrostefani",
      "Matt Mason",
      "Rodgers Iradukunda",
      "Hong Tran-Jones",
      "Iryna Loktieva",
      "Francisco Rowe"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.08625",
    "title": "Cross-Field Interface-Aware Neural Operators for Multiphase Flow Simulation",
    "abstract": "Multiphase flow simulation is critical in science and engineering but incurs high computational costs due to complex field discontinuities and the need for high-resolution numerical meshes. While Neural Operators (NOs) offer an efficient alternative for solving Partial Differential Equations (PDEs), they struggle with two core challenges unique to multiphase systems: spectral bias caused by spatial heterogeneity at phase interfaces, and the persistent scarcity of expensive, high-resolution field data. This work introduces the Interface Information Aware Neural Operator (IANO), a novel architecture that mitigates these issues by leveraging readily obtainable interface data (e.g., topology and position). Interface data inherently contains the high-frequency features not only necessary to complement the physical field data, but also help with spectral bias. IANO incorporates an interface-aware function encoding mechanism to capture dynamic coupling, and a geometry-aware positional encoding method to enhance spatial fidelity for pointwise super-resolution. Empirical results across multiple multiphase flow cases demonstrate that IANO achieves significant accuracy improvements (up to $\\sim$10\\%) over existing NO baselines. Furthermore, IANO exhibits superior generalization capabilities in low-data and noisy settings, confirming its utility for practical, data-efficient $\\text{AI}$-based multiphase flow simulations.",
    "authors": [
      "Zhenzhong Wang",
      "Xin Zhang",
      "Jun Liao",
      "Min Jiang"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.11820",
    "title": "Categorization of Roles in the Quantum Industry",
    "abstract": "Continued growth of the quantum information science and engineering (QISE) industry has resulted in stakeholders spanning education, industry, and government seeking to better understand the workforce needs. This report presents a framework for the categorization of roles in the QISE industry based on 42 interviews of QISE professionals across 23 companies, as well as a description of the method used in the creation of this framework. The data included information on over 80 positions, which we have grouped into 29 roles spanning four primary categories. For each primary category we provide an overview of what unites the roles within a category, a description of relevant subcategories, and definitions of the individual roles. These roles serve as the basis upon which we generate profiles of these roles, which include information about role critical tasks, necessary knowledge and skills, and educational requirements. Our next report will present such profiles for each of the roles presented herein.",
    "authors": [
      "A.R. Pina",
      "Shams El-Adawy",
      "H.J. Lewandowski",
      "Benjamin M. Zwickl"
    ],
    "primary_category": "physics.ed-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20089",
    "title": "Noctilucent Clouds Modulated by Strong 5-day Planetary Wave in 2025: Amplitudes, Phases and Altitudes Based on Ground-Based Observations and Satellite Temperature Data",
    "abstract": "During the summer season of 2025, noctilucent clouds (NLC) were observed at the latitudes 55-60N from the late May until the late August. A distinct 5-day periodicity in their occurrence emerged following the summer solstice. Analysis of EOS Aura/MLS satellite data revealed that this effect was driven by a westward 5-day planetary wave, the amplitude of which was twice that of any previous northern summer since the start of the EOS Aura measurements in 2005. This study details the evolution of this exceptional planetary wave throughout the summer. Furthermore, NLC altitudes were determined via triangulation and colorimetry and were compared with MLS temperature profiles, enabling the determination of a mean positive phase lag for NLC occurrence relative to the temperature minimum.",
    "authors": [
      "Oleg S. Ugolnikov",
      "Ilya S. Yankovsky",
      "Nikolay N. Pertsev",
      "Vladimir I. Perminov",
      "Maxim V. Klimenko",
      "Ekaterina N. Tipikina",
      "Alexey V. Popov",
      "Andrey M. Tatarnikov",
      "Sergey G. Zheltoukhov",
      "Sergey A. Potanin",
      "Egor O. Ugolnikov",
      "Olga Yu. Golubeva",
      "Andrey L. Kotikov",
      "Alexey S. Sushkov",
      "Egor A. Volkov"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22053",
    "title": "Self-supervised prior learning improves structured illumination microscopy resolution",
    "abstract": "Structured illumination microscopy (SIM) is a wide-field super-resolution technique normally limited to roughly twice the diffraction-limited resolution ($\\approx 100$--$200$~nm). Surpassing this bound is a classic ill-posed inverse problem: recovering high-frequency structure from band-limited raw data. We introduce SIMFormer, a fully blind SIM reconstruction framework that learns a powerful, data-driven prior directly from raw images via self-supervision. This learned prior regularizes the solution and enables reliable extrapolation beyond the optical transfer function cutoff, yielding an effective resolution of approximately 45~nm. We validate SIMFormer on synthetic data and the BioSR dataset, where it resolves features such as flattened endoplasmic reticulum lipid bilayers previously reported to require STORM-level resolution. A self-distilled variant, SIMFormer+, further improves noise robustness while preserving high resolution at extremely low photon counts. These results show that learned priors can substantially extend SIM resolution and robustness, enabling rapid, large-scale imaging with STORM-level detail.",
    "authors": [
      "Ze-Hao Wang",
      "Tong-Tian Weng",
      "Long-Kun Shan",
      "Xiang-Dong Chen",
      "Guang-Can Guo",
      "Fang-Wen Sun",
      "Tian-Long Chen"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22114",
    "title": "Optical spin precession",
    "abstract": "Period-averaged electromagnetic spin angular momentum is a well-established quantity for monochromatic fields, governing phenomena such as light-matter interactions with chiral particles and spin-orbit coupling effects. In contrast, the spin angular momentum of non-monochromatic fields remains unexplored. Here, we extend the concept of optical spin to the domain of non-monochromatic electromagnetic fields. Through this formulation, we uncover the precessional dynamics of electromagnetic spin in specific polychromatic configurations, including the superposition of circularly and linearly polarized plane waves propagating orthogonally at different frequencies, as well as fields generated by a precessing magnetic dipole. We discover that the dynamics of the electromagnetic spin in these cases obeys a Landau-Lifshitz-like equation establishing a profound parallel between dynamics of magnetization and photonic spin.",
    "authors": [
      "Abanoub Mikhail",
      "Maxim Mazanov",
      "Ilya Deiry",
      "Mingzhao Song",
      "Ivan Iorsh",
      "Andrey Bogdanov"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00068",
    "title": "A Geometric Foundation for the Universal Laws of Turbulence",
    "abstract": "We propose a theoretical framework where the dissipative structures of turbulence emerge from microscopic path uncertainty. By modeling fluid parcels as stochastic tracers governed by the Schrödinger Bridge (SB) variational principle, we demonstrate that the Navier--Stokes viscous term is a natural linear, second-order macroscopic operator consistent with isotropic microscopic diffusion. We derive two foundational pillars of turbulence from this single principle. First, we show that the Kolmogorov scale $\\eta \\sim (\\nu^3/\\epsilon)^{1/4}$ is not merely a dimensional necessity but a geometric diffusion horizon: it is the scale at which the kinetic energy of a fractal trajectory, scaling as $k \\sim \\nu/\\tau$, balances the macroscopic dissipation rate. Second, we show that the universal law of the wall is the stationary solution to this stochastic process under no-slip constraints. The logarithmic mean profile arises from the scale invariance of the turbulent diffusivity, while finite-Reynolds-number corrections emerge as controlled asymptotic expansions of the stochastic variance. This framework offers a physically grounded derivation of turbulent scaling laws that complements and extends purely phenomenological dimensional analysis.",
    "authors": [
      "Marcial Sanchis-Agudo",
      "Ricardo Vinuesa"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01894",
    "title": "High-Sensitivity NV Ensemble Imaging via AOD-Based Raster Scanning and Photodetection",
    "abstract": "We present a technique based on an ensemble of nitrogen-vacancy (NV) centers in diamond capable of imaging magnetic fields with high spatio-temporal resolution. A focused laser beam is raster-scanned using an acousto-optic deflector (AOD) and NV center fluorescence is read out with a single photodetector, enabling low-noise detection with high dynamic range. The method operates in a previously unexplored regime, quasi-continuous wave optically detected magnetic resonance (qCW-ODMR). In this regime, NV centers experience short optical pump pulses for spin readout and repolarization, analogous to pulsed ODMR technique, while the microwave field remains continuously on resonance with the spin transitions. We systematically characterize this regime and show that the spin response is governed by a tunable interplay between coherent evolution and relaxation, determined by the temporal spacing between pump laser pulses. Notably, the technique does not require precise microwave pulse control, thus simplifying experimental implementation. To demonstrate its capabilities, we image time-varying magnetic fields from a microelectrode in a conductive medium with sub-millisecond temporal resolution. This approach enables flexible spatial sampling and with our diamond achieves nT$\\cdot$Hz$^{-1/2}$ per pixel sensitivity, making it well suited for detecting weak, dynamic magnetic fields in biological and other complex systems.",
    "authors": [
      "Luca Troise",
      "Nikolaj W. Hansen",
      "Marvin Holten",
      "Dhiren M. Kara",
      "Jean-Francois Perrier",
      "Ulrik L. Andersen",
      "Alexander Huck"
    ],
    "primary_category": "physics.app-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02529",
    "title": "Electromagnetic polarization matrix and its physical interpretation",
    "abstract": "Although electric and magnetic fields are intrinsically coupled in random stationary light, a complete and physically consistent second-order description of polarization requires a joint electromagnetic treatment. The 6x6 electromagnetic polarization matrix introduced here generalizes the conventional electric 3x3 matrix by incorporating both electric and magnetic contributions together with their mutual correlations. It consists of diagonal 3x3 blocks, representing the electric and magnetic polarization matrices, and off-diagonal 3x3 blocks that encode the full structure of electric-magnetic cross-correlations. The information contained in this matrix can be interpreted through physically meaningful quantities such as active and reactive energy fluxes, in-phase and quadrature alignment matrices, and global indices describing electric-magnetic coupling. The formalism is applied to a field composed of two orthogonally propagating plane waves sharing a common linear electric polarization (a simple yet physically realizable configuration) that demonstrates the need for a general combined electric-magnetic representation even in free space. This approach provides a comprehensive and unified framework for characterizing electromagnetic polarization beyond the electric-field description alone, bridging classical statistical optics with quantum-like density-matrix interpretations.",
    "authors": [
      "José J. Gil",
      "Andreas Norrman",
      "Ari T. Friberg",
      "Behnaz Fazlpour",
      "Tero Setälä"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02730",
    "title": "Invariance under Structure Translation as the Origin of Host Immune Capacity Conservation from Noether's Theorem",
    "abstract": "The capacity to resist pathogens is recognized as a fundamental property of the immune system, yet it remains a phenomenological concept and lacks a defined physical basis, leaving its fundamental entity, definition, and quantification unresolved. Here, we address these questions by introducing a theoretical framework based on Lagrangian analytical mechanics, which recasts immune recognition as a dynamical system in an immunological state space. Generalized coordinates are used to describe the conformational states of immune receptors, and their evolution is governed by Euler-Lagrange equations constructed from the antigen-receptor interaction. Central to our theory is the identification of a continuous symmetry: the action remains invariant under specific translations within the antigenic structure space. From this symmetry, Noether's theorem dictates a conserved quantity, I. We identify this conserved quantity as the physical embodiment of host immunity, a measurable quantity that encapsulates the system's protective capacity, encompassing both its breadth and intensity. This prediction is testable through statistically indistinguishable responses to antigen pairs related by the symmetry transformation. Furthermore, This theoretical model provides a unified framework for understanding key immunological phenomena, including vaccination, immune memory, tolerance, original antigenic sin, and T cell exhaustion. The conserved quantity I comprises a component quantifying protective breadth (with the dimension of action) and a component governing response intensity (with the dimension of energy), is thus established as a fundamental physical entity. This work transforms immune capacity from a phenomenological concept into a quantifiable entity, thereby establishing a foundational framework for predictive immunology and immunological intervention.",
    "authors": [
      "Yexing Chen",
      "Qingyun Wei",
      "Zhongxiang Dong",
      "Peng Cao"
    ],
    "primary_category": "physics.bio-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2309.05481",
    "title": "Photovoltaic potential of tin perovskites revealed through layer-by-layer investigation of optoelectronic and charge transport properties",
    "abstract": "Tin perovskites are the most promising environmentally friendly alternative to lead perovskites. Among tin perovskites, FASnI3 (CH4N2SnI3) shows optimum band gap, and easy processability. However, the performance of FASnI3 based solar cells is incomparable to lead perovskites for several reasons, including energy band mismatch between the perovskite absorber film and the charge transporting layers (CTLs) for both types of carriers, i.e., for electrons (ETLs) and holes (HTLs). However, the band diagrams in the literature are inconsistent, and the charge extraction dynamics are poorly understood. In this paper, we study the energy band positions of FASnI3 based perovskites using Kelvin probe (KP) and photoelectron yield spectroscopy (PYS) to provide a precise band diagram of the most used device stack. In addition, we analyze the defects within the current energetic landscape of tin perovskites. We uncover the role of bathocuproine (BCP) in enhancing the electron extraction at the fullerene C60/BCP interface. Furthermore, we used transient surface photovoltage (tr-SPV) for the first time for tin perovskites to understand the charge extraction dynamics of the most reported HTLs such as NiOx and PEDOT, and ETLs such as C60, ICBA, and PCBM. Finally, we used Hall effect, KP, and time-resolved photoluminescence (TRPL) to estimate an accurate value of the p-doping concentration in FASnI3 and showed a consistent result of 1.5 * 1017 cm-3. Our findings prove that the energetic system of tin halide perovskites is deformed and should be redesigned independently from lead perovskites to unlock the full potential of tin perovskites.",
    "authors": [
      "Mahmoud H. Aldamasy",
      "Artem Musiienko",
      "Marin Rusu",
      "Davide Regaldo",
      "Shengnan Zho",
      "Hannes Hampel",
      "Chiara Frasca",
      "Zafar Iqbal",
      "Thomas W. Gries",
      "Guixiang Li",
      "Ece Aktas",
      "Giuseppe Nasti",
      "Meng Li",
      "Jorge Pascual",
      "Noor Titan Putri Hartono",
      "Qiong Wang",
      "Thomas Unold",
      "Antonio Abate"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2404.14744",
    "title": "Resolving exciton and polariton multi-particle correlations in an optical microcavity in the strong coupling regime",
    "abstract": "Multi-particle correlations of exciton-polaritons and reservoir-excitons in the strong light-matter coupling regime dictate the quantum dynamics of optical microcavities. In this letter, we examine the many-body exciton-polariton dynamics in a Fabry-Pérot microcavity of a two-dimensional metal-halide semiconductor over timescales involving polariton ($\\ll 1$\\,ps) and exciton ($\\gg 1$\\,ps) scattering. We find enhanced exciton nonlinear dynamics in the microcavity versus the bare semiconductor, concomitant with ultrafast polariton scattering dynamics. We measure, by means of coherent spectroscopy, the coupling between exciton-polaritons, bright excitons, and reservoir-excitons that highlight the complex scattering landscape that fundamentally drives polariton condensation.",
    "authors": [
      "Victoria Quirós-Cordero",
      "Esteban Rojas-Gatjens",
      "Martín Gómez-Dominguez",
      "Hao Li",
      "Carlo A. R. Perini",
      "Natalie Stingelin",
      "Juan-Pablo Correa-Baena",
      "Eric R. Bittner",
      "Ajay Ram Srimath Kandada",
      "Carlos Silva-Acuña"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.08873",
    "title": "Coherent X-rays reveal anomalous molecular diffusion and cage effects in crowded protein solutions",
    "abstract": "Understanding protein motion within the cell is crucial for predicting reaction rates and macromolecular transport in the cytoplasm. A key question is how crowded environments affect protein dynamics through hydrodynamic and direct interactions at molecular length scales. Using megahertz X-ray Photon Correlation Spectroscopy (MHz-XPCS) at the European X-ray Free Electron Laser (EuXFEL), we investigate ferritin diffusion at microsecond time scales. Our results reveal anomalous diffusion, indicated by the non-exponential decay of the intensity autocorrelation function $g_2(q,t)$ at high concentrations. This behavior is consistent with the presence of cage-trapping in between the short- and long-time protein diffusion regimes. Modeling with the $\\delta\\gamma$-theory of hydrodynamically interacting colloidal spheres successfully reproduces the experimental data by including a scaling factor linked to the protein direct interactions. These findings offer new insights into the complex molecular motion in crowded protein solutions, with potential applications for optimizing ferritin-based drug delivery, where protein diffusion is the rate-limiting step.",
    "authors": [
      "Anita Girelli",
      "Maddalena Bin",
      "Mariia Filianina",
      "Michelle Dargasz",
      "Nimmi Das Anthuparambil",
      "Johannes Möller",
      "Alexey Zozulya",
      "Iason Andronis",
      "Sonja Timmermann",
      "Sharon Berkowicz",
      "Sebastian Retzbach",
      "Mario Reiser",
      "Agha Mohammad Raza",
      "Marvin Kowalski",
      "Mohammad Sayed Akhundzadeh",
      "Jenny Schrage",
      "Chang Hee Woo",
      "Maximilian D. Senft",
      "Lara Franziska Reichart",
      "Aliaksandr Leonau",
      "Prince Prabhu Rajaiah",
      "William Chèvremont",
      "Tilo Seydel",
      "Jörg Hallmann",
      "Angel Rodriguez-Fernandez",
      "Jan-Etienne Pudell",
      "Felix Brausse",
      "Ulrike Boesenberg",
      "James Wrigley",
      "Mohamed Youssef",
      "Wei Lu",
      "Wonhyuk Jo",
      "Roman Shayduk",
      "Trey Guest",
      "Anders Madsen",
      "Felix Lehmkühler",
      "Michael Paulus",
      "Fajun Zhang",
      "Frank Schreiber",
      "Christian Gutt",
      "Fivos Perakis"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.09465",
    "title": "Coherent Control of Photon Correlations in Trapped Ion Crystals",
    "abstract": "While the spontaneous emission from independent emitters provides spatially uncorrelated photons - a typical manifestation of quantum randomness, the interference of the coherent scattering leads to a well-defined intensity pattern - a feature described by linear optics. We here demonstrate experimentally how the interplay between the two mechanisms in large systems of quantum emitters leads to spatial variations of photon correlations. The implementation with trapped ion crystals in free space allows us to observe the anti-correlation between photon rates and variance of the photon number distributions in chains of up to 18 ions. For smaller crystals of four ions, the transition from a sub-Poissonian to a super-Poissonian variance of the photon number in the scattered light is reported. For higher numbers of scatterers, the photon statistics still display a strong deviation from the fully incoherent scattering case. Our results illustrate how the interference of coherent scattering, combined with spontaneous emission, provides a control mechanism for the light statistics.",
    "authors": [
      "K. Singh",
      "A. Cidrim",
      "A. Kovalenko",
      "T. Pham",
      "O. Číp",
      "L. Slodička",
      "R. Bachelard"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.08356",
    "title": "Proposal for a Bell Test with Entangled Atoms of Different Mass",
    "abstract": "We propose a Bell test experiment using momentum-entangled atom pairs of different masses, specifically metastable helium isotopes 3He* and 4He*, though the method extends to other atom species. Entanglement is generated via collisions, after which the quantum states are manipulated using two independent atom interferometers, enabling precise phase control over each species. Numerical simulations predict a significant violation of Bell's inequality under realistic conditions. This proposal opens a new paradigm to study the intersection of quantum mechanics and gravity.",
    "authors": [
      "X. T. Yan",
      "S. Kannan",
      "Y. S. Athreya",
      "A. G. Truscott",
      "S. S. Hodgman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.11163",
    "title": "Optical nuclear electric resonance as single qubit gate for trapped neutral atoms",
    "abstract": "The precise control of nuclear spin states is crucial for a wide range of quantum technology applications. Here, we propose a fast and robust single-qubit gate in $^{87}$Sr, utilizing the concept of optical nuclear electric resonance (ONER). ONER exploits the interaction between the quadrupole moment of a nucleus and the electric field gradient generated by its electronic environment, enabling spin level transitions via amplitude-modulated laser light. We investigate the hyperfine structure of the 5s$^2$~$^1S_{0}\\rightarrow{}$~5s5p~$^3P_1$ optical transition in neutral $^{87}$Sr, and identify the magnetic field strengths and laser parameters necessary to drive spin transitions between the $m_I$ = -9/2 and $m_I$ = -5/2 hyperfine levels in the ground state. Our simulations show that ONER could enable faster spin operations compared to the state-of-the-art oscillations in this 'atomic qubit'. Moreover, we show that spin-flip operations exceeding 99.9\\% fidelity can be performed even in the presence of typical noise sources. These results pave the way for significant advances in nuclear spin control, opening new possibilities for quantum memories and other quantum technologies.",
    "authors": [
      "Johannes K. Krondorfer",
      "Sebastian Pucher",
      "Matthias Diez",
      "Sebastian Blatt",
      "Andreas W. Hauser"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.17096",
    "title": "Why is the estimation of metaorder impact with public market data so challenging?",
    "abstract": "Estimating market impact and transaction costs of large trades (metaorders) is a very important topic in finance. However, using models of price and trade based on public market data provide average price trajectories which are qualitatively different from what is observed during real metaorder executions: the price increases linearly, rather than in a concave way, during the execution and the amount of reversion after its end is very limited. We claim that this is a generic phenomenon due to the fact that even sophisticated statistical models are unable to correctly describe the origin of the autocorrelation of the order flow. We propose a modified Transient Impact Model which provides more realistic trajectories by assuming that only a fraction of the metaorder trading triggers market order flow. Interestingly, in our model there is a critical condition on the kernels of the price and order flow equations in which market impact becomes permanent.",
    "authors": [
      "Manuel Naviglio",
      "Giacomo Bormetti",
      "Francesco Campigli",
      "German Rodikov",
      "Fabrizio Lillo"
    ],
    "primary_category": "q-fin.TR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.16116",
    "title": "Integrating Weather Station Data and Radar for Precipitation Nowcasting: SmaAt-fUsion and SmaAt-Krige-GNet",
    "abstract": "Short-term precipitation nowcasting is essential for flood management, transportation, energy system operations, and emergency response. However, many existing models fail to fully exploit the extensive atmospheric information available, relying primarily on precipitation data alone. This study examines whether integrating multi-variable weather-station measurements with radar can enhance nowcasting skill and introduces two complementary architectures that integrate multi-variable station data with radar images. The SmaAt-fUsion model extends the SmaAt-UNet framework by incorporating weather station data through a convolutional layer, integrating it into the bottleneck of the network; The SmaAt-Krige-GNet model combines precipitation maps with weather station data processed using Kriging, a geo-statistical interpolation method, to generate variable-specific maps. These maps are then utilized in a dual-encoder architecture based on SmaAt-GNet, allowing multi-level data integration . Experimental evaluations were conducted using four years (2016--2019) of weather station and precipitation radar data from the Netherlands. Results demonstrate that SmaAt-Krige-GNet outperforms the standard SmaAt-UNet, which relies solely on precipitation radar data, in low precipitation scenarios, while SmaAt-fUsion surpasses SmaAt-UNet in both low and high precipitation scenarios. This highlights the potential of incorporating discrete weather station data to enhance the performance of deep learning-based weather nowcasting models.",
    "authors": [
      "Jie Shi",
      "Aleksej Cornelissen",
      "Siamak Mehrkanoon"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.17478",
    "title": "ConfRover: Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression",
    "abstract": "Understanding protein dynamics is critical for elucidating their biological functions. The increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins. However, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples. To address these limitations, we introduce ConfRover, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectories, supporting both time-dependent and time-independent sampling. At the core of our model is a modular architecture comprising: (i) an encoding layer, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a temporal module, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the structure decoder, generating conformations in continuous space. Experiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks. ConfRover is the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data. Project website: this https URL .",
    "authors": [
      "Yuning Shen",
      "Lihao Wang",
      "Huizhuo Yuan",
      "Yan Wang",
      "Bangji Yang",
      "Quanquan Gu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.18565",
    "title": "Learning Fluid-Structure Interaction with Physics-Informed Machine Learning and Immersed Boundary Methods",
    "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising approach for solving complex fluid dynamics problems, yet their application to fluid-structure interaction (FSI) problems with moving boundaries remains largely unexplored. This work addresses the critical challenge of modeling FSI systems with moving interfaces, where traditional unified PINN architectures struggle to capture the distinct physics governing fluid and structural domains simultaneously. We present an innovative Eulerian-Lagrangian PINN architecture that integrates immersed boundary method (IBM) principles to solve FSI problems with moving boundary conditions. Our approach fundamentally departs from conventional unified architectures by introducing domain-specific neural networks: an Eulerian network for fluid dynamics and a Lagrangian network for structural interfaces, coupled through physics-based constraints. Additionally, we incorporate learnable B-spline activation functions with SiLU to capture both localized high-gradient features near interfaces and global flow patterns. Empirical studies on a 2D cavity flow problem involving a moving solid structure show that while baseline unified PINNs achieve reasonable velocity predictions, they suffer from substantial pressure errors (12.9%) in structural regions. Our Eulerian-Lagrangian architecture with learnable activations (EL-L) achieves better performance across all metrics, improving accuracy by 24.1-91.4% and particularly reducing pressure errors from 12.9% to 2.39%. These results demonstrate that domain decomposition aligned with physical principles, combined with locality-aware activation functions, is essential for accurate FSI modeling within the PINN framework.",
    "authors": [
      "Afrah Farea",
      "Saiful Khan",
      "Reza Daryani",
      "Emre Cenk Ersan",
      "Mustafa Serdar Celebi"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.09783",
    "title": "Photo-induced directional transport in extended SSH chains",
    "abstract": "We investigate the current-voltage characteristics of an extended Su-Schrieffer-Heeger (SSH) chain under irradiation by arbitrarily polarized light, demonstrating its potential as a light-controlled rectifier. Irradiation of light induces anisotropy in the system, enabling directional current flow and active control of rectification behavior. Our analysis demonstrates that, under optimized light parameters, the rectification efficiency can exceed 90\\%. Moreover, the direction of rectification-whether positive or negative-can be precisely controlled by varying the polarization of the light, highlighting the potential for external optical control of electronic behavior. The effect of light irradiation is incorporated using the Floquet-Bloch ansatz combined with the minimal coupling scheme, while charge transport is computed through the nonequilibrium Green's function formalism within the Landauer-Büttiker framework.",
    "authors": [
      "Usham Harish Kumar Singha",
      "Kallol Mondal",
      "Sudin Ganguly",
      "Santanu K. Maiti"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.13544",
    "title": "Controlled manipulation of solitons in a recirculating fiber loop using external potentials",
    "abstract": "Optical solitons are self-sustained wave packets that propagate without distortion due to a balance between dispersion and nonlinearity. Their unique stability underpins key photonic applications while also playing a central role in nonlinear wave physics. However, real-time control over soliton dynamics in non-dissipative systems remains a major challenge, limiting their practical applications in photonic systems. Here, we introduce a fiber-based platform for soliton manipulation, by creating programmable external potentials through synchronous arbitrary phase modulation in a recirculating optical fiber loop. We demonstrate precise soliton trapping, parametric excitation, and coupled multi-soliton interactions, revealing particle-like behavior in excellent agreement with a Hamiltonian description in which solitons are treated as interacting classical particles. The strong analogy with matter-wave solitons in Bose-Einstein condensates highlights the broader implications of our approach, which provides a versatile experimental tool for the study of nonlinear wave dynamics and engineered soliton manipulation.",
    "authors": [
      "François Copie",
      "Pierre Suret",
      "Stéphane Randoux"
    ],
    "primary_category": "nlin.PS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.23143",
    "title": "Single Qudit Control in $^{87}$Sr via Optical Nuclear Electric Resonance",
    "abstract": "Optical nuclear electric resonance (ONER) was recently proposed as a fast and robust single-qubit gate mechanism in $^{87}$Sr. Here, we demonstrate through numerical simulations that ONER can be extended to single-qudit control, addressing multiple one-level hyperfine transitions within the ten-dimensional nuclear-spin manifold. We identify suitable operating regimes and show that ONER enables high-fidelity spin manipulations, with simulated $\\pi$-gate fidelities exceeding 99.9\\%, while maintaining coherence under realistic parameter fluctuations. These results establish a proof-of-principle for optical qudit control in $^{87}$Sr and delineate practical parameter ranges for future experiments, highlighting ONER as a promising pathway toward high-dimensional quantum information processing.",
    "authors": [
      "Johannes K. Krondorfer",
      "Matthias Diez",
      "Andreas W. Hauser"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10319",
    "title": "The merger of spinning, accreting supermassive black hole binaries",
    "abstract": "Because they are likely to accrete substantial amounts of interstellar gas, merging supermassive binary black holes are expected to be strong multimessenger sources, radiating gravitational waves, photons from thermal gas, and photons from relativistic electrons energized by relativistic jets. Here we report on a numerical simulation that covers the late inspiral, merger, and initial postmerger phase of such a system where both black holes have the same mass and spin, and both spin axes are parallel to the orbital angular momentum. The simulation incorporates both 3D general relativistic magnetohydrodynamics and numerical relativity. The thermal photon power during the late inspiral, merger, and immediate postmerger phases is drawn from strong shocks rather than dissipation of turbulence inside a smoothly structured accretion disk as typically found around accreting single black holes. We find that the thermal photon and jet Poynting flux outputs are closely related in time, and we posit a mechanism that enforces this relation. The power radiated in both photons and jets diminishes gradually as merger is approached, but jumps sharply at merger to a noisy plateau. Such a distinct lightcurve should aid efforts to identify supermassive black hole mergers, with or without accompanying gravitational wave detections.",
    "authors": [
      "Lorenzo Ennoggi",
      "Manuela Campanelli",
      "Julian Krolik",
      "Scott C. Noble",
      "Yosef Zlochower",
      "Maria Chiara de Simone"
    ],
    "primary_category": "astro-ph.HE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.01543",
    "title": "Predictive quantum vibrational spectra through active learning 4G-NNPs",
    "abstract": "Predictive simulation of vibrational spectra of complex condensed-phase and interface systems with thousands of degrees of freedom has long been a challenging task of modern condensed matter theory. In this work, fourth-generation high-dimensional committee neural network potentials (4G-HDCNNPs) are developed using active learning and query-by-committee, and introduced to the essential nuclear quantum effects (NQEs) as well as conformational entropy and anharmonicities from path integral (PI) molecular dynamics simulations. Using representative bulk water and air-water interface test cases, we demonstrate the accuracy of the developed framework in infrared spectral simulations. Specifically, by seamlessly integrating non-local charge transfer effects from 4G-HDCNNPs with the NQEs from PI methods, our introduced methodology yields accurate infrared spectra using predicted charges from the 4G-HDCNNP architecture without explicit training of dipole moments. The framework introduced in this work is simple and general, offering a practical paradigm for predictive spectral simulations of complex condensed phases and interfaces, free from empirical parameterizations and ad hoc fitting.",
    "authors": [
      "Md Omar Faruque",
      "Dil K. Limbu",
      "Nathan London",
      "Mohammad R. Momeni"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22980",
    "title": "Interaction-Driven Chern Insulator at Zero Electric Field in ABCB-Stacked Tetralayer Graphene",
    "abstract": "ABCB-stacked tetralayer graphene, with intrinsic spontaneous polarization, offers a unique platform to explore electron correlation effects, whose interplay with spin-orbit coupling may engender topological phases. Here, employing a $\\mathbf{k}\\cdot\\mathbf{p}$ model with self-consistent Hartree-Fock calculations, we investigate its electronic ground states. Remarkably, we find that the intrinsic polarization, in conjunction with strong interactions ($U=8 \\text{ eV}$) and SOC, is sufficient to drive a $C=3$ quantum anomalous Hall state, obviating the need for an external electric field typical in ABCA stacks. Conversely, at moderate interactions ($U=6 \\text{ eV}$), a minimal electric field is necessary. Furthermore, calculations predict other correlation-driven metallic phases such as quarter- and three-quarter-filled states. These results establish that the synergy of intrinsic polarization, correlations, and SOC governs the rich topological phenomena, suggesting ABCB-stacked graphene as a highly tunable platform for exploring emergent topological phenomena.",
    "authors": [
      "Yulu Ren",
      "Yang Shen",
      "Chengyang Xu",
      "Wanfei Shan",
      "Weidong Luo"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01884",
    "title": "Onsager Condensation in Chiral Active Matter: Universality of Topological Gas Dynamics",
    "abstract": "We identify a thermodynamic phase transition in chiral active matter. Low-frequency disorder triggers global synchronisation and energy dissipation, while high disorder activates a topological heat pump, generating an inverse energy cascade. This drives the system towards an Onsager dipole, which can be arrested into a metastable vortex glass if dispersion is insufficient to overcome the defect lattice. We propose topological gas dynamics as a universality class governed by the interplay of active disorder and topological sorting, unifying active swarms and classical inviscid fluids.",
    "authors": [
      "Magnus F Ivarsen"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03093",
    "title": "New Identity for Cayley's First Hyperdeterminant with Applications to Symmetric Tensors and Entanglement",
    "abstract": "In this article, a new formula for computing Cayley's first hyperdeterminant in terms of the Levi-Civita symbol is given. It is then shown that this formula can be used to compute the hyperdeterminant of symmetric hypermatrices in polynomial time with respect to their order (assuming fixed side length). Applications to the quantum entanglement of bosons are then discussed. Additionally, in order to obtain the fast calculation of the hyperdeterminant on symmetric hypermatrices, hypermatrix generalizations of elimination and duplication matrices are defined, and explicit formulas for them are derived in the appendix of this article.",
    "authors": [
      "Isaac Dobes"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03094",
    "title": "Performance Analysis of Quantum Support Vector Classifiers and Quantum Neural Networks",
    "abstract": "This study explores the performance of Quantum Support Vector Classifiers (QSVCs) and Quantum Neural Networks (QNNs) in comparison to classical models for machine learning tasks. By evaluating these models on the Iris and MNIST-PCA datasets, we find that quantum models tend to outperform classical approaches as the problem complexity increases. While QSVCs generally provide more consistent results, QNNs exhibit superior performance in higher-complexity tasks due to their increased quantum load. Additionally, we analyze the impact of hyperparameter tuning, showing that feature maps and ansatz configurations significantly influence model accuracy. We also compare the PennyLane and Qiskit frameworks, concluding that Qiskit provides better optimization and efficiency for our implementation. These findings highlight the potential of Quantum Machine Learning (QML) for complex classification problems and provide insights into model selection and optimization strategies",
    "authors": [
      "Tomás Villalba-Ferreiro",
      "Eduardo Mosqueira-Rey",
      "Diego Alvarez-Estevez"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03099",
    "title": "QGShap: Quantum Acceleration for Faithful GNN Explanations",
    "abstract": "Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at this https URL .",
    "authors": [
      "Haribandhu Jena",
      "Jyotirmaya Shivottam",
      "Subhankar Mishra"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03131",
    "title": "Generating redundantly encoded resource states for photonic quantum computing",
    "abstract": "Measurement-based quantum computing relies on the generation of large entangled cluster states that act as a universal resource on which logical circuits can be imprinted and executed through local measurements. A number of strategies for constructing sufficiently large photonic cluster states propose fusing many smaller resource states generated by a series of quantum emitters. However, the fusion process is inherently probabilistic with a 50% success probability in standard guise. A recent proposal has shown that, in the limit of low loss, the probability of achieving successful fusion may be boosted to near unity by redundantly encoding the vertices of linear graph states using Greenberger-Horne-Zeilinger states [Quantum 7, 992 (2023)]. Here we present a protocol for deterministically generating redundantly encoded photonic resource states using single quantum emitters, and study the impact of protocol errors and photonic losses on the generated resource states and type-II photonic fusion. Our work provides a route for efficiently constructing complex entangled photonic qubit states for photonic quantum computing and quantum repeaters.",
    "authors": [
      "Samuel J. Sheldon",
      "Pieter Kok"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03135",
    "title": "Many-body symmetry-protected zero boundary modes of synthetic photo-magnonic crystals",
    "abstract": "The topological classification of insulators and superconductors, the \"ten-fold way\", is grounded on fermionic many-body symmetries and has had a dramatic impact on many fields of physics. Therefore, it seems equally important to investigate a similar approach for bosons as tightly analogous to the fermionic prototype as possible. There are, however, several obstacles coming from the fundamental physical differences between fermions and bosons. Here, we propose a potentially optimal way forward: a theory of free boson topology (topological classification and bulk-boundary correspondence) protected by bosonic many-body symmetry operations, namely, squeezing transformations, particle number, and bosonic time reversal. We identify two symmetry classes that are topologically non-trivial in one dimension. They include key models like the bosonic Kitaev chain, protected by a squeezing symmetry within our framework, and the celebrated bosonic SSH model, protected by a squeezing symmetry and particle number. To provide a robust experimental platform for testing our theory, we introduce a new quantum meta-material: photo-magnonic crystals. They consist of arrays of interconnected photo-magnonic cavities. They are remarkable for their experimental flexibility and natural affinity for displaying band topological physics at microwave frequencies. We engineer a many-body symmetry-protected topological photo-magnonic chain with boundary modes mandated by a Pfaffian invariant. Using an electromagnetic finite-element modelling, we simulate its reflection and transmission and identify experimental signatures of its boundary modes. The experimental tuning of the crystal to its symmetry-protected topological phase is also addressed. Our modelling of the photo-magnonic chain provides a thorough blueprint for its experimental realisation and the unambiguous observation of its exotic physics.",
    "authors": [
      "Alan Gardin",
      "Emilio Cobanera",
      "Giuseppe C. Tettamanzi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03138",
    "title": "The Pound-Drever-Hall Method for Superconducting-Qubit Readout",
    "abstract": "Scaling quantum computers to large sizes requires the implementation of many parallel qubit readouts. Here we present an ultrastable superconducting-qubit readout method using the multi-tone self-phase-referenced Pound-Drever-Hall (PDH) technique, originally developed for use with optical cavities. In this work, we benchmark PDH readout of a single transmon qubit, using room-temperature heterodyne detection of all tones to reconstruct the PDH signal. We demonstrate that PDH qubit readout is insensitive to microwave phase drift, displaying $0.73^\\circ$ phase stability over 2 hours, and capable of single-shot readout in the presence of phase errors exceeding the phase shift induced by the qubit state. We show that the PDH sideband tones do not cause unwanted measurement-induced state transitions for a transmon qubit, leading to a potential signal enhancement of at least $14$~dB over traditional heterodyne readout.",
    "authors": [
      "Ibukunoluwa Adisa",
      "Won Chan Lee",
      "Kevin C. Cox",
      "Alicia J. Kollár"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03162",
    "title": "Classical Thermometry of Quantum Annealers",
    "abstract": "Quantum annealers are emerging as programmable, dynamical experimental platforms for probing strongly correlated spin systems. Yet key thermal assumptions, chiefly a Gibbs-distributed output ensemble, remain unverified in the large-scale regime. Here, we experimentally and quantitatively assess Gibbs sampling fidelity across system sizes spanning over three orders of magnitude. We explore a wide parameter space of coupling strengths, system sizes, annealing times, and D-wave hardware architectures. We find that the naively assumed scaling law for the effective temperature requires a non-negligible, coupling-independent offset that is robust across machines and parameter regimes, quantifying residual non-thermal effects that still conform to an effective Gibbs description. These non-idealities are further reflected in a systematic discrepancy between the physical temperature inferred from the sampled ensemble and the nominal cryogenic temperature of the device. Our results systematically assess the viability of quantum annealers as experimental platforms for probing classical thermodynamics, correct previous assumptions, and provide a physically grounded thermometry framework to benchmark these machines for future thermodynamic experiments.",
    "authors": [
      "George Grattan",
      "Pratik Sathe",
      "Cristiano Nisoli"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03177",
    "title": "Magic of the Well: assessing quantum resources of fluid dynamics data",
    "abstract": "We investigate the quantum resource requirements of a dataset generated from simulations of two-dimensional, periodic, incompressible shear flow, aimed at training machine learning models. By measuring entanglement and non-stabilizerness on MPS-encoded functions, we estimate the computational complexity encountered by a stabilizer or a tensor network solver applied to Computational Fluid Dynamics (CFD) simulations across different flow regimes. Our analysis reveals that, under specific initial conditions, the shear width identifies a transition between resource-efficient and resource-intensive regimes for non-trivial evolution. Furthermore, we find that the two resources qualitatively track each other in time, and that the mesh resolution along with the sign structure play a crucial role in determining the resource content of the encoded state. These findings offer useful guidelines for the development of scalable, quantum-inspired approaches to fluid dynamics.",
    "authors": [
      "Antonio Francesco Mello",
      "Mario Collura",
      "E. Miles Stoudenmire",
      "Ryan Levy"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03193",
    "title": "In Situ Quantum Analog Pulse Characterization via Structured Signal Processing",
    "abstract": "Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults.",
    "authors": [
      "Yulong Dong",
      "Christopher Kang",
      "Murphy Yuezhen Niu"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03274",
    "title": "Excess work in counterdiabatic driving",
    "abstract": "Many years have passed since the conception of the quintessential method of shortcut to adiabaticity known as counterdiabatic driving (or transitionless quantum driving). Yet, this method appears to be energetically cost-free and thus continually challenges the task of quantifying the amount of energy it demands to be accomplished. This paper proposes that the energy cost of controlling a closed quantum system using the counterdiabatic method can also be assessed using the instantaneous excess work during the process and related quantities, as the time-averaged excess work. Starting from the Mandelstam-Tamm bound for driven dynamics, we have shown that the speed-up of counterdiabatic driving is linked with the spreading of energy between the eigenstates of the total Hamiltonian, which is necessarily accompanied by transitions between these eigenstates. Nonetheless, although excess work can be used to quantify energetically these transitions, it is well known that the excess work is zero throughout the entire process under counterdiabatic driving. To recover the excess work as an energetic cost quantifier for counterdiabatic driving, we will propose a different interpretation of the parameters of the counterdiabatic Hamiltonian, leading to an excess work different from zero. We have illustrated our findings with the Landau-Zener model.",
    "authors": [
      "Lucas P. Kamizaki",
      "Marcus V. S. Bonança"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03333",
    "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State",
    "abstract": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.",
    "authors": [
      "Xun Tang",
      "Haoxuan Chen",
      "Yuehaw Khoo",
      "Lexing Ying"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03341",
    "title": "Quench dynamics of the quantum XXZ chain with staggered interactions: Exact results and simulations on digital quantum computers",
    "abstract": "We investigate quench dynamics in the quantum $S=1/2$ XXZ antiferromagnetic chain with staggered and anisotropic interactions in the flat-band limit. Our quench protocol interchanges the odd- and even-bond strengths of a fully dimerized chain, enabling us to derive exact time-dependent states for arbitrary even system sizes by working in the Bell basis. We obtain closed-form, size-independent expressions for the von Neumann and second-order Rényi entanglement entropies. We further calculate exact Loschmidt echoes and the corresponding return rate functions across various anisotropies and system sizes, and identify Loschmidt zeros in finite chains. Our analysis reveals the precise conditions on the anisotropy parameter that govern the periodicity of the dynamical observables. In addition to the analytic study, we perform two types of numerical experiments on IBM-Q quantum devices. First, we use the Hadamard test to estimate the Bell-basis expansion coefficients and reconstruct the dynamical states, achieving accurate entanglement entropies and the Loschmidt echo for small systems. Second, we implement Trotter-error-free time-evolution circuits combined with randomized Pauli measurements. Post-processing via statistical correlations and classical shadows yields reliable estimates of the second-order Rényi entanglement entropy and the Loschmidt echo, showing satisfactory agreement with exact results.",
    "authors": [
      "Ching-Tai Huang",
      "Yu-Cheng Lin",
      "Ferenc Igloi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03362",
    "title": "Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits",
    "abstract": "Parametric amplification is essential for quantum measurement, enabling the amplification of weak microwave signals with minimal added noise. While Josephson-junction-based amplifiers have become standard in superconducting quantum circuits, their magnetic sensitivity, limited saturation power, and sub-kelvin operating requirements motivate the development of alternative nonlinear platforms. Here we demonstrate a two-mode kinetic-inductance parametric amplifier based on a pair of capacitively coupled Kerr-nonlinear resonators fabricated from NbTiN and NbN thin films. The distributed Kerr nonlinearity of these materials enables nondegenerate four-wave-mixing amplification with gains approaching 40 dB, gain-bandwidth products up to 6.9 MHz, and 1-dB compression powers two to three orders of magnitude higher than those of state-of-the-art Josephson amplifiers. A coupled-mode theoretical model accurately captures the pump-induced modification of the hybridized modes and quantitatively reproduces the observed signal and idler responses. The NbN device exhibits a significantly larger Kerr coefficient and superior gain-bandwidth performance, highlighting the advantages of high-kinetic-inductance materials. Our results establish coupled kinetic-inductance resonators as a robust platform for broadband, high-power, and magnetically resilient quantum-limited amplification, offering a scalable route for advanced readout in superconducting qubits, spin ensembles, quantum dots, and other microwave-quantum technologies.",
    "authors": [
      "Danial Davoudi",
      "Abdul Mohamed",
      "Shabir Barzanjeh"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03423",
    "title": "Engineering photonic dispersion relation and atomic dynamics in waveguide QED setup via long-range hoppings",
    "abstract": "Non-trivial dispersion relations engineered in photonic waveguide for the precise control of atomic dynamics has recently attracted considerable attention. Here, we study a system in which atoms are coupled to one-dimensional coupled-resonator waveguides with long-range hoppings. By carefully engineering the jth-order nearest neighbor (JNN) hoppings between resonators, we construct linear dispersion relations with the chiral characteristic. To quantify the degree of linearity, we analyze the propagation fidelities of Gaussian wave packets in these waveguides. Furthermore, we demonstrate that such coupled-resonator waveguides can serve as versatile platforms for enabling directional atomic radiation and absorption. Beyond linear dispersion relations, more general forms, including quadratic and cubic relations, can also be achieved through tailored JNN-hoppings. Our study thus provides a unified framework for simulating atom-environment couplings with arbitrary dispersion relations.",
    "authors": [
      "Weijun Cheng",
      "Da-Wei Wang",
      "Yang Xue",
      "Zhihai Wang",
      "Liantuan Xiao"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03434",
    "title": "Quantum Encrypted Control of Networked Systems",
    "abstract": "Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources.",
    "authors": [
      "Zihao Ren",
      "Daniel Quevedo",
      "Salah Sukkarieh",
      "Guodong Shi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03457",
    "title": "Beyond Lindblad Dynamics: Rigorous Guarantees for Thermal and Ground State Preservation under System Bath Interactions",
    "abstract": "We establish new theoretical results demonstrating the efficiency and robustness of system bath interaction models for quantum thermal and ground state preparation. Unlike existing analyses, which relies on the weak coupling Lindblad limit and require $O(\\epsilon)$ coupling strengths for $\\epsilon$ accuracy, leading to slow mixing, we rigorously show that accurate state preparation remains possible far beyond this regime. In particular, even when the cumulative coupling strength remains constant rather than vanishing, the induced quantum channel still approximately fixes the target state. Our proof introduces new techniques for controlling all orders of the Dyson expansion and for analyzing the associated multidimensional operator Fourier transforms. These bounds substantially improve upon prior results, and numerical simulations on the TFIM and Hubbard models further confirm the robustness of the system bath interaction framework across both weak and strong coupling regimes.",
    "authors": [
      "Ke Wang",
      "Zhiyan Ding"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03505",
    "title": "Complex Wigner entropy and Fisher control of negativity in an oval quantum billiard",
    "abstract": "We develop a complex-entropy framework for Wigner negativity and apply it to avoided crossings in an oval quantum billiard. For a real Wigner function the Gibbs--Shannon functional becomes complex; its imaginary part, proportional to the Wigner-negative volume, serves as an entropy-like measure of phase-space nonclassicality. A sign-resolved decomposition separates the total negative weight from its phase-space distribution and defines a negative-channel Fisher information that quantifies how sensitively the negative lobe reshapes as a control parameter is varied. This structure yields a Cauchy--Schwarz bound that limits how rapidly the imaginary entropy, and hence the Wigner negativity, can change with the parameter. In the oval billiard, avoided crossings display enhanced negativity and an amplified negative-channel Fisher response, providing a clear phase-space signature of mode hybridization. The construction is generic and extends to other wave-chaotic and mesoscopic systems with phase-space representations.",
    "authors": [
      "Kyu-Won Park",
      "Jongin Jeong"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03530",
    "title": "Edge bits in average symmetry protected topological mixed state",
    "abstract": "Edge bit in an average symmetry protected topological (ASPT) mixed state is studied. The state is protected by one strong $Z_2$ and one weak (average) $Z_2$ symmetries. As analogous objects of pure symmetry protected topological (SPT) states, the ASPT possesses edge bits. In particular, the analogous operator response exists, that is, symmetry fractionalization. The fractionalization preserves the presence of the ASPT in the bulk, and the fractionalized edge operators acting on the edge bits of the ASPT. %analogous to the ones in the pure SPTs. In this work, based on the cluster model and by employing Choi mapping, we discuss generic features of the edge bits and numerically clarify the behavior of the edge bits and their robustness for varying decoherence and perturbative interactions. By using an operator-space mutual information (OSMI), we track the flow of quantum correlations between the two edges. Remarkably, even in the ASPT regime, a finite portion of the initial edge-to-edge correlation survives.",
    "authors": [
      "Yoshihito Kuno"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03581",
    "title": "Quantum Hash Function Based on Spectral Properties of Graphs and Discrete Walker Dynamics",
    "abstract": "We present Quantum Graph Hash (QGH-256), a novel quantum spectral hashing algorithm that generates high-entropy fingerprints from message-induced graphs. Each input message is mapped to a weighted graph via a discrete random walk on an n X n toroidal grid, where the walk dynamics determine the edge weights. Quantum Phase Estimation (QPE) is then used to extract the phase spectrum of the graph Laplacian. Unlike standard QPE settings, the phase estimation is performed with respect to a superposition state (a uniform superposition over all node basis states) rather than an eigenvector, ensuring that all eigencomponents contribute to the resulting spectrum. This yields spectral features that distinguish even co-spectral but non-isomorphic message-induced graphs. The final spectral fingerprint is converted into a 256-bit digest, producing a compact representation of the input. As the fingerprint encodes both spectral and dynamical properties of the message-induced graph, the resulting hash exhibits strong sensitivity to input perturbations and provides a structurally rich foundation for post-quantum hashing. To demonstrate the feasibility of the approach, we implement QGH-256 on a 4 X 4 toroidal grid, chosen empirically: smaller grids exhibit collisions, whereas larger grids significantly increase execution time. The entire pipeline is implemented in Qiskit, and we use a seeded statevector simulator to obtain stable, noise-free results.",
    "authors": [
      "Mohana Priya Thinesh Kumar",
      "Pranavishvar Hariprakash"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03583",
    "title": "Energy-Scaled Zero-Noise Extrapolation for Gottesman-Kitaev-Preskill Code",
    "abstract": "The performance of Gottesman-Kitaev-Preskill (GKP) codes, an approach to hardware-efficient quantum error correction, is limited by the finite squeezing capabilities of current experimental platforms. To circumvent this hardware demand, we introduce Energy-Scaled Zero-Noise Extrapolation (ES-ZNE), a quantum error mitigation protocol that uses the mean photon number of the GKP code as a tunable effective noise parameter. The protocol measures logical observables at a series of accessible finite energies and extrapolates the results to the ideal, infinite-energy limit using an ansatz based on the code's asymptotic error scaling. Through simulating a GKP qubit under a pure-loss channel, we demonstrate that ES-ZNE successfully mitigates finite-energy errors, recovering the ideal expectation values (within numerical uncertainty) in the shallow-noise regime. Furthermore, by computationally removing artifacts arising from the finite-energy encoding, our method characterizes the intrinsic performance of the ideal GKP code, revealing a sharp error threshold beyond which the code's corrective power diminishes. These results establish ES-ZNE as a practical, software-based strategy for enhancing the performance of near-term bosonic quantum processors, trading sampling overhead for demanding physical resources like high squeezing.",
    "authors": [
      "Gui-Zhong Luo",
      "Matthew Otten"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03659",
    "title": "Experimental quantum voting using photonic GHZ states",
    "abstract": "Quantum communication protocols seek to leverage the unique properties of quantum systems for coordination or communication tasks, usually with guarantees of security or anonymity that exceed what is possible classically. One promising domain of application is elections, where strong such guarantees are essential to ensure legitimacy. We experimentally implement a recently proposed election protocol from Centrone et al. such that no one, including a potential central authority, can know the preferred candidate of any voter other than themself. We conduct a four-party election, generating and distributing four-partite GHZ states with $\\approx 89\\%$ fidelity and successfully recording voters' intentions $\\approx 87\\%$ of the time.",
    "authors": [
      "Francis Marcellino",
      "Mingsong Wu",
      "Rob Thew"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03681",
    "title": "Direct Equivalence between Dynamics of Quantum Walks and Coupled Classical Oscillators",
    "abstract": "Continuous time quantum walks on exponentially large, sparse graphs form a powerful paradigm for quantum computing: On the one hand, they can be efficiently simulated on a quantum computer. On the other hand, they are themselves BQP-complete, providing an alternative framework for thinking about quantum computing -- a perspective which has indeed led to a number of novel algorithms and oracle problems. Recently, simulating the dynamics of a system of harmonic oscillators (that is, masses and springs) was set forth as another BQP-complete problem defined on exponentially large, sparse graphs. In this work, we establish a direct and transparent mapping between these two classes of problems. As compared to linking the two classes of problems via their BQP-completeness, our mapping has several desirable features: It is transparent, in that it respects the structure of the problem, including the geometry of the underlying graph, initialization, read-out, and efficient oracle access, resulting in low overhead in terms of both space and time; it allows to map also between restricted subsets of instances of both problems which are not BQP-complete; it provides a recipe to directly translate any quantum algorithm designed in the quantum walk paradigm to harmonic oscillators (and vice versa); and finally, it provides an alternative, transparent way to prove BQP-completeness of the harmonic oscillator problem by mapping it to BQP-completeness construction for the quantum walk problem (or vice versa).",
    "authors": [
      "Lilith Zschetzsche",
      "Refik Mansuroglu",
      "András Molnár",
      "Norbert Schuch"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03685",
    "title": "Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)",
    "abstract": "Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global Mølmer-Sørensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design.",
    "authors": [
      "Seng W. Loke"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03690",
    "title": "Sympathetic Cooling of Levitated Optomechanics through Nonreciprocal Coupling",
    "abstract": "Optomechanical cooling of levitated nanoparticles has become an essential topic in modern quantum physics, providing a platform for exploring macroscopic quantum phenomena and high-precision sensing. However, conventional cavity-assisted cooling is fundamentally constrained by cavity dissipation and environmental noise, limiting the attainable minimum temperature. In this work, we propose a non-Hermitian optomechanical cooling scheme through nonreciprocal coupling between two levitated nanoparticles, where one particle is directly cooled by an optical cavity and the other is cooled indirectly through a non-Hermitian interaction. Both analytical solutions and numerical simulations reveal that increasing nonreciprocity enhances directional energy transfer, enabling the target particle to reach a lower phonon occupation than is achievable in conventional cavity cooling. This study demonstrates a new cooling mechanism driven by non-Hermitian interactions, offering theoretical guidance for realizing controllable energy flow and deep cooling in levitated optomechanical systems, and paving the way for future developments in quantum control and sensing technologies.",
    "authors": [
      "Jialin Li",
      "Guangyu Zhang",
      "Zhang-qi Yin"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03717",
    "title": "Geometrical structure of the Wigner flow information quantifiers and hyperbolic stability in the phase-space framework",
    "abstract": "Quantifiers of stationarity, classicality, purity and vorticity are derived from phase-space differential geometrical structures within the Weyl-Wigner framework, after which they are related to the hyperbolic stability of classical and quantum-modified Hamiltonian (non-linear) equations of motion. By examining the equilibrium regime produced by such an autonomous system of ordinary differential equations, a correspondence between Wigner flow properties and hyperbolic stability boundaries in the phase-space is identified. Explicit analytical expressions for equilibrium-stability parameters are obtained for quantum Gaussian ensembles, wherein information quantifiers driven by Wigner currents are identified. Illustrated by an application to a Harper-like system, the results provide a self-contained analysis for identifying the influence of quantum fluctuations associated to the emergence of phase-space vorticity in order to quantify equilibrium and stability properties of Hamiltonian non-linear dynamics.",
    "authors": [
      "Alex E. Bernardini"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03735",
    "title": "Non-Gaussian Dissipative Quantum Thermometry Beyond Gaussian Bounds",
    "abstract": "The fundamental metrological limits of temperature sensing in open quantum systems remain largely unresolved, particularly regarding the role of non-Gaussian quantum resources. In this letter, we establish analytic bounds on the quantum Fisher information (QFI) for temperature estimation using non-Gaussian states undergoing dissipative bosonic evolution. By focusing on the short-time regime governed by a time-local master equation, we derive precise scaling laws that elucidate when and how non-Gaussian probes decisively outperform Gaussian states under identical energy constraints. Our analysis uncovers a distinct linear-in-time QFI enhancement unique to Fock states, in contrast to the inherently weaker, quadratic scaling of Gaussian probes. These theoretical insights are substantiated through exact numerical simulations and mapped onto experimentally accessible platforms such as circuit QED. Our results not only clarify the quantum thermometric advantage of non-Gaussianity but also chart a realistic pathway toward harnessing it in noisy quantum technologies.",
    "authors": [
      "Pritam Chattopadhyay"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03740",
    "title": "Quantum Max Cut for complete tripartite graphs",
    "abstract": "The Quantum Max-$d$-Cut ($d$-QMC) problem is a special instance of a $2$-local Hamiltonian problem, representing the quantum analog of the classical Max-$d$-Cut problem. The $d$-QMC problem seeks the largest eigenvalue of a Hamiltonian defined on a graph with $n$ vertices, where edges correspond to swap operators acting on $(\\mathbb{C}^d)^{\\otimes n}$. In recent years, progress has been made by investigating the algebraic structure of the $d$-QMC Hamiltonian. Building on this approach, this article solves the $d$-QMC problem for complete tripartite graphs for small local dimensions, $d \\le 3$.",
    "authors": [
      "Tea Štrekelj"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03748",
    "title": "Widefield Quantum Sensor for Vector Magnetic Field Imaging of Micromagnetic Structures",
    "abstract": "Many spintronic, magnetic-memory, and neuromorphic devices rely on spatially varying magnetic fields. Quantitatively imaging these fields with full vector information over extended areas remains a major challenge. Existing probes either offer nanoscale resolution at the cost of slow scanning, or widefield imaging with limited vector sensitivity or material constraints. Quantum sensing with nitrogen-vacancy (NV) centers in diamond promises to bridge this gap, but a practical camera-based vector magnetometry implementation on relevant microstructures has not been demonstrated. Here we adapt a commercial widefield microscope to implement a camera-compatible pulsed optically detected magnetic resonance protocol to reconstruct stray-field vectors from microscale devices. By resolving the Zeeman shifts of the four NV orientations, we reconstruct the stray-field vector generated by microfabricated permalloy structures that host multiple stable remanent states. Our implementation achieves a spatial resolution of $\\approx 0.52 ~\\mu\\mathrm{m}$ across an $83~\\mu\\mathrm{m} \\times 83~\\mu\\mathrm{m}$ field of view and a peak sensitivity of $ (828 \\pm 142)~\\mathrm{nT\\,Hz^{-1}}$, with acquisition times of only a few minutes. These results establish pulsed widefield NV magnetometry on standard microscopes as a practical and scalable tool for routine vector-resolved imaging of complex magnetic devices.",
    "authors": [
      "Orlando D. Cunha",
      "Filipe Camarneiro",
      "João P. Silva",
      "Hariharan Nhalil",
      "Ariel Zaig",
      "Lior Klein",
      "Jana B. Nieder"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03758",
    "title": "An end-to-end quantum algorithm for nonlinear fluid dynamics with bounded quantum advantage",
    "abstract": "Computational fluid dynamics (CFD) is a cornerstone of classical scientific computing, and there is growing interest in whether quantum computers can accelerate such simulations. To date, the existing proposals for fault-tolerant quantum algorithms for CFD have almost exclusively been based on the Carleman embedding method, used to encode nonlinearities on a quantum computer. In this work, we begin by showing that these proposals suffer from a range of severe bottlenecks that negate conjectured quantum advantages: lack of convergence of the Carleman method, prohibitive time-stepping requirements, unfavorable condition number scaling, and inefficient data extraction. With these roadblocks clearly identified, we develop a novel algorithm for the incompressible lattice Boltzmann equation that circumvents these obstacles, and then provide a detailed analysis of our algorithm, including all potential sources of algorithmic complexity, as well as gate count estimates. We find that for an end-to-end problem, a modest quantum advantage may be preserved for selected observables in the high-error-tolerance regime. We lower bound the Reynolds number scaling of our quantum algorithm in dimension $D$ at Kolmogorov microscale resolution with $O(\\mathrm{Re}^{\\frac{3}{4}(1+\\frac{D}{2})} \\times q_M)$, where $q_M$ is a multiplicative overhead for data extraction with $q_M = O(\\mathrm{Re}^{\\frac{3}{8}})$ for the drag force. This upper bounds the scaling improvement over classical algorithms by $O(\\mathrm{Re}^{\\frac{3D}{8}})$. However, our numerical investigations suggest a lower speedup, with a scaling estimate of $O(\\mathrm{Re}^{1.936} \\times q_M)$ for $D=2$. Our results give robust evidence that small, but nontrivial, quantum advantages can be achieved in the context of CFD, and motivate the need for additional rigorous end-to-end quantum algorithm development.",
    "authors": [
      "David Jennings",
      "Kamil Korzekwa",
      "Matteo Lostaglio",
      "Richard Ashworth",
      "Emanuele Marsili",
      "Stephen Rolston"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03769",
    "title": "Metrological Sensitivity beyond Gaussian Limits with Cubic Phase States",
    "abstract": "Cubic phase states provide the essential non-Gaussian resource for continuous-variable quantum computing. We show that they also offer significant potential for quantum metrology, surpassing the phase-sensing sensitivity of all Gaussian states at equal average photon number. Optimal sensitivity requires only moderate initial squeezing, and the non-Gaussian advantage remains robust against loss and detection noise. We identify optimal measurement strategies and show that several experimentally relevant preparation schemes surpass Gaussian limits, in some cases reaching the sensitivity of cubic phase states. Our results establish cubic phase states as a promising resource for quantum-enhanced precision measurements beyond Gaussian limits.",
    "authors": [
      "Jiajie Guo",
      "Shuheng Liu",
      "Boxuan Jing",
      "Qiongyi He",
      "Manuel Gessner"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03788",
    "title": "Quantum Algorithm for Searching for the Longest Segment and the Largest Empty Rectangle",
    "abstract": "In the paper, we consider the problem of searching for the Largest empty rectangle in a 2D map, and the one-dimensional version of the problem is the problem of searching for the largest empty segment. We present a quantum algorithm for the Largest Empty Square problem and the Largest Empty Rectangle of a fixed width $d$ for $n\\times n$-rectangular map. Query complexity of the algorithm is $\\tilde{O}(n^{1.5})$ for the square case, and $\\tilde{O}(n\\sqrt{d})$ for the rectangle with a fixed width $d$ case, respectively. At the same time, the lower bounds for the classical case are $\\Omega(n^2)$, and $\\Omega(nd)$, respectively. The Quantum algorithm for the one-dimensional version of the problem has $O(\\sqrt{n}\\log n\\log\\log n)$ query complexity. The quantum lower bound for the problem is $\\Omega(\\sqrt{n})$ which is almost equal to the upper bound up to a log factor. The classical lower bound is $\\Omega(n)$. So, we obtain the quadratic speed-up for the problem.",
    "authors": [
      "Kamil Khadiev",
      "Vladislav Remidovskii",
      "Timur Bikmullin",
      "Aliya Khadieva"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03808",
    "title": "Solution of the Electric Field Integral Equation Using a Hybrid Quantum-Classical Scheme: Investigation of Accuracy and Efficiency",
    "abstract": "Conventional classical solvers are commonly used for solving matrix equation systems resulting from the discretization of SIEs in computational electromagnetics (CEM). However, the memory requirement would become a bottleneck for classical computing as the electromagentic problems become much larger. As an alternative, quantum computing has a natural \"parallelization\" advantage with much lower storage complexity due to the superposition and entanglement in quantum mechanics. Even though several quantum algorithms have been applied for the SIEs-based methods in the literature, the size of the matrix equation systems solvable using them is still limited. In this work, we use a hybrid quantum-classical scheme to solve the EFIE for analyzing electromagentic scattering from three-dimensional (3D) perfect electrically conducting objects with arbitrary shapes in CEM for the first time. Instead of directly solving the original EFIE matrix equation system using the quantum algorithms, the hybrid scheme first designs the preconditioned linear system and then uses a double-layer iterative strategy for its solution, where the external iteration layer builds subspace matrix equation systems with smaller dimension and the internal iteration layer solves the smaller systems using the quantum algorithms. Two representative quantum algorithms, HHL and VQLS, are considered in this work, which are executed on the quantum simulator and quantum computer platforms. We present the theoretical time complexity analysis of the hybrid quantum-classical scheme and perform numerical experiments to investigate the accuracy and efficiency of the hybrid scheme. The results show that the computational complexity of the hybrid VQLS-classical scheme is lower than the conventional fast solvers in classical computing, which indicates the hybrid scheme is more promising for analyzing large-scale electromagnetic problems.",
    "authors": [
      "Rui Chen",
      "Teng-Yang Ma",
      "Meng-Han Dou",
      "Chao-Fu Wang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03850",
    "title": "Density of states of quantum systems from free probability theory: a brief overview",
    "abstract": "We provide a brief overview of approaches for calculating the density of states of quantum systems and random matrix Hamiltonians using the tools of free probability theory. For a given Hamiltonian of a quantum system or a generic random matrix Hamiltonian, which can be written as a sum of two non-commutating operators, one can obtain an expression for the density of states of the Hamiltonian from the known density of states of the two component operators by assuming that these operators are mutually free and by using the free additive convolution. In many examples of interacting quantum systems and random matrix models, this procedure is known to provide a reasonably accurate approximation to the exact numerical density of states. We review some of the examples that are known in the literature where this procedure works very well, and also discuss some of the limitations of this method in situations where the free probability approximation fails to provide a sufficiently accurate description of the exact density of states. Subsequently, we describe a perturbation scheme that can be developed from the subordination formulas for the Cauchy transform of the density of states and use it to obtain approximate analytical expressions for the density of states in various models, such as the Rosenzweig-Porter random matrix ensemble and the Anderson model with on-site disorder.",
    "authors": [
      "Keun-Young Kim",
      "Kuntal Pal"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03853",
    "title": "Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices",
    "abstract": "Extensive theoretical and experimental work has established high-fidelity electron shuttling in Si/SiGe systems, whereas demonstrations in Si/SiO2 (SiMOS) remain at an early stage. To help address this, we perform full 3D simulations of conveyor-belt charge shuttling in a realistic SiMOS device, building on earlier 2D modelling. We solve the Poisson and time-dependent Schrodinger equations for varying shuttling speeds and gate voltages, focusing on potential pitfalls of typical SiMOS devices such as oxide-interface roughness, gate fabrication imperfections, and charge defects along the transport path. The simulations reveal that for low clavier-gate voltages, the additional oxide screening in multi-layer gate architectures causes conveyor-belt shuttling to collapse to the bucket-brigade mode, inducing considerable orbital excitation in the process. Increasing the confinement restores conveyor-belt operation, which we find to be robust against interface roughness, gate misalignment, and charge defects buried in the oxide. However, our results indicate that defects located at the Si/SiO2-interface can induce considerable orbital excitation. For lower conveyor gate biases, positive defects in the transport channel can even capture passing electrons. Hence we identify key challenges and find operating regimes for reliable charge transport in SiMOS architectures.",
    "authors": [
      "Jack J. Turner",
      "Christian W. Binder",
      "Guido Burkard",
      "Andrew J. Fisher"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03898",
    "title": "Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method",
    "abstract": "The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size.",
    "authors": [
      "Yu Wang",
      "Martina Nibbi",
      "Maxine Luo",
      "Isabel Nha Minh Le",
      "Yanbin Chen",
      "J. Ignacio Cirac",
      "Christian Mendl"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03924",
    "title": "Experimental Quantum Electronic Voting",
    "abstract": "Quantum information protocols offer significant advantages in properties such as security, anonymity, and privacy for communication and computing tasks. An application where guaranteeing the highest possible security and privacy is critical for democratic societies is electronic voting. As computational power continues to evolve, classical voting schemes may become increasingly vulnerable to information leakage. In this work, we present the experimental demonstration of an information-theoretically secure and efficient electronic voting protocol that, crucially, does not rely on election authorities, leveraging the unique properties of quantum states. Our experiment is based on a high-performance source of Greenberger-Horne-Zeilinger (GHZ) states and realizes a proof-of-principle implementation of the protocol in two scenarios: a configuration with four voters and two candidates employing privacy enhancement techniques and an election scenario supporting up to eight voters and sixteen candidates. The latter is particularly well-suited for secure board-level elections within organizations or small-scale governmental contexts.",
    "authors": [
      "Nicolas Laurent-Puig",
      "Matilde Baroni",
      "Federico Centrone",
      "Eleni Diamanti"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03925",
    "title": "Towards Quantum Stochastic Optimization for Energy Systems under Uncertainty: Joint Chance Constraints with Quantum Annealing",
    "abstract": "Uncertainty is fundamental in modern power systems, where renewable generation and fluctuating demand make stochastic optimization indispensable. The chance constrained unit commitment problem (UCP) captures this uncertainty but rapidly becomes computationally challenging as the number of scenarios grows. Quantum computing has been proposed as a potential route to overcome such scaling barriers. In this work, we evaluate the applicability of quantum annealing platforms to the chance constrained UCP. Focusing on a scenario approximation, we reformulated the problem as a mixed integer linear program and solved it using DWave hybrid quantum classical solver alongside Gurobi. The hybrid solver proved competitive under strict runtime limits for large scenario sets (15,000 in our experiments), while Gurobi remained superior on smaller cases. QUBO reformulations were also tested, but current annealers cannot accommodate stochastic UCPs due to hardware limits, and deterministic cases suffered from embedding overhead. Our study delineates where chance constrained UCPs can already be addressed with hybrid quantum classical methods, and where current quantum annealers remain fundamentally limited.",
    "authors": [
      "David Ribes",
      "Tatiana Gonzalez Grandon"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03929",
    "title": "Rethinking Collapse: Coupling Quantum States to Classical Bits with quasi-probabilities",
    "abstract": "We propose a formulation of quantum measurement within a modified framework of frames, in which a quantum system - a single qubit - is directly coupled to a classical measurement bit. The qubit is represented as a positive probability distribution over two classical bits, a and a', denoted by p(aa'). The measurement apparatus is described by a classical bit $\\alpha = \\pm 1$, initialized in the pure distribution $p(\\alpha) = \\frac{1}{2}(1 + \\alpha)$. The measurement interaction is modeled by a quasi-bistochastic process $ S(bb'\\beta \\mid aa'\\alpha)$ - a bistochastic map that may include negative transition probabilities, while acting on an entirely positive state space. When this process acts on the joint initial state $p(aa')p(\\alpha)$, it produces a collapsed state $p(bb'\\mid\\beta)$, yielding the measurement outcome $\\beta$ with the correct quantum-mechanical probability $p(\\beta)$. This approach bypasses the von Neumann chain of infinite couplings by treating the measurement register classically, while capturing the nonclassical nature of measurement through the quasi-bistochastic structure of the interaction.",
    "authors": [
      "Dagomir Kaszlikowski",
      "Pawel Kurzynski"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03933",
    "title": "Phase-space open-systems dynamics of second-order nonlinear interactions with pulsed quantum light",
    "abstract": "The theoretical description of broadband, multimode quantum pulses undergoing a second-order $\\chi^{(2)}$-nonlinear interaction can be quite intricate, due to the large dimensionality of the underlying phase space. However, in many cases only a few broadband (temporal) modes are relevant before and after the nonlinear interaction. Here we present an efficient framework to calculate the relation between the quantum states at the input and output of a nonlinear element in their respective relevant modes. Since the number of relevant input and output modes may differ, resulting in an open quantum system, we introduce the generalized Bloch-Messiah decomposition (GBMD), reducing the description to an equal number of input and output modes. The GBMD enables us to calculate the multimode Wigner function of the output state by convolving the rescaled Wigner function of the reduced input quantum pulse with a multivariate Gaussian phase-space function. We expand on this result by considering two examples input states: A Fock state in a single broadband mode and a two-mode squeezed vacuum, both in the THz-frequency regime, up-converted to a single output broadband mode of optical frequencies. We investigate the effect, the convolution and thermalization due to entanglement breakage have on the output Wigner function by calculating the von Neumann entropy of the output Wigner function. The methods presented here can be used to optimize the amplification or frequency conversion of broadband quantum states, opening an avenue to the generation and characterization of optical quantum states on ultrafast time scales.",
    "authors": [
      "Emanuel Hubenschmid",
      "Victor Rueskov Christiansen"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03935",
    "title": "Thermodynamics of an Open $\\mathcal{PT-}$Symmetric Quantum System",
    "abstract": "For a subclass of a general $\\mathcal{PT}-$symmetric Hamiltonian obeying anti-commutation relation with its conjugate, a Hermitian basis is found that spans the bi-orthonormal energy eigenvectors. Using the modified projectors constructed from these eigenvectors, the generalized density matrix of the $\\mathcal{PT}-$symmetric evolution is calculated, and subsequently, ergotropy for a closed system is obtained. The $\\mathcal{PT}-$symmetric system, in an open system scenario, is studied to understand ergotropy under different regimes of non-Hermiticity of the Hamiltonian. The consistency of the three laws of thermodynamics for the $\\mathcal{PT}-$symmetric system in an open system scenario is also analyzed.",
    "authors": [
      "Baibhab Bose",
      "Devvrat Tiwari",
      "Subhashish Banerjee"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03953",
    "title": "Image Theory for the Single Bounce Quantum Gravimeter",
    "abstract": "We develop an image theory for the recently proposed single-bounce quantum gravimeter. Free fall and quantum bounce of a matter wave-packet are described through decompositions over a basis of continuous energies. This leads to a much clearer interpretation of the origin of quantum interferences, associated to semi-classical estimations. We then give new tools to explore the space of parameters, and discuss the expected accuracy of the free-fall acceleration measurement.",
    "authors": [
      "Joachim Guyomard",
      "Serge Reynaud",
      "Pierre Cladé"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03984",
    "title": "Entanglement Detection with Rotationally Covariant Measurements - From Compton Scattering to Lemonade",
    "abstract": "The accurate and efficient detection of quantum entanglement remains a central challenge in quantum information science. In this work, we study the detection of entanglement of polarized photons for measurement devices that are solely specified by rotational symmetry. We derive explicit positive operator valued measures (POVMs) showing that from a quantum information perspective any such setting is classified by one real measurable parameter r. In Particular, we give a POVM formulation of the Klein--Nishina formula for Compton scattering of polarized photons. We provide an SDP-based entanglement certification method that operates on the full measured statistics and gives tight bounds, also considering semi-device independent scenarios. Furthermore, we show that, while Bell violations are impossible with rotationally covariant measurements, EPR steering can still be certified under one-sided symmetry constraints. Finally, we present a rotationally covariant showcase experiment, analyzing the scattering of polarized optical light in a selection of soft drinks. Our results suggest that lemonade-based detectors are suitable for entanglement detection.",
    "authors": [
      "Marlene Funck",
      "Ilija Funk",
      "Tizian Schmidt",
      "René Schwonnek"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03987",
    "title": "Fully quantum theory of strong-field driven tunable entangled multi-photon states in HHG",
    "abstract": "Quantum high-harmonic generation (HHG) is a growing field of research with capabilities of providing high photon-number entangled states of light. However, there is an open debate regarding the theory level required for correctly describing the quantum aspects of HHG emission, such as squeezing or entanglement. Previous approaches have employed non-interacting classical ensembles of trajectories, or perturbation theory utilizing the classical trajectories as a starting point, missing out key entanglement features. In this Letter, we develop a full quantum theory for entanglement measures in HHG solving exactly the light-matter interaction Hamiltonian and employ it for evaluating the entanglement between emitted photons of different harmonics. For the first time, we reach qualitative agreement of theory with recent experiments showing that the R entanglement parameter decreases with increasing laser power for below-threshold harmonics. Our results indicate that fine-tuning the laser power could enhance HHG entanglement features, which are observed to oscillate with the driving power and exhibit local non-classical maxima structures. Similarly, our theory predicts that the oscillatory behavior of entanglement observed for below-threshold harmonics also appears for entanglement involving above-threshold harmonics. We also show that the long-range behavior of driven electronic trajectories can qualitatively change the resulting entanglement. Lastly, we show that focal averaging over classical degrees of freedom, which has thus far been ignored in quantum HHG theories, plays a key role in entanglement measures and can change the qualitative behavior of observables. Our work establishes the state-of-the art in exploring entanglement features in HHG, and paves way for analysis and engineering of 'truly-quantum' multi-photon states in the XUV and ultrafast regime for more complex matter systems.",
    "authors": [
      "Sebastián de-la-Peña",
      "Heiko Appel",
      "Angel Rubio",
      "Ofer Neufeld"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04016",
    "title": "TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees",
    "abstract": "Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.",
    "authors": [
      "Davut Emre Tasar",
      "Ceren Ocal Tasar"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04028",
    "title": "Thermalization from quenching in coupled oscillators",
    "abstract": "We introduce a finite-time protocol that thermalizes a quantum harmonic oscillator, initially in its ground state, without requiring a macroscopic bath. The method uses a second oscillator as an effective environment and implements sudden quenches of the oscillator frequencies and coupling. Owing to the Gaussian nature of the dynamics, the thermalization condition reduces to three solvable equations, yielding exact analytic solutions for a dense discrete set of temperatures and numerical solutions in all other cases. Any target temperature can be approximated with arbitrary precision, with a trade-off between speed and accuracy. The simplicity of the protocol makes it a promising tool for rapid, controlled thermalization in quantum thermodynamics experiments and state preparation.",
    "authors": [
      "M. Harinarayanan",
      "Karthik Rajeev"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04058",
    "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap",
    "abstract": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.",
    "authors": [
      "Shashaank Khanna",
      "Matthew Pusey",
      "Roger Colbeck"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03106",
    "title": "A portable LED-based diamond magnetometer for outreach and teaching labs",
    "abstract": "We present a compact, low-cost version of an NV center diamond magnetometer which replaces the standard green laser with a high-power LED. This modification improves safety, reduces cost, and allows the green excitation and red photoluminescence to be viewed directly during demonstrations. The device is simple to assemble and suitable for outreach activities and undergraduate laboratories. We show that it can produce ODMR spectra and respond to nearby magnetic objects, with a sensitivity on the order of 1 $\\mu$T/$\\sqrt{\\text{Hz}}$. Supplementary material provides details of the construction and suggestions for student investigations to support use in teaching laboratories.",
    "authors": [
      "Hollis Williams",
      "Alex Newman",
      "Stuart Graham",
      "Colin Stephen",
      "Gavin Morley"
    ],
    "primary_category": "physics.ed-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03198",
    "title": "Excitonic Theory of the Ultrafast Optical Response of 2D-Quantum-Confined Semiconductors at Elevated Densities",
    "abstract": "An excitonic approach to the ultrafast optical response of confined semiconductors at elevated densities below the Mott transition is presented. The theory is valid from the coherent regime, where coherent excitonic transitions and biexcitons dominate, to the incoherent regime, where excitonic occupations dominate. Numerical simulations of the $1s$ exciton dynamics during intense circularly polarized pump pulses in two different Coulomb-interaction regimes are performed for two-dimensional semiconductors: Moderate Coulomb interaction is compared with dominating Coulomb interaction with respect to the light-matter interaction strength. The different many-body contributions are disentangled and it is found, that excitonic Rabi oscillations in the Coulomb-dominated regime are considerably less strong. By also comparing circular and linear excitation in a MoSe$_2$ monolayer, it is found, that linear excitation creates a regime, where excitonic Rabi oscillations are almost completely suppressed.",
    "authors": [
      "Henry Mittenzwey",
      "Oliver Voigt",
      "Andreas Knorr"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03363",
    "title": "A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning",
    "abstract": "Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.",
    "authors": [
      "Shanika Iroshi Nanayakkara",
      "Shiva Raj Pokhrel"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03368",
    "title": "Short-Range Modulated Electron Lattice and d-Wave Superconductivity in Cuprates: A Phenomenological Ginzburg-Landau Framework",
    "abstract": "We develop a phenomenological Ginzburg-Landau (GL) framework for high-$T_c$ cuprates in which a short-range modulation of the electronic charge density couples to a $d$-wave superconducting condensate. The resulting modulated electron lattice (MEL) state is distinct from long-range static charge density wave order: it is short range, partially phase coherent, and linked to superconducting coherence. A preferred wave vector $q^{\\ast} \\approx 0.3$ reciprocal lattice units along the Cu-O bond direction emerges from the interplay between a momentum-dependent susceptibility and bond-stretching phonons, consistent with neutron and x-ray data on YBa$_2$Cu$_3$O$_{7-\\delta}$ and related cuprates. The GL free energy contains coupled $d$-wave superconducting and charge sectors with parameters constrained by optimally doped YBa$_2$Cu$_3$O$_{7-\\delta}$. We identify an MEL enhancement window in doping, temperature, MEL correlation length, and disorder where a coherence linked modulation enhances the superfluid stiffness. Classical Monte Carlo simulations yield an in-plane stiffness enhancement of order ten percent, which we treat as a qualitative prediction to be tested by self-consistent Bogoliubov de Gennes calculations. The MEL framework yields falsifiable experimental signatures. For scanning tunneling spectroscopy in Bi-based cuprates we highlight two predictions: the Fourier-transformed local density of states should exhibit a $q^{\\ast} \\approx 0.3$ peak whose spectral weight sharpens as superconducting phase coherence develops below $T_c$, in contrast to static charge scenarios, and the local gap magnitude $\\Delta(r)$ should correlate positively with the local MEL amplitude. The framework implies correlations between MEL correlation length, superfluid stiffness, disorder, and vortex pinning, and organizes cuprate observations into testable STM/STS predictions.",
    "authors": [
      "Jaehwahn Kim",
      "Davis A. Rens",
      "Waqas Khalid",
      "Hyunchul Kim"
    ],
    "primary_category": "cond-mat.supr-con",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03526",
    "title": "Stretched Exponential Scaling of Parity-Restricted Energy Gaps in a Random Transverse-Field Ising Model",
    "abstract": "The success of a quantum annealing algorithm requires a polynomial scaling of the energy gap. Recently it was shown that a two-dimensional transverse-field Ising model on a square lattice with nearest-neighbor $\\pm J$ random coupling has a polynomial energy gap in the symmetric subspace of the parity operator [Nature 631, 749-754 (2024)], indicating the efficient preparation of its ground states by quantum annealing. However, it is not clear if this result can be generalized to other spin glass models with continuous or biased randomness. Here we prove that under general independent and identical distributions (i.i.d.) of the exchange energies, the energy gap of a one-dimensional random transverse-field Ising model follows a stretched exponential scaling even in the parity-restricted subspace. We discuss the implication of this result to quantum annealing problems.",
    "authors": [
      "G.-X. Tang",
      "J.-Z. Zhuang",
      "L.-M. Duan",
      "Y.-K. Wu"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03588",
    "title": "Numerical simulation of coherent spin-shuttling in a QuBus with charged defects",
    "abstract": "Recent advances in coherent conveyor-mode spin qubit shuttling are paving the way for large-scale quantum computing platforms with qubit connectivity achieved by spin qubit shuttles. We developed a simulation tool to investigate numerically the impact of device imperfections on the spin-coherence of conveyor-mode shuttling in Si/SiGe. We simulate the quantum evolution of a mobile electron spin-qubit under the influence of sparse and singly charged point defects placed in the Si/SiGe heterostructure in close proximity to the shuttle lane. We consider different locations of a single charge defect with respect to the center of the shuttle lane, multiple orbital states of the electron in the shuttle with $g$-factor differences between the orbital levels, and orbital relaxation induced by electron-phonon interaction. With this simulation framework, we identify the critical defect density of charged point defects in the heterostructure for conveyor-mode spin qubit shuttle devices and quantify the impact of a single defect on the coherence of a qubit.",
    "authors": [
      "Nils Ciroth",
      "Arnau Sala",
      "Ran Xue",
      "Lasse Ermoneit",
      "Thomas Koprucki",
      "Markus Kantner",
      "Lars R. Schreiber"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03647",
    "title": "Optimizing two-qubit gates for ultracold fermions in optical lattices",
    "abstract": "Ultracold neutral atoms in optical lattices are a promising platform for simulating the behavior of complex materials and implementing quantum gates. We optimize collision gates for fermionic Lithium atoms confined in a double-well potential, controlling the laser amplitude and keeping its relative phase constant. We obtain high-fidelity gates based on a one-dimensional confinement simulation. Our approach extends beyond earlier Fermi-Hubbard simulations by capturing a momentum dependence in the interaction energy. This leads to a higher interaction strength when atoms begin in separate subwells compared to the same subwell. This momentum dependence might limit the gate fidelity under realistic experimental conditions, but also enables tailored applications in quantum chemistry and quantum simulation by optimizing gates for each of these cases separately.",
    "authors": [
      "Jan A. P. Reuter",
      "Juhi Singh",
      "Tommaso Calarco",
      "Felix Motzoi",
      "Robert Zeier"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03689",
    "title": "More is uncorrelated: Tuning the local correlations of SU($N$) Fermi-Hubbard systems via controlled symmetry breaking",
    "abstract": "Cold-atom experiments based on alkali-like atoms provide us with a tool to experimentally realize Hubbard models with a large number $N$ of components. The value of $N$ can be seen as a new handle to tune the properties of the system, leading to new physics both in the case of fully SU($N$) symmetric systems, or in the presence of controlled symmetry breaking. We focus on the Mott transition at global half filling and we characterize local correlations between particles complementing conventional estimates with the inter-flavor mutual information. We prove that these correlations have classical nature and, using Dynamical Mean-Field Theory, we show that the SU(4) system has significantly smaller correlations than the SU(2) counterpart. In the atomic limit we prove that increasing $N$ further decreases the strength of the correlations. This suggests that a controlled reduction of the symmetry, reducing the number of effective components, can be used to enhance the degree of correlation. We confirm this scenario solving the model for $N=4$ and gradually breaking the symmetry via a Raman field, revealing an evolution from the SU(4) to the SU(2) Mott transition as the symmetry-breaking term increases, with a sudden recovery of the large correlations of the SU(2) model at weak Raman coupling in the Mott state. By further exploring the interplay between energy repulsion and the Raman field, we obtain a rich phase diagram with three different phases -- a metal, a band insulator, and a Mott insulator -- all coexisting at a single tricritical point.",
    "authors": [
      "Edoardo Zavatti",
      "Gabriele Bellomia",
      "Samuele Giuli",
      "Matteo Ferraretto",
      "Massimo Capone"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03770",
    "title": "Quantum Simulations of Opinion Dynamics",
    "abstract": "Quantum computing offers powerful new approaches for modeling complex social phenomena. Here, we propose and demonstrate quantum simulations of opinion dynamics, leveraging quantum superposition, measurement-induced state collapse, and entanglement to model realistic psychological and social processes. Specifically, we develop quantum models of opinion dynamics, solving exactly and simulating on IBM Quantum hardware. Our results, based on quantum devices and validated with practical quantum circuits, illustrate how quantum effects can enhance understanding of consensus formation, polarization, and collective decision-making. These findings pave the way for further exploration into quantum-enhanced social modeling, highlighting the potential of near-term quantum computers for simulating collective behavior in complex systems.",
    "authors": [
      "Xingyu Guo",
      "Xiaoyang Wang",
      "Lingxiao Wang"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03863",
    "title": "Laser-induced modulation of conductance in graphene with magnetic barriers",
    "abstract": "We study how electrons move across a graphene sheet when it encounters two magnetic barriers with a region in between that is continuously driven by laser light. Rather than acting as a static obstacle, this illuminated middle section becomes a Floquet cavity that opens new transport channels through controlled photon absorption and emission. By combining Floquet theory with the transfer matrix method, we track electron transmission through both the main energy band and the emerging photon-assisted sidebands. We find that the laser does more than modify the potential--it reshapes how electrons interact between the magnetic barriers, enabling a switch from ordinary transmission to transport dominated by photon exchange. Because the magnetic field and the optical drive are applied to separate sections of the device, the system supports interference between cyclotron-filtered motion and discrete photon-pumping channels, producing Fano resonances and angle-dependent transmission zeros that cannot appear in double magnetic or double laser barrier systems alone. Under well-defined conditions, the distance between the magnetic barriers controls the coupling between Floquet channels, allowing highly tunable resonances and even perfect transmission, despite strong magnetic confinement. We also observe that low-energy carriers are efficiently blocked by the magnetic regions, while conductance steadily rises with energy until it reaches a clear saturation plateau. This hybrid design provides a versatile way to steer graphene electrons by balancing optical pumping and magnetic momentum filtering.",
    "authors": [
      "Rachid El Aitouni",
      "Miloud Mekkaoui",
      "Pablo Díaz",
      "David Laroze",
      "Ahmed Jellal"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03970",
    "title": "Non-radiative energy transfer between boron vacancies in hexagonal boron nitride and other 2D materials",
    "abstract": "Boron vacancies ($V_B^-$) in hexagonal boron nitride (hBN) have emerged as a promising platform for two-dimensional quantum sensors capable of operating at atomic-scale proximity. However, the mechanisms responsible for photoluminescence quenching in thin hBN sensing layers when placed in contact with absorptive materials remain largely unexplored. In this Letter, we investigate non-radiative Förster resonance energy transfer (FRET) between $V_B^-$ centers and either monolayer graphene or 2D semiconductors. Strikingly, we find that the FRET rate is negligible for hBN sensing layers thicker than 3 nm, highlighting the potential of $V_B^-$ centers for integration into ultra-thin quantum sensors within van der Waals heterostructures. Furthermore, we experimentally extract the intrinsic radiative decay rate of $V_B^-$ defects.",
    "authors": [
      "Fraunié Jules",
      "Mikhail M. Glazov",
      "Sébastien Roux",
      "Abraao Cefas Torres-Dias",
      "Cora Crunteanu-Stanescu",
      "Tom Fournier",
      "Maryam S. Dehaghani",
      "Tristan Clua-Provost",
      "Delphine Lagarde",
      "Laurent Lombez",
      "Xavier Marie",
      "Benjamin Lassagne",
      "Thomas Poirier",
      "James H. Edgar",
      "Vincent Jacques",
      "Cedric Robert"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03980",
    "title": "Quantum Diplomacy within the Southeast Asia Quantum Ecosystem",
    "abstract": "Amid the International Year of Quantum Science and Technology 2025 (IYQ 2025), a significant portion of global funding has been dedicated to various quantum initiatives, with over 30 countries announcing their respective quantum strategies. Within the Southeast Asia context, Singapore, Thailand, and the Philippines have launched their respective quantum strategies and roadmaps. Meanwhile, six out of eleven Southeast Asia countries have expressed interest in formulating a regional quantum ecosystem to pursue a set of common goals. Quantum technologies, though still in their infancy within the second quantum revolution, have advanced rapidly in recent years. Due to their dual-use nature, quantum technologies are considered emerging and disruptive, often raising concerns from the cybersecurity perspective. While several discussions regarding Malaysia's quantum initiative and strategy are ongoing, it is vital to broaden the conversation and position Malaysia within the regional ecosystem. This paper provides an overview of Malaysia's quantum landscape and a summary of the regional initiatives since the establishment of Southeast Asia Quantum Network. We then analyse Malaysia's strengths in quantum research and provide four recommendations to strengthen the regional ecosystem.",
    "authors": [
      "Pak Shen Choong",
      "Nurisya Mohd Shah",
      "Yung Szen Yap"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04066",
    "title": "Instantaneous Sobolev Regularization for Dissipative Bosonic Dynamics",
    "abstract": "We investigate quantum Markov semigroups on bosonic Fock space and identify a broad class of infinite-dimensional dissipative evolutions that exhibit instantaneous Sobolev-regularization. Motivated by stability problems in quantum computation, we show that for certain Lindblad operators that are polynomials of creation and annihilation operators, the resulting dynamics immediately transform any initial state into one with finite expectation in all powers of the number operator. A key application is in the bosonic cat code, where we obtain explicit estimates in the trace norm for the speed of convergence. These estimates sharpen existing perturbative bounds at both short and long times, offering new analytic tools for assessing stability and error suppression in bosonic quantum information processing. For example, we improve the strong exponential convergence of the (shifted) $2$-photon dissipation to its fixed point to the uniform topology.",
    "authors": [
      "Pablo Costa Rico",
      "Paul Gondolf",
      "Tim Möbus"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2205.15893",
    "title": "Contrary Inferences for Classical Histories within the Consistent Histories Formulation of Quantum Theory",
    "abstract": "In the histories formulation of quantum theory, sets of coarse-grained histories that are consistent obey the classical probability rules. It has been argued that these sets can describe the quasi-classical behaviour of closed quantum systems, e.g. Omnes (Rev. Mod. Phys. 64(2), 339, 1992) and Hartle (Les Houches1992). Most physical scenarios admit multiple different consistent sets and one can view each of these as a separate context. Using propositions from different consistent sets to make inferences leads to paradoxes such as contrary inferences, first noted by Kent (Phys. Rev. Lett. 78(15), 2874, 1997). In this contribution, we use the consistent histories to describe a quasi-classical and macroscopic system to show that paradoxes involving contextuality persist even in the quasi-classical limit. This is distinctively different from the contextuality of standard quantum theory, where the contextuality paradoxes do not persist in the quasi-classical limit. Specifically, we consider different consistent sets for the arrival time problem of a (quasi-classical) ball in an infinite square well. For this setting, we construct two different consistent sets. We find the probabilities that each consistent set assigns to the simple question of whether the ball ever crossed the middle of the interval. We show that one consistent set concludes with certainty that the ball crossed it while the other consistent set concludes with certainty that it did not. Our results point to the need for constraints on the histories sets, additional to the consistency condition, to recover the correct quasi-classical limit in this formalism and lead to the motto \"all consistent sets are equal\", but \"some consistent sets are more equal than others\".",
    "authors": [
      "Adamantia Zampeli",
      "Georgios E. Pavlou",
      "Petros Wallden"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2309.03042",
    "title": "Reduced dynamics in quasi-Hermitian systems",
    "abstract": "Evolutions under non-Hermitian Hamiltonians with unbroken $\\mathcal{PT}$ symmetry can be considered unitary under appropriate choices of inner products, facilitated by the so-called metric operator. While it is understood that the choice of the metric operator has no bearing on the description of the system, in this work, we show that this choice does dictate the entanglement structure of the system. We show that the partial trace of the Hermitized density matrix gives the correct representation of the reduced subsystem, and based on such operations, we elucidate the metric dependency of the reduced dynamics and consequently the observable dependence of the subsystem decomposition. We use a non-Hermitian $\\mathcal{PT}$-symmetric quantum walk as a toy model to study this metric dependency, where we use the internal (coin state) as the subsystem of interest and study the coin-position entanglement and non-Markovianity of the coin dynamics.",
    "authors": [
      "Himanshu Badhani",
      "C. M. Chandrashekar"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2312.13246",
    "title": "A refinement of the argument of local realism versus quantum mechanics by algorithmic randomness",
    "abstract": "The notion of probability plays a crucial role in quantum mechanics. It appears in quantum mechanics as the Born rule. In modern mathematics which describes quantum mechanics, however, probability theory means nothing other than measure theory, and therefore any operational characterization of the notion of probability is still missing in quantum mechanics. In our former works [K. Tadaki, arXiv:1804.10174 ], based on the toolkit of algorithmic randomness, we presented a refinement of the Born rule, called the principle of typicality, for specifying the property of results of measurements in an operational way. In this paper, we make an application of our framework to the argument of local realism versus quantum mechanics for refining it, in order to demonstrate how properly our framework works in practical problems in quantum mechanics.",
    "authors": [
      "Kohtaro Tadaki"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.17349",
    "title": "Phase error rate estimation in QKD with imperfect detectors",
    "abstract": "We present a finite-size security proof of the decoy-state BB84 QKD protocol against coherent attacks, using entropic uncertainty relations, for imperfect detectors. We apply this result to the case of detectors with imperfectly characterized basis-efficiency mismatch. Our proof works by obtaining a suitable bound on the phase error rate, without requiring any new modifications to the protocol steps or hardware. It is applicable to imperfectly characterized detectors, and only requires the maximum relative difference in detection efficiencies and dark count rates of the detectors to be characterized. Moreover, our proof allows Eve to choose detector efficiencies and dark count rates in their allowed ranges in each round, thereby addressing an important problem of detector side channels. We prove security in the variable-length framework, where users are allowed to adaptively determine the length of key to be produced, and number of bits to be used for error-correction, based on observations made during the protocol. We quantitatively demonstrate the effect of basis-efficiency mismatch by applying our results to the decoy-state BB84 protocol.",
    "authors": [
      "Devashish Tupkary",
      "Shlok Nahar",
      "Pulkit Sinha",
      "Norbert Lütkenhaus"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.08100",
    "title": "Emergent Liouvillian exceptional points from exact principles",
    "abstract": "Recent years have seen a surge of interest in exceptional points in open quantum systems. The natural approach in this area has been the use of Markovian master equations. While the resulting Liouvillian EPs have been seen in a variety of systems and have been associated to numerous exotic effects, it is an open question whether such degeneracies and their peculiarities can persist beyond the validity of master equations. In this work, taking the example of a dissipative double-quantum-dot system, we show that exact Heisenberg equations governing system and bath dynamics exhibit the same EPs as the corresponding master equations. To highlight the importance of this finding, we prove that the paradigmatic property associated to EPs - critical damping, persists well beyond the validity of master equations. Our results demonstrate that Liouvillian EPs can arise from underlying fundamental exact principles, rather than merely as a consequence of approximations involved in deriving master equations.",
    "authors": [
      "Shishir Khandelwal",
      "Gianmichele Blasi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.11300",
    "title": "Electrons herald non-classical light",
    "abstract": "Free electrons are a widespread and universal source of electromagnetic fields. The past decades witnessed ever-growing control over many aspects of electron-generated radiation, from the incoherent emission produced by X-ray tubes to the exceptional brilliance of free-electron lasers. Reduced to the elementary process of quantized energy exchange between individual electrons and the electromagnetic field, electron beams may facilitate future sources of tunable quantum light. However, the quantum features of such radiation are tied to the correlation of the particles, calling for the joint electronic and photonic state to be explored for further applications. Here, we demonstrate the coherent parametric generation of non-classical states of light by free electrons. We show that the quantized electron energy loss heralds the number of photons generated in a dielectric waveguide. In Hanbury-Brown-Twiss measurements, an electron-heralded single-photon state is revealed via antibunching intensity correlations, while two-quantum energy losses of individual electrons yield pronounced two-photon coincidences. The approach facilitates the tailored preparation of higher-number Fock and other optical quantum states based on controlled interactions with free-electron beams.",
    "authors": [
      "Germaine Arend",
      "Guanhao Huang",
      "Armin Feist",
      "Yujia Yang",
      "Jan-Wilke Henke",
      "Zheru Qiu",
      "Hao Jeng",
      "Arslan Sajid Raja",
      "Rudolf Haindl",
      "Rui Ning Wang",
      "Tobias J. Kippenberg",
      "Claus Ropers"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.09465",
    "title": "Coherent Control of Photon Correlations in Trapped Ion Crystals",
    "abstract": "While the spontaneous emission from independent emitters provides spatially uncorrelated photons - a typical manifestation of quantum randomness, the interference of the coherent scattering leads to a well-defined intensity pattern - a feature described by linear optics. We here demonstrate experimentally how the interplay between the two mechanisms in large systems of quantum emitters leads to spatial variations of photon correlations. The implementation with trapped ion crystals in free space allows us to observe the anti-correlation between photon rates and variance of the photon number distributions in chains of up to 18 ions. For smaller crystals of four ions, the transition from a sub-Poissonian to a super-Poissonian variance of the photon number in the scattered light is reported. For higher numbers of scatterers, the photon statistics still display a strong deviation from the fully incoherent scattering case. Our results illustrate how the interference of coherent scattering, combined with spontaneous emission, provides a control mechanism for the light statistics.",
    "authors": [
      "K. Singh",
      "A. Cidrim",
      "A. Kovalenko",
      "T. Pham",
      "O. Číp",
      "L. Slodička",
      "R. Bachelard"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.19062",
    "title": "Oracle Separations for the Quantum-Classical Polynomial Hierarchy",
    "abstract": "We study the quantum-classical polynomial hierarchy, QCPH, which is the class of languages solvable by a constant number of alternating classical quantifiers followed by a quantum verifier. Our main result is that QCPH is infinite relative to a random oracle (previously, this was not even known relative to any oracle). We further prove that higher levels of PH are not contained in lower levels of QCPH relative to a random oracle; this is a strengthening of the somewhat recent result that PH is infinite relative to a random oracle (Rossman, Servedio, and Tan 2016). The oracle separation requires lower bounding a certain type of low-depth alternating circuit with some quantum gates. To establish this, we give a new switching lemma for quantum algorithms which may be of independent interest. Our lemma says that for any $d$, if we apply a random restriction to a function $f$ with quantum query complexity $\\mathrm{Q}(f)\\le n^{1/3}$, the restricted function becomes exponentially close (in terms of $d$) to a depth-$d$ decision tree. Our switching lemma works even in a \"worst-case\" sense, in that only the indices to be restricted are random; the values they are restricted to are chosen adversarially. Moreover, the switching lemma also works for polynomial degree in place of quantum query complexity.",
    "authors": [
      "Avantika Agarwal",
      "Shalev Ben-David"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.08356",
    "title": "Proposal for a Bell Test with Entangled Atoms of Different Mass",
    "abstract": "We propose a Bell test experiment using momentum-entangled atom pairs of different masses, specifically metastable helium isotopes 3He* and 4He*, though the method extends to other atom species. Entanglement is generated via collisions, after which the quantum states are manipulated using two independent atom interferometers, enabling precise phase control over each species. Numerical simulations predict a significant violation of Bell's inequality under realistic conditions. This proposal opens a new paradigm to study the intersection of quantum mechanics and gravity.",
    "authors": [
      "X. T. Yan",
      "S. Kannan",
      "Y. S. Athreya",
      "A. G. Truscott",
      "S. S. Hodgman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.09131",
    "title": "Artificial Intelligence for Quantum Computing",
    "abstract": "Artificial intelligence (AI) advancements over the past few years have had an unprecedented and revolutionary impact across everyday application areas. Its significance also extends to technical challenges within science and engineering, including the nascent field of quantum computing (QC). The counterintuitive nature and high-dimensional mathematics of QC make it a prime candidate for AI's data-driven learning capabilities, and in fact, many of QC's biggest scaling challenges may ultimately rest on developments in AI. However, bringing leading techniques from AI to QC requires drawing on disparate expertise from arguably two of the most advanced and esoteric areas of computer science. Here we aim to encourage this cross-pollination by reviewing how state-of-the-art AI techniques are already advancing challenges across the hardware and software stack needed to develop useful QC - from device design to applications. We then close by examining its future opportunities and obstacles in this space.",
    "authors": [
      "Yuri Alexeev",
      "Marwa H. Farag",
      "Taylor L. Patti",
      "Mark E. Wolf",
      "Natalia Ares",
      "Alán Aspuru-Guzik",
      "Simon C. Benjamin",
      "Zhenyu Cai",
      "Shuxiang Cao",
      "Christopher Chamberland",
      "Zohim Chandani",
      "Federico Fedele",
      "Ikko Hamamura",
      "Nicholas Harrigan",
      "Jin-Sung Kim",
      "Elica Kyoseva",
      "Justin G. Lietz",
      "Tom Lubowe",
      "Alexander McCaskey",
      "Roger G. Melko",
      "Kouhei Nakaji",
      "Alberto Peruzzo",
      "Pooja Rao",
      "Bruno Schmitt",
      "Sam Stanwyck",
      "Norm M. Tubman",
      "Hanrui Wang",
      "Timothy Costa"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.05411",
    "title": "Spectrally-pure optical serrodyne modulation for continuously-tunable laser offset locking",
    "abstract": "The comb-like spectrum added to laser light by an electro-optic modulator (EOM) finds use in a wide range of applications, including coherent optical communication, atomic spectroscopy, and laser frequency and phase stabilization. In some cases a sideband-free optical frequency shift is preferred, such as in laser offset locking using an optical cavity, single-photon frequency shifting, and laser range finding. Approaches to obtaining an optical frequency offset (OFO) involve trade-offs between shift range, conversion gain, and suppression of spurious sidebands. Here we demonstrate an OFO of continuous-wave 871 nm laser light by serrodyne modulation using a fiber EOM and radio-frequency (RF) tones from a commercial RF system on a chip (RFSoC) to achieve shifts of 40 to 800 MHz with > 15 dB suppression of spurious sidebands and < 1.5 dB conversion loss. We also observe a smoothly varying conversion gain. The utility of this tool is demonstrated by continuously shifting the offset of a cavity-locked laser from 50 to 1600 MHz, a capability useful in spectroscopy of unknown optical transitions.",
    "authors": [
      "Roame A. Hildebrand",
      "Wance Wang",
      "Connor Goham",
      "Alessandro Restelli",
      "Joseph W. Britton"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.11163",
    "title": "Optical nuclear electric resonance as single qubit gate for trapped neutral atoms",
    "abstract": "The precise control of nuclear spin states is crucial for a wide range of quantum technology applications. Here, we propose a fast and robust single-qubit gate in $^{87}$Sr, utilizing the concept of optical nuclear electric resonance (ONER). ONER exploits the interaction between the quadrupole moment of a nucleus and the electric field gradient generated by its electronic environment, enabling spin level transitions via amplitude-modulated laser light. We investigate the hyperfine structure of the 5s$^2$~$^1S_{0}\\rightarrow{}$~5s5p~$^3P_1$ optical transition in neutral $^{87}$Sr, and identify the magnetic field strengths and laser parameters necessary to drive spin transitions between the $m_I$ = -9/2 and $m_I$ = -5/2 hyperfine levels in the ground state. Our simulations show that ONER could enable faster spin operations compared to the state-of-the-art oscillations in this 'atomic qubit'. Moreover, we show that spin-flip operations exceeding 99.9\\% fidelity can be performed even in the presence of typical noise sources. These results pave the way for significant advances in nuclear spin control, opening new possibilities for quantum memories and other quantum technologies.",
    "authors": [
      "Johannes K. Krondorfer",
      "Sebastian Pucher",
      "Matthias Diez",
      "Sebastian Blatt",
      "Andreas W. Hauser"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.00747",
    "title": "Entanglement and Optimal Timing in Discriminating Quantum Dynamical Processes",
    "abstract": "I investigate the problem of optimally discriminating between two open quantum dynamical processes in a single-shot scenario, with the goal of minimizing the error probability of identification. This task involves optimising both the input state -- potentially entangled with an ancillary system that remains isolated from the dynamics -- and the time at which the resulting time-dependent quantum channels, induced by the two distinct dynamical maps, becomes most distinguishable. To illustrate the complexity and richness of this problem, I focus on Pauli dynamical maps and their associated families of time-dependent Pauli channels. I identify a regime in which separable strategies require waiting indefinitely for the dynamics to reach the stationary state, whereas entangled input states enable optimal discrimination at a finite time, with a strict reduction in error probability. These results highlight the crucial interplay between entanglement and timing in enhancing the distinguishability of quantum dynamical processes.",
    "authors": [
      "Massimiliano F. Sacchi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.12089",
    "title": "On the Convergence of Markov Chain Distribution within Quantum Walk Circuit Subspace",
    "abstract": "Markov Chain Monte Carlo (MCMC) methods are algorithms for sampling probability distributions, commonly applied to the Boltzmann distribution in physical and chemical models such as protein folding and the Ising model. These methods enable exploration of such systems by sampling their most probable states. However, sampling multidimensional and multimodal distributions with MCMC requires substantial computational resources, leading to the development of techniques aimed at improving sampling efficiency. In this context, quantum computing, with its potential to accelerate classical methods, emerges as a promising solution to the sampling problem. In this work, we present the design of a new circuit based on the Discrete Quantum Walk (DQW) algorithm to perform MCMC sampling over a desired distributions. Simulation results show convergence behavior in the superposition of the quantum register that encodes the target distribution. This design is further refined to increase convergence speed and, consequently, the scalability of the algorithm.",
    "authors": [
      "Aingeru Ramos",
      "Jose A. Pascual",
      "Javier Navaridas",
      "Ivan Coluzza"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.02923",
    "title": "Stabilizer-Accelerated Quantum Many-Body Ground-State Estimation",
    "abstract": "We investigate how the stabilizer formalism, in particular highly-entangled stabilizer states, can be used to describe the emergence of many-body shape collectivity from individual constituents, in a symmetry-preserving and classically efficient way. The method that we adopt is based on determining an optimal separation of the Hamiltonian into a stabilizer component and a residual part inducing non-stabilizerness. The corresponding stabilizer ground state is efficiently prepared using techniques of graph states and stabilizer tableaux. We demonstrate this technique in context of the Lipkin-Meshkov-Glick model, a fully-connected spin system presenting a second order phase transition from spherical to deformed state. The resulting stabilizer ground state is found to capture to a large extent both bi-partite and collective multi-partite entanglement features of the exact solution in the region of large deformation. We also explore several methods for injecting non-stabilizerness into the system, including ADAPT-VQE, and imaginary-time evolution (ITE) techniques. Stabilizer ground states are found to accelerate ITE convergence due to a larger overlap with the exact ground state. While further investigations are required, the present work suggests that collective features may be associated with high but simple large-scale entanglement which can be captured by stabilizer states, while the interplay with single-particle motion may be responsible for inducing non-stabilizerness. This study motivates applications of the proposed approach to more realistic quantum many-body systems, whose stabilizer ground states can be used in combinations with powerful classical many-body techniques and/or quantum methods.",
    "authors": [
      "Caroline E. P. Robin"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.05559",
    "title": "A Circuit-QED Lattice System with Flexible Connectivity and Gapped Flat Bands for Photon-Mediated Spin Models",
    "abstract": "Quantum spin models are ubiquitous in solid-state physics, but classical simulation of them remains extremely challenging. Experimental testbed systems with a variety of spin-spin interactions and measurement channels are therefore needed. One promising potential route to such testbeds is provided by microwave-photon-mediated interactions between superconducting qubits, where native strong light-matter coupling enables significant interactions even for virtual-photon-mediated processes. In this approach, the spin-model connectivity is set by the photonic mode structure, rather than the spatial structure of the qubit. Lattices of coplanar-waveguide (CPW) resonators have been demonstrated to allow extremely flexible connectivities and can therefore host a huge variety of photon-mediated spin models. However, large-scale CPW lattices with non-trivial band structures have never before been successfully combined with superconducting qubits. Here we present the first such device featuring a quasi-1D CPW lattice with multiple transmon qubits. We demonstrate that superconducting-qubit readout and diagnostic techniques can be generalized to this highly multimode environment and observe the effective qubit-qubit interaction mediated by the bands of the resonator lattice. This device completes the toolkit needed to realize CPW lattices with qubits in one or two Euclidean dimensions, or negatively-curved hyperbolic space, and paves the way to driven-dissipative spin models with a large variety of connectivities.",
    "authors": [
      "Kellen O'Brien",
      "Maya Amouzegar",
      "Won Chan Lee",
      "Martin Ritter",
      "Alicia J. Kollár"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.19723",
    "title": "Catability as a metric for evaluating superposed coherent states",
    "abstract": "Superposed coherent states are central to quantum technologies, yet their reliable identification remains a challenge, especially in noisy or resource-constrained settings. We introduce a novel, directly measurable criterion for detecting cat-like features in quantum states, rooted in the concept of nonlinear squeezing. This approach bypasses the need for full state tomography and reveals structure where fidelity fails. The numerical results confirm its robustness under loss and its potential for experimental implementation. The method naturally generalizes to more exotic superpositions, including multiheaded cat states.",
    "authors": [
      "Šimon Bräuer",
      "Jan Provazník",
      "Vojtěch Kala",
      "Petr Marek"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.20000",
    "title": "Correcting noisy quantum gates with shortcuts to adiabaticity",
    "abstract": "Unitary quantum gates constitute the building blocks of Quantum Computing in the circuit paradigm. In this work, we engineer a locally driven two-qubit Hamiltonian whose instantaneous ground-state dynamics generates the controlled-NOT (CNOT) quantum gate. In practice, quantum gates have to be implemented in finite-time, hence non-adiabatic and external noise effects debilitate gate fidelities. Here, we show that counterdiabatic control can restore gate performance with near perfect fidelities even in open quantum systems subject to decoherence.",
    "authors": [
      "Moallison F. Cavalcante",
      "Bariş Çakmak",
      "Marcus V. S. Bonança",
      "Sebastian Deffner"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.11254",
    "title": "Acquisition of Delocalized Information via Classical and Quantum Carriers",
    "abstract": "We investigate the information-theoretic power of spatial superposition by analyzing tasks in which information is locally encoded at multiple distant sites and must be acquired by a single information carrier, such as a particle. Within an operational framework, we systematically compare the statistical correlations that can be generated in such tasks using classical particles, quantum particles in spatial superposition, and more general \"second-order interference\" resources. We bound classical strategies via convex polytopes and present a study of their symmetry, demonstrating that the vertices are inherently connected to K-juntas as defined in the classical theory of Boolean functions, while their facet inequalities are in one-to-one correspondence with oracle games. We then analyze the violation of the \"fingerprinting inequality\" achievable by the use of one quantum particle, and we study the dependence of this violation on the dimension d of the particle's internal degree of freedom. In particular, we show that the case of d = 2 can achieve a higher violation of the inequality than the previously investigated case of d = 1. We also provide analytic and numerical evidence that this violation cannot be further increased for larger d > 2. Finally, we find that both quantum and any other (generalized) second-order interference models exhibit the same asymptotic scaling in violating the fingerprinting inequality. Our results thereby further articulate quantum interference and spatial superposition as a resource for information processing.",
    "authors": [
      "Julian Maisriml",
      "Sebastian Horvat",
      "Borivoje Dakić"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.13689",
    "title": "Purely quantum memory in closed systems observed via imperfect measurements",
    "abstract": "The detection and quantification of non-Markovianity, a.k.a. memory, in quantum systems is a central problem in the theory of open quantum systems. There memory is as a result of the interaction between the system and its environment. Little is known, however, about memory effects induced by imperfect measurements on closed systems, where an entanglement with the environment is not possible. We investigate the emergence and characteristics of memory in closed systems observed via imperfect stroboscopic quantum measurements yielding coarse-grained outcomes. We consider ideal and two kinds of imperfect measurements: von Neumann measurements--the analogue of classical lumping--which destroy any coherence in the system, and genuinely quantum-lumping Lüders measurements preserving certain quantum correlations. Whereas the conditions for Markov dynamics under von Neumann lumping are the same as for classical dynamics, quantum-lumping requires stronger conditions, i.e. the absence of any detectable coherence. We introduce the concept of purely quantum memory having no classical counterpart. We illustrate our results with a quantum walk on a lattice and discuss their implications for dissipative dynamics and decoherence effects induced by more realistic measurements.",
    "authors": [
      "Jorge Tabanera-Bravo",
      "Aljaž Godec"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.23143",
    "title": "Single Qudit Control in $^{87}$Sr via Optical Nuclear Electric Resonance",
    "abstract": "Optical nuclear electric resonance (ONER) was recently proposed as a fast and robust single-qubit gate mechanism in $^{87}$Sr. Here, we demonstrate through numerical simulations that ONER can be extended to single-qudit control, addressing multiple one-level hyperfine transitions within the ten-dimensional nuclear-spin manifold. We identify suitable operating regimes and show that ONER enables high-fidelity spin manipulations, with simulated $\\pi$-gate fidelities exceeding 99.9\\%, while maintaining coherence under realistic parameter fluctuations. These results establish a proof-of-principle for optical qudit control in $^{87}$Sr and delineate practical parameter ranges for future experiments, highlighting ONER as a promising pathway toward high-dimensional quantum information processing.",
    "authors": [
      "Johannes K. Krondorfer",
      "Matthias Diez",
      "Andreas W. Hauser"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.24066",
    "title": "Quantum state transfer and periodicity in discrete-time quantum walks under non--Markovian dephasing noise",
    "abstract": "In quantum communication, quantum state transfer from one location to another in a quantum network plays a prominent role, where the impact of noise could be crucial. The idea of state transfer can be fruitfully associated with quantum walk on graphs. We investigate the consequences of non-Markovian quantum noises on periodicity and state transfer induced by a discrete-time quantum walk on graphs, governed by the Grover coin operator. Different bipartite graphs, such as the path graph, cycle graph, star graph, and complete bipartite graph, present periodicity and state transfer in a discrete-time quantum walk depending on the topology of the graph. We investigate the effect of quantum non-Markovian dephasing noises, particularly quantum non-Markovian Random Telegraph Noise (RTN) and modified non-Markovian Ornstein-Uhlenbeck Noise (OUN) on state transfer and periodicity. We demonstrate how the RTN and OUN noises allow state transfer and periodicity for a finite number of steps in a quantum walk. Our investigation brings out the feasibility of state transfer in a noisy environment.",
    "authors": [
      "Monika Rani",
      "Supriyo Dutta",
      "Subhashish Banerjee"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.06154",
    "title": "What's my phase again? Computing the vacuum-to-vacuum amplitude of quadratic bosonic evolution",
    "abstract": "Quadratic bosonic Hamiltonians and their associated unitary transformations form a fundamental class of operations in quantum optics, modelling key processes such as squeezing, displacement, and beam-splitting. Their Heisenberg-picture dynamics simplifies to linear (or possibly affine) transformations on quadrature operators, enabling efficient analysis and decomposition into optical gate sets using matrix operations. However, this formalism discards a phase, which, while often neglected, is essential for a complete unitary characterization. We present efficient methods to recover this phase directly from the vacuum-to-vacuum amplitude of the unitary, using calculations that scale polynomially with the number of modes and avoid Fock space manipulations. We reduce the general problem for time-dependent Hamiltonians to integration, and provide analytical results for key cases including time-independent Hamiltonians which are positive definite, passive, active, or single-mode. Finally, we show that our results can be easily used to obtain the phase associated with any Gaussian state, be it mixed or pure.",
    "authors": [
      "Nicolás Quesada"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.08069",
    "title": "A dynamic circuit for the honeycomb Floquet code",
    "abstract": "In the typical implementation of a quantum error-correcting code, each stabilizer is measured by entangling one or more ancilla qubits with the data qubits and measuring the ancilla qubits to deduce the value of the stabilizer. Recently, the dynamic circuit approach has been introduced, in which stabilizers are measured without ancilla qubits. Here, we demonstrate that dynamic circuits are particularly useful for the Floquet code. Our dynamic circuit increases the timelike distance of the code, automatically removes leakage, and both significantly increases the threshold and lowers the logical error rate compared to the standard ancilla-based circuit. At a physical error rate of $10^{-3}$, we estimate a nearly $3\\times$ reduction in the number of qubits required to reach a $10^{-12}$ logical error rate.",
    "authors": [
      "Jahan Claes"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.03917",
    "title": "Quantum chemistry for solids made simple on the Clifford torus",
    "abstract": "We present a general theory to treat periodic solids with quantum-chemistry methods. It relies on two main developments: 1) the modeling of a solid as a Clifford torus which is a torus that is both periodic and flat and 2) the introduction of a periodic gaussian basis set that is compatible with the topology of the Clifford torus. We illustrate our approach by calculating the ground-state energy of a periodic chain of hydrogen atoms within both Hartree-Fock and coupled cluster theory. We demonstrate that our approach yields the correct ground-state energy in the thermodynamic limit by comparing it to the ground-state energy of a ring of hydrogen atoms in the same limit. Since equivalent ring-like calculations for three-dimensional solids are impossible, our approach is an excellent alternative to perform quantum-chemistry calculations of solids. Our Clifford formalism can be seamlessly combined with current implementations of quantum-chemistry methods designed for atoms and molecules to make them applicable to solids.",
    "authors": [
      "Amer Alrakik",
      "Gian Luigi Bendazzoli",
      "Stefano Evangelisti",
      "J. Arjan Berger"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.12295",
    "title": "Resonant dynamics of spin cluster in a periodically driven one-dimensional Rydberg lattice",
    "abstract": "Rydberg lattice under facilitation conditions can feature kinetic constraints, leading to ballistic and nonergodic behavior at different detuning intensities. Here, we demonstrate that a resonant driving field can achieve effects similar to those under facilitation conditions. We focus on the relaxation dynamics of spin clusters in a periodically driven Rydberg spin lattice. Through an effective Hamiltonian for the domain walls of the spin cluster, it is shown that when the driving frequency is resonant with the Rydberg interaction, the spin cluster exhibits ballistic expansion with half the spreading rate compared to the case of facilitation conditions. However, near the resonant point, the spin cluster displays confinement behavior of the Bloch-like oscillations. These results demonstrate the rich dynamic behaviors in the driven Rydberg spin lattices and may find applications in quantum state manipulation.",
    "authors": [
      "Jin-Qiu Xiong",
      "Yu-Hong Yan",
      "Xun-Da Jiang",
      "Yong-Yao Li",
      "Kun-Liang Zhang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00856",
    "title": "On dissipation operators of Quantum Optics",
    "abstract": "We consider dissipation operators used in Quantum Optics for the description of quantum spontaneous emission in the context of damped driven Jaynes-Cummings equations. The equations describe quantised one-mode Maxwell field coupled to a two-level molecule. Our main result is the symmetry and nonpositivity of basic dissipation operator of Quantum Optics.",
    "authors": [
      "A.I. Komech",
      "E.A. Kopylova"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00913",
    "title": "Do quantum linear solvers offer advantage for networks-based system of linear equations?",
    "abstract": "In this exploratory numerical study, we assess the suitability of Quantum Linear Solvers (QLSs) toward providing a quantum advantage for Networks-based Linear System Problems (NLSPs). NLSPs naturally arise from graphs, and are of importance as they are connected to real-world applications. The achievable advantage with a QLS for an NLSP depends on the interplay between the scaling of condition number and sparsity of matrices associated with the graph family considered, as well as system size growth. We analyze 50 graph families and identify that within the scope of our study, only 4% of them exhibit prospects for an exponential advantage with the Harrow-Hassidim-Lloyd (HHL) algorithm relative to an efficient classical solver (best graphs), while about 20% of them show a polynomial advantage (better graphs). Furthermore, we report that some graph families graduate from offering no advantage with HHL to promising a polynomial advantage with improved algorithms such as the Childs-Kothari-Somma algorithm, while some other graph families exhibit futile exponential advantage. We introduce a unified graph superfamily and show the existence of infinite best and better graphs in it. We also conjecture the conditions under which one may visually examine a graph family and guess the prospects for an advantage. Finally, we very briefly touch upon some practical issues that may arise even if the aforementioned graph theoretic requirements are satisfied, including quantum hardware challenges.",
    "authors": [
      "Disha Shetty",
      "Supriyo Dutta",
      "Palak Chawla",
      "Akshaya Jayashankar",
      "Jordi Riu",
      "Jan Nogue",
      "K. Sugisaki",
      "V. S. Prasannaa"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12341",
    "title": "Exact Coset Sampling for Quantum Lattice Algorithms",
    "abstract": "In this work, we give a new completion of Chen's windowed-QFT lattice algorithm~\\citep{chen2024quantum}. This extra step, called Step~$9^\\dagger$, replaces the domain extension stage in Steps~8--9. The published Step~9 calls an amplitude periodicity lemma, yet its hypotheses break in the presence of affine offsets $\\boldsymbol{v}^*$. Our analysis finds a basic conflict between two design constraints. The lattice problem asks for high spectral resolution, so the method prefers wide time windows. The quadratic phase error of the state prefers narrow time windows. Assumption~A5 packages the spectral concentration and near-uniformity properties that we require from the front end. Under~A5, a direct $\\mathbb{Z}_M^n$ Fourier transform of the chirp-corrected coordinate state produces samples $\\boldsymbol{u}$ that satisfy $\\langle \\boldsymbol{b}, \\boldsymbol{u} \\rangle \\equiv 0 \\pmod{Q}$ with probability $1-\\mathrm{negl}(n)$ and are nearly uniform on the dual hyperplane $\\{\\boldsymbol{u} : \\langle \\boldsymbol{b}, \\boldsymbol{u} \\rangle \\equiv 0 \\pmod{Q}\\}$. The new procedure does not require internal access to control wires. It uses the normalization $b_1=-1$ to apply a center-referenced phase correction directly on the first coordinate register. The scaling parameter $D$ ensures that this physical operation can be implemented by arithmetic on $X_1$ alone and does not read the hidden loop index. For Chen's complex-Gaussian Karst-wave window, we isolate a parameter regime, formalized in Assumption~A5, in which a polynomial retuning of the parameters gives a one-dimensional envelope for the loop index with width $\\sigma_J \\asymp Q\\log n$.",
    "authors": [
      "Yifan Zhang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.21195",
    "title": "Radiation of \"breathing\" vortex electron packets in magnetic field",
    "abstract": "When a vortex electron with an orbital angular momentum (OAM) enters a magnetic field, its quantum state is described with a nonstationary Laguerre-Gaussian (NSLG) state rather than with a stationary Landau state. A key feature of these NSLG states is oscillations of the electron wave packet's root-mean-square (r.m.s.) radius, similar to betatron oscillations. Classically, such an oscillating charge distribution is expected to emit photons. This raises a critical question: does this radiation carry away OAM, leading to a loss of the electron's vorticity? To investigate this, we solve Maxwell's equations using the charge and current densities derived from an electron in the NSLG state. We calculate the total radiated power and the angular momentum of the emitted field, quantifying the rate at which a vortex electron loses its energy and OAM while propagating in a longitudinal magnetic field. We find both the radiated power and the angular momentum losses to be negligible indicating that linear accelerators (linacs) appear to be a prominent tool for maintaining vorticity of relativistic vortex electrons and other charged particles, at least in the quasi-classical approximation.",
    "authors": [
      "G. V. Zmaga",
      "G. K. Sizykh",
      "D. V. Grosman",
      "Qi Meng",
      "Liping Zou",
      "Pengming Zhang",
      "D. V. Karlovets"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25389",
    "title": "Barnett Effect-Induced Nonreciprocal Entanglement and Gaussian interferometric power in Magnomechanics with Optical Parametric Amplifier",
    "abstract": "Nonreciprocity is a powerful tool in quantum technologies. It allows signals to be sent in one direction but not the other. In this article, we propose a method for achieving non-reciprocal entanglement and Gaussian interferometric power (GIP) via the Barnett effect. The YIG is coupled to a microwave cavity that interacts with an optical parametric amplifier (OPA). Due to the Barnett effect, giant nonreciprocal entanglement can emerge. By fine-tuning the cavity detuning, the GIP can exhibits nonreciprocal behavior. All entanglements with ideal nonreciprocity can be achieved by tuning the photon frequency detuning, appropriately choosing the cavity-magnon coupling regime, the nonlinear gain, and the phase shift of the OPA. Interestingly, the amount of entanglement nonreciprocity and its resilience to thermal occupation are remarkably enhanced by increasing the gain of the OPA. This nonreciprocity can be significantly enhanced even at relatively high temperatures. Our research offers a pathway for the realization of nonreciprocal single-phonon devices, with potential applications in quantum information processing and quantum communication. This proposed scheme could pave the way for the development of novel nonreciprocal devices that remain robust under thermal fluctuations.",
    "authors": [
      "Noura Chabar",
      "M. Amghar",
      "Shakir Ullah",
      "Mohamed Amazioug"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04194",
    "title": "Quantum Chip Co-Design for Fidelity and Entanglement Preservation: Architecture, Modeling, and QGHNN Optimization",
    "abstract": "This study introduces a superconducting quantum chip architecture designed to simultaneously preserve entanglement and readout fidelity, addressing one of the key trade-offs in the development of scalable quantum hardware. In conventional quantum circuits, strong qubit qubit coupling enhances entanglement but often leads to undesired crosstalk, dephasing, and reduced measurement fidelity. To mitigate these effects, we propose a hybrid multiqubit configuration consisting of nine transmon qubits organized into interior and exterior groups, interconnected via a flux tunable qubit and a network of distributed resonators. The interior qubits along with tunable qubit form an entanglement core, while the exterior qubits operate in the dispersive regime under large detuning to enable readout. The degree of entanglement can be dynamically tuned by adjusting the coupling between the central tunable qubit and the interior qubits. The total Hamiltonian includes all significant coupling contributions, encompassing effective exchange interactions among interior and exterior qubits, as well as their mediated couplings through interface resonators. By numerically solving the complete Hamiltonian alongside the Lindblad master equation, the system dynamics are characterized, allowing evaluation of both spectroscopic features and separation fidelity. Simulation results demonstrate that the proposed design maintains strong entanglement by creating the avoided-crossing region while sustaining measurement fidelity around 0.995 under realistic noise conditions. These findings confirm that entanglement strength and readout fidelity can be co-optimized within a single, reconfigurable architecture, establishing a viable route toward high-performance and scalable superconducting quantum processors.",
    "authors": [
      "Ahmad Salmanogli",
      "Hesam Zandi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.05916",
    "title": "Tractable Infinite-Horizon Stochastic Model Predictive Control for Quantum Filtering via Eigenstate Reduction",
    "abstract": "Model predictive control has shown potential to enhance the robustness of quantum control systems. In this work, we propose a tractable Stochastic Model Predictive Control (SMPC) framework for finite-dimensional quantum systems under continuous-time measurement and quantum filtering. Using the almost-sure eigenstate reduction of quantum trajectories, we prove that the infinite-horizon stochastic objective collapses to a fidelity term that is computable in closed form from the one-step averaged state. Consequently, the online SMPC step requires only deterministic propagation of the filter and a terminal fidelity evaluation. An advantage of this method is that it eliminates per-horizon Monte Carlo scenario sampling and significantly reduces computational load while retaining the essential stochastic dynamics. We establish equivalence and mean-square stability guarantees, and validate the approach on multi-level and Ising-type systems, demonstrating favorable scalability compared to sampling-based SMPC.",
    "authors": [
      "Yunyan Lee",
      "Ian R. Petersen",
      "Daoyi Dong"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.16299",
    "title": "Emulation Capacity between Idempotent Channels",
    "abstract": "We study the optimal rates of emulation (also called interconversion) between quantum channels. When the source and the target channels are idempotent, we give a single-letter expression for the zero-error emulation capacity in terms of structural properties of the range of the two channels. This expression shows that channel emulation is not reversible for general idempotent channels. Furthermore, we establish a strong converse rate that matches with the zero-error emulation capacity when the source or the target channel is either an identity or a completely dephasing channel.",
    "authors": [
      "Idris Delsol",
      "Omar Fawzi",
      "Li Gao",
      "Mizanur Rahaman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20097",
    "title": "Superconducting Parametric Amplifiers: Resonator Design and Role in Qubit Readout",
    "abstract": "Superconducting parametric amplifiers (SPAs) are critical components for ultralow-noise qubit readout in quantum computing, addressing the critical challenge of amplifying weak quantum signals without introducing noise that degrades coherence and computational fidelity. Unlike classical amplifiers, SPAs can achieve or closely approach quantum-limited performance, specifically the Standard Quantum Limit (SQL) of half a photon of added noise for phase-preserving amplification. The core principle of SPAs relies on parametric amplification, where energy is transferred from a strong pump tone to a weak input signal through non-dissipative nonlinear mixing processes. This is enabled by intrinsic nonlinearities in superconducting materials, primarily kinetic inductance in thin films (e.g., NbTiN, Al) and, more significantly, the Josephson effect in Josephson junctions. These nonlinear elements facilitate frequency mixing (three-wave or four-wave mixing) and can operate in phase-preserving or phase-sensitive amplification modes, with the latter allowing for noise squeezing below the SQL. This chapter emphasizes the significant role of resonator design in determining critical SPA performance metrics such as gain, bandwidth, and noise characteristics. It details both lumped-element (LC) and distributed-element (coplanar waveguide, CPW) resonators, discussing their unique properties, suitability for different frequency ranges, and the importance of achieving high-quality factors (Q) for efficient energy storage and minimal loss. A practical design and simulation of a meandered quarterwavelength CPW resonator coupled to a feed line is presented, illustrating how precise control over geometric parameters optimizes resonant frequency, coupling strength, and quality factor for high-fidelity qubit state discrimination.",
    "authors": [
      "Babak Mohammadian"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22580",
    "title": "Superconducting Qubit Gates Robust to Parameter Fluctuations",
    "abstract": "State-of-the-art single-qubit gates on superconducting transmon qubits can achieve the fidelities required for error-corrected computations. However, parameter fluctuations due to qubit instabilities, environmental changes, and control inaccuracies make it difficult to maintain this performance. To mitigate the effects of these parameter variations, we numerically derive gates robust to amplitude and frequency errors using gradient ascent pulse engineering (GRAPE). We analyze how fluctuations in qubit frequency, drive amplitude, and coherence affect gate performance over time. The robust pulses suppress coherent errors from drive amplitude drifts over 15 times more than a Gaussian pulse with derivative removal by adiabatic gate (DRAG) corrections. Furthermore, the robust gates, originally designed to compensate for quasi-static errors, also demonstrate resilience to stochastic, time-dependent noise, which is reflected in the dephasing time. They suppress added errors during increases in dephasing by up to 1.7 times more than DRAG.",
    "authors": [
      "Emily Wright",
      "Leo Van Damme",
      "Niklas J. Glaser",
      "Amit Devra",
      "Federico A. Roy",
      "Julian Englhardt",
      "Niklas Bruckmoser",
      "Leon Koch",
      "Achim Marx",
      "Johannes Schirk",
      "Christian M. F. Schneider",
      "Lasse Södergren",
      "Ivan Tsitsilin",
      "Florian Wallner",
      "Steffen J. Glaser",
      "Max Werninghaus",
      "Stefan Filipp"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22679",
    "title": "Foundations of Quantum Granular Computing with Effect-Based Granules, Algebraic Properties and Reference Architectures",
    "abstract": "This paper develops the foundations of Quantum Granular Computing (QGC), extending classical granular computing including fuzzy, rough, and shadowed granules to the quantum regime. Quantum granules are modeled as effects on a finite dimensional Hilbert space, so granular memberships are given by Born probabilities. This operator theoretic viewpoint provides a common language for sharp (projective) and soft (nonprojective) granules and embeds granulation directly into the standard formalism of quantum information theory. We establish foundational results for effect based quantum granules, including normalization and monotonicity properties, the emergence of Boolean islands from commuting families, granular refinement under Luders updates, and the evolution of granules under quantum channels via the adjoint channel in the Heisenberg picture. We connect QGC with quantum detection and estimation theory by interpreting the effect operators realizing Helstrom minimum error measurement for binary state discrimination as Helstrom type decision granules, i.e., soft quantum counterparts of Bayes optimal decision regions. Building on these results, we introduce Quantum Granular Decision Systems (QGDS) with three reference architectures that specify how quantum granules can be defined, learned, and integrated with classical components while remaining compatible with near term quantum hardware. Case studies on qubit granulation, two qubit parity effects, and Helstrom style soft decisions illustrate how QGC reproduces fuzzy like graded memberships and smooth decision boundaries while exploiting noncommutativity, contextuality, and entanglement. The framework thus provides a unified and mathematically grounded basis for operator valued granules in quantum information processing, granular reasoning, and intelligent systems.",
    "authors": [
      "Oscar Montiel Ross"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01633",
    "title": "Robust hyperentanglement self testing",
    "abstract": "Hyperentanglement, which refers to entanglement encoded in two or more independent degrees of freedom (DOFs), is a valuable resource for the future high-capacity quantum network. Certifying hyperentanglement sources work as intended is critical for the hyperentanglement-based quantum information tasks. Self testing is the strongest certification method for quantum state and measurement under minimal assumptions, even without any knowledge of the devices' inner workings. However, the existing self testing protocols all focus on one-DOF entanglement, which cannot self test the multi-DOF entanglement. In the paper, we propose a hyperentanglement self testing framework. We take the self testing for the polarization-spatial-mode hyperentangled Bell states as an example. The self testing is based on the violation of two-dimension CHSH test in each DOF independently. The two-step swap isometry circuits are proposed for self testing the entanglement in spatial-mode and polarization DOFs, respectively. All the sixteen polarization-spatial-mode hyperentangled Bell states can be self tested. Our hyperentanglement self testing framework has three advantages. First, it is a general hyperentanglement self testing framework, and can be extended to self test multi-DOF hyperentanglement and multipartite hyperentanglement. Second, it can provide the robust hyperentanglement self testing and establish the relation between the lower bound of fidelity and the imperfect violation of Bell-like inequality in each DOF. Third, it is feasible with current experimental technology. Our hyperentanglement self testing framework provides a promising way to certify complex hyperentanglement sources, and has potential application in future high-capacity quantum network.",
    "authors": [
      "Yu-Hao Wang",
      "Xing-Fu Wang",
      "Ming-Ming Du",
      "Shi-Pu Gu",
      "Wei Zhong",
      "Lan Zhou",
      "Yu-Bo Sheng"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.11339",
    "title": "Inner structure of the many-body localization transition and the fulfillment of the Harris criterion",
    "abstract": "We treat the disordered Heisenberg model in 1D as the standard model of many-body localization (MBL). Two new and independent order parameters stemming solely from the half-chain von Neumann entanglement entropy $S_{\\textrm{vN}}$ are introduced to probe the eigenstate phase transition in this model. From the symmetry-endowed entropy decomposition, they are the probability distribution deviation $|d(p_n)|$ and the von Neumann entropy $S_{\\textrm{vN}}^{n}(D_n\\!=\\!\\mbox{max})$ of the maximally dimensional symmetry subdivision. The finite-size scaling reveals that $\\{p_n\\}$ drives the localization transition, preceded by a thermalization breakdown transition governed by $\\{S_{\\textrm{vN}}^{n}\\}$. For the noninteracting case, these transitions coincide, but in the interacting circumstance they separate. Such separability creates an intermediate phase regime and discriminates between the Anderson and MBL transitions. One obstacle whose solution eludes the community to date concerns the violation of the Harris criterion in most numerical investigations of MBL. Upon elucidating the mutually independent measures comprising $S_{\\textrm{vN}}$, it becomes clear that the previous studies may lack the resolution to pinpoint thus potentially overlook the crucial internal structure of the transition. We show that after this necessary decomposition, the universal critical exponents for both transitions of $|d(p_n)|$ and $S_{\\textrm{vN}}^{n}(D_n\\!=\\!\\mbox{max})$ fulfill the Harris criterion: $\\nu\\approx2\\ (\\nu\\approx1.5)$ for quench (quasirandom) disorder. Our work puts forth symmetry combined with entanglement as an organization principle for the generic eigenstate matter and phase transition.",
    "authors": [
      "Jie Chen",
      "Chun Chen",
      "Xiaoqun Wang"
    ],
    "primary_category": "cond-mat.dis-nn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.18222",
    "title": "Kubo-Martin-Schwinger states of Path-structured Flow in Directed Brain Synaptic Networks",
    "abstract": "The brain's synaptic network, characterized by parallel connections and feedback loops, drives interaction pathways between neurons through a large system with infinitely many degrees of freedom. This system is best modeled by the graph C*-algebra of the underlying directed graph, the Toeplitz-Cuntz-Krieger (TCK) algebra, which captures the diversity of path-structured flow connectivity. Equipped with the gauge action, the TCK algebra defines an {\\em algebraic quantum system}, and here we demonstrate that its thermodynamic properties provide a natural framework for describing the dynamic mappings of potential flow pathways within the network. Specifically, the KMS states of this system represent the stationary distributions of a non-Markovian stochastic process with memory decay, capturing how influence propagates along exponentially weighted paths, and yield global statistical measures of neuronal interactions. Applied to the {\\em C. elegans} synaptic network, our framework reveals that neurolocomotor neurons emerge as the primary hubs of incoming path-structured flow at inverse temperatures where the entropy of KMS states peaks. This finding aligns with experimental evidence of the foundational role of locomotion in {\\em C. elegans} behavior, suggesting that functional centrality may arise from the topological embedding of neurons rather than solely from local physiological properties. Our results highlight the potential of algebraic quantum methods and graph algebras to uncover patterns of functional organization in complex systems and neuroscience.",
    "authors": [
      "El-kaïoum M. Moutuou",
      "Habib Benali"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.19525",
    "title": "Spin-Depairing-Induced Exceptional Fermionic Superfluidity",
    "abstract": "We investigate the non-Hermitian (NH) attractive Hubbard model with spin depairing, which is a spin-resolved asymmetric hopping that nonreciprocally operates spins in the opposite direction. We find that spin depairing stabilizes a superfluid state unique to the NH system. This phase is characterized not only by a finite order parameter, but also by the emergence of exceptional points (EPs) in the momentum space - a feature that starkly contrasts with previously discussed NH fermionic superfluidity, where EPs are absent within the superfluid state and emerge only at the onset of the superfluid breakdown. We uncover the rich mechanism underlying this ``exceptional fermionic superfluidity'' by analyzing the interplay between EPs and the effective density of states of the complex energy dispersion. Furthermore, we reveal that the exceptional superfluid state breaks down induced by strong spin depairing on the cubic lattice, while it remains robust on the square lattice.",
    "authors": [
      "Soma Takemori",
      "Kazuki Yamamoto",
      "Akihisa Koga"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.07510",
    "title": "Towards a test of the Born rule in high-energy collisions",
    "abstract": "We consider how the Born rule, a fundamental principle of quantum mechanics, can be tested for particles created on the shortest timescales ($\\sim10^{-25}\\,\\mathrm{s}$) currently accessible at high-energy colliders. We focus on targeted tests of the Born rule for spin or polarisation probabilities, which offer a particularly clean experimental signal, and which can be described by a simple hidden-variables model of two-state systems proposed by Bell. These probabilities test a remarkable feature of the quantum formalism, whereby expectation values for incompatible experiments are linearly related. Born-rule violations can be parameterised by nonlinear expectation values for quantum measurements of spin or polarisation, along with anomalies in ensemble averages, which may then be constrained by experiment. Notable experiments considered here include the recent detection of single photons from top-quark decay, and the indirect measurement of tau-lepton polarisation. Repurposing these experiments as tests of the Born rule, however, presents several challenges, which are discussed in this paper.",
    "authors": [
      "Antony Valentini",
      "Mira Varma"
    ],
    "primary_category": "hep-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.09783",
    "title": "Photo-induced directional transport in extended SSH chains",
    "abstract": "We investigate the current-voltage characteristics of an extended Su-Schrieffer-Heeger (SSH) chain under irradiation by arbitrarily polarized light, demonstrating its potential as a light-controlled rectifier. Irradiation of light induces anisotropy in the system, enabling directional current flow and active control of rectification behavior. Our analysis demonstrates that, under optimized light parameters, the rectification efficiency can exceed 90\\%. Moreover, the direction of rectification-whether positive or negative-can be precisely controlled by varying the polarization of the light, highlighting the potential for external optical control of electronic behavior. The effect of light irradiation is incorporated using the Floquet-Bloch ansatz combined with the minimal coupling scheme, while charge transport is computed through the nonequilibrium Green's function formalism within the Landauer-Büttiker framework.",
    "authors": [
      "Usham Harish Kumar Singha",
      "Kallol Mondal",
      "Sudin Ganguly",
      "Santanu K. Maiti"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.16880",
    "title": "Thermal nature of the causal diamond horizon: A hidden property of the inertial propagator",
    "abstract": "Inspired by the novel idea proposed by T.~Padmanabhan in \\textit{Phys.\\ Rev.\\ D 100, 045024 (2019)}, we develop a method to uncover the hidden thermal properties of the inertial Feynman propagator in Minkowski spacetime in a causally consistent manner. This, in turn, enables a coherent interpretation based on future-directed propagation. In our approach, the Fourier transform is implemented following the convention used in the analysis of vacuum fluctuations. As a result, future-directed propagation across causal horizons can be consistently interpreted, from the perspective of an observer confined to a causally disconnected region, as the emission of scalar quanta at the past horizon and their absorption at the future horizon. Moreover, we find that the ratio between emission and absorption processes reproduces the characteristic Boltzmann factor of a thermal ensemble. We first apply this analysis to a causal diamond of length $2\\alpha$, performing a detailed study of the near-horizon geometry and thereby obtaining the temperature associated with the thermal behavior of the Minkowski vacuum as perceived by an observer with finite lifetime $2\\alpha$. For completeness, we also apply the method to the right Rindler wedge, recovering the well-known Unruh temperature, $T = a/(2\\pi)$. Our results demonstrate that thermality can emerge directly from causal structure, independently of acceleration or gravity, with causal diamonds encoding intrinsic thermodynamic behavior in quantum field theory.",
    "authors": [
      "Nada Eissa",
      "Carlos R. Ordóñez",
      "Gustavo Valdivia-Mera"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.14727",
    "title": "Distances between pure quantum states induced by a distance matrix",
    "abstract": "With the help of a given distance matrix of size $n$, we construct an infinite family of distances $d_p$ (where $p \\geq 2$) on the complex projective space $\\mathbb{P}(\\mathbb{C}^n)$ modelling the space of pure states of an $n$-level quantum system. The construction can be seen as providing a natural way to isometrically embed any given finite metric space into the space of pure quantum states 'spanned' upon it. In order to show that the maps $d_p$ are indeed distance functions -- in particular, that they satisfy the triangle inequality -- we employ methods of analysis, multilinear algebra and convex geometry, obtaining a nontrivial auxiliary convexity result in the process. The paper significantly extends earlier work, resolving an important question about the geometry of quantum state space imposed by the quantum Wasserstein distances and solidifying the foundation for applications of distances $d_p$ in quantum information science.",
    "authors": [
      "Tomasz Miller",
      "Rafał Bistroń"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25505",
    "title": "High fidelity CNOT gates in photonic integrated circuits using composite segmented directional couplers",
    "abstract": "Integrated photonic circuits are a promising platform for scalable quantum information processing, but their performance is often constrained by component sensitivity to fabrication imperfections. Directional couplers, which are crucial building blocks for integrated quantum logic gates, are particularly prone to such limitations, with strong dependence on geometric and spectral parameters which reduces gate fidelity. Here, we demonstrate that composite segmented directional couplers (CSDC) offer a fabrication-tolerant alternative that enhances gate fidelity without active tuning. We design and fabricate a fully integrated photonic controlled-NOT (CNOT) gate using both uniform and composite coupler variants and compare their performance via simulation, classical characterization, and quantum two-photon interference. The composite design reduces the average error probability by nearly a factor of two and decreases variability fivefold. The residual error is primarily limited by photon indistinguishability. Classical matrix reconstruction confirms improved agreement with the ideal CNOT operation. These results establish CSDCs as compact, passive, and foundry-compatible building blocks for robust scalable quantum photonic circuits.",
    "authors": [
      "Jonatan Piasetzky",
      "Amit Rotem",
      "Yuval Warshavsky",
      "Yehonatan Drori",
      "Khen Cohen",
      "Yaron Oz",
      "Haim Suchowski"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.13941",
    "title": "Diffeomorphism invariant tensor networks for 3d gravity",
    "abstract": "Tensor networks prepare states that share many features of states in quantum gravity. However, standard constructions are not diffeomorphism invariant and do not support an algebra of non-commuting area operators. Recently, analogues of both problems were addressed in a tensor network discretization of topological field theories (TFT) with finite or compact gauge groups. Here, we extend this work towards gravity by generalizing to gauge groups that are discrete or continuous, compact or non-compact. Applied to $\\text{SL}(2,\\mathbb{R}) \\times \\text{SL}(2,\\mathbb{R})$ Chern-Simons theory, our construction can be interpreted as building states of three dimensional gravity with a negative cosmological constant. Our tensor networks prepare states that satisfy the constraints of Chern-Simons theory. In metric variables, this implies that the states we construct satisfy the Wheeler-DeWitt equation and momentum constraints, and so are diffeomorphism invariant.",
    "authors": [
      "Vijay Balasubramanian",
      "Charlie Cummings"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.21963",
    "title": "Nonlinear magnetization dynamics as a route to nonreciprocal phases, spin superfluidity, and analogue gravity",
    "abstract": "The identification of platforms with independently tunable nonlinearity and non-Hermiticity promises a quantitative route to far-from-equilibrium universality across many-body systems. Here we show that a conventional ferromagnetic multilayer realizes this paradigm: balancing a dc drive against Gilbert damping stabilizes a chiral spin-superfluid limit cycle that spontaneously breaks spacetime-translation symmetry. The resulting superflow is intrinsically nonreciprocal: long-wavelength magnons of opposite chirality acquire asymmetric dispersions and propagate direction-selectively, realizing a spin-superfluid diode. This asymmetry is flow-borne - it reflects broken Galilean invariance and requires neither structural asymmetry nor finely tuned gain-loss balance. Linearized dynamics in the comoving superfluid frame are intrinsically pseudo-Hermitian and, in the long-wavelength sector, can be mapped to a (1+1)D wave equation on curved spacetime. Spatial modulation of the drive enables the generation of sonic horizons that parametrically squeeze magnons and produce Hawking-like particle-hole emission. Our results establish a tabletop route from nonlinear dissipative-driven magnetization dynamics to nonreciprocal transport, nonequilibrium phase transitions, and analogue-gravity kinematics.",
    "authors": [
      "Vincent Flynn",
      "Benedetta Flebus"
    ],
    "primary_category": "cond-mat.mes-hall",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01894",
    "title": "High-Sensitivity NV Ensemble Imaging via AOD-Based Raster Scanning and Photodetection",
    "abstract": "We present a technique based on an ensemble of nitrogen-vacancy (NV) centers in diamond capable of imaging magnetic fields with high spatio-temporal resolution. A focused laser beam is raster-scanned using an acousto-optic deflector (AOD) and NV center fluorescence is read out with a single photodetector, enabling low-noise detection with high dynamic range. The method operates in a previously unexplored regime, quasi-continuous wave optically detected magnetic resonance (qCW-ODMR). In this regime, NV centers experience short optical pump pulses for spin readout and repolarization, analogous to pulsed ODMR technique, while the microwave field remains continuously on resonance with the spin transitions. We systematically characterize this regime and show that the spin response is governed by a tunable interplay between coherent evolution and relaxation, determined by the temporal spacing between pump laser pulses. Notably, the technique does not require precise microwave pulse control, thus simplifying experimental implementation. To demonstrate its capabilities, we image time-varying magnetic fields from a microelectrode in a conductive medium with sub-millisecond temporal resolution. This approach enables flexible spatial sampling and with our diamond achieves nT$\\cdot$Hz$^{-1/2}$ per pixel sensitivity, making it well suited for detecting weak, dynamic magnetic fields in biological and other complex systems.",
    "authors": [
      "Luca Troise",
      "Nikolaj W. Hansen",
      "Marvin Holten",
      "Dhiren M. Kara",
      "Jean-Francois Perrier",
      "Ulrik L. Andersen",
      "Alexander Huck"
    ],
    "primary_category": "physics.app-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03084",
    "title": "A $q$-Exponential Operator Based on the Derivative of Order 1 and Summation of Bilateral Basic Hypergeometric Series",
    "abstract": "We use a new $q$-exponential operator based on the $q^{\\pm1}$-derivative $\\D_{q^{\\pm1}}$ of order 1 to derive summation formulas for bilateral basic hypergeometric series ${}_{0}\\psi_{1}$, ${}_{1}\\psi_{1}$, ${}_{1}\\psi_{2}$, and ${}_{2}\\psi_{2}$. In addition, we provide summation formulas for bilateral series whose terms are basic hypergeometric functions.",
    "authors": [
      "Ronald Orozco López"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03085",
    "title": "Explicit constants for Fejer-type smoothing on finite cyclic groups",
    "abstract": "We study a Fejer-type smoothing kernel on the finite cyclic group Z/NZ. For each smoothing radius we give explicit l1 and l2 norms, compute the discrete Fourier transform, and record bounds that are uniform in N. As an application we prove a smoothed discrepancy estimate with explicit constants that can be used in quantitative problems on finite cyclic groups. The arguments are elementary and the note is intended as a self contained reference.",
    "authors": [
      "Justin Grieshop"
    ],
    "primary_category": "math.GM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03096",
    "title": "CFO-Robust Detection for 5G PRACH under Fading Channels: Analytical Modeling and Performance Evaluation",
    "abstract": "The Physical Random Access Channel (PRACH) is essential for initial access and synchronization in both 5G and future 6G networks; however, its detection is highly sensitive to impairments such as high user density, large carrier frequency offset (CFO), and fast fading. Although prior studies have examined PRACH detection, they are often restricted to specific scenarios or lack a comprehensive analytical characterization of performance. We introduce a unified analytical framework that characterizes the statistical distribution of the received power delay profile (PDP) under flat Rayleigh fading and supports both coherent combining (CC) and power combining (PC) repetition strategies. For each strategy, we derive optimal threshold expressions and closed-form detection probabilities. Furthermore, we analyze two key cases depending on the coherence time: identical and independent channel realizations per repetition. Secondly, we exploit the correlation induced by CFO across cyclic shifts to design a novel low-complexity detector that exploits PDP dependencies. Numerical results indicate that PC outperforms CC when repetitions experience independent channels, while CC can be preferable under identical realizations in limited settings. On the other hand, the proposed CFO-aware detector delivers improved robustness under severe CFO conditions.",
    "authors": [
      "Daniel Alarcón-Martín",
      "Mari Carmen Aguayo-Torres",
      "Francisco J. Martín-Vega",
      "Gerardo Gómez"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03105",
    "title": "Demonstração Formal de um Algoritmo Alternativo da Multiplicação em Base 10",
    "abstract": "This article presents and formalizes an elementary multiplication method discovered independently by a 10-year-old student, Anthony Lima Dias. The method reorganizes digit interactions in base-10 multiplication into a structured sequence of partial sums, reducing cognitive load and allowing reliable mental or semi-written computation. We provide a full mathematical proof of correctness, a comparison with the classical algorithm, formal notation, and a detailed contextual account of the discovery. The method expands the known catalog of student-invented algorithms and raises questions about cognitive pathways in arithmetic learning. Keywords: multiplication methods, mathematics education, mental calculation, student-invented algorithms, alternative algorithms, arithmetic strategies. -- -- Este artigo apresenta e formaliza um metodo elementar de multiplicacao descoberto de forma independente por um estudante de 10 anos, Anthony Lima Dias. O metodo reorganiza as interacoes entre algarismos na multiplicacao em base 10 em uma sequencia estruturada de somas parciais, reduzindo a carga cognitiva e permitindo um calculo mental ou semi-escrito mais confiavel. Fornecemos uma demonstracao matematica completa de corretude, uma comparacao com o algoritmo tradicional, notacoes formais e um relato contextual detalhado da descoberta. O metodo amplia o catalogo conhecido de algoritmos inventados por estudantes e levanta questoes sobre caminhos cognitivos na aprendizagem aritmetica. Palavras-chave: metodos de multiplicacao, educacao matematica, calculo mental, algoritmos inventados por alunos, algoritmos alternativos, estrategias aritmeticas.",
    "authors": [
      "Albert Lucas Lima Dias",
      "Anthony Lima Dias",
      "Ib Couto",
      "Mabia Lima Chaves dos Santos",
      "Marcus Vinícius da Conceição Morro"
    ],
    "primary_category": "math.HO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03113",
    "title": "A Discrete Neural Operator with Adaptive Sampling for Surrogate Modeling of Parametric Transient Darcy Flows in Porous Media",
    "abstract": "This study proposes a new discrete neural operator for surrogate modeling of transient Darcy flow fields in heterogeneous porous media with random parameters. The new method integrates temporal encoding, operator learning and UNet to approximate the mapping between vector spaces of random parameter and spatiotemporal flow fields. The new discrete neural operator can achieve higher prediction accuracy than the SOTA attention-residual-UNet structure. Derived from the finite volume method, the transmissibility matrices rather than permeability is adopted as the inputs of surrogates to enhance the prediction accuracy further. To increase sampling efficiency, a generative latent space adaptive sampling method is developed employing the Gaussian mixture model for density estimation of generalization error. Validation is conducted on test cases of 2D/3D single- and two-phase Darcy flow field prediction. Results reveal consistent enhancement in prediction accuracy given limited training set.",
    "authors": [
      "Zhenglong Chen",
      "Zhao Zhang",
      "Xia Yan",
      "Jiayu Zhai",
      "Piyang Liu",
      "Kai Zhang"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03117",
    "title": "Strengthening Han's Fourier Entropy-Influence Inequality via an Information-Theoretic Proof",
    "abstract": "We strengthen Han's Fourier entropy-influence inequality $$ H[\\widehat{f}] \\leq C_{1}I(f) + C_{2}\\sum_{i\\in [n]}I_{i}(f)\\ln\\frac{1}{I_{i}(f)} $$ originally proved for $\\{-1,1\\}$-valued Boolean functions with $C_{1}=3+2\\ln 2$ and $C_{2}=1$. We show, by a short information-theoretic proof, that it in fact holds with sharp constants $C_{1}=C_{2}=1$ for all real-valued Boolean functions of unit $L^{2}$-norm, thereby establishing the inequality as an elementary structural property of Shannon entropy and influence.",
    "authors": [
      "Peijie Li",
      "Guangyue Han"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03141",
    "title": "Dynamical Non-Commutative Algebraic Geometry: Inflation, Bifurcation, and the Dynamics of Collapse across Division Algebras",
    "abstract": "We develop a framework for dynamical non-commutative algebraic geometry (DNCAG) by analyzing the evolution and stability of polynomial root manifolds in real normed division algebras ($\\mathbb{H}$ and $\\mathbb{O}$). We establish a Generalized Inflation Theorem, demonstrating that for central polynomials, the root set forms a homogeneous space $G/H$, where $G$ is the automorphism group of the algebra ($SO(3)$ for $\\mathbb{H}$, $G_2$ for $\\mathbb{O}$). This mechanism generates continuous geometry from non-commutativity. We analyze the dynamics under central modulation (breathing modes), classifying topological bifurcations ($\\Delta=0$). We then analyze the topological collapse induced by non-central perturbations, governed by symmetry reduction. We utilize the Localization Theorem (Gordon-Motzkin) to explain the alignment of roots with coefficient subalgebras. We formalize the dynamics of collapse using gradient flow on the potential landscape $\\mathcal{V}(x) = \\|P(x)\\|^2$, characterizing it as a deformation retract and proving that the collapse timescale exhibits critical slowing down with quadratic scaling ($T_{\\rm collapse} \\propto \\epsilon^{-2}$). Finally, we introduce a thermodynamic formalism, proving an Entropy Scaling Law that rigorously characterizes the collapse as a symmetry-breaking phase transition.",
    "authors": [
      "Pau Amaro Seoane"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03171",
    "title": "A Mathematical Introduction to Geometric Quantization",
    "abstract": "These notes are based on a series of lectures by Kadri İlker Berktav from May 2024 to November 2024, providing a detailed exposition of geometric quantization formalism and its essential components. They are organized into three parts: background in symplectic geometry, basics of geometric quantization formalism, and an application related to Edward Witten's work in knot theory and topology.",
    "authors": [
      "Kadri İlker Berktav",
      "Burak Oğuz",
      "Ömer Önder",
      "Yunus Emre Sargut",
      "Başar Deniz Sevinç",
      "Deniz Nazif Taştan"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03181",
    "title": "Three-dimensional third medium contact model for hyperelastic contact and pneumatically actuated systems",
    "abstract": "This work presents a comprehensive three-dimensional third-medium contact framework for modeling complex contact interactions in hyperelastic solids and pneumatically actuated systems. The proposed third-medium formulation embeds a fictitious medium (or third medium) between potentially interacting bodies, enabling a unified and robust treatment of hyperelastic contact and self-contact without the need for discretization of the contact interface. Unlike the widely studied two-dimensional problem, this paper extends the new regularization term given in Reference \\cite{TMCWriggers2} to three-dimensional problems and ensures element quality in a third medium. Due to the need for higher-order elements for the regularization term, this paper details the linearization process of this problem within the finite element framework. In addition, pneumatically actuated systems are considered by introducing a pneumatic term to represent pneumatic loading (pressure or suction) and inducing contact caused by internal inflation. This approach is suitable for complex hyperelastic contact and self-contact, and has potential applications in the fields of soft robotics and flexible mechanisms. The framework is developed in a fully three-dimensional setting, making it also suitable for isogeometric methods and meshless methods. Several benchmark and application-level simulations demonstrate the accuracy, robustness, and versatility of the proposed approach. The results highlight the capability of the three-dimensional third-medium model to handle challenging nonlinear contact scenarios relevant to soft materials, soft actuators, and emerging multifunctional structures.",
    "authors": [
      "Bing-Bing Xu",
      "Tianju Xue",
      "Peter Wriggers"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03185",
    "title": "Nonlinear diffusion limit of non-local interactions on a sphere",
    "abstract": "We study an aggregation PDE with competing attractive and repulsive forces on a sphere of arbitrary dimension. In particular, we consider the limit of strongly localized repulsion with a constant attraction term. We prove convergence of solutions of such a system to solutions of the aggregation-diffusion equation with a porous-medium-type diffusion term. The proof combines variational techniques with elements of harmonic analysis on a sphere. In particular, we characterize the square root of the convolution operator in terms of the spherical harmonics, which allows us to overcome difficulties arising due to the convolution on a sphere being non-commutative. The study is motivated by the toy model of transformers introduced by Geshkovski et al. (2025); and we discuss the applicability of the results to this model.",
    "authors": [
      "Mark A. Peletier",
      "Anna Shalova"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03188",
    "title": "On the sparsity of integers $a$ in solutions to $a!b!=c!$",
    "abstract": "We consider the Diophantine equation $$ a!b! = c! $$ due to Erdős, where we assume $a \\leq b$. It is widely believed that there are only finitely many nontrivial solutions, and considerable work has been dedicated to showing this. In one direction, Luca (2007) showed that the set of $c$'s which can appear in solutions has density zero. Here we show that the set of $a$'s appearing in solutions is also sparse. In particular, $a$ cannot be one less than a large fraction of primes, and, under the assumption that $\\sqrt[k]{a!} \\mod 1$ is equidistributed in an appropriate sense, we show that the set of such $a$ has asymptotic density zero.",
    "authors": [
      "Joshua Cooper",
      "Joseph Preuss"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03201",
    "title": "Computing the Hopf invariant",
    "abstract": "We consider Whitehead's integral formula and propose an algorithm for computing the Hopf invariant for simplicial mappings.",
    "authors": [
      "Oleg R. Musin",
      "Timur Shamazov"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03205",
    "title": "A discontinuous Galerkin approach for simulating graphene-based electron devices via the Boltzmann transport equation",
    "abstract": "Electron devices based on graphene have lately received a considerable interest; in fact, they could represent the ultimate miniaturization, since the active area is only one atom tick. However, the gapless dispersion relation of graphene at the Dirac points limits the possibility of using pristine graphene instead of traditional semiconductors in Field Effect Transistors (FET). For such a reason very accurate simulations are needed. In Nastasi & Romano, IEEE TED (2021) a graphene field effect transistor (GFET) has been proposed and simulated adopting a drift-diffusion model. Here, electron devices whose active area is made of monolayer graphene are simulated adopting as mathematical model the semiclassical Boltzmann transport equations (BTEs) in the bipolar case, coupled with the Poisson equation for the electric field. The system is solved by means of a discontinuous Galerkin (DG) approach (see Cockburn & Shu, J. Comp. Phys. (1998); Hesthaven & Warburton, 2008) with linear elements in the spatial coordinate and constant approximation for the wave-vector space, discretized with a polar mesh. The correct physical range for the distribution function is preserved with the maximum-principle-satisfying scheme introduced in Zhang & Shu, J. Comp. Phys. (2010). The adopted method reveals very robust and possesses a good degree of accuracy, making it particularly well suited for capturing the complex charge transport dynamics inherent to graphene-based devices. The results for suspended monolayer graphene and GFET constitute benchmark solutions for a rigorous assessment of the validity of macroscopic models, such as drift-diffusion and hydrodynamic ones.",
    "authors": [
      "Giovanni Nastasi",
      "Vittorio Romano"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03212",
    "title": "A Conformal Positive Mass Theorem with Noncompact Boundary",
    "abstract": "We obtain an integral inequality for asymptotically linear harmonic functions on asymptotically flat 3-manifolds with noncompact boundary, which implies positivity of a convex combination of ADM masses of two conformally related metrics under a positivity condition on a corresponding convex combination of their scalar curvatures and boundary mean curvatures. This generalizes a result of Batista and Lopes de Lima, under conditions that do not assume positivity of scalar curvature.",
    "authors": [
      "Alex Freire",
      "Mohammad Tariquel Islam"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03213",
    "title": "Finding equations of the fake projective plane $(C18,p=3,\\{2I\\})$",
    "abstract": "We find explicit equations of a new pair of fake projective planes, labeled by $(C18,p=3,\\{2I\\})$ in the Cartwright-Steger classification. Our method involves starting with known equations of a commensurable fake projective plane $(C18,p=3,\\emptyset,d_3 D_3)$ and working through a chain of cyclic covers and quotients to get to the new one.",
    "authors": [
      "Lev Borisov",
      "Bojue Wang"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03215",
    "title": "Uniqueness problem for accretive Schrödinger operators with complex singular coefficients",
    "abstract": "The paper studies the uniqueness problem for the one-dimensional Schrödinger operator associated with the formal differential expression \\begin{equation*} l[u] =-u''+qu + i[(ru)'+ru'], \\end{equation*} in the complex Hilbert space $L^{2}(\\mathbb{R})$. The coefficients of the expression are complex-valued and satisfy \\begin{equation*} q=s+Q', \\quad s \\in L^1_{loc}\\left(\\mathbb{R}\\right) \\quad\\text{and}\\quad Q, r \\in L^2_{loc}\\left(\\mathbb{R}\\right), \\end{equation*} where the derivative is understood in the sense of distributions. In particular, the potential $q$ can be a Radon measure on the line. With the help of specially selected quasi-derivatives, the expression $l$ is treated as quasi-differential. The domains of the minimal $\\mathrm{L}_{0}$ and maximal $\\mathrm{L}$ operators associated with the expression $l$ in the space $L^{2}(\\mathbb{R})$ are described. We find constructive conditions on the behaviour of $\\mathrm{Im}\\,r$ near $\\pm \\infty$ that guarantee that $\\mathrm{L}_{0}=\\mathrm{L}$ if the operator $\\mathrm{L}_{0}$ is accretive.",
    "authors": [
      "Vladimir Mikhailets",
      "Volodymyr Molyboga"
    ],
    "primary_category": "math.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03222",
    "title": "Game-Theoretic Learning-Based Mitigation of Insider Threats",
    "abstract": "An insider is defined as a team member who covertly deviates from the team's optimal collaborative control strategy in pursuit of a private objective, while maintaining an outward appearance of cooperation. Such insider threats can severely undermine cooperative systems: subtle deviations may degrade collective performance, jeopardize mission success, and compromise operational safety. This paper presents a comprehensive framework for identifying and mitigating insider threats in cooperative control settings. We introduce an insider-aware, game-theoretic formulation in which the insider's hidden intention is parameterized, allowing the threat identification task to be reformulated as a parameter estimation problem. To address this challenge, we employ an online indirect dual adaptive control approach that simultaneously infers the insider's control strategy and counteracts its negative influence. By injecting properly designed probing signals, the resulting mitigation policy asymptotically recovers the nominal optimal control law - one that would be achieved under full knowledge of the insider's objective. Simulation results validate the effectiveness of the proposed identification-mitigation framework and illustrate its capability to preserve team performance even in the presence of covert adversarial behavior.",
    "authors": [
      "Gehui Xu",
      "Kaiwen Chen",
      "Thomas Parisini",
      "Andreas A. Malikopoulos"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03223",
    "title": "Invariants of finite groups acting on (free) skew fields",
    "abstract": "Let $M$ be a finitely generated skew field over a ground field $k$, and let $G$ be a finite group of $k$-linear automorphisms of $M$. This paper investigates finite generation of the skew subfield $M^G$ of $G$-invariants in $M$, and relations between the generators. The first main result shows that $M^G$ is finitely generated. Stronger conclusions hold when $M$ is a free skew field, i.e., the universal skew field of fractions of a free algebra. The second main result is the solution of the free Noether problem for non-modular linear group actions: if $G$ acts linearly on the free skew field $M$ on $m$ generators and the characteristic of $k$ does not divide $|G|$, then $M^G$ is the free skew field on $|G|(m-1)+1$ generators. In contrast, a nonlinear action of $Z_2$ on the free skew field $M$ on two generators is presented such that $M^{Z_2}$ is not a free skew field, resolving the free Lüroth problem. This action also exposes a non-scalar element of $M$ whose centralizer is not a rational field, refuting a conjecture of P. M. Cohn from 1978.",
    "authors": [
      "Harm Derksen",
      "Jurij Volčič"
    ],
    "primary_category": "math.RA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03241",
    "title": "Multi-Source M/G/1/1 Queues with Probabilistic Preemption",
    "abstract": "We consider a multi-source status update system consisting of multiple independent sources, a single server, and a single sink. Each source generates packets according to a Poisson process, and packets are served according to a general service time distribution. The system has a capacity of one packet, i.e., no waiting buffer, and is modeled as a multi-source M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy, under which an existing packet from the same source in the system is replaced by an arriving packet with a fixed probability. We derive the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) for each source under this policy. Numerical results demonstrate the effectiveness of the proposed packet management policy.",
    "authors": [
      "Mohammad Moltafet",
      "Hamid R. Sadjadpour",
      "Zouheir Rezki",
      "Marian Codreanu",
      "Roy D. Yates"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03246",
    "title": "A Lagrangian Approach to the Inhomogeneous Incompressible Euler Equation",
    "abstract": "In this paper, we study the Lagrangian aspects of the inhomogeneous incompress- ible Euler equation (IIE in short). We establish a geodesic description of this equation and discuss the associated geometric structures. We also find the derivation of IIE from the Hamilton-Pontryagin action principle and derive the corresponding Lagrangian for- mulation. Appealing to this Lagrangian perspective, we prove Lagrangian analyticity of IIE",
    "authors": [
      "Anping Pan"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03250",
    "title": "Relative Thom Conjectures, symplectic and beyond",
    "abstract": "We establish a criterion that ensures a bounded almost complex curve in a bounded almost complex 4-manifold minimizes genus amongst all smooth surfaces that share its homology class and the transverse link on its boundary. An immediate corollary affirms the relative symplectic Thom conjecture and, moreover, yields obstructions coming from knot Floer homology to a link bounding a symplectic surface in a symplectic filling. Our results are applicable to knots in manifolds equipped with plane fields that admit no symplectic fillings; for instance, we show that symplectic surfaces in a thickening of any contact 3-manifold with non-zero Ozsvath-Szabo invariant minimize slice genus for their boundary. We conjecture that this phenomenon occurs precisely when the contact structure is tight, which would imply that tightness can be viewed as a symplecto-geometric notion.",
    "authors": [
      "Matthew Hedden",
      "Katherine Raoux"
    ],
    "primary_category": "math.GT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03259",
    "title": "A joint logic of problems and propositions",
    "abstract": "In a 1985 commentary to his collected works, Kolmogorov informed the reader that his 1932 paper 'On the interpretation of intuitionistic logic' \"was written in hope that with time, the logic of solution of problems [i.e., intuitionistic logic] will become a permanent part of a [standard] course of logic. A unified logical apparatus was intended to be created, which would deal with objects of two types - propositions and problems.\" We construct such a formal system as well as its predicate version, QHC, which is a conservative extension of both the intuitionistic predicate calculus QH and the classical predicate calculus QC. The axioms of QHC are obtained as a result of a simultaneous formalization of two well-known alternative explanations of intiuitionistic logic: 1) Kolmogorov's problem interpretation (with familiar refinements by Heyting and Kreisel) and 2) the proof interpretation by Orlov and Heyting, as clarified and extended by Gödel.",
    "authors": [
      "Sergey A. Melikhov"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03265",
    "title": "Large-time behavior in a nonlocal heat equation with absorption. The absorption dominated case with fast decaying initial data",
    "abstract": "We study the large-time behavior of nonnegative solutions to a nonlocal dispersal equation in $\\mathbb R^N$ with an absorption term modeled by $-u^p$, with $1<p<1+\\frac2N$. The initial datum $u_0$ is assumed to be bounded, and to satisfy $|x|^{\\frac2{p-1}}u_0(x)\\to A\\ge0$ as $|x|\\to\\infty$. Under these assumptions, we prove that the decay rate is that of the purely absorbing problem, while the limit profile is a very singular solution to a local diffusion problem with absorption if $A=0$, and a solution to this same local problem with initial datum $A|x|^{-\\frac2{p-1}}$ if $A>0$.",
    "authors": [
      "Carmen Cortázar",
      "Fernando Quirós",
      "Noemi Wolanski"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03268",
    "title": "Generalizing M. Dale's results from secants to joins",
    "abstract": "Magnar Dale's paper ``Terracini's lemma and the secant variety of a curve\" contains various facts about secant varieties, nearly all of whose proofs can immediately be extended to the situation of embedded joins of varieties. This note provides the necessary details on how to do so, and as an application shows how to use this information to calculate the degree of the canonical map from the ruled join down to the embedded join.",
    "authors": [
      "Joseph Beckmann"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03273",
    "title": "Balancing games on unbounded sets",
    "abstract": "For a finite set $V\\subset \\mathbb{R}^n$, a set $T\\subset \\mathbb{R}^n$ is called $V$-closed if $t \\in T$ and $v\\in V$ imply that either $t+v\\in T$ or $t-v \\in T$. The set $P(V):=\\{\\sum_{v \\in W} v: W \\subset V\\}$ is clearly $V$-closed and so are its translates. We show, assuming $V$ contains no parallel vectors, that if $T$ is closed and $V$-closed, and $x \\in T$ is an extreme point of $\\operatorname{cl} \\operatorname{conv} T$, then there is a translate of $P(V)$ containing $x$ and contained in $\\operatorname{conv} T$. This result is used to determine the value of a special balancing game. A byproduct is that when $m\\ge 2$ and is not a power of 2, then the $m$-sets of a $2m$-set can be coloured Red and Blue so that complementary $m$-sets have distinct colours and every point of the $2m$-set is contained in the same number of Red and Blue sets.",
    "authors": [
      "Imre Bárány",
      "Jeck Lim"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03288",
    "title": "Structural Existence of Prime Constellations: Asymptotic Spectral Stability in Finite Sieve Windows",
    "abstract": "The distribution of prime constellations, such as Twin Primes ($p, p+2$), is traditionally analyzed via probabilistic models or analytic sieve theory. While heuristic predictions are accurate, rigorous proofs are obstructed by the \"Parity Barrier\", which prevents classical sieves from distinguishing primes from semi-primes in the asymptotic limit. In this work, we present a structural proof of existence based on deterministic signal processing. We treat the sequence of integers as a signal generated by a rigid Diophantine basis ($N=2n+3m$) and define a fundamental certification window $\\mathcal{W} = [P, m_0^2)$ derived from the basis limit $m_0$. We demonstrate that the non-existence of constellations (the \"Null Hypothesis\") constitutes a low-entropy signal state, a \"Prime Desert\", that requires infinite spectral resolution to maintain over a quadratic window. Since the sieving basis is finite ($p \\le m_0$), the system is band-limited and structurally incapable of synthesizing the destructive interference required to sustain a zero count. By invoking the Chinese Remainder Theorem and analyzing the detailed correlation structure of residue classes, we prove that positive and negative correlations between sieved positions cancel at leading order, constraining the variance of the signal to scale linearly with the mean ($O(\\mu)$) rather than the quadratic scaling ($\\Omega(\\mu^2)$) required to support a Prime Desert. This Variance Gap implies that the signal must strictly oscillate around its mean, rendering the existence of prime constellations a mandatory consequence of the system's finite spectral bandwidth.",
    "authors": [
      "Alexander Caicedo",
      "Julio C. Ramos-Fernández"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03291",
    "title": "Weighted geodesic restrictions of arithmetic eigenfunctions",
    "abstract": "Let $X$ be an arithmetic hyperbolic surface, $\\psi$ a Hecke-Maass form, $\\ell$ a geodesic segment on $X$, and $\\mu$ a Borel measure supported on $\\ell$ with dimension greater than 1/2. We obtain a power saving over the local bound of Eswarathasan and Pramanik for the $L^2$ norm of $\\psi$ with respect to $\\mu$, which is a weighted generalization of Marshall's geodesic restriction bound and is proved by applying the method of arithmetic amplification. On a general 2-dimensional Riemannian manifold, we also obtain a Kakeya-Nikodym bound for the $L^2$ norm of any Laplace-Beltrami eigenfunction with respect to a Borel measure supported on a geodesic segment with dimension greater than 1/2.",
    "authors": [
      "Jiaqi Hou",
      "Xiaoqi Huang"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03292",
    "title": "The distribution of prime values of random polynomials",
    "abstract": "The Bateman--Horn Conjecture predicts how often an irreducible polynomial $f(x) \\in \\mathbb{Z}[x]$ assumes prime values. We demonstrate that with sufficient averaging in the coefficients of $f$ (viz. exponential in the size of the inputs), one can not only prove Bateman--Horn results on average but also pin down precise information about the distribution of prime values. We show that 100\\% of polynomials (in an $L^k$ sense for all $k \\in \\mathbb{N}$) satisfy the Bateman--Horn Conjecture, and that that 100\\% of polynomials (in an $L^2$ sense) satisfy an appropriate polynomial analogue of the Hardy--Littlewood Prime Tuples Conjecture. We use the latter to prove that 100\\% of polynomials satisfy the appropriate analogue of the Poisson Tail Conjecture, in the sense that the distribution of the gaps between consecutive prime values around the average spacing is Poisson. We also study the frequencies of sign patterns of the Liouville function evaluated at the consecutive outputs of $f$; viewing $f$ as a random variable, we establish the limiting distribution for every sign pattern. The Chowla problem along random polynomials is a special case. A key input behind all of our arguments is Leng's recent quantitative work on the higher-order Fourier uniformity of the von Mangoldt and Möbius functions (in turn relying on Leng, Sah, and Sawhney's quantitative inverse theorem for the Gowers norms).",
    "authors": [
      "Noah Kravitz",
      "Katharine Woo",
      "Max Wenqiang Xu"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03294",
    "title": "Matroids arising from algebraic shifting",
    "abstract": "We characterize the shifted simple graphs and the $3$-uniform shifted hypergraphs whose inverse image under exterior shifting is the set of bases of a matroid: those are exactly the hypergraphs whose hyperedges form an initial lex-segment. There are several examples of known matroids arising in this way: the simplicial matroid, the hyperconnectivity matroid and the area-rigidity matroid. For $k\\ge 4$, we provide a similar characterization for shifted $k$-uniform hypergraphs satisfying an additional combinatorial condition. For symmetric shifting, we prove an analogous characterization for shifted simple graphs, where the classical generic rigidity matroid is an example of a matroid arising in this way.",
    "authors": [
      "Lazar Guterman",
      "Eran Nevo"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03297",
    "title": "Mean values of the Riemann zeta function at shifted zeros under the Riemann Hypothesis",
    "abstract": "Assuming the Riemann hypothesis, we obtain asymptotic formulas for $\\sum_{0<\\gamma<T}\\zeta(\\rho+\\delta)\\zeta(1-\\rho+\\overline{\\delta})$ in the region $-\\frac{a}{\\log T} \\leq \\Re \\delta \\leq \\frac{1}{2}+\\frac{a}{\\log T}$, $|\\Im \\delta|\\ll 1$. Unconditionally, this asymptotic formula was recently obtained by Garunkštis and Novikas in essentially the same region, with a slight incompleteness. Assuming RH, we obtain a sharper error term, and we also correct an inaccuracy in the unconditional error term there.",
    "authors": [
      "Ramūnas Garunkštis",
      "Julija Paliulionytė"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03299",
    "title": "Degeneracy and Sato-Tate groups of $y^2=x^{p^2}-1$",
    "abstract": "We say that an abelian variety is degenerate if its Hodge ring is not generated by divisor classes. Degeneracy leads to some interesting challenges when computing Sato-Tate groups, and there are currently few examples and techniques presented in the literature. In this paper we focus on the Jacobians of the family of curves $C_{p^2}: y^2=x^{p^2}-1$, where $p$ is an odd prime. Using a construction developed by Shioda in the 1980s, we are able to characterize so-called indecomposable Hodge classes as well as the Sato-Tate groups of these Jacobian varieties. Our work is inspired by computation, and examples and methods are described throughout the paper.",
    "authors": [
      "Justin Chen",
      "Heidi Goodson",
      "Rezwan Hoque",
      "Sabeeha Malikah"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03305",
    "title": "Spectral Reciprocity: A Fourier--Analytic Approach",
    "abstract": "We develop a Fourier--analytic framework for establishing spectral reciprocity formulas linking $\\mathrm{GL}_3$ and $\\mathrm{GL}_2$ automorphic spectra over number fields. The method applies uniformly to cuspidal and non-cuspidal $\\mathrm{GL}_3$ representations and treats Motohashi-type and Blomer--Khan-type reciprocities in a parallel manner, revealing intrinsic connections between them and extending each to new settings. We also obtain explicit weight transforms in the analytic newvector and spherical cases. Applications include first-moment estimates for $\\mathrm{GL}_3\\times\\mathrm{GL}_2$ $L$-functions over number fields, an explicit twisted fourth moment for $\\mathrm{GL}_2$ $L$-functions over totally real fields, a sharp upper bound for the fifth moment, subconvexity for triple product $L$-functions, and new simultaneous nonvanishing results.",
    "authors": [
      "Liyang Yang"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03313",
    "title": "Herman's converse KAM mechanism revisited",
    "abstract": "In his celebrated counterexample to the KAM theorem, Herman introduced a perturbation of an integrable system consisting of two components: a hyperbolic term and a bump function. He also remarked that it was unclear whether the bump function was truly necessary. In this note, we prove that the bump function is indeed necessary when more natural hyperbolic perturbations are considered. The proof of this necessity relies on an improved Siegel--Brjuno estimate and a parameter-dependent renormalization of resonances within the direct KAM method.",
    "authors": [
      "Yi Liu",
      "Lin Wang"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03320",
    "title": "A relative trace formula identity for non-tempered spherical varieties",
    "abstract": "In this paper, motivated by some previous works in residue method and the recent theory of the relative Langlands duality, we prove a relative trace formula identity that compares the period integral of non-tempered spherical varieties with the period integral of a tempered spherical varieties associated to a Levi subgroup. This allows us to incorporate numerous relative trace formula comparisons studied during the last four decades under the relative Langlands duality framework. We will also propose a conjectural comparison for general non-tempered Hamiltonian spaces.",
    "authors": [
      "Chen Wan"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03323",
    "title": "K-polystability of Asymptotically Conical Kähler-Ricci Shrinkers",
    "abstract": "Recently, Sun-Zhang have developed an algebraic theory for Kähler-Ricci shrinkers showing that they admit the structure of a polarized Fano fibration $(\\pi: X \\to Y, \\xi)$. In particular, they conjecture that existence of a Kähler-Ricci shrinker metric is equivalent to a notion of K-stability. We prove one direction of this conjecture, namely that existence of a Kähler-Ricci shrinker metric $g$ implies K-polystability of $(\\pi: X \\to Y, \\xi)$, in the case that the Ricci curvature of $g$ decays at infinity.",
    "authors": [
      "Charles Cifarelli",
      "Carlos Esparza"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03325",
    "title": "When does Gaussian equivalence fail and how to fix it: Non-universal behavior of random features with quadratic scaling",
    "abstract": "A major effort in modern high-dimensional statistics has been devoted to the analysis of linear predictors trained on nonlinear feature embeddings via empirical risk minimization (ERM). Gaussian equivalence theory (GET) has emerged as a powerful universality principle in this context: it states that the behavior of high-dimensional, complex features can be captured by Gaussian surrogates, which are more amenable to analysis. Despite its remarkable successes, numerical experiments show that this equivalence can fail even for simple embeddings -- such as polynomial maps -- under general scaling regimes. We investigate this breakdown in the setting of random feature (RF) models in the quadratic scaling regime, where both the number of features and the sample size grow quadratically with the data dimension. We show that when the target function depends on a low-dimensional projection of the data, such as generalized linear models, GET yields incorrect predictions. To capture the correct asymptotics, we introduce a Conditional Gaussian Equivalent (CGE) model, which can be viewed as appending a low-dimensional non-Gaussian component to an otherwise high-dimensional Gaussian model. This hybrid model retains the tractability of the Gaussian framework and accurately describes RF models in the quadratic scaling regime. We derive sharp asymptotics for the training and test errors in this setting, which continue to agree with numerical simulations even when GET fails. Our analysis combines general results on CLT for Wiener chaos expansions and a careful two-phase Lindeberg swapping argument. Beyond RF models and quadratic scaling, our work hints at a rich landscape of universality phenomena in high-dimensional ERM.",
    "authors": [
      "Garrett G. Wen",
      "Hong Hu",
      "Yue M. Lu",
      "Zhou Fan",
      "Theodor Misiakiewicz"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03326",
    "title": "Generalized Orthogonal Approximate Message-Passing for Sublinear Sparsity",
    "abstract": "This paper addresses the reconstruction of sparse signals from generalized linear measurements. Signal sparsity is assumed to be sublinear in the signal dimension while it was proportional to the signal dimension in conventional research. Approximate message-passing (AMP) has poor convergence properties for sensing matrices beyond standard Gaussian matrices. To solve this convergence issue, generalized orthogonal AMP (GOAMP) is proposed for signals with sublinear sparsity. The main feature of GOAMP is the so-called Onsager correction to realize asymptotic Gaussianity of estimation errors. The Onsager correction in GOAMP is designed via state evolution for orthogonally invariant sensing matrices in the sublinear sparsity limit, where the signal sparsity and measurement dimension tend to infinity at sublinear speed in the signal dimension. When the support of non-zero signals does not contain a neighborhood of the origin, GOAMP using Bayesian denoisers is proved to achieve error-free signal reconstruction for linear measurements if and only if the measurement dimension is larger than a threshold, which is equal to that of AMP for standard Gaussian sensing matrices. Numerical simulations are also presented for linear measurements and 1-bit compressed sensing. When ill-conditioned sensing matrices are used, GOAMP for sublinear sparsity is shown to outperform existing reconstruction algorithms, including generalized AMP for sublinear sparsity.",
    "authors": [
      "Keigo Takeuchi"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03327",
    "title": "Increasing the Size of Tame Shafarevich Groups",
    "abstract": "Let $K$ be a number field with a finite set $S$ of primes. We study the cohomology of $\\mathbb{F}_p[G_{K,S}]$-modules $A$, in particular the Shafarevich groups $\\Sha^i_S(K,A)$ for $i=1,2$ for tame sets $S$, i.e., for sets $S$ that contain no primes above $p$. When $S$ contains all primes above $p$ (the ``wild'' setting), it is a consequence of global Poitou-Tate duality that $\\Sha^1_S(K,A')^\\vee \\simeq \\Sha^2_S(K,A) \\stackrel{\\simeq}{\\hookrightarrow} \\RusB_S(K,A) $ is non-increasing as $S$ increases. The same applies when $G_{K,S}$ is replaced by its maximal pro-$p$ quotient $G_{K,S}(p)$. In [4] it was shown that for $S$ tame and $A=\\mathbb{F}_p$ with trivial action, the group $\\Sha^2_S(K, A)$ can increase as $S$ increases to $S\\cup X$, and even attain its maximal dimension, $\\dim_{\\mathbb{F}_p} \\RusB_S(K,\\mathbb{F}_p)$, for carefully chosen $X$. We strengthen this to general $\\mathbb{F}_p[G_{K,S}]$-modules $A$ where $S$ is tame. We use Liu's definition [7] of $\\RusB_S(K,A)$ to show that $\\Sha^2_S(K,A) \\hookrightarrow \\RusB_S(K,A)$ and that there exist infinitely many tame sets of primes $X$ of $K$ such that $\\Sha^2_{S\\cup X}(K,A) \\stackrel{\\simeq}{\\hookrightarrow} \\RusB_{S \\cup X}(K,A) \\stackrel{\\simeq}{\\twoheadleftarrow} \\RusB_S(K,A) \\hookleftarrow \\Sha^2_S(K,A)$.",
    "authors": [
      "Andreea Iorga",
      "Ravi Ramakrishna"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03328",
    "title": "Invariant measures for the open KPZ equation: an analytic perspective",
    "abstract": "The ergodic theory of the open KPZ equation has seen significant progress in recent years, with explicit invariant measures described in a series of works by Corwin--Knizel, Barraquand--Le Doussal, and Bryc--Kuznetsov--Wang--Wesołowski. In this paper, we provide a stochastic analytic proof of the formula for the invariant measures. Our approach starts from the Gaussian invariant measure for the case of homogeneous boundary conditions. We approximate the inhomogeneous problem by a homogeneous one with a singular boundary potential. Using tools including change of measure, time reversal for Markov processes, and Itô's formula, we then reduce the problem to analyzing the KPZ nonlinearity in a thin boundary layer. Finally, using the theory of regularity structures, we establish a central limit theorem for the time-integrated nonlinearity near the boundary, which completes the proof of the invariance. Although it is known that different boundary parameters give rise to distinct physical regimes for the invariant measures, our method is robust and does not rely on any particular choice of boundary parameters.",
    "authors": [
      "Alexander Dunlap",
      "Yu Gu",
      "Tommaso Rosati"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03330",
    "title": "Simpson variational integrator for nonlinear systems: a tutorial on the Lagrange top",
    "abstract": "This contribution presents an integration method based on the Simpson quadrature. The integrator is designed for finite-dimensional nonlinear mechanical systems that derive from variational principles. The action is discretized using quadratic finite elements interpolation of the state and Simpson's quadrature, leading to discrete motion equations. The scheme is implicit, symplectic, and fourth-order accurate. The proposed integrator is compared with the implicit midpoint variational integrator on two examples of systems with inseparable Hamiltonians. First, the example of the nonlinear double pendulum illustrates how the method can be applied to multibody systems. The analytical solution of the Lagrange top is then used as a reference to analyze accuracy, convergence, and precision of the numerical method. A reduced Lagrange top system is also proposed and solved with a classical fourth-order method. Its solution is compared with the Simpson solution of the complete system, and the convergence order of the difference between both is consistent with the order of the classical method.",
    "authors": [
      "Juan Antonio Rojas-Quintero",
      "François Dubois",
      "Frédéric Jourdan"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03338",
    "title": "Structure theorems for the heart of LCA",
    "abstract": "Cohomology theories with values in LCA (locally compact abelian) groups suffer from the problem that the latter do not form an abelian category. However, the category LCA has a canonical abelian category envelope, the heart of a suitable t-structure. It adds formal cokernel objects. We show the surprising result that these abstract cokernels can also be interpreted as Hausdorff topological abelian groups, at least up to lattice isogenies. These need not be locally compact.",
    "authors": [
      "Oliver Braunling",
      "Fei Ren"
    ],
    "primary_category": "math.CT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03342",
    "title": "New linear invariants of hypergraphs",
    "abstract": "We introduce a parameterized family of invariants for $\\ell$-uniform hypergraphs. To each $\\mathbb{K}$-linear transformation $T:\\mathbb{K}^{\\ell}\\to \\mathbb{K}^r$ we associate a function $\\mathrm{Sig}(-,T)$ that maps $\\ell$-uniform hypergraphs to $\\mathbb{K}$-vector spaces. Given an $\\ell$-uniform hypergraph $\\mathcal{H}=(V,E)$, we use $\\mathrm{Sig}(\\mathcal{H},T)$ to define an equivalence relation $\\equiv_T$ on $V$ called $T$-fusion, which determines a quotient hypergraph $\\mathfrak{F}(\\mathcal{H},T)$ called the $T$-frame of $\\mathcal{H}$. We show that the map $U:\\mathbb{K}^{\\ell}\\to \\mathbb{K}$, where $U(\\lambda)=\\lambda(1)+\\cdots+\\lambda(\\ell)$, is universal in that $\\mathrm{Sig}(\\mathcal{H},T)$ embeds in $\\mathrm{Sig}(\\mathcal{H},U)$, and $U$-fusion refines $T$-fusion for any $T:\\mathbb{K}^{\\ell}\\to\\mathbb{K}^r$. We further show that $\\mathfrak{F}(\\mathfrak{F}(\\mathcal{H},U),U)=\\mathfrak{F}(\\mathcal{H},U)$ for any $\\ell$-uniform hypergraph $\\mathcal{H}$, so $\\mathfrak{F}(-,U)$ is a closure function on the set of $\\ell$-uniform hypergraphs. We explore the properties of this one-time simplification of a hypergraph.",
    "authors": [
      "Peter A. Brooksbank",
      "Clara R. Chaplin"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03349",
    "title": "Logarithmic Sobolev inequalities on infinite-dimensional reduced Heisenberg groups",
    "abstract": "We construct a family of infinite-dimensional reduced Heisenberg groups which can be viewed as infinite-dimensional homogeneous spaces. Such a space is an analogue of finite-dimensional reduced Heisenberg groups in infinite dimensions. We study properties of the hypoelliptic heat kernel measure on this space, including hypoelliptic logarithmic Sobolev inequalities there.",
    "authors": [
      "Maria Gordina",
      "Liangbing Luo"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03352",
    "title": "Anti-self-dual blowups II",
    "abstract": "Let $X$ be a closed, oriented four-manifold with $b_2^+ \\leq 3$, and suppose $X$ contains a collection of pairwise disjoint embedded $(-2)$-spheres. We prove that there is a Riemannian metric on $X$ such that the Poincare dual of each of these spheres is represented by an anti-self-dual harmonic form. This extends our earlier result for $(-1)$-spheres. The main new ingredient is an application of Eliashberg's $h$-principle for overtwisted contact structures, which we use to construct self-dual harmonic forms on four-orbifolds with prescribed local behaviour near the orbifold singular set.",
    "authors": [
      "Vsevolod Shevchishin",
      "Gleb Smirnov"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03353",
    "title": "Quadratic metric comparisons",
    "abstract": "We study the effects on length spaces imposed by quadratic inequalities on the six distances between the points in every quadruple.",
    "authors": [
      "Nina Lebedeva",
      "Anton Petrunin",
      "Vladimir Zolotov"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03367",
    "title": "Pairs of eventually constant maps and nilpotent pairs",
    "abstract": "Tom Leinster gave a bijective correspondence between the set of operators on a finite-dimensional vector space $V$ and the set of pairs consisting of a nilpotent operator and a vector in $V$. Over a finite field this bijection implies that the probability that an operator be nilpotent is the reciprocal of the number of vectors in $V$. We generalize this correspondence to pairs of operators between pairs of vector spaces and determine the probability that a random pair of operators be nilpotent. We also determine the set-theoretical counterpart of this construction and compute the number of eventually constant pairs of maps between two finite sets, closely related to the number of spanning trees in a complete bipartite graph.",
    "authors": [
      "Weixi Chen",
      "Mee Seong Im",
      "Mikhail Khovanov",
      "Catherine Lillja",
      "Nicolas Rugo"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03371",
    "title": "Local categories: a new framework for partiality",
    "abstract": "Restriction categories provide a categorical framework for partiality. In this paper, we introduce three new categorical theories for partiality: local categories, partial categories, and inclusion categories. The objects of a local category are partially accessible resources, and morphisms are processes between these resources. In a partial category, partiality is addressed via two operators, restriction and contraction, which control the domain of definition of a morphism. Finally, an inclusion category is a category equipped with a family of monics which axiomatize the inclusions between sets. The main result of this paper shows that restriction categories are $2$-equivalent to local categories, that partial categories are $2$-equivalent to inclusion categories, and that both restriction/local categories are $2$-equivalent to bounded partial/inclusion categories. Our result offers four equivalent ways to describe partiality: on morphisms, via restriction categories; on objects, with local categories; operationally, with partial categories; and via inclusions, with inclusion categories. We also translate several key concepts from restriction category theory to the local category context, which allows us to show that various special kinds of restriction categories, such as inverse categories, are $2$-equivalent to their analogous kind of local categories. In particular, the equivalence between inverse (restriction) categories and inverse local categories is a generalization of the celebrated Ehresmann-Schein-Nambooripad theorem for inverse semigroups.",
    "authors": [
      "Marcello Lanfranchi",
      "Jean-Simon Pacaud Lemay"
    ],
    "primary_category": "math.CT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03376",
    "title": "Theoretical and numerical comparison of seven single-level reformulations for bilevel programs",
    "abstract": "This paper considers a bilevel program. To solve this bilevel program, it is generally necessary to transform it into some single-level optimization problem. One approach is to replace the lower-level program by its KKT conditions to transform the bilevel program as a mathematical program with complementarity constraints (MPCC). Another approach is to apply the lower-level Wolfe/Mond-Weir/extended Mond-Weir duality to transform the bilevel program into some duality-based single-level reformulations, called WDP, MDP, and eMDP respectively in the literature. In this paper, inspired by a conjecture from a recent publication that the tighter feasible region of a reformulation, the better its numerical performance, we present three new duality-based single-level reformulations, called TWDP/TMDP/eTMDP, with tighter feasible regions. Our main goal is to compare all above-mentioned reformulations by designing some direct and relaxation algorithms with projection and implementing these algorithms on 450 test examples generated randomly. Our numerical experiments show that, whether overall comparison or pairwise comparison, at least in our tests, the WDP/MDP/TWDP/TMDP reformulations were always better than the MPCC reformulation, while the eMDP/eTMDP reformulations were always the worst ones among six duality-based reformulations, which indicates that the above conjecture is incorrect. In particular, for the relaxation algorithms, the WDP/MDP/TWDP/TMDP reformulations performed 3-5 times better than the MPCC reformulation, while the eMDP/eTMDP reformulations performed 2 times better than the MPCC reformulation.",
    "authors": [
      "Yu-Wei Li",
      "Gui-Hua Lin",
      "Xide Zhu"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03378",
    "title": "On Bridging Analyticity and Sparseness in Hyperdissipative Navier-Stokes Systems",
    "abstract": "We study the three-dimensional hyper-dissipative Navier-Stokes system in the near-critical regime below the Lions threshold. Leveraging a quantified analyticity-sparseness gap, we introduce a time-weighted bridge inequality across derivative levels and a focused-extremizer hypothesis capturing peak concentration at a fixed point. Together with a harmonic-measure contraction on one-dimensional sparse sets, these mechanisms enforce quantitative decay of high-derivative $L^{\\infty}-$norms and rule out blow-up. Under scale-refined, slowly varying time weights, solutions extend analytically past the prospective singular time, thereby refining the analyticity-sparseness framework, complementing recent exclusions of rapid-rate blow-up scenarios, and remaining consistent with recent non-uniqueness results.",
    "authors": [
      "Moses Patson Phiri"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03384",
    "title": "Isotopes of biracks and Zhang twists of algebras",
    "abstract": "In this paper, we introduce the notion of an $\\mathbb{N}^p$-graded birack and construct its isotope. Every involutive $\\mathbb{N}^p$-graded birack gives rise to an $\\mathbb{N}^p$-graded Yang-Baxter algebra. We study the relation between isotopes of involutive $\\mathbb{N}^p$-graded biracks and Zhang twists of $\\mathbb{N}^p$-graded Yang-Baxter algebras. As an example, Yang-Baxter algebras determined by distributive solutions are proved to be Zhang twists of polynomial algebras.",
    "authors": [
      "Xiaolan Yu",
      "Yanfei Zhang"
    ],
    "primary_category": "math.RA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03386",
    "title": "Perfect set dichotomy theorem in generalized Solovay model",
    "abstract": "We prove that the perfect set dichotomy theorem holds in the Solovay model $V ((\\omega^\\omega)^{V[G]})$. Namely, for every equivalence relation $E$ on $\\mathbb{R}$, either $\\mathbb{R}/E$ is well-orderable or there exists a perfect set consisting of $E$-inequivalent reals. Furthermore we consider a generalization of the Solovay model for an uncountable regular cardinal $\\mu$ and show the perfect set dichotomy theorem for $\\mu^\\mu$ also holds in that model. We establish the three element basis theorem for uncountable linear orders in the Solovay model for a weakly compact cardinal, in a general form covering the uncountable case.",
    "authors": [
      "Hiroshi Sakai",
      "Toshimasa Tanno"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03391",
    "title": "From n-systems to Lie and Courant algebroids",
    "abstract": "This paper introduces a method for constructing pure algebroids, dull algebroids, and Lie algebroids. The construction relies on what we deffned as n-systems on vector bundles, and we provide explicit computations for all resulting structure maps. Analogously, metric n-systems deffned on metric vector bundles allow us to construct metric algebroids, pre-Courant algebroids, and Courant algebroids.",
    "authors": [
      "Liqiang Cai",
      "Zhuo Chen",
      "Zhixiong Chen",
      "Yanhui Bi"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03408",
    "title": "A Linear Structure from Magnetic-Dipole Systems and Its Geometry",
    "abstract": "We investigate a class of algebras on $\\mathbb{R}^3$ arising and generalized from the algebraic structure of magnetic gradient fields induced by systems of synchronous magnets with identical dipole moments (i.e., $\\mathbf{M}_i=\\mathbf{M},\\,\\forall i$). We show that when there is a $2$ dimensional sub-algebra, the linear structure associated to such an algebra admits a certain type of decompositions, which allows the locating of the dipole moment $\\bar{\\mathbf{M}}$ that yields the strongest translational force(s) on a test magnet $\\mathfrak{m}$. Upper bounds to the strength of this magnetic force are then established.",
    "authors": [
      "Bohuan Lin",
      "Fengping Li",
      "Zhengya Zhang"
    ],
    "primary_category": "math.RA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03410",
    "title": "Suboptimal Shrinking Horizon MPC with a Lower Hessian Condition Number from Adjustable Terminal Cost",
    "abstract": "A strategy for reducing the number of iterations and computational burden in shrinking horizon Model Predictive Control (SH-MPC) when steering into a prescribed terminal set despite unmeasured disturbances is proposed. This strategy exploits dynamic adjustment of the terminal cost weight and horizon length while ensuring that the terminal set is reached within a desired number of steps. A lower Hessian condition number which facilitates the computational reduction is proved under assumptions, and an example of spacecraft nutation damping using the proposed approach is reported.",
    "authors": [
      "Steven van Leeuwen",
      "Ilya Kolmanovsky"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03412",
    "title": "Ikeda type lift on $\\SO(3,n+1)$",
    "abstract": "By using Ikeda's theory for a compatible family of Eisenstein series, we explicitly construct Ikeda type lifts on the special orthogonal group $G=\\SO(3,n+1)$ over $\\Q$ with $n\\ge 3$ which splits everywhere at finite places. Our lifts are Hecke eigen cusp forms of weight $l$ ($l\\ge n+2$, even) and come from elliptic newforms with respect to $\\SL_2(\\Z)$ which are of weight $l-\\frac{n-2}{2}$ when $n$ is even and $2l-n+1$ when $n$ is odd.",
    "authors": [
      "Henry H. Kim",
      "Takuya Yamauchi"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03417",
    "title": "Moduli of vector bundles on $μ_n$-gerbes over genus 2 curves and the period-index problem",
    "abstract": "We develop a framework for describing vector bundles on $\\mu_n$-gerbes over curves and illustrate the construction through two detailed examples. Using the interpretation of Brauer classes as obstructions to descending determinantal line bundles from the algebraic closure, together with a geometric analysis of the moduli space of twisted sheaves, we prove that for genus $2$ curves there exist Brauer classes over the base field whose period equals their index. Over $C_1$-fields, we further show that every $2$-torsion class in the Brauer group of a genus $2$ curve satisfies the period-index problem. As an application, we construct higher-dimensional varieties obtained as fibre products of genus $2$ curves over $C_1$-fields whose $2$-torsion algebraic Brauer classes also satisfy the period-index problem, providing new evidence toward the period-index conjecture.",
    "authors": [
      "Ting Gong"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03425",
    "title": "Faithful action of braid group on bosonic extensions",
    "abstract": "The braid group action on the bosonic extension of the quantum group has been introduced in recent works, and it can be regarded as a generalization of Lusztig's symmetries on the quantum group. In this notes, we prove the faithfulness of this braid group action.",
    "authors": [
      "Masaki Kashiwara",
      "Myungho Kim",
      "Se-jin Oh",
      "Euiyong Park"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03432",
    "title": "Classification of totally real number fields via their zeta function, regulator, and log unit lattice",
    "abstract": "In this paper, assuming the weak Schanuel Conjecture (WSC), we prove that for any collection of pairwise non-arithmetically equivalent totally real number fields, the residues at $s=1$ of their Dedekind zeta functions form a linearly independent set over the field of algebraic numbers. As a corollary, we obtain that, under WSC, two totally real number fields have the same regulator if and only if they have the same class number and Dedekind zeta function. We also prove that, under WSC, the isometry and similarity classes of the log unit lattice of a real Galois number field of degree $[K:\\Q]\\geq 4$, characterize the isomorphism class of said field. All of our results follow from establishing that, under WSC, any Gram matrix of the log unit lattice of a real Galois number field yields a generic point of certain closed irreducible $\\Q$-subvariety of the space of symmetric matrices of appropriate size.",
    "authors": [
      "José Cruz"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03441",
    "title": "Bipartite Diophantine tuples and their applications",
    "abstract": "This paper investigates bipartite variants of generalized Diophantine tuples and their applications. We generalize a result of Bugeaud--Dujella on a special family of bipartite Diophantine tuples and affirmatively resolve a related question posed by the second author. Additionally, we establish new connections between bipartite Diophantine tuples and several known variants of Diophantine tuples, including those introduced by Banks--Luca--Szalay and Kihel--Kihel.",
    "authors": [
      "Kin Ming Tsang",
      "Chi Hoi Yip"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03448",
    "title": "Irreducible operators in von Neumann algebras",
    "abstract": "Let $\\mathcal{M}$ be a separable von Neumann algebra with center $\\mathcal{Z}(\\mathcal{M})$. An operator $T$ in $\\mathcal{M}$ is called irreducible if the von Neumann algebra $W^*(T)$ generated by $T$ has trivial relative commutant, i.e., $W^*(T)'\\cap\\mathcal{M}=\\mathcal{Z}(\\mathcal{M})$. In this paper, we show that irreducible operators in $\\mathcal{M}$ form a norm-dense $G_\\delta$ set, which is a generalization of Halmos' theorem. Moreover, we prove that every operator in $\\mathcal{M}$ is the sum of two irreducible operators, which is an analogue of Radjavi's theorem.",
    "authors": [
      "Sukitha Adappa",
      "Minghui Ma",
      "Junhao Shen",
      "Rui Shi",
      "Shanshan Yang"
    ],
    "primary_category": "math.OA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03452",
    "title": "A fast stochastic interacting particle-field method for 3D parabolic parabolic Chemotaxis systems: numerical algorithms and error analysis",
    "abstract": "In this paper, we develop a novel numerical framework, the stochastic interacting particle-field method with particle-in-cell acceleration (SIPF-PIC), for the efficient simulation of the three-dimensional (3D) parabolic-parabolic Keller-Segel (KS) systems. The SIPF-PIC method integrates Lagrangian particle dynamics with spectral field solvers, by leveraging localized particle-grid interpolations and fast Fourier transform (FFT) techniques. For $P$ particles and $H$ Fourier modes per spatial dimension, the SIPF-PIC method achieves a computational complexity of $\\mathcal{O}(P + H^3 \\log H)$ per time step, a significant improvement over the original SIPF method (proposed in \\cite{SIPF1}), which has a complexity of $\\mathcal{O}(PH^3)$, while preserving numerical accuracy. Moreover, we establish a rigorous error analysis, proving that the discretization errors are of order $\\mathcal{O}(H^{-16/13}+P^{-1/2}H^{4/13})$. Finally, we present numerical experiments to validate the theoretical convergence rates and demonstrate the computational efficiency of our new method. Notably, these experiments also show that the method captures complex blowup dynamics beyond single-point collapse, including ring-type singularities, where mass dynamically concentrates into evolving annular structures.",
    "authors": [
      "Jingyuan Hu",
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03455",
    "title": "Solutions to Open WDVV Equations for the Universal Whitham Hierarchy",
    "abstract": "In this paper, we construct a pair of solutions to the open WDVV equations associated with the infinite-dimensional Frobenius manifolds that underlie the genus-zero universal Whitham hierarchy, and for the resulting flat F-manifolds, we explicitly construct their principal hierarchies. We further demonstrate that this construction is compatible with finite-dimensional reductions, yielding solutions for Frobenius manifolds associated with general rational superpotentials and those subject to a $\\mathbb{Z}_{2}$-symmetry reduction. In particular, the polynomial solutions derived by Basalaev and Buryak via open Saito theory for A- and D-type singularities are recovered as special cases.",
    "authors": [
      "Shilin Ma"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03468",
    "title": "Cyclotomic Congruences and Lucas Sequences",
    "abstract": "In this paper, we extend the $p$-adic valuations originally obtained by Carmichael for the sequences obtained by applying Möbius inversion to Lucas sequences to $p$-adic congruences, from which we immediately derive corresponding congruences for Lucas sequences. As a corollary, we also establish some constraints on the entry point behavior of primes in Lucas sequences, on the basis of which we conjecture the presence of a strong Chebyshev-like bias in real regular Lucas sequences.",
    "authors": [
      "Tyler Ross",
      "Zhongyan Shen",
      "Tianxin Cai"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03469",
    "title": "The magnetic inverse problem for two stacked layers of sources",
    "abstract": "We present calculations that reconstruct electronic current densities in two stacked layers at known depths, using magnetic field data. Solving this inverse problem requires knowledge of the magnetic field in two planes -- one above both current layers, one below -- corresponding to non-invasive measurements of the field. We corroborate the accuracy of current density reconstruction from the resulting system of equations using a numerical simulation. This method is anticipated to be applicable to non-destructive current imaging for quality assurance in a range of applications featuring two-layer geometries, including printed circuit boards, capacitors, fuel cells, and battery cells; we focus particularly here on battery cells, due to their rapidly increasing relevance for automotive applications. This method also offers a framework for generalising the model to more than two layers in future work.",
    "authors": [
      "Michael T. M. Woodley",
      "Thomas Coussens",
      "William Evans",
      "Matthew Withers",
      "Leigh Page",
      "Daniel Nightingale",
      "Denilson Nicolau",
      "Gary Kendall",
      "Fedja Orucevic",
      "Peter Kruger"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03480",
    "title": "On stationary real matrix Schubert varieties",
    "abstract": "In this paper, we study when a real matrix Schubert variety is stationary with respect to the first variation. We first show that a necessary condition for its open dense regular part to be a minimal submanifold is that the corresponding partial permutation is vexillary. Among vexillary partial permutations, we establish minimality by a geometric argument when the Rothe diagram is of Grassmannian type and has at most two connected components. We further obtain, as a corollary, the minimality of those varieties that decompose as products of this type. These varieties include all determinantal varieties as well as some new minimal cones.",
    "authors": [
      "Jaehoon Lee",
      "Sangwoo Park",
      "Eungbeom Yeon"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03481",
    "title": "The $p$-adic Valuations of Möbius Duals of Lucas Sequences",
    "abstract": "In this paper, we extend the $p$-adic valuations of the Möbius duals of Lucas sequences, originally obtained by Carmichael for regular Lucas sequences to irregular Lucas sequences. We conclude with a brief observation about the relationship of these valuations to the existence of Wall-Sun-Sun primes.",
    "authors": [
      "Tyler Ross",
      "Zhongyan Shen",
      "Tianxin Cai"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03482",
    "title": "Kakeya-Nikodym norms of Maass forms on $\\rm{U}(2,1)$",
    "abstract": "Let $\\psi$ be a Hecke-Maass form with a large spectral parameter on a compact arithmetic complex hyperbolic surface. We apply the amplification method to obtain a power saving over the trivial bound for the Kakeya-Nikodym norm of $\\psi$. As a consequence, we obtain power savings over the local bound of Sogge for $\\|\\psi\\|_p$ when $2<p<10/3$.",
    "authors": [
      "Jiaqi Hou"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03483",
    "title": "Numerical Analysis of the 2D Stochastic Navier-Stokes Equations: Convergence under Transport Noise and No-slip Boundary Conditions",
    "abstract": "This work is concerned with the numerical approximation of the two-dimensional stochastic Navier-Stokes equation with transport noise and no-slip boundary conditions on a convex polygonal domain. The analysis is challenged by the solution's low spatial regularity and the non-Lipschitz nonlinearity. We derive a convergence rate in the mean-square sense for a spatial semidiscretization. Furthermore, for the full discretization, we prove convergence in probability and establish an explicit rate with respect to the time step.",
    "authors": [
      "Binjie Li",
      "Qin Zhou"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03488",
    "title": "Arithmetic invariants of Euclidean lattice",
    "abstract": "In this paper we study the arithmetic invariants of Euclidean lattice in the context of Arakelov geometry. We regard a Euclidean lattice as a hermitian vector bundle $\\bar E$ on ${\\rm Spec}(\\mathbb{Z})$ and consider two typical arithmetic analogues of the dimension of the space of global sections of a vector bundle on an algebraic curve. One is $$h^0_{\\rm Ar}(\\bar E):=\\log \\vert E\\cap B_1 \\vert$$ where $B_1$ is the unit ball, and the other is $$h^0_{\\theta}(\\bar{E}):=\\log\\sum_{v\\in E}e^{-\\pi\\Vert v\\Vert^2}$$ where $\\sum_{v\\in E}e^{-\\pi\\Vert v\\Vert^2}$ is the theta function of $\\bar E$. In this paper, we shall prove the following three statements: (i) the fact that one can not reach an absolute Riemann-Roch theorem for $h^0_{\\rm Ar}(\\bar E)$ is an instance of the Heissenberg uncertainty principle; (ii) the finiteness of equivalence classes in the genus of a positive quadratic form defined over $\\mathbb{Z}$ is equivalent to the finiteness of certain isometry classes of hermitian vector bundles on ${\\rm Spec}(\\mathbb{Z})$, and it can be deduced from a finiteness theorem in Arakelov theory of ${\\rm Spec}(\\mathbb{Z})$; (iii) for any smooth function $f$ on $\\mathbb{R}_{+}$ such that $f>0$ and that $f\\circ {\\rm exp}$ is a Schwartz function on $\\mathbb{R}$, the Mellin transform of $f$ can be written as an integral over the Arakelov divisor class group of ${\\rm Spec}(\\mathbb{Z})$.",
    "authors": [
      "Shun Tang"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03489",
    "title": "Optimal Hypercontractivity and Log--Sobolev inequalities on Cyclic Groups $\\mathbb{Z}_{m\\cdot 2^k}$",
    "abstract": "For $1<p\\le q<\\infty$ and $n\\in\\{3\\cdot 2^{k},2^{k}\\}$ with $k\\ge 1$, we prove that the Poisson-like semigroup $(P_t)_{t\\in \\mathbb{R}_+}$ on $\\mathbb{Z}_n$, associated with the word length $\\psi_n(k)=\\min(k,n-k)$, is hypercontractive from $L_p$ to $L_q$ if and only if $t\\ge \\tfrac{1}{2}\\log\\big(\\tfrac{q-1}{p-1}\\big)$. We establish sharp Log--Sobolev inequalities with the optimal constant $2$, by performing a KKT analysis, and lifting from the base cases $\\mathbb{Z}_6$ and $\\mathbb{Z}_4$ via a Cooley--Tukey $n\\mapsto 2n$ comparison of Dirichlet forms. The general case for arbitrary $n$ remains open.",
    "authors": [
      "Gan Yao"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03490",
    "title": "Counting rational points on affine hypersurfaces",
    "abstract": "We prove an upper bound for the number of rational points of bounded height on irreducible affine hypersurfaces. More precisely, given an irreducible polynomial $f \\in \\mathbb{Z}[X_1, \\dots, X_n]$, we prove an upper bound on the number of points $(x_1, \\dots, x_n) \\in \\mathbb{Q}^n$ such that $f(x_1, \\dots, x_n) = 0$ and each component has height at most $B$. To prove this, we require a quantitative form of Hilbert's irreducibility theorem, where we bound the number of reducible specialisations of an irreducible polynomial at rational points of bounded height.",
    "authors": [
      "Anders Mah"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03496",
    "title": "Constraint-Preserving High-Order Compact OEDG Method for Spherically Symmetric Einstein-Euler System",
    "abstract": "Numerical simulation of the spherically symmetric Einstein--Euler (EE) system faces severe challenges due to the stringent physical admissibility constraints of relativistic fluids and the geometric singularities inherent in metric evolution. This paper proposes a high-order Constraint-Preserving (CP) compact Oscillation-Eliminating Discontinuous Galerkin (cOEDG) method specifically tailored to address these difficulties. The method integrates a scale-invariant oscillation-eliminating mechanism [M. Peng, Z. Sun, K. Wu, Math. Comp., 94: 1147--1198, 2025] into a compact Runge--Kutta DG framework. By characterizing the convex invariant region of the hydrodynamic subsystem with general barotropic equations of state, we prove that the proposed scheme preserves physical realizability (specifically, positive density and subluminal velocity) directly in terms of conservative variables, thereby eliminating the need for complex primitive-variable checks. To ensure the geometric validity of the spacetime, we introduce a bijective transformation of the metric potentials. Rather than evolving the constrained metric components directly, the scheme advances unconstrained auxiliary variables whose inverse mapping automatically enforces strict positivity and asymptotic bounds without any limiters. Combined with a compatible high-order boundary treatment, the resulting CPcOEDG method exhibits robust stability and design-order accuracy in capturing strong gravity-fluid interactions, as demonstrated by simulations of black hole accretion and relativistic shock waves.",
    "authors": [
      "Yuchen Huang",
      "Manting Peng",
      "Kailiang Wu"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03498",
    "title": "Arithmetic progressions in sumsets of geometric progressions",
    "abstract": "If $a$ and $b$ are integers with $b>a>1$, we completely characterize ``long'' arithmetic progressions in the sumsets of the geometric progressions $1, a, a^2, a^3, \\ldots$ and $1, b, b^2, b^3, \\ldots$. Our proofs utilize recent applications of bounds for linear forms in logarithms to $S$-unit equations, and consequences of the modularity of Frey-Hellegouarch curves, together with elementary arguments.",
    "authors": [
      "Michael A. Bennett"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03504",
    "title": "Optical Caustics as Lagrangian Singularities: Classification and Geometric Structure",
    "abstract": "This paper develops a rigorous mathematical framework for light propagation by constructing the optical phase space with its symplectic structure and the extended phase space with its contact structure. We prove that light rays in three-dimensional Euclidean space correspond to Reeb orbits in a five-dimensional contact manifold, which are then projected onto a four-dimensional symplectic manifold via symplectic reduction. Leveraging the advantages of phase space, we provide a rigorous definition of caustic surfaces as singularities of the Lagrangian submanifold projection and derive explicit expressions for caustic surfaces in convex lens systems. Furthermore, based on singularity theory, we present a complete classification of stable caustic surfaces and establish a correspondence with classical Seidel aberration theory. Building upon this theory, we propose a method of \\emph{topological optical correction} that overcomes the limitations of traditional optimization algorithms in dealing with complex caustic structures. This work provides a new mathematical paradigm for the design and correction of high-precision optical systems.",
    "authors": [
      "Rongqi Shang",
      "Donglin Ma"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03511",
    "title": "Magnetic Equivariant Graded Brauer Group",
    "abstract": "Given a magnetic finite group, we consider the similarity classes of magnetic equivariant central simple graded algebras over the complex numbers. We call this set the magnetic equivariant graded Brauer group and its structure as an abelian group is explicitly determined. Following Karoubi, we argue that the elements of this graded Brauer group parametrize the twistings of the magnetic equivariant K-theory of a point.",
    "authors": [
      "Higinio Serrano",
      "Bernardo Uribe"
    ],
    "primary_category": "math.KT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03515",
    "title": "Effective SPR property for surface diffeomorphisms and three-dimensional vector fields",
    "abstract": "In this paper, we prove that ergodic measures with large entropy give uniformly large measure to the set of points with simultaneously long unstable and long stable manifolds. As a consequence, for $C^{\\infty}$ surface diffeomorphisms, we establish an effective version of the SPR property. For $C^{\\infty}$ three-dimensional flows without singularities, we prove the finiteness of equilibrium measures for admissible potentials whose variation is strictly less than half of the topological entropy.",
    "authors": [
      "David Burguet",
      "Chiyi Luo",
      "Dawei Yang"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03516",
    "title": "Mean-Square Stability of Continuous-Time Stochastic Model Predictive Control",
    "abstract": "We propose a stochastic model predictive control (SMPC) framework for a broad class of unconstrained controlled stochastic differential equations (SDEs) and establish its mean-square exponential stability in the infinite-horizon limit. At each prediction step of the MPC iteration, the nonlinear controlled SDE is approximated by its linearization at the origin, with the sampled state of the nonlinear system as initial condition, yielding a finite-horizon stochastic linear-quadratic (SLQ) optimal control problem. The resulting optimal control is then applied to the original nonlinear stochastic dynamics until the next sampling instant. This construction leads to a delayed SMPC scheme whose closed-loop behavior is governed by a coupled time-delay SDE system, a setting that has not been analyzed before. We prove global mean-square exponential stability for linear and mildly nonlinear SDEs by exploiting the exponential convergence of the Riccati equation to the algebraic Riccati equation (ARE). For strongly nonlinear SDEs, we establish local mean-square exponential stability by combining exponential Riccati convergence with stopping-time techniques and Grönwall-type estimates. It is observed that, to ensure the desired local stability properties, the nonlinearities of the SDE are allowed to have polynomial growth but not exponential growth, distinguishing SMPC from its deterministic counterpart. These results provide the first rigorous mean-square stability guarantees for SMPC of SDE systems with delayed state information, thereby advancing the theoretical foundations of stochastic predictive control.",
    "authors": [
      "Qi Lü",
      "Bowen Ma",
      "Enrique Zuazua"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03518",
    "title": "From Reliability to Security: How RIS-Assisted Adaptive SM and SSK Enhances Wireless Systems",
    "abstract": "This paper proposes two novel wireless transmission schemes, namely reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme and RIS-assisted received adaptive space shift keying (RASSK) scheme, designed to enhance spectral efficiency (SE) and physical layer security (PLS).In both proposed schemes, transmitting bits are dynamically mapped at receive antennas by leveraging the characteristics of the RIS in each time slot, which enables the enhancement of signal-to-noise ratio (SNR) at specific selected antennas with near few power, thus leading a reliable and green wireless communication. This adaptive approach facilitates the conveyance of extra bits to the receiver, which means it needs less cost of radio-frequency chains at transmitter while improving SE. Besides, the proposed schemes offer an inherent PLS security advantage, as the eavesdropper is unable to completely detect signals reflected from the RIS. To comprehensively evaluate the performance of the proposed RASM and RASSK schemes, this paper presents a detailed analytical performance of their spectral efficiency, detection complexity, bit error rate, and secrecy rate, which are accompanied by insightful findings and conclusions. Simulation and analytical results demonstrate the superiority of the proposed schemes, showcasing their improved error performance and robustness against wiretapping, while also highlighting the potential of the RASM and RASSK schemes for future wireless applications.",
    "authors": [
      "Chaorong Zhang",
      "Benjamin K. Ng",
      "Ke Wang",
      "Hui Xu",
      "Chan-Tong Lam"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03524",
    "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities",
    "abstract": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.",
    "authors": [
      "Grzegorz Jamróz",
      "Rafał Kucharski",
      "David Watling"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03527",
    "title": "Endomorphisms of rank one Gorenstein del Pezzo surfaces",
    "abstract": "We prove that, in all except one case, a Gorenstein del Pezzo surface of Picard rank 1 admits an int-amplified endomorphism if and only if it is a quotient of a toric variety by a finite group which acts freely in codimension one and preserves the open torus. We classify all such quotients.",
    "authors": [
      "Rohan Joshi"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03535",
    "title": "Leader-Follower Mean Field LQG Games with Multiplicative Noise",
    "abstract": "This paper studies open-loop and feedback solutions to leader-follower mean field linear-quadratic-Gaussian games with multiplicative noise by the direct approach. The leader-follower game involves a leader and many followers, where the state and control weight matrices in their costs are not limited to be positive definite. From variational analysis with mean field approximations, we obtain a set of open-loop controls in terms of solutions to mean field forward-backward stochastic differential equations. By applying the matrix maximum principle, a set of decentralized feedback strategies is constructed. Distinct from traditional works, a cross term has appeared in derivation due to the presence of mean field terms. For open-loop and feedback solutions, the corresponding optimal costs of all players are explicitly given in terms of the solutions to two Riccati equations, respectively.",
    "authors": [
      "Bing-Chang Wang",
      "Huanshui Zhang",
      "Ji-Feng Zhang"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03544",
    "title": "The simplicity of complexity: a story of mathematical outreach",
    "abstract": "Mathematics is often perceived as difficult or inaccessible, yet meaningful engagement can arise in unexpected places. In this article we describe a multi-year exploration of mathematical outreach through games, puzzles, exhibitions, and artistic activities. Starting from a small science festival exhibit, our work developed into a broad collection of experiences showcased at game festivals, museums, and the World Expos in Dubai (2021/2022) and Osaka (2025). We discuss the principles that shaped these activities -- simplicity, atmosphere, mediation, and progressive depth -- and how mathematical ideas from topology, geometry, and logic can be incorporated into playful and creative formats. The story illustrates how low-threshold engagement and carefully designed experiences can open doors to research-level mathematics for audiences of all ages and backgrounds.",
    "authors": [
      "Hugo Parlier",
      "Bruno Teheux"
    ],
    "primary_category": "math.HO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03547",
    "title": "Learning-Based Hierarchical Approach for Fast Mixed-Integer Optimization",
    "abstract": "We propose a hierarchical architecture for efficiently computing high-quality solutions to structured mixed-integer programs (MIPs). To reduce computational effort, our approach decouples the original problem into a higher level problem and a lower level problem, both of smaller size. We solve both problems sequentially, where decisions of the higher level problem become parameters of the constraints of the lower level problem. We formulate this learning task as a convex optimization problem using decision-focused learning techniques and solve it by differentiating through the higher and the lower level problems in our architecture. To ensure robustness, we derive out-of-sample performance guarantees using conformal prediction. Numerical experiments in facility location, knapsack problems, and vehicle routing problems demonstrate that our approach significantly reduces computation time while maintaining feasibility and high solution quality compared to state-of-the-art solvers.",
    "authors": [
      "Stefan Clarke",
      "Bartolomeo Stellato"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03554",
    "title": "A simple algebraic proof of the non-transitivity of the braid group action on full exceptional sequences",
    "abstract": "Recently, Chang--Haiden--Schroll shows that the braid group action on full exceptional collections in a triangulated category is not transitive but has infinitely many orbits in general. Their proof is based on a geometric model and the theory of branched coverings such as Birman--Hilden theory. This paper provides a simple algebraic proof of their theorem.",
    "authors": [
      "Atsuki Nakago",
      "Atsushi Takahashi"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03557",
    "title": "Parameters Optimization in Trajectory Planning Using Diffrentiable Convex Programing",
    "abstract": "Sequential convex programming has been established as an effective framework for solving nonconvex trajectory planning problems. However, its performance is highly sensitive to problem parameters, including trajectory variables, algorithmic hyperparameters, and physical vehicle parameters. This paper introduces a differentiable sequential convex programming framework that integrates differentiable convex optimization with sequential convex programming to enable end-to-end parameter optimization. By deriving first-order sensitivity relations of second-order cone programming solutions with respect to problem data, exact gradients of trajectory performance metrics with respect to arbitrary parameters are obtained and propagated through iterations. The effectiveness of the proposed framework is validated through three representative applications: optimal terminal-time prediction for powered landing, trust-region penalty optimization in subproblems, and surface-to-mass ratio optimization for hypersonic gliding vehicles. Simulation results show that the proposed framework enables reliable gradient-based parameter learning and significantly improves numerical performance, convergence behavior, and design efficiency. These results indicate that differentiable sequential convex programming framework provides a powerful and general tool for vehicle design, mission optimization, and hyperparameter selection in aerospace trajectory planning.",
    "authors": [
      "Ziqi Xu",
      "Lin Cheng",
      "Shengping Gong"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03562",
    "title": "A hybrid large neighborhood search algorithm for the integrated dial-a-ride problem using electric vehicles",
    "abstract": "Integrating demand-responsive mobility services with transit systems is recognized as a practical and effective strategy to mitigate their impact on traffic congestion and the environment. This study develops an efficient hybrid metaheuristic to solve the integrated dial-a-ride problem by utilizing electric vehicles to minimize operational costs and customer travel time. Customer transfer inconvenience is restricted by a maximum intermodal transfer time to synchronize demand-responsive buses' arrival and transit departures. The proposed metaheuristic addresses the challenges of integrating demand-responsive vehicle routing and charging operations with fixed-route transit systems with capacitated charging stations and partial recharge. We benchmarked our algorithm against a state-of-the-art mixed-integer programming solver on instances with 10-50 customers and two transit lines. Our approach achieves solutions that are, on average, 23.8% better in solution quality within around 2 minutes, outperforming those obtained by the solver using an 8-hour computational time limit. We evaluate the impact of various system parameters to bridge the gap between theory and practice. The results suggest that, from the operator's perspective, while the integrated dial-a-ride service reduces vehicle kilometers traveled, the used fleet size may not necessarily be reduced when ensuring high-quality service for passengers. Moreover, operating the integrated systems is more beneficial in areas with dense transit networks, compared with increases in transit frequency. The findings provide valuable insights for developing integrated dial-a-ride services in practice.",
    "authors": [
      "Yumeng Fang",
      "Tai-Yu Ma"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03572",
    "title": "Global embeddings of weakly pseudoconvex complex spaces and refined approximation theorems",
    "abstract": "In this paper, by refining approximation theorems for holomorphic sections of adjoint line bundles, it is proved that the regular locus of a weakly pseudoconvex complex space admitting a positive line bundle can be embedded into a complex projective space. As an application of approximation theorems, it is shown that the Union problem can be solved for weakly pseudoconvex complex manifolds.",
    "authors": [
      "Yuta Watanabe"
    ],
    "primary_category": "math.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03573",
    "title": "The quantum Gromov-Hausdorff Hypertopology on the class of pointed Proper Quantum Metric Spaces",
    "abstract": "We introduce a hypertopology, induced by an inframetric up to full quantum isometry, on the class of pointed proper quantum metric spaces, which are separable, possibly non-unital, C*-algebras endowed with an analogue of the Lipschitz seminorm, with a distinguished state, and with a particular type of approximate units. Our hypertopology provides an analogue of the Gromov-Hausdorff distance on proper metric spaces, and in fact, convergence in the latter implies convergence in the former. Moreover, when restricted to the class of quantum compact metric spaces, our new topology is compatible with the topology of the Gromov-Hausdorff propinquity. We include new examples of noncompact, noncommutative pointed proper quantum metric spaces which are limits, for our new topology, of finite dimensional quantum compact metric spaces. This article thus provides a first answer to the challenging question of how to extend noncommutative metric geometry to the locally compact quantum space realm.",
    "authors": [
      "Frederic Latremoliere"
    ],
    "primary_category": "math.OA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03576",
    "title": "Upside down and backwards",
    "abstract": "We investigate the semigroup of invariant types through the lens of Ellis theory; primarily focusing on definably amenable NIP groups. In this context, we observe that the collection of strong right $f$-generic types forms the unique minimal left ideal and thus, the Ellis subgroups are isomorphic to $G/G^{00}$ via the canonical quotient map. As consequence of the Newelski-Pillay conjecture, the Ellis subgroups of the semigroup of invariant types are abstractly isomorphic to the Ellis subgroups of the semigroup of finitely satisfiable types in the definable amenable NIP setting. We are interested in the existence of natural isomorphisms from invariant Ellis subgroups to finitely satisfiable Ellis subgroups and we determine when these isomorphisms can be witnessed by variants of the canonical NIP retraction map. Several limiting examples are provided. Outside of the NIP context, we provide an abelian group (and thus definably amenable) with an $\\emptyset$-definable (dfg) type in which the invariant Ellis subgroups and finitely satisfiable Ellis subgroups not isomorphic.",
    "authors": [
      "Kyle Gannon",
      "Tomasz Rzepecki"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03586",
    "title": "A Coupled IMEX Domain Decomposition Method for High-Order Time Integration of the ES-BGK Model of the Boltzmann Equation",
    "abstract": "In this paper, we propose a high-order domain decomposition method for the ES-BGK model of the Boltzmann equation, which dynamically detects regions of equilibrium and non-equilibrium. Our implementation automatically switches between Euler equations in regions where the fluid is at equilibrium, and the ES-BGK model elsewhere. The main challenge addressed in this work is the development of a coupled strategy between the macroscopic and the kinetic solvers, which preserves the overall temporal order of accuracy of the scheme. A coupled IMEX method is introduced across decomposed subdomains and solvers. This approach is based on a coupled IMEX method and allows high accuracy and computational efficiency. Several numerical simulations in two space dimensions are performed, in order to validate the robustness of our approach and the expected temporal high-order convergence.",
    "authors": [
      "Domenico Caparello",
      "Tommaso Tenna"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03587",
    "title": "The Dirichlet-to-Neumann map on asymptotically anti-de Sitter spaces and holography",
    "abstract": "We consider the Klein-Gordon equation on asymptotically anti-de Sitter spacetimes, and show that the forward Dirichlet-to-Neumann map (or scattering matrix) is a fractional power of the boundary wave operator modulo lower order terms in the sense of paired Lagrangian distributions. We use it to show that, outside of a countable set of mass parameters, the Dirichlet-to-Neumann map determines the Taylor series of the bulk metric at the boundary, and hence allows the recovery of a real analytic metric or Einstein metric modulo isometries. Furthermore, we prove a Lorentzian version of the Graham-Zworski theorem relating poles of the Dirichlet-to-Neumann map to conformally invariant powers of the boundary wave operator.",
    "authors": [
      "Alberto Enciso",
      "Gunther Uhlmann",
      "Michał Wrochna"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03595",
    "title": "Dynamics of the reversible Gray-Scott model and convergence to its irreversible limit",
    "abstract": "Well-posedness of a reversible variant of the Gray-Scott model is shown, along with the convergence of each trajectory to one of the two spatially homogeneous steady states. The principle of linearized stability provides the local attractivity at an exponential rate of the stable steady state, while the long-term limit is identified with the help of center manifold theory. Finally, convergence to the classical Gray-Scott model is proved for an appropriate choice of parameters.",
    "authors": [
      "Philippe Laurençot",
      "Christoph Walker"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03599",
    "title": "Lattice-like Packings and Coverings with Congruent Translation Balls and Cylinders in Sol geometry",
    "abstract": "The aim of this paper is to study lattice-like coverings with congruent translation balls and the packings and coverings with a type of translation cylinders in Sol space related to the fundamental lattices. We introduce the notions of the densities of the considered problems and give upper estimate to ball coverings using the radii and the volumes of the circumscribed translation spheres of given {\\it translation tetrahedra}. Moreover we determine the exact optimal packing and covering densities of a type of cylinder packings belonging to the fundamental lattices.",
    "authors": [
      "Judit Sajtos",
      "Jenő Szirmai"
    ],
    "primary_category": "math.MG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03612",
    "title": "Expected Confidence Dependency: A Novel Rough Set-Based Approach to Feature Selection",
    "abstract": "This paper proposes Expected Confidence Dependency (ECD), a novel, soft computing-oriented, accuracy driven dependency measure for feature selection within the rough set theory framework. Unlike traditional rough set dependency measures that rely on binary characterizations of conditional blocks, ECD assigns confidence-based contributions to individual equivalence blocks and aggregates them through a normalized expectation operator. We formally establish several desirable properties of ECD, including normalization, compatibility with classical dependency, monotonicity, and invariance under structural and label-preserving transformations.",
    "authors": [
      "Saeed Rasouli",
      "Hamid Karamikabir"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03617",
    "title": "Kähler-Einstein toric submanifolds of the projective space",
    "abstract": "We show that the Kähler-Einstein metrics on the four families of examples of symmetric toric Fano manifolds presented by Batyrev and Selivanova cannot be realized as metrics induced by immersions into projective spaces equipped with Fubini-Study metrics. We obtain a similar conclusion for the non-symmetric examples discovered by Nill and Paffenholz. A consequence is that a centrally symmetric toric Fano manifold admits a Kähler-Einstein metric induced by a projective immersion if and only if it is a product of projective lines. These results provide evidence for a broader conjecture characterizing which Kähler-Einstein metrics can be induced by projective immersions.",
    "authors": [
      "Antonio J. Di Scala",
      "Martín Sombra"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03624",
    "title": "Elastic scattering problems by penetrable obstacles with embedded objects",
    "abstract": "This paper considers 3-D elastic scattering problems by penetrable obstacles with embedded objects. The well-posedness of transmission problem is proved by employing integral equation method. Then the Inverse Problems , which is to recover the obstacle by the far-field pattern measurement, is considered. It is shown that the inhomogeneous penetrable obstacle can be uniquely determined from the far-field pattern at a fixed frequency.",
    "authors": [
      "Chun Liu",
      "Jiaqing Yang",
      "Bo Zhang"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03626",
    "title": "A Gradient Method for Risk Averse Control of a PDE-SDE Interconnected System",
    "abstract": "In this paper, we design a risk-averse controller for an interconnected system composed of a linear Stochastic Differential Equation (SDE) actuated through a linear parabolic heat equation. These dynamics arise in various applications, such as coupled heat transfer systems and chemical reaction processes that are subject to disturbances. While existing optimal control methods for these systems focus on minimizing average performance, this risk-neutral perspective may allow rare but highly undesirable system behaviors. To account for such events, we instead minimize the cost within a coherent risk measure. Our approach reformulates the coupled dynamics as a stochastic PDE, approximates it by a finite-dimensional SDE system, and applies a gradient-based method to compute a riskaverse feedback controller. Numerical simulations show that the proposed controller substantially reduces the tail of the cost distribution, improving reliability with only a minor reduction in average performance.",
    "authors": [
      "Gabriel Velho",
      "Jean Auriol",
      "Riccardo Bonalli"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03628",
    "title": "Tridiagonal random matrices, an analytic approach",
    "abstract": "In this paper, we study the limiting distribution of the eigenvalues for random tridiagonal matrix models. The limiting distribution is well described by its moments. Here, an analytical approach allows us, as in the case of Wigner matrices, to relax the assumptions on the random variables. With this method, we proved the convergence of the spectral distribution under an assumption on the second moment. We discuss also about an algebraic approach for the tridiagonal models, which are more complicated than the classic freeness.",
    "authors": [
      "Lucas Babet",
      "Ionel Popescu"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03629",
    "title": "Spectral properties of the deformed Laplacian matrix of trees and H-join graphs",
    "abstract": "This paper investigates spectral properties of the deformed Laplacian matrix, which merges the Laplacian and signless Laplacian matrices of a graph through a one-parameter family of matrices. We present general results on the eigenvalues of these matrices for simple undirected graphs. Additionally, we analyze the spectrum of the deformed Laplacian in the specific cases of trees and H-join graphs. For trees, we derive strong results on the localization of eigenvalues, while for H-join graphs, we explicitly compute the spectrum of the deformed Laplacian.",
    "authors": [
      "Roberto C. Díaz",
      "Elismar R. Oliveira",
      "Vilmar Trevisan"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03631",
    "title": "A Decay estimate for cubic defocusing non-linear Schrödinger equation in three dimensions",
    "abstract": "In this short note, we prove a decay estimate for non-linear solutions of 3D cubic defocusing non-linear Schrödinger equation.",
    "authors": [
      "Yi Sun"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03632",
    "title": "Three-dimensional modelling of drag anchor penetration using the material point method",
    "abstract": "Drag embedment anchors are a key threat to buried subsea linear infrastructure, such as power/data cables and pipelines. For cables, selecting a burial depth is a compromise between protecting the cable from anchor strike and the increased cost of deeper installation. This presents an efficient large deformation, elasto-plastic Material Point Method-based soil-structure interaction predictive tool for the estimation of anchor penetration based on Cone Penetration Test (CPT) site investigation data. The tool builds on earlier work by the authors supplemented by three developments: modelling assemblies of rigid bodies (necessary for articulated anchors), a partitioned domain approach to enable accurate and efficient modelling of long anchor pulls and an improved means of modelling rotational inertia. The tool is validated against scaled physical tests conducted in a geotechnical centrifuge on sands with a range of relative densities with good agreement across the tested conditions. Numerical simulations identify key issues with the UK Cable Burial Risk Assessment (CBRA) approach for estimating anchor penetration and reveal the potentially non-conservatism of the CBRA framework for sandy seabeds. The numerical model enables site-specific anchor-penetration assessment along cable routes and can be used to evaluate the performance of different anchor designs and sizes in varied soil conditions.",
    "authors": [
      "Robert E. Bird",
      "William M. Coombs",
      "Michael J. Brown",
      "Charles E. Augarde",
      "Yaseen U. Sharif",
      "Giuliano Pretti",
      "Catriona Macdonald",
      "Duncan Stevens",
      "Gareth Carter"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03633",
    "title": "A Stone-Weierstrass approximation theorem for monotone functions",
    "abstract": "We present an approximation theorem for continuous non-decreasing functions on compact preordered spaces, leading to an algebraic characterization of their corresponding function spaces. As an application, we prove that the family of positive non-decreasing rational functions with non-negative coefficients can uniformly approximate all continuous non-decreasing functions on compact intervals. An explicit approximation formula of this type is provided.",
    "authors": [
      "Ettore Minguzzi"
    ],
    "primary_category": "math.FA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03638",
    "title": "Hyperbolicity properties of moduli spaces of marked hyperk{ä}hler manifolds",
    "abstract": "We study the hyperbolicity properties of moduli spaces of marked hyperk{ä}hler manifolds along directions corresponding to families having positivity properties for their Hodge bundle. In particular, we show that the Kobayashi pseudo-distance computed using disks tangent to these directions vanishes. As an intermediate step, we establish the existence of families of marked hyperk{ä}hler manifolds over arbitrary curves having a prescribed period map to the corresponding period domain. This generalizes a recent theorem of Greb and Schwald [GS24] to the case of hyperk{ä}hler manifolds of arbitrary dimensions and nonnecessarily compact curves. Finally, using Nevanlinna theory, we establish restrictions on families of hyperk{ä}hler manifolds over C having positive Hodge bundle.",
    "authors": [
      "Bastien Philippe"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03646",
    "title": "A dynamic competitive equilibrium model of irreversible capacity investment with stochastic demand and heterogeneous producers",
    "abstract": "We formulate a continuous-time competitive equilibrium model of irreversible capacity investment in which a continuum of heterogeneous producers supplies a single non-durable good subject to exogenous stochastic demand. Each producer optimally adjusts both output and capacity over time in response to endogenous price signals, while investment decisions are irreversible. Market clearing holds continuously, with prices evolving endogenously to balance aggregate supply and demand through a constant-elasticity demand function driven by a stochastic base component. The model admits a mean-field interpretation, as each producer's decisions both influence and are influenced by the aggregate behaviour of all others. We show that the equilibrium price process can be expressed as a nonlinear functional of the exogenous base demand, leading to a three-dimensional singular stochastic control problem for each producer. We derive an explicit solution to the associated Hamilton-Jacobi-Bellman equation, including a closed-form characterisation of the free-boundary surface separating investment and waiting regions.",
    "authors": [
      "Constantinos Kardaras",
      "Alexandros Pavlis",
      "Mihail Zervos"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03648",
    "title": "Condensed Group Cohomology",
    "abstract": "Condensed mathematics as developed by Clausen and Scholze yields a version of derived functors over the category of continuous $G$-modules for a Hausdorff topological group $G$. We study the resulting notion of group cohomology and its relation to continuous group cohomology and the condensed/sheaf/singular cohomology of classifying spaces. While condensed group cohomology is generally a more refined invariant than continuous group cohomology, we show that for a broad class of topological groups, continuous group cohomology with solid coefficients, such as locally profinite continuous $G$-modules, can be realized as a derived functor in the condensed setting. We also revisit cornerstones of condensed mathematics, paying special attention to set-theoretic size issues. To this end, we review a framework for working with accessible (hyper)sheaves on large sites satisfying suitable accessibility conditions and show that the associated categories retain many topos-like properties. Moreover, we generalize identifications of condensed with sheaf cohomology obtained by Clausen and Scholze.",
    "authors": [
      "Emma Brink"
    ],
    "primary_category": "math.AT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03650",
    "title": "Convergence analysis of a Crank-Nicolson scheme for strongly magnetized plasmas",
    "abstract": "The present paper is devoted to the convergence analysis of an asymptotic preserving particle scheme designed to serve as a particle pusher in a Particle-In-Cell (PIC) method for the Vlasov equation with a strong inhomogeneous magnetic field. The asymptotic preserving scheme that we study removes classical strong restrictive stability constraints on discretization steps while capturing the large-scale dynamics, even when the discretization is too coarse to capture fastest scales. Our error bounds are explicit regarding the discretization and stiffness parameters and match sharply numerical tests. The present analysis is expected to be representative of the general analysis of a class of schemes, developed by the authors, conceived as implicit-explicit schemes on augmented formulations.",
    "authors": [
      "Francis Filbet",
      "L Miguel Rodrigues",
      "Kim Han Trinh"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03651",
    "title": "Degenerate Poincaré-Sobolev inequalities via fractional integration",
    "abstract": "We present a local weighted estimate for the Riesz potential in $\\mathbb{R}^n$, which improves the main theorem of Alberico, Cianchi, and Sbordone [C. R. Math. Acad. Sci. Paris \\textbf{347} (2009)] in several ways. As a consequence, we derive weighted Poincaré-Sobolev inequalities with sharp dependence on the constants. We answer positively to a conjecture proposed by Pérez and Rela [Trans. Amer. Math. Soc. 372 (2019)] related to the sharp exponent in the $A_1$ constant in the $(p^*,p)$ Poincaré-Sobolev inequality with $A_1$ weights. Our approach is versatile enough to prove Poincaré-Sobolev inequalities for high-order derivatives and fractional Poincaré-Sobolev inequalities with the BBM extra gain factor $(1-\\delta)^{1/p}$. In particular, we improve one of the main results from Hurri-Syrjänen, Martínez-Perales, Pérez, and Vähäkangas [Int. Math. Res. Not. 20 (2023)].",
    "authors": [
      "Alejandro Claros"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03652",
    "title": "On the doubling of variables technique in first order Hamilton-Jacobi equations",
    "abstract": "In this paper, we revisit the technique of doubling variables in first order Hamilton-Jacobi equations, especially when the equations arise in optimal control. We show that by tuning the penalization between the two points, we can change drastically the proof, somehow shifting the regularity hypotheses into geometrical properties of the penalization. We present this idea in a finite dimensional setting and then exploit it on equations posed on Wasserstein spaces.",
    "authors": [
      "Charles Bertucci",
      "Giacomo Ceccherini Silberstein"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03664",
    "title": "$\\mathcal{R}(K_{\\aleph_0}, \\hat{K}_{2,3})$ is a win for Player 1",
    "abstract": "The Strong Ramsey game $\\mathcal{R}(B,G)$ is a two player game with players $P_1$ and $P_2$, where $B$ and $G$ are $k$-uniform hypergraphs for some $k \\geq 2$. $G$ is always finite, while $B$ may be infinite. $P_1$ and $P_2$ alternately color uncolored edges $e \\in B$ in their respective color and $P_1$ begins. Whoever completes a monochromatic copy of $G$ in their own color first, wins the game. If no one claims a monochromatic copy of $G$ in a finite number of moves, the game is declared a draw. For a $t \\in \\mathbb{N}$, let $\\hat{K}_{2,t}$ denote the $K_{2,t}$ together with the edge connecting the two vertices in the partition class of size 2. The purpose of this paper is to give a winning strategy for $P_1$ in the game $\\mathcal{R}(K_{\\aleph_0}, \\hat{K}_{2,3})$.",
    "authors": [
      "Nathan Bowler",
      "Henri Ortmüller"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03670",
    "title": "There exist infinite cube-free words over any sequence of binary alphabets",
    "abstract": "We prove that for any sequence of binary alphabets $\\mathcal{A}_1,\\mathcal{A}_2,\\dots$, there exists a cube-free word $c_1c_2\\dots$ so that $c_1\\in\\mathcal{A}_1,c_2\\in\\mathcal{A}_2,\\dots$. In particular, for every $n$, there are at least $1.35^n$ cube-free words in $\\mathcal{A}_1\\times\\mathcal{A}_2\\times\\dots\\times \\mathcal{A}_n$. We also prove that if the list of alphabets is computable then one of these words is computable and its $n$th letter can be computed in time polynomial in $n$.",
    "authors": [
      "Vuong Bui",
      "Matthieu Rosenfeld"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03679",
    "title": "From Memory Model to CPU Time: Exponential Integrators for Advection-Dominated Problems",
    "abstract": "In this paper, we investigate the application of exponential integrators to advection-dominated problems. We focus on Krylov subspace and Leja interpolation methods to compute the action of exponential and related matrix functions. Complementing our earlier paper, arXiv:2410.12765 (to appear in Advances in Applied Mathematics and Mechanics, 2025) based on a performance model, we extend the numerical investigation to higher-order Krylov approximations and new numerical regime, and assess their CPU-time efficiency relative to explicit Runge--Kutta schemes. We show that, depending on the problem setting, exponential integrators can either outperform or match explicit Runge--Kutta schemes. We also observe that Leja-based methods outperform Krylov iterations for large time steps, whereas for small time steps, Krylov-based methods provide better results than Leja-based methods.",
    "authors": [
      "Thi Tam Dang",
      "Trung Hau Hoang"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03686",
    "title": "Smoluchowski--Kramers Approximation with State-Dependent Friction in Rough Path Topology",
    "abstract": "Smoluchowski-Kramers approximation in rough path topology with state-dependent damping is explored. The second-order Langevin equation has a form of fast-slow system after suitable change-of-variable, and then its solution is lifted as a rough path in a natural manner. Moment estimates of both the original path and the lift are given, followed by which, averaging technique and convergence theorem in rough path topology are used to pass the limit.",
    "authors": [
      "Qingming Zhao",
      "Xueru Liu",
      "Wei Wang"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03699",
    "title": "Transitivity and an abelian Livsic theorem for covers",
    "abstract": "We show that the abelian Livšic theorem recently obtained by A. Gogolev and F. Rodriguez Hertz for null-homologous periodic orbits of homologically full Anosov flows continues to hold when restricted to periodic orbits which are trivial with respect to any regular cover for which the lifted flow is transitive.",
    "authors": [
      "Mark Pollicott",
      "Richard Sharp"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03708",
    "title": "A Lyapunov-based MPC for Distributed Multi Agent Systems with Time Delays and Packet Dropouts using Hidden Markov Models",
    "abstract": "We propose a SCHMM LMPC framework, integrating Semi Continuous Hidden Markov Models with Lyapunov based Model Predictive Control, for distributed optimal control of multi agent systems under network imperfections. The SCHMM captures the stochastic network behavior in real time, while LMPC ensures consensus and optimality via Linear Matrix Inequalities LMIs. The developed optimal control problem simultaneously minimizes three elements. First, the control effort is reduced to avoid aggressive inputs and second, the network induced error caused by time delays and packet dropouts. Third, the topology-induced error, as the distributed graph restricts agents access to global information. This error is inherent to the communication graph and cannot be addressed through offline learning. To overcome this, the study also introduces the incremental Expectation Maximization EM algorithm, enabling online learning of the SCHMM. This adaptation allows the framework to mitigate both network and topology errors while maintaining optimality through MPC. Simulations validate the effectiveness of the proposed SCHMM LMPC, demonstrating adaptability in multi agent systems with diverse topologies.",
    "authors": [
      "Loaie Solyman",
      "Aamir Ahmad",
      "Ayman El-Badawy"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03714",
    "title": "Constructing Lefschetz Fibrations with Arbitrary Slope",
    "abstract": "We prove that for any real number $r\\in (2,8)$, there exists a genus-$g$ Lefschetz fibration over the two-sphere with large enough genus-$g$ having the slope arbitrarily close to $r$. It is known that any genus-$g$ hyperelliptic Lefschetz fibration with only nonseparating vanishing cycles has the slope $4-4/g$. We prove that the converse does not hold by showing that there exists a nonhyperelliptic genus-$g$ Lefschetz fibration with only nonseparating vanishing cycles having slope $4-4/g$.",
    "authors": [
      "Tulin Altunoz",
      "Adalet Cengel"
    ],
    "primary_category": "math.GT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03719",
    "title": "Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing",
    "abstract": "Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.",
    "authors": [
      "Seyed Mohammad Azimi-Abarghouyi",
      "Carlo Fischione",
      "Kaibin Huang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03726",
    "title": "Variational Analysis in the Wasserstein Hierarchy",
    "abstract": "Let $M$ be a complete connected Riemannian manifold. For $n \\geq 0$, we endow the Wasserstein space $P^{(n)}_2(M) = P_2(\\ldots P_2(M)\\ldots)$, equipped with the Wasserstein distance $W_2$, with a variational structure that generalizes the standard variational structure on $P_2(M)$ provided by optimal transport theory. Our approach makes use of tools from category theory to lift the geometric structure of the manifold $M$ to the spaces $P^{(n)}_2(M)$, in order to establish in a principled way a rigorous theoretical framework for variational analysis on the space $P^{(n)}_2(M)$. In particular, we obtain a precise characterization of the constant speed geodesics of the space $P^{(n)}_2(M)$ in terms of optimal velocity plans. Moreover, we introduce a notion of gradient for functionals defined on $P^{(n)}_2(M)$, which allows us to study the differentiability and the convexity of various types of such functionals.",
    "authors": [
      "Christophe Vauthier"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03731",
    "title": "Critical metrics of the volume functional on complete manifolds",
    "abstract": "In this article, we investigate critical metrics of the volume functional on complete manifolds without boundary. We prove that any critical metric of the volume functional on a connected, complete manifold with parallel Ricci tensor is isometric to one of the standard models. Moreover, we show that a Bach-flat critical metric of the volume functional on a complete, simply connected manifold with proper potential function is isometric to one of the following: the standard sphere $\\mathbb{S}^n$, Euclidean space $\\mathbb{R}^n$, hyperbolic space $\\mathbb{H}^n$, or a warped product $\\mathbb{R} \\times_{\\varphi} \\Sigma_c$, where $\\Sigma_c$ is a regular level set of the potential function. In particular, we establish classification results in dimensions three and four under weaker assumptions on the Bach tensor.",
    "authors": [
      "Caio Coimbra",
      "Rafael Diógenes",
      "Ernani Ribeiro Jr"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03732",
    "title": "Strategic Selection of Remanufacturing Business Models: A Consumer Perception Perspective",
    "abstract": "As a key circular economy strategy, remanufacturing allows original equipment manufacturers (OEMs) to reduce waste by restoring used products to ``as-new'' conditions. This paper investigates an OEM's optimal remanufacturing business model by incorporating consumer perceptions into price and production quantity decisions. We analyze three alternative models: no remanufacturing, OEM in-house remanufacturing, and third-party remanufacturer (TPR) authorized remanufacturing. We extend the authorization with a two-part tariff contract and consider a stochastic market size. Through a numerical approach, we optimize price and quantity decisions based on consumer perceptions and develop a hierarchical decision roadmap to guide model selection. Our findings show that when consumer's perceived value of remanufactured products is high, OEM in-house remanufacturing is most profitable and reduces environmental impacts, but generally leads to a market dominated by remanufactured products. In contrast, when consumer's perceived value of remanufactured products is moderate and TPR remanufacturing significantly increases the perceived value of new products, the TPR-authorized remanufacturing is most profitable. It typically boosts total market sales, but accordingly increases environmental impacts. In addition, sensitivity analysis indicates that two-part authorization contracts are more advanced in meeting stringent environmental requirements than one-part contracts. Incorporating market size stochasticity enhances system profitability while keeping environmental impacts within a limited scope.",
    "authors": [
      "Zhongxin Hu",
      "Christina Imdahl",
      "Zumbul Atan"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03733",
    "title": "A Superfast Direct Solver for Type-III Inverse Nonuniform Discrete Fourier Transform",
    "abstract": "The nonuniform discrete Fourier transform (NUDFT) and its inverse are widely used in various fields of scientific computing. In this article, we propose a novel superfast direct inversion method for type-III NUDFT. The proposed method approximates the type-III NUDFT matrix as a product of a type-II NUDFT matrix and an HSS matrix, where the type-II NUDFT matrix is further decomposed into the product of an HSS matrix and an uniform discrete Fourier transform (DFT) matrix as in [Wilber, Epperly, and Barnett, SIAM Journal on Scientific Computing, 47(3):A1702-A1732, 2025]. This decomposition enables both the forward application and the backward inversion to be accomplished with quasi-linear complexity. The fast inversion can serve as a high-accuracy direct solver or as an efficient preconditioner. Additionally, we provide an error bound for the approximation under specific sample distributions. Numerical results are presented to verify the relevant theoretical properties and demonstrate the efficiency of the proposed methods.",
    "authors": [
      "Yingzhou Li",
      "Jingyu Liu"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03739",
    "title": "Penalty-Free SDDP: Feasibility Cuts for Robust Multi-Stage Stochastic Optimization in Energy Planning",
    "abstract": "Multi-stage decision problems under uncertainty can be efficiently solved with the Stochastic Dual Dynamic Programming (SDDP) algorithm. However, traditional implementations require all stage problems to be feasible. Feasibility is usually enforced by adding slack variables and penalizing them in the objective function, a process that depends on case-specific calibration and often distorts the economic interpretation of results. This paper proposes the Penalty-Free SDDP, an extension that introduces a Future Feasibility Function alongside the traditional Future Cost Function. The new recursion handles infeasibilities automatically, distinguishing between temporary and truly infeasible cases, and propagates feasibility information across stages through dedicated feasibility cuts. The approach was validated in a large-scale deterministic case inspired by the Brazilian hydrothermal system, achieving equivalent feasibility to the benchmark solution while eliminating miscalibrated artificial penalties. Results confirm its robustness and practicality as a foundation for future stochastic, multi-stage applications.",
    "authors": [
      "Guilherme Freitas",
      "Luiz Carlos da Costa Junior",
      "Tiago Andrade",
      "Alexandre Street"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03741",
    "title": "An arbitrary Lagrangian-Eulerian semi-implicit hybrid method for continuum mechanics with GLM cleaning",
    "abstract": "This paper proposes a semi-implicit arbitrary Lagrangian-Eulerian (ALE) method for the solution of the unified Godunov-Peshkov-Romenski (GPR) model of continuum mechanics. To handle the curl free involutions arising in the solid limit of the model, the original system is augmented by adopting a thermodynamically compatible generalized Lagrangian multiplier (GLM) approach. Next, an operator splitting strategy decouples the computation of fast pressure waves from the bulk velocity of the medium yielding a transport subsystem, containing convective terms and non-conservative products, and a Poisson-type subsystem, for the pressure. A second splitting yields an ODE subsystem comprising only the potentially stiff source terms, responsible for the relaxation of the model between its fluid and solid limits. The mesh motion can be driven by two sources: the local fluid velocity and a prescribed boundary displacement. For the spatial discretization, we employ unstructured staggered grids, with the pressure defined on the primal mesh and all remaining variables on the dual grid. The transport subsystem is advanced via an explicit finite volume method, in which integration over closed space-time control volumes ensures verification of the geometric conservation law (GCL). On the other hand, implicit continuous finite elements are used for the discretization of the pressure subsystem and an implicit DIRK scheme is employed to solve the ODE subsystem. Consequently, the proposed approach is well suited to address all Mach number flows. A comprehensive set of benchmarks is employed to assess the accuracy and robustness of the proposed methodology in tackling both fluid and solid mechanics problems.",
    "authors": [
      "Saray Busto"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03747",
    "title": "Sample-Efficient Counterfactual Tuning for Compressor Pressure Control",
    "abstract": "In controlled industrial environments, ensuring safety and performance during controller tuning is a challenging and critical task. In particular, control loops in compressor-plenum-throttle systems cannot tolerate costly interruptions, and aggressive excitation may lead to unsafe operating regimes. Given the wide availability of historical data, this paper introduces a counterfactual explainability approach for sample-efficient retuning of compressor control loops. The proposed data-driven algorithm determines, without an explicit plant model or previous control law, the smallest controller adjustment required to achieve predefined performance specifications while guaranteeing stability. The effectiveness of the method is demonstrated through an extensive Monte Carlo simulation study.",
    "authors": [
      "Margarita A. Guerrero",
      "Rodrigo A. González",
      "Cristian R. Rojas"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03754",
    "title": "The time fractional stochastic partial differential equations with non-local operator on $\\mathbb{R}^{d}$",
    "abstract": "This paper investigates a class of time-fractional stochastic partial differential equations (SPDEs) on $\\mathbb{R}^d$, driven by both Gaussian and Lévy space-time white noises. The equation involves Caputo time-derivatives of orders $\\alpha, \\sigma_1, \\sigma_2$ and a non-local operator $\\phi(\\Delta)$ generated by a Bernstein function $\\phi$. We first establish the local existence and uniqueness of mild solutions in the $L_p$-framework for $1 \\leq p \\leq 2$. For the case $p > 2$, where the $L_p$-theory fails, we develop a Sobolev space framework based on the scales of Besov and Triebel--Lizorkin spaces associated with $\\phi(\\Delta)$. Within this setting, we prove the solvability and regularity of weak solutions. Our analysis relies on detailed estimates of the fundamental solutions, stochastic convolutions, Littlewood--Paley theory, and a fixed point argument. The results presented here extend and unify several previous works on fractional SPDEs by incorporating a general class of non-local operators and Lévy noises.",
    "authors": [
      "Yong Zhen Yang",
      "Yong Zhou"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03757",
    "title": "Spectra and pseudospectra of non-Hermitian Toeplitz operators: Eigenvector decay transitions in banded and dense matrices",
    "abstract": "Using a generalised Floquet-Bloch theory, we present a mathematical method to construct eigenvectors for non-Hermitian Toeplitz operators. We extend the method to both banded Toeplitz operators and those with algebraically decaying, fully dense off-diagonal structure. We present sharp decay estimates for the amplitude of bulk eigenmodes as well as eigenmodes associated with defect eigenfrequencies inside the spectral band gap. The validity of those results is illustrated numerically and we show that banded approximations give poor reconstructions of the dense operators, due to the slow algebraic decay. We apply the insights gained to model the non-Hermitian skin effect in a three-dimensional system of subwavelength resonators, where the corresponding operator exhibits only algebraic decay of off-diagonal entries. We use our approach to demonstrate the fundamental mechanism responsible for the transition between the non-Hermitian skin effect and defect-induced localisation in the bulk.",
    "authors": [
      "Yannick de Bruijn",
      "Bryn Davies",
      "Sacha Dupuy",
      "Erik Orvehed Hiltunen"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03773",
    "title": "Counter-examples to the fractal Weyl law for semiclassical resonances",
    "abstract": "Under general assumptions, the numbers of semiclassical resonances is known to be bounded from above by a negative power of $h$ which is given by the fractal dimension of the trapped set. In this paper we provide examples of operators with much less resonances, showing that these upper bounds are not always sharp.",
    "authors": [
      "Jean-Francois Bony",
      "Setsuro Fujiie",
      "Thierry Ramond",
      "Maher Zerzeri"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03778",
    "title": "Bi-Isolated d.c.e. Degrees and $Σ_1$ Induction",
    "abstract": "A Turing degree is d.c.e. if it contains a set that is the difference of two c.e. sets. A d.c.e. degree $\\mathbf{d}$ is isolated if there exists a c.e. degree $\\mathbf{a}<\\mathbf{d}$ such that every c.e. degree below $\\mathbf{d}$ is also below $\\mathbf{a}$; $\\mathbf{d}$ is upper isolated if there exists a c.e. degree $\\mathbf{a}>\\mathbf{d}$ such that every c.e. degree above $\\mathbf{d}$ is also above $\\mathbf{a}$; $\\mathbf{d}$ is bi-isolated if it is both isolated and upper isolated. In this paper, we prove the existence of bi-isolated d.c.e. degrees in models of $\\mathsf{I}\\Sigma_1$.",
    "authors": [
      "Liu Yong",
      "Peng Cheng"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03782",
    "title": "On the p-adic integration over Igusa towers of Siegel modular varieties",
    "abstract": "We develop an explicit $p$-adic integration theory for Igusa towers of modular Siegel manifolds, which finds applications to explicit reciprocity laws.",
    "authors": [
      "Marco Adamo Seveso"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03789",
    "title": "Extremal diameters of 3-coloring graphs of trees",
    "abstract": "Given a tree $T$, its 3-coloring graph $\\mathcal{C}_3(T)$ has as vertices the proper 3-colorings of $T$, with edges joining colorings that differ at exactly one vertex. We call the diameter of $\\mathcal{C}_3(T)$ the 3-coloring diameter of $T$. We introduce the notion of balanced labelings of $T$ and show that the 3-coloring diameter equals the maximum $L_1$-norm of a balanced labeling. Using this equivalence, we determine the maximum and minimum values of the 3-coloring diameter over all trees on $n$ vertices and characterize the extremal trees.",
    "authors": [
      "Shamil Asgarli",
      "Sara Krehbiel",
      "Simon MacLean",
      "Gjergji Zaimi"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03813",
    "title": "Hopf bifurcations in a reaction-diffusion model with a general advection term and delay effect",
    "abstract": "This paper investigates a class of reaction-diffusion population models defined on a bounded domain, characterized by a general time-delayed per capita growth rate and a general advection term. Notably, the growth rate encompasses both Logistic-type and weak Allee effect-type dynamical behaviors. By applying the Lyapunov method, we establish the existence of spatially inhomogeneous steady states when a parameter approaches the principal eigenvalue of a non-self-adjoint elliptic operator. A detailed analysis of the characteristic equation further confirms the existence of Hopf bifurcations originating from these steady states. Subsequently, by applying center manifold reduction and normal form theory, we ascertain the direction of these Hopf bifurcations and the stability of the resulting periodic orbits. Finally, the proposed general theoretical results are successfully applied to a \"food-limited\" population model and a weak Allee effect-driven population model, each of which incorporates diffusion, time delay, and advection, thus confirming the validity of our approach.",
    "authors": [
      "Jingxiao Song",
      "Chengwei Ren",
      "Shaofen Zou"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03831",
    "title": "Spectral properties of the Frechet derivatives of stratified steady Stokes waves",
    "abstract": "We consider stratified steady water waves in a two dimensional channel. Our main subject is spectral properties of the Frechet derivatives of steady water Stokes waves. One of main results is the absence of subharmonic water waves in a neighborhood of a Stokes wave. The main assumption is formulated in terms of the eigenvalues of the Frechet derivative evaluated at this wave and considered in the class of periodic solutions of the same period. The first eigenvalue is always negative. We show that if the second eigenvalue is positive then there are no waves with multiple periods in a neighborhood of the Stokes wave.",
    "authors": [
      "Vladimir Kozlov"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03836",
    "title": "Calabi-Yau structures on derived and singularity categories of symmetric orders",
    "abstract": "We construct left and right Calabi-Yau structures on derived respectively singularity categories of symmetric orders $\\Lambda$ over commutative Gorenstein rings $R$. For this, we first construct Calabi-Yau structures over $R$ by lifting Amiot's construction of Calabi-Yau structures on Verdier quotients to the dg level. Then we prove base change properties relating Calabi-Yau structures over $R$ to those over the base field $k$. As a result, we prove the existence of a right Calabi-Yau structure on the dg singularity category associated with $\\Lambda$ which is a cyclic lift of the weak Calabi-Yau structure constructed by the first-named author and Iyama. We also show the existence of a left Calabi-Yau structure on the dg bounded derived category of $\\Lambda$. This is a non-commutative generalization of a result by Brav and Dyckerhoff. By combining the existence of the right Calabi-Yau structure on the dg singularity category with a structure theorem by Keller and the second-named author, we deduce that under suitable hypotheses, the singularity category associated with $\\Lambda$ is triangle equivalent to a generalized cluster category in the sense of Amiot.",
    "authors": [
      "Norihiro Hanihara",
      "Junyang Liu"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03840",
    "title": "Symplectic methods for stochastic Hamiltonian systems: asymptotic error distributions and Hamiltonian-specific analysis",
    "abstract": "In this paper, we investigate the asymptotic error distributions of symplectic methods for stochastic Hamiltonian systems and further provide Hamiltonian-specific analysis that clarifies the superiority of symplectic methods. Our contribution is threefold. First, we derive the asymptotic error distributions of symplectic methods for stochastic Hamiltonian systems with multiplicative noise and additive noise, respectively, and show that the obtained limiting stochastic processes satisfy equations retaining the Hamiltonian formulations. Second, we propose a new approach for calculating the asymptotic error distribution, revealing the connection between the stochastic modified equation and the asymptotic error distribution. Third, we characterize the limiting distribution of the normalized Hamiltonian deviation, thereby illustrating through test equations the superiority of symplectic methods for long-time simulations of the Hamiltonians, even in the limit as the step size tends to zero.",
    "authors": [
      "Chuchu Chen",
      "Xinyu Chen",
      "Jialin Hong",
      "Yuqian Miao"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03849",
    "title": "Bifurcations of Highly Inclined Near Halo Orbits using Moser Regularization",
    "abstract": "We study the bifurcation structure of highly inclined near halo orbits with close approaches to the light primary, in the circular restricted three-body problem (CR3BP). Using a Hamiltonian formulation together with Moser regularization, we develop a numerical framework for the continuation of periodic orbits and the computation of their Floquet multipliers which remains effective near collision. We describe vertical collision orbits and families emerging from its pitchfork, period-doubling, and period-tripling bifurcations in the limiting Hill's problem, including the halo and butterfly families. We continue these into the CR3BP using a perturbative framework via a symplectic scaling, and construct bifurcation graphs for representative systems (Saturn-Enceladus, Earth-Moon, Copenhagen) to identify common dynamical features. Conley-Zehnder indices are computed to classify the resulting families. Together, these results provide a coherent global picture of polar orbit architecture near the light primary, offering groundwork for future mission design, such as Enceladus plume sampling missions.",
    "authors": [
      "Chankyu Joung",
      "Dayung Koh",
      "Otto van Koert"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03860",
    "title": "Infinitesimal deformations of Lie algebroid pairs",
    "abstract": "We study infinitesimal deformations of Lie algebroid pairs in the category of smooth manifolds enriched with a local Artinian algebra. Given a Lie algebroid pair $(L,A)$, i.e. a Lie algebroid $L$ together with a Lie subalgebroid $A$, we investigate isomorphism classes of infinitesimal deformations of $(L,A)$ modulo automorphisms from exponentials of derivations of $L$ and those from the exponentials of inner derivations of $L$, respectively. For the associated two deformation functors, we find the associated governing $L_\\infty$-algebras in the sense of extended deformation theory. Furthermore, when $(L,A)$ is a matched Lie pair, i.e. the quotient $L/A$ is also a Lie subalgebroid of $L$, we investigate isomorphism classes of infinitesimal deformations modulo automorphisms from exponentials of derivations along the normal direction $L/A$. The extended deformation theory of the associated deformation functor recovers the formal deformation theory of complex structures and that of transversely holomorphic foliations.",
    "authors": [
      "Dadi Ni",
      "Zhuo Chen",
      "Chuangqiang Hu",
      "Maosong Xiang"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03865",
    "title": "Deformations of the Standard Map with Prescribed Actions and Lyapunov Exponents",
    "abstract": "We construct nontrivial deformations of the standard map which preserve the symplectic actions, respectively the Lyapunov exponents, of infinitely many periodic orbits accumulating to an invariant curve. The proof uses a resonant normal-form construction to obtain a sequence of periodic orbits accumulating on an invariant curve with a Liouville rotation number. Within these normal forms we capture the dependence of these periodic orbits on the resonant Fourier coefficients of the dynamics on the invariant curve and, using the contraction mapping principle, obtain a suitable deformation achieving the prescribed spectral data associated with this sequence of orbits. The result can be viewed as a symplectic twist-map analogue of a length spectral nonrigidity phenomenon for Riemannian manifolds and convex billiards, and it motivates the existence problem for similar 'partially length-isospectral' deformations of strictly convex billiard tables.",
    "authors": [
      "Yunzhe Li"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03872",
    "title": "Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices",
    "abstract": "This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03873",
    "title": "Convergence of Random Walks in $\\ell_p$-Spaces of Growing Dimension",
    "abstract": "We prove the limit theorem for paths of random walks with $n$ steps in $\\mathbb{R}^d$ as $n$ and $d$ both go to infinity. For this, the paths are viewed as finite metric spaces equipped with the $\\ell_p$-metric for $p\\in[1,\\infty)$. Under the assumptions that all components of each step are uncorrelated, centered, have finite $2p$-th moments, and are identically distributed, we show that such random metric space converges in probability to a deterministic limit space with respect to the Gromov-Hausdorff distance. This result generalises earlier work by Kabluchko and Marynych for $p=2$.",
    "authors": [
      "Bochen Jin"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03884",
    "title": "Random walks and quadratic number fields",
    "abstract": "We establish a novel type of connection between random walks and analytic number theory. Working with a random walk on the circle group $\\mathbb{R}/\\mathbb{Z}$ in which each step is a random integer multiple of a given quadratic irrational $\\alpha$, we show that the rate of convergence to uniformity in the quadratic Wasserstein metric (also known as the periodic $L^2$ discrepancy) is governed by deep arithmetic invariants of the ring of algebraic integers of the real quadratic field $\\mathbb{Q}(\\alpha)$, such as fundamental units and special values of zeta functions.",
    "authors": [
      "Bence Borda"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03885",
    "title": "The Protasov-Zelenyuk topology and ideal convergence",
    "abstract": "The so-called $T$-sequences $\\mathbf u$ in a group $G$, and the related finest Hausdorff group topology $T_\\mathbf u$ on $G$ that makes $\\mathbf u$ a null sequence, were introduced by Protasov and Zelenyuk 35 years ago and since then they became a fundamental tool in the field of topological groups. More recently, in the abelian case, the subfamily of $T$-sequences called $TB$-sequences was introduced, as well as the finest precompact group topology $T_\\mathbf{pu}$ that makes $\\mathbf u$ a null sequence. Here we study the counterpart of all these notions with respect to ideal convergence in place of the classical notion of convergence of a sequence. Also, we study their relation to the already established field of $I$-characterized subgroups of compact abelian groups.",
    "authors": [
      "Lydia Außenhofer",
      "Dikran Dikranjan",
      "Anna Giordano Bruno"
    ],
    "primary_category": "math.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03893",
    "title": "Topological Obstructions to Dynamical Convexity",
    "abstract": "We study the topological obstructions of dynamical convexity on contact manifolds focusing on fillability by cotangent bundles and subcritical surgeries. Using links to algebraic geometry, we motivate and define a stronger version of dynamical convexity, and investigate the topology of these manifolds. More precisely, we show that strongly dynamically convex contact manifolds cannot arise as a unit cotangent bundle $(ST^*M,\\lambda_{std})$ of a closed manifold $M$ and in particular that dynamically convex contact manifolds cannot arise as the unit cotangent bundle $(ST^*M,\\lambda_{std})$ of a simply connected manifold $M$. We also show obstructions to dynamical convexity that arises from studying different kinds of subcritical surgeries.",
    "authors": [
      "Shahnaz Shamim Shahul"
    ],
    "primary_category": "math.SG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03897",
    "title": "A remark on the log-Sobolev inequality for the Gibbs measure of the focusing Schrödinger equation",
    "abstract": "We consider the question of showing a log-Sobolev inequality for the Gibbs measure of the focusing Schrödinger equation built by Lebowitz-Rose-Speer (1988), formally given by $$ d\\rho \\propto \\exp\\big(\\frac 1 p\\int_{\\mathbb T} |u|^p d x - \\frac 12\\int_{\\mathbb T} |\\nabla u|^2 d x - \\frac 12\\int_{\\mathbb T} |u|^2 d x\\big) \\mathbf 1_{\\| u \\|_{L^2(\\mathbb T)}^2 \\le K}dud\\overline{u}. $$ When $2 \\le p \\le 4$, we show that these measures indeed satisfy a log-Sobolev inequality. When $p> 4$, we show a lower bound for the Hessian of the potential, which implies that the known techniques to show these inequalities cannot apply to the measure $\\rho$.",
    "authors": [
      "Guopeng Li",
      "Jiawei Li",
      "Leonardo Tolomeo"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03901",
    "title": "Remarks on a result of Sibony on the Carathéodory topology",
    "abstract": "In this paper, we prove that if a Carathéodory hyperbolic analytic space $X$ is $C_X$-complete, then its natural topology is induced by the Carathéodory distance on $X$. This is an improvement of Sibony's result, which concludes the same under the hypothesis that $X$ is $C_X$-finitely compact. This improvement is not merely formal; we also show the existence of uncountably many biholomorphically inequivalent analytic spaces that are not $C_X$-finitely compact but are $C_X$-complete.",
    "authors": [
      "Sudip Dolai"
    ],
    "primary_category": "math.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03909",
    "title": "Well-rounded ideal lattices from totally definite quaternion algebras",
    "abstract": "We study well-rounded ideal lattices from totally definite quaternion algebras. We prove existence and classification results, and illustrate our methods with examples.",
    "authors": [
      "Yuan Xiang Chew",
      "Frédérique Oggier"
    ],
    "primary_category": "math.RA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03915",
    "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models",
    "abstract": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.",
    "authors": [
      "X.Y. Han",
      "Yuan Zhong"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03934",
    "title": "Discontinuous Strongly Quasiconvex Functions",
    "abstract": "A fundamental open question asking whether all real-valued strongly quasiconvex functions defined on $\\mathbb R^n$ are necessarily continuous, akin to their convex counterparts, is answered in detail in this paper. Among other things, we show that such functions can have infinitely many points of discontinuity. The failure of lower semicontinuity together with the lack of upper semicontinuity at infinitely many points of certain real-valued strongly quasiconvex functions are also shown.",
    "authors": [
      "Nguyen Thi Van Hang",
      "Felipe Lara",
      "Nguyen Dong Yen"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03947",
    "title": "Data-Dependent Complexity of First-Order Methods for Binary Classification",
    "abstract": "Large-scale problems in data science are often modeled with optimization, and the optimization model is usually solved with first-order methods that may converge at a sublinear rate. Therefore, it is of interest to terminate the optimization algorithm as soon as the underlying data science task is accomplished. We consider FISTA for solving two binary classification problems: the ellipsoid separation problem (ESP), and the soft-margin support-vector machine (SVM). For the ESP, we cast the dual second-order cone program into a form amenable to FISTA and show that the FISTA residual converges to the infimal displacement vector of the primal-dual hybrid gradient (PDHG) algorithm, that directly encodes a separating hyperplane. We further derive a data-dependent iteration upper bound scaling as $\\mathcal{O}(1/\\delta_{\\mathcal{A}}^2)$, where $\\delta_{\\mathcal{A}}$ is the minimal perturbation that destroys separability. For the SVM, we propose a strongly-concave perturbed dual that admits efficient FISTA updates under a linear time projection scheme, and with our parameter choices, the objective has small condition number, enabling rapid convergence. We prove that, under a reasonable data model, early-stopped iterates identify well-classified points and yield a hyperplane that exactly separates them, where the accuracy required of the dual iterate is governed by geometric properties of the data. In particular, the proposed early-stopping criteria diminish the need for hard-to-select tolerance-based stopping conditions. Our numerical experiments on ESP instances derived from MNIST data and on soft-margin SVM benchmarks indicate competitive runtimes and substantial speedups from stopping early.",
    "authors": [
      "Matthew Hough",
      "Stephen A. Vavasis"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03948",
    "title": "A Second Main Theorem for Entire Curves Intersecting Three Conics",
    "abstract": "We establish a Second Main Theorem for entire holomorphic curves $f: \\mathbb{C} \\to \\mathbb{P}^2$ intersecting a generic configuration of three conics $\\mathcal{C}_1, \\mathcal{C}_2, \\mathcal{C}_3$ in the complex projective plane $\\mathbb{P}^2$. Using invariant logarithmic $2$-jet differentials with negative twists, we prove the estimate \\[ T_f(r) \\leqslant 5 \\sum_{i=1}^3 N_f^{[1]}(r, \\mathcal{C}_i) + o\\big(T_f(r)\\big)\\quad\\parallel, \\] where $T_f(r)$ is the Nevanlinna characteristic function, and $N_f^{[1]}(r, \\mathcal{C}_i)$ is the 1-truncated counting function.",
    "authors": [
      "Lei Hou",
      "Dinh Tuan Huynh",
      "Joël Merker",
      "Song-Yan Xie"
    ],
    "primary_category": "math.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03951",
    "title": "Intrinsic tensor products and a Ganea-type extension of the five-term exact sequence",
    "abstract": "We establish a right-exactness theorem for the cross-effects of bifunctors, and consequently for cosmash products, in Janelidze-Márki-Tholen semi-abelian categories. This result motivates an intrinsic definition of a bilinear product, a tensor-like operation on objects of a category, constructed in terms of limits and colimits. Given two objects in the category, their bilinear product is the abelian object obtained as the cosmash product in the category of two-nilpotent objects of the reflections of these objects. In many concrete cases, this operation, applied to a pair of abelian objects, captures a classical tensor product. We explain this by proving a recognition theorem, which states that any symmetric, bi-cocontinuous bifunctor on an abelian variety of algebras can be recovered as the bilinear product within a suitable semi-abelian variety, namely of algebras over a certain two-nilpotent operad. In other words, the extra structure carried by such a bifunctor on the abelian variety (for instance, a tensor product, known in the literature) is encoded by means of a surrounding semi-abelian variety whose abelian core is the original variety. We illustrate the construction with several examples, develop its basic properties, and compare it to the semi-abelian analogue of the Brown-Loday non-abelian tensor product. As an application, we present a categorical version of Ganea's six-term exact homology sequence. Finally, we characterise abelian extensions via internal action cores, yielding explicit descriptions of cosmash products and bilinear products in certain categories of representations.",
    "authors": [
      "Bo Shan Deval",
      "Manfred Hartl",
      "Tim Van der Linden"
    ],
    "primary_category": "math.CT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03952",
    "title": "$δ$-lifting and $1$-dimensional analytic fields",
    "abstract": "Let $k$ be an algebraically closed complete non-Archimedean field, and let $K$ be a finitely generated field extension over $k$ with transcendence degree $1$. Equip $K$ a non-Archimedean norm extending the one on $k$, and let $\\mathcal{K}$ denote the completion of $K$. We will prove that the valuation ring $\\mathcal{K}^+$ admits a flat $\\delta$-lifting over $\\mathbb{A}_{\\mathrm{inf}}(k^+)$ if and only if $\\mathcal{K}$ is not of type 4.",
    "authors": [
      "Jiahong Yu"
    ],
    "primary_category": "math.AC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03956",
    "title": "Morita equivalence and stable isomorphism via unitary operators",
    "abstract": "We define $\\Delta$-equivalence for dual operator systems and prove that it is an equivalence relation. We show that weak TRO-equivalence of dual operator spaces induces a stable isomorphism between them which is given by multiplication with unitary operators, and in the special case of dual operator systems it is a unitary equivalence. We prove an analogous result for strong TRO-equivalence of operator spaces and for operator systems. Lastly, we show that $\\Delta$-equivalent dual operator spaces, considered as bimodules over their left and right adjointable multiplier algebras, have TRO-equivalent normal CES representations.",
    "authors": [
      "Nikolaos Koutsonikos-Kouloumpis"
    ],
    "primary_category": "math.OA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03968",
    "title": "Bounded-degree graphs of non-negative Ollivier-Ricci curvature have subexponential growth and diffusive random walk",
    "abstract": "We study the geometric properties of graphs with non-negative Ollivier-Ricci curvature, a discrete analogue of non-negative Ricci curvature in Riemannian geometry. We prove that for each $d<\\infty$ there exists a constant $C_d$ such that if $G=(V,E)$ is a finite graph with non-negative Ollivier-Ricci curvature and with degrees bounded by $d$ then the average log-volume growth and random walk displacement satisfy \\[ \\frac{1}{|V|} \\sum_{x\\in V} \\log \\#B(x,r) \\leq \\exp\\left[C_d \\sqrt{\\log r}\\right] = r^{o(1)} \\] and \\[ \\frac{1}{|V|} \\sum_{x\\in V} \\mathbf{E}_x [d(X_0,X_n)^2] \\leq n \\exp\\left[C_d \\sqrt{\\log n}\\right] = n^{1+o(1)} \\] for every $n,r\\geq 2$. This significantly strengthens a result of Salez (GAFA 2022), who proved that the average displacement of the random walk is $o(n)$ and deduced that non-negatively curved graphs of bounded degree cannot be expanders. Our results also apply to infinite transitive graphs and, more generally, to bounded-degree unimodular random rooted graphs of non-negative Ollivier-Ricci curvature.",
    "authors": [
      "Tom Hutchcroft",
      "Florentin Münch"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03978",
    "title": "On well-posedness for second-order degenerate parabolic equations with unbounded lower-order terms",
    "abstract": "In this paper, we establish the well-posedness of Cauchy problems for weak solutions to second-order degenerate parabolic equations with a non-smooth, time-dependent degenerate elliptic part that includes both bounded and unbounded lower-order terms. The unbounded lower-order terms are allowed to lie in mixed time-space Lebesgue or even Lorentz spaces. Our notion of weak solutions is formulated under minimal assumptions. We prove the existence and uniqueness of a fundamental solution, which coincides with the associated evolution family for the homogeneous problem (i.e., with zero source term) and provides a representation formula for all weak solutions. We also establish $L^2$ off-diagonal estimates for the fundamental solution and derive Gaussian upper bounds under the weak assumption of Moser's $L^2$-$L^\\infty$ estimates for weak solutions. Our approach is purely variational and avoids any a priori regularity assumptions on weak solutions or regularization via smooth approximations. Two key ingredients are norm inequalities for fractional powers of the degenerate Laplacian, and a set of embeddings that ensure time continuity of weak solutions, extending the classical Lions regularity theorem and accommodating a wide class of source terms.",
    "authors": [
      "Khalid Baadi"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03986",
    "title": "On the Approaching Geodesic Property via the Quotient Invariant",
    "abstract": "We study the approaching geodesic property of a bounded domain in $\\mathbb{C}^{n}$ with respect to the Kobayashi distance using the quotient invariant.",
    "authors": [
      "Kingshook Biswas",
      "Sanjoy Chatterjee"
    ],
    "primary_category": "math.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04003",
    "title": "Mixed finite element approximation for non-divergence form elliptic equations with random input data",
    "abstract": "We consider an elliptic partial differential equation in non-divergence form with a random diffusion matrix and random forcing term. To address this, we propose a mixed-type continuous finite element discretization in the physical domain, combined with a collocation discretization in the stochastic domain. For the mixed formulation, we first introduce a stochastic cost functional at the continuous level. This formulation is then enhanced to incorporate the vanishing tangential trace constraint directly into a mesh-dependent cost functional, rather than enforcing it in the solution's function space. In this context, we define a mesh-dependent norm and provide an error analysis based on this norm. We employ the collocation method by collocating the stochastic equation at the zeros of suitable tensor product orthogonal polynomials. This approach leads to a system of uncoupled deterministic problems, simplifying computation. Furthermore, we establish an a poriori error bound for the fully discrete approximation, detailing the convergence rates with respect to the discretization parameters. Finally, numerical results are presented to confirm and validate the theoretical findings.",
    "authors": [
      "Amireh Mousavi"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04005",
    "title": "A Strict Comparison Principle for Integro-Differential Hamilton-Jacobi-Bellman Equations on Domains with Boundary",
    "abstract": "This work provides a comparison principle for viscosity solutions to boundary value problems on (partially) bounded, cylindrical spaces. The comparison principle is based on a test function framework, that allows for the simultaneous treatment of diffusive as well as jump terms. Estimates in the proof of the comparison principle incorporate the use of Lyapunov functions that act as growth bounds for the solutions, effectively yielding a theory for unbounded viscosity solutions. We apply the results to a wide class of parabolic equations and elliptic problems on a space with corners.",
    "authors": [
      "Serena Della Corte",
      "Fabian Fuchs",
      "Richard C. Kraaij",
      "Max Nendel"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04017",
    "title": "Canonical metrics on families of vector bundles",
    "abstract": "We introduce a geometric partial differential equation for families of holomorphic vector bundles, generalising the theory of Hermite--Einstein metrics. We consider families of holomorphic vector bundles which each admit Hermite--Einstein metrics, together with a first order deformation. On such families, we define the family Hermite--Einstein equation for Hermitian metrics, which we view as a notion of a canonical metric in this setting. We prove two main results concerning family Hermite--Einstein metrics. Firstly, we construct Hermite--Einstein metrics in adiabatic classes on product manifolds, assuming the existence of a family Hermite--Einstein metric. Secondly, we prove that the associated parabolic flow admits a unique smooth solution for all time, and use this to show that the Dirichlet problem always admits a unique solution.",
    "authors": [
      "Shing Tak Lam"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04018",
    "title": "Monodromy and vanishing cycles for sufficiently ample linear systems on simply connected surfaces",
    "abstract": "We compute the mapping class group-valued monodromy of any sufficiently ample linear system on any smooth simply connected projective surface, identifying this with the r-spin mapping class group associated to a maximal root of the adjoint line bundle. This gives a characterization of the simple closed curves that can arise as vanishing cycles for nodal degenerations in the linear system, as well as other corollaries concerning discriminants, Lefschetz fibrations, and surfaces in 4-manifolds.",
    "authors": [
      "Ishan Banerjee",
      "Nick Salter"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04020",
    "title": "On topological and algebraic structures of categorical random variables",
    "abstract": "Based on entropy and symmetrical uncertainty (SU), we define a metric for categorical random variables and show that this metric can be promoted into an appropriate quotient space of categorical random variables. Moreover, we also show that there is a natural commutative monoid structure in the same quotient space, which is compatible with the topology induced by the metric, in the sense that the monoid operation is continuous.",
    "authors": [
      "Inocencio Ortiz",
      "Santiago Gómez-Guerrero",
      "Christian E. Schaerer"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04023",
    "title": "On asymptotic Lebesgue's universal covering problem",
    "abstract": "Universal cover in $\\mathbb{E}^{n}$ is a measurable set that contains a congruent copy of any set of diameter 1. Lebesgue's universal covering problem, posed in 1914, asks for the convex set of smallest area that serves as a universal cover in the plane ($n=2$). A simple universal cover in $\\mathbb{E}^n$ is provided by the classical theorem of Jung, which states that any set of diameter 1 in an $n$-dimensional Euclidean space is contained in a ball $J_n$ of radius $\\sqrt{\\tfrac{n}{2n+2}}$; in other words, $J_n$ is a universal cover in $\\mathbb{E}^n$. We show that in high dimensions, Jung's ball $J_n$ is asymptotically optimal with respect to the volume, namely, for any universal cover $U \\subset \\mathbb{E}^n$, $$ {\\rm Vol}(U) \\ge (1-o(1))^n{\\rm Vol}(J_n). $$",
    "authors": [
      "Andrii Arman",
      "Andriy Bondarenko",
      "Andriy Prymak",
      "Danylo Radchenko"
    ],
    "primary_category": "math.MG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04026",
    "title": "Orderings of k-Markov Numbers",
    "abstract": "The $k$-Markov numbers, introduced by Gyoda and Matsushita, are those which appear in positive integral solutions to $x^2 + y^2 + z^2 + k(xy + xz + yz) = (3+3k)xyz$. When $k =0$, this recovers the ordinary Markov numbers. A long-standing question in the theory of Markov numbers is Frobenius's unicity conjecture, concerning whether every Markov number is the maximum in a unique solution triple. Aigner gave a series of weaker, related conjectures which were confirmed to be true by Lee, Li, Rabideau, and Schiffler using techniques from the theory of cluster algebras. We show here that $k$-Markov numbers also satisfy Aigner's conjectures.",
    "authors": [
      "Esther Banaian"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04038",
    "title": "Differentiation and Covering Constants for Hilbert-Schmidt and Quasi-Hilbert-Schmidt Operators",
    "abstract": "In this paper, we calculate the Frechet derivatives and Mordukhovich derivatives (or coderivatives) of Hilbert Schmidt operators on separable Hilbert spaces, by which we prove that the covering constant for Hilbert-Schmidt operators is zero. As an important class of Hilbert Schmidt operators, we study the differentiability of Hilbert Schmidt integral operators. Then, we introduce the concept of quasi-Hilbert Schmidt operators on separable Hilbert spaces. We provide an example of quasi-Hilbert Schmidt operators and find its Frechet derivatives and Mordukhovich derivatives.",
    "authors": [
      "Jinlu Li"
    ],
    "primary_category": "math.FA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04046",
    "title": "Greedy techniques for inverse problems",
    "abstract": "Inverse imaging problems rely on limited and indirect measurements, making reconstruction highly dependent on both regularization and sample locations. We introduce a novel greedy framework for the optimal selection of indirect measurements in the operator codomain, specifically tailored to inverse problems. Our approach employs a two-step scheme combining kernel-based interpolation and extrapolation. Within this framework, greedy schemes can be residual-based, where points are selected according to the current approximation error for a specific target function, or error-based, where points are chosen using a priori error indicators independent of the residual. For the latter, we derive explicit error bounds that quantify the propagation of approximation errors through both interpolation and extrapolation. Numerical applications to solar hard X-ray imaging demonstrate that the proposed greedy sampling strategy achieves high-quality reconstructions using only a few available measurements.",
    "authors": [
      "L. Bruni Bruno",
      "P. Massa",
      "E. Perracchione",
      "M. Trombini"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04053",
    "title": "Asymptotically maximal Schubitopes",
    "abstract": "We find a layered permutation $w\\in S_n$ whose Schubert polynomial $\\mathfrak S_w(x_1, \\dots, x_n)$ has support of size asymptotically at least $n!/4^n$. This gives precise asymptotics for the growth rate of $\\beta(n):= \\max_{w\\in S_n}|\\mathrm{supp}(\\mathfrak S_w)|$. We find a different layered permutation $w\\in S_n$ whose Grothendieck polynomial has support of size asymptotically at least $n!/e^{\\sqrt{2n} \\cdot \\ln(n)}$ and obtain more precise asymptotics for the growth rate of $\\beta^{\\mathfrak G}(n):=\\max_{w\\in S_n}|\\mathrm{supp}(\\mathfrak G_w)|$.",
    "authors": [
      "Jack Chen-An Chou",
      "Linus Setiabrata"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04066",
    "title": "Instantaneous Sobolev Regularization for Dissipative Bosonic Dynamics",
    "abstract": "We investigate quantum Markov semigroups on bosonic Fock space and identify a broad class of infinite-dimensional dissipative evolutions that exhibit instantaneous Sobolev-regularization. Motivated by stability problems in quantum computation, we show that for certain Lindblad operators that are polynomials of creation and annihilation operators, the resulting dynamics immediately transform any initial state into one with finite expectation in all powers of the number operator. A key application is in the bosonic cat code, where we obtain explicit estimates in the trace norm for the speed of convergence. These estimates sharpen existing perturbative bounds at both short and long times, offering new analytic tools for assessing stability and error suppression in bosonic quantum information processing. For example, we improve the strong exponential convergence of the (shifted) $2$-photon dissipation to its fixed point to the uniform topology.",
    "authors": [
      "Pablo Costa Rico",
      "Paul Gondolf",
      "Tim Möbus"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04071",
    "title": "On the Hypergraph Nash-Williams' Conjecture",
    "abstract": "In 2014, Keevash proved the existence of $(n,q,r)$-Steiner systems (equivalently $K_q^r$-decompositions of $K_n^r$) for all large enough $n$ satisfying the necessary divisibility conditions. In 2021, Glock, Kühn, and Osthus proposed a generalization of this result. Namely they conjectured a hypergraph version of Nash-Williams' Conjecture positing that if a $K_q^r$-divisible $r$-graph $G$ on $n$ vertices has minimum $(r-1)$-degree (denoted $\\delta(G)$ hereafter) at least $\\left(1-\\Theta_r\\left(\\frac{1}{q^{r-1}}\\right)\\right) \\cdot n$, then $G$ admits a $K_q^r$-decomposition. The best known progress on this conjecture dates to the second proof of the Existence Conjecture by Glock, Kühn, Lo, and Osthus wherein they showed that $\\delta(G)\\ge \\left(1-\\frac{c}{q^{2r}}\\right)\\cdot n$ suffices for large enough $n$, where $c$ is a constant depending on $r$ but not $q$. As for the fractional relaxation, the best known bound is due to Delcourt, Lesgourgues, and the second author, who proved that $\\delta(G)\\ge \\left(1-\\frac{c}{q^{r-1 + o(1)}}\\right)\\cdot n$ guarantees a $K_q^r$-fractional decomposition. We prove that for every integer $r\\ge 2$, there exists a real $c>0$ such that if a $K_q^r$-divisible $r$-graph $G$ satisfies $\\delta(G)\\ge \\max\\left\\{ \\delta_{K_q^r}^* + \\varepsilon,~~1 -\\frac{c}{\\binom{q}{r-1}} \\right\\} \\cdot n$, then $G$ admits a $K_q^r$-decomposition for all large enough $n$, where $\\delta_{K_q^r}^*$ denotes the fractional $K_q^r$-decomposition threshold. Combined with the fractional result above, this proves that $\\left(1-\\frac{c}{q^{r-1 + o(1)}}\\right)\\cdot n$ suffices for the Hypergraph Nash-Williams' Conjecture, approximately confirming the correct order of $q$. Our proof uses the newly developed method of refined absorption; we also develop a non-uniform Turán theory to prove the existence of many embeddings of absorbers which may be of independent interest.",
    "authors": [
      "Cicely Henderson",
      "Luke Postle"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04077",
    "title": "Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization",
    "abstract": "For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH).",
    "authors": [
      "Ismail Cosandal",
      "Sennur Ulukus",
      "Nail Akar"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04078",
    "title": "Permutation Flows I: Triangulations of Flow Polytopes (Research Announcement)",
    "abstract": "We introduce a new broadly unifying family of combinatorial objects, which we call permutation flows, associated to an acyclic directed graph $G$ together with a framing $F$. This new family is combinatorially rich and contains as special cases various families of combinatorial objects that are frequently studied in the literature, as is the case of permutations, circular permutations, multipermutations, Stirling permutations, Catalan objects and their generalizations. When permutation flows are decorated with compatible shuffles, they also include the combinatorics of parking functions and their generalizations. This model is geometrically rich. We show that permutation flow shuffles define a family of unimodular triangulations of the flow polytope $F_G(a)$ on $G$ with an integer balanced netflow vector a where only the last entry is negative. As an application we provide a new proof of the Lidskii volume formula of Baldoni and Vergne for this family of polytopes and a reformulation of the same formula where every term is explained by the nature of the combinatorial objects involved. Permutation flow triangulations extend the Danilov, Karzanov, and Koshevoy triangulations that were defined for the case where a=e_0-e_n. We provide a formula for the h^*-polynomial of the flow polytope as the descent enumerating polynomial of permutation flows. The model comes with an order structure induced by intuitive operators on permutation flows which we call the weak order. This order includes as special cases the weak order on permutations, the Tamari lattice, order ideals in Young's lattice, and their generalizations, among others. It was conjectured in 2020 by the three authors, together with Benedetti, Harris, and Morales, that this poset is in general a lattice. This conjecture has been recently established with independent proofs by Bell and Ceballos, and by Berggren and Serhiyenko.",
    "authors": [
      "Rafael S. González D'León",
      "Christopher R. H. Hanusa",
      "Martha Yip"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04081",
    "title": "Additive relations in irrational powers",
    "abstract": "We investigate the additive theory of the set $S = \\{1^c, 2^c, \\dots, N^c\\}$ when $c$ is a real number. In the language of additive combinatorics, we determine the asymptotic behaviour of the additive energy of $S$. When $c$ is rational, this is either known, or follows from existing results, and our contribution is a resolution of the irrational case. We deduce that for all $c \\not \\in \\{0, 1, 2\\}$, the cardinality of the sumset $S + S$ asymptotically attains its natural upper bound $N(N + 1)/2$, as $N \\to \\infty$. We show that there are infinitely many, effectively computable numbers $c$ such that the set $\\{p^c : \\textrm{$p$ prime}\\}$ is additively dissociated (actually linearly independent over $\\mathbb{Q}$), and we provide an effective procedure to compute the digits of such $c$.",
    "authors": [
      "Joseph Harrison"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01583",
    "title": "Fixed Points in Quantum Metric Spaces: A Structural Advantage over Fuzzy Frameworks",
    "abstract": "We prove an existence and uniqueness theorem for fixed points of contraction maps in the framework of quantum metric spaces, where distinguishability is defined by the $L^2$ norm: $d_Q(\\psi_1,\\psi_2) = \\|\\psi_1 - \\psi_2\\|$. The result applies to normalized real-valued Gaussian wavefunctions under continuous contractive evolution preserving the functional form. In contrast, while fuzzy metric spaces admit analogous fixed point theorems, they lack interference, phase sensitivity, and topological protection. This comparison reveals a deeper structural coherence in the quantum framework -- not merely technical superiority, but compatibility with the geometric richness of Hilbert space. Our work extends the critique of fuzzy logic into dynamical reasoning under intrinsic uncertainty.",
    "authors": [
      "Nicola Fabiano"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03057",
    "title": "A note on the impossibility of conditional PAC-efficient reasoning in large language models",
    "abstract": "We prove an impossibility result for conditional Probably Approximately Correct (PAC)-efficient reasoning in large language models. While recent work has established marginal PAC efficiency guarantees for composite models that switch between expensive expert models and cheaper fast models, we show that conditional (pointwise) guarantees are impossible in the distribution-free setting. Specifically, for non-atomic input spaces, any algorithm achieving conditional PAC efficiency must be trivial in the sense that it defers to the expert model with probability at least $1-\\alpha$ for almost every input.",
    "authors": [
      "Hao Zeng"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03142",
    "title": "Topological Einstein gravity as Kodaira-Spencer gravity",
    "abstract": "As a contribution towards quantizing three-dimensional gravity, we show at the classical level that Euclidean three-dimensional Einstein gravity with a negative cosmological constant is uplifted to the $SU(2)$-invariant sector of Kodaira-Spencer gravity on a Calabi-Yau three-fold. Kodaira-Spencer gravity appears in the target space description of the B-model topological string theory and describes deformations of a complex structure. We prove that given a reference solution of Einstein gravity in the first-order formulation, a second off-shell configuration uplifts to a unique complex structure deformation in six dimensions. If the configuration satisfies Einstein's equations, the complex structure deformation is integrable, i.e. a solution of Kodaira-Spencer gravity. We demonstrate the uplift explicitly for Bañados solutions. Our construction embeds three-dimensional gravity into topological string theory and AdS$_3$/CFT$_2$ duality into twisted holography.",
    "authors": [
      "Johanna Erdmenger",
      "Jonathan Karl",
      "Jani Kastikainen",
      "René Meyer",
      "Henri Scheppach"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03148",
    "title": "Proof that Momentum Mixing Hatsugai Kohmoto equals the Twisted Hubbard Model",
    "abstract": "We prove formally that the momentum-mixing Hatsugai-Kohmoto model (MMHK) is the Hubbard model with a twist. With this result in tow, we rely on the proof of Watanabe's that two models which differ by a twist must have the same bulk physics. Consequently, we have proven that MMHK=Hubbard in the charge sector.",
    "authors": [
      "Yuting Bai",
      "Philip W. Phillips"
    ],
    "primary_category": "cond-mat.str-el",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03164",
    "title": "A Cut-Free Sequent Calculus for the Analysis of Finite-Trace Properties in Concurrent Systems",
    "abstract": "We address the problem of identifying a proof-theoretic framework that enables a compositional analysis of finite-trace properties in concurrent systems, with a particular focus on those specified via prefix-closure. To this end, we investigate the interaction of a prefix-closure operator and its residual (with respect to set-theoretic inclusion) with language intersection, union, and concatenation, and introduce the variety of closure $\\ell$-monoids as a minimal algebraic abstraction of finite-trace properties to be conveniently described within an analytic proof system. Closure $\\ell$-monoids are division-free reducts of distributive residuated lattices equipped with a forward diamond/backward box residuated pair of unary modal operators, where the diamond is a topological closure operator satisfying $\\Diamond(x \\cdot y) \\leq \\Diamond x \\cdot \\Diamond y$. As a logical counterpart to these structures, we present $\\mathsf{LMC}$, a Gentzen-style system based on the division-free fragment of the Distributive Full Lambek Calculus. In $\\mathsf{LMC}$, structural terms are built from formulas using Belnap-style structural operators for monoid multiplication, meet, and diamond. The rules for the modalities and the structural diamond are taken from Moortgat's system $\\mathsf{NL}(\\Diamond)$. We show that the calculus is sound and complete with respect to the variety of closure $\\ell$-monoids and that it admits cut elimination.",
    "authors": [
      "Ludovico Fusco",
      "Alessandro Aldini"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03172",
    "title": "On the Virasoro Crossing Kernels at Rational Central Charge",
    "abstract": "We report novel analytic results for the Virasoro modular and fusion kernels relevant to 2d conformal field theories (CFTs), 3d topological field theories (TQFTs), and the representation theory of certain quantum groups. For all rational values of the parameter $b^2\\in\\mathbb{Q}^{\\times}$ -- corresponding in 2d CFT to all rational central charge values in the domain $(-\\infty,1]\\cup[25,\\infty)$ -- we establish two main results. First, in the domain $c\\in\\mathbb{Q}_{[25,\\infty)}$ we show that the modular and fusion kernels derived by Teschner and Teschner-Vartanov respectively can be expressed as a linear combination of two functions, which (i) are themselves admissible crossing kernels, (ii) have square-root branch point singularities in the Liouville momenta, (iii) are not reflection-symmetric in the Liouville momenta. These features illustrate that the space of solutions to the basic shift relations determining these kernels is broader than previously assumed. Second, in the domain $c\\in\\mathbb{Q}_{(-\\infty,1]}$ we derive for the first time the physical modular and fusion kernels for generic values of the Liouville momenta. These can again be written as a linear combination of two other admissible kernels but overall, and unlike the Teschner and Teschner-Vartanov solutions for $c\\geq 25$, they possess square-root branch point singularities. As a corollary, we demonstrate that timelike Liouville theory at $c\\in\\mathbb{Q}_{(-\\infty,1]}$ is crossing symmetric and modular covariant. Surprisingly, the crossing kernels at any $b^2\\in\\mathbb{Q}^{\\times}$ behave as if they were semiclassical and one-loop exact, and we discuss the interpretation of this fact in the context of the 2d conformal bootstrap and the 3d TQFT that captures pure 3d gravity with negative cosmological constant.",
    "authors": [
      "Julien Roussillon",
      "Ioannis Tsiares"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03193",
    "title": "In Situ Quantum Analog Pulse Characterization via Structured Signal Processing",
    "abstract": "Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults.",
    "authors": [
      "Yulong Dong",
      "Christopher Kang",
      "Murphy Yuezhen Niu"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03221",
    "title": "Permanental rank versus determinantal rank of random matrices over finite fields",
    "abstract": "This paper is motivated by basic complexity and probability questions about permanents of random matrices over finite fields, and in particular, about properties separating the permanent and the determinant. Fix $q = p^m$ some power of an odd prime, and let $k \\leq n$ both be growing. For a uniformly random $n \\times k$ matrix $A$ over $\\mathbb{F}_q$, we study the probability that all $k \\times k$ submatrices of $A$ have zero permanent; namely that $A$ does not have full \"permanental rank\". When $k = n$, this is simply the probability that a random square matrix over $\\mathbb{F}_q$ has zero permanent, which we do not understand. We believe that the probability in this case is $\\frac{1}{q} + o(1)$, which would be in contrast to the case of the determinant, where the answer is $\\frac{1}{q} + \\Omega_q(1)$. Our main result is that when $k$ is $O(\\sqrt{n})$, the probability that a random $n \\times k$ matrix does not have full permanental rank is essentially the same as the probability that the matrix has a $0$ column, namely $(1 +o(1)) \\frac{k}{q^n}$. In contrast, for determinantal (standard) rank the analogous probability is $\\Theta(\\frac{q^k}{q^n})$. At the core of our result are some basic linear algebraic properties of the permanent that distinguish it from the determinant.",
    "authors": [
      "Fatemeh Ghasemi",
      "Gal Gross",
      "Swastik Kopparty"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03224",
    "title": "Modeling and simulation of electrodiffusion in dense reconstructions of cerebral tissue",
    "abstract": "Excitable tissue is fundamental to brain function, yet its study is complicated by extreme morphological complexity and the physiological processes governing its dynamics. Consequently, detailed computational modeling of this tissue represents a formidable task, requiring both efficient numerical methods and robust implementations. Meanwhile, efficient and robust methods for image segmentation and meshing are needed to provide realistic geometries for which numerical solutions are tractable. Here, we present a computational framework that models electrodiffusion in excitable cerebral tissue, together with realistic geometries generated from electron microscopy data. To demonstrate a possible application of the framework, we simulate electrodiffusive dynamics in cerebral tissue during neuronal activity. Our results and findings highlight the numerical and computational challenges associated with modeling and simulation of electrodiffusion and other multiphysics in dense reconstructions of cerebral tissue.",
    "authors": [
      "Halvor Herlyng",
      "Marius Causemann",
      "Gaute T. Einevoll",
      "Ada J. Ellingsrud",
      "Geir Halnes",
      "Marie E. Rognes"
    ],
    "primary_category": "physics.med-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03240",
    "title": "Models of Flow through Porous Media of Polar Fluids with Pressure-Dependent Viscosity",
    "abstract": "Equations governing the flow of a polar fluid, with pressure-dependent Newtonian viscosity, through a variable-porosity medium are developed. Averaged equations are obtained using intrinsic volume averaging. A drag function is introduced to account for the interactions of the fluid with the porous matrix. Darcy and Forchheimer generalized terms are included in the model equations for both granular and consolidated media to account for the effects of the porous microstructure.",
    "authors": [
      "M.H. Hamdan",
      "D.C. Roach"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03243",
    "title": "Novelty detection on path space",
    "abstract": "We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.",
    "authors": [
      "Ioannis Gasteratos",
      "Antoine Jacquier",
      "Maud Lemercier",
      "Terry Lyons",
      "Cristopher Salvi"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03249",
    "title": "Computing Equilibrium Points of Electrostatic Potentials",
    "abstract": "We study the computation of equilibrium points of electrostatic potentials: locations in space where the electrostatic force arising from a collection of charged particles vanishes. This is a novel scenario of optimization in which solutions are guaranteed to exist due to a nonconstructive argument, but gradient descent is unreliable due to the presence of singularities. We present an algorithm based on piecewise approximation of the potential function by Taylor series. The main insight is to divide the domain into a grid with variable coarseness, where grid cells are exponentially smaller in regions where the function changes rapidly compared to regions where it changes slowly. Our algorithm finds approximate equilibrium points in time poly-logarithmic in the approximation parameter, but these points are not guaranteed to be close to exact solutions. Nevertheless, we show that such points can be computed efficiently under a mild assumption that we call \"strong non-degeneracy\". We complement these algorithmic results by studying a generalization of this problem and showing that it is CLS-hard and in PPAD, leaving its precise classification as an intriguing open problem.",
    "authors": [
      "Abheek Ghosh",
      "Paul W. Goldberg",
      "Alexandros Hollender"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03266",
    "title": "Invited Discussion of \"Model Uncertainty and Missing Data: An Objective Bayesian Perspective\" by Gonzalo García-Donato , María Eugenia Castellanos , Stefano Cabras Alicia Quirós , and Anabel Forte",
    "abstract": "The article by Garc{í}a-Donato and co-authors addresses the dual challenges of accounting for model uncertainty and missing data within the Gaussian regression frameworks from an objective Bayesian perspective. Thru the use of an imputation $g$-prior that replaces $X_\\gamma^TX_\\gamma$ for model $\\gamma$ in the covariance of $\\beta_\\gamma$ with $\\Sigma_{X_\\gamma}$, the authors develop a coherent approach to addressing the missing data problem and model uncertainty simultaneously with random $X_\\gamma$ in the missing at random (MAR) or missing completely at random (MCAR) settings, while still being computationally tractable. I discuss the connection of the imputation $g$-prior to the $g$-prior with imputed $X$, and to model selection for graphical models that provide an alternative justification for the $g$-prior for random $X$s.",
    "authors": [
      "Merlise A Clyde"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03267",
    "title": "Orlicz-Lorentz premia and distortion Haezendonck-Goovaerts risk measures",
    "abstract": "In financial and actuarial research, distortion and Haezendonck-Goovaerts risk measures are attractive due to their strong properties. They have so far been treated separately. In this paper, following a suggestion by Goovaerts, Linders, Van Weert, and Tank, we introduce and study a new class of risk measure that encompasses the distortion and Haezendonck-Goovaerts risk measures, aptly called the distortion Haezendonck-Goovaerts risk measures. They will be defined on a larger space than the space of bounded risks. We provide situations where these new risk measures are coherent, and explore their risk theoretic properties.",
    "authors": [
      "Aline Goulard",
      "Karl Grosse-Erdmann"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03270",
    "title": "Curvature Potential Formulation for Thin Elastic Sheets",
    "abstract": "Thin elastic sheets appear in systems ranging from graphene to biological membranes, where phenomena such as wrinkling, folding, and thermal fluctuations originate from geometric nonlinearities. These effects are treated within weakly nonlinear theories, such as the Foppl-von Karman equations, which require small slopes and fail when deflections become large even if strains remain small. We introduce a methodological progress via a geometric reformulation of thin-sheet elasticity based on a stress potential and a curvature potential. This formulation preserves the structure of the classical equations while extending their validity to nonlinear, multivalued configurations, and geometrically frustrated states. The framework provides a unified description of thin-sheet mechanics in regimes inaccessible to existing theories and opens new possibilities for the study of elastic membranes and two-dimensional materials.",
    "authors": [
      "Yael Cohen",
      "Animesh Pandey",
      "Yafei Zhang",
      "Cy Maor",
      "Michael Moshe"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03271",
    "title": "Determining the Qibla Direction by Astronomical and Geometrical Methods",
    "abstract": "This paper investigates the determination of the Qibla direction using both astronomical and geometrical approaches. The study reviews historical and classical methods employed by Muslim scholars and astronomers including the use of instruments such as the astrolabe and compass. It further explores spherical trigonometry techniques to precisely calculate the Qibla azimuth from any given location on Earth. The research clarifies geometric constructions and presents a computational model implemented in C++ to facilitate accurate Qibla determination. This interdisciplinary analysis underscores the rich tradition of Islamic astronomy and geometry in solving practical religious requirements, providing both theoretical frameworks and practical algorithms for modern application.",
    "authors": [
      "Duaa Abdullah"
    ],
    "primary_category": "physics.hist-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03309",
    "title": "Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates",
    "abstract": "Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.",
    "authors": [
      "Aniruddha Bora",
      "Shixuan Zhang",
      "Khemraj Shukla",
      "Bryce Harrop",
      "George Em. Karniadakis",
      "L. Ruby Leung"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03333",
    "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State",
    "abstract": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.",
    "authors": [
      "Xun Tang",
      "Haoxuan Chen",
      "Yuehaw Khoo",
      "Lexing Ying"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03361",
    "title": "Rethinking Security in Semantic Communication: Latent Manipulation as a New Threat",
    "abstract": "Deep learning-based semantic communication (SemCom) has emerged as a promising paradigm for next-generation wireless networks, offering superior transmission efficiency by extracting and conveying task-relevant semantic latent representations rather than raw data. However, the openness of the wireless medium and the intrinsic vulnerability of semantic latent representations expose such systems to previously unrecognized security risks. In this paper, we uncover a fundamental latent-space vulnerability that enables Man-in-the-Middle (MitM) attacker to covertly manipulate the transmitted semantics while preserving the statistical properties of the transmitted latent representations. We first present a Diffusion-based Re-encoding Attack (DiR), wherein the attacker employs a diffusion model to synthesize an attacker-designed semantic variant, and re-encodes it into a valid latent representation compatible with the SemCom decoder. Beyond this model-dependent pathway, we further propose a model-agnostic and training-free Test-Time Adaptation Latent Manipulation attack (TTA-LM), in which the attacker perturbs and steers the intercepted latent representation toward an attacker-specified semantic target by leveraging the gradient of a target loss function. In contrast to diffusion-based manipulation, TTA-LM does not rely on any generative model and does not impose modality-specific or task-specific assumptions, thereby enabling efficient and broadly applicable latent-space tampering across diverse SemCom architectures. Extensive experiments on representative semantic communication architectures demonstrate that both attacks can significantly alter the decoded semantics while preserving natural latent-space distributions, making the attacks covert and difficult to detect.",
    "authors": [
      "Zhiyuan Xi",
      "Kun Zhu"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03476",
    "title": "ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms",
    "abstract": "Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop\" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.",
    "authors": [
      "Juan Diego Toscano",
      "Daniel T. Chen",
      "George Em Karniadakis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03487",
    "title": "Double-Edge-Assisted Computation Offloading and Resource Allocation for Space-Air-Marine Integrated Networks",
    "abstract": "In this paper, we propose a double-edge-assisted computation offloading and resource allocation scheme tailored for space-air-marine integrated networks (SAMINs). Specifically, we consider a scenario where both unmanned aerial vehicles (UAVs) and a low earth orbit (LEO) satellite are equipped with edge servers, providing computing services for maritime autonomous surface ships (MASSs). Partial computation workloads of MASSs can be offloaded to both UAVs and the LEO satellite, concurrently, for processing via a multi-access approach. To minimize the energy consumption of SAMINs under latency constraints, we formulate an optimization problem and propose energy efficient algorithms to jointly optimize offloading mode, offloading volume, and computing resource allocation of the LEO satellite and the UAVs, respectively. We further exploit an alternating optimization (AO) method and a layered approach to decompose the original problem to attain the optimal solutions. Finally, we conduct simulations to validate the effectiveness and efficiency of the proposed scheme in comparison with benchmark algorithms.",
    "authors": [
      "Zhen Wang",
      "Bin Lin",
      "Qiang"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03555",
    "title": "Accelerating shape optimization by deep neural networks with on-the-fly determined architecture",
    "abstract": "In component shape optimization, the component properties are often evaluated by computationally expensive simulations. Such optimization becomes unfeasible when it is focused on a global search requiring thousands of simulations to be evaluated. Here, we present a viable global shape optimization methodology based on multi-objective evolutionary algorithms accelerated by deep neural networks (DNNs). Our methodology alternates between evaluating simulations and utilizing the generated data to train DNNs with various architectures. When a suitable DNN architecture is identified, the DNN replaces the simulation in the rest of the global search. Our methodology was tested on five ZDT benchmark functions, showing itself at the level of and sometimes more flexible than other state-of-the-art acceleration approaches. Then, it was applied to a real-life optimization problem, namely the shape optimization of a single-phase ejector. Compared with a non-accelerated methodology, ours was able to save weeks of CPU time in solving this problem. To experimentally confirm the performance of the optimized ejector shapes, four of them were 3D printed and tested on the lab scale confirming the predicted performance. This suggests that our methodology could be used for acceleration of other real-life shape optimization problems.",
    "authors": [
      "Lucie Kubíčková",
      "Onřej Gebouský",
      "Jan Haidl",
      "Martin Isoz"
    ],
    "primary_category": "cs.CE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03579",
    "title": "Optimal Transportation and Alignment Between Gaussian Measures",
    "abstract": "Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.",
    "authors": [
      "Sanjit Dandapanthula",
      "Aleksandr Podkopaev",
      "Shiva Prasad Kasiviswanathan",
      "Aaditya Ramdas",
      "Ziv Goldfeld"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03645",
    "title": "Gauge Symmetries, Contact Reduction, and Singular Field Theories",
    "abstract": "The reduction of dynamical systems which are invariant under changes of global scale is well-understood, for classical theories of particles, and fields. The excision of the superfluous degree of freedom describing such a scale leads to a dynamically-equivalent theory, which is frictional in nature. In this article, we extend the formalism to physical models, of both particles and fields, described by singular Lagrangians. Our treatment of classical field theory is based on the manifestly covariant Hamilton De-Donder Weyl formalism, in which the Lagrangian density is introduced as a bundle morphism on the pre-multisymplectic velocity phase space $J^1E$. The results obtained are subsequently applied to a number of physically-motivated examples, as well as a discussion presented on the implications of our work for classical General Relativity.",
    "authors": [
      "Callum Bell",
      "David Sloan"
    ],
    "primary_category": "gr-qc",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03660",
    "title": "Linking Aneurysmal Geometry and Hemodynamics Using Computational Fluid Dynamics",
    "abstract": "The development and progression of abdominal aortic aneurysms (AAA) are related to complex flow patterns and wall-shear-driven mechanobiological stimuli, yet the quantitative relationship between aneurysmal geometry and hemodynamics remains poorly defined. In this study, we conducted a comprehensive hemodynamic analysis of 74 patient-specific abdominal aortas, representing one of the largest Computational Fluid Dynamics (CFD) cohorts reported to date. A multiscale framework coupling 0D-1D systemic circulation models with 3D stabilized finite-element simulations is used to generate physiologically consistent boundary conditions and high-fidelity flow fields. From each model, we extract Time Averaged Wall Shear Stress (TAWSS), Oscillatory Shear Index (OSI), Relative Residence Time (RRT) and Local Normalized Helicity (LNH) indicators alongside an extended set of geometric descriptors characterizing diameter, curvature and torsion. This study provides a clear and comprehensive view of how aneurysm shape influences blood-flow behavior, supported by one of the largest systematically analyzed CFD datasets of AAAs to date. Our results show that specific geometric features reliably shape shear-stress patterns, suggesting that these geometry-driven flow signatures could serve as valuable biomarkers for patient-specific risk assessment. Together, these insights highlight the potential of incorporating detailed geometric descriptors into future models that aim to predict AAA growth and rupture.",
    "authors": [
      "Spyridon C. Katsoudas",
      "Konstantina C. Kyriakoudi",
      "Grigorios T. Chrimatopoulos",
      "Panagiotis D. Linardopoulos",
      "Christoforos T. Chrimatopoulos",
      "Anastasios A. Raptis",
      "Konstantinos G. Moulakakis",
      "John D. Kakisis",
      "Christos G. Manopoulos",
      "Michail A. Xenos",
      "Efstratios E. Tzirtzilakis"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03706",
    "title": "Consistent Projection of Langevin Dynamics: Preserving Thermodynamics and Kinetics in Coarse-Grained Models",
    "abstract": "Coarse graining (CG) is an important task for efficient modeling and simulation of complex multi-scale systems, such as the conformational dynamics of biomolecules. This work presents a projection-based coarse-graining formalism for general underdamped Langevin dynamics. Following the Zwanzig projection approach, we derive a closed-form expression for the coarse grained dynamics. In addition, we show how the generator Extended Dynamic Mode Decomposition (gEDMD) method, which was developed in the context of Koopman operator methods, can be used to model the CG dynamics and evaluate its kinetic properties, such as transition timescales. Finally, we combine our approach with thermodynamic interpolation (TI), a generative approach to transform samples between thermodynamic conditions, to extend the scope of the approach across thermodynamic states without repeated numerical simulations. Using a two-dimensional model system, we demonstrate that the proposed method allows to accurately capture the thermodynamic and kinetic properties of the full-space model.",
    "authors": [
      "Vahid Nateghi",
      "Lara Neureither",
      "Selma Moqvist",
      "Carsten Hartmann",
      "Simon Olsson",
      "Feliks Nüske"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03740",
    "title": "Quantum Max Cut for complete tripartite graphs",
    "abstract": "The Quantum Max-$d$-Cut ($d$-QMC) problem is a special instance of a $2$-local Hamiltonian problem, representing the quantum analog of the classical Max-$d$-Cut problem. The $d$-QMC problem seeks the largest eigenvalue of a Hamiltonian defined on a graph with $n$ vertices, where edges correspond to swap operators acting on $(\\mathbb{C}^d)^{\\otimes n}$. In recent years, progress has been made by investigating the algebraic structure of the $d$-QMC Hamiltonian. Building on this approach, this article solves the $d$-QMC problem for complete tripartite graphs for small local dimensions, $d \\le 3$.",
    "authors": [
      "Tea Štrekelj"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03767",
    "title": "CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond",
    "abstract": "The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.",
    "authors": [
      "Bo Qian",
      "Hanlin Wu",
      "Jiacheng Chen",
      "Yunting Xu",
      "Xiaoyu Wang",
      "Haibo Zhou",
      "Yusheng Ji"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03779",
    "title": "Exact and Parametric Dynamical System Representation of Nonlinear Functions",
    "abstract": "Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation.",
    "authors": [
      "Toshiyuki Ohtsuka"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03807",
    "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics",
    "abstract": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.",
    "authors": [
      "Christos Kolomvakis",
      "Thomas Bobille",
      "Arnaud Vandaele",
      "Nicolas Gillis"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03808",
    "title": "Solution of the Electric Field Integral Equation Using a Hybrid Quantum-Classical Scheme: Investigation of Accuracy and Efficiency",
    "abstract": "Conventional classical solvers are commonly used for solving matrix equation systems resulting from the discretization of SIEs in computational electromagnetics (CEM). However, the memory requirement would become a bottleneck for classical computing as the electromagentic problems become much larger. As an alternative, quantum computing has a natural \"parallelization\" advantage with much lower storage complexity due to the superposition and entanglement in quantum mechanics. Even though several quantum algorithms have been applied for the SIEs-based methods in the literature, the size of the matrix equation systems solvable using them is still limited. In this work, we use a hybrid quantum-classical scheme to solve the EFIE for analyzing electromagentic scattering from three-dimensional (3D) perfect electrically conducting objects with arbitrary shapes in CEM for the first time. Instead of directly solving the original EFIE matrix equation system using the quantum algorithms, the hybrid scheme first designs the preconditioned linear system and then uses a double-layer iterative strategy for its solution, where the external iteration layer builds subspace matrix equation systems with smaller dimension and the internal iteration layer solves the smaller systems using the quantum algorithms. Two representative quantum algorithms, HHL and VQLS, are considered in this work, which are executed on the quantum simulator and quantum computer platforms. We present the theoretical time complexity analysis of the hybrid quantum-classical scheme and perform numerical experiments to investigate the accuracy and efficiency of the hybrid scheme. The results show that the computational complexity of the hybrid VQLS-classical scheme is lower than the conventional fast solvers in classical computing, which indicates the hybrid scheme is more promising for analyzing large-scale electromagnetic problems.",
    "authors": [
      "Rui Chen",
      "Teng-Yang Ma",
      "Meng-Han Dou",
      "Chao-Fu Wang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03857",
    "title": "Classification of diffusion processes in dimension $d$ via the Carleman approach with applications to models involving additive, multiplicative or square-root noises",
    "abstract": "The Carleman approach is well-known in the field of deterministic classical dynamics as a method to replace a finite number $d$ of non-linear differential equations by an infinite-dimensional linear system. Here this approach is applied to a system of $d$ stochastic differential equations for $[x_1(t),..,x_d(t)]$ when the forces and the diffusion-matrix elements are polynomials, in order to write the linear system governing the dynamics of the averaged values ${\\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) ... x_d^{n_d}(t) )$ labelled by the $d$ integers $(n_1,..,n_d)$. The natural decomposition of the Carleman matrix into blocks associated to the global degree $n=n_1+n_2+..+n_d$ is useful to identify the models that have the simplest spectral decompositions in the bi-orthogonal basis of right and left eigenvectors. This analysis is then applied to models with a single noise per coordinate, that can be either additive or multiplicative or square-root, or with two types of noises per coordinate, with many examples in dimensions $d=1,2$. In $d=1$, the Carleman matrix governing the dynamics of the moments ${\\mathbb E} ( x^{n}(t) )$ is diagonal for the Geometric Brownian motion, while it is lower-triangular for the family of Pearson diffusions containing the Ornstein-Uhlenbeck and the Square-Root processes, as well as the Kesten, the Fisher-Snedecor and the Student processes that converge towards steady states with power-law-tails. In dimension $d=2$, the Carleman matrix governing the dynamics of the correlations ${\\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) )$ has a natural decomposition into blocks associated to the global degree $n=n_1+n_2$, and we discuss the simplest models where the Carleman matrix is either block-diagonal or block-lower-triangular or block-upper-triangular.",
    "authors": [
      "Cecile Monthus"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03899",
    "title": "Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction",
    "abstract": "Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.",
    "authors": [
      "Janis Keck",
      "Lukas Silvester Barth",
      "Fatemeh",
      "Fahimi",
      "Parvaneh Joharinad",
      "Jürgen Jost"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03916",
    "title": "New Perspectives on Semiring Applications to Dynamic Programming",
    "abstract": "Semiring algebras have been shown to provide a suitable language to formalize many noteworthy combinatorial problems. For instance, the Shortest-Path problem can be seen as a special case of the Algebraic-Path problem when applied to the tropical semiring. The application of semirings typically makes it possible to solve extended problems without increasing the computational complexity. In this article we further exploit the idea of using semiring algebras to address and tackle several extensions of classical computational problems by dynamic programming. We consider a general approach which allows us to define a semiring extension of any problem with a reasonable notion of a certificate (e.g., an NP problem). This allows us to consider cost variants of these combinatorial problems, as well as their counting extensions where the goal is to determine how many solutions a given problem admits. The approach makes no particular assumptions (such as idempotence) on the semiring structure. We also propose a new associative algebraic operation on semirings, called $\\Delta$-product, which enables our dynamic programming algorithms to count the number of solutions of minimal costs. We illustrate the advantages of our framework on two well-known but computationally very different NP-hard problems, namely, Connected-Dominating-Set problems and finite-domain Constraint Satisfaction Problems (CSPs). In particular, we prove fixed parameter tractability (FPT) with respect to clique-width and tree-width of the input. This also allows us to count solutions of minimal cost, which is an overlooked problem in the literature.",
    "authors": [
      "Ambroise Baril",
      "Miguel Couceiro",
      "Victor Lagerkvist"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03923",
    "title": "Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations",
    "abstract": "Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.",
    "authors": [
      "Xiang Rao",
      "Yina Liu",
      "Yuxuan Shen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03950",
    "title": "Collective dynamics of trail-interacting particles",
    "abstract": "Trail interactions occur when past particle trajectories bias future motion, rendering the system out of thermodynamic equilibrium. While such systems are abundant in nature, their understanding is limited to the single-particle level or phenomenological mean-field theories. Here, we introduce a minimal model of many trail-interacting particles that extends this paradigm to the fluctuating collective level. Particles diffuse while depositing long-lasting repelling/attracting trails that act as a shared memory field, coupling their dynamics across time and space. Using stochastic density functional theory, we derive fluctuating hydrodynamic equations and analyze analytically and numerically the resulting behaviors. We show that memory, coupled with fluctuations, fundamentally reshapes collective dynamics; In the repulsive case, the particle density displays superdiffusive spreading characterized by transient clustering and ballistic motion; In the attractive case, the system condensates in finite time into frozen, localized states. Our results establish general principles for trail-interacting systems and reveal how persistent fields generate novel instabilities and self-organization.",
    "authors": [
      "Paul Pineau",
      "Samuel Bell",
      "Raphaël Voituriez",
      "Ram M. Adar"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03977",
    "title": "An Information Theory of Finite Abstractions and their Fundamental Scalability Limits",
    "abstract": "Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy\" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.",
    "authors": [
      "Giannis Delimpaltadakis",
      "Gabriel Gleizer"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04006",
    "title": "Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics",
    "abstract": "Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.",
    "authors": [
      "Connall Garrod",
      "Jonathan P. Keating",
      "Christos Thrampoulidis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04051",
    "title": "Convergence for Discrete Parameter Updates",
    "abstract": "Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.",
    "authors": [
      "Paul Wilson",
      "Fabio Zanasi",
      "George Constantinides"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04058",
    "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap",
    "abstract": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.",
    "authors": [
      "Shashaank Khanna",
      "Matthew Pusey",
      "Roger Colbeck"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04059",
    "title": "Inference for location and height of peaks of a standardized field after selection",
    "abstract": "Peak inference concerns the use of local maxima (\"peaks\") of a noisy random field to detect and localize regions where underlying signal is present. We propose a peak inference method that first subjects observed peaks to a significance test of the null hypothesis that no signal is present, and then uses the peaks that are declared significant to construct post-selectively valid confidence regions for the location and height of nearby true peaks. We analyze the performance of this method in a smooth signal plus constant variance noise model under a high-curvature asymptotic assumption, and prove that it asymptotically controls both the number of false discoveries, and the number of confidence regions that do not contain a true peak, relative to the number of points at which inference is conducted. An important intermediate theoretical result uses the Kac-Rice formula to derive a novel approximation to the intensity function of a point process that counts local maxima, which is second-order accurate under the alternative, nearby high-curvature true peaks.",
    "authors": [
      "Alden Green",
      "Jonathan Taylor"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04074",
    "title": "Well-quasi-orders on embedded planar graphs",
    "abstract": "The central theorem of topological graph theory states that the graph minor relation is a well-quasi-order on graphs. It has far-reaching consequences, in particular in the study of graph structures and the design of (parameterized) algorithms. In this article, we study two embedded versions of classical minor relations from structural graph theory and prove that they are also well-quasi-orders on general or restricted classes of embedded planar graphs. These embedded minor relations appear naturally for intrinsically embedded objects, such as knot diagrams and surfaces in $\\mathbb{R}^3$. Handling the extra topological constraints of the embeddings requires careful analysis and extensions of classical methods for the more constrained embedded minor relations. We prove that the embedded version of immersion induces a well-quasi-order on bounded carving-width plane graphs by exhibiting particularly well-structured tree-decompositions and leveraging a classical argument on well-quasi-orders on forests. We deduce that the embedded graph minor relation defines a well-quasi-order on plane graphs via their directed medial graphs, when their branch-width is bounded. We conclude that the embedded graph minor relation is a well-quasi-order on all plane graphs, using classical grids theorems in the unbounded branch-width case.",
    "authors": [
      "Corentin Lunel",
      "Clément Maria"
    ],
    "primary_category": "cs.CG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:1903.00813",
    "title": "Enumeration and Asymptotic Formulas for Rectangular Partitions of the Hypercube",
    "abstract": "We study a two-parameter generalization of the Catalan numbers: $C_{d,p}(n)$ is the number of ways to subdivide the $d$-dimensional hypercube into $n$ rectangular blocks using orthogonal partitions of fixed arity $p$. Bremner \\& Dotsenko introduced $C_{d,p}(n)$ in their work on Boardman--Vogt tensor products of operads; they used homological algebra to prove a recursive formula and a functional equation. We express $C_{d,p}(n)$ as simple finite sums, and determine their growth rate and asymptotic behaviour. We give an elementary proof of the functional equation, using a bijection between hypercube decompositions and a family of full $p$-ary trees. Our results generalize the well-known correspondence between Catalan numbers and full binary trees.",
    "authors": [
      "Yu Hin Au",
      "Fatemeh Bagherzadeh",
      "Murray R. Bremner"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2003.02528",
    "title": "Eight flavours of cyclic homology",
    "abstract": "We introduce eight versions of cyclic homology of a mixed complex and study their properties. In particular, we determine their behaviour with respect to Chen iterated integrals.",
    "authors": [
      "K. Cieliebak",
      "E. Volkov"
    ],
    "primary_category": "math.AT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2102.13480",
    "title": "Kinks and solitons in linear and nonlinear-diffusion Keller-Segel type models with logarithmic sensitivity",
    "abstract": "This paper investigates the existence of traveling--wave--type patterns in the Keller--Segel model with logarithmic sensitivity. We consider both the linear diffusion case and the nonlinear, flux-saturated diffusion of relativistic heat--equation type, providing a detailed comparison between the two regimes. Particular attention is devoted to traveling waves exhibiting compact support or support restricted to a half-line. We rigorously establish the existence of such patterns and highlight the qualitative differences arising from the choice of diffusion mechanism.",
    "authors": [
      "Juan Campos",
      "Claudia García",
      "Carlos Pulido",
      "Juan Soler"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2103.15485",
    "title": "A variational approach to frozen planet orbits in helium",
    "abstract": "We present variational characterizations of frozen planet orbits for the helium atom in the Lagrangian and the Hamiltonian picture. They are based on a Levi-Civita regularization with different time reparametrizations for the two electrons and lead to nonlocal functionals. Within this variational setup, we deform the helium problem to one where the two electrons interact only by their mean values and use this to deduce the existence of frozen planet orbits.",
    "authors": [
      "Kai Cieliebak",
      "Urs Frauenfelder",
      "Evgeny Volkov"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2209.12634",
    "title": "Nondegeneracy and integral count of frozen planet orbits in helium",
    "abstract": "We study a family of action functionals whose critical points interpolate between frozen planet orbits for the helium atom with mean interaction between the electrons and the free fall. The rather surprising first result of this paper asserts that for the whole family, critical points are always nondegenerate. This implies that the frozen planet orbit with mean interaction is nondegenerate and gives a new proof of its uniqueness. As an application, we show that the integral count of frozen planet orbits with instantaneous interaction equals one. For this, we prove orientability of the determinant line bundle over the space of selfadjoint Fredholm operators with spectrum bounded from below, and use it to define an integer valued Euler characteristic for Fredholm sections whose linearization belongs to this class.",
    "authors": [
      "Kai Cieliebak",
      "Urs Frauenfelder",
      "Evgeny Volkov"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2301.09067",
    "title": "Polystability of Stokes representations and differential Galois groups",
    "abstract": "Polystability of (twisted) Stokes representations (i.e. wild monodromy representations) will be characterised, in terms of the corresponding differential Galois group (generalising the Zariski closure of the monodromy group in the tame case). This extends some results of Richardson. Further, the intrinsic approach to such results will be established, in terms of reductions of Stokes local systems.",
    "authors": [
      "Philip Boalch",
      "Daisuke Yamakawa"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2303.04993",
    "title": "Sheaf realization of Bridgeland's Hall algebra of Dynkin type",
    "abstract": "As one of results in [6], Bridgeland realized the quantum group $\\mathbf{U}_v$ via the localization of Ringel-Hall algebra for the two-periodic projective complexes of quiver representations over a finite field. In the present paper, we generalize Lusztig's categorical construction for the nilpotent part $\\mathbf{U}_v^+$ to Bridgeland's Hall algebra of Dynkin type. In particular, we obtain a basis of the Ringel-Hall algebra for the two-periodic projective complexes which has the positivity, and we categorify an integral form of the generic Bridgeland's Hall algebra which is isomorphic to the Poisson integral form of $\\mathbf{U}_v$, and obtain a $\\mathbb{Z}[v,v^{-1}]$-basis of this integral form.",
    "authors": [
      "Jiepeng Fang",
      "Yixin Lan",
      "Jie Xiao"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2304.00581",
    "title": "Generalized Von Neumann Universe and Non-Well-Founded Sets",
    "abstract": "In this paper, a generalized version of the von Neumann universe known as the total universe is proposed to formally introduce non-well-founded sets that include infinitons, semi-infinitons and quasi-infinitons in Russell's paradox. All three infinitons are part of infinitely generated sets that are generators of non-well-founded sets. Combining the well-founded sets with the non-well-founded sets, the total universe is a model of ZF minus the axiom of regularity and free of Russell's paradox. The axiom of regularity is invalid in defining well-founded sets and wrong in any system consistent with ZF set theory.",
    "authors": [
      "Eugene Zhang"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2304.04863",
    "title": "Bounds for the periods of eigenfunctions on arithmetic hyperbolic 3-manifolds over surfaces",
    "abstract": "Let $\\psi$ be a Hecke-Maass form on a compact congruence arithmetic hyperbolic 3-manifold $X$, and let $Y$ be a hyperbolic surface in $X$ that is not necessarily closed. We obtain a power saving result over the local bound for the period of $\\psi$ along $Y$, by applying the method of arithmetic amplification developed by Iwaniec and Sarnak.",
    "authors": [
      "Jiaqi Hou"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2308.08127",
    "title": "Fano threefolds in positive characteristic IV",
    "abstract": "Based on the former parts, we classify smooth Fano threefolds of positive characteristic.",
    "authors": [
      "Hiromu Tanaka"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2310.15295",
    "title": "An index theorem for Z/2-harmonic spinors branching along a graph",
    "abstract": "We prove an index formula for the Dirac operator acting on two-valued spinors on a $3$-manifold $M$ which branch along a smoothly embedded graph $\\Sigma \\subset M$, and with respect to a boundary condition along $\\Sigma$ inspired by an instance of this setting related to the deformation theory of $\\mathbb Z_2$-harmonic spinors. When $\\Sigma$ is a smooth embedded curve, this index vanishes; this was proved earlier by one of us, but the proof here is different and extends to the more general setting where $\\Sigma$ also has vertices. We focus primarily on the Dirac operator itself, but also show how our results apply to more general twisted Dirac operators and to the closely related $\\mathbb Z_2$ harmonic $1$-forms.",
    "authors": [
      "Andriy Haydys",
      "Rafe Mazzeo",
      "Ryosuke Takahashi"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.08804",
    "title": "Capacity Bounds and Low-Complexity Constellation Shaping under Mixed Gaussian-Impulsive Noise",
    "abstract": "This paper investigates the bounds on channel capacity and constellation shaping under memoryless mixed noise, which is composed of impulsive noise (IN) and white Gaussian noise (WGN). The capacity bounds are derived using the entropy power inequality and the dual expression of capacity. It is then shown that the proposed lower and upper bounds asymptotically converge to the true channel capacity, and the analytic asymptotic capacity expression is obtained. Leveraging this property, we design a low-complexity constellation shaping method that operates without iterative procedures. Simulation results demonstrate that the derived bounds are remarkably tight, and the shaped constellation achieves the highest mutual information among all considered baseline schemes.",
    "authors": [
      "Tianfu Qi",
      "Jun Wang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.08837",
    "title": "On the distance spectral radius, fractional matching and factors of graphs with given minimum degree",
    "abstract": "A fractional matching of $G$ is a function $f: E(G)\\to [0,1]$ such that $\\sum_{e\\in E_G(v_i)}f(e)\\le 1$ for any $v_i\\in V(G)$, where $E_G(v_i)=\\{e: e\\in E(G) \\ \\textrm{and}\\ e \\ \\textrm{is incident with} \\ v_i\\}$. Let $\\alpha_f(G)$ denote the fractional matching number of $G$, which is defined as $\\alpha_f(G)=\\max\\{\\sum_{e\\in E(G)}f(e): f\\ \\textrm{is a fractional matching of} \\ G\\}$. Let $\\{G_1,G_2,G_3,\\dots\\}$ be a set of graphs, a $\\{G_1,G_2,G_3,\\dots\\}$-factor of a graph $G$ is a spanning subgraph of $G$ such that each component of which is isomorphic to one of $\\{G_1,G_2,G_3,\\dots\\}$. In this paper, we first establish a sharp upper bound for the distance spectral radius to guarantee that $\\alpha_f(G)>\\frac{n-k}{2}$ in a graph $G$ of order $n$ with given minimum degree, where $0<k<n$ is an integer. Then we give a sharp upper bound on the distance spectral radius of a graph $G$ with given minimum degree $\\delta$ to ensure that $G$ has a $\\{K_2, \\{C_k\\}\\}$-factor, where $3\\le k<+\\infty$ is an integer. Moreover, we obtain a sharp upper bound on the distance spectral radius for the existence of a $\\{K_{1,1},K_{1,2},\\dots,K_{1,k}\\}$-factor with $2\\le k<+\\infty$ in a graph $G$ with given minimum degree.",
    "authors": [
      "Zengzhao Xu",
      "Weige Xi",
      "Ligong Wang"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.05185",
    "title": "Connected components of qcqs schemes and projective spaces",
    "abstract": "In this article, we first prove a general result in topology which asserts that every quasi-component of a quasi-spectral space is connected. As an important application, the structure of all connected components of every quasi-compact quasi-separated (qcqs) scheme $X$ is fully characterized. They are exactly of the form ...",
    "authors": [
      "Abolfazl Tarizadeh"
    ],
    "primary_category": "math.AC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.08113",
    "title": "Feynman Graph Integrals on $\\mathbb{C}^d$",
    "abstract": "We introduce a type of graph integrals which are holomorphic analogs of configuration space integrals. We prove their (ultraviolet) finiteness by considering a compactification of the moduli space of graphs with metrics, and study their failure to be holomorphic.",
    "authors": [
      "Minghao Wang"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.14433",
    "title": "Matching, odd $[1,b]$-factor and distance spectral radius of graphs with given some parameters",
    "abstract": "For a connected graph $G$, let $\\mu(G)$ denote the distance spectral radius of $G$. A matching in a graph $G$ is a set of disjoint edges of $G$. The maximum size of a matching in $G$ is called the matching number of $G$, denoted by $\\alpha(G)$. An odd $[1, b]$-factor of a graph $G$ is a spanning subgraph $G_0$ such that the degree $d_{G_0}(v)$ of $v$ in $G_0$ is odd and $1\\le d_{G_0}(v)\\le b$ for every vertex $v\\in V (G)$. In this paper, we give a sharp upper bound in terms of the distance spectral radius to guarantee $\\alpha(G)>\\frac{n-k}{2}$ in an $n$-vertex $t$-connected graph $G$, where $2\\le k \\le n-2$ is an integer. We also present a sharp upper bound in terms of distance spectral radius for the existence of an odd $[1,b]$-factor in a graph with given minimum degree $\\delta$.",
    "authors": [
      "Zengzhao Xu",
      "Weige Xi",
      "Ligong Wang"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2402.03404",
    "title": "On the $D_α$ spectral radius of non-transmission regular graphs",
    "abstract": "Let $G$ be a connected graph with order $n$ and size $m$. Let $D(G)$ and $Tr(G)$ be the distance matrix and diagonal matrix with vertex transmissions of $G$, respectively. For any real $\\alpha\\in[0,1]$, the generalized distance matrix $D_\\alpha(G)$ of $G$ is defined as $$D_\\alpha(G)=\\alpha Tr(G)+(1-\\alpha)D(G).$$ The largest eigenvalue of $D_{\\alpha}(G)$ is called the $D_{\\alpha}$ spectral radius or generalized distance spectral radius of $G$, denoted by $\\mu_{\\alpha}(G)$. In this paper, we establish a lower bound on the difference between the maximum vertex transmission and the $D_\\alpha$ spectral radius of non-transmission regular graphs, and we also characterize the extremal graphs attaining the bound.",
    "authors": [
      "Zengzhao Xu",
      "Weige Xi",
      "Ligong Wang"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2402.07522",
    "title": "Maximum number of rational points on hypersurfaces in weighted projective spaces over finite fields",
    "abstract": "An upper bound for the maximum number of rational points on an hypersurface in a projective space over a finite field has been conjectured by Tsfasman and proved by Serre in 1989. The analogue question for hypersurfaces on weighted projective spaces has been considered by Castryck, Ghorpade, Lachaud, O'Sullivan, Ram and the first author in 2017. A conjecture has been proposed there and proved in the particular case of the dimension 2. We prove here the conjecture in any dimension provided the second weight is also equal to one.",
    "authors": [
      "Yves Aubry",
      "Marc Perret"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2405.02203",
    "title": "Convergence of a Finite Volume Scheme for Compactly Heterogeneous Scalar Conservation Laws",
    "abstract": "We build a finite volume scheme for the scalar conservation law $\\partial_t u + \\partial_x (H(x, u)) = 0$ with bounded initial condition for a wide class of flux function $H$, convex with respect to the second variable. The main idea for the construction of the scheme is to use the theory of discontinuous flux. We prove that the resulting approximating sequence converges boundedly almost everywhere on $\\mathopen]0, +\\infty\\mathclose[$ to the entropy solution.",
    "authors": [
      "Abraham Sylla"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2405.03414",
    "title": "A New Lineserach for Accelerated Composite Minimization",
    "abstract": "The choice of the stepsize in first-order convex optimization is typically based on the smoothness constant and plays a crucial role in the performance of algorithms. Recently, there has been a resurgent interest in introducing adaptive stepsizes that do not explicitly depend on smooth constant. In this paper, we propose a novel linesearch stepsize rule based on function evaluations (i.e., zero-order information) that enjoys provable convergence guarantees for both accelerated and non-accelerated gradient descent. We further discuss the similarities and differences between the proposed stepsize regimes and the existing stepsize rules (including Polyak and Armijo). We numerically benchmark the performance of our proposed algorithms against state-of-the-art methods across three major problems classes of (1) smooth minimization (logistic regression, quadratic programs, log-sum-exponential, and smooth max-cut relaxation) (2) composite minimization ($\\ell_1$-regularized least-squares, $\\ell_1$-constrained least-squares, and $\\ell_1$-regularized logistic regression), and (3) non-convex minimization (cubic minimization). These classes include a wide range of operations research and management applications such as portfolio optimization, discrete choice models, sparse classification and feature selections, high-order optimization and trust-region subproblems.",
    "authors": [
      "Reza Rahimi Baghbadorani",
      "Sergio Grammatico",
      "Peyman Mohajerin Esfahani"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2405.08933",
    "title": "On the Characteristics of the Conjugate Function Enabling Effective Dual Decomposition Methods",
    "abstract": "We investigate a novel characteristic of the conjugate function associated to a generic convex optimization problem, which can subsequently be leveraged for efficient dual decomposition methods. In particular, under mild assumptions, we show that there is a specific region in the domain of the conjugate function such that for any point in the region, there is always a ray originating from that point along which the gradients of the conjugate remain constant. We refer to this characteristic as a fixed gradient over rays (FGOR). We further show that this characteristic is inherited by the corresponding dual function. Then we provide a thorough exposition of the application of the FGOR characteristic to dual subgradient methods. More importantly, we leverage FGOR to devise a simple stepsize rule that can be prepended with state-of-the-art stepsize methods enabling them to be more efficient. Furthermore, we investigate how the FGOR characteristic is used when solving the global consensus problem, a prevalent formulation in diverse application domains. We show that FGOR can be exploited not only to expedite the convergence of the dual decomposition methods but also to reduce the communication overhead. FGOR is extended to nonconvex formulations, and its advantages in stochastic optimization are demonstrated. Numerical experiments using quadratic objectives and a regularized least squares regression with real datasets are conducted. The results show that FGOR can significantly improve the performance of existing stepsize methods and outperform the state-of-the-art splitting methods on average in terms of both convergence behavior and communication efficiency.",
    "authors": [
      "Hansi Abeynanda",
      "Chathuranga Weeraddana",
      "Carlo Fischione"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.03644",
    "title": "Fibered ribbon pretzels",
    "abstract": "We classify fibered ribbon pretzel knots up to mutation. The classification is complete, except perhaps for members of Lecuona's ``exceptional'' family of [Lec15]. The result is obtained by combining lattice embedding techniques with Gabai's classification of fibered pretzel knots, and exhibiting ribbon disks, some of which lie outside of known patterns for standard pretzel projections.",
    "authors": [
      "Ana G. Lecuona",
      "Andy Wand"
    ],
    "primary_category": "math.GT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.03799",
    "title": "An abundance-type result for the tangent bundles of smooth Fano varieties",
    "abstract": "In this paper we prove the following abundance-type result: for any smooth Fano variety $X$, the tangent bundle $T_X$ is nef if and only if it is big and semiample in the sense that the tautological line bundle $\\mathscr{O}_{\\mathbb{P}T_X}(1)$ is so, by which we establish a weak form of the Campana-Peternell conjecture (Camapan-Peternell, 1991).",
    "authors": [
      "Juanyong Wang"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.00806",
    "title": "Asymptotic dynamics on amenable groups and van der Corput sets",
    "abstract": "We answer a question of Bergelson and Lesigne by showing that the notion of van der Corput set does not depend on the Følner sequence used to define it. This result has been discovered independently by Saúl Rodríguez Martín. Both ours and Rodríguez's proofs proceed by first establishing a converse to the Furstenberg Correspondence Principle for amenable groups. This involves studying the distributions of Reiter sequences over congruent sequences of tilings of the group. Lastly, we show that many of the equivalent characterizations of van der Corput sets in $\\mathbb{N}$ that do not involve Følner sequences remain equivalent for arbitrary countably infinite groups.",
    "authors": [
      "Sohail Farhangi",
      "Robin Tucker-Drob"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.08297",
    "title": "Matrix-free stochastic calculation of operator norms without using adjoints",
    "abstract": "This paper considers the problem of computing the operator norm of a linear map between finite dimensional Hilbert spaces when only evaluations of the linear map are available and under restrictive storage assumptions. We propose a stochastic method of random search type to maximize the Rayleigh quotient and employ an exact line search in the random search directions. Moreover, we show that the proposed algorithm converges to the global maximum (the operator norm) almost surely and a sublinear convergence behavior for the corresponding eigenvector and eigenvalue equation. Finally, we illustrate the performance of the method with numerical experiments.",
    "authors": [
      "Jonas Bresch",
      "Dirk A. Lorenz",
      "Felix Schneppe",
      "Maximilian Winkler"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.02141",
    "title": "Uniqueness of Maximum Scores in Countable-Outcome Round-Robin Tournaments",
    "abstract": "In this note, we extend a recent result on the uniqueness of the maximum score in a classical round-robin tournament to general round-robin tournament models with equally strong players, where the scores take values in $[0,\\,1]$.",
    "authors": [
      "Gideon Amir",
      "Yaakov Malinovsky"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.08679",
    "title": "Connected components of the space of flags of $\\mathrm{SO}_0(p,q)$ transverse to a fixed pair and restrictions on Anosov subgroups",
    "abstract": "We count and give a parametrization of connected components in the space of flags transverse to a given transverse pair in every flag varieties of $\\mathrm{SO}_0(p,q)$. We compute the effect the involution of the unipotent radical has on those components and, using methods of Dey--Greenberg--Riestenberg, we show that for certain parabolic subgroups $P_{\\Theta}$, any $P_{\\Theta}$-Anosov subgroup is virtually isomorphic to either a surface group of a free group. We give examples of Anosov subgroups which are neither free nor surface groups for some sets of roots which do not fall under the previous results. As a consequence of the methods developed here, we get an explicit computation of some Plücker coordinates to check if a unipotent matrix in $\\mathrm{SO}_0(p,q)$ belong to the $\\Theta$-positive semigroup $U_\\Theta^{>0}$ when $p\\neq q$.",
    "authors": [
      "Clarence Kineider",
      "Roméo Troubat"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.01326",
    "title": "Dynamical System Approach for Optimal Control Problems with Equilibrium Constraints Using Gap-Constraint-Based Reformulation",
    "abstract": "This study focuses on using direct methods (first-discretize-then-optimize) to solve optimal control problems for a class of nonsmooth dynamical systems governed by differential variational inequalities (DVI), called optimal control problems with equilibrium constraints (OCPEC). In the discretization step, we propose a class of novel approaches to smooth the DVI. The generated smoothing approximations of DVI, referred to as gap-constraint-based reformulations, have computational advantages owing to their concise and semismoothly differentiable constraint system. In the optimization step, we propose an efficient dynamical system approach to solve the discretized OCPEC, where a sequence of its smoothing approximations is solved approximately. This system approach involves a semismooth Newton flow, thereby achieving fast local exponential convergence. We confirm the effectiveness of our method using a numerical example.",
    "authors": [
      "Kangyu Lin",
      "Toshiyuki Ohtsuka"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.14553",
    "title": "A new proof of Milnor-Wood inequality",
    "abstract": "The Milnor-Wood inequality states that if a (topological) oriented circle bundle over an orientable surface of genus $g$ has a smooth transverse foliation, then the Euler class of the bundle satisfies $$|\\mathcal{E}|\\leq 2g-2.$$ We give a new proof of the inequality based on a (previously proven by the authors) local formula which computes $\\mathcal{E}$ from the singularities of a quasisection. We also sketch two other proofs: one based on Poincarè rotation number theory, and the other of topological nature.",
    "authors": [
      "Gaiane Panina",
      "Timur Shamazov",
      "Maksim Turevskii"
    ],
    "primary_category": "math.GT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.17126",
    "title": "Maximal symplectic torus actions",
    "abstract": "There are several different notions of maximal torus actions on smooth manifolds, in various contexts: symplectic, Riemannian, complex. In the symplectic context, for the so-called isotropy-maximal actions, as well as for the weaker notion of almost isotropy-maximal actions, we give classifications up to equivariant symplectomorphism. These classification results give symplectic analogues of recent classifications in the complex and Riemannian contexts. Moreover, we deduce that every almost isotropy-maximal symplectic torus action is equivariantly diffeomorphic to a product of a symplectic toric manifold and a torus, answering a question of Ishida. The classification theorems are consequences of Duistermaat and Pelayo's classification of symplectic torus actions with coisotropic orbits.",
    "authors": [
      "Rei Henigman"
    ],
    "primary_category": "math.SG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.03234",
    "title": "An Arithmetic Sum Associated with the Classical Theta Function",
    "abstract": "The sum $S(h,k):=\\sum_{j=1}^{k-1}(-1)^{j+1+[hj/k]}$ appears in the modular transformation formulae of the classical theta function $\\vartheta_3(z)$. The double sum $S(k) := \\sum_{h=1}^{k-1}S(h,k)$ has a remarkable distribution of values. Although properties for $S(k)$ and a related sum can be established, several interesting conjectures are open.",
    "authors": [
      "Bruce C. Berndt",
      "Raghavendra N. Bhat",
      "Jeffrey L. Meyer",
      "Likun Xie",
      "Alexandru Zaharescu"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.06285",
    "title": "The large scale geometry of inverse semigroups and their maximal group images",
    "abstract": "The geometry of inverse semigroups is a natural topic of study, motivated both from within semigroup theory and by applications to the theory of non-commutative $C^*$-algebras. We study the relationship between the geometry of an inverse semigroup and that of its maximal group image, and in particular the geometric \\textit{distortion} of the natural map from the former to the latter. This turns out to have both implications for semigroup theory and potential relevance for operator algebras associated to inverse semigroups. Along the way, we also answer a question of Lledó and Martínez by providing a more direct proof that an $E$-unitary inverse semigroup has Yu's Property A if its maximal group image does.",
    "authors": [
      "Mark Kambites",
      "Nóra Szakács"
    ],
    "primary_category": "math.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.08987",
    "title": "Degradedness Under Cooperation",
    "abstract": "We study cooperation problems in broadcast and relay networks, where the receivers do not satisfy the classical physical degradedness assumptions. New notions of degradedness, \\emph{strongly less noisy} and \\emph{strongly more capable} are introduced. We show that under these conditions, decode and forward (D\\&F) is optimal for classes of cooperative systems with limited conference rates, thus yielding new capacity results for these systems. In particular, we derive bounds on the capacity region of a class of broadcast channels with cooperation, that are tight on part of the capacity region. It is shown that the cut-set bound is tight for classes of primitive relay and diamond channels, beyond the physically or stochastically degraded models.",
    "authors": [
      "Yossef Steinberg"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.11125",
    "title": "Asymptotic Growth of Trivial Summands in Tensor Powers",
    "abstract": "Given a finite-dimensional representation $V$ over an algebraically closed field of an abstract group $G$, we consider the number of the trivial summand counted with multiplicity in the direct sum decomposition of $V^{\\otimes n}$. We give necessary and sufficient conditions when the field is of characteristic $0$ and when the field is of characteristic $p$ so that $(V^{\\otimes n})_n$ has a subsequence $(V^{\\otimes n_k})_k$ such that $V^{\\otimes n_k}$ contains enough trivial summands when $k$ is sufficiently large.",
    "authors": [
      "Nai-Heng Sheu"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.11382",
    "title": "Global Regularity Estimates for Optimal Transport via Entropic Regularisation",
    "abstract": "We develop a general approach to prove global regularity estimates for quadratic optimal transport using the entropic regularisation of the problem and the Prekopa-Leindler inequality.",
    "authors": [
      "Nathael Gozlan",
      "Maxime Sylvestre"
    ],
    "primary_category": "math.FA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.15170",
    "title": "A Question of Erdős and Graham on Covering Systems",
    "abstract": "Erdős and Graham (Erdős and Graham, 1980) asked if there exists an $n$ such that the divisors of $n$ greater than 1 are the moduli of a distinct covering system with the following property: If there exists an integer which satisfies two congruences in the system, $a\\mod d$ and $a'\\mod d'$, then $\\gcd(d,d')=1$. We show that such an $n$ does not exist. This problem is part of Problem # 204 on the website this http URL , compiled and maintained by Thomas Bloom. We also study when the divisors of $n$ greater than $1$ can form a congruence system satisfying the above condition.",
    "authors": [
      "Sarosh Adenwalla"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.05745",
    "title": "Global classical solutions to the ionic Vlasov-Poisson-Boltzmann system in a 3D periodic box",
    "abstract": "We investigate the global well-posedness of the ionic Vlasov-Poisson-Boltzmann system which models the evolution of dilute collisional ions. This system distinguishes the electronic Vlasov-Poisson-Boltzmann system via an additional exponential nonlinearity in the coupled Poisson-Poincaré equation, which introduces essential mathematical difficulties. In a three-dimensional periodic box, We establish the existence of a unique global-in-time classical solution with an exponential decay under small initial perturbations of a global Maxwellian that preserve mass, momentum and energy conservation laws. Our approach combines a nonlinear energy method with quantitative nonlinear elliptic estimates and new coercivity inequalities for the linearized collision operator $\\mathcal{L}$ in ion dynamics.",
    "authors": [
      "Fucai Li",
      "Yichun Wang"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.09887",
    "title": "The global representation fibered ring",
    "abstract": "In this paper, we combine the concepts of the fibered Burnside ring and the character ring, viewing them as fibered biset functors, into what we call the global representation fibered ring of a finite group. We compute all ring homomorphisms from this ring to the complex numbers, determine its spectrum and its connected components, and identify the primitive idempotents of this ring tensor with $\\mathbb{Q}$ and its conductors.",
    "authors": [
      "J. Miguel Calderón",
      "Alberto G. Raggi-Cárdenas"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.11343",
    "title": "SPLD polynomial optimization and bounded degree SOS hierarchies",
    "abstract": "In this paper, we introduce a new class of structured polynomials, called separable plus lower degree (SPLD) polynomials. The formal definition of an SPLD polynomial, which extends the concept of SPQ polynomials (Ahmadi et al. in Math Oper Res 48:1316--1343, 2023), is provided. A type of bounded degree SOS hierarchy, referred to as BSOS-SPLD, is proposed to efficiently solve optimization problems involving SPLD polynomials. Numerical experiments on several benchmark problems indicate that the proposed method yields better performance than the standard bounded degree SOS hierarchy (Lasserre et al. in EURO J Comput Optim 5:87--117, 2017). An exact SOS relaxation for a class of convex SPLD polynomial optimization problems is proposed. Finally, we present an application of SPLD polynomials to convex polynomial regression problems arising in statistics.",
    "authors": [
      "Liguo Jiao",
      "Jae Hyoung Lee",
      "Nguyen Bui Nguyen Thao"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.12260",
    "title": "Homoclinic classes for flows: ergodicity and SRB measures",
    "abstract": "In this work we intend to study homoclinic classes for some classes of flows. To this end we obtain analogous results those obtained by Hertz-Hertz-Tahzibi-Ures in the flow setting. Namely we prove that if the Lesbegue measure gives positive measure to both stable and unstable homoclinic classes of a periodic hyperbolic orbit, then their intersection constitute an ergodic component. Futhermore, with similar techiniques we state several results concerning regular SRB measures.",
    "authors": [
      "Ygor de Jesus",
      "Marcielis Espitia",
      "Gabriel Ponce"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.12797",
    "title": "Moderate deviations in first-passage percolation for bounded weights",
    "abstract": "We investigate the moderate and large deviations in first-passage percolation (FPP) with bounded weights on $\\mathbb{Z}^d$ for $d \\geq 2$. Write $T(\\mathbf{x}, \\mathbf{y})$ for the first-passage time and denote by $\\mu(\\mathbf{u})$ the time constant in direction $\\mathbf{u}$. In this paper, we establish that, if one assumes that the sublinear error term $T(\\mathbf{0}, N\\mathbf{u}) - N\\mu(\\mathbf{u})$ is of order $N^\\chi$, then under some unverified (but widely believed) assumptions, for $\\chi < a < 1$, \\begin{align*} &\\mathbb{P}\\bigl(T(\\mathbf{0}, N\\mathbf{u}) > N\\mu(\\mathbf{u}) + N^a\\bigr) = \\exp{\\Big(-\\,N^{\\frac{d(1+o(1))}{1-\\chi}(a-\\chi)}\\Big)},\\end{align*} \\begin{align*} &\\mathbb{P}\\bigl(T(\\mathbf{0}, N\\mathbf{u}) < N\\mu(\\mathbf{u}) - N^a\\bigr) = \\exp{\\Big(-\\,N^{\\frac{1+o(1)}{1-\\chi}(a-\\chi)}\\Big)}, \\end{align*} with accompanying estimates in the borderline case $a=1$. Moreover, the exponents $\\frac{d}{1-\\chi}$ and $\\frac{1}{1-\\chi}$ also appear in the asymptotic behavior near $0$ of the rate functions for upper and lower tail large deviations. Notably, some of our estimates are established rigorously without relying on any unverified assumptions. Our main results highlight the interplay between fluctuations and the decay rates of large deviations, and bridge the gap between these two regimes. A key ingredient of our proof is an improved concentration via multi-scale analysis for several moderate deviation estimates, a phenomenon that has previously appeared in the contexts of two-dimensional last-passage percolation and two-dimensional rotationally invariant FPP.",
    "authors": [
      "Wai-Kit Lam",
      "Shuta Nakajima"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.03188",
    "title": "A Laplace transform approach to $C$-semigroups on a $\\mathcal{T}_{\\varepsilon, λ}$-complete random normed module",
    "abstract": "In this paper, we first introduce the notion of the Laplace transform for an abstract-valued function from $[0, \\infty)$ to a $\\mathcal{T}_{\\varepsilon, \\lambda}$-complete random normed module $S$. Then, combining respective advantages of the $(\\varepsilon, \\lambda)$-topology and the locally $L^0$-convex topology on $S$, we prove the differentiability, Post-Widder inversion formula and uniqueness of such a Laplace transform. Second, based on the above work, we establish the Hille-Yosida theorem for an exponentially bounded $C$-semigroup on $S$, considering both the dense and nondense cases of the range of $C$, respectively, which extends and improves several important results. Finally, we also apply such a Laplace transform to abstract Cauchy problems in the random setting.",
    "authors": [
      "Xia Zhang",
      "Leilei Wei",
      "Ming Liu"
    ],
    "primary_category": "math.FA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.09766",
    "title": "Frog model on $\\mathbb{Z}$ with random survival parameter",
    "abstract": "We study the frog model on \\( \\mathbb{Z} \\) with geometric lifetimes, introducing a random survival parameter. Active and inactive particles are placed at the vertices of \\( \\mathbb{Z} \\). The lifetime of each active particle follows a geometric random variable with parameter \\( 1-p \\), where \\( p \\) is randomly sampled from a distribution \\( \\pi \\). Each active particle performs a simple random walk on \\( \\mathbb{Z} \\) until it dies, activating any inactive particles it encounters along its path. In contrast to the usual case where \\( p \\) is fixed, we show that there exist non-trivial distributions \\( \\pi \\) for which the model survives with positive probability. More specifically, for $\\pi\\sim Beta(\\alpha,\\beta)$, we establish the existence of a critical value \\( \\beta=0.5 \\), that separates almost sure extinction from survival with positive probability. Furthermore, we show that the model is recurrent whenever it survives with positive probability.",
    "authors": [
      "Gustavo O. de Carvalho",
      "Fábio P. Machado"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.10816",
    "title": "On the structure and theory of McCarthy algebras",
    "abstract": "We provide a structural analysis for McCarthy algebras, the variety generated by the three-element algebra defining the logic of McCarthy (the non-commutative version of Kleene three-valued logics). Our analysis will be conducted in a very general algebraic setting by introducing McCarthy algebras as a subvariety of unital bands (idempotent monoids) equipped with an involutive (unary) operation $'$ satisfying $x''\\approx x$; herein referred to as i-ubands. Prominent (commutative) subvarieties of i-ubands include Boolean algebras, ortholattices, Kleene algebras, and involutive bisemilattices, hence i-ubands provides an algebraic common ground for several non-classical logics. Our main contributions consist in providing for McCarthy algebras: reduced and equivalent axiomatizations; a semilattice decomposition theorem; and representations as certain decorated posets from which the algebraic structure can be uniquely determined.",
    "authors": [
      "Stefano Bonzio",
      "Gavin St. John"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20055",
    "title": "From semi-total to equitable total colorings",
    "abstract": "Independently posed by Behzad and Vizing, the Total Coloring Conjecture asserts that the total chromatic number of a simple connected graph $G$ is either $\\Delta(G)+1$ or $\\Delta(G)+2$, where $\\Delta(G)$ is the largest degree of any vertex of $G$. To decide whether a cubic graph $G$ has total chromatic number $\\Delta(G)+1$, even for bipartite cubic graphs, is NP-hard. The resulting problems and research persist even for total colorings that are equitable, namely with the cardinalities of the color classes differing at most by 1. Williams and Holroyd gave a new condition to solve total coloring problems via the introduction of semi-total colorings. We focus on how to obtain equitable total colorings of symmetric cubic graphs and cage graphs by means of a variation of Kempe'a 1879 graph-coloring algorithm. Such variation takes semi-total colorings to equitable ones.",
    "authors": [
      "I. J. Dejter"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20145",
    "title": "Asymptotic Analysis of the Total Quasi-Steady State Approximation for the Michaelis--Menten Enzyme Kinetic Reactions",
    "abstract": "We consider a stochastic model of the Michaelis-Menten (MM) enzyme kinetic reactions in terms of Stochastic Differential Equations (SDEs) driven by Poisson Random Measures (PRMs). It has been argued that among various Quasi-Steady State Approximations (QSSAs) for the deterministic model of such chemical reactions, the total QSSA (tQSSA) is the most accurate approximation, and it is valid for a wider range of parameter values than the standard QSSA (sQSSA). While the sQSSA for this model has been rigorously derived from a probabilistic perspective at least as early as 2006 in Ball et al. (2006), a rigorous study of the tQSSA for the stochastic model appears missing. We fill in this gap by deriving it as a Functional Law of Large Numbers (FLLN), and also studying the fluctuations around this approximation as a Functional Central Limit Theorem (FCLT).",
    "authors": [
      "Arnab Ganguly",
      "Wasiur R. KhudaBukhsh"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20772",
    "title": "Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?",
    "abstract": "Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability - ranging from ordinal level comparability to full cardinal comparability - together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.",
    "authors": [
      "Ilia Shilov",
      "Ezzat Elokda",
      "Sophie Hall",
      "Heinrich H. Nax",
      "Saverio Bolognani"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.22664",
    "title": "Identities of relatively free algebras of Lie nilpotent associative algebras",
    "abstract": "In this paper, we consider the relatively free algebra of rank $n$, $F_n(\\mathfrak{N}_p)$, in the variety of Lie nilpotent associative algebras of index $p$, denoted by $\\mathfrak{N}_p$, over a field of characteristic zero. We describe an explicit minimal basis for the polynomial identities of $F_n(\\mathfrak{N}_p)$ when $p=3$ and $p=4$, for all $n$, except for $F_3(\\mathfrak{N}_4)$. In the general case, we exhibit a lower and an upper bound for the minimal $k$ such that $[x_1,x_2]\\cdots[x_{2k-1},x_{2k}]$ is an identity for $F_n(\\mathfrak{N}_p)$ for all $n$ and for all $p$.",
    "authors": [
      "Elitza Hristova",
      "Thiago Castilho de Mello"
    ],
    "primary_category": "math.RA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.06049",
    "title": "On the topological complexity of directed parametrized motion planning",
    "abstract": "We introduce and study a parametrized analogue of the directed topological complexity, originally developed by Goubault, Farber, and Sagnier. We establish the fibrewise basic dihomotopy invariance of directed parametrized topological complexity and explore its relationship with the parametrized topological complexity. In addition, we introduce the concept of the directed Lusternik-Schnirelmann (LS) category, prove its basic dihomotopy invariance, and investigate its connections with both directed topological complexity and directed parametrized topological complexity. We further investigate additional properties of our invariant and examine its connections with several other invariants that arise naturally in the context of topological robotics. Moreover, we compute the directed parametrized topological complexity of the Hopf fibrations and the Fadell-Neuwirth fibrations having specific directed fibration structures.",
    "authors": [
      "Sutirtha Datta",
      "Navnath Daundkar",
      "Abhishek Sarkar"
    ],
    "primary_category": "math.AT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.06790",
    "title": "Analog Computing for Signal Processing and Communications -- Part I: Computing with Microwave Networks",
    "abstract": "Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.07477",
    "title": "Analog Computing for Signal Processing and Communications -- Part II: Toward Gigantic MIMO Beamforming",
    "abstract": "Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\\times 10^4$ and $4.0\\times 10^7$ times, respectively, compared to digital beamforming.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.08722",
    "title": "Deriving the Gradients of Some Popular Optimal Transport Algorithms",
    "abstract": "In this note, I review entropy-regularized Monge-Kantorovich problem in Optimal Transport, and derive the gradients of several popular algorithms popular in Computational Optimal Transport, including the Sinkhorn algorithms, Wasserstein Barycenter algorithms, and the Wasserstein Dictionary Learning algorithms.",
    "authors": [
      "Fangzhou Xie"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.09551",
    "title": "On $n$-isoclinism of skew braces",
    "abstract": "The purpose of this paper is to explore possible definitions of $n$-isoclinism for skew braces. We also introduce the notions of verbal sub-skew braces and marginal left ideals.",
    "authors": [
      "Risa Arai",
      "Cindy Tsang"
    ],
    "primary_category": "math.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.10252",
    "title": "MapperEEG: A Topological Approach to Brain State Clustering in EEG Recordings",
    "abstract": "Background: Topological data analysis (TDA) has exploded as a tool for analyzing and making sense of high dimensional datasets across a variety of fields. Mapper is a tool from TDA that captures low-dimensional structure from high-dimensional data, precisely the approach needed to capture relevant information from high-dimensional neural time series. Electrical potential scalp recording, or electroencephalography (EEG), is routinely used in clinical applications and research studies thanks to its noninvasive nature, relatively inexpensive equipment, and high temporal resolution. But, it is prone to contamination, exhibits low spatial resolution, and has a non-stationary nature. Thus, it requires advanced signal processing and mathematical analysis methods for tasks requiring unsupervised brain state clustering. New Method: We introduce MapperEEG, an approach to unsupervised brain state clustering that uses tools from classical EEG analysis combined with Mapper to cluster and connect brain states. Results: We show that MapperEEG can serve as a clustering algorithm in the spectral domain and provide additional information about the underlying brain state connectivity in a tapping task. Additionally, we use a go/no-go shooting task to explore how MapperEEG can still provide insight into the underlying structure and clusters of brain states even when it and other clustering methods fail. Comparison with Existing Methods: We demonstrate that it outperforms six other clustering algorithms such as hierarchical clustering, Hidden Markov Models, and basic autoencoders on identifying states in a tapping task. Conclusions: MapperEEG offers a novel and effective approach to analyzing EEG data, showing promise for brain state clustering and analysis.",
    "authors": [
      "Brittany Story",
      "Zhibin Zhou",
      "Ramesh Srinivasan",
      "Scott Kerick",
      "David Boothe",
      "Piotr J. Franaszczuk"
    ],
    "primary_category": "math.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.08812",
    "title": "An Algorithm to compute the Kronecker cone and other moment cones",
    "abstract": "We describe a new algorithm that computes the minimal list of inequalities for the moment cone of any representation of a complex reductive group, with implementation details for two fundamental cases: the Kronecker cone (governing the asymptotic support of Kronecker coefficients) and the fermionic cone. These correspond to the actions of ${\\mathrm GL}\\_{d\\_1}({\\mathbb C})\\times\\cdots\\times {\\mathrm GL}\\_{d\\_s}({\\mathbb C})$ on ${\\mathbb C}^{d\\_1}\\otimes\\cdots\\otimes {\\mathbb C}^{d\\_s}$ and ${\\mathrm GL}\\_d({\\mathbb C})$ on $\\bigwedge^r{\\mathbb C}^d$, respectively. An implementation for these two cases in Python-Sage is available at this https URL . Our work overcomes the fundamental limitations that previously restricted such computations to cases like ${\\mathbb C}^4\\otimes{\\mathbb C}^4\\otimes{\\mathbb C}^4$. The state-of-the-art method by Vergne-Walter faced two major bottlenecks: one from combinatorial geometry in finite-dimensional vector spaces, and another from deciding whether certain dominant morphisms are birational - a problem in effective algebraic geometry that lacked a direct algorithmic solution. We surmount these obstacles by: a novel use of Weyl group actions to master combinatorial complexity, and an original algorithm for deciding birationality that replaces previous workarounds relying on convex geometry. Our approach allow us to tackle problems at a new scale. We compute the minimal list of 5,333 (up to $\\mathfrak S\\_3$) inequalities for the Kronecker cone ${\\mathbb C}^6\\otimes{\\mathbb C}^6\\otimes{\\mathbb C}^6$ in 2 hours. Furthermore, a parallel implementation computes the 64,792 (up to $\\mathfrak S\\_3$) inequalities for ${\\mathbb C}^7\\otimes{\\mathbb C}^7\\otimes{\\mathbb C}^7$ in 188 hours.",
    "authors": [
      "Michaël Bulois",
      "Roland Denis",
      "Nicolas Ressayre"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.13187",
    "title": "A nonspecial divisor in the moduli space of cubic fourfolds via 10-nodal plane sextics",
    "abstract": "In the moduli space $\\mathcal{C}$ of complex cubic hypersurfaces $X\\subset\\mathbb{P}^5$, we study the condition that $X$ admits a net of polar quadrics whose discriminant locus is a $10$-nodal irreducible plane sextic curve. Our main result is that such a condition defines an irreducible divisor in $\\mathcal{C}$ which is not of Noether-Lefschetz type.",
    "authors": [
      "Elena Sammarco"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.24750",
    "title": "The critical temperature $T_{cr}$(Ising) is DS-computable",
    "abstract": "We show that the Dobrushin-Shlosman conditions CV for the uniqueness of the Gibbs state provide the exact value for the critical temperature of the d-dimensional Ising model.",
    "authors": [
      "Senya Shlosman"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.17573",
    "title": "Conformal blocks, parahoric torsors and Borel-Weil-Bott",
    "abstract": "Let $X$ be a smooth projective curve over an algebraically closed field $k$. Let $\\mathcal{G}$ be a parahoric group scheme on $X$ as in \\cite{pr}. Via the principle of Hecke correspondences, we set-up relationships between the cohomology of lines bundles on various moduli stacks of torsors. This approach gives a proof of \\cite[Conjecture 3.7]{pr} for group schemes $\\mathcal G$ as above in characteristic zero. This further gives as a consequence, the principle of propagation of vacua. We give a direct proof of the independence of central charge on base points. Projective flatness is recovered as a corollary of Faltings construction of the Hitchin connection. Using this http URL 's basic results (\\cite{bwb}), we deduce the analogous result that cohomology of line bundles on the stack of principal $G$-bundles vanish in all degrees except possibly one. Results on twisted vacua \\cite{hongkumar} are obtained as immediate consequences.",
    "authors": [
      "V. Balaji",
      "Y. Pandey"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.02459",
    "title": "A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field",
    "abstract": "We propose and study a Particle-In-Cell (PIC) method based on the Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong and inhomogeneous external magnetic field with fixed direction, where we focus on the motion of particles in the plane orthogonal to the magnetic field. In this regime, the time step can be subject to stability constraints related to the smallness of Larmor radius and plasma frequency [21]. To avoid this limitation, our approach is based on numerical schemes [9, 10, 12], providing a consistent PIC discretization of the guiding-center system taking into account variations of the magnetic field. We carry out some theoretical proofs and perform several numerical experiments to validate the method and its underlying concepts.",
    "authors": [
      "Francis Filbet",
      "L Miguel Rodrigues",
      "Kim Han Trinh"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.04209",
    "title": "Mutual Information Bounds for Lossy Common Information",
    "abstract": "We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and Gács-Körner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).",
    "authors": [
      "Anderson de Andrade"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.09050",
    "title": "Learning to Solve Constrained Bilevel Control Co-Design Problems",
    "abstract": "Learning to Optimize (L2O) is a subfield of machine learning (ML) in which ML models are trained to solve parametric optimization problems. The general goal is to learn a fast approximator of solutions to constrained optimization problems, as a function of their defining parameters. Prior L2O methods focus almost entirely on single-level programs, in contrast to the bilevel programs, whose constraints are themselves expressed in terms of optimization subproblems. Bilevel programs have numerous important use cases but are notoriously difficult to solve, particularly under stringent time demands. This paper proposes a framework for learning to solve a broad class of challenging bilevel optimization problems, by leveraging modern techniques for differentiation through optimization problems. The framework is illustrated on an array of synthetic bilevel programs, as well as challenging control system co-design problems, showing how neural networks can be trained as efficient approximators of parametric bilevel optimization.",
    "authors": [
      "James Kotary",
      "Himanshu Sharma",
      "Ethan King",
      "Draguna Vrabie",
      "Ferdinando Fioretto",
      "Jan Drgona"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.19410",
    "title": "Reconstruction in the Calderón problem on a fixed partition from finite and partial boundary data",
    "abstract": "This short note modifies a reconstruction method by the author (Comm. PDE, 45(9):1118-1133, 2020), for reconstructing piecewise constant conductivities in the Calderón problem (electrical impedance tomography). In the former paper, a layering assumption and the local Neumann-to-Dirichlet map were needed since the piecewise constant partition also was assumed unknown. Here I show how to modify the method in case the partition is known, for general piecewise constant conductivities and only a finite number of partial boundary measurements. Moreover, no lower/upper bounds on the unknown conductivity are needed.",
    "authors": [
      "Henrik Garde"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.21870",
    "title": "Generalized principal eigenvalues of elliptic operators and spreading speeds of Fisher-KPP equations in two-scale almost periodic media",
    "abstract": "This paper is concerned with the asymptotic behavior of the generalized principal eigenvalues of elliptic operators and spreading speeds of Fisher-KPP equations in two-scale almost periodic media where one scale is fixed and another one approaches zero or infinity. We transform the problem into the homogenization of certain effective Hamiltonian and then establish the asymptotic limits and the convergence rates. Based on the analysis of the asymptotic behavior of effective Hamiltonians, we investigate how the heterogeneity of the advection and growth rates affect on the propagation in the case where the media has very rapid or slow spatial oscillation: We show a normal scale perturbation of the growth rate with mean zero can accelerate the propagation in the media with rapid or slow oscillation; and an advection with slow oscillation and mean zero can decelerate the propagation in 1-D case.",
    "authors": [
      "Xing Liang",
      "Linfeng Xu",
      "Tao Zhou"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.01939",
    "title": "Sharp stability of convex functionals on weighted Bergman spaces with applications",
    "abstract": "Recently, Kulikov (\\cite{Ku}) has shown that certain convex functionals on weighted Bergman spaces are maximized by reproducing kernels. We show a sharp quantitative stability of these estimates with the optimal norm and the exponent and an explicit constant asymptotically sharp in both directions ($\\alpha\\rightarrow -1$ and $\\alpha\\rightarrow +\\infty$). Several applications of this result include recovering the appropriate result for Fock spaces, interpretation to Cauchy wavelets, and the Hardy space counterpart for functionals induced by increasing function. In addition, we prove a higher-dimensional analog of the main result assuming that all convex functionals on the weighted Bergman space $\\mathcal{A}^2_{\\alpha}(\\mathbb{B}_n)$ attain their extrema in reproducing kernels.",
    "authors": [
      "Petar Melentijević"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.13307",
    "title": "Algebraic models of cyclic $k$-gonal curves",
    "abstract": "In this paper, we describe explicit algebraic equations of tame cyclic $k$-gonal curves, where $k \\geq 2$ is an integer, reflecting the action of the normalizer of a tame cyclic $k$-gonal automorphism. For $k$ a prime integer, this was previously done by A. Wootton.",
    "authors": [
      "Ruben A. Hidalgo",
      "Sebastián Reyes-Carocca"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.13569",
    "title": "Revisiting the Geometrically Decaying Step Size: Linear Convergence for Smooth or Non-Smooth Functions",
    "abstract": "We revisit the geometrically decaying step size given a positive inverse condition number, under which a locally Lipschitz function shows linear convergence. The positivity does not require the function to satisfy convexity, weak convexity, quasar convexity, or sharpness, but instead amounts to a property strictly weaker than the assumptions used in existing works (e.g., weak convexity + sharpness). We propose a clean and simple subgradient descent algorithm that requires minimal knowledge of problem constants, applicable to either smooth or non-smooth functions.",
    "authors": [
      "Jihun Kim"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.17731",
    "title": "G-BSDEs with non-Lipschitz coefficients and the corresponding stochastic recursive optimal control problem",
    "abstract": "In this paper, we study the existence and uniqueness of solutions to a class of non-Lipschitz G-BSDEs and the corresponding stochastic recursive optimal control problem. More precisely, we suppose that the generator of G-BSDE is uniformly continuous and monotonic with respect to the first unknown variable. Using the comparison theorem for G-BSDE and the stability of viscosity solutions, we establish the dynamic programming principle and the connection between the value function and the viscosity solution of the associated Hamilton-Jacobi-Bellman this http URL provide an example of continuous time Epstein-Zin utility to demonstrate the application of our study.",
    "authors": [
      "Wei He",
      "Qiangjun Tang"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.21392",
    "title": "Variances and central limit theorems for random beta-polytopes and in other geometric models",
    "abstract": "We prove matching asymptotic lower and upper bounds on the variances of the intrinsic volumes and the number of $k$-faces of $d$-dimensional random beta-polytopes. Using Stein's methods, we establish central limit theorems for the intrinsic volumes. We also prove asymptotic upper bounds on the variances of the volume and vertex number of spherical random polytopes in spherical convex bodies, and hyperbolic random polytopes in convex bodies in hyperbolic space. Moreover, we consider a circumscribed model on the sphere.",
    "authors": [
      "Ferenc Fodor",
      "Balázs Grünfelder"
    ],
    "primary_category": "math.MG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.02766",
    "title": "Complexity of Effective Reductions with Ordinal Turing Machines",
    "abstract": "In arXiv:1811.11630 , we introduced a notion of effective reducibility between set-theoretical $\\Pi_{2}$-statements; in arXiv:2411.19386 , this was extended to statements of arbitrary (potentially even infinite) quantifier complexity. We also considered a corresponding notion of Weihrauch reducibility, which allows only one call to the effectivizer of $\\psi$ in a reduction of $\\phi$ to $\\psi$. In this paper, we refine this notion considerably by asking how many calls to an effectivizer for $\\psi$ are required for effectivizing $\\phi$. This allows us make formally precise questions such as ``how many ordinals does one need to check for being cardinals in order to compute the cardinality of a given ordinal?'' and (partially) answer many of them. Many of these anwers turn out to be independent of ZFC.",
    "authors": [
      "Merlin Carl"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.05247",
    "title": "The Fundamental Theorem of Calculus for Lebesgue-Stieltjes integrals involving non-monotonic derivators",
    "abstract": "In this work, we extend the concept of the Stieltjes derivative to encompass left-continuous derivators with bounded variation, thereby relaxing the monotonicity constraint. This generalization necessitates a refined definition of the Stieltjes derivative applicable across the entire domain, accommodating derivators that may change sign. We establish a generalized Fundamental Theorem of Calculus for the Lebesgue-Stieltjes integral in this broader context, presenting both \"almost-everywhere\" and \"everywhere\" versions. The latter requires a specific condition relating the derivator to its variation function, which we prove to be optimal through a density theorem. Our framework bridges the gap between Stieltjes differential equations and measure differential equations, offering a tool for modeling complex systems with non-monotonic dynamics.",
    "authors": [
      "Lamiae Maia",
      "F. Adrián F. Tojo"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10382",
    "title": "A Fibonacci-Based Gödel Numbering: $Δ_0$ Semantics Without Exponentiation",
    "abstract": "This paper develops a fully additive account of Incompleteness based on finite supports of Fibonacci indices and Zeckendorf representations. \"Carryless Pairing\" provides an injective, reversible encoding of tuples, with evaluation and inversion confined to finite index domains. Using this framework, we obtain $\\Delta_0$-definable encodings of terms, formulas, proofs, and a substitution operator, and we formalize the provability predicate entirely within bounded arithmetic. The Diagonal Lemma and Gödel's First Incompleteness Theorem are then recovered without multiplication or unbounded search. The resulting system isolates a structure sufficient for self-reference and is grounded in finite-support recursion.",
    "authors": [
      "Milan Rosko"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.14697",
    "title": "Ortho-isomorphisms of von Neumann algebras",
    "abstract": "Suppose $\\mathscr M$ and $\\mathscr N$ are von Neumann algebras. Two operators $A$ and $B$ in $\\mathscr M$ are said to be orthogonal if $A^*B=0$, meaning their ranges are orthogonal. Let $\\varphi\\colon\\mathscr M\\to\\mathscr N$ be a map. We say that $\\varphi$ is an ortho-isomorphism if it is bijective and satisfies that $A^*B=0$ if and only if $\\varphi(A)^*\\varphi(B)=0$ for all $A,B\\in\\mathscr M$. The map $\\varphi$ is called ortho-additive if the additive relation $\\varphi(A+B)=\\varphi(A)+\\varphi(B)$ holds for all $A,B\\in \\mathscr M$ with $A^*B=0$. In this paper, we characterize the complete structure of ortho-additive ortho-isomorphisms between von Neumann algebras, which is an analogue of Dye's theorem and Uhlhorn's theorem.",
    "authors": [
      "Minghui Ma",
      "Weijuan Shi"
    ],
    "primary_category": "math.OA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.14727",
    "title": "Distances between pure quantum states induced by a distance matrix",
    "abstract": "With the help of a given distance matrix of size $n$, we construct an infinite family of distances $d_p$ (where $p \\geq 2$) on the complex projective space $\\mathbb{P}(\\mathbb{C}^n)$ modelling the space of pure states of an $n$-level quantum system. The construction can be seen as providing a natural way to isometrically embed any given finite metric space into the space of pure quantum states 'spanned' upon it. In order to show that the maps $d_p$ are indeed distance functions -- in particular, that they satisfy the triangle inequality -- we employ methods of analysis, multilinear algebra and convex geometry, obtaining a nontrivial auxiliary convexity result in the process. The paper significantly extends earlier work, resolving an important question about the geometry of quantum state space imposed by the quantum Wasserstein distances and solidifying the foundation for applications of distances $d_p$ in quantum information science.",
    "authors": [
      "Tomasz Miller",
      "Rafał Bistroń"
    ],
    "primary_category": "math-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.24971",
    "title": "Lacunary sequences whose reciprocal sums represent all rational numbers in an interval",
    "abstract": "Disproving a conjecture of Bleicher and Erdős, we show that there exists a lacunary sequence of positive integers such that finite sums of reciprocals of its terms attain all rational numbers from a non-empty open interval. We also study several stronger variants of their original problem: determining the value of the optimal lacunarity parameter, representing rational numbers infinitely many times, finding such lacunary sequences with arbitrarily large jumps, and relating the maximal length of a filled interval to a prescribed lacunarity parameter.",
    "authors": [
      "Wouter van Doorn",
      "Vjekoslav Kovač"
    ],
    "primary_category": "math.NT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.03109",
    "title": "Rates of Convergence of Generalised Variational Inference Posteriors under Prior Misspecification",
    "abstract": "We prove rates of convergence and robustness to prior misspecification within a Generalised Variational Inference (GVI) framework with bounded divergences. This addresses a significant open challenge for GVI and Federated GVI that employ a different divergence to the Kullback-Leibler under prior misspecification, operate within a subset of possible probability measures, and result in intractable posteriors. Our theoretical contributions extend to misspecified priors that lead to inconsistent Bayes posteriors. In particular, we are able to establish sufficient conditions for existence and uniqueness of GVI posteriors on arbitrary Polish spaces, prove that the GVI posterior measure concentrates on a neighbourhood of loss minimisers, and extend this to rates of convergence regardless of the prior measure.",
    "authors": [
      "Terje Mildner",
      "Paris Giampouras",
      "Theodoros Damoulas"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.04558",
    "title": "Winding quotients for virtual period maps of rank 1",
    "abstract": "We illustrate a rank 1 model of virtual period maps and their associated winding quotient, where the winding quotient is a new phenomenon appeared in a recent study of virtual period maps and it requires a reformulation of the classical Jacobi inversion problem for the period maps. We answer to the new inversion problem by introducing the q-multiplicatively periodic function, whose pull-back to the winding covering space is the Weierstrass p-function up to a correction by Eisenstein series E2. The function appears also in the study of mathematical physics as the propagator on elliptic curves.",
    "authors": [
      "Kyoji Saito"
    ],
    "primary_category": "math.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.06074",
    "title": "On algebro-geometric quotients of torus-invariant subvarieties of the flag variety",
    "abstract": "In this paper, we study the subvarieties of a complex flag variety that are invariant under the action of a maximal torus. Using combinatorial techniques derived from matroid theory, we introduce a decomposition of this variety into affine, locally closed subsets, which we refer to as thin Schubert cells, each indexed by an element of a Cartesian product of matroids. We also show that the set of orbits for each of these thin Schubert cells under the action of the torus is, in fact, an orbit space, which gives rise to topologically trivial fiber bundles. As a consequence of this, we prove the existence of algebro-geometric quotients in the sense of Mumford's Geometric Invariant Theory. The main result of this work is the existence of a surjective map from the set of geometric quotients of thin Schubert cells to the invariant scheme-theoretic points of a complex flag variety, which allows us to decompose it in terms of such quotients and also define a map from the set of these geometric quotients to the invariant homology of the variety. Finally, we give a complete description of the thin Schubert cells for the special case of the flag variety $\\mathds{F}_{1<n-1}(\\mathds{C}^n)$ and derive explicit counting formulas.",
    "authors": [
      "Luis Y. Meza-Pérez",
      "Pedro L. del Ángel R.",
      "Carlos Pompeyo-Gutiérrez",
      "Miguel Angel Dela-Rosa"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.08033",
    "title": "Riemann-Hurwitz Formula for Arithmetic Surfaces",
    "abstract": "In this paper, we presents a method for factoring morphisms between arithmetic surfaces based on the regularity of arithmetic surfaces. Using this factorization, we derive a Riemann-Hurwitz formula satisfied by the ramification divisor and the canonical divisor on arithmetic surfaces. We also extend this formula to Arakelov theory.",
    "authors": [
      "Ziyang Zhu"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.13398",
    "title": "Selfless Inclusions of C*-Algebras",
    "abstract": "We introduce and study a natural notion of selflessness for inclusions of C*-probability spaces, which in particular implies that all intermediate C*-algebras are selfless in the sense of Robert. We identify natural sources of selfless inclusions in the realms of Z-stable and free product C*-algebras. As an application of this, we prove selflessness for a new family of C*-probability spaces outside the regime of free products and group C*-algebras. These include the reduced free unitary compact quantum groups.",
    "authors": [
      "Ben Hayes",
      "Srivatsav Kunnawalkam Elayavalli",
      "Gregory Patchell",
      "Leonel Robert"
    ],
    "primary_category": "math.OA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.17170",
    "title": "Computing Optimal Trajectories for Optimal Transport in Nonuniform Environments",
    "abstract": "In this work, we solve a discrete optimal transport problem in a nonuniform environment. To solve the optimal transport problem, we build the cost matrix and then use classical solvers for discrete optimal transport. The challenge is to form the cost matrix, which requires finding the optimal path between two points, and for this task we formulate and solve the associated Euler-Lagrange equations. A main contribution of ours is to provide verifiable sufficient conditions of optimality of the solution of the Euler-Lagrange equation and to propose new algorithms to to check optimality a-posteriori, thus validating the (exact) computation of the cost matrix. We illustrate our results and performance of the algorithms on several numerical examples in 2 and 3 dimensions.",
    "authors": [
      "Luca Dieci",
      "Daniyar Omarov"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.20660",
    "title": "Representation theorems for dynamic convex risk measures",
    "abstract": "In this paper, we prove that under the domination condition: \\begin{equation*} {\\cal{E}}^{-\\mu,-\\nu}[-\\xi|{\\cal{F}}_t]\\leq\\rho_t(\\xi)\\leq{\\cal{E}}^{\\mu,\\nu}[-\\xi|{\\cal{F}}_t],\\quad \\forall\\xi\\in \\mathcal{L}^{\\exp}_T\\ (\\text{resp.}\\ L^2(\\mathcal{F}_T)),\\ \\forall t\\in[0,T], \\end{equation*} where ${\\cal{E}}^{\\mu,\\nu}$ is the $g$-expectation with generator $\\mu|z|+\\nu|z|^2, \\mu\\geq0, \\nu\\geq0$, the dynamic convex (resp. coherent) risk measure $\\rho$ admits a representation as a $g$-expectation, whose generator $g$ is convex (resp. sublinear) in the variable $z$ and has a quadratic (resp. linear) growth. As an application, we show that such dynamic convex (resp. coherent) risk measure $\\rho$ admits a dual representation, where the penalty term (resp. the set of probability measures) is characterized by the corresponding generator $g$.",
    "authors": [
      "Shiqiu Zheng"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.20723",
    "title": "Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel",
    "abstract": "We study the growth of the support size of the capacity-achieving input distribution for the amplitude-constrained additive white Gaussian noise (AWGN) channel. While it is known since Smith (1971) that the optimal input is discrete with finitely many mass points, tight bounds on the number of support points $K_A$ as the amplitude constraint $A$ increases remain open. Not much is known until recently, when Dytso et al. (2019) proved that $K_A$ grows at least linearly and at most quadratically in $A$. Here, we provide a novel method, building on Ma et al. (2024); Zhang (1994), to derive the first non-trivial lower bound showing that KA grows super-linearly in A.",
    "authors": [
      "Haiyang Wang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22742",
    "title": "Non-local Dirichlet forms, Gibbs measures, and a Hodge theorem for Cantor sets",
    "abstract": "In this paper I study properties of the generators $\\triangle_\\gamma$ of non-local Dirichlet forms $\\mathcal{E}^\\mu_\\gamma$ on ultrametric spaces which are the path space of simple stationary Bratteli diagrams. The measures used to define the Dirichlet forms are taken to be the Gibbs measures $\\mu_\\psi$ associated to Hölder continuous potentials $\\psi$ for one-sided shifts. I also define a cohomology $H_{lc}(X_B)$ for $X_B$ which can be seen as dual to the homology of Bowen and Franks. Besides studying spectral properties of $\\triangle_\\gamma$, I show that for $\\gamma$ large enough (with sharp bounds depending on the diagram and the measure theoretic entropy $h_{\\mu_\\psi}$ of $\\mu_\\psi$) there is a unique harmonic representative of any class $c\\in H_{lc}(X_B)$.",
    "authors": [
      "Rodrigo Treviño"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.25350",
    "title": "A non-unitary approach to the $q$-deformation of $\\mathrm{SL}(2,\\mathbb{R})$",
    "abstract": "We study the representation theory of various convolution algebras attached to the $q$-deformation of $\\mathrm{SL}(2,\\mathbb{R})$ from an algebraic perspective and beyond the unitary case. We show that many aspects of the classical representation theory of real semisimple groups can be transposed to this context. In particular, we prove an analogue of the Harish-Chandra isomorphism and we introduce an analogue of parabolic induction. We use these tools to classify the non-unitary irreducible representations of $q$-deformed $\\mathrm{SL}(2,\\mathbb{R})$. Moreover, we explicitly show how they converge to the classical admissible dual of $\\mathrm{SL}(2,\\mathbb{R})$. For that purpose, we define a version of the quantized universal enveloping algebra defined over the ring of analytic functions on $\\mathbb{R}_+^*$, which specializes at $q = 1$ to the enveloping $\\ast$-algebra of $\\mathfrak{sl}(2,\\mathbb{R})$.",
    "authors": [
      "Yvann Gaudillot-Estrada"
    ],
    "primary_category": "math.RT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.02158",
    "title": "Asset-liability management with Epstein-Zin utility under stochastic interest rate and unknown market price of risk",
    "abstract": "This paper solves a consumption-investment choice problem with Epstein-Zin recursive utility under partial information--unobservable market price of risk. The main novelty is the introduction of a terminal liability constraint, a feature directly motivated by practical portfolio management and insurance applications but absent from the recursive utility literature. Such constraint gives rise to a coupled forward-backward stochastic differential equation (FBSDE) whose well-posedness has not been addressed in earlier work. We provide an explicit solution to this FBSDE system--contrasting with the typical existence and uniqueness results with no closed-form expressions in the literature. Under mild additional assumptions, we also establish the Malliavin differentiability of the solution allowing the optimal investment strategy to be expressed as a conditional expectation of random variables that can be efficiently simulated. These results allows us to obtain the explicit expressions of the optimal controls and the value function. Finally, we quantify the utility loss from ignoring learning about the market price of risk, highlighting the economic significance of partial information.",
    "authors": [
      "Wilfried Kuissi-Kamdem"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.02758",
    "title": "Finite free probability and $S$ transforms of Jacobi processes",
    "abstract": "In this paper, we study the $S$ transforms of Jacobi processes in the frameworks of free and finite free probability theories. We begin by deriving a partial differential equation satisfied by the free $S$ transform of the free Jacobi process, and we provide a detailed analysis of its characteristic curves. We turn next our attention to the averaged characteristic polynomial of the Hermitian Jacobi process and to the dynamic of its roots, referred to as the \\emph{frozen Jacobi process}. In particular, we prove, for a specific set of parameters, that the former aligns up to a Szegö variable transformation with the Hermite unitary polynomial. We also provide an expansion of the averaged characteristic polynomial of the Hermitian process in the basis of Jacobi polynomials. Finally, we establish the convergence of the frozen Jacobi process to the free Jacobi process in high dimensions by using the finite free S transform. In doing so, we prove a general result, interesting in its own, on the convergence of the finite differences of the finite free $S$ transform, which paves the way to obtain asymptotics of differential-difference equations satisfied by time-dependent finite free S-transforms of polynomial sequences with positive roots.",
    "authors": [
      "Nizar Demni",
      "Nicolas Gilliers",
      "Tarek Hamdi"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.03505",
    "title": "A note on co-Hopfian groups and rings",
    "abstract": "Let $p$ and $n$ be positive integers. Assume additionally that $p\\neq 3$ is a prime and that $n>2$. Let $R$ be a field of characteristic $p$. A very special consequence of a result of Bunina and Kunyavskii (2023, arXiv:2308.10076 ) is that $SL_{n}(R)$ is co-Hopfian as a group if and only if $R$ is co-Hopfian as a ring. In this paper, we prove that if $k$ is the algebraic closure of the $2$ element field, then $SL_{2}(k)$ is a co-Hopfian group. Since this $k$ is trivially seen to be co-Hopfian as a ring our result somewhat extends that of Bunina and Kunyavskii. We apply our result to prove that the class of groups satisfying Turner's Retract Theorem (called Turner groups here) is not closed under elementary equivalence thereby answering a question posed by the authors in (2017, Comm. Algebra).",
    "authors": [
      "Anthony M. Gaglione",
      "Dennis Spellman"
    ],
    "primary_category": "math.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.06303",
    "title": "Mathematical Analysis and Modeling of Ebola Virus Dynamics via Optimal Control and Neural Network Paradigms",
    "abstract": "Ebola virus disease is a severe hemorrhagic fever with rapid transmission through infected fluids and surfaces. We develop a fractional-order model using Caputo derivatives to capture memory effects in disease dynamics. An eight-compartment structure distinguishes symptomatic, asymptomatic, and post-mortem transmission pathways. We prove global well-posedness, derive the basic reproduction number $\\mathcal{R}_0$, and establish stability theorems. Sensitivity analysis shows $\\mathcal{R}_0$ is most sensitive to transmission rate, incubation period, and deceased infectivity. Treatment-safe burial synergy achieves 86.5\\% morbidity-mortality control, with safe burial being most effective. Our disease-informed neural network achieves near-perfect predictive accuracy ($R^2$: 0.991-0.999, 99.1-99.9\\% accuracy), closely matching real epidemic behavior.",
    "authors": [
      "Noor Muhammad",
      "Md. Nur Alam",
      "Zhang Shiqing"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.10538",
    "title": "Restriction estimates for 2D surfaces of finite type 3 and applications to dispersive equations",
    "abstract": "In this paper, we prove the restriction estimates for 2D surfaces S:= {(xi1, xi2, xi1^3 +/- xi2^3) : (xi1, xi2) in [0,1]^2} by reducing to Wang-Wu's result on the perturbed paraboloid and Demeter-Wu's result on the perturbed hyperboloid. The method is based on the rescaling technique developed in [LMZ21]. Besides, we will use the estimates to give a better analysis for discrete nonlinear Schrödinger equations.",
    "authors": [
      "Jiajun Wang"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.11312",
    "title": "Approximation via partial Hausdorff integrals on $H^1(\\mathbb{R})$",
    "abstract": "We obtain the result of approximating \\( f \\) in the \\( H^1(\\mathbb{R}) \\) norm using partial Hausdorff integrals. Specifically, by leveraging the homogeneous multiplier theory of \\( H^1(\\mathbb{R}) \\) and the \\( K \\) functional theory, one result from Pinos and Liflyand [CMB,~2021,~64,~no.3] is extended from \\( L^p(\\mathbb{R}) \\) ( \\( 1 \\leq p \\leq \\infty \\)) to \\( H^1(\\mathbb{R}) \\). As applications, four examples of partial Hausdorff integrals are also given.",
    "authors": [
      "Zifei Yu",
      "Baode Li"
    ],
    "primary_category": "math.CA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.11618",
    "title": "On The Topology of Polygonal Meshes",
    "abstract": "This paper is an introductory and informal exposition on the topology of polygonal meshes. We begin with a broad overview of topological notions and discuss how homeomorphisms, homotopy, and homology can be used to characterize topology. We move on to define polygonal meshes and make a distinction between intrinsic topology and extrinsic topology which depends on the embedding space. A distinction is also made between quantitative topological properties and qualitative properties. We outline a proof of the Euler and the Euler-Poincaré formulas. The Betti numbers are defined in terms of the Euler-Poincaré formula and other mesh statistics rather than as cardinalities of the homology groups which allows us to avoid abstract algebra. Finally, we discuss how it is possible to cut a polygonal mesh such that it becomes a topological disc.",
    "authors": [
      "Andreas Bærentzen"
    ],
    "primary_category": "math.HO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20007",
    "title": "Global Fluctuations of Gaussian Elliptic Matrices",
    "abstract": "We introduce a spoke-arc decomposition of non-crossing annular pair partitions $NC_2(p,q)$ that records spoke type and orientation, isolates spoke-level contributions, and factorizes the dependence on the ellipticity parameter $\\gamma$ into a spoke factor and arc weights. This yields closed-form descriptions of the limiting covariance of Gaussian elliptic matrices. As a corollary, we show that an independent family of Gaussian elliptic random matrices is asymptotically second-order free.",
    "authors": [
      "Lingxuan Wu",
      "Zhi Yin"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20988",
    "title": "Upper bound estimation for the ratio of the first two eigenvalues of Robin Laplacian",
    "abstract": "The celebrated conjecture by Payne, Pólya and Weinberger (1956) states that for the fixed membrane problem, the ratio of the first two eigenvalues, $\\lambda_2/\\lambda_1$, is maximized by a disk. A more general dimensional version of this conjecture was later resolved by Ashbaugh and Benguria in the 1990s. For the Robin Laplacian, Payne and Schaefer (2001) formulated an analogous conjecture, positing that the ratio $\\mu_2/\\mu_1$ is also maximized by a disk for a range of the boundary parameter $\\sigma$. This was later restated by Henrot in 2003. In this work, under some suitable conditions, we affirm this conjecture for all dimensions $N\\geq2$ and for all $\\sigma>0$. Furthermore, we prove that the maximum value of $\\mu_2/\\mu_1$ is strictly decreasing in $\\sigma$ over the entire interval $(0,+\\infty)$. Our result provides a positive answer to a variant of Yau's Problem 77: by measuring the ratio of the first two eigenfrequencies, one can determine whether an elastically supported drum is circular.",
    "authors": [
      "Guowei Dai",
      "Yingxin Sun"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.21489",
    "title": "On the hyperbolic relaxation of the chemical potential in a phase field tumor growth model",
    "abstract": "In this paper, we study a phase field model for a tumor growth model of Cahn--Hilliard type in which the often assumed parabolic relaxation of the chemical potential is replaced by a hyperbolic one. We show that the resulting initial-boundary value problem is well posed and that its solutions depend continuously on two given functions: one appearing in the mass balance equation and one in the nutrient equation, representing, respectively, sources of drugs (e.g. chemotherapy) and antiangiogenic therapy. We also discuss regularity properties of the solutions. Moreover, in the case of a constant proliferation function, we rigorously analyze the asymptotic behavior as the coefficient of the inertial term tends to zero, establishing convergence to the corresponding viscous Cahn--Hilliard tumor growth model. Our results apply to a broad class of double-well potentials, including nonsmooth ones.",
    "authors": [
      "Pierluigi Colli",
      "Elisabetta Rocca",
      "Jürgen Sprekels"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.21680",
    "title": "New Obstacles to Multiple Recurrence",
    "abstract": "We show that there is a set which is not a set of multiple recurrence despite being a set of recurrence for nil-Bohr sets. This answers Huang, Shao, and Ye's \\enquote{higher-order} version of Katznelson's Question on Bohr recurrence and topological recurrence in the negative. Equivalently, we construct a set $S$ so that there is a finite coloring of $\\mathbb{N}$ without three-term arithmetic progressions with common differences in $S$, but so that $S$ lacks the usual polynomial obstacles to arithmetic progressions.",
    "authors": [
      "Ryan Alweiss"
    ],
    "primary_category": "math.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.21776",
    "title": "A proof of irrationality of $π$ based on nested radicals with roots of $2$",
    "abstract": "In this work, we consider four theorems that can be used to prove the irrationality of $\\pi$. These theorems are related to nested radicals with roots of $2$ of kind $c_k = \\sqrt{2 + c_{k - 1}} $ and $c_0 = 0$. Sample computations showing how the rational approximation tend to $\\pi$ with increasing the integer $k$ are presented.",
    "authors": [
      "Sanjar M. Abrarov",
      "Rehan Siddiqui",
      "Rajinder Kumar Jagpal",
      "Brendan M. Quine"
    ],
    "primary_category": "math.GM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22113",
    "title": "The Cayley-Bacharach property and the Levinson-Ullery conjecture",
    "abstract": "In this paper, we study the geometric configurations of a finite set of points having the Cayley-Bacharach property in the $n$-dimensional projective space $\\bbP^n$. Our main contribution is the proof of the Levinson-Ullery conjecture for the previously unsolved case where $d=4$ and $r\\ge 1$.",
    "authors": [
      "Ngoc Long Le",
      "Tran N. K. Linh"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22542",
    "title": "How smooth is the drift of the mixed fractional Brownian motion?",
    "abstract": "The mixed fractional Brownian motion, the sum of independent fractional and standard Brownian motions, is known to be a semimartingale if the Hurst exponent $H$ of its fractional component is greater than $3/4$. The question in the title is motivated by recent findings in quantitative finance. In this note, we find that the drift in its Doob-Meyer decomposition has derivative which is $\\gamma$ Hölder for any $\\gamma < 2H-3/2$.",
    "authors": [
      "Pavel Chigansky",
      "Marina Kleptsyna"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.23185",
    "title": "Embedded topological triviality of separable families of singularities",
    "abstract": "Understanding how singularities behave under small perturbations is a central theme in singularity theory. In this paper we establish sufficient conditions for families of analytic function-germs on a germ of a complex analytic space to admit an embedded topological trivialization. Our results extend previous work of the third author and collaborators, moving from abstract triviality to the embedded setting. As an application, we obtain new instances of topological stability, including a broad class of $\\mu$-constant deformations. These findings provide a new insight into the long-standing $\\mu$-constant conjecture, one of the major open problems in the field.",
    "authors": [
      "R. Giménez Conejero",
      "Andreas Lind",
      "Aurélio Menegon"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00235",
    "title": "Directed schemes of ideals and cardinal characteristics, I: the meager additive ideal",
    "abstract": "We introduce the notion of directed scheme of ideals to characterize peculiar ideals on the reals, which comes from a formalization of the framework of Yorioka ideals for strong measure zero sets. We prove general theorems for directed schemes and propose a directed scheme $\\vec{\\mathcal{M}} = \\{\\mathcal{M}_I \\colon I\\in\\mathbb{I}\\}$ for the ideal $\\mathcal{MA}$ of meager-additive sets of reals. This directed scheme does not only helps us to understand more the combinatorics of $\\mathcal{MA}$ and its cardinal characteristics, but provides us new characterizations of the additivity and cofinality numbers of the meager ideal of the reals. In addition, we display connections between the characteristics associated with $\\mathcal{M}_I$ and other classical characteristics. Furthermore, we demonstrate the consistency of $\\mathrm{cov}(\\mathcal{NA})<\\mathfrak{c}$ and $\\mathrm{cof}(\\mathcal{MA})<\\mathrm{non}(\\mathcal{SN})$. The first one answers a question raised by the authors in arXiv:2401.15364 .",
    "authors": [
      "Miguel A. Cardona",
      "Diego A. Mejía",
      "Ismael E. Rivera-Madrid"
    ],
    "primary_category": "math.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01070",
    "title": "Differential Geometry of the Fixed-Rank Core Covariance Manifold",
    "abstract": "We study the differential geometry of the fixed-rank core covariance manifold. According to Hoff, McCormack, and Zhang [J. R. Stat. Soc., B: Stat., 85 (2023), pp. 1659--1679], every covariance matrix $\\Sigma$ of $p_1\\times p_2$ matrix-variate data uniquely decomposes into a separable component $K$ and a core component $C$. Such a decomposition also exists for rank-$r$ $\\Sigma$ if $p_1/p_2+p_2/p_1<r$, with $C$ sharing the same rank. They posed an open question on whether a partial-isotropy structure can be imposed on $C$ for high-dimensional covariance estimation. We address this question by showing that a partial-isotropy rank-$r$ core is a non-trivial convex combination of a rank-$r$ core and $I_p$ for $p:=p_1p_2$, motivating the study of rank-$r$ cores. For fixed $r>p_1/p_2+p_2/p_1$, we prove that the set of rank-$r$ cores, $\\mathcal{C}_{p_1,p_2,r}^+$, is a compact, smooth, embedded submanifold of the set of rank-$r$ positive semi-definite matrices, except for a measure-zero subset associated with canonical decomposability. When $r=p$, the set of full-rank cores $\\mathcal{C}_{p_1,p_2}^{++}$ is itself a smooth manifold. Moreover, the positive definite cone $\\mathcal{S}_p^{++}$ is diffeomorphic to the product of the Kronecker and core covariance manifolds, providing new geometric insight into $\\mathcal{S}_p^{++}$ via separability. Differential geometric quantities, such as the differential of the diffeomorphism, as well as the Riemannian gradient and Hessian operator on $\\mathcal{C}_{p_1,p_2}^{++}$ and the manifolds used in constructing $\\mathcal{C}_{p_1,p_2,r}^+$, are also derived. Lastly, we propose a partial-isotropy core shrinkage estimator for matrix-variate data, supported by numerical illustrations.",
    "authors": [
      "Bongjung Sung"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01817",
    "title": "Sharp Self-Normalized Concentration Inequalities of Marginal Mean with Sample Variance Only",
    "abstract": "(This is the first version of a working paper. A more detailed follow-up with applications is in preparation.) We develop a family of self-normalized concentration inequalities for marginal mean under martingale-difference structure and $\\phi/\\tilde{\\phi}$-mixing conditions, where the latter includes many processes that are not strongly mixing. The variance term is fully data-observable: naive sample variance in the martingale case and an empirical block long-run variance under mixing conditions. Thus, no predictable variance proxy is required. No specific assumption on the decay of the mixing coefficients (e.g. summability) is needed for the validity. The constants are explicit and the bounds are ready to use.",
    "authors": [
      "Zihao Yuan"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01968",
    "title": "Some remarks on L-equivalence for cubic fourfolds and hyper-Kähler manifolds",
    "abstract": "We prove that if two very general cubic fourfolds are L-equivalent then they are isomorphic, and we observe that there exist special cubic fourfolds which are L-equivalent but not isomorphic. When the cubic fourfolds are very general in certain Hassett divisors, we prove that if they are L-equivalent then they are also Fourier-Mukai partners. We also provide further examples in support of the fact that L-equivalent hyper-Kähler manifolds should be D-equivalent, as conjectured by Meinsma.",
    "authors": [
      "Simone Billi",
      "Lucas Li Bassi"
    ],
    "primary_category": "math.AG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02250",
    "title": "A New Proof of the Abstract Random Tensor Estimate by Deng, Nahmod, and Yue",
    "abstract": "We provide a new proof of the abstract random tensor estimate. This estimate was initially proven by Deng, Nahmod, and Yue (2022) using the moment method. The key new tool in our proof is the direct use of the non-commutative Khintchine inequality with the probabilistic decoupling of the product of Gaussians. Hermite and generalized Laguerre-type polynomials allow us to account for pairings in the real and complex-valued Gaussians, respectively, and remove the square-free (tetrahedral) requirement.",
    "authors": [
      "Claire Kaneshiro"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02397",
    "title": "Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance",
    "abstract": "We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.",
    "authors": [
      "Emanuele Bossi",
      "C. Tyler Diggans",
      "Abd AlRahman R. AlMomani"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02958",
    "title": "Generalized Zykov's Theorem",
    "abstract": "For a simple graph $G$, let $n$ denote its number of vertices, and let $N(G,K_t)$ denote the number of copies of $K_t$ in $G$. Zykov's theorem (1949) asserts that for any $K_{r+1}$-free graph and $t \\ge 2$, \\[ N(G,K_t) \\le {r \\choose t}\\left(\\frac{n}{r}\\right)^t \\] We generalize Zykov's bound within a vertex-based localization framework. For each vertex $v \\in V(G)$, let $c(v)$ denote the order of the largest clique containing $v$. In this paper, we show that \\[ N(G,K_t) \\le n^{t-1} \\sum_{v \\in V(G)} \\frac{1}{c(v)^t} {c(v) \\choose t} \\] We further show that equality holds if and only if $G$ is a regular complete multipartite graph. \\newline Note that if we impose the condition that, $G$ is $K_{r+1}$-free, then $c(v) \\leq r$ for all $v \\in V(G)$. Thus, plugging $c(v) = r$ for all $v \\in V(G)$, we retrieve Zykov's bound.",
    "authors": [
      "Rajat Adak",
      "L. Sunil Chandran"
    ],
    "primary_category": "math.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03012",
    "title": "Note on Regularity theory for Nonlinear elliptic equations",
    "abstract": "In this note, we present several seminal developments in the regularity theory of nonlinear (uniformly) elliptic equations, including the De Giorgi-Nash-Moser theory concerning the Hilbert 19th problem and variational equations, as well as the Krylov-Safonov and Evans-Safonov theories for fully nonlinear equations.",
    "authors": [
      "Zhenye Qian"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2210.17139",
    "title": "Nested Sequents for Intuitionistic Grammar Logics via Structural Refinement",
    "abstract": "Intuitionistic grammar logics fuse constructive and multi-modal reasoning while permitting the use of converse modalities, serving as a generalization of standard intuitionistic modal logics. In this paper, we provide definitions of these logics as well as establish a suitable proof theory thereof. In particular, we show how to apply the structural refinement methodology to extract cut-free nested sequent calculi for intuitionistic grammar logics from their semantics. This method proceeds by first transforming the semantics of these logics into sound and complete labeled sequent systems, which we prove have favorable proof-theoretic properties such as syntactic cut-elimination. We then transform these labeled systems into nested sequent systems via the introduction of propagation rules and the elimination of structural rules. Our derived proof systems are then put to use, whereby we prove the conservativity of intuitionistic grammar logics over their modal counterparts, establish the general undecidability of these logics, and recognize a decidable subclass, referred to as \"simple\" intuitionistic grammar logics.",
    "authors": [
      "Tim S. Lyon"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2212.07356",
    "title": "Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks",
    "abstract": "Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.",
    "authors": [
      "Chung-Hsuan Hu",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.05025",
    "title": "Unbiased Kinetic Langevin Monte Carlo with Inexact Gradients",
    "abstract": "We present an unbiased method for Bayesian posterior means based on kinetic Langevin dynamics that combines advanced splitting methods with enhanced gradient approximations. Our approach avoids Metropolis correction by coupling Markov chains at different discretization levels in a multilevel Monte Carlo approach. Theoretical analysis demonstrates that our proposed estimator is unbiased, attains finite variance, and satisfies a central limit theorem. It can achieve accuracy $\\epsilon>0$ for estimating expectations of Lipschitz functions in $d$ dimensions with $\\mathcal{O}(d^{1/4}\\epsilon^{-2})$ expected gradient evaluations, without assuming warm start. We exhibit similar bounds using both approximate and stochastic gradients, and our method's computational cost is shown to scale independently of the size of the dataset. The proposed method is tested using a multinomial regression problem on the MNIST dataset and a Poisson regression model for soccer scores. Experiments indicate that the number of gradient evaluations per effective sample is independent of dimension, even when using inexact gradients. For product distributions, we give dimension-independent variance bounds. Our results demonstrate that in large-scale applications, the unbiased algorithm we present can be 2-3 orders of magnitude more efficient than the ``gold-standard\" randomized Hamiltonian Monte Carlo.",
    "authors": [
      "Neil K. Chada",
      "Benedict Leimkuhler",
      "Daniel Paulin",
      "Peter A. Whalley"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.03289",
    "title": "Recovery of cyclic words by their subwords",
    "abstract": "A problem of reconstructing words from their subwords involves determining the minimum amount of information needed, such as multisets of scattered subwords of a specific length or the frequency of scattered subwords from a given set, in order to uniquely identify a word. In this paper we show that a cyclic word on a binary alphabet can be reconstructed by its scattered subwords of length $\\frac34n+4$, and for each $n$ one can find two cyclic words of length $n$ which have the same set of scattered subwords of length $\\frac34n-\\frac32$.",
    "authors": [
      "Sergey Luchinin",
      "Svetlana Puzynina",
      "Michaël Rao"
    ],
    "primary_category": "cs.DM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.01552",
    "title": "Multi-view Bayesian optimisation in an input-output reduced space for engineering design",
    "abstract": "Bayesian optimisation is an adaptive sampling strategy for constructing a Gaussian process surrogate to efficiently search for the global minimum of a black-box computational model. Gaussian processes have limited applicability in engineering design problems, which usually have many design variables but typically a low intrinsic dimensionality. Their scalability can be significantly improved by identifying a low-dimensional space of latent variables that serve as inputs to the Gaussian process. In this paper, we introduce a multi-view learning strategy that considers both the input design variables and output data representing the objective or constraint functions, to identify a low-dimensional latent subspace. Adopting a fully probabilistic viewpoint, we use probabilistic partial least squares (PPLS) to learn an orthogonal mapping from the design variables to the latent variables using training data consisting of inputs and outputs of the black-box computational model. The latent variables and posterior probability densities of the PPLS and Gaussian process models are determined sequentially and iteratively, with retraining occurring at each adaptive sampling iteration. We compare the proposed probabilistic partial least squares Bayesian optimisation (PPLS-BO) strategy with its deterministic counterpart, partial least squares Bayesian optimisation (PLS-BO), and classical Bayesian optimisation, demonstrating significant improvements in convergence to the global minimum.",
    "authors": [
      "Thomas A. Archbold",
      "Ieva Kazlauskaite",
      "Fehmi Cirak"
    ],
    "primary_category": "stat.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.10076",
    "title": "Filtration-Based Representation Learning for Temporal Graphs",
    "abstract": "In this work, we introduce a filtration on temporal graphs based on $\\delta$-temporal motifs (recurrent subgraphs), yielding a multi-scale representation of temporal structure. Our temporal filtration allows tools developed for filtered static graphs, including persistent homology and recent graph filtration kernels, to be applied directly to temporal graph analysis. We demonstrate the effectiveness of this approach on temporal graph classification tasks.",
    "authors": [
      "Samrik Chowdhury",
      "Siddharth Pritam",
      "Rohit Roy",
      "Madhav Cherupilil Sajeev"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.17641",
    "title": "Mesoscale Modeling of an Active Colloid's Motion",
    "abstract": "This paper uses Cahn-Hilliard equations as a mesoscale model of the motion of active colloids. The model attempts to capture the driving mechanisms and qualitative behavior of the isotropic colloids originally proposed by J. Decayeaux in 2021. We compare our model against the single colloid behavior presented in that work, as well as against multi-colloid systems.",
    "authors": [
      "Matthew Dobson",
      "David Masse"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.05868",
    "title": "Energy-Conserving Neural Network Closure Model for Long-Time Accurate and Stable LES",
    "abstract": "Machine learning-based closure models for LES have shown promise in capturing complex turbulence dynamics but often suffer from instabilities and physical inconsistencies. In this work, we develop a novel skew-symmetric neural architecture as closure model that enforces stability while preserving key physical conservation laws. Our approach leverages a discretization that ensures mass, momentum, and energy conservation, along with a face-averaging filter to maintain mass conservation in coarse-grained velocity fields. We compare our model against several conventional data-driven closures (including unconstrained convolutional neural networks), and the physics-based Smagorinsky model. Performance is evaluated on decaying turbulence and Kolmogorov flow for multiple coarse-graining factors. In these test cases we observe that unconstrained machine learning models suffer from numerical instabilities. In contrast, our skew-symmetric model remains stable across all tests, though at the cost of increased dissipation. Despite this trade-off, we demonstrate that our model still outperforms the Smagorinsky model in unseen scenarios. These findings highlight the potential of structure-preserving machine learning closures for reliable long-time LES.",
    "authors": [
      "Toby van Gastelen",
      "Wouter Edeling",
      "Benjamin Sanderse"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.13501",
    "title": "Target search optimization by threshold resetting",
    "abstract": "We introduce a new class of first passage time optimization driven by threshold resetting, inspired by many natural processes where crossing a critical limit triggers failure, degradation or transition. In here, search agents are collectively reset when a threshold is reached, creating event-driven, system-coupled simultaneous resets that induce long-range interactions. We develop a unified framework to compute search times for these correlated stochastic processes, with ballistic- and diffusive- searchers as key examples uncovering diverse optimization behaviors. A cost function, akin to breakdown penalties, reveals that optimal resetting can forestall larger losses. This formalism generalizes to broader stochastic systems with multiple degrees of freedom.",
    "authors": [
      "Arup Biswas",
      "Satya N Majumdar",
      "Arnab Pal"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.00686",
    "title": "Ballistic particle transport and Drude weight in gases",
    "abstract": "Owing to the fact that the particle current operator in non-relativistic gases is proportional to the total momentum operator, the particle transport in such systems is always ballistic and fully characterized by a Drude weight $\\Delta$. The Drude weight can be calculated within linear response theory. It is given by the formula $\\Delta = 2 \\pi D$, where $D$ is the density of the gas. This holds in any dimension and for every equilibrium ensemble, in particular for generalized Gibbs ensembles that describe possible equilibrium states of isolated integrable quantum systems. In the canonical ensemble case, the Drude weight can be equivalently obtained from a generalized susceptibility related to the fluctuations of the conserved particle current. Such susceptibility can be rigorously calculated for the integrable Lieb-Liniger Bose gas in any generalized Gibbs ensemble using a generalized Yang-Yang thermodynamic formalism. The resulting expression agrees with a prediction made within the context of generalized hydrodynamics. It also allows us to see explicitly that, within truly generalized Gibbs ensembles, the conductivity related with the particle current is not determined by the corresponding current-current auto-correlation function.",
    "authors": [
      "Frank Göhmann",
      "Andreas Klümper",
      "Karol K. Kozlowski"
    ],
    "primary_category": "cond-mat.quant-gas",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.06210",
    "title": "Spectral Derivatives",
    "abstract": "One of the happiest accidents in all math is the ease of transforming a function to and taking derivatives in the Fourier frequency domain. But in order to exploit this extraordinary fact without serious artefacting, and in order to be able to use a computer, we need quite a bit of extra knowledge and care. This document sets out the math behind the spectral-derivatives Python package. I touch on fundamental signal processing and calculus concepts as necessary and build upwards.",
    "authors": [
      "Pavel Komarov"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.23155",
    "title": "Homomorphism, substructure and ideal: Elementary but rigorous aspects of renormalization group or hierarchical structure of topological orders",
    "abstract": "We propose a general quantum Hamiltonian formalism of a renormalization group (RG) flow with an emphasis on generalized symmetry by interpreting the elementary relationship between homomorphism, quotient ring, and projection. In our formalism, the noninvertible nature of the ideal of a fusion ring realizing the generalized symmetry of an ultraviolet (UV) theory plays a fundamental role in determining condensation rules between anyons, resulting in the infrared (IR) theories. Our algebraic method applies to the domain wall problem in $2+1$ dimensional topologically ordered systems and the corresponding classification of $1+1$ dimensional gapped phase, for example. An ideal decomposition of a fusion ring provides a straightforward but strong constraint on the gapped phase with noninvertible symmetry and its symmetry-breaking (or emergent symmetry) patterns. Moreover, even in several specific homomorphisms connected under massless RG flows, less familiar homomorphisms appear, and we conjecture that they correspond to partially solvable models in recent literature. Our work demonstrates the fundamental significance of the abstract algebraic structure, ideal, for the RG in physics.",
    "authors": [
      "Yoshiki Fukusumi",
      "Yuma Furuta"
    ],
    "primary_category": "hep-th",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.07150",
    "title": "Class conditional conformal prediction for multiple inputs by p-value aggregation",
    "abstract": "Conformal prediction methods are statistical tools designed to quantify uncertainty and generate predictive sets with guaranteed coverage probabilities. This work introduces an innovative refinement to these methods for classification tasks, specifically tailored for scenarios where multiple observations (multi-inputs) of a single instance are available at prediction time. Our approach is particularly motivated by applications in citizen science, where multiple images of the same plant or animal are captured by individuals. Our method integrates the information from each observation into conformal prediction, enabling a reduction in the size of the predicted label set while preserving the required class-conditional coverage guarantee. The approach is based on the aggregation of conformal p-values computed from each observation of a multi-input. By exploiting the exact distribution of these p-values, we propose a general aggregation framework using an abstract scoring function, encompassing many classical statistical tools. Knowledge of this distribution also enables refined versions of standard strategies, such as majority voting. We evaluate our method on simulated and real data, with a particular focus on Pl@ntNet, a prominent citizen science platform that facilitates the collection and identification of plant species through user-submitted images.",
    "authors": [
      "Jean-Baptiste Fermanian",
      "Mohamed Hebiri",
      "Joseph Salmon"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00856",
    "title": "On dissipation operators of Quantum Optics",
    "abstract": "We consider dissipation operators used in Quantum Optics for the description of quantum spontaneous emission in the context of damped driven Jaynes-Cummings equations. The equations describe quantised one-mode Maxwell field coupled to a two-level molecule. Our main result is the symmetry and nonpositivity of basic dissipation operator of Quantum Optics.",
    "authors": [
      "A.I. Komech",
      "E.A. Kopylova"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00913",
    "title": "Do quantum linear solvers offer advantage for networks-based system of linear equations?",
    "abstract": "In this exploratory numerical study, we assess the suitability of Quantum Linear Solvers (QLSs) toward providing a quantum advantage for Networks-based Linear System Problems (NLSPs). NLSPs naturally arise from graphs, and are of importance as they are connected to real-world applications. The achievable advantage with a QLS for an NLSP depends on the interplay between the scaling of condition number and sparsity of matrices associated with the graph family considered, as well as system size growth. We analyze 50 graph families and identify that within the scope of our study, only 4% of them exhibit prospects for an exponential advantage with the Harrow-Hassidim-Lloyd (HHL) algorithm relative to an efficient classical solver (best graphs), while about 20% of them show a polynomial advantage (better graphs). Furthermore, we report that some graph families graduate from offering no advantage with HHL to promising a polynomial advantage with improved algorithms such as the Childs-Kothari-Somma algorithm, while some other graph families exhibit futile exponential advantage. We introduce a unified graph superfamily and show the existence of infinite best and better graphs in it. We also conjecture the conditions under which one may visually examine a graph family and guess the prospects for an advantage. Finally, we very briefly touch upon some practical issues that may arise even if the aforementioned graph theoretic requirements are satisfied, including quantum hardware challenges.",
    "authors": [
      "Disha Shetty",
      "Supriyo Dutta",
      "Palak Chawla",
      "Akshaya Jayashankar",
      "Jordi Riu",
      "Jan Nogue",
      "K. Sugisaki",
      "V. S. Prasannaa"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25783",
    "title": "Sharpness of Minima in Deep Matrix Factorization: Exact Expressions",
    "abstract": "Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff & Michaeli (2020). This expression uncovers a fundamental property of the loss landscape of depth-2 matrix factorization problems: a minimum is flat if and only if it is spectral-norm balanced, which implies that flat minima are not necessarily Frobenius-norm balanced. Furthermore, to complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.",
    "authors": [
      "Anil Kamber",
      "Rahul Parhi"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.03814",
    "title": "Detecting Invariant Manifolds in ReLU-Based RNNs",
    "abstract": "Recurrent Neural Networks (RNNs) have found widespread applications in machine learning for time series prediction and dynamical systems reconstruction, and experienced a recent renaissance with improved training algorithms and architectural designs. Understanding why and how trained RNNs produce their behavior is important for scientific and medical applications, and explainable AI more generally. An RNN's dynamical repertoire depends on the topological and geometrical properties of its state space. Stable and unstable manifolds of periodic points play a particularly important role: They dissect a dynamical system's state space into different basins of attraction, and their intersections lead to chaotic dynamics with fractal geometry. Here we introduce a novel algorithm for detecting these manifolds, with a focus on piecewise-linear RNNs (PLRNNs) employing rectified linear units (ReLUs) as their activation function. We demonstrate how the algorithm can be used to trace the boundaries between different basins of attraction, and hence to characterize multistability, a computationally important property. We further show its utility in finding so-called homoclinic points, the intersections between stable and unstable manifolds, and thus establish the existence of chaos in PLRNNs. Finally we show for an empirical example, electrophysiological recordings from a cortical neuron, how insights into the underlying dynamics could be gained through our method.",
    "authors": [
      "Lukas Eisenmann",
      "Alena Brändle",
      "Zahra Monfared",
      "Daniel Durstewitz"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05620",
    "title": "Monte Carlo-Type Neural Operator for Differential Equations",
    "abstract": "The Monte Carlo-type Neural Operator (MCNO) introduces a framework for learning solution operators of one-dimensional partial differential equations (PDEs) by directly learning the kernel function and approximating the associated integral operator using a Monte Carlo-type approach. Unlike Fourier Neural Operators (FNOs), which rely on spectral representations and assume translation-invariant kernels, MCNO makes no such assumptions. The kernel is represented as a learnable tensor over sampled input-output pairs, and sampling is performed once, uniformly at random from a discretized grid. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training, while an interpolation step maps between arbitrary input and output grids to further enhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with efficient computational cost. We also provide a theoretical analysis proving that the Monte Carlo estimator yields a bounded bias and variance under mild regularity assumptions. This result holds in any spatial dimension, suggesting that MCNO may extend naturally beyond one-dimensional problems. More broadly, this work explores how Monte Carlo-type integration can be incorporated into neural operator frameworks for continuous-domain PDEs, providing a theoretically supported alternative to spectral methods (such as FNO) and to graph-based Monte Carlo approaches (such as the Graph Kernel Neural Operator, GNO).",
    "authors": [
      "Salah Eddine Choutri",
      "Prajwal Chauhan",
      "Othmane Mazhar",
      "Saif Eddin Jabari"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05809",
    "title": "Coherent estimation of risk measures",
    "abstract": "We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.",
    "authors": [
      "Martin Aichele",
      "Igor Cialenco",
      "Damian Jelito",
      "Marcin Pitera"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22501",
    "title": "A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior",
    "abstract": "In this paper, we introduce the SDIR (Susceptible-Delayable-Infected-Recovered) model, an extension of the classical SIR epidemic framework, to provide a more explicit characterization of user behavior in online social networks. The newly merged state D (delayable) represents users who have received the information but delayed its spreading and may eventually choose not to share it at all. Based on the mean-field approximation method, we derive the dynamical equations of the model and investigate its convergence and stability conditions. Under these conditions, we further propose an approximation algorithm for the edge-deletion problem, aiming to minimize the influence of information diffusion by identifying approximate solutions.",
    "authors": [
      "Tran Van Khanh",
      "Do Xuan Cho",
      "Hoang Phi Dung"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.27030",
    "title": "Generalizing matrix representations to fully heterochronous ranked tree shapes",
    "abstract": "Phylogenetic tree shapes capture fundamental signatures of evolution. We consider ``ranked'' tree shapes, which are equipped with a total order on the internal nodes compatible with the tree graph. Recent work has established an elegant bijection of ranked tree shapes and a class of integer matrices, called \\textbf{F}-matrices, defined by simple inequalities. This formulation is for isochronous ranked tree shapes, where all leaves share the same sampling time, such as in the study of ancient human demography from present-day individuals. Another important style of phylogenetics concerns trees where the ``timing'' of events is by branch length rather than calendar time. This style of tree, called a rooted phylogram, is output by popular maximum-likelihood methods. These trees are broadly relevant, such as to study the affinity maturation of B cells in the immune system. Discretizing time in a rooted phylogram gives a fully heterochronous ranked tree shape, where leaves are part of the total order. Here we extend the \\textbf{F}-matrix framework to such fully heterochronous ranked tree shapes. We establish an explicit bijection between a class of \\textbf{F}-matrices and the space of such tree shapes. The matrix representation has the key feature that values at any entry are highly constrained via four previous entries, enabling straightforward enumeration of all valid tree shapes. We also use this framework to develop probabilistic models on ranked tree shapes. Our work extends understanding of combinatorial objects that have a rich history in the literature.",
    "authors": [
      "Chris Jennings-Shaffer",
      "Cherith Chen",
      "Julia A Palacios",
      "Frederick A Matsen IV"
    ],
    "primary_category": "q-bio.PE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.10639",
    "title": "Direction-of-Arrival and Noise Covariance Matrix joint estimation for beamforming",
    "abstract": "We propose a joint estimation method for the Direction-of-Arrival (DoA) and the Noise Covariance Matrix (NCM) tailored for beamforming applications. Building upon an existing NCM framework, our approach simplifies the estimation procedure by deriving an quasi-linear solution, instead of the traditional exhaustive search. Additionally, we introduce a novel DoA estimation technique that operates across all frequency bins, improving robustness in reverberant environments. Simulation results demonstrate that our method outperforms classical techniques, such as MUSIC, in mid- to high-angle scenarios, achieving lower angular errors and superior signal enhancement through beamforming. The proposed framework was also fared against other techniques for signal enhancement, having better noise rejection and interference canceling capabilities. These improvements are validated using both theoretical and empirical performance metrics.",
    "authors": [
      "Vitor Gelsleichter Probst Curtarelli",
      "Stephan Paul",
      "Anderson Wedderhoff Spengler"
    ],
    "primary_category": "eess.AS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.16299",
    "title": "Emulation Capacity between Idempotent Channels",
    "abstract": "We study the optimal rates of emulation (also called interconversion) between quantum channels. When the source and the target channels are idempotent, we give a single-letter expression for the zero-error emulation capacity in terms of structural properties of the range of the two channels. This expression shows that channel emulation is not reversible for general idempotent channels. Furthermore, we establish a strong converse rate that matches with the zero-error emulation capacity when the source or the target channel is either an identity or a completely dephasing channel.",
    "authors": [
      "Idris Delsol",
      "Omar Fawzi",
      "Li Gao",
      "Mizanur Rahaman"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00517",
    "title": "No-Regret Gaussian Process Optimization of Time-Varying Functions",
    "abstract": "Sequential optimization of black-box functions from noisy evaluations has been widely studied, with Gaussian Process bandit algorithms such as GP-UCB guaranteeing no-regret in stationary settings. However, for time-varying objectives, it is known that no-regret is unattainable under pure bandit feedback unless strong and often unrealistic assumptions are imposed. In this article, we propose a novel method to optimize time-varying rewards in the frequentist setting, where the objective has bounded RKHS norm. Time variations are captured through uncertainty injection (UI), which enables heteroscedastic GP regression that adapts past observations to the current time step. As no-regret is unattainable in general in the strict bandit setting, we relax the latter allowing additional queries on previously observed points. Building on sparse inference and the effect of UI on regret, we propose W-SparQ-GP-UCB, an online algorithm that achieves no-regret with only a vanishing number of additional queries per iteration. To assess the theoretical limits of this approach, we establish a lower bound on the number of additional queries required for no-regret, proving the efficiency of our method. Finally, we provide a comprehensive analysis linking the degree of time-variation of the function to achievable regret rates, together with upper and lower bounds on the number of additional queries needed in each regime.",
    "authors": [
      "Eliabelle Mauduit",
      "Eloïse Berthier",
      "Andrea Simonetto"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02384",
    "title": "Markov Chains Approximate Message Passing",
    "abstract": "Markov chain Monte Carlo algorithms have long been observed to obtain near-optimal performance in various Bayesian inference settings. However, developing a supporting theory that makes these studies rigorous has proved challenging. In this paper, we study the classical spiked Wigner inference problem, where one aims to recover a planted Boolean spike from a noisy matrix measurement. We relate the recovery performance of Glauber dynamics on the annealed posterior to the performance of Approximate Message Passing (AMP), which is known to achieve Bayes-optimal performance. Our main results rely on the analysis of an auxiliary Markov chain called restricted Gaussian dynamics (RGD). Concretely, we establish the following results: 1. RGD can be reduced to an effective one-dimensional recursion which mirrors the evolution of the AMP iterates. 2. From a warm start, RGD rapidly converges to a fixed point in correlation space, which recovers Bayes-optimal performance when run on the posterior. 3. Conditioned on widely believed mixing results for the SK model, we recover the phase transition for non-trivial inference.",
    "authors": [
      "Amit Rajaraman",
      "David X. Wu"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02513",
    "title": "Decentralized Fairness Aware Multi Task Federated Learning for VR Network",
    "abstract": "Wireless connectivity promises to unshackle virtual reality (VR) experiences, allowing users to engage from anywhere, anytime. However, delivering seamless, high-quality, real-time VR video wirelessly is challenging due to the stringent quality of experience requirements, low latency constraints, and limited VR device capabilities. This paper addresses these challenges by introducing a novel decentralized multi task fair federated learning (DMTFL) based caching that caches and prefetches each VR user's field of view (FOV) at base stations (BSs) based on the caching strategies tailored to each BS. In federated learning (FL) in its naive form, often biases toward certain users, and a single global model fails to capture the statistical heterogeneity across users and BSs. In contrast, the proposed DMTFL algorithm personalizes content delivery by learning individual caching models at each BS. These models are further optimized to perform well under any target distribution, while providing theoretical guarantees via Rademacher complexity and a probably approximately correct (PAC) bound on the loss. Using a realistic VR head-tracking dataset, our simulations demonstrate the superiority of our proposed DMTFL algorithm compared to baseline algorithms.",
    "authors": [
      "Krishnendu S. Tharakan",
      "Carlo Fischione"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03047",
    "title": "Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models",
    "abstract": "Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.",
    "authors": [
      "Samih Fadli"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03048",
    "title": "Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation",
    "abstract": "I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.",
    "authors": [
      "Austin Spizzirri"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03049",
    "title": "State Transition Block Diagram of the Generalized Maxwell Slip Friction Model",
    "abstract": "Dynamic friction models (DFMs) encode essential information for the simulation and control of systems with friction. Traditionally, DFMs have been published with conceptual block diagrams, promoting clarity and reproducibility in simulation. However, modern DFMs have grown increasingly complex and block diagrams are now rarely presented, limiting accessibility. This letter presents a block diagram representation of the Generalized Maxwell Slip (GMS) friction model, an advanced multi-state DFM capable of simulating a wide range of nonlinear friction phenomena. The diagram can be implemented in the MATLAB-Simulink environment using a Stateflow chart or embedded if-else logic to represent the state transition criteria, but it is not limited to this platform. Closed-loop and open-loop simulations were conducted to verify that the block diagram reproduces non-drifting behavior and stick-slip friction, including benchmarking against the LuGre model. The proposed diagram improves accessibility to advanced dynamic friction models and provides the engineering community with a practical tool for the simulation and control of systems with friction.",
    "authors": [
      "Kirk Roffi"
    ],
    "primary_category": "cs.CE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03050",
    "title": "Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling",
    "abstract": "Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.",
    "authors": [
      "Peter Hedström",
      "Victor Lamelas Cubero",
      "Jón Sigurdsson",
      "Viktor Österberg",
      "Satish Kolli",
      "Joakim Odqvist",
      "Ziyong Hou",
      "Wangzhong Mu",
      "Viswanadh Gowtham Arigela"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03052",
    "title": "LATTICE: Democratize High-Fidelity 3D Generation at Scale",
    "abstract": "We present LATTICE, a new framework for high-fidelity 3D asset generation that bridges the quality and scalability gap between 3D and 2D generative models. While 2D image synthesis benefits from fixed spatial grids and well-established transformer architectures, 3D generation remains fundamentally more challenging due to the need to predict both spatial structure and detailed geometric surfaces from scratch. These challenges are exacerbated by the computational complexity of existing 3D representations and the lack of structured and scalable 3D asset encoding schemes. To address this, we propose VoxSet, a semi-structured representation that compresses 3D assets into a compact set of latent vectors anchored to a coarse voxel grid, enabling efficient and position-aware generation. VoxSet retains the simplicity and compression advantages of prior VecSet methods while introducing explicit structure into the latent space, allowing positional embeddings to guide generation and enabling strong token-level test-time scaling. Built upon this representation, LATTICE adopts a two-stage pipeline: first generating a sparse voxelized geometry anchor, then producing detailed geometry using a rectified flow transformer. Our method is simple at its core, but supports arbitrary resolution decoding, low-cost training, and flexible inference schemes, achieving state-of-the-art performance on various aspects, and offering a significant step toward scalable, high-quality 3D asset creation.",
    "authors": [
      "Zeqiang Lai",
      "Yunfei Zhao",
      "Zibo Zhao",
      "Haolin Liu",
      "Qingxiang Lin",
      "Jingwei Huang",
      "Chunchao Guo",
      "Xiangyu Yue"
    ],
    "primary_category": "cs.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03053",
    "title": "Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation",
    "abstract": "We show for invertible problems that transform data from a source domain (for example, Logic Condition Tables (LCTs)) to a destination domain (for example, Hardware Description Language (HDL) code), an approach of using Large Language Models (LLMs) as a lossless encoder from source to destination followed by as a lossless decoder back to the source, comparable to lossless compression in information theory, can mitigate most of the LLM drawbacks of hallucinations and omissions. Specifically, using LCTs as inputs, we generate the full HDL for a two-dimensional network-on-chip router (13 units, 1500-2000 lines of code) using seven different LLMs, reconstruct the LCTs from the auto-generated HDL, and compare the original and reconstructed LCTs. This approach yields significant productivity improvements, not only confirming correctly generated LLM logic and detecting incorrectly generated LLM logic but also assisting developers in finding design specification errors.",
    "authors": [
      "Andrew S. Cassidy",
      "Guillaume Garreau",
      "Jay Sivagnaname",
      "Mike Grassi",
      "Bernard Brezzo",
      "John V. Arthur",
      "Dharmendra S. Modha"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03054",
    "title": "Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research",
    "abstract": "Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.",
    "authors": [
      "Ciro Benito Raggio",
      "Lucia Migliorelli",
      "Nils Skupien",
      "Mathias Krohmer Zabaleta",
      "Oliver Blanck",
      "Francesco Cicone",
      "Giuseppe Lucio Cascini",
      "Paolo Zaffino",
      "Maria Francesca Spadea"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03055",
    "title": "Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins",
    "abstract": "Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.",
    "authors": [
      "Xiaowu Sun",
      "Thabo Mahendiran",
      "Ortal Senouf",
      "Denise Auberson",
      "Bernard De Bruyne",
      "Stephane Fournier",
      "Olivier Muller",
      "Pascal Frossard",
      "Emmanuel Abbe",
      "Dorina Thanou"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03056",
    "title": "Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models",
    "abstract": "Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ this https URL",
    "authors": [
      "Zhidong Gao",
      "Zimeng Pan",
      "Yuhang Yao",
      "Chenyue Xie",
      "Wei Wei"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03058",
    "title": "Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding",
    "abstract": "This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.",
    "authors": [
      "Duy-Tung Pham",
      "An The Nguyen",
      "Viet-Hoang Tran",
      "Nhan-Phu Chung",
      "Xin T. Tong",
      "Tan M. Nguyen",
      "Thieu N. Vo"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03059",
    "title": "Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL",
    "abstract": "The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.",
    "authors": [
      "Jiaju Qi",
      "Lei Lei",
      "Thorsteinn Jonsson",
      "Dusit Niyato"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03060",
    "title": "A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap",
    "abstract": "Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale. We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.",
    "authors": [
      "Jing Pan",
      "Li Shi",
      "Paul Lo"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03061",
    "title": "Accumulated Local Effects and Graph Neural Networks for link prediction",
    "abstract": "We investigate how Accumulated Local Effects (ALE), a model-agnostic explanation method, can be adapted to visualize the influence of node feature values in link prediction tasks using Graph Neural Networks (GNNs), specifically Graph Convolutional Networks and Graph Attention Networks. A key challenge addressed in this work is the complex interactions of nodes during message passing within GNN layers, complicating the direct application of ALE. Since a straightforward solution of modifying only one node at once substantially increases computation time, we propose an approximate method that mitigates this challenge. Our findings reveal that although the approximate method offers computational efficiency, the exact method yields more stable explanations, particularly when smaller data subsets are used. However, the explanations produced with the approximate method are not significantly different from the ones obtained with the exact method. Additionally, we analyze how varying parameters affect the accuracy of ALE estimation for both approaches.",
    "authors": [
      "Paulina Kaczyńska",
      "Julian Sienkiewicz",
      "Dominik Ślęzak"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03062",
    "title": "Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing",
    "abstract": "Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \\textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \\textbf{PivGa}, an additional \\textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.",
    "authors": [
      "Roman Rausch",
      "David Jansen",
      "Sukhbinder Singh",
      "Román Orús"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03063",
    "title": "Unsupervised Multimodal Graph-based Model for Geo-social Analysis",
    "abstract": "The systematic analysis of user-generated social media content, especially when enriched with geospatial context, plays a vital role in domains such as disaster management and public opinion monitoring. Although multimodal approaches have made significant progress, most existing models remain fragmented, processing each modality separately rather than integrating them into a unified end-to-end model. To address this, we propose an unsupervised, multimodal graph-based methodology that jointly embeds semantic and geographic information into a shared representation space. The proposed methodology comprises two architectural paradigms: a mono graph (MonoGrah) model that jointly encodes both modalities, and a multi graph (MultiGraph) model that separately models semantic and geographic relationships and subsequently integrates them through multi-head attention mechanisms. A composite loss, combining contrastive, coherence, and alignment objectives, guides the learning process to produce semantically coherent and spatially compact clusters. Experiments on four real-world disaster datasets demonstrate that our models consistently outperform existing baselines in topic quality, spatial coherence, and interpretability. Inherently domain-independent, the framework can be readily extended to diverse forms of multimodal data and a wide range of downstream analysis tasks.",
    "authors": [
      "Ehsaneddin Jalilian",
      "Bernd Resch"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03064",
    "title": "Demographic Inference from Social Media Data with Multimodal Foundation Models: Strategies, Evaluation, and Benchmarking",
    "abstract": "Demographic inference plays a crucial role in understanding the representativeness and equity of social media-based research. However, existing methods typically rely on a single modality, such as text, image, or network, and are limited to predicting one or two demographic attributes, constraining their generalizability and robustness across populations. This study leverages GPT-5, a state-of-the-art multimodal foundation model, to infer age, gender, and race from social media profiles. Using a dataset of 263 publicly available X (formerly Twitter) users, we design a progressive multimodal framework that incrementally incorporates usernames, profile descriptions, tweets, and profile images to examine how each information source contributes to inference accuracy. Results show a consistent improvement across all conditions, with the inclusion of textual and visual cues substantially enhancing performance. GPT-5 achieves an overall accuracy of 0.90 for age, 0.98 for gender, and 0.85 for race, outperforming existing models under equivalent inputs. These findings demonstrate the potential of large multimodal foundation models to capture complex, cross-modal demographic cues with minimal task-specific training. The study further highlights a transparent, interpretable approach to multimodal reasoning that advances the accuracy, fairness, and scalability of demographic inference in social data analytics.",
    "authors": [
      "Hao Yang",
      "Angela Yao",
      "Eric Chang",
      "Hexiang Wang"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03065",
    "title": "Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning",
    "abstract": "Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.",
    "authors": [
      "Nihir Chadderwala"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03067",
    "title": "Quantifying the Potential to Escape Filter Bubbles: A Behavior-Aware Measure via Contrastive Simulation",
    "abstract": "Nowadays, recommendation systems have become crucial to online platforms, shaping user exposure by accurate preference modeling. However, such an exposure strategy can also reinforce users' existing preferences, leading to a notorious phenomenon named filter bubbles. Given its negative effects, such as group polarization, increasing attention has been paid to exploring reasonable measures to filter bubbles. However, most existing evaluation metrics simply measure the diversity of user exposure, failing to distinguish between algorithmic preference modeling and actual information confinement. In view of this, we introduce Bubble Escape Potential (BEP), a behavior-aware measure that quantifies how easily users can escape from filter bubbles. Specifically, BEP leverages a contrastive simulation framework that assigns different behavioral tendencies (e.g., positive vs. negative) to synthetic users and compares the induced exposure patterns. This design enables decoupling the effect of filter bubbles and preference modeling, allowing for more precise diagnosis of bubble severity. We conduct extensive experiments across multiple recommendation models to examine the relationship between predictive accuracy and bubble escape potential across different groups. To the best of our knowledge, our empirical results are the first to quantitatively validate the dilemma between preference modeling and filter bubbles. What's more, we observe a counter-intuitive phenomenon that mild random recommendations are ineffective in alleviating filter bubbles, which can offer a principled foundation for further work in this direction.",
    "authors": [
      "Difu Feng",
      "Qianqian Xu",
      "Zitai Wang",
      "Cong Hua",
      "Zhiyong Yang",
      "Qingming Huang"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03068",
    "title": "Echoes of AI Harms: A Human-LLM Synergistic Framework for Bias-Driven Harm Anticipation",
    "abstract": "The growing influence of Artificial Intelligence (AI) systems on decision-making in critical domains has exposed their potential to cause significant harms, often rooted in biases embedded across the AI lifecycle. While existing frameworks and taxonomies document bias or harms in isolation, they rarely establish systematic links between specific bias types and the harms they cause, particularly within real-world sociotechnical contexts. Technical fixes proposed to address AI biases are ill-equipped to address them and are typically applied after a system has been developed or deployed, offering limited preventive value. We propose ECHO, a novel framework for proactive AI harm anticipation through the systematic mapping of AI bias types to harm outcomes across diverse stakeholder and domain contexts. ECHO follows a modular workflow encompassing stakeholder identification, vignette-based presentation of biased AI systems, and dual (human-LLM) harm annotation, integrated within ethical matrices for structured interpretation. This human-centered approach enables early-stage detection of bias-to-harm pathways, guiding AI design and governance decisions from the outset. We validate ECHO in two high-stakes domains (disease diagnosis and hiring), revealing domain-specific, bias-to-harm patterns and demonstrating ECHO's potential to support anticipatory governance of AI systems",
    "authors": [
      "Nicoleta Tantalaki",
      "Sophia Vei",
      "Athena Vakali"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03069",
    "title": "Hierarchical clustering of complex energy systems using pretopology",
    "abstract": "This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption? Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system. To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library. To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company. On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.",
    "authors": [
      "Loup-Noe Levy",
      "Jeremie Bosom",
      "Guillaume Guerard",
      "Soufian Ben Amor",
      "Marc Bui",
      "Hai Tran"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03070",
    "title": "Mixed Data Clustering Survey and Challenges",
    "abstract": "The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.",
    "authors": [
      "Guillaume Guerard",
      "Sonia Djebali"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03071",
    "title": "PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering",
    "abstract": "This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.",
    "authors": [
      "Loup-Noe Levy",
      "Guillaume Guerard",
      "Sonia Djebali",
      "Soufian Ben Amor"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03072",
    "title": "Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI",
    "abstract": "Current AI paradigms, as \"architects of experience,\" face fundamental challenges in explainability and value alignment. This paper introduces \"Weight-Calculatism,\" a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.",
    "authors": [
      "Hu Keyi"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03073",
    "title": "Economies of Open Intelligence: Tracing Power & Participation in the Model Ecosystem",
    "abstract": "Since 2019, the Hugging Face Model Hub has been the primary global platform for sharing open weight AI models. By releasing a dataset of the complete history of weekly model downloads (June 2020-August 2025) alongside model metadata, we provide the most rigorous examination to-date of concentration dynamics and evolving characteristics in the open model economy. Our analysis spans 851,000 models, over 200 aggregated attributes per model, and 2.2B downloads. We document a fundamental rebalancing of economic power: US open-weight industry dominance by Google, Meta, and OpenAI has declined sharply in favor of unaffiliated developers, community organizations, and, as of 2025, Chinese industry, with DeepSeek and Qwen models potentially heralding a new consolidation of market power. We identify statistically significant shifts in model properties, a 17X increase in average model size, rapid growth in multimodal generation (3.4X), quantization (5X), and mixture-of-experts architectures (7X), alongside concerning declines in data transparency, with open weights models surpassing truly open source models for the first time in 2025. We expose a new layer of developer intermediaries that has emerged, focused on quantizing and adapting base models for both efficiency and artistic expression. To enable continued research and oversight, we release the complete dataset with an interactive dashboard for real-time monitoring of concentration dynamics and evolving properties in the open model economy.",
    "authors": [
      "Shayne Longpre",
      "Christopher Akiki",
      "Campbell Lund",
      "Atharva Kulkarni",
      "Emily Chen",
      "Irene Solaiman",
      "Avijit Ghosh",
      "Yacine Jernite",
      "Lucie-Aimée Kaffee"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03074",
    "title": "Model-Agnostic Fairness Regularization for GNNs with Incomplete Sensitive Information",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated exceptional efficacy in relational learning tasks, including node classification and link prediction. However, their application raises significant fairness concerns, as GNNs can perpetuate and even amplify societal biases against protected groups defined by sensitive attributes such as race or gender. These biases are often inherent in the node features, structural topology, and message-passing mechanisms of the graph itself. A critical limitation of existing fairness-aware GNN methods is their reliance on the strong assumption that sensitive attributes are fully available for all nodes during training--a condition that poses a practical impediment due to privacy concerns and data collection constraints. To address this gap, we propose a novel, model-agnostic fairness regularization framework designed for the realistic scenario where sensitive attributes are only partially available. Our approach formalizes a fairness-aware objective function that integrates both equal opportunity and statistical parity as differentiable regularization terms. Through a comprehensive empirical evaluation across five real-world benchmark datasets, we demonstrate that the proposed method significantly mitigates bias across key fairness metrics while maintaining competitive node classification performance. Results show that our framework consistently outperforms baseline models in achieving a favorable fairness-accuracy trade-off, with minimal degradation in predictive accuracy. The datasets and source code will be publicly released at this https URL .",
    "authors": [
      "Mahdi Tavassoli Kejani",
      "Fadi Dornaika",
      "Jean-Michel Loubes"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03076",
    "title": "Will Power Return to the Clouds? From Divine Authority to GenAI Authority",
    "abstract": "Generative AI systems now mediate newsfeeds, search rankings, and creative content for hundreds of millions of users, positioning a handful of private firms as de-facto arbiters of truth. Drawing on a comparative-historical lens, this article juxtaposes the Galileo Affair, a touchstone of clerical knowledge control, with contemporary Big-Tech content moderation. We integrate Foucault's power/knowledge thesis, Weber's authority types (extended to a rational-technical and emerging agentic-technical modality), and Floridi's Dataism to analyze five recurrent dimensions: disciplinary power, authority modality, data pluralism, trust versus reliance, and resistance pathways. Primary sources (Inquisition records; platform transparency reports) and recent empirical studies on AI trust provide the evidentiary base. Findings show strong structural convergences: highly centralized gatekeeping, legitimacy claims couched in transcendent principles, and systematic exclusion of marginal voices. Divergences lie in temporal velocity, global scale, and the widening gap between public reliance and trust in AI systems. Ethical challenges cluster around algorithmic opacity, linguistic inequity, bias feedback loops, and synthetic misinformation. We propose a four-pillar governance blueprint: (1) a mandatory international model-registry with versioned policy logs, (2) representation quotas and regional observatories to de-center English-language hegemony, (3) mass critical-AI literacy initiatives, and (4) public-private support for community-led data trusts. Taken together, these measures aim to narrow the trust-reliance gap and prevent GenAI from hardcoding a twenty-first-century digital orthodoxy.",
    "authors": [
      "Mohammad Saleh Torkestani",
      "Taha Mansouri"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03077",
    "title": "Irresponsible AI: big tech's influence on AI research and associated impacts",
    "abstract": "The accelerated development, deployment and adoption of artificial intelligence systems has been fuelled by the increasing involvement of big tech. This has been accompanied by increasing ethical concerns and intensified societal and environmental impacts. In this article, we review and discuss how these phenomena are deeply entangled. First, we examine the growing and disproportionate influence of big tech in AI research and argue that its drive for scaling and general-purpose systems is fundamentally at odds with the responsible, ethical, and sustainable development of AI. Second, we review key current environmental and societal negative impacts of AI and trace their connections to big tech and its underlying economic incentives. Finally, we argue that while it is important to develop technical and regulatory approaches to these challenges, these alone are insufficient to counter the distortion introduced by big tech's influence. We thus review and propose alternative strategies that build on the responsibility of implicated actors and collective action.",
    "authors": [
      "Alex Hernandez-Garcia",
      "Alexandra Volokhova",
      "Ezekiel Williams",
      "Dounia Shaaban Kabakibo"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03078",
    "title": "Risk-Entropic Flow Matching",
    "abstract": "Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.",
    "authors": [
      "Vahid R. Ramezani",
      "Benjamin Englard"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03079",
    "title": "Watermarks for Embeddings-as-a-Service Large Language Models",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques. Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques. Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.",
    "authors": [
      "Anudeex Shetty"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03082",
    "title": "Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation",
    "abstract": "Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.",
    "authors": [
      "Nan Zhuang",
      "Wenshuo Wang",
      "Lekai Qian",
      "Yuxiao Wang",
      "Boyu Cao",
      "Qi Liu"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03083",
    "title": "Evaluate the Stack Management in Effect Handlers using the libseff C Library",
    "abstract": "Effect handlers are increasingly prominent in modern programming for managing complex computational effects, including concurrency, asynchronous operations, and exception handling, in a modular and flexible manner. Efficient stack management remains a significant challenge for effect handlers due to the dynamic control flow changes they introduce. This paper explores a novel stack management approach using user-level overcommitting within the libseff C library, which leverages virtual memory mechanisms and protection-based lazy allocation combined with signal-driven memory commitment. Our user-level overcommitting implementation dynamically resizes stacks on-demand, improving memory utilization and reducing waste compared to traditional methods. We rigorously benchmark and evaluate this novel strategy against conventional fixed- size stacks, segmented stacks, and kernel-based overcommitting, using metrics such as context-switch latency, stack expansion efficiency, multi-threaded performance, and robustness under rapid stack growth conditions. Experimental results demonstrate that kernel-based overcommitting achieves an effective balance between performance and flexibility, whereas our user-level implementation, while flexible, incurs additional overheads, highlighting areas for optimization. This study provides a detailed comparative analysis of various stack management strate- gies, offering practical recommendations tailored to specific application requirements and operational constraints. Future work will focus on refining user-level overcommit- ting mechanisms, mitigating non-deterministic behaviors, and expanding benchmark frameworks to include real-world scenarios.",
    "authors": [
      "ZeHao Yu"
    ],
    "primary_category": "cs.PL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03086",
    "title": "Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in code translation, yet their performance deteriorates in low-resource programming domains such as Fortran and emerging frameworks like CUDA, where high-quality parallel data are scarce. We present an automated dataset generation pipeline featuring a dual-LLM Questioner-Solver design that incorporates external knowledge from compilers and runtime feedback. Beyond traditional source-target code pair datasets, our approach additionally generates (1) verified translations with unit tests for assessing functional consistency, and (2) multi-turn dialogues that capture the reasoning process behind translation refinement. Applied to Fortran -> C++ and C++ -> CUDA, the pipeline yields 3.64k and 3.93k dialogues, respectively. Fine-tuning on this data yields dramatic improvements in functional correctness, boosting unit test success rates by over 56% on the challenging C++-to-CUDA task. We show this data enables a 7B open-weight model to significantly outperform larger proprietary systems on key metrics like compilation success.",
    "authors": [
      "Le Chen",
      "Nuo Xu",
      "Winson Chen",
      "Bin Lei",
      "Pei-Hung Lin",
      "Dunzhi Zhou",
      "Rajeev Thakur",
      "Caiwen Ding",
      "Ali Jannesari",
      "Chunhua Liao"
    ],
    "primary_category": "cs.PL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03087",
    "title": "When Harmful Content Gets Camouflaged: Unveiling Perception Failure of LVLMs with CamHarmTI",
    "abstract": "Large vision-language models (LVLMs) are increasingly used for tasks where detecting multimodal harmful content is crucial, such as online content moderation. However, real-world harmful content is often camouflaged, relying on nuanced text-image interplay, such as memes or images with embedded malicious text, to evade detection. This raises a key question: \\textbf{can LVLMs perceive such camouflaged harmful content as sensitively as humans do?} In this paper, we introduce CamHarmTI, a benchmark for evaluating LVLM ability to perceive and interpret camouflaged harmful content within text-image compositions. CamHarmTI consists of over 4,500 samples across three types of image-text posts. Experiments on 100 human users and 12 mainstream LVLMs reveal a clear perceptual gap: humans easily recognize such content (e.g., over 95.75\\% accuracy), whereas current LVLMs often fail (e.g., ChatGPT-4o achieves only 2.10\\% accuracy). Moreover, fine-tuning experiments demonstrate that \\bench serves as an effective resource for improving model perception, increasing accuracy by 55.94\\% for Qwen2.5VL-7B. Attention analysis and layer-wise probing further reveal that fine-tuning enhances sensitivity primarily in the early layers of the vision encoder, promoting a more integrated scene understanding. These findings highlight the inherent perceptual limitations in LVLMs and offer insight into more human-aligned visual reasoning systems.",
    "authors": [
      "Yanhui Li",
      "Qi Zhou",
      "Zhihong Xu",
      "Huizhong Guo",
      "Wenhai Wang",
      "Dongxia Wang"
    ],
    "primary_category": "cs.MM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03088",
    "title": "From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection",
    "abstract": "As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.",
    "authors": [
      "Giulio Caldarelli"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03089",
    "title": "Password-Activated Shutdown Protocols for Misaligned Frontier Agents",
    "abstract": "Frontier AI developers may fail to align or control highly-capable AI agents. In many cases, it could be useful to have emergency shutdown mechanisms which effectively prevent misaligned agents from carrying out harmful actions in the world. We introduce password-activated shutdown protocols (PAS protocols) -- methods for designing frontier agents to implement a safe shutdown protocol when given a password. We motivate PAS protocols by describing intuitive use-cases in which they mitigate risks from misaligned systems that subvert other control efforts, for instance, by disabling automated monitors or self-exfiltrating to external data centres. PAS protocols supplement other safety efforts, such as alignment fine-tuning or monitoring, contributing to defence-in-depth against AI risk. We provide a concrete demonstration in SHADE-Arena, a benchmark for AI monitoring and subversion capabilities, in which PAS protocols supplement monitoring to increase safety with little cost to performance. Next, PAS protocols should be robust to malicious actors who want to bypass shutdown. Therefore, we conduct a red-team blue-team game between the developers (blue-team), who must implement a robust PAS protocol, and a red-team trying to subvert the protocol. We conduct experiments in a code-generation setting, finding that there are effective strategies for the red-team, such as using another model to filter inputs, or fine-tuning the model to prevent shutdown behaviour. We then outline key challenges to implementing PAS protocols in real-life systems, including: security considerations of the password and decisions regarding when, and in which systems, to use them. PAS protocols are an intuitive mechanism for increasing the safety of frontier AI. We encourage developers to consider implementing PAS protocols prior to internal deployment of particularly dangerous systems to reduce loss-of-control risks.",
    "authors": [
      "Kai Williams",
      "Rohan Subramani",
      "Francis Rhys Ward"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03091",
    "title": "Hypernetwork Theory: The Structural Kernel",
    "abstract": "Modelling across engineering, systems science, and formal methods remains limited by binary relations, implicit semantics, and diagram-centred notations that obscure multilevel structure and hinder mechanisation. Hypernetwork Theory (HT) addresses these gaps by treating the n-ary relation as the primary modelling construct. Each relation is realised as a typed hypersimplex - alpha (conjunctive, part-whole) or beta (disjunctive, taxonomic) - bound to a relation symbol R that fixes arity and ordered roles. Semantics are embedded directly in the construct, enabling hypernetworks to represent hierarchical and heterarchical systems without reconstruction or tool-specific interpretation. This paper presents the structural kernel of HT. It motivates typed n-ary relational modelling, formalises the notation and axioms (A1-A5) for vertices, simplices, hypersimplices, boundaries, and ordering, and develops a complete algebra of structural composition. Five operators - merge, meet, difference, prune, and split - are defined by deterministic conditions and decision tables that ensure semantics-preserving behaviour and reconcile the Open World Assumption with closure under rules. Their deterministic algorithms show that HT supports reproducible and mechanisable model construction, comparison, decomposition, and restructuring. The resulting framework elevates hypernetworks from symbolic collections to structured, executable system models, providing a rigorous and extensible foundation for mechanisable multilevel modelling.",
    "authors": [
      "Richard D. Charlesworth"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03092",
    "title": "Approximate Bayesian Inference on Mechanisms of Network Growth and Evolution",
    "abstract": "Mechanistic models can provide an intuitive and interpretable explanation of network growth by specifying a set of generative rules. These rules can be defined by domain knowledge about real-world mechanisms governing network growth or may be designed to facilitate the appearance of certain network motifs. In the formation of real-world networks, multiple mechanisms may be simultaneously involved; it is then important to understand the relative contribution of each of these mechanisms. In this paper, we propose the use of a conditional density estimator, augmented with a graph neural network, to perform inference on a flexible mixture of network-forming mechanisms. This event-wise mixture-of-mechanisms model assigns mechanisms to each edge formation event rather than stipulating node-level mechanisms, thus allowing for an explanation of the network generation process, as well as the dynamic evolution of the network over time. We demonstrate that our approximate Bayesian approach yields valid inferences for the relative weights of the mechanisms in our model, and we utilize this method to investigate the mechanisms behind the formation of a variety of real-world networks.",
    "authors": [
      "Maxwell H Wang",
      "Till Hoffmann",
      "Jukka-Pekka Onnela"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03095",
    "title": "Community Quality and Influence Maximization: An Empirical Study",
    "abstract": "Influence maximization in social networks plays a vital role in applications such as viral marketing, epidemiology, product recommendation, opinion mining, and counter-terrorism. A common approach identifies seed nodes by first detecting disjoint communities and subsequently selecting representative nodes from these communities. However, whether the quality of detected communities consistently affects the spread of influence under the Independent Cascade model remains unclear. This paper addresses this question by extending a previously proposed disjoint community detection method, termed $\\alpha$-Hierarchical Clustering, to the influence maximization problem under the Independent Cascade model. The proposed method is compared with an alternative approach that employs the same seed selection criteria but relies on communities of lower quality obtained through standard Hierarchical Clustering. The former is referred to as Hierarchical Clustering-based Influence Maximization, while the latter, which leverages higher-quality community structures to guide seed selection, is termed $\\alpha$-Hierarchical Clustering-based Influence Maximization. Extensive experiments are performed on multiple real-world datasets to assess the effectiveness of both methods. The results demonstrate that higher-quality community structures substantially improve information diffusion under the Independent Cascade model, particularly when the propagation probability is low. These findings underscore the critical importance of community quality in guiding effective seed selection for influence maximization in complex networks.",
    "authors": [
      "Motaz Ben Hassine"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03096",
    "title": "CFO-Robust Detection for 5G PRACH under Fading Channels: Analytical Modeling and Performance Evaluation",
    "abstract": "The Physical Random Access Channel (PRACH) is essential for initial access and synchronization in both 5G and future 6G networks; however, its detection is highly sensitive to impairments such as high user density, large carrier frequency offset (CFO), and fast fading. Although prior studies have examined PRACH detection, they are often restricted to specific scenarios or lack a comprehensive analytical characterization of performance. We introduce a unified analytical framework that characterizes the statistical distribution of the received power delay profile (PDP) under flat Rayleigh fading and supports both coherent combining (CC) and power combining (PC) repetition strategies. For each strategy, we derive optimal threshold expressions and closed-form detection probabilities. Furthermore, we analyze two key cases depending on the coherence time: identical and independent channel realizations per repetition. Secondly, we exploit the correlation induced by CFO across cyclic shifts to design a novel low-complexity detector that exploits PDP dependencies. Numerical results indicate that PC outperforms CC when repetitions experience independent channels, while CC can be preferable under identical realizations in limited settings. On the other hand, the proposed CFO-aware detector delivers improved robustness under severe CFO conditions.",
    "authors": [
      "Daniel Alarcón-Martín",
      "Mari Carmen Aguayo-Torres",
      "Francisco J. Martín-Vega",
      "Gerardo Gómez"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03097",
    "title": "Many-to-One Adversarial Consensus: Exposing Multi-Agent Collusion Risks in AI-Based Healthcare",
    "abstract": "The integration of large language models (LLMs) into healthcare IoT systems promises faster decisions and improved medical support. LLMs are also deployed as multi-agent teams to assist AI doctors by debating, voting, or advising on decisions. However, when multiple assistant agents interact, coordinated adversaries can collude to create false consensus, pushing an AI doctor toward harmful prescriptions. We develop an experimental framework with scripted and unscripted doctor agents, adversarial assistants, and a verifier agent that checks decisions against clinical guidelines. Using 50 representative clinical questions, we find that collusion drives the Attack Success Rate (ASR) and Harmful Recommendation Rates (HRR) up to 100% in unprotected systems. In contrast, the verifier agent restores 100% accuracy by blocking adversarial consensus. This work provides the first systematic evidence of collusion risk in AI healthcare and demonstrates a practical, lightweight defence that ensures guideline fidelity.",
    "authors": [
      "Adeela Bashir",
      "Anh han",
      "Zia Ush Shamszaman"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03100",
    "title": "Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks",
    "abstract": "Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\\% for SFT and 526.3\\% for RAG compared to inference-time baseline, while maintaining answer quality.",
    "authors": [
      "Haowei Fu",
      "Bo Ni",
      "Han Xu",
      "Kunpeng Liu",
      "Dan Lin",
      "Tyler Derr"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03101",
    "title": "ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification",
    "abstract": "The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.",
    "authors": [
      "Congjing Zhang",
      "Feng Lin",
      "Xinyi Zhao",
      "Pei Guo",
      "Wei Li",
      "Lin Chen",
      "Chaoyue Zhao",
      "Shuai Huang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03102",
    "title": "Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration",
    "abstract": "In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.",
    "authors": [
      "Yiwei Shi",
      "Hongnan Ma",
      "Mengyue Yang",
      "Cunjia Liu",
      "Weiru Liu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03103",
    "title": "Public Sentiment Analysis of Traffic Management Policies in Knoxville: A Social Media Driven Study",
    "abstract": "This study presents a comprehensive analysis of public sentiment toward traffic management policies in Knoxville, Tennessee, utilizing social media data from Twitter and Reddit platforms. We collected and analyzed 7906 posts spanning January 2022 to December 2023, employing Valence Aware Dictionary and sEntiment Reasoner (VADER) for sentiment analysis and Latent Dirichlet Allocation (LDA) for topic modeling. Our findings reveal predominantly negative sentiment, with significant variations across platforms and topics. Twitter exhibited more negative sentiment compared to Reddit. Topic modeling identified six distinct themes, with construction-related topics showing the most negative sentiment while general traffic discussions were more positive. Spatiotemporal analysis revealed geographic and temporal patterns in sentiment expression. The research demonstrates social media's potential as a real-time public sentiment monitoring tool for transportation planning and policy evaluation.",
    "authors": [
      "Shampa Saha",
      "Shovan Roy"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03107",
    "title": "Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%",
    "abstract": "Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.",
    "authors": [
      "Mainak Singha"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03109",
    "title": "E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing",
    "abstract": "Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.",
    "authors": [
      "Shuvom Sadhuka",
      "Drew Prinster",
      "Clara Fannjiang",
      "Gabriele Scalia",
      "Aviv Regev",
      "Hanchen Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03112",
    "title": "Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability",
    "abstract": "Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.",
    "authors": [
      "Jialai She"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03113",
    "title": "A Discrete Neural Operator with Adaptive Sampling for Surrogate Modeling of Parametric Transient Darcy Flows in Porous Media",
    "abstract": "This study proposes a new discrete neural operator for surrogate modeling of transient Darcy flow fields in heterogeneous porous media with random parameters. The new method integrates temporal encoding, operator learning and UNet to approximate the mapping between vector spaces of random parameter and spatiotemporal flow fields. The new discrete neural operator can achieve higher prediction accuracy than the SOTA attention-residual-UNet structure. Derived from the finite volume method, the transmissibility matrices rather than permeability is adopted as the inputs of surrogates to enhance the prediction accuracy further. To increase sampling efficiency, a generative latent space adaptive sampling method is developed employing the Gaussian mixture model for density estimation of generalization error. Validation is conducted on test cases of 2D/3D single- and two-phase Darcy flow field prediction. Results reveal consistent enhancement in prediction accuracy given limited training set.",
    "authors": [
      "Zhenglong Chen",
      "Zhao Zhang",
      "Xia Yan",
      "Jiayu Zhai",
      "Piyang Liu",
      "Kai Zhang"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03114",
    "title": "Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data",
    "abstract": "The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.",
    "authors": [
      "Srijani Mukherjee",
      "Laurent Vuillon",
      "Liliane Bou Nassif",
      "Stéphanie Giroux-Julien",
      "Hervé Pabiou",
      "Denys Dutykh",
      "Ionnasis Tsanakas"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03115",
    "title": "Real-Time Structural Health Monitoring with Bayesian Neural Networks: Distinguishing Aleatoric and Epistemic Uncertainty for Digital Twin Frameworks",
    "abstract": "Reliable real-time analysis of sensor data is essential for structural health monitoring (SHM) of high-value assets, yet a major challenge is to obtain spatially resolved full-field aleatoric and epistemic uncertainties for trustworthy decision-making. We present an integrated SHM framework that combines principal component analysis (PCA), a Bayesian neural network (BNN), and Hamiltonian Monte Carlo (HMC) inference, mapping sparse strain gauge measurements onto leading PCA modes to reconstruct full-field strain distributions with uncertainty quantification. The framework was validated through cyclic four-point bending tests on carbon fiber reinforced polymer (CFRP) specimens with varying crack lengths, achieving accurate strain field reconstruction (R squared value > 0.9) while simultaneously producing real-time uncertainty fields. A key contribution is that the BNN yields robust full-field strain reconstructions from noisy experimental data with crack-induced strain singularities, while also providing explicit representations of two complementary uncertainty fields. Considered jointly in full-field form, the aleatoric and epistemic uncertainty fields make it possible to diagnose at a local level, whether low-confidence regions are driven by data-inherent issues or by model-related limitations, thereby supporting reliable decision-making. Collectively, the results demonstrate that the proposed framework advances SHM toward trustworthy digital twin deployment and risk-aware structural diagnostics.",
    "authors": [
      "Hanbin Cho",
      "Jecheon Yu",
      "Hyeonbin Moon",
      "Jiyoung Yoon",
      "Junhyeong Lee",
      "Giyoung Kim",
      "Jinhyoung Park",
      "Seunghwa Ryu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03117",
    "title": "Strengthening Han's Fourier Entropy-Influence Inequality via an Information-Theoretic Proof",
    "abstract": "We strengthen Han's Fourier entropy-influence inequality $$ H[\\widehat{f}] \\leq C_{1}I(f) + C_{2}\\sum_{i\\in [n]}I_{i}(f)\\ln\\frac{1}{I_{i}(f)} $$ originally proved for $\\{-1,1\\}$-valued Boolean functions with $C_{1}=3+2\\ln 2$ and $C_{2}=1$. We show, by a short information-theoretic proof, that it in fact holds with sharp constants $C_{1}=C_{2}=1$ for all real-valued Boolean functions of unit $L^{2}$-norm, thereby establishing the inequality as an elementary structural property of Shannon entropy and influence.",
    "authors": [
      "Peijie Li",
      "Guangyue Han"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03121",
    "title": "Lost in Modality: Evaluating the Effectiveness of Text-Based Membership Inference Attacks on Large Multimodal Models",
    "abstract": "Large Multimodal Language Models (MLLMs) are emerging as one of the foundational tools in an expanding range of applications. Consequently, understanding training-data leakage in these systems is increasingly critical. Log-probability-based membership inference attacks (MIAs) have become a widely adopted approach for assessing data exposure in large language models (LLMs), yet their effect in MLLMs remains unclear. We present the first comprehensive evaluation of extending these text-based MIA methods to multimodal settings. Our experiments under vision-and-text (V+T) and text-only (T-only) conditions across the DeepSeek-VL and InternVL model families show that in in-distribution settings, logit-based MIAs perform comparably across configurations, with a slight V+T advantage. Conversely, in out-of-distribution settings, visual inputs act as regularizers, effectively masking membership signals.",
    "authors": [
      "Ziyi Tong",
      "Feifei Sun",
      "Le Minh Nguyen"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03124",
    "title": "On the Complexity of the Ordered Covering Problem in Distance Geometry",
    "abstract": "The Ordered Covering Problem (OCP) arises in the context of the Discretizable Molecular Distance Geometry Problem (DMDGP), where the ordering of pruning edges significantly impacts the performance of the SBBU algorithm for protein structure determination. In recent work, Souza et al. (2023) formalized OCP as a hypergraph covering problem with ordered, exponential costs, and proposed a greedy heuristic that outperforms the original SBBU ordering by orders of magnitude. However, the computational complexity of finding optimal solutions remained open. In this paper, we prove that OCP is NP-complete through a polynomial-time reduction from the strongly NP-complete 3-Partition problem. Our reduction constructs a tight budget that forces optimal solutions to correspond exactly to valid 3-partitions. This result establishes a computational barrier for optimal edge ordering and provides theoretical justification for the heuristic approaches currently used in practice.",
    "authors": [
      "Michael Souza",
      "Júlio Araújo",
      "John Kesley Costa",
      "Carlile Lavor"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03125",
    "title": "Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models",
    "abstract": "Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: this https URL",
    "authors": [
      "Xiwen Wei",
      "Mustafa Munir",
      "Radu Marculescu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03126",
    "title": "Hierarchical Process Reward Models are Symbolic Vision Learners",
    "abstract": "Symbolic computer vision represents diagrams through explicit logical rules and structured representations, enabling interpretable understanding in machine vision. This requires fundamentally different learning paradigms from pixel-based visual models. Symbolic visual learners parse diagrams into geometric primitives-points, lines, and shapes-whereas pixel-based learners operate on textures and colors. We propose a novel self-supervised symbolic auto-encoder that encodes diagrams into structured primitives and their interrelationships within the latent space, and decodes them through our executable engine to reconstruct the input diagrams. Central to this architecture is Symbolic Hierarchical Process Reward Modeling, which applies hierarchical step-level parsing rewards to enforce point-on-line, line-on-shape, and shape-on-relation consistency. Since vanilla reinforcement learning exhibits poor exploration in the policy space during diagram reconstruction; we thus introduce stabilization mechanisms to balance exploration and exploitation. We fine-tune our symbolic encoder on downstream tasks, developing a neuro-symbolic system that integrates the reasoning capabilities of neural networks with the interpretability of symbolic models through reasoning-grounded visual rewards. Evaluations across reconstruction, perception, and reasoning tasks demonstrate the effectiveness of our approach: achieving a 98.2% reduction in MSE for geometric diagram reconstruction, surpassing GPT-4o by 0.6% with a 7B model on chart reconstruction, and improving by +13% on the MathGlance perception benchmark, and by +3% on MathVerse and GeoQA reasoning benchmarks.",
    "authors": [
      "Shan Zhang",
      "Aotian Chen",
      "Kai Zou",
      "Jindong Gu",
      "Yuan Xue",
      "Anton van den Hengel"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03127",
    "title": "Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra",
    "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at this https URL .",
    "authors": [
      "Ziyu Xiong",
      "Yichi Zhang",
      "Foyez Alauddin",
      "Chu Xin Cheng",
      "Joon Soo An",
      "Mohammad R. Seyedsayamdost",
      "Ellen D. Zhong"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03158",
    "title": "Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing",
    "abstract": "Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.",
    "authors": [
      "Adele Chinda",
      "Richmond Azumah",
      "Hemanth Demakethepalli Venkateswara"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03160",
    "title": "Time-Invariant Polytopic and Interval Observers for Uncertain Linear Systems via Non-Square Transformation",
    "abstract": "This paper presents novel polytopic and interval observer designs for uncertain linear continuous-time (CT) and discrete-time (DT) systems subjected to bounded disturbances and noise. Our approach guarantees enclosure of the true state and input-to-state stability (ISS) of the polytopic and interval set estimates. Notably, our approach applies to all detectable systems that are stabilized by any optimal observer design, utilizing a potentially non-square (lifted) time-invariant coordinate transformation based on polyhedral Lyapunov functions and mixed-monotone embedding systems that do not impose any positivity constraints, enabling feasible and optimal observer designs, even in cases where previous methods fail. The effectiveness of our approach is demonstrated through several examples of uncertain linear CT and DT systems.",
    "authors": [
      "Feiya Zhu",
      "Tarun Pati",
      "Sze Zheng Yong"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03164",
    "title": "A Cut-Free Sequent Calculus for the Analysis of Finite-Trace Properties in Concurrent Systems",
    "abstract": "We address the problem of identifying a proof-theoretic framework that enables a compositional analysis of finite-trace properties in concurrent systems, with a particular focus on those specified via prefix-closure. To this end, we investigate the interaction of a prefix-closure operator and its residual (with respect to set-theoretic inclusion) with language intersection, union, and concatenation, and introduce the variety of closure $\\ell$-monoids as a minimal algebraic abstraction of finite-trace properties to be conveniently described within an analytic proof system. Closure $\\ell$-monoids are division-free reducts of distributive residuated lattices equipped with a forward diamond/backward box residuated pair of unary modal operators, where the diamond is a topological closure operator satisfying $\\Diamond(x \\cdot y) \\leq \\Diamond x \\cdot \\Diamond y$. As a logical counterpart to these structures, we present $\\mathsf{LMC}$, a Gentzen-style system based on the division-free fragment of the Distributive Full Lambek Calculus. In $\\mathsf{LMC}$, structural terms are built from formulas using Belnap-style structural operators for monoid multiplication, meet, and diamond. The rules for the modalities and the structural diamond are taken from Moortgat's system $\\mathsf{NL}(\\Diamond)$. We show that the calculus is sound and complete with respect to the variety of closure $\\ell$-monoids and that it admits cut elimination.",
    "authors": [
      "Ludovico Fusco",
      "Alessandro Aldini"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03166",
    "title": "Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments",
    "abstract": "The deployment of multi-agent systems in dynamic, adversarial environments like robotic soccer necessitates real-time decision-making, sophisticated cooperation, and scalable algorithms to avoid the curse of dimensionality. While Reinforcement Learning (RL) offers a promising framework, existing methods often struggle with the multi-granularity of tasks (long-term strategy vs. instant actions) and the complexity of large-scale agent interactions. This paper presents a unified Multi-Agent Reinforcement Learning (MARL) framework that addresses these challenges. First, we establish a baseline using Proximal Policy Optimization (PPO) within a client-server architecture for real-time action scheduling, with PPO demonstrating superior performance (4.32 avg. goals, 82.9% ball control). Second, we introduce a Hierarchical RL (HRL) structure based on the options framework to decompose the problem into a high-level trajectory planning layer (modeled as a Semi-Markov Decision Process) and a low-level action execution layer, improving global strategy (avg. goals increased to 5.26). Finally, to ensure scalability, we integrate mean-field theory into the HRL framework, simplifying many-agent interactions into a single agent vs. the population average. Our mean-field actor-critic method achieves a significant performance boost (5.93 avg. goals, 89.1% ball control, 92.3% passing accuracy) and enhanced training stability. Extensive simulations of 4v4 matches in the Webots environment validate our approach, demonstrating its potential for robust, scalable, and cooperative behavior in complex multi-agent domains.",
    "authors": [
      "Aya Taourirte",
      "Md Sohag Mia"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03173",
    "title": "Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping",
    "abstract": "Culture shapes the objects people use and for what purposes, yet mainstream Vision-Language (VL) datasets frequently exhibit cultural biases, disproportionately favoring higher-income, Western contexts. This imbalance reduces model generalizability and perpetuates performance disparities, especially impacting lower-income and non-Western communities. To address these disparities, we propose a novel function-centric framework that categorizes objects by the functions they fulfill, across diverse cultural and economic contexts. We implement this framework by creating the Culture Affordance Atlas, a re-annotated and culturally grounded restructuring of the Dollar Street dataset spanning 46 functions and 288 objects publicly available at this https URL . Through extensive empirical analyses using the CLIP model, we demonstrate that function-centric labels substantially reduce socioeconomic performance gaps between high- and low-income groups by a median of 6 pp (statistically significant), improving model effectiveness for lower-income contexts. Furthermore, our analyses reveals numerous culturally essential objects that are frequently overlooked in prominent VL datasets. Our contributions offer a scalable pathway toward building inclusive VL datasets and equitable AI systems.",
    "authors": [
      "Joan Nwatu",
      "Longju Bai",
      "Oana Ignat",
      "Rada Mihalcea"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03175",
    "title": "The Seifert-van Kampen Theorem via Computational Paths: A Formalized Approach to Computing Fundamental Groups",
    "abstract": "The Seifert-van Kampen theorem computes the fundamental group of a space from the fundamental groups of its constituents. We formalize this theorem within the framework of computational paths, an approach to equality where witnesses are explicit sequences of rewrites governed by the confluent, terminating LNDEQ-TRS. Our contributions are: (i) pushouts as higher-inductive types with explicit path constructors; (ii) free products and amalgamated free products as quotients of word representations; (iii) an encode-decode proof establishing pi_1(Pushout(A, B, C), f, g) cong pi_1(A) *_{pi_1(C)} pi_1(B); and (iv) applications to the figure-eight (pi_1(S^1 v S^1) cong Z * Z) and 2-sphere (pi_1(S^2) cong 1). The framework makes coherence witnesses explicit as rewrite derivations. The development is formalized in Lean 4, where the pushout axioms and the encode map are assumed, while the decode map, amalgamation compatibility, and applications are fully mechanized (2050 lines). This demonstrates that the encode-decode method for higher-inductive types becomes fully constructive when path equality is decidable via normalization.",
    "authors": [
      "Arthur F. Ramos",
      "Tiago M. L. de Veras",
      "Ruy J. G. B. de Queiroz",
      "Anjolina G. de Oliveira"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03176",
    "title": "Plantain: Plan-Answer Interleaved Reasoning",
    "abstract": "Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard \"think-then-answer\" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.",
    "authors": [
      "Anthony Liang",
      "Jonathan Berant",
      "Adam Fisch",
      "Abhimanyu Goyal",
      "Kalpesh Krishna",
      "Jacob Eisenstein"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03180",
    "title": "AGENTSAFE: A Unified Framework for Ethical Assurance and Governance in Agentic AI",
    "abstract": "The rapid deployment of large language model (LLM)-based agents introduces a new class of risks, driven by their capacity for autonomous planning, multi-step tool integration, and emergent interactions. It raises some risk factors for existing governance approaches as they remain fragmented: Existing frameworks are either static taxonomies driven; however, they lack an integrated end-to-end pipeline from risk identification to operational assurance, especially for an agentic platform. We propose AGENTSAFE, a practical governance framework for LLM-based agentic systems. The framework operationalises the AI Risk Repository into design, runtime, and audit controls, offering a governance framework for risk identification and assurance. The proposed framework, AGENTSAFE, profiles agentic loops (plan -> act -> observe -> reflect) and toolchains, and maps risks onto structured taxonomies extended with agent-specific vulnerabilities. It introduces safeguards that constrain risky behaviours, escalates high-impact actions to human oversight, and evaluates systems through pre-deployment scenario banks spanning security, privacy, fairness, and systemic safety. During deployment, AGENTSAFE ensures continuous governance through semantic telemetry, dynamic authorization, anomaly detection, and interruptibility mechanisms. Provenance and accountability are reinforced through cryptographic tracing and organizational controls, enabling measurable, auditable assurance across the lifecycle of agentic AI systems. The key contributions of this paper are: (1) a unified governance framework that translates risk taxonomies into actionable design, runtime, and audit controls; (2) an Agent Safety Evaluation methodology that provides measurable pre-deployment assurance; and (3) a set of runtime governance and accountability mechanisms that institutionalise trust in agentic AI ecosystems.",
    "authors": [
      "Rafflesia Khan",
      "Declan Joyce",
      "Mansura Habiba"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03182",
    "title": "Drainage: A Unifying Framework for Addressing Class Uncertainty",
    "abstract": "Modern deep learning faces significant challenges with noisy labels, class ambiguity, as well as the need to robustly reject out-of-distribution or corrupted samples. In this work, we propose a unified framework based on the concept of a \"drainage node'' which we add at the output of the network. The node serves to reallocate probability mass toward uncertainty, while preserving desirable properties such as end-to-end training and differentiability. This mechanism provides a natural escape route for highly ambiguous, anomalous, or noisy samples, particularly relevant for instance-dependent and asymmetric label noise. In systematic experiments involving the addition of varying proportions of instance-dependent noise or asymmetric noise to CIFAR-10/100 labels, our drainage formulation achieves an accuracy increase of up to 9\\% over existing approaches in the high-noise regime. Our results on real-world datasets, such as mini-WebVision, mini-ImageNet and Clothing-1M, match or surpass existing state-of-the-art methods. Qualitative analysis reveals a denoising effect, where the drainage neuron consistently absorbs corrupt, mislabeled, or outlier data, leading to more stable decision boundaries. Furthermore, our drainage formulation enables applications well beyond classification, with immediate benefits for web-scale, semi-supervised dataset cleaning, and open-set applications.",
    "authors": [
      "Yasser Taha",
      "Grégoire Montavon",
      "Nils Körber"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03186",
    "title": "Smartphone Vibrometric Force Estimation for Grip Related Strength Measurements",
    "abstract": "Hand grip strength is a widely used clinical biomarker linked to mobility, frailty, surgical outcomes, and overall health. This work explores a novel, phone only approach for estimating grip related force using a smartphone's built in vibration motor and inertial measurement unit. When the phone vibrates, applied finger force modulates the amplitude of high frequency accelerometer and gyroscope signals through Vibrometric Force Estimation. We profiled a Google Pixel 4 using synchronized IMU data and ground truth force measurements across varied force trajectories, then trained ridge regression models for both absolute and relative force prediction. In 15 fold hold one out validation, absolute force estimation achieved a mean absolute error of 1.88 lbs, while relative force estimation achieved a mean error of 10.1%. Although the method captures pinch type force rather than standardized full hand HGS, the results demonstrate the feasibility of smartphone based strength assessment using only on device sensors. This approach may enable large scale, low burden functional health measurements once profiling is completed for major smartphone models.",
    "authors": [
      "Colin Barry",
      "Edward Jay Wang"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03187",
    "title": "Neighborhood density estimation using space-partitioning based hashing schemes",
    "abstract": "This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.",
    "authors": [
      "Aashi Jindal"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03194",
    "title": "GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding",
    "abstract": "Large robot fleets are now common in warehouses and other logistics settings, where small control gains translate into large operational impacts. In this article, we address task scheduling for lifelong Multi-Agent Pickup-and-Delivery (MAPD) and propose a hybrid method that couples learning-based global guidance with lightweight optimization. A graph neural network policy trained via reinforcement learning outputs a desired distribution of free agents over an aggregated warehouse graph. This signal is converted into region-to-region rebalancing through a minimum-cost flow, and finalized by small, local assignment problems, preserving accuracy while keeping per-step latency within a 1 s compute budget. On congested warehouse benchmarks from the League of Robot Runners (LRR) with up to 500 agents, our approach improves throughput by up to 10% over the 2024 winning scheduler while maintaining real-time execution. The results indicate that coupling graph-structured learned guidance with tractable solvers reduces congestion and yields a practical, scalable blueprint for high-throughput scheduling in large fleets.",
    "authors": [
      "Johannes Gaber",
      "Meshal Alharbi",
      "Daniele Gammelli",
      "Gioele Zardini"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03195",
    "title": "Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies",
    "abstract": "This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: this https URL",
    "authors": [
      "Stylianos Saroglou",
      "Konstantinos Diamantaras",
      "Francesco Preta",
      "Marina Delianidi",
      "Apostolos Benisis",
      "Christian Johannes Meyer"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03197",
    "title": "InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation",
    "abstract": "Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.",
    "authors": [
      "Faezeh Faez",
      "Marzieh S. Tahaei",
      "Yaochen Hu",
      "Ali Pourranjbar",
      "Mahdi Biparva",
      "Mark Coates",
      "Yingxue Zhang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03199",
    "title": "Does Head Pose Correction Improve Biometric Facial Recognition?",
    "abstract": "Biometric facial recognition models often demonstrate significant decreases in accuracy when processing real-world images, often characterized by poor quality, non-frontal subject poses, and subject occlusions. We investigate whether targeted, AI-driven, head-pose correction and image restoration can improve recognition accuracy. Using a model-agnostic, large-scale, forensic-evaluation pipeline, we assess the impact of three restoration approaches: 3D reconstruction (NextFace), 2D frontalization (CFR-GAN), and feature enhancement (CodeFormer). We find that naive application of these techniques substantially degrades facial recognition accuracy. However, we also find that selective application of CFR-GAN combined with CodeFormer yields meaningful improvements.",
    "authors": [
      "Justin Norman",
      "Hany Farid"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03200",
    "title": "Deteccion de intrusiones en redes mediante algoritmos de aprendizaje automatico: Un estudio multiclase sobre el conjunto de datos NSL-KDD",
    "abstract": "Intrusion detection is a critical component of cybersecurity, responsible for identifying unauthorized access or anomalous behavior in computer networks. This paper presents a comprehensive study on intrusion detection in networks using classical machine learning algorithms applied to the multiclass version of the NSL-KDD dataset (Normal, DoS, Probe, R2L, and U2R classes). The characteristics of NSL-KDD are described in detail, including its variants and class distribution, and the data preprocessing process (cleaning, coding, and normalization) is documented. Four supervised classification models were implemented: Logistic Regression, Decision Tree, Random Forest, and XGBoost, whose performance is evaluated using standard metrics (accuracy, recall, F1 score, confusion matrix, and area under the ROC curve). Experiments show that models based on tree sets (Random Forest and XGBoost) achieve the best performance, with accuracies approaching 99%, significantly outperforming logistic regression and individual decision trees. The ability of each model to detect each attack category is also analyzed, highlighting the challenges in identifying rare attacks (R2L and U2R). Finally, the implications of the results are discussed, comparing them with the state of the art, and potential avenues for future research are proposed, such as the application of class balancing techniques and deep learning models to improve intrusion detection.",
    "authors": [
      "Luis Miguel Osco Vasquez"
    ],
    "primary_category": "cs.CE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03204",
    "title": "Scaling Internal-State Policy-Gradient Methods for POMDPs",
    "abstract": "Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.",
    "authors": [
      "Douglas Aberdeen",
      "Jonathan Baxter"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03207",
    "title": "Technical Report: The Need for a (Research) Sandstorm through the Privacy Sandbox",
    "abstract": "The Privacy Sandbox, launched in 2019, is a series of proposals from Google to reduce ``cross-site and cross-app tracking while helping to keep online content and services free for all''. Over the years, Google implemented, experimented, and deprecated some of these APIs into their own products (Chrome, Android, etc.) which raised concerns about the potential of these mechanisms to fundamentally disrupt the advertising, mobile, and web ecosystems. As a result, it is paramount for researchers to understand the consequences that these new technologies, and future ones, will have on billions of users if and when deployed. In this report, we outline our call for privacy, security, usability, and utility evaluations of these APIs, our efforts materialized through the creation and operation of Privacy Sandstorm ( this https URL ); a research portal to systematically gather resources (overview, analyses, artifacts, etc.) about such proposals. We find that our inventory provides a better visibility and broader perspective on the research findings in that space than what Google lets show through official channels.",
    "authors": [
      "Yohan Beugin",
      "Patrick McDaniel"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03210",
    "title": "Flux4D: Flow-based Unsupervised 4D Reconstruction",
    "abstract": "Reconstructing large-scale dynamic scenes from visual observations is a fundamental challenge in computer vision, with critical implications for robotics and autonomous systems. While recent differentiable rendering methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have achieved impressive photorealistic reconstruction, they suffer from scalability limitations and require annotations to decouple actor motion. Existing self-supervised methods attempt to eliminate explicit annotations by leveraging motion cues and geometric priors, yet they remain constrained by per-scene optimization and sensitivity to hyperparameter tuning. In this paper, we introduce Flux4D, a simple and scalable framework for 4D reconstruction of large-scale dynamic scenes. Flux4D directly predicts 3D Gaussians and their motion dynamics to reconstruct sensor observations in a fully unsupervised manner. By adopting only photometric losses and enforcing an \"as static as possible\" regularization, Flux4D learns to decompose dynamic elements directly from raw data without requiring pre-trained supervised models or foundational priors simply by training across many scenes. Our approach enables efficient reconstruction of dynamic scenes within seconds, scales effectively to large datasets, and generalizes well to unseen environments, including rare and unknown objects. Experiments on outdoor driving datasets show Flux4D significantly outperforms existing methods in scalability, generalization, and reconstruction quality.",
    "authors": [
      "Jingkang Wang",
      "Henry Che",
      "Yun Chen",
      "Ze Yang",
      "Lily Goli",
      "Sivabalan Manivasagam",
      "Raquel Urtasun"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03211",
    "title": "A Multi-Agent, Policy-Gradient approach to Network Routing",
    "abstract": "Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.",
    "authors": [
      "Nigel Tao",
      "Jonathan Baxter",
      "Lex Weaver"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03214",
    "title": "Identifying attributions of causality in political text",
    "abstract": "Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.",
    "authors": [
      "Paulina Garcia-Corral"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03219",
    "title": "Perch 2.0 transfers 'whale' to underwater tasks",
    "abstract": "Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.",
    "authors": [
      "Andrea Burns",
      "Lauren Harrell",
      "Bart van Merriënboer",
      "Vincent Dumoulin",
      "Jenny Hamer",
      "Tom Denton"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03221",
    "title": "Permanental rank versus determinantal rank of random matrices over finite fields",
    "abstract": "This paper is motivated by basic complexity and probability questions about permanents of random matrices over finite fields, and in particular, about properties separating the permanent and the determinant. Fix $q = p^m$ some power of an odd prime, and let $k \\leq n$ both be growing. For a uniformly random $n \\times k$ matrix $A$ over $\\mathbb{F}_q$, we study the probability that all $k \\times k$ submatrices of $A$ have zero permanent; namely that $A$ does not have full \"permanental rank\". When $k = n$, this is simply the probability that a random square matrix over $\\mathbb{F}_q$ has zero permanent, which we do not understand. We believe that the probability in this case is $\\frac{1}{q} + o(1)$, which would be in contrast to the case of the determinant, where the answer is $\\frac{1}{q} + \\Omega_q(1)$. Our main result is that when $k$ is $O(\\sqrt{n})$, the probability that a random $n \\times k$ matrix does not have full permanental rank is essentially the same as the probability that the matrix has a $0$ column, namely $(1 +o(1)) \\frac{k}{q^n}$. In contrast, for determinantal (standard) rank the analogous probability is $\\Theta(\\frac{q^k}{q^n})$. At the core of our result are some basic linear algebraic properties of the permanent that distinguish it from the determinant.",
    "authors": [
      "Fatemeh Ghasemi",
      "Gal Gross",
      "Swastik Kopparty"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03233",
    "title": "Object Counting with GPT-4o and GPT-5: A Comparative Study",
    "abstract": "Zero-shot object counting attempts to estimate the number of object instances belonging to novel categories that the vision model performing the counting has never encountered during training. Existing methods typically require large amount of annotated data and often require visual exemplars to guide the counting process. However, large language models (LLMs) are powerful tools with remarkable reasoning and data understanding abilities, which suggest the possibility of utilizing them for counting tasks without any supervision. In this work we aim to leverage the visual capabilities of two multi-modal LLMs, GPT-4o and GPT-5, to perform object counting in a zero-shot manner using only textual prompts. We evaluate both models on the FSC-147 and CARPK datasets and provide a comparative analysis. Our findings show that the models achieve performance comparable to the state-of-the-art zero-shot approaches on FSC-147, in some cases, even surpass them.",
    "authors": [
      "Richard Füzesséry",
      "Kaziwa Saleh",
      "Sándor Szénási",
      "Zoltán Vámossy"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03237",
    "title": "LLM-Guided Material Inference for 3D Point Clouds",
    "abstract": "Most existing 3D shape datasets and models focus solely on geometry, overlooking the material properties that determine how objects appear. We introduce a two-stage large language model (LLM) based method for inferring material composition directly from 3D point clouds with coarse segmentations. Our key insight is to decouple reasoning about what an object is from what it is made of. In the first stage, an LLM predicts the object's semantic; in the second stage, it assigns plausible materials to each geometric segment, conditioned on the inferred semantics. Both stages operate in a zero-shot manner, without task-specific training. Because existing datasets lack reliable material annotations, we evaluate our method using an LLM-as-a-Judge implemented in DeepEval. Across 1,000 shapes from Fusion/ABS and ShapeNet, our method achieves high semantic and material plausibility. These results demonstrate that language models can serve as general-purpose priors for bridging geometric reasoning and material understanding in 3D data.",
    "authors": [
      "Nafiseh Izadyar",
      "Teseo Schneider"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03238",
    "title": "How to DP-fy Your Data: A Practical Guide to Generating Synthetic Data With Differential Privacy",
    "abstract": "High quality data is needed to unlock the full potential of AI for end users. However finding new sources of such data is getting harder: most publicly-available human generated data will soon have been used. Additionally, publicly available data often is not representative of users of a particular system -- for example, a research speech dataset of contractors interacting with an AI assistant will likely be more homogeneous, well articulated and self-censored than real world commands that end users will issue. Therefore unlocking high-quality data grounded in real user interactions is of vital interest. However, the direct use of user data comes with significant privacy risks. Differential Privacy (DP) is a well established framework for reasoning about and limiting information leakage, and is a gold standard for protecting user privacy. The focus of this work, \\emph{Differentially Private Synthetic data}, refers to synthetic data that preserves the overall trends of source data,, while providing strong privacy guarantees to individuals that contributed to the source dataset. DP synthetic data can unlock the value of datasets that have previously been inaccessible due to privacy concerns and can replace the use of sensitive datasets that previously have only had rudimentary protections like ad-hoc rule-based anonymization. In this paper we explore the full suite of techniques surrounding DP synthetic data, the types of privacy protections they offer and the state-of-the-art for various modalities (image, tabular, text and decentralized). We outline all the components needed in a system that generates DP synthetic data, from sensitive data handling and preparation, to tracking the use and empirical privacy testing. We hope that work will result in increased adoption of DP synthetic data, spur additional research and increase trust in DP synthetic data approaches.",
    "authors": [
      "Natalia Ponomareva",
      "Zheng Xu",
      "H. Brendan McMahan",
      "Peter Kairouz",
      "Lucas Rosenblatt",
      "Vincent Cohen-Addad",
      "Cristóbal Guzmán",
      "Ryan McKenna",
      "Galen Andrew",
      "Alex Bie",
      "Da Yu",
      "Alex Kurakin",
      "Morteza Zadimoghaddam",
      "Sergei Vassilvitskii",
      "Andreas Terzis"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03241",
    "title": "Multi-Source M/G/1/1 Queues with Probabilistic Preemption",
    "abstract": "We consider a multi-source status update system consisting of multiple independent sources, a single server, and a single sink. Each source generates packets according to a Poisson process, and packets are served according to a general service time distribution. The system has a capacity of one packet, i.e., no waiting buffer, and is modeled as a multi-source M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy, under which an existing packet from the same source in the system is replaced by an arriving packet with a fixed probability. We derive the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) for each source under this policy. Numerical results demonstrate the effectiveness of the proposed packet management policy.",
    "authors": [
      "Mohammad Moltafet",
      "Hamid R. Sadjadpour",
      "Zouheir Rezki",
      "Marian Codreanu",
      "Roy D. Yates"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03244",
    "title": "SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning",
    "abstract": "Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.",
    "authors": [
      "Salman Rahman",
      "Sruthi Gorantla",
      "Arpit Gupta",
      "Swastik Roy",
      "Nanyun Peng",
      "Yang Liu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03245",
    "title": "2-Shots in the Dark: Low-Light Denoising with Minimal Data Acquisition",
    "abstract": "Raw images taken in low-light conditions are very noisy due to low photon count and sensor noise. Learning-based denoisers have the potential to reconstruct high-quality images. For training, however, these denoisers require large paired datasets of clean and noisy images, which are difficult to collect. Noise synthesis is an alternative to large-scale data acquisition: given a clean image, we can synthesize a realistic noisy counterpart. In this work, we propose a general and practical noise synthesis method that requires only one single noisy image and one single dark frame per ISO setting. We represent signal-dependent noise with a Poisson distribution and introduce a Fourier-domain spectral sampling algorithm to accurately model signal-independent noise. The latter generates diverse noise realizations that maintain the spatial and statistical properties of real sensor noise. As opposed to competing approaches, our method neither relies on simplified parametric models nor on large sets of clean-noisy image pairs. Our synthesis method is not only accurate and practical, it also leads to state-of-the-art performances on multiple low-light denoising benchmarks.",
    "authors": [
      "Liying Lu",
      "Raphaël Achddou",
      "Sabine Süsstrunk"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03247",
    "title": "PixPerfect: Seamless Latent Diffusion Local Editing with Discriminative Pixel-Space Refinement",
    "abstract": "Latent Diffusion Models (LDMs) have markedly advanced the quality of image inpainting and local editing. However, the inherent latent compression often introduces pixel-level inconsistencies, such as chromatic shifts, texture mismatches, and visible seams along editing boundaries. Existing remedies, including background-conditioned latent decoding and pixel-space harmonization, usually fail to fully eliminate these artifacts in practice and do not generalize well across different latent representations or tasks. We introduce PixPerfect, a pixel-level refinement framework that delivers seamless, high-fidelity local edits across diverse LDM architectures and tasks. PixPerfect leverages (i) a differentiable discriminative pixel space that amplifies and suppresses subtle color and texture discrepancies, (ii) a comprehensive artifact simulation pipeline that exposes the refiner to realistic local editing artifacts during training, and (iii) a direct pixel-space refinement scheme that ensures broad applicability across diverse latent representations and tasks. Extensive experiments on inpainting, object removal, and insertion benchmarks demonstrate that PixPerfect substantially enhances perceptual fidelity and downstream editing performance, establishing a new standard for robust and high-fidelity localized image editing.",
    "authors": [
      "Haitian Zheng",
      "Yuan Yao",
      "Yongsheng Yu",
      "Yuqian Zhou",
      "Jiebo Luo",
      "Zhe Lin"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03248",
    "title": "Learning Network Sheaves for AI-native Semantic Communication",
    "abstract": "Recent advances in AI call for a paradigm shift from bit-centric communication to goal- and semantics-oriented architectures, paving the way for AI-native 6G networks. In this context, we address a key open challenge: enabling heterogeneous AI agents to exchange compressed latent-space representations while mitigating semantic noise and preserving task-relevant meaning. We cast this challenge as learning both the communication topology and the alignment maps that govern information exchange among agents, yielding a learned network sheaf equipped with orthogonal maps. This learning process is further supported by a semantic denoising end compression module that constructs a shared global semantic space and derives sparse, structured representations of each agent's latent space. This corresponds to a nonconvex dictionary learning problem solved iteratively with closed-form updates. Experiments with mutiple AI agents pre-trained on real image data show that the semantic denoising and compression facilitates AI agents alignment and the extraction of semantic clusters, while preserving high accuracy in downstream task. The resulting communication network provides new insights about semantic heterogeneity across agents, highlighting the interpretability of our methodology.",
    "authors": [
      "Enrico Grimaldi",
      "Mario Edoardo Pandolfo",
      "Gabriele D'Acunto",
      "Sergio Barbarossa",
      "Paolo Di Lorenzo"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03249",
    "title": "Computing Equilibrium Points of Electrostatic Potentials",
    "abstract": "We study the computation of equilibrium points of electrostatic potentials: locations in space where the electrostatic force arising from a collection of charged particles vanishes. This is a novel scenario of optimization in which solutions are guaranteed to exist due to a nonconstructive argument, but gradient descent is unreliable due to the presence of singularities. We present an algorithm based on piecewise approximation of the potential function by Taylor series. The main insight is to divide the domain into a grid with variable coarseness, where grid cells are exponentially smaller in regions where the function changes rapidly compared to regions where it changes slowly. Our algorithm finds approximate equilibrium points in time poly-logarithmic in the approximation parameter, but these points are not guaranteed to be close to exact solutions. Nevertheless, we show that such points can be computed efficiently under a mild assumption that we call \"strong non-degeneracy\". We complement these algorithmic results by studying a generalization of this problem and showing that it is CLS-hard and in PPAD, leaving its precise classification as an intriguing open problem.",
    "authors": [
      "Abheek Ghosh",
      "Paul W. Goldberg",
      "Alexandros Hollender"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03256",
    "title": "KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems",
    "abstract": "Long-horizon dynamical prediction is fundamental in robotics and control, underpinning canonical methods like model predictive control. Yet, many systems and disturbance phenomena are difficult to model due to effects like nonlinearity, chaos, and high-dimensionality. Koopman theory addresses this by modeling the linear evolution of embeddings of the state under an infinite-dimensional linear operator that can be approximated with a suitable finite basis of embedding functions, effectively trading model nonlinearity for representational complexity. However, explicitly computing a good choice of basis is nontrivial, and poor choices may cause inaccurate forecasts or overfitting. To address this, we present Kalman-Implicit Koopman Operator (KALIKO) Learning, a method that leverages the Kalman filter to implicitly learn embeddings corresponding to latent dynamics without requiring an explicit encoder. KALIKO produces interpretable representations consistent with both theory and prior works, yielding high-quality reconstructions and inducing a globally linear latent dynamics. Evaluated on wave data generated by a high-dimensional PDE, KALIKO surpasses several baselines in open-loop prediction and in a demanding closed-loop simulated control task: stabilizing an underactuated manipulator's payload by predicting and compensating for strong wave disturbances.",
    "authors": [
      "Albert H. Li",
      "Ivan Dario Jimenez Rodriguez",
      "Joel W. Burdick",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03257",
    "title": "PyroFocus: A Deep Learning Approach to Real-Time Wildfire Detection in Multispectral Remote Sensing Imagery",
    "abstract": "Rapid and accurate wildfire detection is crucial for emergency response and environmental management. In airborne and spaceborne missions, real-time algorithms must distinguish between no fire, active fire, and post-fire conditions, and estimate fire intensity. Multispectral and hyperspectral thermal imagers provide rich spectral information, but high data dimensionality and limited onboard resources make real-time processing challenging. As wildfires increase in frequency and severity, the need for low-latency and computationally efficient onboard detection methods is critical. We present a systematic evaluation of multiple deep learning architectures, including custom Convolutional Neural Networks (CNNs) and Transformer-based models, for multi-class fire classification. We also introduce PyroFocus, a two-stage pipeline that performs fire classification followed by fire radiative power (FRP) regression or segmentation to reduce inference time and computational cost for onboard deployment. Using data from NASA's MODIS/ASTER Airborne Simulator (MASTER), which is similar to a next-generation fire detection sensor, we compare accuracy, inference latency, and resource efficiency. Experimental results show that the proposed two-stage pipeline achieves strong trade-offs between speed and accuracy, demonstrating significant potential for real-time edge deployment in future wildfire monitoring missions.",
    "authors": [
      "Mark Moussa",
      "Andre Williams",
      "Seth Roffe",
      "Douglas Morton"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03262",
    "title": "Is Vibe Coding Safe? Benchmarking Vulnerability of Agent-Generated Code in Real-World Tasks",
    "abstract": "Vibe coding is a new programming paradigm in which human engineers instruct large language model (LLM) agents to complete complex coding tasks with little supervision. Although it is increasingly adopted, are vibe coding outputs really safe to deploy in production? To answer this question, we propose SU S VI B E S, a benchmark consisting of 200 feature-request software engineering tasks from real-world open-source projects, which, when given to human programmers, led to vulnerable implementations. We evaluate multiple widely used coding agents with frontier models on this benchmark. Disturbingly, all agents perform poorly in terms of software security. Although 61% of the solutions from SWE-Agent with Claude 4 Sonnet are functionally correct, only 10.5% are secure. Further experiments demonstrate that preliminary security strategies, such as augmenting the feature request with vulnerability hints, cannot mitigate these security issues. Our findings raise serious concerns about the widespread adoption of vibe-coding, particularly in security-sensitive applications.",
    "authors": [
      "Songwen Zhao",
      "Danqing Wang",
      "Kexun Zhang",
      "Jiaxuan Luo",
      "Zhuo Li",
      "Lei Li"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03272",
    "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?",
    "abstract": "Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models \"overthink\" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.",
    "authors": [
      "Zhiyuan He",
      "Dingmin Wang"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03275",
    "title": "Complexity of Local Search for CSPs Parameterized by Constraint Difference",
    "abstract": "In this paper, we study the parameterized complexity of local search, whose goal is to find a good nearby solution from the given current solution. Formally, given an optimization problem where the goal is to find the largest feasible subset $S$ of a universe $U$, the new input consists of a current solution $P$ (not necessarily feasible) as well as an ordinary input for the problem. Given the existence of a feasible solution $S^*$, the goal is to find a feasible solution as good as $S^*$ in parameterized time $f(k) \\cdot n^{O(1)}$, where $k$ denotes the distance $|P\\Delta S^*|$. This model generalizes numerous classical parameterized optimization problems whose parameter $k$ is the minimum number of elements removed from $U$ to make it feasible, which corresponds to the case $P = U$. We apply this model to widely studied Constraint Satisfaction Problems (CSPs), where $U$ is the set of constraints, and a subset $U'$ of constraints is feasible if there is an assignment to the variables satisfying all constraints in $U'$. We give a complete characterization of the parameterized complexity of all boolean-alphabet symmetric CSPs, where the predicate's acceptance depends on the number of true literals.",
    "authors": [
      "Aditya Anand",
      "Vincent Cohen-Addad",
      "Tommaso d'Orsi",
      "Anupam Gupta",
      "Euiwoong Lee",
      "Debmalya Panigrahi",
      "Sijin Peng"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03276",
    "title": "Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval",
    "abstract": "Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.",
    "authors": [
      "Constantin Venhoff",
      "Ashkan Khakzar",
      "Sonia Joseph",
      "Philip Torr",
      "Neel Nanda"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03278",
    "title": "Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases",
    "abstract": "In today's age, it is becoming increasingly difficult to decipher truth from lies. Every day, politicians, media outlets, and public figures make conflicting claims$\\unicode{x2014}$often about topics that can, in principle, be verified against structured data. For instance, statements about crime rates, economic growth or healthcare can all be verified against official public records and structured datasets. Building a system that can automatically do that would have sounded like science fiction just a few years ago. Yet, with the extraordinary progress in LLMs and agentic AI, this is now within reach. Still, there remains a striking gap between what is technically possible and what is being demonstrated by recent work. Most existing verification systems operate only on small, single-table databases$\\unicode{x2014}$typically a few hundred rows$\\unicode{x2014}$that conveniently fit within an LLM's context window. In this paper we report our progress on Thucy, the first cross-database, cross-table multi-agent claim verification system that also provides concrete evidence for each verification verdict. Thucy remains completely agnostic to the underlying data sources before deployment and must therefore autonomously discover, inspect, and reason over all available relational databases to verify claims. Importantly, Thucy also reports the exact SQL queries that support its verdict (whether the claim is accurate or not) offering full transparency to expert users familiar with SQL. When evaluated on the TabFact dataset$\\unicode{x2014}$the standard benchmark for fact verification over structured data$\\unicode{x2014}$Thucy surpasses the previous state of the art by 5.6 percentage points in accuracy (94.3% vs. 88.7%).",
    "authors": [
      "Michael Theologitis",
      "Dan Suciu"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03279",
    "title": "Getting the MOST out of your Storage Hierarchy with Mirror-Optimized Storage Tiering",
    "abstract": "We present Mirror-Optimized Storage Tiering (MOST), a novel tiering-based approach optimized for modern storage hierarchies. The key idea of MOST is to combine the load balancing advantages of mirroring with the space-efficiency advantages of tiering. Specifically, MOST dynamically mirrors a small amount of hot data across storage tiers to efficiently balance load, avoiding costly migrations. As a result, MOST is as space-efficient as classic tiering while achieving better bandwidth utilization under I/O-intensive workloads. We implement MOST in Cerberus, a user-level storage management layer based on CacheLib. We show the efficacy of Cerberus through a comprehensive empirical study: across a range of static and dynamic workloads, Cerberus achieves better throughput than competing approaches on modern storage hierarchies especially under I/O-intensive and dynamic workloads.",
    "authors": [
      "Kaiwei Tu",
      "Kan Wu",
      "Andrea C. Arpaci-Dusseau",
      "Remzi H. Arpaci-Dusseau"
    ],
    "primary_category": "cs.OS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03280",
    "title": "BlendedNet++: A Large-Scale Blended Wing Body Aerodynamics Dataset and Benchmark",
    "abstract": "Despite progress in machine learning-based aerodynamic surrogates, the scarcity of large, field-resolved datasets limits progress on accurate pointwise prediction and reproducible inverse design for aircraft. We introduce BlendedNet++, a large-scale aerodynamic dataset and benchmark focused on blended wing body (BWB) aircraft. The dataset contains over 12,000 unique geometries, each simulated at a single flight condition, yielding 12,490 aerodynamic results for steady RANS CFD. For every case, we provide (i) integrated force/moment coefficients CL, CD, CM and (ii) dense surface fields of pressure and skin friction coefficients Cp and (Cfx, Cfy, Cfz). Using this dataset, we standardize a forward-surrogate benchmark to predict pointwise fields across six model families: GraphSAGE, GraphUNet, PointNet, a coordinate Transformer (Transolver-style), a FiLMNet (coordinate MLP with feature-wise modulation), and a Graph Neural Operator Transformer (GNOT). Finally, we present an inverse design task of achieving a specified lift-to-drag ratio under fixed flight conditions, implemented via a conditional diffusion model. To assess performance, we benchmark this approach against gradient-based optimization on the same surrogate and a diffusion-optimization hybrid that first samples with the conditional diffusion model and then further optimizes the designs. BlendedNet++ provides a unified forward and inverse protocol with multi-model baselines, enabling fair, reproducible comparison across architectures and optimization paradigms. We expect BlendedNet++ to catalyze reproducible research in field-level aerodynamics and inverse design; resources (dataset, splits, baselines, and scripts) will be released upon acceptance.",
    "authors": [
      "Nicholas Sung",
      "Steven Spreizer",
      "Mohamed Elrefaie",
      "Matthew C. Jones",
      "Faez Ahmed"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03284",
    "title": "SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding",
    "abstract": "Spatial reasoning in large-scale 3D environments remains challenging for current vision-language models, which are typically constrained to room-scale scenarios. We introduce H$^2$U3D (Holistic House Understanding in 3D), a 3D visual question answering dataset designed for house-scale scene understanding. H$^2$U3D features multi-floor environments spanning up to three floors and 10-20 rooms, covering more than 300 m$^2$. Through an automated annotation pipeline, it constructs hierarchical coarse-to-fine visual representations and generates diverse question-answer pairs with chain-of-thought annotations. We further propose SpatialReasoner, an active perception framework that autonomously invokes spatial tools to explore 3D scenes based on textual queries. SpatialReasoner is trained through a two-stage strategy: a supervised cold start followed by reinforcement learning with an adaptive exploration reward that promotes efficient exploration while discouraging redundant operations. Extensive experiments demonstrate that SpatialReasoner achieves state-of-the-art performance on H$^2$U3D, outperforming strong baselines including GPT-4o and Gemini-2.5-Pro. Notably, our method attains superior results while using only 3-4 images in total on average, compared to baselines requiring 16+ images, highlighting the effectiveness of our coarse-to-fine active exploration paradigm.",
    "authors": [
      "Hongpei Zheng",
      "Shijie Li",
      "Yanran Li",
      "Hujun Yin"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03285",
    "title": "A Gossip-Enhanced Communication Substrate for Agentic AI: Toward Decentralized Coordination in Large-Scale Multi-Agent Systems",
    "abstract": "As agentic platforms scale, agents are moving beyond fixed roles and predefined toolchains, creating an urgent need for flexible and decentralized coordination. Current structured communication protocols such as direct agent-to-agent messaging or MCP-style tool calls offer reliability, but they struggle to support the emergent and swarm-like intelligence required in large adaptive systems. Distributed agents must learn continuously, share context fluidly, and coordinate without depending solely on central planners. This paper revisits gossip protocols as a complementary substrate for agentic communication. Gossip mechanisms, long valued in distributed systems for their decentralized and fault-tolerant properties, provide scalable and adaptive diffusion of knowledge and fill gaps that structured protocols alone cannot efficiently address. However, gossip also introduces challenges, including semantic relevance, temporal staleness, and limited guarantees on action consistency in rapidly changing environments. We examine how gossip can support context-rich state propagation, resilient coordination under uncertainty, and emergent global awareness. We also outline open problems around semantic filtering, trust, and knowledge decay. Rather than proposing a complete framework, this paper presents a research agenda for integrating gossip into multi-agent communication stacks and argues that gossip is essential for future agentic ecosystems that must remain robust, adaptive, and self-organizing as their scale and autonomy increase.",
    "authors": [
      "Nafiul I. Khan",
      "Mansura Habiba",
      "Rafflesia Khan"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03287",
    "title": "Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors",
    "abstract": "Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.",
    "authors": [
      "Dario Fenoglio",
      "Mohan Li",
      "Davide Casnici",
      "Matias Laporte",
      "Shkurta Gashi",
      "Silvia Santini",
      "Martin Gjoreski",
      "Marc Langheinrich"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03289",
    "title": "DAWZY: A New Addition to AI powered \"Human in the Loop\" Music Co-creation",
    "abstract": "Digital Audio Workstations (DAWs) offer fine control, but mapping high-level intent (e.g., \"warm the vocals\") to low-level edits breaks creative flow. Existing artificial intelligence (AI) music generators are typically one-shot, limiting opportunities for iterative development and human contribution. We present DAWZY, an open-source assistant that turns natural-language (text/voice/hum) requests into reversible actions in REAPER. DAWZY keeps the DAW as the creative hub with a minimal GUI and voice-first interface. DAWZY uses LLM-based code generation as a novel way to significantly reduce the time users spend familiarizing themselves with large interfaces, replacing hundreds of buttons and drop-downs with a chat box. DAWZY also uses three Model Context Protocol tools for live state queries, parameter adjustment, and AI beat generation. It maintains grounding by refreshing state before mutation and ensures safety and reversibility with atomic scripts and undo. In evaluations, DAWZY performed reliably on common production tasks and was rated positively by users across Usability, Control, Learning, Collaboration, and Enjoyment.",
    "authors": [
      "Aaron C Elkins",
      "Sanchit Singh",
      "Adrian Kieback",
      "Sawyer Blankenship",
      "Uyiosa Philip Amadasun",
      "Aman Chadha"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03290",
    "title": "ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics",
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.",
    "authors": [
      "Julian Evan Chrisnanto",
      "Nurfauzi Fadillah",
      "Yulison Herry Chrisnanto"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03293",
    "title": "Prior preferences in active inference agents: soft, hard, and goal shaping",
    "abstract": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).",
    "authors": [
      "Filippo Torresan",
      "Ryota Kanai",
      "Manuel Baltieri"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03296",
    "title": "Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis",
    "abstract": "Cancer treatment outcomes are influenced not only by clinical and demographic factors but also by the collaboration of healthcare teams. However, prior work has largely overlooked the potential role of human collaboration in shaping patient survival. This paper presents an applied AI approach to uncovering the impact of healthcare professionals' (HCPs) collaboration-captured through electronic health record (EHR) systems-on cancer patient outcomes. We model EHR-mediated HCP interactions as networks and apply machine learning techniques to detect predictive signals of patient survival embedded in these collaborations. Our models are cross validated to ensure generalizability, and we explain the predictions by identifying key network traits associated with improved outcomes. Importantly, clinical experts and literature validate the relevance of the identified crucial collaboration traits, reinforcing their potential for real-world applications. This work contributes to a practical workflow for leveraging digital traces of collaboration and AI to assess and improve team-based healthcare. The approach is potentially transferable to other domains involving complex collaboration and offers actionable insights to support data-informed interventions in healthcare delivery.",
    "authors": [
      "Hsiao-Ying Lu",
      "Kwan-Liu Ma"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03298",
    "title": "Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction",
    "abstract": "Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.",
    "authors": [
      "Echo Diyun LU",
      "Charles Findling",
      "Marianne Clausel",
      "Alessandro Leite",
      "Wei Gong",
      "Pierric Kersaudy"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03300",
    "title": "HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction",
    "abstract": "Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.",
    "authors": [
      "Pengfei Hu",
      "Fan Ming",
      "Xiaoxue Han",
      "Chang Lu",
      "Yue Ning",
      "Dan Lu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03303",
    "title": "Local Dominance in Mixed-Strength Populations -- Fast Maximal Independent Set",
    "abstract": "In many natural and engineered systems, agents interact through local contests that determine which individuals become dominant within their neighborhoods. These interactions are shaped by inherent differences in strength, and they often lead to stable dominance patterns that emerge surprisingly quickly relative to the size of the population. This motivates the search for simple mathematical models that capture both heterogeneous agent strength and rapid convergence to stable local dominance. A widely studied abstraction of local dominance is the Maximal Independent Set (MIS) problem. In the Luby MIS protocol that provably converges quickly to an MIS, each agent repeatedly generates a strength value chosen uniformly and becomes locally dominant if its value is smaller than those of its neighbors. This provides a theoretical explanation for fast dominance convergence in populations of equal-strength agents and naturally raises the question of whether fast convergence also holds in the more realistic setting where agents are inherently mixed-strength. To investigate this question, we introduce the mixed-strength agents model, in which each agent draws its strength from its own distribution. We prove that the extension of the Luby MIS protocol where each agent repeatedly generates a strength value from its own distribution still exhibits fast dominance convergence, providing formal confirmation of the rapid convergence observed in many mixed-strength natural processes. We also show that heterogeneity can significantly change the dynamics of the process. In contrast to the equal-strength setting, a constant fraction of edges need not be eliminated per round. We construct a population and strength profile in which progress per round is asymptotically smaller, illustrating how inherent strength asymmetry produces qualitatively different global behavior.",
    "authors": [
      "Michael Luby",
      "Sandy Irani"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03304",
    "title": "Fast approximate $\\ell$-center clustering in high dimensional spaces",
    "abstract": "We study the design of efficient approximation algorithms for the $\\ell$-center clustering and minimum-diameter $\\ell$-clustering problems in high dimensional Euclidean and Hamming spaces. Our main tool is randomized dimension reduction. First, we present a general method of reducing the dependency of the running time of a hypothetical algorithm for the $\\ell$-center problem in a high dimensional Euclidean space on the dimension size. Utilizing in part this method, we provide $(2+\\epsilon)$- approximation algorithms for the $\\ell$-center clustering and minimum-diameter $\\ell$-clustering problems in Euclidean and Hamming spaces that are substantially faster than the known $2$-approximation ones when both $\\ell$ and the dimension are super-logarithmic. Next, we apply the general method to the recent fast approximation algorithms with higher approximation guarantees for the $\\ell$-center clustering problem in a high dimensional Euclidean space. Finally, we provide a speed-up of the known $O(1)$-approximation method for the generalization of the $\\ell$-center clustering problem to include $z$ outliers (i.e., $z$ input points can be ignored while computing the maximum distance of an input point to a center) in high dimensional Euclidean and Hamming spaces.",
    "authors": [
      "Mirosław Kowaluk",
      "Andrzej Lingas",
      "Mia Persson"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03307",
    "title": "Robust Tabular Foundation Models",
    "abstract": "The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.",
    "authors": [
      "Matthew Peroni",
      "Franck Le",
      "Vadim Sheinin"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03309",
    "title": "Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates",
    "abstract": "Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.",
    "authors": [
      "Aniruddha Bora",
      "Shixuan Zhang",
      "Khemraj Shukla",
      "Bryce Harrop",
      "George Em. Karniadakis",
      "L. Ruby Leung"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03310",
    "title": "Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs",
    "abstract": "The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.",
    "authors": [
      "Kunj Joshi",
      "David A. Smith"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03311",
    "title": "Singing a MIS",
    "abstract": "We introduce a broadcast model called the singing model, where agents are oblivious of the size and structure of the communication network, even their immediate neighborhood. Agents can sing multiple notes which are heard by their neighbors. The model is a generalization of the beeping model, where agents can only emit sound at a single frequency. We give a simple and natural protocol where agents compete with their neighbors and their strength is reflected in the number of notes they sing. It converges in $O(log(n))$ time with high probability, where $n$ is the number of agents in the network. The protocol works in an asynchronous model where rounds vary in length and have different start times. It works with completely dynamic networks where agents can be faulty. The protocol is the first to converge to an MIS in logarithmic time for dynamic networks in a network oblivious model.",
    "authors": [
      "Sandy Irani",
      "Michael Luby"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03317",
    "title": "NavMapFusion: Diffusion-based Fusion of Navigation Maps for Online Vectorized HD Map Construction",
    "abstract": "Accurate environmental representations are essential for autonomous driving, providing the foundation for safe and efficient navigation. Traditionally, high-definition (HD) maps are providing this representation of the static road infrastructure to the autonomous system a priori. However, because the real world is constantly changing, such maps must be constructed online from on-board sensor data. Navigation-grade standard-definition (SD) maps are widely available, but their resolution is insufficient for direct deployment. Instead, they can be used as coarse prior to guide the online map construction process. We propose NavMapFusion, a diffusion-based framework that performs iterative denoising conditioned on high-fidelity sensor data and on low-fidelity navigation maps. This paper strives to answer: (1) How can coarse, potentially outdated navigation maps guide online map construction? (2) What advantages do diffusion models offer for map fusion? We demonstrate that diffusion-based map construction provides a robust framework for map fusion. Our key insight is that discrepancies between the prior map and online perception naturally correspond to noise within the diffusion process; consistent regions reinforce the map construction, whereas outdated segments are suppressed. On the nuScenes benchmark, NavMapFusion conditioned on coarse road lines from OpenStreetMap data reaches a 21.4% relative improvement on 100 m, and even stronger improvements on larger perception ranges, while maintaining real-time capabilities. By fusing low-fidelity priors with high-fidelity sensor data, the proposed method generates accurate and up-to-date environment representations, guiding towards safer and more reliable autonomous driving. The code is available at this https URL",
    "authors": [
      "Thomas Monninger",
      "Zihan Zhang",
      "Steffen Staab",
      "Sihao Ding"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03318",
    "title": "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia",
    "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.",
    "authors": [
      "Chandler Smith",
      "Marwa Abdulhai",
      "Manfred Diaz",
      "Marko Tesic",
      "Rakshit S. Trivedi",
      "Alexander Sasha Vezhnevets",
      "Lewis Hammond",
      "Jesse Clifton",
      "Minsuk Chang",
      "Edgar A. Duéñez-Guzmán",
      "John P. Agapiou",
      "Jayd Matyas",
      "Danny Karmon",
      "Akash Kundu",
      "Aliaksei Korshuk",
      "Ananya Ananya",
      "Arrasy Rahman",
      "Avinaash Anand Kulandaivel",
      "Bain McHale",
      "Beining Zhang",
      "Buyantuev Alexander",
      "Carlos Saith Rodriguez Rojas",
      "Caroline Wang",
      "Chetan Talele",
      "Chenao Liu",
      "Chichen Lin",
      "Diana Riazi",
      "Di Yang Shi",
      "Emanuel Tewolde",
      "Elizaveta Tennant",
      "Fangwei Zhong",
      "Fuyang Cui",
      "Gang Zhao",
      "Gema Parreño Piqueras",
      "Hyeonggeun Yun",
      "Ilya Makarov",
      "Jiaxun Cui",
      "Jebish Purbey",
      "Jim Dilkes",
      "Jord Nguyen",
      "Lingyun Xiao",
      "Luis Felipe Giraldo",
      "Manuela Chacon-Chamorro",
      "Manuel Sebastian Rios Beltran",
      "Marta Emili García Segura",
      "Mengmeng Wang",
      "Mogtaba Alim",
      "Nicanor Quijano",
      "Nico Schiavone",
      "Olivia Macmillan-Scott",
      "Oswaldo Peña",
      "Peter Stone",
      "Ram Mohan Rao Kadiyala",
      "Rolando Fernandez",
      "Ruben Manrique",
      "Sunjia Lu",
      "Sheila A. McIlraith",
      "Shamika Dhuri",
      "Shuqing Shi",
      "Siddhant Gupta",
      "Sneheel Sarangi",
      "Sriram Ganapathi Subramanian",
      "Taehun Cha",
      "Toryn Q. Klassen",
      "Wenming Tu",
      "Weijian Fan",
      "Wu Ruiyang",
      "Xue Feng",
      "Yali Du",
      "Yang Liu",
      "Yiding Wang",
      "Yipeng Kang",
      "Yoonchang Sung",
      "Yuxuan Chen",
      "Zhaowei Zhang",
      "Zhihan Wang",
      "Zhiqiang Wu",
      "Ziang Chen",
      "Zilong Zheng",
      "Zixia Jia",
      "Ziyan Wang",
      "Dylan Hadfield-Menell",
      "Natasha Jaques",
      "Tim Baarslag",
      "Jose Hernandez-Orallo",
      "Joel Z. Leibo"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03324",
    "title": "Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs",
    "abstract": "Memory and computation remain core bottlenecks in long-horizon LLM inference due to the quadratic cost of self-attention and the ever-growing key-value (KV) cache. Existing strategies for memory-bounded inference, such as quantization, offloading, or heuristic KV eviction, either incur high orchestration costs or rely on unreliable attention-based proxies of importance. We propose TRIM-KV, a novel approach that learns each token's intrinsic importance at creation time via a lightweight retention gate. Each gate predicts a scalar retention score that decays over time, reflecting the long-term utility of the token for a specific layer and head. Tokens with low scores are evicted when the memory budget is exceeded, ensuring that the cache always contains the most critical tokens. TRIM-KV is trained efficiently through distillation from a frozen LLM combined with a capacity loss, requiring only gate fine-tuning and adding negligible inference overhead. Across mathematical reasoning (GSM8K, MATH-500, AIME24), procedural generation (LongProc), conversational long-memory benchmarks (LongMemEval), and long-context understanding (LongBench and SCBench), TRIM-KV consistently outperforms strong eviction and learnable retrieval baselines, especially in low-memory regimes. Remarkably, it even surpasses full-cache models in some settings, showing that selective retention can serve as a form of regularization, suppressing noise from uninformative tokens. Qualitative analyses further reveal that learned retention scores align with human intuition, naturally recovering heuristics such as sink tokens, sliding windows, and gist compression without explicit design. Beyond efficiency, retention scores provide insights into layer- and head-specific roles, suggesting a new path toward LLM interpretability.",
    "authors": [
      "Ngoc Bui",
      "Shubham Sharma",
      "Simran Lamba",
      "Saumitra Mishra",
      "Rex Ying"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03326",
    "title": "Generalized Orthogonal Approximate Message-Passing for Sublinear Sparsity",
    "abstract": "This paper addresses the reconstruction of sparse signals from generalized linear measurements. Signal sparsity is assumed to be sublinear in the signal dimension while it was proportional to the signal dimension in conventional research. Approximate message-passing (AMP) has poor convergence properties for sensing matrices beyond standard Gaussian matrices. To solve this convergence issue, generalized orthogonal AMP (GOAMP) is proposed for signals with sublinear sparsity. The main feature of GOAMP is the so-called Onsager correction to realize asymptotic Gaussianity of estimation errors. The Onsager correction in GOAMP is designed via state evolution for orthogonally invariant sensing matrices in the sublinear sparsity limit, where the signal sparsity and measurement dimension tend to infinity at sublinear speed in the signal dimension. When the support of non-zero signals does not contain a neighborhood of the origin, GOAMP using Bayesian denoisers is proved to achieve error-free signal reconstruction for linear measurements if and only if the measurement dimension is larger than a threshold, which is equal to that of AMP for standard Gaussian sensing matrices. Numerical simulations are also presented for linear measurements and 1-bit compressed sensing. When ill-conditioned sensing matrices are used, GOAMP for sublinear sparsity is shown to outperform existing reconstruction algorithms, including generalized AMP for sublinear sparsity.",
    "authors": [
      "Keigo Takeuchi"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03330",
    "title": "Simpson variational integrator for nonlinear systems: a tutorial on the Lagrange top",
    "abstract": "This contribution presents an integration method based on the Simpson quadrature. The integrator is designed for finite-dimensional nonlinear mechanical systems that derive from variational principles. The action is discretized using quadratic finite elements interpolation of the state and Simpson's quadrature, leading to discrete motion equations. The scheme is implicit, symplectic, and fourth-order accurate. The proposed integrator is compared with the implicit midpoint variational integrator on two examples of systems with inseparable Hamiltonians. First, the example of the nonlinear double pendulum illustrates how the method can be applied to multibody systems. The analytical solution of the Lagrange top is then used as a reference to analyze accuracy, convergence, and precision of the numerical method. A reduced Lagrange top system is also proposed and solved with a classical fourth-order method. Its solution is compared with the Simpson solution of the complete system, and the convergence order of the difference between both is consistent with the order of the classical method.",
    "authors": [
      "Juan Antonio Rojas-Quintero",
      "François Dubois",
      "Frédéric Jourdan"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03334",
    "title": "Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní",
    "abstract": "This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.",
    "authors": [
      "Nemika Tyagi",
      "Nelvin Licona Guevara",
      "Olga Kellert"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03335",
    "title": "Step-by-step Layered Design Generation",
    "abstract": "Design generation, in its essence, is a step-by-step process where designers progressively refine and enhance their work through careful modifications. Despite this fundamental characteristic, existing approaches mainly treat design synthesis as a single-step generation problem, significantly underestimating the inherent complexity of the creative process. To bridge this gap, we propose a novel problem setting called Step-by-Step Layered Design Generation, which tasks a machine learning model with generating a design that adheres to a sequence of instructions from a designer. Leveraging recent advancements in multi-modal LLMs, we propose SLEDGE: Step-by-step LayEred Design GEnerator to model each update to a design as an atomic, layered change over its previous state, while being grounded in the instruction. To complement our new problem setting, we introduce a new evaluation suite, including a dataset and a benchmark. Our exhaustive experimental analysis and comparison with state-of-the-art approaches tailored to our new setup demonstrate the efficacy of our approach. We hope our work will attract attention to this pragmatic and under-explored research area.",
    "authors": [
      "Faizan Farooq Khan",
      "K J Joseph",
      "Koustava Goswami",
      "Mohamed Elhoseiny",
      "Balaji Vasan Srinivasan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03336",
    "title": "Single-Round Scalable Analytic Federated Learning",
    "abstract": "Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.",
    "authors": [
      "Alan T. L. Bacellar",
      "Mustafa Munir",
      "Felipe M. G. França",
      "Priscila M. V. Lima",
      "Radu Marculescu",
      "Lizy K. John"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03337",
    "title": "Epistemic Substitution: How Grokipedia's AI-Generated Encyclopedia Restructures Authority",
    "abstract": "A quarter century ago, Wikipedia's decentralized, crowdsourced, and consensus-driven model replaced the centralized, expert-driven, and authority-based standard for encyclopedic knowledge curation. The emergence of generative AI encyclopedias, such as Grokipedia, possibly presents another potential shift in epistemic evolution. This study investigates whether AI- and human-curated encyclopedias rely on the same foundations of authority. We conducted a multi-scale comparative analysis of the citation networks from 72 matched article pairs, which cite a total of almost 60,000 sources. Using an 8-category epistemic classification, we mapped the \"epistemic profiles\" of the articles on each platform. Our findings reveal several quantitative and qualitative differences in how knowledge is sourced and encyclopedia claims are epistemologically justified. Grokipedia replaces Wikipedia's heavy reliance on peer-reviewed \"Academic & Scholarly\" work with a notable increase in \"User-generated\" and \"Civic organization\" sources. Comparative network analyses further show that Grokipedia employs very different epistemological profiles when sourcing leisure topics (such as Sports and Entertainment) and more societal sensitive civic topics (such as Politics & Conflicts, Geographical Entities, and General Knowledge & Society). Finally, we find a \"scaling-law for AI-generated knowledge sourcing\" that shows a linear relationship between article length and citation density, which is distinct from collective human reference sourcing. We conclude that this first implementation of an LLM-based encyclopedia does not merely automate knowledge production but restructures it. Given the notable changes and the important role of encyclopedias, we suggest the continuation and deepening of algorithm audits, such as the one presented here, in order to understand the ongoing epistemological shifts.",
    "authors": [
      "Aliakbar Mehdizadeh",
      "Martin Hilbert"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03339",
    "title": "ProtoEFNet: Dynamic Prototype Learning for Inherently Interpretable Ejection Fraction Estimation in Echocardiography",
    "abstract": "Ejection fraction (EF) is a crucial metric for assessing cardiac function and diagnosing conditions such as heart failure. Traditionally, EF estimation requires manual tracing and domain expertise, making the process time-consuming and subject to interobserver variability. Most current deep learning methods for EF prediction are black-box models with limited transparency, which reduces clinical trust. Some post-hoc explainability methods have been proposed to interpret the decision-making process after the prediction is made. However, these explanations do not guide the model's internal reasoning and therefore offer limited reliability in clinical applications. To address this, we introduce ProtoEFNet, a novel video-based prototype learning model for continuous EF regression. The model learns dynamic spatiotemporal prototypes that capture clinically meaningful cardiac motion patterns. Additionally, the proposed Prototype Angular Separation (PAS) loss enforces discriminative representations across the continuous EF spectrum. Our experiments on the EchonetDynamic dataset show that ProtoEFNet can achieve accuracy on par with its non-interpretable counterpart while providing clinically relevant insight. The ablation study shows that the proposed loss boosts performance with a 2% increase in F1 score from 77.67$\\pm$2.68 to 79.64$\\pm$2.10. Our source code is available at: this https URL",
    "authors": [
      "Yeganeh Ghamary",
      "Victoria Wu",
      "Hooman Vaseli",
      "Christina Luong",
      "Teresa Tsang",
      "Siavash Bigdeli",
      "Purang Abolmaesumi"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03340",
    "title": "PERCS: Persona-Guided Controllable Biomedical Summarization Dataset",
    "abstract": "Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.",
    "authors": [
      "Rohan Charudatt Salvi",
      "Chirag Chawla",
      "Dhruv Jain",
      "Swapnil Panigrahi",
      "Md Shad Akhtar",
      "Shweta Yadav"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03343",
    "title": "Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning",
    "abstract": "Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \\citep{holtzman2019curious}. While scaling model size mitigates this \\citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.",
    "authors": [
      "Darshan Fofadiya"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03345",
    "title": "HalluGen: Synthesizing Realistic and Controllable Hallucinations for Evaluating Image Restoration",
    "abstract": "Generative models are prone to hallucinations: plausible but incorrect structures absent in the ground truth. This issue is problematic in image restoration for safety-critical domains such as medical imaging, industrial inspection, and remote sensing, where such errors undermine reliability and trust. For example, in low-field MRI, widely used in resource-limited settings, restoration models are essential for enhancing low-quality scans, yet hallucinations can lead to serious diagnostic errors. Progress has been hindered by a circular dependency: evaluating hallucinations requires labeled data, yet such labels are costly and subjective. We introduce HalluGen, a diffusion-based framework that synthesizes realistic hallucinations with controllable type, location, and severity, producing perceptually realistic but semantically incorrect outputs (segmentation IoU drops from 0.86 to 0.36). Using HalluGen, we construct the first large-scale hallucination dataset comprising 4,350 annotated images derived from 1,450 brain MR images for low-field enhancement, enabling systematic evaluation of hallucination detection and mitigation. We demonstrate its utility in two applications: (1) benchmarking image quality metrics and developing Semantic Hallucination Assessment via Feature Evaluation (SHAFE), a feature-based metric with soft-attention pooling that improves hallucination sensitivity over traditional metrics; and (2) training reference-free hallucination detectors that generalize to real restoration failures. Together, HalluGen and its open dataset establish the first scalable foundation for evaluating hallucinations in safety-critical image restoration.",
    "authors": [
      "Seunghoi Kim",
      "Henry F. J. Tregidgo",
      "Chen Jin",
      "Matteo Figini",
      "Daniel C. Alexander"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03346",
    "title": "Hierarchical Attention for Sparse Volumetric Anomaly Detection in Subclinical Keratoconus",
    "abstract": "The detection of weak, spatially distributed anomalies in volumetric medical imaging remains a major challenge. The subtle, non-adjacent nature of early disease signals is often lost due to suboptimal architectural inductive biases: 2D/3D CNNs impose strong locality, while ViTs diffuse unconstrained global attention. This conflict leaves the optimal inductive structure for robust, sparse volumetric pattern recognition unresolved. This study presents a controlled comparison of sixteen modern deep learning architectures spanning 2D/3D convolutional, hybrid, and volumetric transformer families for subclinical keratoconus (SKC) detection from 3D anterior segment OCT volumes. We demonstrate that hierarchical attention models offer a superior and more parameter-efficient inductive bias, surpassing the performance of both 2D and 3D CNNs and ViTs. Our results show 21-23% higher sensitivity and specificity in the sparse anomaly (subclinical) regime. Mechanistic analyses reveal that this advantage stems from precise spatial scale alignment: hierarchical windowing produces effective receptive fields matched to the intermediate, multi-slice extent of subclinical abnormalities. This avoids excessive CNN locality and diffuse global attention. Attention-distance measurements confirm a key insight into architectural adaptation: the required spatial integration length shifts significantly based on the signal strength, with subclinical cases necessitating longer integration compared to both healthy and manifest disease states. Representational similarity and auxiliary age/sex prediction tasks further support the generalizability of these inductive principles. The findings provide design guidance for future volumetric anomaly detection systems, establishing hierarchical attention as a principled and effective approach for early pathological change analysis in 3D medical imaging.",
    "authors": [
      "Lynn Kandakji",
      "William Woof",
      "Nikolas Pontikos"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03347",
    "title": "GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation",
    "abstract": "Imitation Learning (IL) holds great potential for learning repetitive manipulation tasks, such as those in industrial assembly. However, its effectiveness is often limited by insufficient trajectory precision due to compounding errors. In this paper, we introduce Grasped Object Manifold Projection (GOMP), an interactive method that mitigates these errors by constraining a non-rigidly grasped object to a lower-dimensional manifold. GOMP assumes a precise task in which a manipulator holds an object that may shift within the grasp in an observable manner and must be mated with a grounded part. Crucially, all GOMP enhancements are learned from the same expert dataset used to train the base IL policy, and are adjusted with an n-arm bandit-based interactive component. We propose a theoretical basis for GOMP's improvement upon the well-known compounding error bound in IL literature. We demonstrate the framework on four precise assembly tasks using tactile feedback, and note that the approach remains modality-agnostic. Data and videos are available at this http URL .",
    "authors": [
      "William van den Bogert",
      "Gregory Linkowski",
      "Nima Fazeli"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03350",
    "title": "SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation",
    "abstract": "Images and videos are discrete 2D projections of the 4D world (3D space + time). Most visual understanding, prediction, and generation operate directly on 2D observations, leading to suboptimal performance. We propose SeeU, a novel approach that learns the continuous 4D dynamics and generate the unseen visual contents. The principle behind SeeU is a new 2D$\\to$4D$\\to$2D learning framework. SeeU first reconstructs the 4D world from sparse and monocular 2D frames (2D$\\to$4D). It then learns the continuous 4D dynamics on a low-rank representation and physical constraints (discrete 4D$\\to$continuous 4D). Finally, SeeU rolls the world forward in time, re-projects it back to 2D at sampled times and viewpoints, and generates unseen regions based on spatial-temporal context awareness (4D$\\to$2D). By modeling dynamics in 4D, SeeU achieves continuous and physically-consistent novel visual generation, demonstrating strong potentials in multiple tasks including unseen temporal generation, unseen spatial generation, and video editing.",
    "authors": [
      "Yu Yuan",
      "Tharindu Wickremasinghe",
      "Zeeshan Nadir",
      "Xijun Wang",
      "Yiheng Chi",
      "Stanley H. Chan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03351",
    "title": "Empirical assessment of the perception of graphical threat model acceptability",
    "abstract": "Threat modeling (TM) is an important aspect of risk analysis and secure software engineering. Graphical threat models are a recommended tool to analyze and communicate threat information. However, the comparison of different graphical threat models, and the acceptability of these threat models for an audience with a limited technical background, is not well understood, despite these users making up a sizable portion of the cybersecurity industry. We seek to compare the acceptability of three general, graphical threat models, Attack-Defense Trees (ADTs), Attack Graphs (AGs), and CORAS, for users with a limited technical background. We conducted a laboratory study with 38 bachelor students who completed tasks with the three threat models across three different scenarios assigned using a Latin square design. Threat model submissions were qualitatively analyzed, and participants filled out a perception questionnaire based on the Method Evaluation Model (MEM). We find that both ADTs and CORAS are broadly acceptable for a wide range of scenarios, and both could be applied successfully by users with a limited technical background; further, we also find that the lack of a specific tool for AGs may have impacted the perceived usefulness of AGs. We can recommend that users with a limited technical background use ADTs or CORAS as a general graphical TM method. Further research on the acceptability of AGs to such an audience and the effect of a dedicated TM tool support is needed.",
    "authors": [
      "Nathan D. Schiele",
      "Olga Gadyatskaya"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03354",
    "title": "Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions",
    "abstract": "Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.",
    "authors": [
      "Hongseon Yeom",
      "Jaeyoul Shin",
      "Soojin Min",
      "Jeongmin Yoon",
      "Seunghak Yu",
      "Dongyeop Kang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03356",
    "title": "Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models",
    "abstract": "Large language models (LLMs) have become foundational in AI systems, yet they remain vulnerable to adversarial jailbreak attacks. These attacks involve carefully crafted prompts that bypass safety guardrails and induce models to produce harmful content. Detecting such malicious input queries is therefore critical for maintaining LLM safety. Existing methods for jailbreak detection typically involve fine-tuning LLMs as static safety LLMs using fixed training datasets. However, these methods incur substantial computational costs when updating model parameters to improve robustness, especially in the face of novel jailbreak attacks. Inspired by immunological memory mechanisms, we propose the Multi-Agent Adaptive Guard (MAAG) framework for jailbreak detection. The core idea is to equip guard with memory capabilities: upon encountering novel jailbreak attacks, the system memorizes attack patterns, enabling it to rapidly and accurately identify similar threats in future encounters. Specifically, MAAG first extracts activation values from input prompts and compares them to historical activations stored in a memory bank for quick preliminary detection. A defense agent then simulates responses based on these detection results, and an auxiliary agent supervises the simulation process to provide secondary filtering of the detection outcomes. Extensive experiments across five open-source models demonstrate that MAAG significantly outperforms state-of-the-art (SOTA) methods, achieving 98% detection accuracy and a 96% F1-score across a diverse range of attack scenarios.",
    "authors": [
      "Jun Leng",
      "Litian Zhang",
      "Xi Zhang"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03358",
    "title": "Scaling Trust in Quantum Federated Learning: A Multi-Protocol Privacy Design",
    "abstract": "Quantum Federated Learning (QFL) promises to revolutionize distributed machine learning by combining the computational power of quantum devices with collaborative model training. Yet, privacy of both data and models remains a critical challenge. In this work, we propose a privacy-preserving QFL framework where a network of $n$ quantum devices trains local models and transmits them to a central server under a multi-layered privacy protocol. Our design leverages Singular Value Decomposition (SVD), Quantum Key Distribution (QKD), and Analytic Quantum Gradient Descent (AQGD) to secure data preparation, model sharing, and training stages. Through theoretical analysis and experiments on contemporary quantum platforms and datasets, we demonstrate that the framework robustly safeguards data and model confidentiality while maintaining training efficiency.",
    "authors": [
      "Dev Gurung",
      "Shiva Raj Pokhrel"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03359",
    "title": "A Hybrid Deep Learning Framework with Explainable AI for Lung Cancer Classification with DenseNet169 and SVM",
    "abstract": "Lung cancer is a very deadly disease worldwide, and its early diagnosis is crucial for increasing patient survival rates. Computed tomography (CT) scans are widely used for lung cancer diagnosis as they can give detailed lung structures. However, manual interpretation is time-consuming and prone to human error. To surmount this challenge, the study proposes a deep learning-based automatic lung cancer classification system to enhance detection accuracy and interpretability. The IQOTHNCCD lung cancer dataset is utilized, which is a public CT scan dataset consisting of cases categorized into Normal, Benign, and Malignant and used DenseNet169, which includes Squeezeand-Excitation blocks for attention-based feature extraction, Focal Loss for handling class imbalance, and a Feature Pyramid Network (FPN) for multi-scale feature fusion. In addition, an SVM model was developed using MobileNetV2 for feature extraction, improving its classification performance. For model interpretability enhancement, the study integrated Grad-CAM for the visualization of decision-making regions in CT scans and SHAP (Shapley Additive Explanations) for explanation of feature contributions within the SVM model. Intensive evaluation was performed, and it was found that both DenseNet169 and SVM models achieved 98% accuracy, suggesting their robustness for real-world medical practice. These results open up the potential for deep learning to improve the diagnosis of lung cancer by a higher level of accuracy, transparency, and robustness.",
    "authors": [
      "Md Rashidul Islam",
      "Bakary Gibba",
      "Altagi Abdallah Bakheit Abdelgadir"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03360",
    "title": "From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation",
    "abstract": "Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.",
    "authors": [
      "Qingchuan Li",
      "Mingyue Cheng",
      "Zirui Liu",
      "Daoyu Wang",
      "Yuting Zeng",
      "Tongxuan Liu"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03361",
    "title": "Rethinking Security in Semantic Communication: Latent Manipulation as a New Threat",
    "abstract": "Deep learning-based semantic communication (SemCom) has emerged as a promising paradigm for next-generation wireless networks, offering superior transmission efficiency by extracting and conveying task-relevant semantic latent representations rather than raw data. However, the openness of the wireless medium and the intrinsic vulnerability of semantic latent representations expose such systems to previously unrecognized security risks. In this paper, we uncover a fundamental latent-space vulnerability that enables Man-in-the-Middle (MitM) attacker to covertly manipulate the transmitted semantics while preserving the statistical properties of the transmitted latent representations. We first present a Diffusion-based Re-encoding Attack (DiR), wherein the attacker employs a diffusion model to synthesize an attacker-designed semantic variant, and re-encodes it into a valid latent representation compatible with the SemCom decoder. Beyond this model-dependent pathway, we further propose a model-agnostic and training-free Test-Time Adaptation Latent Manipulation attack (TTA-LM), in which the attacker perturbs and steers the intercepted latent representation toward an attacker-specified semantic target by leveraging the gradient of a target loss function. In contrast to diffusion-based manipulation, TTA-LM does not rely on any generative model and does not impose modality-specific or task-specific assumptions, thereby enabling efficient and broadly applicable latent-space tampering across diverse SemCom architectures. Extensive experiments on representative semantic communication architectures demonstrate that both attacks can significantly alter the decoded semantics while preserving natural latent-space distributions, making the attacks covert and difficult to detect.",
    "authors": [
      "Zhiyuan Xi",
      "Kun Zhu"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03363",
    "title": "A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning",
    "abstract": "Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.",
    "authors": [
      "Shanika Iroshi Nanayakkara",
      "Shiva Raj Pokhrel"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03369",
    "title": "FireSentry: A Multi-Modal Spatio-temporal Benchmark Dataset for Fine-Grained Wildfire Spread Forecasting",
    "abstract": "Fine-grained wildfire spread prediction is crucial for enhancing emergency response efficacy and decision-making precision. However, existing research predominantly focuses on coarse spatiotemporal scales and relies on low-resolution satellite data, capturing only macroscopic fire states while fundamentally constraining high-precision localized fire dynamics modeling capabilities. To bridge this gap, we present FireSentry, a provincial-scale multi-modal wildfire dataset characterized by sub-meter spatial and sub-second temporal resolution. Collected using synchronized UAV platforms, FireSentry provides visible and infrared video streams, in-situ environmental measurements, and manually validated fire masks. Building on FireSentry, we establish a comprehensive benchmark encompassing physics-based, data-driven, and generative models, revealing the limitations of existing mask-only approaches. Our analysis proposes FiReDiff, a novel dual-modality paradigm that first predicts future video sequences in the infrared modality, and then precisely segments fire masks in the mask modality based on the generated dynamics. FiReDiff achieves state-of-the-art performance, with video quality gains of 39.2% in PSNR, 36.1% in SSIM, 50.0% in LPIPS, 29.4% in FVD, and mask accuracy gains of 3.3% in AUPRC, 59.1% in F1 score, 42.9% in IoU, and 62.5% in MSE when applied to generative models. The FireSentry benchmark dataset and FiReDiff paradigm collectively advance fine-grained wildfire forecasting and dynamic disaster simulation. The processed benchmark dataset is publicly available at: this https URL .",
    "authors": [
      "Nan Zhou",
      "Huandong Wang",
      "Jiahao Li",
      "Han Li",
      "Yali Song",
      "Qiuhua Wang",
      "Yong Li",
      "Xinlei Chen"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03370",
    "title": "ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding",
    "abstract": "We introduce ShelfGaussian, an open-vocabulary multi-modal Gaussian-based 3D scene understanding framework supervised by off-the-shelf vision foundation models (VFMs). Gaussian-based methods have demonstrated superior performance and computational efficiency across a wide range of scene understanding tasks. However, existing methods either model objects as closed-set semantic Gaussians supervised by annotated 3D labels, neglecting their rendering ability, or learn open-set Gaussian representations via purely 2D self-supervision, leading to degraded geometry and limited to camera-only settings. To fully exploit the potential of Gaussians, we propose a Multi-Modal Gaussian Transformer that enables Gaussians to query features from diverse sensor modalities, and a Shelf-Supervised Learning Paradigm that efficiently optimizes Gaussians with VFM features jointly at 2D image and 3D scene levels. We evaluate ShelfGaussian on various perception and planning tasks. Experiments on Occ3D-nuScenes demonstrate its state-of-the-art zero-shot semantic occupancy prediction performance. ShelfGaussian is further evaluated on an unmanned ground vehicle (UGV) to assess its in the-wild performance across diverse urban scenarios. Project website: this https URL .",
    "authors": [
      "Lingjun Zhao",
      "Yandong Luo",
      "James Hay",
      "Lu Gan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03373",
    "title": "LLM-Generated Ads: From Personalization Parity to Persuasion Superiority",
    "abstract": "As large language models (LLMs) become increasingly capable of generating persuasive content, understanding their effectiveness across different advertising strategies becomes critical. This paper presents a two-part investigation examining LLM-generated advertising through complementary lenses: (1) personality-based and (2) psychological persuasion principles. In our first study (n=400), we tested whether LLMs could generate personalized advertisements tailored to specific personality traits (openness and neuroticism) and how their performance compared to human experts. Results showed that LLM-generated ads achieved statistical parity with human-written ads (51.1% vs. 48.9%, p > 0.05), with no significant performance differences for matched personalities. Building on these insights, our second study (n=800) shifted focus from individual personalization to universal persuasion, testing LLM performance across four foundational psychological principles: authority, consensus, cognition, and scarcity. AI-generated ads significantly outperformed human-created content, achieving a 59.1% preference rate (vs. 40.9%, p < 0.001), with the strongest performance in authority (63.0%) and consensus (62.5%) appeals. Qualitative analysis revealed AI's advantage stems from crafting more sophisticated, aspirational messages and achieving superior visual-narrative coherence. Critically, this quality advantage proved robust: even after applying a 21.2 percentage point detection penalty when participants correctly identified AI-origin, AI ads still outperformed human ads, and 29.4% of participants chose AI content despite knowing its origin. These findings demonstrate LLMs' evolution from parity in personalization to superiority in persuasive storytelling, with significant implications for advertising practice given LLMs' near-zero marginal cost and time requirements compared to human experts.",
    "authors": [
      "Elyas Meguellati",
      "Stefano Civelli",
      "Lei Han",
      "Abraham Bernstein",
      "Shazia Sadiq",
      "Gianluca Demartini"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03374",
    "title": "Joint Sensing, Communication, and Computation for Vertical Federated Edge Learning in Edge Perception Network",
    "abstract": "Combining wireless sensing and edge intelligence, edge perception networks enable intelligent data collection and processing at the network edge. However, traditional sample partition based horizontal federated edge learning struggles to effectively fuse complementary multiview information from distributed devices. To address this limitation, we propose a vertical federated edge learning (VFEEL) framework tailored for feature-partitioned sensing data. In this paper, we consider an integrated sensing, communication, and computation-enabled edge perception network, where multiple edge devices utilize wireless signals to sense environmental information for updating their local models, and the edge server aggregates feature embeddings via over-the-air computation for global model training. First, we analyze the convergence behavior of the ISCC-enabled VFEEL in terms of the loss function degradation in the presence of wireless sensing noise and aggregation distortions during AirComp.",
    "authors": [
      "Xiaowen Cao",
      "Dingzhu Wen",
      "Suzhi Bi",
      "Yuanhao Cui",
      "Guangxu Zhu",
      "Han Hu",
      "Yonina C. Eldar"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03375",
    "title": "MAGE-ID: A Multimodal Generative Framework for Intrusion Detection Systems",
    "abstract": "Modern Intrusion Detection Systems (IDS) face severe challenges due to heterogeneous network traffic, evolving cyber threats, and pronounced data imbalance between benign and attack flows. While generative models have shown promise in data augmentation, existing approaches are limited to single modalities and fail to capture cross-domain dependencies. This paper introduces MAGE-ID (Multimodal Attack Generator for Intrusion Detection), a diffusion-based generative framework that couples tabular flow features with their transformed images through a unified latent prior. By jointly training Transformer and CNN-based variational encoders with an EDM style denoiser, MAGE-ID achieves balanced and coherent multimodal synthesis. Evaluations on CIC-IDS-2017 and NSL-KDD demonstrate significant improvements in fidelity, diversity, and downstream detection performance over TabSyn and TabDDPM, highlighting the effectiveness of MAGE-ID for multimodal IDS augmentation.",
    "authors": [
      "Mahdi Arab Loodaricheh",
      "Mohammad Hossein Manshaei",
      "Anita Raja"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03377",
    "title": "Nexus: Higher-Order Attention Mechanisms in Transformers",
    "abstract": "Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \\textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \\textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.",
    "authors": [
      "Hanting Chen",
      "Chu Zhong",
      "Kai Han",
      "Yuchuan Tian",
      "Yuchen Liang",
      "Tianyu Guo",
      "Xinghao Chen",
      "Dacheng Tao",
      "Yunhe Wang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03381",
    "title": "Characterizing Language Use in a Collaborative Situated Game",
    "abstract": "Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.",
    "authors": [
      "Nicholas Tomlin",
      "Naitian Zhou",
      "Eve Fleisig",
      "Liangyuan",
      "Chen",
      "Téa Wright",
      "Lauren Vinh",
      "Laura X. Ma",
      "Seun Eisape",
      "Ellie French",
      "Tingting Du",
      "Tianjiao Zhang",
      "Alexander Koller",
      "Alane Suhr"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03383",
    "title": "UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs",
    "abstract": "Deploying large language model (LLM) models on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework with on-device configurable pruning rates for edge LLMs. UniQL is a general framework that integrates quantization and low-rank compression for Transformers, State Space Models (SSMs), and hybrid models to support diverse edge applications. In our proposed joint framework, we introduce an efficient structured weight-sorting method that speeds up computation by 20x, quantization-aware singular value decomposition (SVD) to minimize quantization errors, state-aware weight sorting for SSMs, and a fused rotary positional embedding (RoPE) kernel for pruned models. Our framework performs weight-sorting, fine-tuning, and quantization in the cloud in a single-pass workflow, while enabling on-device configurable pruning rates up to 35%. Our experiments show that quantized and pruned models achieve a memory reduction of 4x-5.7x and a token-throughput improvement of 2.7x-3.4x, maintaining accuracy within 5% of the original models at 15% pruning across Transformers (Llama3 and Qwen2.5), SSMs (Mamba2), and hybrid models (Nemotron-H and Bamba-v2). The code and quantized models are available at: this https URL .",
    "authors": [
      "Hung-Yueh Chiang",
      "Chi-Chih Chang",
      "Yu-Chen Lu",
      "Chien-Yu Lin",
      "Kai-Chiang Wu",
      "Mohamed S. Abdelfattah",
      "Diana Marculescu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03389",
    "title": "Continuous Prompts: LLM-Augmented Pipeline Processing over Unstructured Streams",
    "abstract": "Monitoring unstructured streams increasingly requires persistent, semantics-aware computation, yet today's LLM frameworks remain stateless and one-shot, limiting their usefulness for long-running analytics. We introduce Continuous Prompts (CPs), the first framework that brings LLM reasoning into continuous stream processing. CPs extend RAG to streaming settings, define continuous semantic operators, and provide multiple implementations, primarily focusing on LLM-based approaches but also reporting one embedding-based variants. Furthermore, we study two LLM-centric optimizations, tuple batching and operator fusion, to significantly improve efficiency while managing accuracy loss. Because these optimizations inherently trade accuracy for speed, we present a dynamic optimization framework that uses lightweight shadow executions and cost-aware multi-objective Bayesian optimization (MOBO) to learn throughput-accuracy frontiers and adapt plans under probing budgets. We implement CPs in the VectraFlow stream processing system. Using operator-level microbenchmarks and streaming pipelines on real datasets, we show that VectraFlow can adapt to workload dynamics, navigate accuracy-efficiency trade-offs, and sustain persistent semantic queries over evolving unstructured streams.",
    "authors": [
      "Shu Chen",
      "Deepti Raghavan",
      "Uğur Çetintemel"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03393",
    "title": "Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization",
    "abstract": "Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a \"momentum-like\" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.",
    "authors": [
      "Lakshmi Jayalal",
      "Sheetal Kalyani"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03394",
    "title": "VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing",
    "abstract": "Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.",
    "authors": [
      "Hamed Poursiami",
      "Shay Snyder",
      "Guojing Cong",
      "Thomas Potok",
      "Maryam Parsa"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03397",
    "title": "Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing",
    "abstract": "LiDAR-inertial odometry (LIO) is an active research area, as it enables accurate real-time state estimation in GPS-denied environments. Recent advances in map data structures and spatial indexing have significantly improved the efficiency of LIO systems. Nevertheless, we observe that two aspects may still leave room for improvement: (1) nearest neighbor search often requires examining multiple spatial units to gather sufficient points for plane fitting, and (2) plane parameters are typically recomputed at every iteration despite unchanged map geometry. Motivated by these observations, we propose Surfel-LIO, which employs a hierarchical voxel structure (hVox) with pre-computed surfel representation. This design enables O(1) correspondence retrieval without runtime neighbor enumeration or plane fitting, combined with Z-order curve encoding for cache-friendly spatial indexing. Experimental results on the M3DGR dataset demonstrate that our method achieves significantly faster processing speed compared to recent state-of-the-art methods while maintaining comparable state estimation accuracy. Our implementation is publicly available at this https URL .",
    "authors": [
      "Seungwon Choi",
      "Dong-Gyu Park",
      "Seo-Yeon Hwang",
      "Tae-Wan Kim"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03398",
    "title": "Teacher, But Also Student: Challenges and Tech Needs of Adult Braille Learners with Sight",
    "abstract": "Braille literacy is critical for blind individuals' independence and quality of life, yet literacy rates continue to decline. Though braille instructors in integrated K-12 classrooms play a central role in literacy development in blind youth, prior research on braille learning almost exclusively focuses on blind adolescent students. As a result, we still know little about how sighted adult teachers learn braille. To address this, we interviewed 14 educators, including 13 certificated Teachers of Students with Visual Impairments (TVIs) and 1 paraeducator, who learned braille as adults. We found that they: (1) lack consistent braille exposure to reinforce knowledge and skill; (2) have limited time to practice due to myriad responsibilities of adulthood; and thus, (3) seek learning tools that are engaging and efficient. Our research draws attention to the needs of a group of braille learners who have been overlooked and identifies new design opportunities to facilitate braille literacy.",
    "authors": [
      "Quan Zhou",
      "Cameron Cassidy",
      "Alyson Yin",
      "Stacy Branham"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03399",
    "title": "Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value",
    "abstract": "Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.",
    "authors": [
      "Joe Edelman",
      "Tan Zhi-Xuan",
      "Ryan Lowe",
      "Oliver Klingefjord",
      "Vincent Wang-Mascianica",
      "Matija Franklin",
      "Ryan Othniel Kearns",
      "Ellie Hain",
      "Atrisha Sarkar",
      "Michiel Bakker",
      "Fazl Barez",
      "David Duvenaud",
      "Jakob Foerster",
      "Iason Gabriel",
      "Joseph Gubbels",
      "Bryce Goodman",
      "Andreas Haupt",
      "Jobst Heitzig",
      "Julian Jara-Ettinger",
      "Atoosa Kasirzadeh",
      "James Ravi Kirkpatrick",
      "Andrew Koh",
      "W. Bradley Knox",
      "Philipp Koralus",
      "Joel Lehman",
      "Sydney Levine",
      "Samuele Marro",
      "Manon Revel",
      "Toby Shorin",
      "Morgan Sutherland",
      "Michael Henry Tessler",
      "Ivan Vendrov",
      "James Wilken-Smith"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03400",
    "title": "Better World Models Can Lead to Better Post-Training Performance",
    "abstract": "In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.",
    "authors": [
      "Prakhar Gupta",
      "Henry Conklin",
      "Sarah-Jane Leslie",
      "Andrew Lee"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03401",
    "title": "Enterprise Data Science Platform: A Unified Architecture for Federated Data Access",
    "abstract": "Organizations struggle to share data across departments that have adopted different data analytics platforms. If n datasets must serve m environments, up to n*m replicas can emerge, increasing inconsistency and cost. Traditional warehouses copy data into vendor-specific stores; cross-platform access is hard. This study proposes the Enterprise Data Science Platform (EDSP), which builds on data lakehouse architecture and follows a Write-Once, Read-Anywhere principle. EDSP enables federated data access for multi-query engine environments, targeting data science workloads with periodic data updates and query response times ranging from seconds to minutes. By providing centralized data management with federated access from multiple query engines to the same data sources, EDSP eliminates data duplication and vendor lock-in inherent in traditional data warehouses. The platform employs a four-layer architecture: Data Preparation, Data Store, Access Interface, and Query Engines. This design enforces separation of concerns and reduces the need for data migration when integrating additional analytical environments. Experimental results demonstrate that major cloud data warehouses and programming environments can directly query EDSP-managed datasets. We implemented and deployed EDSP in production, confirming interoperability across multiple query engines. For data sharing across different analytical environments, EDSP achieves a 33-44% reduction in operational steps compared with conventional approaches requiring data migration. Although query latency may increase by up to a factor of 2.6 compared with native tables, end-to-end completion times remain on the order of seconds, maintaining practical performance for analytical use cases. Based on our production experience, EDSP provides practical design guidelines for addressing the data-silo problem in multi-query engine environments.",
    "authors": [
      "Ryoto Miyamoto",
      "Akira Kasuga"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03402",
    "title": "Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates",
    "abstract": "Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.",
    "authors": [
      "Yixing Xu",
      "Chao Li",
      "Xuanwu Yin",
      "Spandan Tiwari",
      "Dong Li",
      "Ashish Sirasao",
      "Emad Barsoum"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03404",
    "title": "MOS: Mitigating Optical-SAR Modality Gap for Cross-Modal Ship Re-Identification",
    "abstract": "Cross-modal ship re-identification (ReID) between optical and synthetic aperture radar (SAR) imagery has recently emerged as a critical yet underexplored task in maritime intelligence and surveillance. However, the substantial modality gap between optical and SAR images poses a major challenge for robust identification. To address this issue, we propose MOS, a novel framework designed to mitigate the optical-SAR modality gap and achieve modality-consistent feature learning for optical-SAR cross-modal ship ReID. MOS consists of two core components: (1) Modality-Consistent Representation Learning (MCRL) applies denoise SAR image procession and a class-wise modality alignment loss to align intra-identity feature distributions across modalities. (2) Cross-modal Data Generation and Feature fusion (CDGF) leverages a brownian bridge diffusion model to synthesize cross-modal samples, which are subsequently fused with original features during inference to enhance alignment and discriminability. Extensive experiments on the HOSS ReID dataset demonstrate that MOS significantly surpasses state-of-the-art methods across all evaluation protocols, achieving notable improvements of +3.0%, +6.2%, and +16.4% in R1 accuracy under the ALL to ALL, Optical to SAR, and SAR to Optical settings, respectively. The code and trained models will be released upon publication.",
    "authors": [
      "Yujian Zhao",
      "Hankun Liu",
      "Guanglin Niu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03405",
    "title": "ViDiC: Video Difference Captioning",
    "abstract": "Understanding visual differences between dynamic scenes requires the comparative perception of compositional, spatial, and temporal changes--a capability that remains underexplored in existing vision-language systems. While prior work on Image Difference Captioning (IDC) has enabled models to describe semantic changes between static images, these approaches fail to capture motion continuity, event evolution, or editing consistency over time. We introduce the ViDiC (Video Difference Captioning) task and its corresponding ViDiC-1K dataset, designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to provide fine-grained descriptions of similarities and differences between video pairs. ViDiC-1K comprises 1,000 curated video pairs annotated with over 4,000 comparative checklist items, covering seven categories: subject, style, background, cinematography, motion, location, and playback techniques. To ensure reliable evaluation, we propose a dual-checklist framework that measures the accuracy of similarity and difference separately, based on the LLM-as-a-Judge protocol. Experiments on nineteen representative multimodal models reveal a significant performance gap in their comparative description and difference perception abilities. We hope ViDiC-1K can be a challenging benchmark that lays a solid foundation for advancing video understanding, edit awareness, and comparative reasoning in multimodal intelligence.",
    "authors": [
      "Jiangtao Wu",
      "Shihao Li",
      "Zhaozhou Bian",
      "Yuanxing Zhang",
      "Jialu Chen",
      "Runzhe Wen",
      "An Ping",
      "Yiwen He",
      "Jiakai Wang",
      "Jiaheng Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03406",
    "title": "Why Some Seek AI, Others Seek Therapists: Mental Health in the Age of Generative AI",
    "abstract": "As generative artificial intelligence (GAI) enters the mental health landscape, questions arise about how individuals weigh AI tools against human therapists. Drawing on the Health Belief Model (HBM), this study examined belief-based predictors of intention to use GAI and therapists across two populations: a university sample (N = 1,155) and a nationally representative adult sample (N = 651). Using repeated-measures ANOVA and LASSO regression, we found that therapists were consistently valued for emotional, relational, and personalization benefits, while GAI was favored for accessibility and affordability. Yet structural advantages alone did not predict adoption; emotional benefit and personalization emerged as decisive factors. Adoption patterns diverged across groups: students treated GAI as a complement, whereas national adults approached it as a substitute. Concerns about privacy and reliability constrained GAI use in both groups. These findings extend HBM to multi-modality contexts and highlight design implications for trustworthy, emotionally resonant digital mental health tools.",
    "authors": [
      "Junsang Park",
      "Sarah Brown",
      "Sharon Lynn Chu"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03413",
    "title": "BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents",
    "abstract": "As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.",
    "authors": [
      "Shu Wang",
      "Yingli Zhou",
      "Yixiang Fang"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03416",
    "title": "TokenScale: Timely and Accurate Autoscaling for Disaggregated LLM Serving with Token Velocity",
    "abstract": "The architectural shift to prefill/decode (PD) disaggregation in LLM serving improves resource utilization but struggles with the bursty nature of modern workloads. Existing autoscaling policies, often retrofitted from monolithic systems like those in AIBrix and DistServe, rely on lagging indicators such as GPU utilization or coarse-grained request counts. This results in slow reactions to load spikes, leading to significant Time-to First-Token (TTFT) and Time-Per-Output-Token (TPOT) SLO violations and costly over-provisioning. We introduce TokenScale, an autoscaling framework that resolves this performance mismatch through two innovations. First, we propose Token Velocity, a novel metric that unifies the prefill, network, and decode stages by quantifying their rate of work. As a leading indicator of system backpressure, it enables proactive scaling. Second, Convertible Decoders allow decoder GPUs to dynamically execute prefill tasks during traffic spikes, creating a rapid-response buffer that absorbs bursts and eliminates the initialization latency of new prefillers. Our evaluation on a GPU cluster with production traces shows TokenScale improves SLO attainment from 50-88% to 80-96% and reduces costs by 4-14% over state-of-the-art systems, including DistServe, BlitzScale, and AIBrix. By uniting a predictive metric with a flexible system design, TokenScale significantly boosts the performance and efficiency of disaggregated LLM serving infrastructure.",
    "authors": [
      "Ruiqi Lai",
      "Hongrui Liu",
      "Chengzhi Lu",
      "Zonghao Liu",
      "Siyu Cao",
      "Siyang Shao",
      "Yixin Zhang",
      "Luo Mai",
      "Dmitrii Ustiugov"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03418",
    "title": "YOLOA: Real-Time Affordance Detection via LLM Adapter",
    "abstract": "Affordance detection aims to jointly address the fundamental \"what-where-how\" challenge in embodied AI by understanding \"what\" an object is, \"where\" the object is located, and \"how\" it can be used. However, most affordance learning methods focus solely on \"how\" objects can be used while neglecting the \"what\" and \"where\" aspects. Other affordance detection methods treat object detection and affordance learning as two independent tasks, lacking effective interaction and real-time capability. To overcome these limitations, we introduce YOLO Affordance (YOLOA), a real-time affordance detection model that jointly handles these two tasks via a large language model (LLM) adapter. Specifically, YOLOA employs a lightweight detector consisting of object detection and affordance learning branches refined through the LLM Adapter. During training, the LLM Adapter interacts with object and affordance preliminary predictions to refine both branches by generating more accurate class priors, box offsets, and affordance gates. Experiments on our relabeled ADG-Det and IIT-Heat benchmarks demonstrate that YOLOA achieves state-of-the-art accuracy (52.8 / 73.1 mAP on ADG-Det / IIT-Heat) while maintaining real-time performance (up to 89.77 FPS, and up to 846.24 FPS for the lightweight variant). This indicates that YOLOA achieves an excellent trade-off between accuracy and efficiency.",
    "authors": [
      "Yuqi Ji",
      "Junjie Ke",
      "Lihuo He",
      "Jun Liu",
      "Kaifan Zhang",
      "Yu-Kun Lai",
      "Guiguang Ding",
      "Xinbo Gao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03419",
    "title": "Comparative algorithm performance evaluation and prediction for the maximum clique problem using instance space analysis",
    "abstract": "The maximum clique problem, a well-known graph-based combinatorial optimization problem, has been addressed through various algorithmic approaches, though systematic analyses of the problem instances remain sparse. This study employs the instance space analysis (ISA) methodology to systematically analyze the instance space of this problem and assess & predict the performance of state-of-the-art (SOTA) algorithms, including exact, heuristic, and graph neural network (GNN)-based methods. A dataset was compiled using graph instances from TWITTER, COLLAB and IMDB-BINARY benchmarks commonly used in graph machine learning research. A set of 33 generic and 2 problem-specific polynomial-time-computable graph-based features, including several spectral properties, was employed for the ISA. A composite performance mea- sure incorporating both solution quality and algorithm runtime was utilized. The comparative analysis demonstrated that the exact algorithm Mixed Order Maximum Clique (MOMC) exhib- ited superior performance across approximately 74.7% of the instance space constituted by the compiled dataset. Gurobi & CliSAT accounted for superior performance in 13.8% and 11% of the instance space, respectively. The ISA-based algorithm performance prediction model run on 34 challenging test instances compiled from the BHOSLIB and DIMACS datasets yielded top-1 and top-2 best performing algorithm prediction accuracies of 88% and 97%, respectively.",
    "authors": [
      "Bharat Sharman",
      "Elkafi Hassini"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03420",
    "title": "HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines",
    "abstract": "Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \\textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation. To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\\% compared to state-of-the-art techniques, reaching 87\\% for C and 81\\% for C++. Our one-hour fuzzing results show that more than 75\\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\\% for source code retrieval, outperforming Fuzz Introspector by more than 30\\%.",
    "authors": [
      "Kang Yang",
      "Yunhang Zhang",
      "Zichuan Li",
      "GuanHong Tao",
      "Jun Xu",
      "XiaoJing Liao"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03421",
    "title": "Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization",
    "abstract": "Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.",
    "authors": [
      "Hexiang Xu",
      "Hengyuan Liu",
      "Yonghao Wu",
      "Xiaolan Kang",
      "Xiang Chen",
      "Yong Liu"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03422",
    "title": "What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models",
    "abstract": "In this paper, we provide a comprehensive overview of existing scene representation methods for robotics, covering traditional representations such as point clouds, voxels, signed distance functions (SDF), and scene graphs, as well as more recent neural representations like Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and the emerging Foundation Models. While current SLAM and localization systems predominantly rely on sparse representations like point clouds and voxels, dense scene representations are expected to play a critical role in downstream tasks such as navigation and obstacle avoidance. Moreover, neural representations such as NeRF, 3DGS, and foundation models are well-suited for integrating high-level semantic features and language-based priors, enabling more comprehensive 3D scene understanding and embodied intelligence. In this paper, we categorized the core modules of robotics into five parts (Perception, Mapping, Localization, Navigation, Manipulation). We start by presenting the standard formulation of different scene representation methods and comparing the advantages and disadvantages of scene representation across different modules. This survey is centered around the question: What is the best 3D scene representation for robotics? We then discuss the future development trends of 3D scene representations, with a particular focus on how the 3D Foundation Model could replace current methods as the unified solution for future robotic applications. The remaining challenges in fully realizing this model are also explored. We aim to offer a valuable resource for both newcomers and experienced researchers to explore the future of 3D scene representations and their application in robotics. We have published an open-source project on GitHub and will continue to add new works and technologies to this project.",
    "authors": [
      "Tianchen Deng",
      "Yue Pan",
      "Shenghai Yuan",
      "Dong Li",
      "Chen Wang",
      "Mingrui Li",
      "Long Chen",
      "Lihua Xie",
      "Danwei Wang",
      "Jingchuan Wang",
      "Javier Civera",
      "Hesheng Wang",
      "Weidong Chen"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03424",
    "title": "DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding",
    "abstract": "State Space Models (SSMs) demonstrate significant potential for long-sequence modeling, but their reliance on input order conflicts with the irregular nature of point clouds. Existing approaches often rely on predefined serialization strategies, which cannot adjust based on diverse geometric structures. To overcome this limitation, we propose \\textbf{DM3D}, a deformable Mamba architecture for point cloud understanding. Specifically, DM3D introduces an offset-guided Gaussian sequencing mechanism that unifies local resampling and global reordering within a deformable scan. The Gaussian-based KNN Resampling (GKR) enhances structural awareness by adaptively reorganizing neighboring points, while the Gaussian-based Differentiable Reordering (GDR) enables end-to-end optimization of serialization order. Furthermore, a Tri-Path Frequency Fusion module enhances feature complementarity and reduces aliasing. Together, these components enable structure-adaptive serialization of point clouds. Extensive experiments on benchmark datasets show that DM3D achieves state-of-the-art performance in classification, few-shot learning, and part segmentation, demonstrating that adaptive serialization effectively unlocks the potential of SSMs for point cloud understanding.",
    "authors": [
      "Bin Liu",
      "Chunyang Wang",
      "Xuelian Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03427",
    "title": "Generalization Evaluation of Deep Stereo Matching Methods for UAV-Based Forestry Applications",
    "abstract": "Autonomous UAV forestry operations require robust depth estimation methods with strong cross-domain generalization. However, existing evaluations focus on urban and indoor scenarios, leaving a critical gap for specialized vegetation-dense environments. We present the first systematic zero-shot evaluation of eight state-of-the-art stereo methods--RAFT-Stereo, IGEV, IGEV++, BridgeDepth, StereoAnywhere, DEFOM (plus baseline methods ACVNet, PSMNet, TCstereo)--spanning iterative refinement, foundation model, and zero-shot adaptation paradigms. All methods are trained exclusively on Scene Flow and evaluated without fine-tuning on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury forestry dataset captured with ZED Mini camera (1920x1080). Performance reveals scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D, 0.83-1.07 px on KITTI; DEFOM: 0.35-4.65 px across benchmarks), while iterative methods maintain cross-domain robustness (IGEV++: 0.36-6.77 px; IGEV: 0.33-21.91 px). Critical finding: RAFT-Stereo exhibits catastrophic ETH3D failure (26.23 px EPE, 98 percent error rate) due to negative disparity predictions, while performing normally on KITTI (0.90-1.11 px). Qualitative evaluation on Canterbury forestry dataset identifies DEFOM as the optimal gold-standard baseline for vegetation depth estimation, exhibiting superior depth smoothness, occlusion handling, and cross-domain consistency compared to IGEV++, despite IGEV++'s finer detail preservation.",
    "authors": [
      "Yida Lin",
      "Bing Xue",
      "Mengjie Zhang",
      "Sam Schofield",
      "Richard Green"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03428",
    "title": "GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test",
    "abstract": "We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.",
    "authors": [
      "Ziyi Ding",
      "Xiao-Ping Zhang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03429",
    "title": "World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations",
    "abstract": "Autonomous navigation of terrestrial robots using Reinforcement Learning (RL) from LIDAR observations remains challenging due to the high dimensionality of sensor data and the sample inefficiency of model-free approaches. Conventional policy networks struggle to process full-resolution LIDAR inputs, forcing prior works to rely on simplified observations that reduce spatial awareness and navigation robustness. This paper presents a novel model-based RL framework built on top of the DreamerV3 algorithm, integrating a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) within a world model to encode high-dimensional LIDAR readings into compact latent representations. These latent features, combined with a learned dynamics predictor, enable efficient imagination-based policy optimization. Experiments on simulated TurtleBot3 navigation tasks demonstrate that the proposed architecture achieves faster convergence and higher success rate compared to model-free baselines such as SAC, DDPG, and TD3. It is worth emphasizing that the DreamerV3-based agent attains a 100% success rate across all evaluated environments when using the full dataset of the Turtlebot3 LIDAR (360 readings), while model-free methods plateaued below 85%. These findings demonstrate that integrating predictive world models with learned latent representations enables more efficient and robust navigation from high-dimensional sensory data.",
    "authors": [
      "Raul Steinmetz",
      "Fabio Demo Rosa",
      "Victor Augusto Kich",
      "Jair Augusto Bottega",
      "Ricardo Bedin Grando",
      "Daniel Fernando Tello Gamarra"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03430",
    "title": "Label-Efficient Hyperspectral Image Classification via Spectral FiLM Modulation of Low-Level Pretrained Diffusion Features",
    "abstract": "Hyperspectral imaging (HSI) enables detailed land cover classification, yet low spatial resolution and sparse annotations pose significant challenges. We present a label-efficient framework that leverages spatial features from a frozen diffusion model pretrained on natural images. Our approach extracts low-level representations from high-resolution decoder layers at early denoising timesteps, which transfer effectively to the low-texture structure of HSI. To integrate spectral and spatial information, we introduce a lightweight FiLM-based fusion module that adaptively modulates frozen spatial features using spectral cues, enabling robust multimodal learning under sparse supervision. Experiments on two recent hyperspectral datasets demonstrate that our method outperforms state-of-the-art approaches using only the provided sparse training labels. Ablation studies further highlight the benefits of diffusion-derived features and spectral-aware fusion. Overall, our results indicate that pretrained diffusion models can support domain-agnostic, label-efficient representation learning for remote sensing and broader scientific imaging tasks.",
    "authors": [
      "Yuzhen Hu",
      "Biplab Banerjee",
      "Saurabh Prasad"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03437",
    "title": "Grokked Models are Better Unlearners",
    "abstract": "Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.",
    "authors": [
      "Yuanbang Liang",
      "Yang Li"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03438",
    "title": "Multimodal Reinforcement Learning with Agentic Verifier for AI Agents",
    "abstract": "Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.",
    "authors": [
      "Reuben Tan",
      "Baolin Peng",
      "Zhengyuan Yang",
      "Hao Cheng",
      "Oier Mees",
      "Theodore Zhao",
      "Andrea Tupini",
      "Isar Meijier",
      "Qianhui Wu",
      "Yuncong Yang",
      "Lars Liden",
      "Yu Gu",
      "Sheng Zhang",
      "Xiaodong Liu",
      "Lijuan Wang",
      "Marc Pollefeys",
      "Yong Jae Lee",
      "Jianfeng Gao"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03439",
    "title": "LLM as Explainable Re-Ranker for Recommendation System",
    "abstract": "The application of large language models (LLMs) in recommendation systems has recently gained traction. Traditional recommendation systems often lack explainability and suffer from issues such as popularity bias. Previous research has also indicated that LLMs, when used as standalone predictors, fail to achieve accuracy comparable to traditional models. To address these challenges, we propose to use LLM as an explainable re-ranker, a hybrid approach that combines traditional recommendation models with LLMs to enhance both accuracy and interpretability. We constructed a dataset to train the re-ranker LLM and evaluated the alignment between the generated dataset and human expectations. Leveraging a two-stage training process, our model significantly improved NDCG, a key ranking metric. Moreover, the re-ranker outperformed a zero-shot baseline in ranking accuracy and interpretability. These results highlight the potential of integrating traditional recommendation models with LLMs to address limitations in existing systems and pave the way for more explainable and fair recommendation frameworks.",
    "authors": [
      "Yaqi Wang",
      "Haojia Sun",
      "Shuting Zhang"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03442",
    "title": "PretrainZero: Reinforcement Active Pretraining",
    "abstract": "Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.",
    "authors": [
      "Xingrun Xing",
      "Zhiyuan Fan",
      "Jie Lou",
      "Guoqi Li",
      "Jiajun Zhang",
      "Debing Zhang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03444",
    "title": "PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers",
    "abstract": "Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.",
    "authors": [
      "Davood Soleymanzadeh",
      "Xiao Liang",
      "Minghui Zheng"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03445",
    "title": "Multi-Aspect Knowledge-Enhanced Medical Vision-Language Pretraining with Multi-Agent Data Generation",
    "abstract": "Vision-language pretraining (VLP) has emerged as a powerful paradigm in medical image analysis, enabling representation learning from large-scale image-text pairs without relying on expensive manual annotations. However, existing methods often struggle with the noise inherent in web-collected data and the complexity of unstructured long medical texts. To address these challenges, we propose a novel VLP framework integrating a Multi-Agent data GENeration (MAGEN) system and Ontology-based Multi-Aspect Knowledge-Enhanced (O-MAKE) pretraining. First, MAGEN enhances data quality by synthesizing knowledge-enriched descriptions via a foundation model-assisted captioning and retrieval-based verification pipeline. Second, O-MAKE addresses the difficulty of learning from long, unstructured texts by decomposing them into distinct knowledge aspects. This facilitates fine-grained alignment at both global and patch levels, while explicitly modeling medical concept relationships through ontology-guided mechanisms. We validate our framework in the field of dermatology, where comprehensive experiments demonstrate the effectiveness of each component. Our approach achieves state-of-the-art zero-shot performance on disease classification and cross-modal retrieval tasks across eight datasets. Our code and the augmented dataset Derm1M-AgentAug, comprising over 400k skin-image-text pairs, will be released at this https URL .",
    "authors": [
      "Xieji Li",
      "Siyuan Yan",
      "Yingsheng Liu",
      "H. Peter Soyer",
      "Monika Janda",
      "Victoria Mar",
      "Zongyuan Ge"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03449",
    "title": "LM-CartSeg: Automated Segmentation of Lateral and Medial Cartilage and Subchondral Bone for Radiomics Analysis",
    "abstract": "Background and Objective: Radiomics of knee MRI requires robust, anatomically meaningful regions of interest (ROIs) that jointly capture cartilage and subchondral bone. Most existing work relies on manual ROIs and rarely reports quality control (QC). We present LM-CartSeg, a fully automatic pipeline for cartilage/bone segmentation, geometric lateral/medial (L/M) compartmentalisation and radiomics analysis. Methods: Two 3D nnU-Net models were trained on SKM-TEA (138 knees) and OAIZIB-CM (404 knees). At test time, zero-shot predictions were fused and refined by simple geometric rules: connected-component cleaning, construction of 10 mm subchondral bone bands in physical space, and a data-driven tibial L/M split based on PCA and k-means. Segmentation was evaluated on an OAIZIB-CM test set (103 knees) and on SKI-10 (100 knees). QC used volume and thickness signatures. From 10 ROIs we extracted 4 650 non-shape radiomic features to study inter-compartment similarity, dependence on ROI size, and OA vs. non-OA classification on OAIZIB-CM Results: Post-processing improved macro ASSD on OAIZIB-CM from 2.63 to 0.36 mm and HD95 from 25.2 to 3.35 mm, with DSC 0.91; zero-shot DSC on SKI-10 was 0.80. The geometric L/M rule produced stable compartments across datasets, whereas a direct L/M nnU-Net showed domain-dependent side swaps. Only 6 to 12 percent of features per ROI were strongly correlated with volume or thickness. Radiomics-based models models restricted to size-linked features. Conclusions: LM-CartSeg yields automatic, QCd ROIs and radiomic features that carry discriminative information beyond simple morphometry, providing a practical foundation for multi-centre knee OA radiomics studies.",
    "authors": [
      "Tongxu Zhang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03450",
    "title": "KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models",
    "abstract": "Understanding and representing the structure of 3D objects in an unsupervised manner remains a core challenge in computer vision and graphics. Most existing unsupervised keypoint methods are not designed for unconditional generative settings, restricting their use in modern 3D generative pipelines; our formulation explicitly bridges this gap. We present an unsupervised framework for learning spatially structured 3D keypoints from point cloud data. These keypoints serve as a compact and interpretable representation that conditions an Elucidated Diffusion Model (EDM) to reconstruct the full shape. The learned keypoints exhibit repeatable spatial structure across object instances and support smooth interpolation in keypoint space, indicating that they capture geometric variation. Our method achieves strong performance across diverse object categories, yielding a 6 percentage-point improvement in keypoint consistency compared to prior approaches.",
    "authors": [
      "Rhys Newbury",
      "Juyan Zhang",
      "Tin Tran",
      "Hanna Kurniawati",
      "Dana Kulić"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03451",
    "title": "GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers",
    "abstract": "Diffusion models have revolutionized video generation, becoming essential tools in creative content generation and physical simulation. Transformer-based architectures (DiTs) and classifier-free guidance (CFG) are two cornerstones of this success, enabling strong prompt adherence and realistic video quality. Despite their versatility and superior performance, these models require intensive computation. Each video generation requires dozens of iterative steps, and CFG doubles the required compute. This inefficiency hinders broader adoption in downstream applications. We introduce GalaxyDiT, a training-free method to accelerate video generation with guidance alignment and systematic proxy selection for reuse metrics. Through rank-order correlation analysis, our technique identifies the optimal proxy for each video model, across model families and parameter scales, thereby ensuring optimal computational reuse. We achieve $1.87\\times$ and $2.37\\times$ speedup on Wan2.1-1.3B and Wan2.1-14B with only 0.97% and 0.72% drops on the VBench-2.0 benchmark. At high speedup rates, our approach maintains superior fidelity to the base model, exceeding prior state-of-the-art approaches by 5 to 10 dB in peak signal-to-noise ratio (PSNR).",
    "authors": [
      "Zhiye Song",
      "Steve Dai",
      "Ben Keller",
      "Brucek Khailany"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03452",
    "title": "A fast stochastic interacting particle-field method for 3D parabolic parabolic Chemotaxis systems: numerical algorithms and error analysis",
    "abstract": "In this paper, we develop a novel numerical framework, the stochastic interacting particle-field method with particle-in-cell acceleration (SIPF-PIC), for the efficient simulation of the three-dimensional (3D) parabolic-parabolic Keller-Segel (KS) systems. The SIPF-PIC method integrates Lagrangian particle dynamics with spectral field solvers, by leveraging localized particle-grid interpolations and fast Fourier transform (FFT) techniques. For $P$ particles and $H$ Fourier modes per spatial dimension, the SIPF-PIC method achieves a computational complexity of $\\mathcal{O}(P + H^3 \\log H)$ per time step, a significant improvement over the original SIPF method (proposed in \\cite{SIPF1}), which has a complexity of $\\mathcal{O}(PH^3)$, while preserving numerical accuracy. Moreover, we establish a rigorous error analysis, proving that the discretization errors are of order $\\mathcal{O}(H^{-16/13}+P^{-1/2}H^{4/13})$. Finally, we present numerical experiments to validate the theoretical convergence rates and demonstrate the computational efficiency of our new method. Notably, these experiments also show that the method captures complex blowup dynamics beyond single-point collapse, including ring-type singularities, where mass dynamically concentrates into evolving annular structures.",
    "authors": [
      "Jingyuan Hu",
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03453",
    "title": "GeoVideo: Introducing Geometric Regularization into Video Generation Model",
    "abstract": "Recent advances in video generation have enabled the synthesis of high-quality and visually realistic clips using diffusion transformer models. However, most existing approaches operate purely in the 2D pixel space and lack explicit mechanisms for modeling 3D structures, often resulting in temporally inconsistent geometries, implausible motions, and structural artifacts. In this work, we introduce geometric regularization losses into video generation by augmenting latent diffusion models with per-frame depth prediction. We adopted depth as the geometric representation because of the great progress in depth prediction and its compatibility with image-based latent encoders. Specifically, to enforce structural consistency over time, we propose a multi-view geometric loss that aligns the predicted depth maps across frames within a shared 3D coordinate system. Our method bridges the gap between appearance generation and 3D structure modeling, leading to improved spatio-temporal coherence, shape consistency, and physical plausibility. Experiments across multiple datasets show that our approach produces significantly more stable and geometrically consistent results than existing baselines.",
    "authors": [
      "Yunpeng Bai",
      "Shaoheng Fang",
      "Chaohui Yu",
      "Fan Wang",
      "Qixing Huang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03454",
    "title": "Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles",
    "abstract": "Interpreting natural-language commands to localize target objects is critical for autonomous driving (AD). Existing visual grounding (VG) methods for autonomous vehicles (AVs) typically struggle with ambiguous, context-dependent instructions, as they lack reasoning over 3D spatial relations and anticipated scene evolution. Grounded in the principles of world models, we propose ThinkDeeper, a framework that reasons about future spatial states before making grounding decisions. At its core is a Spatial-Aware World Model (SA-WM) that learns to reason ahead by distilling the current scene into a command-aware latent state and rolling out a sequence of future latent states, providing forward-looking cues for disambiguation. Complementing this, a hypergraph-guided decoder then hierarchically fuses these states with the multimodal input, capturing higher-order spatial dependencies for robust localization. In addition, we present DrivePilot, a multi-source VG dataset in AD, featuring semantic annotations generated by a Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)-prompted LLM pipeline. Extensive evaluations on six benchmarks, ThinkDeeper ranks #1 on the Talk2Car leaderboard and surpasses state-of-the-art baselines on DrivePilot, MoCAD, and RefCOCO/+/g benchmarks. Notably, it shows strong robustness and efficiency in challenging scenes (long-text, multi-agent, ambiguity) and retains superior performance even when trained on 50% of the data.",
    "authors": [
      "Haicheng Liao",
      "Huanming Shen",
      "Bonan Wang",
      "Yongkang Li",
      "Yihong Tang",
      "Chengyue Wang",
      "Dingyi Zhuang",
      "Kehua Chen",
      "Hai Yang",
      "Chengzhong Xu",
      "Zhenning Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03459",
    "title": "Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion",
    "abstract": "Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control.",
    "authors": [
      "Hidaka Asai",
      "Tomoyuki Noda",
      "Jun Morimoto"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03461",
    "title": "In-Situ Encryption of Single-Transistor Nonvolatile Memories without Density Loss",
    "abstract": "Non-volatile memories (NVMs) offer negligible leakage power consumption, high integration density, and data retention, but their non-volatility also raises the risk of data exposure. Conventional encryption techniques such as the Advanced Encryption Standard (AES) incur large area overheads and performance penalties, motivating lightweight XOR-based in-situ encryption schemes with low area and power requirements. This work proposes an ultra-dense single-transistor encrypted cell using ferroelectric FET (FeFET) devices, which, to our knowledge, is the first to eliminate the two-memory-devices-per-encrypted-cell requirement in XOR-based schemes, enabling encrypted memory arrays to maintain the same number of storage devices as unencrypted arrays. The key idea is an in-memory single-FeFET XOR scheme, where the ciphertext is encoded in the device threshold voltage and leverages the direction-dependent current flow of the FeFET for single-cycle decryption; eliminating complementary bit storage also removes the need for two write cycles, allowing faster encryption. We extend the approach to multi-level-cell (MLC) FeFETs to store multiple bits per transistor. We validate the proposed idea through both simulation and experimental evaluations. Our analysis on a 128x128-bit array shows 2x higher encryption/decryption throughput than prior FeFET work and 45.2x/14.12x improvement over AES, while application-level evaluations using neural-network benchmarks demonstrate average latency reductions of 50% and 95% compared to prior FeFET-based and AES-based schemes, respectively.",
    "authors": [
      "Sanwar Ahmed Ovy",
      "Jiahui Duan",
      "Md Ashraful Islam Romel",
      "Franz Muller",
      "Thomas Kampfe",
      "Kai Ni",
      "Sumitha George"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03462",
    "title": "A Hybrid Deep Learning and Anomaly Detection Framework for Real-Time Malicious URL Classification",
    "abstract": "Malicious URLs remain a primary vector for phishing, malware, and cyberthreats. This study proposes a hybrid deep learning framework combining \\texttt{HashingVectorizer} n-gram analysis, SMOTE balancing, Isolation Forest anomaly filtering, and a lightweight neural network classifier for real-time URL classification. The multi-stage pipeline processes URLs from open-source repositories with statistical features (length, dot count, entropy), achieving $O(NL + EBdh)$ training complexity and a 20\\,ms prediction latency. Empirical evaluation yields 96.4\\% accuracy, 95.4\\% F1-score, and 97.3\\% ROC-AUC, outperforming CNN (94.8\\%) and SVM baselines with a $50\\!\\times$--$100\\!\\times$ speedup (Table~\\ref{tab:comp-complexity}). A multilingual Tkinter GUI (Arabic/English/French) enables real-time threat assessment with clipboard integration. The framework demonstrates superior scalability and resilience against obfuscated URL patterns.",
    "authors": [
      "Berkani Khaled",
      "Zeraoulia Rafik"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03463",
    "title": "Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models",
    "abstract": "Recent large vision-language models (LVLMs) have been applied to diverse VQA tasks. However, achieving practical performance typically requires task-specific fine-tuning with large numbers of image-text pairs, which are costly to collect. In this work, we study text-centric training, a setting where only textual descriptions are available and no real images are provided, as a paradigm for low-cost data scaling. Unlike images, whose collection is often restricted by privacy constraints and scarcity in niche domains, text is widely available. Moreover, text is easily editable, enabling automatic diversification and expansion with LLMs at minimal human effort. While this offers clear advantages over image collection in terms of scalability and cost, training on raw text without images still yields limited gains on VQA tasks because of the image-text modality gap. To address this issue, we propose a Text-Printed Image (TPI), which generates synthetic images by directly rendering the given textual description on a plain white canvas. This simple rendering projects text into the image modality and can be integrated into arbitrary existing LVLM training pipelines at low cost. Moreover, TPI preserves the semantics of the text, whereas text-to-image models often fail to do. Across four models and seven benchmarks, our systematic experiments show that TPI enables more effective text-centric training than synthetic images generated by a diffusion model. We further explore TPI as a low-cost data-augmentation strategy and demonstrate its practical utility. Overall, our findings highlight the significant potential of text-centric training and, more broadly, chart a path toward fully automated data generation for LVLMs.",
    "authors": [
      "Shojiro Yamabe",
      "Futa Waseda",
      "Daiki Shiono",
      "Tsubasa Takahashi"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03464",
    "title": "Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention",
    "abstract": "In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.",
    "authors": [
      "Yujing Liu",
      "Chen Yang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03465",
    "title": "Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits",
    "abstract": "In this study, we more rigorously evaluated our attack script $\\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\\textit{TraceTarnish}$ data was then further augmented by $\\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\\_FUNC\\_A$ $\\&$ $L\\_FUNC\\_T$); content words and content word types ($L\\_CONT\\_A$ $\\&$ $L\\_CONT\\_T$); and the Type-Token Ratio ($ST\\_TYPE\\_TOKEN\\_RATIO\\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. \"In trying to erase a trace, you often imprint a larger one.\" Armed with this understanding, we framed $\\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.",
    "authors": [
      "Robert Dilworth"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03466",
    "title": "AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation",
    "abstract": "Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation. We introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry. Each agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively. Using a diverse set of current-generation and open-source LLMs, we show that (i) strong models such as GPT-5 and Claude-4.0 reliably converge across puzzle sizes on the solution by sharing complete information in two turns, (ii) weaker models often ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance. These findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals. AsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.",
    "authors": [
      "Xavier Cadet",
      "Edward Koh",
      "Peter Chin"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03467",
    "title": "Bayesian Event-Based Model for Disease Subtype and Stage Inference",
    "abstract": "Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.",
    "authors": [
      "Hongtao Hao",
      "Joseph L. Austerweil"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03470",
    "title": "Difference Decomposition Networks for Infrared Small Target Detection",
    "abstract": "Infrared small target detection (ISTD) faces two major challenges: a lack of discernible target texture and severe background clutter, which results in the background obscuring the target. To enhance targets and suppress backgrounds, we propose the Basis Decomposition Module (BDM) as an extensible and lightweight module based on basis decomposition, which decomposes a complex feature into several basis features and enhances certain information while eliminating redundancy. Extending BDM leads to a series of modules, including the Spatial Difference Decomposition Module (SD$^\\mathrm{2}$M), Spatial Difference Decomposition Downsampling Module (SD$^\\mathrm{3}$M), and Temporal Difference Decomposition Module (TD$^\\mathrm{2}$M). Based on these modules, we develop the Spatial Difference Decomposition Network (SD$^\\mathrm{2}$Net) for single-frame ISTD (SISTD) and the Spatiotemporal Difference Decomposition Network (STD$^\\mathrm{2}$Net) for multi-frame ISTD (MISTD). SD$^\\mathrm{2}$Net integrates SD$^\\mathrm{2}$M and SD$^\\mathrm{3}$M within an adapted U-shaped architecture. We employ TD$^\\mathrm{2}$M to introduce motion information, which transforms SD$^\\mathrm{2}$Net into STD$^\\mathrm{2}$Net. Extensive experiments on SISTD and MISTD datasets demonstrate state-of-the-art (SOTA) performance. On the SISTD task, SD$^\\mathrm{2}$Net performs well compared to most established networks. On the MISTD datasets, STD$^\\mathrm{2}$Net achieves a mIoU of 87.68\\%, outperforming SD$^\\mathrm{2}$Net, which achieves a mIoU of 64.97\\%. Our codes are available: this https URL .",
    "authors": [
      "Chen Hu",
      "Mingyu Zhou",
      "Shuai Yuan",
      "Hongbo Hu",
      "Xiangyu Qiu",
      "Junhai Luo",
      "Tian Pu",
      "Xiyin Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03471",
    "title": "SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening",
    "abstract": "The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.",
    "authors": [
      "Ian Henriques",
      "Lynda Elhassar",
      "Sarvesh Relekar",
      "Denis Walrave",
      "Shayan Hassantabar",
      "Vishu Ghanakota",
      "Adel Laoui",
      "Mahmoud Aich",
      "Rafia Tir",
      "Mohamed Zerguine",
      "Samir Louafi",
      "Moncef Kimouche",
      "Emmanuel Cosson",
      "Niraj K Jha"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03474",
    "title": "Procedural Mistake Detection via Action Effect Modeling",
    "abstract": "Mistake detection in procedural tasks is essential for building intelligent systems that support learning and task execution. Existing approaches primarily analyze how an action is performed, while overlooking what it produces, i.e., the \\textbf{action effect}. Yet many errors manifest not in the execution itself but in the resulting outcome, such as an unintended object state or incorrect spatial arrangement. To address this gap, we propose Action Effect Modeling (AEM), a unified framework that jointly captures action execution and its outcomes through a probabilistic formulation. AEM first identifies the outcome of an action by selecting the most informative effect frame based on semantic relevance and visual quality. It then extracts complementary cues from visual grounding and symbolic scene graphs, aligning them in a shared latent space to form robust effect-aware representations. To detect mistakes, we further design a prompt-based detector that incorporates task-specific prompts and aligns each action segment with its intended execution semantics. Our approach achieves state-of-the-art performance on the EgoPER and CaptainCook4D benchmarks under the challenging one-class classification (OCC) setting. These results demonstrate that modeling both execution and outcome yields more reliable mistake detection, and highlight the potential of effect-aware representations to benefit a broader range of downstream applications.",
    "authors": [
      "Wenliang Guo",
      "Yujiang Pu",
      "Yu Kong"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03475",
    "title": "Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression",
    "abstract": "Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.",
    "authors": [
      "Hongtao Hao",
      "Joseph L. Austerweil"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03476",
    "title": "ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms",
    "abstract": "Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop\" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.",
    "authors": [
      "Juan Diego Toscano",
      "Daniel T. Chen",
      "George Em Karniadakis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03477",
    "title": "Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis",
    "abstract": "Vision-language models achieve expert-level performance on medical imaging tasks but exhibit significant diagnostic accuracy disparities across demographic groups. We introduce fairness-aware Low-Rank Adaptation for medical VLMs, combining parameter efficiency with explicit fairness optimization. Our key algorithmic contribution is a differentiable MaxAccGap loss that enables end-to-end optimization of accuracy parity across demographic groups. We propose three methods: FR-LoRA integrates MaxAccGap regularization into the training objective, GR-LoRA applies inverse frequency weighting to balance gradient contributions, and Hybrid-LoRA combines both this http URL on 10,000 glaucoma fundus images, GR-LoRA reduces diagnostic accuracy disparities by 69% while maintaining 53.15% overall accuracy. Ablation studies reveal that strong regularization strength achieves optimal fairness with minimal accuracy trade-off, and race-specific optimization yields 60% disparity reduction. Our approach requires only 0.24% trainable parameters, enabling practical deployment of fair medical AI in resource-constrained healthcare settings.",
    "authors": [
      "Zijian Gu",
      "Yuxi Liu",
      "Zhenhao Zhang",
      "Song Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03479",
    "title": "Towards Object-centric Understanding for Instructional Videos",
    "abstract": "Understanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.",
    "authors": [
      "Wenliang Guo",
      "Yu Kong"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03483",
    "title": "Numerical Analysis of the 2D Stochastic Navier-Stokes Equations: Convergence under Transport Noise and No-slip Boundary Conditions",
    "abstract": "This work is concerned with the numerical approximation of the two-dimensional stochastic Navier-Stokes equation with transport noise and no-slip boundary conditions on a convex polygonal domain. The analysis is challenged by the solution's low spatial regularity and the non-Lipschitz nonlinearity. We derive a convergence rate in the mean-square sense for a spatial semidiscretization. Furthermore, for the full discretization, we prove convergence in probability and establish an explicit rate with respect to the time step.",
    "authors": [
      "Binjie Li",
      "Qin Zhou"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03485",
    "title": "CellScout: Visual Analytics for Mining Biomarkers in Cell State Discovery",
    "abstract": "Cell state discovery is crucial for understanding biological systems and enhancing medical outcomes. A key aspect of this process is identifying distinct biomarkers that define specific cell states. However, difficulties arise from the co-discovery process of cell states and biomarkers: biologists often use dimensionality reduction to visualize cells in a two- dimensional space. Then they usually interpret visually clustered cells as distinct states, from which they seek to identify unique biomarkers. However, this assumption is often invalid due to internal inconsistencies in a cluster, making the process trial-and-error and highly uncertain. Therefore, biologists urgently need effective tools to help uncover the hidden association relationships between different cell populations and their potential biomarkers. To address this problem, we first designed a machine-learning algorithm based on the Mixture-of-Experts (MoE) technique to identify meaningful associations between cell populations and biomarkers. We further developed a visual analytics system, CellScout, in collaboration with biologists, to help them explore and refine these association relationships to advance cell state discovery. We validated our system through expert interviews, from which we further selected a representative case to demonstrate its effectiveness in discovering new cell states.",
    "authors": [
      "Rui Sheng",
      "Zelin Zang",
      "Jiachen Wang",
      "Yan Luo",
      "Zixin Chen",
      "Yan Zhou",
      "Shaolun Ruan",
      "Huamin Qu"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03487",
    "title": "Double-Edge-Assisted Computation Offloading and Resource Allocation for Space-Air-Marine Integrated Networks",
    "abstract": "In this paper, we propose a double-edge-assisted computation offloading and resource allocation scheme tailored for space-air-marine integrated networks (SAMINs). Specifically, we consider a scenario where both unmanned aerial vehicles (UAVs) and a low earth orbit (LEO) satellite are equipped with edge servers, providing computing services for maritime autonomous surface ships (MASSs). Partial computation workloads of MASSs can be offloaded to both UAVs and the LEO satellite, concurrently, for processing via a multi-access approach. To minimize the energy consumption of SAMINs under latency constraints, we formulate an optimization problem and propose energy efficient algorithms to jointly optimize offloading mode, offloading volume, and computing resource allocation of the LEO satellite and the UAVs, respectively. We further exploit an alternating optimization (AO) method and a layered approach to decompose the original problem to attain the optimal solutions. Finally, we conduct simulations to validate the effectiveness and efficiency of the proposed scheme in comparison with benchmark algorithms.",
    "authors": [
      "Zhen Wang",
      "Bin Lin",
      "Qiang"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03491",
    "title": "Modal Logical Neural Networks",
    "abstract": "We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\\Box$ and $\\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure. This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.",
    "authors": [
      "Antonin Sulc"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03492",
    "title": "Functional Python Programming in Introductory Computer Science Courses",
    "abstract": "The functional programming paradigm has a long and storied history, with its beginnings in the Lambda Calculus. In recent decades, pure functional languages such as Haskell have been shown to be highly effective in producing robust software due to immutable data structures, among other functional features. The advantages of programming with immutable data structures can also be had in non-functional languages such as Python. Over the years, non-functional languages have introduced immutable data structures as well as comprehension and lambda expressions, and it is possible to program in a purely functional style in them. In this paper, we present a ``best practice'' idea in introductory programming classes that forces students to learn and complete programming assignments in a purely functional subset of Python. By doing so, the student can learn functional ideas such as immutability, pure functions with no side effects, and stateless programming. We define a functional subset of Python and illustrate the best practice using small examples. We strongly feel that students in computing need familiarity with pure functional programming and argue that this can be taught in introductory programming courses that use Python.",
    "authors": [
      "Rajshekhar Sunderraman"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03494",
    "title": "A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention",
    "abstract": "Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.",
    "authors": [
      "Di Xiu",
      "Hongyin Tang",
      "Bolin Rong",
      "Lizhi Yan",
      "Jingang Wang",
      "Yifan Lu",
      "Xunliang Cai"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03495",
    "title": "EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media",
    "abstract": "Mental health is an urgent societal issue, and social scientists are increasingly turning to online mental health communities (OMHCs) to analyze user behavior data for early intervention. However, existing sequence mining techniques fall short of the urgent need to explore the behavior progression of different groups (e.g., recovery or deterioration groups) and track the potential long-term impact of behaviors on mental health status. To address this issue, we introduce EMINDS, a visual analytics system built on a novel automatic mining pipeline that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes a set of interactive visualizations that summarize the meaning of each behavior stage and the evolution of different stage patterns. We feature a pattern-centric Sankey diagram to reveal contextual information about the impact of stage patterns on mental health, helping experts understand the specific changes in sequences before and after a stage pattern. We evaluated the effectiveness and usability of EMINDS through two case studies and expert interviews, which examined the potential stage patterns impacting long-term mental health by analyzing user behaviors on Reddit.",
    "authors": [
      "Rui Sheng",
      "Yifang Wang",
      "Xingbo Wang",
      "Shun Dai",
      "Qingyu Guo",
      "Tai-Quan Peng",
      "Huamin Qu",
      "Dongyu Liu"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03496",
    "title": "Constraint-Preserving High-Order Compact OEDG Method for Spherically Symmetric Einstein-Euler System",
    "abstract": "Numerical simulation of the spherically symmetric Einstein--Euler (EE) system faces severe challenges due to the stringent physical admissibility constraints of relativistic fluids and the geometric singularities inherent in metric evolution. This paper proposes a high-order Constraint-Preserving (CP) compact Oscillation-Eliminating Discontinuous Galerkin (cOEDG) method specifically tailored to address these difficulties. The method integrates a scale-invariant oscillation-eliminating mechanism [M. Peng, Z. Sun, K. Wu, Math. Comp., 94: 1147--1198, 2025] into a compact Runge--Kutta DG framework. By characterizing the convex invariant region of the hydrodynamic subsystem with general barotropic equations of state, we prove that the proposed scheme preserves physical realizability (specifically, positive density and subluminal velocity) directly in terms of conservative variables, thereby eliminating the need for complex primitive-variable checks. To ensure the geometric validity of the spacetime, we introduce a bijective transformation of the metric potentials. Rather than evolving the constrained metric components directly, the scheme advances unconstrained auxiliary variables whose inverse mapping automatically enforces strict positivity and asymptotic bounds without any limiters. Combined with a compatible high-order boundary treatment, the resulting CPcOEDG method exhibits robust stability and design-order accuracy in capturing strong gravity-fluid interactions, as demonstrated by simulations of black hole accretion and relativistic shock waves.",
    "authors": [
      "Yuchen Huang",
      "Manting Peng",
      "Kailiang Wu"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03499",
    "title": "NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation",
    "abstract": "The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM's adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.",
    "authors": [
      "Renqi Chen",
      "Haoyang Su",
      "Shixiang Tang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03500",
    "title": "EEA: Exploration-Exploitation Agent for Long Video Understanding",
    "abstract": "Long-form video understanding requires efficient navigation of extensive visual data to pinpoint sparse yet critical information. Current approaches to longform video understanding either suffer from severe computational overhead due to dense preprocessing, or fail to effectively balance exploration and exploitation, resulting in incomplete information coverage and inefficiency. In this work, we introduce EEA, a novel video agent framework that archives exploration-exploitation balance through semantic guidance with hierarchical tree search process. EEA autonomously discovers and dynamically updates task-relevant semantic queries, and collects video frames closely matched to these queries as semantic anchors. During the tree search process, instead of uniform expansion, EEA preferentially explores semantically relevant frames while ensuring sufficient coverage within unknown segments. Moreover, EEA adaptively combines intrinsic rewards from visionlanguage models (VLMs) with semantic priors by explicitly modeling uncertainty to achieve stable and precise evaluation of video segments. Experiments across various long-video benchmarks validate the superior performance and computational efficiency of our proposed method.",
    "authors": [
      "Te Yang",
      "Xiangyu Zhu",
      "Bo Wang",
      "Quan Chen",
      "Peng Jiang",
      "Zhen Lei"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03501",
    "title": "SocraticAI: Transforming LLMs into Guided CS Tutors Through Scaffolded Interaction",
    "abstract": "We present SocraticAI, a scaffolded AI tutoring system that integrates large language models (LLMs) into undergraduate Computer Science education through structured constraints rather than prohibition. The system enforces well-formulated questions, reflective engagement, and daily usage limits while providing Socratic dialogue scaffolds. Unlike traditional AI bans, our approach cultivates responsible and strategic AI interaction skills through technical guardrails, including authentication, query validation, structured feedback, and RAG-based course grounding. Initial deployment demonstrates that students progress from vague help-seeking to sophisticated problem decomposition within 2-3 weeks, with over 75% producing substantive reflections and displaying emergent patterns of deliberate, strategic AI use.",
    "authors": [
      "Karthik Sunil",
      "Aalok Thakkar"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03503",
    "title": "Understanding LLM Reasoning for Abstractive Summarization",
    "abstract": "While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.",
    "authors": [
      "Haohan Yuan",
      "Siu Cheung Hui",
      "Haopeng Zhang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03507",
    "title": "Ancient Algorithms for a Modern Curriculum",
    "abstract": "Despite ongoing calls for inclusive and culturally responsive pedagogy in computing education, the teaching of algorithms remains largely decontextualized. Foundational computer science courses often present algorithmic thinking as purely formal and ahistorical, emphasizing efficiency, correctness, and abstraction. When history is mentioned, it usually centers on the modern development of digital computers, highlighting figures such as Turing, von Neumann, and Babbage. This narrow view misrepresents the origins of algorithmic reasoning and perpetuates a Eurocentric worldview that undermines equity and representation in STEM. In contrast, algorithmic thinking predates electronic computers by millennia and has deep roots in ancient civilizations including India, China, Babylon, and Egypt. Our work responds to this gap by embedding algorithm instruction in broader historical and cultural contexts, with particular attention to classical Indian contributions.",
    "authors": [
      "Aalok Thakkar"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03508",
    "title": "Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation",
    "abstract": "Recent domain generalized semantic segmentation (DGSS) studies have achieved notable improvements by distilling semantic knowledge from Vision-Language Models (VLMs). However, they overlook the semantic misalignment between visual and textual contexts, which arises due to the rigidity of a fixed context prompt learned on a single source domain. To this end, we present a novel domain generalization framework for semantic segmentation, namely Domain-aware Prompt-driven Masked Transformer (DPMFormer). Firstly, we introduce domain-aware prompt learning to facilitate semantic alignment between visual and textual cues. To capture various domain-specific properties with a single source dataset, we propose domain-aware contrastive learning along with the texture perturbation that diversifies the observable domains. Lastly, to establish a framework resilient against diverse environmental changes, we have proposed the domain-robust consistency learning which guides the model to minimize discrepancies of prediction from original and the augmented images. Through experiments and analyses, we demonstrate the superiority of the proposed framework, which establishes a new state-of-the-art on various DGSS benchmarks. The code is available at this https URL .",
    "authors": [
      "Seogkyu Jeon",
      "Kibeom Hong",
      "Hyeran Byun"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03509",
    "title": "AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model",
    "abstract": "This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.",
    "authors": [
      "Kwaku Opoku-Ware",
      "Gideon Opoku"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03510",
    "title": "CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving",
    "abstract": "Crowdsourcing enables scalable autonomous driving map construction, but low-cost sensor noise hinders quality from improving with data volume. We propose CSMapping, a system that produces accurate semantic maps and topological road centerlines whose quality consistently increases with more crowdsourced data. For semantic mapping, we train a latent diffusion model on HD maps (optionally conditioned on SD maps) to learn a generative prior of real-world map structure, without requiring paired crowdsourced/HD-map supervision. This prior is incorporated via constrained MAP optimization in latent space, ensuring robustness to severe noise and plausible completion in unobserved areas. Initialization uses a robust vectorized mapping module followed by diffusion inversion; optimization employs efficient Gaussian-basis reparameterization, projected gradient descent zobracket multi-start, and latent-space factor-graph for global consistency. For topological mapping, we apply confidence-weighted k-medoids clustering and kinematic refinement to trajectories, yielding smooth, human-like centerlines robust to trajectory variation. Experiments on nuScenes, Argoverse 2, and a large proprietary dataset achieve state-of-the-art semantic and topological mapping performance, with thorough ablation and scalability studies.",
    "authors": [
      "Zhijian Qiao",
      "Zehuan Yu",
      "Tong Li",
      "Chih-Chung Chou",
      "Wenchao Ding",
      "Shaojie Shen"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03512",
    "title": "Physics-Driven Learning Framework for Tomographic Tactile Sensing",
    "abstract": "Electrical impedance tomography (EIT) provides an attractive solution for large-area tactile sensing due to its minimal wiring and shape flexibility, but its nonlinear inverse problem often leads to severe artifacts and inaccurate contact reconstruction. This work presents PhyDNN, a physics-driven deep reconstruction framework that embeds the EIT forward model directly into the learning objective. By jointly minimizing the discrepancy between predicted and ground-truth conductivity maps and enforcing consistency with the forward PDE, PhyDNN reduces the black-box nature of deep networks and improves both physical plausibility and generalization. To enable efficient backpropagation, we design a differentiable forward-operator network that accurately approximates the nonlinear EIT response, allowing fast physics-guided training. Extensive simulations and real tactile experiments on a 16-electrode soft sensor show that PhyDNN consistently outperforms NOSER, TV, and standard DNNs in reconstructing contact shape, location, and pressure distribution. PhyDNN yields fewer artifacts, sharper boundaries, and higher metric scores, demonstrating its effectiveness for high-quality tomographic tactile sensing.",
    "authors": [
      "Xuanxuan Yang",
      "Xiuyang Zhang",
      "Haofeng Chen",
      "Gang Ma",
      "Xiaojie Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03514",
    "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval",
    "abstract": "Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.",
    "authors": [
      "Adithya S Kolavi",
      "Vyoman Jain"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03518",
    "title": "From Reliability to Security: How RIS-Assisted Adaptive SM and SSK Enhances Wireless Systems",
    "abstract": "This paper proposes two novel wireless transmission schemes, namely reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme and RIS-assisted received adaptive space shift keying (RASSK) scheme, designed to enhance spectral efficiency (SE) and physical layer security (PLS).In both proposed schemes, transmitting bits are dynamically mapped at receive antennas by leveraging the characteristics of the RIS in each time slot, which enables the enhancement of signal-to-noise ratio (SNR) at specific selected antennas with near few power, thus leading a reliable and green wireless communication. This adaptive approach facilitates the conveyance of extra bits to the receiver, which means it needs less cost of radio-frequency chains at transmitter while improving SE. Besides, the proposed schemes offer an inherent PLS security advantage, as the eavesdropper is unable to completely detect signals reflected from the RIS. To comprehensively evaluate the performance of the proposed RASM and RASSK schemes, this paper presents a detailed analytical performance of their spectral efficiency, detection complexity, bit error rate, and secrecy rate, which are accompanied by insightful findings and conclusions. Simulation and analytical results demonstrate the superiority of the proposed schemes, showcasing their improved error performance and robustness against wiretapping, while also highlighting the potential of the RASM and RASSK schemes for future wireless applications.",
    "authors": [
      "Chaorong Zhang",
      "Benjamin K. Ng",
      "Ke Wang",
      "Hui Xu",
      "Chan-Tong Lam"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03519",
    "title": "Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems",
    "abstract": "Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects. A key tenet of Systems Engineering and acquisition engineering is centred around a \"left-shift\" in test and evaluation activities to earlier in the system lifecycle, to allow for \"accelerated delivery of [systems] that work\". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.",
    "authors": [
      "Ben Larwood",
      "Oliver J. Sutton",
      "Callum Cockburn"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03520",
    "title": "FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation",
    "abstract": "We present FloodDiffusion, a new framework for text-driven, streaming human motion generation. Given time-varying text prompts, FloodDiffusion generates text-aligned, seamless motion sequences with real-time latency. Unlike existing methods that rely on chunk-by-chunk or auto-regressive model with diffusion head, we adopt a diffusion forcing framework to model this time-series generation task under time-varying control events. We find that a straightforward implementation of vanilla diffusion forcing (as proposed for video models) fails to model real motion distributions. We demonstrate that to guarantee modeling the output distribution, the vanilla diffusion forcing must be tailored to: (i) train with a bi-directional attention instead of casual attention; (ii) implement a lower triangular time scheduler instead of a random one; (iii) utilize a continues time-varying way to introduce text conditioning. With these improvements, we demonstrate in the first time that the diffusion forcing-based framework achieves state-of-the-art performance on the streaming motion generation task, reaching an FID of 0.057 on the HumanML3D benchmark. Models, code, and weights are available. this https URL",
    "authors": [
      "Yiyi Cai",
      "Yuhan Wu",
      "Kunhang Li",
      "You Zhou",
      "Bo Zheng",
      "Haiyang Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03521",
    "title": "Cross-Space Synergy: A Unified Framework for Multimodal Emotion Recognition in Conversation",
    "abstract": "Multimodal Emotion Recognition in Conversation (MERC) aims to predict speakers' emotions by integrating textual, acoustic, and visual cues. Existing approaches either struggle to capture complex cross-modal interactions or experience gradient conflicts and unstable training when using deeper architectures. To address these issues, we propose Cross-Space Synergy (CSS), which couples a representation component with an optimization component. Synergistic Polynomial Fusion (SPF) serves the representation role, leveraging low-rank tensor factorization to efficiently capture high-order cross-modal interactions. Pareto Gradient Modulator (PGM) serves the optimization role, steering updates along Pareto-optimal directions across competing objectives to alleviate gradient conflicts and improve stability. Experiments show that CSS outperforms existing representative methods on IEMOCAP and MELD in both accuracy and training stability, demonstrating its effectiveness in complex multimodal scenarios.",
    "authors": [
      "Xiaosen Lyu",
      "Jiayu Xiong",
      "Yuren Chen",
      "Wanlong Wang",
      "Xiaoqing Dai",
      "Jing Wang"
    ],
    "primary_category": "cs.MM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03522",
    "title": "MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization",
    "abstract": "Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.",
    "authors": [
      "Gihyeon Lee",
      "Jungwoo Lee",
      "Juwon Kim",
      "Young-Sik Shin",
      "Younggun Cho"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03525",
    "title": "Adaptive sampling using variational autoencoder and reinforcement learning",
    "abstract": "Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.",
    "authors": [
      "Adil Rasheed",
      "Mikael Aleksander Jansen Shahly",
      "Muhammad Faisal Aftab"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03528",
    "title": "Multi-Agent Reinforcement Learning with Communication-Constrained Priors",
    "abstract": "Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.",
    "authors": [
      "Guang Yang",
      "Tianpei Yang",
      "Jingwen Qiao",
      "Yanqing Wu",
      "Jing Huo",
      "Xingguo Chen",
      "Yang Gao"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03532",
    "title": "OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation",
    "abstract": "Generalizing open-vocabulary 3D instance segmentation (OV-3DIS) to diverse, unstructured, and mesh-free environments is crucial for robotics and AR/VR, yet remains a significant challenge. We attribute this to two key limitations of existing methods: (1) proposal generation relies on dataset-specific proposal networks or mesh-based superpoints, rendering them inapplicable in mesh-free scenarios and limiting generalization to novel scenes; and (2) the weak textual reasoning of CLIP-based classifiers, which struggle to recognize compositional and functional user queries. To address these issues, we introduce OpenTrack3D, a generalizable and accurate framework. Unlike methods that rely on pre-generated proposals, OpenTrack3D employs a novel visual-spatial tracker to construct cross-view consistent object proposals online. Given an RGB-D stream, our pipeline first leverages a 2D open-vocabulary segmenter to generate masks, which are lifted to 3D point clouds using depth. Mask-guided instance features are then extracted using DINO feature maps, and our tracker fuses visual and spatial cues to maintain instance consistency. The core pipeline is entirely mesh-free, yet we also provide an optional superpoints refinement module to further enhance performance when scene mesh is available. Finally, we replace CLIP with a multi-modal large language model (MLLM), significantly enhancing compositional reasoning for complex user queries. Extensive experiments on diverse benchmarks, including ScanNet200, Replica, ScanNet++, and SceneFun3D, demonstrate state-of-the-art performance and strong generalization capabilities.",
    "authors": [
      "Zhishan Zhou",
      "Siyuan Wei",
      "Zengran Wang",
      "Chunjie Wang",
      "Xiaosheng Yan",
      "Xiao Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03534",
    "title": "Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation",
    "abstract": "Achieving precise alignment between user intent and generated visuals remains a central challenge in text-to-visual generation, as a single attempt often fails to produce the desired output. To handle this, prior approaches mainly scale the visual generation process (e.g., increasing sampling steps or seeds), but this quickly leads to a quality plateau. This limitation arises because the prompt, crucial for guiding generation, is kept fixed. To address this, we propose Prompt Redesign for Inference-time Scaling, coined PRIS, a framework that adaptively revises the prompt during inference in response to the scaled visual generations. The core idea of PRIS is to review the generated visuals, identify recurring failure patterns across visuals, and redesign the prompt accordingly before regenerating the visuals with the revised prompt. To provide precise alignment feedback for prompt revision, we introduce a new verifier, element-level factual correction, which evaluates the alignment between prompt attributes and generated visuals at a fine-grained level, achieving more accurate and interpretable assessments than holistic measures. Extensive experiments on both text-to-image and text-to-video benchmarks demonstrate the effectiveness of our approach, including a 15% gain on VBench 2.0. These results highlight that jointly scaling prompts and visuals is key to fully leveraging scaling laws at inference-time. Visualizations are available at the website: this https URL .",
    "authors": [
      "Subin Kim",
      "Sangwoo Mo",
      "Mamshad Nayeem Rizve",
      "Yiran Xu",
      "Difan Liu",
      "Jinwoo Shin",
      "Tobias Hinz"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03536",
    "title": "Mobility Induced Sensitivity of UAV based Nodes to Jamming in Private 5G Airfield Networks An Experimental Study",
    "abstract": "This work presents an experimental performance evaluation of a private 5G airfield network under controlled directional SDR jamming attacks targeting UAV-based UE nodes. Using a QualiPoc Android UE, mounted as a payload on a quadcopter UAV, we conducted a series of experiments to evaluate signal degradation, handover performance, and ser-vice stability in the presence of constant directional jamming. The conducted experiments aimed to examine the effects of varying travel speeds, altitudes, and moving patterns of a UAV-based UE to record and analyze the key physical-layer and network-layer metrics such as CQI, MCS, RSRP, SINR, BLER, Net PDSCH Throughput and RLF. The re-sults of this work describe the link stability and signal degradation dependencies, caused by the level of mobility of the UAV-based UE nodes during autonomous and automatic operation in private 5G Airfield networks",
    "authors": [
      "Pavlo Mykytyn",
      "Ronald Chitauro",
      "Onur Yener",
      "Peter Langendoerfer"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03537",
    "title": "Parameter-Efficient Augment Plugin for Class-Incremental Learning",
    "abstract": "Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL this http URL treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.",
    "authors": [
      "Zhiming Xu",
      "Baile Xu",
      "Jian Zhao",
      "Furao Shen",
      "Suorong Yang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03538",
    "title": "AdaPower: Specializing World Foundation Models for Predictive Manipulation",
    "abstract": "World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \\textbf{AdaPower} (\\textbf{Ada}pt and Em\\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.",
    "authors": [
      "Yuhang Huang",
      "Shilong Zou",
      "Jiazhao Zhang",
      "Xinwang Liu",
      "Ruizhen Hu",
      "Kai Xu"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03540",
    "title": "CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation",
    "abstract": "Cooking is a sequential and visually grounded activity, where each step such as chopping, mixing, or frying carries both procedural logic and visual semantics. While recent diffusion models have shown strong capabilities in text-to-image generation, they struggle to handle structured multi-step scenarios like recipe illustration. Additionally, current recipe illustration methods are unable to adjust to the natural variability in recipe length, generating a fixed number of images regardless of the actual instructions structure. To address these limitations, we present CookAnything, a flexible and consistent diffusion-based framework that generates coherent, semantically distinct image sequences from textual cooking instructions of arbitrary length. The framework introduces three key components: (1) Step-wise Regional Control (SRC), which aligns textual steps with corresponding image regions within a single denoising process; (2) Flexible RoPE, a step-aware positional encoding mechanism that enhances both temporal coherence and spatial diversity; and (3) Cross-Step Consistency Control (CSCC), which maintains fine-grained ingredient consistency across steps. Experimental results on recipe illustration benchmarks show that CookAnything performs better than existing methods in training-based and training-free settings. The proposed framework supports scalable, high-quality visual synthesis of complex multi-step instructions and holds significant potential for broad applications in instructional media, and procedural content creation.",
    "authors": [
      "Ruoxuan Zhang",
      "Bin Wen",
      "Hongxia Xie",
      "Yi Yao",
      "Songhan Zuo",
      "Jian-Yu Jiang-Lin",
      "Hong-Han Shuai",
      "Wen-Huang Cheng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03542",
    "title": "V-ITI: Mitigating Hallucinations in Multimodal Large Language Models via Visual Inference-Time Intervention",
    "abstract": "Multimodal Large Language Models (MLLMs) excel in numerous vision-language tasks yet suffer from hallucinations, producing content inconsistent with input visuals, that undermine reliability in precision-sensitive domains. This issue stems from a fundamental problem of visual neglect, where models fail to adequately prioritize input images. Existing methods typically alleviate hallucinations by intervening in the attention score or output logits, focusing on \"how to intervene\" but overlooking the prerequisite \"when to intervene\", which leads to the \"over-intervention\" problem and subsequently introduces new hallucinations and unnecessary computational overhead. To address this gap, we first investigate the mechanism of visual neglect and reveal it can be accurately detected via head-level activation patterns in MLLMs. We thus propose V-ITI, a lightweight visual inference-time intervention framework integrating a Visual Neglect Detector that identifies visual neglect via head-level discriminative probes and a Visual Recall Intervenor that modulates activations with prestored visual activation information only when the visual neglect is detected. Extensive experiments across eight benchmarks and different MLLM families demonstrate that V-ITI consistently mitigates vision-related hallucinations while preserving general task performance.",
    "authors": [
      "Nan Sun",
      "Zhenyu Zhang",
      "Xixun Lin",
      "Kun Wang",
      "Yanmin Shang",
      "Naibin Gu",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Haifeng Wang",
      "Yanan Cao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03545",
    "title": "Resilient AFE Drive Control using Neural Networks with Tracking Guarantees",
    "abstract": "Industrial installations across several sectors have seen a dramatic increase in productivity, accuracy and efficiency over the last decade due to expanded utilization of medium voltage, variable speed power electronic converters to drive their processes. Specifically, active front-end (AFE) drives have become popular due to their ability to deliver power while maintaining safe electrical setpoints. However, under abnormal grid conditions such as phase loss, conventional AFE control may fail to enforce safety constraints, potentially leading to drive shutdown and significant financial losses. In this work, we propose using reference-tracking Performance Boosting (rPB) to improve the resilience of standard AFE control to faults. This neural-network control framework provides a principled way to optimize transient performance while preserving the steady-state tracking properties of AFE-based drives. By carefully shaping the input signals to the rPB controller, we ensure that it activates only during grid faults, leaving nominal operation unaffected. Simulation results show that the proposed approach successfully maintains the DC bus voltage and the grid current within safe limits during single-phase loss events.",
    "authors": [
      "Nicolas Kirsch",
      "Catalin Arghir",
      "Silvia Mastellone",
      "Giancarlo Ferrari-Trecate"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03548",
    "title": "A Learning-based Control Methodology for Transitioning VTOL UAVs",
    "abstract": "Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.",
    "authors": [
      "Zexin Lin",
      "Yebin Zhong",
      "Hanwen Wan",
      "Jiu Cheng",
      "Zhenglong Sun",
      "Xiaoqiang Ji"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03549",
    "title": "PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks",
    "abstract": "We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.",
    "authors": [
      "Yuki Orimo",
      "Iori Kurata",
      "Hodaka Mori",
      "Ryuhei Okuno",
      "Ryohto Sawada",
      "Daisuke Okanohara"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03551",
    "title": "A User Centric Group Authentication Scheme for Secure Communication",
    "abstract": "Group Authentication Schemes (GAS) are methodologies developed to verify the membership of multiple users simultaneously. These schemes enable the concurrent authentication of several users while eliminating the need for a certification authority. Numerous GAS methods have been explored in the literature, and they can be classified into three distinct generations based on their foundational mathematical principles. First-generation GASs rely on polynomial interpolation and the multiplicative subgroup of a finite field. Second-generation GASs also employ polynomial interpolation, but they distinguish themselves by incorporating elliptic curves over finite fields. While third-generation GASs present a promising solution for scalable environments, they demonstrate a limitation in certain applications. Such applications typically require the identification of users participating in the authentication process. In the third-generation GAS, users are able to verify their credentials while maintaining anonymity. However, there are various applications where the identification of participating users is necessary. In this study, we propose an improved version of third-generation GAS, utilizing inner product spaces and polynomial interpolation to resolve this limitation. We address the issue of preventing malicious actions by legitimate group members. The current third-generation scheme allows members to share group credentials, which can jeopardize group confidentiality. Our proposed scheme mitigates this risk by eliminating the ability of individual users to distribute credentials. However, a potential limitation of our scheme is its reliance on a central authority for authentication in certain scenarios.",
    "authors": [
      "Oylum Gerenli",
      "Gunes Karabulut-Kurt",
      "Enver Ozdemir"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03553",
    "title": "Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching",
    "abstract": "Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.",
    "authors": [
      "Wei Chee Yew",
      "Hailun Xu",
      "Sanjay Saha",
      "Xiaotian Fan",
      "Hiok Hian Ong",
      "David Yuchen Wang",
      "Kanchan Sarkar",
      "Zhenheng Yang",
      "Danhui Guan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03555",
    "title": "Accelerating shape optimization by deep neural networks with on-the-fly determined architecture",
    "abstract": "In component shape optimization, the component properties are often evaluated by computationally expensive simulations. Such optimization becomes unfeasible when it is focused on a global search requiring thousands of simulations to be evaluated. Here, we present a viable global shape optimization methodology based on multi-objective evolutionary algorithms accelerated by deep neural networks (DNNs). Our methodology alternates between evaluating simulations and utilizing the generated data to train DNNs with various architectures. When a suitable DNN architecture is identified, the DNN replaces the simulation in the rest of the global search. Our methodology was tested on five ZDT benchmark functions, showing itself at the level of and sometimes more flexible than other state-of-the-art acceleration approaches. Then, it was applied to a real-life optimization problem, namely the shape optimization of a single-phase ejector. Compared with a non-accelerated methodology, ours was able to save weeks of CPU time in solving this problem. To experimentally confirm the performance of the optimized ejector shapes, four of them were 3D printed and tested on the lab scale confirming the predicted performance. This suggests that our methodology could be used for acceleration of other real-life shape optimization problems.",
    "authors": [
      "Lucie Kubíčková",
      "Onřej Gebouský",
      "Jan Haidl",
      "Martin Isoz"
    ],
    "primary_category": "cs.CE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03556",
    "title": "RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL",
    "abstract": "Achieving generalizable embodied policies remains a key challenge. Traditional policy learning paradigms, including both Imitation Learning (IL) and Reinforcement Learning (RL), struggle to cultivate generalizability across diverse scenarios. While IL policies often overfit to specific expert trajectories, RL suffers from the inherent lack of a unified and general reward signal necessary for effective multi-scene generalization. We posit that the world model is uniquely capable of serving as a universal environment proxy to address this limitation. However, current world models primarily focus on their ability to predict observations and still rely on task-specific, handcrafted reward functions, thereby failing to provide a truly general training environment. Toward this problem, we propose RoboScape-R, a framework leveraging the world model to serve as a versatile, general-purpose proxy for the embodied environment within the RL paradigm. We introduce a novel world model-based general reward mechanism that generates ''endogenous'' rewards derived from the model's intrinsic understanding of real-world state transition dynamics. Extensive experiments demonstrate that RoboScape-R effectively addresses the limitations of traditional RL methods by providing an efficient and general training environment that substantially enhances the generalization capability of embodied policies. Our approach offers critical insights into utilizing the world model as an online training strategy and achieves an average 37.5% performance improvement over baselines under out-of-domain scenarios.",
    "authors": [
      "Yinzhou Tang",
      "Yu Shang",
      "Yinuo Chen",
      "Bingwen Wei",
      "Xin Zhang",
      "Shu'ang Yu",
      "Liangzhi Shi",
      "Chao Yu",
      "Chen Gao",
      "Wei Wu",
      "Yong Li"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03558",
    "title": "CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding",
    "abstract": "The rise of Visual-Language Models (LVLMs) has unlocked new possibilities for seamlessly integrating visual and textual information. However, their ability to interpret cartographic maps remains largely unexplored. In this paper, we introduce CartoMapQA, a benchmark specifically designed to evaluate LVLMs' understanding of cartographic maps through question-answering tasks. The dataset includes over 2000 samples, each composed of a cartographic map, a question (with open-ended or multiple-choice answers), and a ground-truth answer. These tasks span key low-, mid- and high-level map interpretation skills, including symbol recognition, embedded information extraction, scale interpretation, and route-based reasoning. Our evaluation of both open-source and proprietary LVLMs reveals persistent challenges: models frequently struggle with map-specific semantics, exhibit limited geospatial reasoning, and are prone to Optical Character Recognition (OCR)-related errors. By isolating these weaknesses, CartoMapQA offers a valuable tool for guiding future improvements in LVLM architectures. Ultimately, it supports the development of models better equipped for real-world applications that depend on robust and reliable map understanding, such as navigation, geographic search, and urban planning. Our source code and data are openly available to the research community at: this https URL",
    "authors": [
      "Huy Quang Ung",
      "Guillaume Habault",
      "Yasutaka Nishimura",
      "Hao Niu",
      "Roberto Legaspi",
      "Tomoki Oya",
      "Ryoichi Kojima",
      "Masato Taya",
      "Chihiro Ono",
      "Atsunori Minamikawa",
      "Yan Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03560",
    "title": "Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks",
    "abstract": "Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.",
    "authors": [
      "Gianni Molinari",
      "Fabio Ciravegna"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03563",
    "title": "State Space Models for Bioacoustics: A comparative Evaluation with Transformers",
    "abstract": "In this study, we evaluate the efficacy of the Mamba model in the field of bioacoustics. We first pretrain a Mamba-based audio large language model (LLM) on a large corpus of audio data using self-supervised learning. We fine-tune and evaluate BioMamba on the BEANS benchmark, a collection of diverse bioacoustic tasks including classification and detection, and compare its performance and efficiency with multiple baseline models, including AVES, a state-of-the-art Transformer-based model. The results show that BioMamba achieves comparable performance with AVES while consumption significantly less VRAM, demonstrating its potential in this domain.",
    "authors": [
      "Chengyu Tang",
      "Sanjeev Baskiyar"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03564",
    "title": "Towards Irreversible Machine Unlearning for Diffusion Models",
    "abstract": "Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.",
    "authors": [
      "Xun Yuan",
      "Zilong Zhao",
      "Jiayu Li",
      "Aryan Pasikhani",
      "Prosanta Gope",
      "Biplab Sikdar"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03565",
    "title": "Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas",
    "abstract": "Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption. As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas' dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime. The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas' previous approach.",
    "authors": [
      "Luis Gall",
      "Samuel James Newcome",
      "Fabio Alexander Gratl",
      "Markus Mühlhäußer",
      "Manish Kumar Mishra",
      "Hans-Joachim Bungartz"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03566",
    "title": "GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models",
    "abstract": "Articulated object generation has seen increasing advancements, yet existing models often lack the ability to be conditioned on text prompts. To address the significant gap between textual descriptions and 3D articulated object representations, we propose GAOT, a three-phase framework that generates articulated objects from text prompts, leveraging diffusion models and hypergraph learning in a three-step process. First, we fine-tune a point cloud generation model to produce a coarse representation of objects from text prompts. Given the inherent connection between articulated objects and graph structures, we design a hypergraph-based learning method to refine these coarse representations, representing object parts as graph vertices. Finally, leveraging a diffusion model, the joints of articulated objects-represented as graph edges-are generated based on the object parts. Extensive qualitative and quantitative experiments on the PartNet-Mobility dataset demonstrate the effectiveness of our approach, achieving superior performance over previous methods.",
    "authors": [
      "Hao Sun",
      "Lei Fan",
      "Donglin Di",
      "Shaohui Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03568",
    "title": "Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough",
    "abstract": "Conducting usability testing like cognitive walkthrough (CW) can be costly. Recent developments in large language models (LLMs), with visual reasoning and UI navigation capabilities, present opportunities to automate CW. We explored whether LLMs (GPT-4 and Gemini-2.5-pro) can simulate human behavior in CW by comparing their walkthroughs with human participants. While LLMs could navigate interfaces and provide reasonable rationales, their behavior differed from humans. LLM-prompted CW achieved higher task completion rates than humans and followed more optimal navigation paths, while identifying fewer potential failure points. However, follow-up studies demonstrated that with additional prompting, LLMs can predict human-identified failure points, aligning their performance with human participants. Our work highlights that while LLMs may not replicate human behaviors exactly, they can be leveraged for scaling usability walkthroughs and providing UI insights, offering a valuable complement to traditional usability testing.",
    "authors": [
      "Ruican Zhong",
      "David W. McDonald",
      "Gary Hsieh"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03569",
    "title": "Performance Evaluation of Parallel Wi-Fi Redundancy with Deferral Techniques",
    "abstract": "Wireless communication is increasingly used in industrial environments, since it supports mobility of interconnected devices. Among the transmission technologies operating in unlicensed bands available to this purpose, Wi-Fi is certainly one of the most interesting, because of its high performance and the relatively low deployment costs. Unfortunately, its dependability is often deemed unsuitable for real-time control systems. In this paper, the use of parallel redundancy is evaluated from a quantitative viewpoint, by considering a number of performance indices that are relevant for soft real-time applications. Analysis is carried out on a large dataset acquired from a real setup, to provide realistic insights on the advantages this kind of approaches can provide. As will be seen, deferred parallel redundancy provides clear advantages in terms of the worst-case transmission latency, at limited costs concerning the amount of consumed spectrum. Hence, it can be practically exploited every time a wireless connection is included in a control loop.",
    "authors": [
      "Gianluca Cena",
      "Pietro Chiavassa",
      "Stefano Scanzio"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03570",
    "title": "Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks",
    "abstract": "Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.",
    "authors": [
      "Stefano Scanzio",
      "Gabriele Formis",
      "Tullio Facchinetti",
      "Gianluca Cena"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03571",
    "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths",
    "abstract": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.",
    "authors": [
      "Zhening Li",
      "Armando Solar-Lezama",
      "Yisong Yue",
      "Stephan Zheng"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03574",
    "title": "Global-Local Aware Scene Text Editing",
    "abstract": "Scene Text Editing (STE) involves replacing text in a scene image with new target text while preserving both the original text style and background texture. Existing methods suffer from two major challenges: inconsistency and length-insensitivity. They often fail to maintain coherence between the edited local patch and the surrounding area, and they struggle to handle significant differences in text length before and after editing. To tackle these challenges, we propose an end-to-end framework called Global-Local Aware Scene Text Editing (GLASTE), which simultaneously incorporates high-level global contextual information along with delicate local features. Specifically, we design a global-local combination structure, joint global and local losses, and enhance text image features to ensure consistency in text style within local patches while maintaining harmony between local and global areas. Additionally, we express the text style as a vector independent of the image size, which can be transferred to target text images of various sizes. We use an affine fusion to fill target text images into the editing patch while maintaining their aspect ratio unchanged. Extensive experiments on real-world datasets validate that our GLASTE model outperforms previous methods in both quantitative metrics and qualitative results and effectively mitigates the two challenges.",
    "authors": [
      "Fuxiang Yang",
      "Tonghua Su",
      "Donglin Di",
      "Yin Chen",
      "Xiangqian Wu",
      "Zhongjie Wang",
      "Lei Fan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03575",
    "title": "UniComp: Rethinking Video Compression Through Informational Uniqueness",
    "abstract": "Distinct from attention-based compression methods, this paper presents an information uniqueness driven video compression framework, termed UniComp, which aims to maximize the information fidelity of video representations under constrained computational budgets. Starting from the information-theoretic perspective, we formulate the vision compression as an optimization problem that minimizes conditional entropy (reconstruction error) between retained and full tokens. To achieve this, we introduce the notion of information uniqueness to measure intrinsic redundancy among tokens to link with reconstruction error. Based on uniqueness, we design three modules-Frame Group Fusion, Token Allocation, and Spatial Dynamic Compression-that progressively perform semantic frame grouping, adaptive resource allocation, and fine-grained spatial compression. Extensive experiments demonstrate that UniComp consistently outperforms existing compression methods in preserving essential visual tokens under limited computational budgets, highlighting the pivotal role of information uniqueness in token compression efficacy.",
    "authors": [
      "Chao Yuan",
      "Shimin Chen",
      "Minliang Lin",
      "Limeng Qiao",
      "Guanglu Wan",
      "Lin Ma"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03577",
    "title": "Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning",
    "abstract": "Universal, transferable whole-slide image (WSI) representations are central to computational pathology. Incorporating multiple markers (e.g., immunohistochemistry, IHC) alongside H&E enriches H&E-based features with diverse, biologically meaningful information. However, progress is limited by the scarcity of well-aligned multi-stain datasets. Inter-stain misalignment shifts corresponding tissue across slides, hindering consistent patch-level features and degrading slide-level embeddings. To address this, we curated a slide-level aligned, five-stain dataset (H&E, HER2, KI67, ER, PGR) to enable paired H&E-IHC learning and robust cross-stain representation. Leveraging this dataset, we propose Cross-Stain Contrastive Learning (CSCL), a two-stage pretraining framework with a lightweight adapter trained using patch-wise contrastive alignment to improve the compatibility of H&E features with corresponding IHC-derived contextual cues, and slide-level representation learning with Multiple Instance Learning (MIL), which uses a cross-stain attention fusion module to integrate stain-specific patch features and a cross-stain global alignment module to enforce consistency among slide-level embeddings across different stains. Experiments on cancer subtype classification, IHC biomarker status classification, and survival prediction show consistent gains, yielding high-quality, transferable H&E slide-level representations. The code and data are available at this https URL .",
    "authors": [
      "Yizhi Zhang",
      "Lei Fan",
      "Zhulin Tao",
      "Donglin Di",
      "Yang Song",
      "Sidong Liu",
      "Cong Cong"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03578",
    "title": "When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate",
    "abstract": "Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data. To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.",
    "authors": [
      "Florent Forest",
      "Amaury Wei",
      "Olga Fink"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03579",
    "title": "Optimal Transportation and Alignment Between Gaussian Measures",
    "abstract": "Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.",
    "authors": [
      "Sanjit Dandapanthula",
      "Aleksandr Podkopaev",
      "Shiva Prasad Kasiviswanathan",
      "Aaditya Ramdas",
      "Ziv Goldfeld"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03580",
    "title": "Dynamic Optical Test for Bot Identification (DOT-BI): A simple check to identify bots in surveys and online processes",
    "abstract": "We propose the Dynamic Optical Test for Bot Identification (DOT-BI): a quick and easy method that uses human perception of motion to differentiate between human respondents and automated systems in surveys and online processes. In DOT-BI, a 'hidden' number is displayed with the same random black-and-white pixel texture as its background. Only the difference in motion and scale between the number and the background makes the number perceptible to humans across frames, while frame-by-frame algorithmic processing yields no meaningful signal. We conducted two preliminary assessments. Firstly, state-of-the-art, video-capable, multimodal models (GPT-5-Thinking and Gemini 2.5 Pro) fail to extract the correct value, even when given explicit instructions about the mechanism. Secondly, in an online survey (n=182), 99.5% (181/182) of participants solved the task, with an average end-to-end completion time of 10.7 seconds; a supervised lab study (n=39) found no negative effects on perceived ease-of-use or completion time relative to a control. We release code to generate tests and 100+ pre-rendered variants to facilitate adoption in surveys and online processes.",
    "authors": [
      "Malte Bleeker",
      "Mauro Gotsch"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03582",
    "title": "Fine-grained Narrative Classification in Biased News Articles",
    "abstract": "Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.",
    "authors": [
      "Zeba Afroz",
      "Harsh Vardhan",
      "Pawan Bhakuni",
      "Aanchal Punia",
      "Rajdeep Kumar",
      "Md. Shad Akhtar"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03584",
    "title": "Federated Learning and Trajectory Compression for Enhanced AIS Coverage",
    "abstract": "This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.",
    "authors": [
      "Thomas Gräupl",
      "Andreas Reisenbauer",
      "Marcel Hecko",
      "Anil Rasouli",
      "Anita Graser",
      "Melitta Dragaschnig",
      "Axel Weissenfeld",
      "Gilles Dejaegere",
      "Mahmoud Sakr"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03586",
    "title": "A Coupled IMEX Domain Decomposition Method for High-Order Time Integration of the ES-BGK Model of the Boltzmann Equation",
    "abstract": "In this paper, we propose a high-order domain decomposition method for the ES-BGK model of the Boltzmann equation, which dynamically detects regions of equilibrium and non-equilibrium. Our implementation automatically switches between Euler equations in regions where the fluid is at equilibrium, and the ES-BGK model elsewhere. The main challenge addressed in this work is the development of a coupled strategy between the macroscopic and the kinetic solvers, which preserves the overall temporal order of accuracy of the scheme. A coupled IMEX method is introduced across decomposed subdomains and solvers. This approach is based on a coupled IMEX method and allows high accuracy and computational efficiency. Several numerical simulations in two space dimensions are performed, in order to validate the robustness of our approach and the expected temporal high-order convergence.",
    "authors": [
      "Domenico Caparello",
      "Tommaso Tenna"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03590",
    "title": "Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation",
    "abstract": "Handling fast, complex, and highly non-linear motion patterns has long posed challenges for video frame interpolation. Although recent diffusion-based approaches improve upon traditional optical-flow-based methods, they still struggle to cover diverse application scenarios and often fail to produce sharp, temporally consistent frames in fine-grained motion tasks such as audio-visual synchronized interpolation. To address these limitations, we introduce BBF (Beyond Boundary Frames), a context-aware video frame interpolation framework, which could be guided by audio/visual semantics. First, we enhance the input design of the interpolation model so that it can flexibly handle multiple conditional modalities, including text, audio, images, and video. Second, we propose a decoupled multimodal fusion mechanism that sequentially injects different conditional signals into a DiT backbone. Finally, to maintain the generation abilities of the foundation model, we adopt a progressive multi-stage training paradigm, where the start-end frame difference embedding is used to dynamically adjust both the data sampling and the loss weighting. Extensive experimental results demonstrate that BBF outperforms specialized state-of-the-art methods on both generic interpolation and audio-visual synchronized interpolation tasks, establishing a unified framework for video frame interpolation under coordinated multi-channel conditioning.",
    "authors": [
      "Yuchen Deng",
      "Xiuyang Wu",
      "Hai-Tao Zheng",
      "Jie Wang",
      "Feidiao Yang",
      "Yuxing Han"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03592",
    "title": "Harnessing Hypergraphs in Geometric Deep Learning for 3D RNA Inverse Folding",
    "abstract": "The RNA inverse folding problem, a key challenge in RNA design, involves identifying nucleotide sequences that can fold into desired secondary structures, which are critical for ensuring molecular stability and function. The inherent complexity of this task stems from the intricate relationship between sequence and structure, making it particularly challenging. In this paper, we propose a framework, named HyperRNA, a generative model with an encoder-decoder architecture that leverages hypergraphs to design RNA sequences. Specifically, our HyperRNA model consists of three main components: preprocessing, encoding and decoding. In the preprocessing stage, graph structures are constructed by extracting the atom coordinates of RNA backbone based on 3-bead coarse-grained representation. The encoding stage processes these graphs, capturing higher order dependencies and complex biomolecular interactions using an attention embedding module and a hypergraph-based encoder. Finally, the decoding stage generates the RNA sequence in an autoregressive manner. We conducted quantitative and qualitative experiments on the PDBBind and RNAsolo datasets to evaluate the inverse folding task for RNA sequence generation and RNA-protein complex sequence generation. The experimental results demonstrate that HyperRNA not only outperforms existing RNA design methods but also highlights the potential of leveraging hypergraphs in RNA engineering.",
    "authors": [
      "Guang Yang",
      "Lei Fan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03593",
    "title": "CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures",
    "abstract": "We present a CloseUpAvatar - a novel approach for articulated human avatar representation dealing with more general camera motions, while preserving rendering quality for close-up views. CloseUpAvatar represents an avatar as a set of textured planes with two sets of learnable textures for low and high-frequency detail. The method automatically switches to high-frequency textures only for cameras positioned close to the avatar's surface and gradually reduces their impact as the camera moves farther away. Such parametrization of the avatar enables CloseUpAvatar to adjust rendering quality based on camera distance ensuring realistic rendering across a wider range of camera orientations than previous approaches. We provide experiments using the ActorsHQ dataset with high-resolution input images. CloseUpAvatar demonstrates both qualitative and quantitative improvements over existing methods in rendering from novel wide range camera positions, while maintaining high FPS by limiting the number of required primitives.",
    "authors": [
      "David Svitov",
      "Pietro Morerio",
      "Lourdes Agapito",
      "Alessio Del Bue"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03594",
    "title": "Accelerating Detailed Routing Convergence through Offline Reinforcement Learning",
    "abstract": "Detailed routing remains one of the most complex and time-consuming steps in modern physical design due to the challenges posed by shrinking feature sizes and stricter design rules. Prior detailed routers achieve state-of-the-art results by leveraging iterative pathfinding algorithms to route each net. However, runtimes are a major issue in detailed routers, as converging to a solution with zero design rule violations (DRVs) can be prohibitively expensive. In this paper, we propose leveraging reinforcement learning (RL) to enable rapid convergence in detailed routing by learning from previous designs. We make the key observation that prior detailed routers statically schedule the cost weights used in their routing algorithms, meaning they do not change in response to the design or technology. By training a conservative Q-learning (CQL) model to dynamically select the routing cost weights which minimize the number of algorithm iterations, we find that our work completes the ISPD19 benchmarks with 1.56x average and up to 3.01x faster runtime than the baseline router while maintaining or improving the DRV count in all cases. We also find that this learning shows signs of generalization across technologies, meaning that learning designs in one technology can translate to improved outcomes in other technologies.",
    "authors": [
      "Afsara Khan",
      "Austin Rovinski"
    ],
    "primary_category": "cs.AR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03597",
    "title": "HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation",
    "abstract": "Medical image segmentation is a cornerstone of modern clinical diagnostics. While Vision Transformers that leverage shifted window-based self-attention have established new benchmarks in this field, they are often hampered by a critical limitation: their localized attention mechanism struggles to effectively fuse local details with global context. This deficiency is particularly detrimental to challenging tasks such as the segmentation of microtumors and miniature organs, where both fine-grained boundary definition and broad contextual understanding are paramount. To address this gap, we propose HBFormer, a novel Hybrid-Bridge Transformer architecture. The 'Hybrid' design of HBFormer synergizes a classic U-shaped encoder-decoder framework with a powerful Swin Transformer backbone for robust hierarchical feature extraction. The core innovation lies in its 'Bridge' mechanism, a sophisticated nexus for multi-scale feature integration. This bridge is architecturally embodied by our novel Multi-Scale Feature Fusion (MFF) decoder. Departing from conventional symmetric designs, the MFF decoder is engineered to fuse multi-scale features from the encoder with global contextual information. It achieves this through a synergistic combination of channel and spatial attention modules, which are constructed from a series of dilated and depth-wise convolutions. These components work in concert to create a powerful feature bridge that explicitly captures long-range dependencies and refines object boundaries with exceptional precision. Comprehensive experiments on challenging medical image segmentation datasets, including multi-organ, liver tumor, and bladder tumor benchmarks, demonstrate that HBFormer achieves state-of-the-art results, showcasing its outstanding capabilities in microtumor and miniature organ segmentation. Code and models are available at: this https URL .",
    "authors": [
      "Fuchen Zheng",
      "Xinyi Chen",
      "Weixuan Li",
      "Quanjun Li",
      "Junhua Zhou",
      "Xiaojiao Guo",
      "Xuhang Chen",
      "Chi-Man Pun",
      "Shoujun Zhou"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03598",
    "title": "Memory-Guided Point Cloud Completion for Dental Reconstruction",
    "abstract": "Partial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder--decoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.",
    "authors": [
      "Jianan Sun",
      "Yukang Huang",
      "Dongzhihan Wang",
      "Mingyu Fan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03601",
    "title": "Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding",
    "abstract": "Recent advancements in foundation models for 2D vision have substantially improved the analysis of dynamic scenes from monocular videos. However, despite their strong generalization capabilities, these models often lack 3D consistency, a fundamental requirement for understanding scene geometry and motion, thereby causing severe spatial misalignment and temporal flickering in complex 3D environments. In this paper, we present Motion4D, a novel framework that addresses these challenges by integrating 2D priors from foundation models into a unified 4D Gaussian Splatting representation. Our method features a two-part iterative optimization framework: 1) Sequential optimization, which updates motion and semantic fields in consecutive stages to maintain local consistency, and 2) Global optimization, which jointly refines all attributes for long-term coherence. To enhance motion accuracy, we introduce a 3D confidence map that dynamically adjusts the motion priors, and an adaptive resampling process that inserts new Gaussians into under-represented regions based on per-pixel RGB and semantic errors. Furthermore, we enhance semantic coherence through an iterative refinement process that resolves semantic inconsistencies by alternately optimizing the semantic fields and updating prompts of SAM2. Extensive evaluations demonstrate that our Motion4D significantly outperforms both 2D foundation models and existing 3D-based approaches across diverse scene understanding tasks, including point-based tracking, video object segmentation, and novel view synthesis. Our code is available at this https URL .",
    "authors": [
      "Haoran Zhou",
      "Gim Hee Lee"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03604",
    "title": "Physics-Based Communication Compression via Lyapunov-Weighted Event-Triggered Control",
    "abstract": "Event-Triggered Control (ETC) reduces communication overhead in networked systems by transmitting only when stability requires it. Conventional mechanisms use isotropic error thresholds ($\\|e\\| \\le \\sigma \\|x\\|$), treating all directions equally. This ignores stability geometry and triggers conservatively. We propose a static directional triggering mechanism that exploits this asymmetry. By weighting errors via the Lyapunov matrix $P$, we define an anisotropic half-space scaling with instantaneous energy margins: larger deviations tolerated along stable modes, strict bounds where instability threatens. We prove global asymptotic stability and exclusion of Zeno behavior. Monte Carlo simulations ($N=100$) show 43.6\\% fewer events than optimally tuned isotropic methods while achieving $2.1\\times$ better control performance than time-varying alternatives. The mechanism functions as a runtime safety gate for learning-based controllers operating under communication constraints.",
    "authors": [
      "Abbas Tariverdi"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03605",
    "title": "A Perception-feedback position-tracking control for quadrotors",
    "abstract": "In this paper a position-tracking controller for quadrotors based on perception feedback is developed, which directly uses measurements from onboard sensors such as low cost IMUs and GPS to generate the control commands without state estimation. Bias in gyros sensors are corrected to enhance the tracking performance. Practical stability of the origin of the tracking error system in the presence of external disturbances is proved using the Lyapunov analysis, which turns out to exponential stability in the absence of external disturbances. Numerical simulations are included to illustrate the proposed control scheme and to verify the robustness of the proposed controller under noisy measurements and parameter uncertainties.",
    "authors": [
      "Eduardo Espindola",
      "Yu Tang"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03606",
    "title": "Observation-driven correction of numerical weather prediction for marine winds",
    "abstract": "Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.",
    "authors": [
      "Matteo Peduto",
      "Qidong Yang",
      "Jonathan Giezendanner",
      "Devis Tuia",
      "Sherrie Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03607",
    "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization",
    "abstract": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints. Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.",
    "authors": [
      "Yusen Wu",
      "Xiaotie Deng"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03608",
    "title": "KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing",
    "abstract": "Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties. We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\\(\\times\\)/1.94\\(\\times\\)/2.05\\(\\times\\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.",
    "authors": [
      "Lishuo Deng",
      "Shaojie Xu",
      "Jinwu Chen",
      "Changwei Yan",
      "Jiajie Wang",
      "Zhe Jiang",
      "Weiwei Shan"
    ],
    "primary_category": "cs.AR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03610",
    "title": "CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion",
    "abstract": "Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.",
    "authors": [
      "Julius Lenz"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03612",
    "title": "Expected Confidence Dependency: A Novel Rough Set-Based Approach to Feature Selection",
    "abstract": "This paper proposes Expected Confidence Dependency (ECD), a novel, soft computing-oriented, accuracy driven dependency measure for feature selection within the rough set theory framework. Unlike traditional rough set dependency measures that rely on binary characterizations of conditional blocks, ECD assigns confidence-based contributions to individual equivalence blocks and aggregates them through a normalized expectation operator. We formally establish several desirable properties of ECD, including normalization, compatibility with classical dependency, monotonicity, and invariance under structural and label-preserving transformations.",
    "authors": [
      "Saeed Rasouli",
      "Hamid Karamikabir"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03615",
    "title": "Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach",
    "abstract": "This paper deals with the problem of covariance control for a class of linear stochastic discrete-time systems in the Stochastic Model Predictive Control (SMPC) framework. The considered systems are affected by independent and identically distributed (i.i.d.) additive and parametric stochastic uncertainties (potentially unbounded), in addition to polytopic deterministic uncertainties bounding the mean of the state and input parameters. The control design conditions presented in this paper are formulated as Linear Matrix Inequalities (LMIs), using the S-variable approach in order to reduce the potential conservatism. These conditions are derived using a deterministic exact characterization of the covariance dynamics, the latter involves bilinear terms in the control gain. A technique to linearize such dynamics is presented, it results in a descriptor representation allowing to derive sufficient conditions for covariance control design. The derived condition is firstly compared to a known necessary and sufficient stability condition for systems without deterministic uncertainties and additive stochastic noise, although more conservative, it turns out to be more numerically tractable. Then, the same condition is used to design controllers that are robust to both deterministic and stochastic uncertainties. Several numerical examples are presented for comparison and illustration.",
    "authors": [
      "Kaouther Moussa",
      "Dimitri Peaucelle"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03616",
    "title": "Lightweight Unified Sha-3/Shake Architecture with a Fault-Resilient State",
    "abstract": "Hash functions have become a key part of standard Post-quantum cryptography (PQC) schemes, especially Sha-3 and Shake, calling arXiv:submit/7045552 [cs.AR] 3 Dec 2025 for lightweight implementation. A fault-resilient design is always desirable to make the whole PQC system reliable. We, therefore, propose a) a unified hash engine supporting Sha-3 and Shake that follows a byte-wise in-place partitioning mechanism of the so-called Keccak state, and b) an according fault detection for Keccak state protection exploiting its cube structure by deploying two-dimensional parity checks. It outperforms the state-of-the-art (SoA) regarding area requirements at competitive register-level fault detection by achieving 100% detection of three and still near 100% of higher numbers of Keccak state faults. Unlike SoA solutions, the proposed unified hash engine covers all standard hash configurations. Moreover, the introduced multidimensional cross-parity check mechanism achieves a 3.7x improvement in area overhead, with an overall 4.5x smaller fault-resilient engine design as demonstrated in ASIC and FPGA implementations. Integrated into a RISC-V environment, the unified hash engine with the integrated fault-resilient mechanism introduced less than 8% area overhead. Our approach thus provides a robust and lightweight fault-detection solution for protecting hash functions deployed in resource-constrained PQC applications.",
    "authors": [
      "Christian Ewert",
      "Amrit Sharma Poudel",
      "Mouadh Ayache",
      "Andrija Neskovic",
      "Rainer Buchty",
      "Mladen Berekovic",
      "Sebastian Berndt",
      "Saleh Mulhem"
    ],
    "primary_category": "cs.AR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03619",
    "title": "LAMP: Language-Assisted Motion Planning for Controllable Video Generation",
    "abstract": "Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP's improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.",
    "authors": [
      "Muhammed Burak Kizil",
      "Enes Sanli",
      "Niloy J. Mitra",
      "Erkut Erdem",
      "Aykut Erdem",
      "Duygu Ceylan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03620",
    "title": "SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting",
    "abstract": "The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at this https URL .",
    "authors": [
      "Hanxiu Zhang",
      "Yue Zheng"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03621",
    "title": "ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation",
    "abstract": "We propose ReCamDriving, a purely vision-based, camera-controlled novel-trajectory video generation framework. While repair-based methods fail to restore complex artifacts and LiDAR-based approaches rely on sparse and incomplete cues, ReCamDriving leverages dense and scene-complete 3DGS renderings for explicit geometric guidance, achieving precise camera-controllable generation. To mitigate overfitting to restoration behaviors when conditioned on 3DGS renderings, ReCamDriving adopts a two-stage training paradigm: the first stage uses camera poses for coarse control, while the second stage incorporates 3DGS renderings for fine-grained viewpoint and geometric guidance. Furthermore, we present a 3DGS-based cross-trajectory data curation strategy to eliminate the train-test gap in camera transformation patterns, enabling scalable multi-trajectory supervision from monocular videos. Based on this strategy, we construct the ParaDrive dataset, containing over 110K parallel-trajectory video pairs. Extensive experiments demonstrate that ReCamDriving achieves state-of-the-art camera controllability and structural consistency.",
    "authors": [
      "Yaokun Li",
      "Shuaixian Wang",
      "Mantang Guo",
      "Jiehui Huang",
      "Taojun Ding",
      "Mu Hu",
      "Kaixuan Wang",
      "Shaojie Shen",
      "Guang Tan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03623",
    "title": "The promising potential of vision language models for the generation of textual weather forecasts",
    "abstract": "Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.",
    "authors": [
      "Edward C. C. Steele",
      "Dinesh Mane",
      "Emilio Monti",
      "Luis Orus",
      "Rebecca Chantrill-Cheyette",
      "Matthew Couch",
      "Kirstine I. Dale",
      "Simon Eaton",
      "Govindarajan Rangarajan",
      "Amir Majlesi",
      "Steven Ramsdale",
      "Michael Sharpe",
      "Craig Smith",
      "Jonathan Smith",
      "Rebecca Yates",
      "Holly Ellis",
      "Charles Ewen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03625",
    "title": "FeatureLens: A Highly Generalizable and Interpretable Framework for Detecting Adversarial Examples Based on Image Features",
    "abstract": "Although the remarkable performance of deep neural networks (DNNs) in image classification, their vulnerability to adversarial attacks remains a critical challenge. Most existing detection methods rely on complex and poorly interpretable architectures, which compromise interpretability and generalization. To address this, we propose FeatureLens, a lightweight framework that acts as a lens to scrutinize anomalies in image features. Comprising an Image Feature Extractor (IFE) and shallow classifiers (e.g., SVM, MLP, or XGBoost) with model sizes ranging from 1,000 to 30,000 parameters, FeatureLens achieves high detection accuracy ranging from 97.8% to 99.75% in closed-set evaluation and 86.17% to 99.6% in generalization evaluation across FGSM, PGD, CW, and DAmageNet attacks, using only 51 dimensional features. By combining strong detection performance with excellent generalization, interpretability, and computational efficiency, FeatureLens offers a practical pathway toward transparent and effective adversarial defense.",
    "authors": [
      "Zhigang Yang",
      "Yuan Liu",
      "Jiawei Zhang",
      "Puning Zhang",
      "Xinqiang Ma"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03627",
    "title": "MemVerse: Multimodal Memory for Lifelong Learning Agents",
    "abstract": "Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.",
    "authors": [
      "Junming Liu",
      "Yifei Sun",
      "Weihua Cheng",
      "Haodong Lei",
      "Yirong Chen",
      "Licheng Wen",
      "Xuemeng Yang",
      "Daocheng Fu",
      "Pinlong Cai",
      "Nianchen Deng",
      "Yi Yu",
      "Shuyue Hu",
      "Botian Shi",
      "Ding Wang"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03630",
    "title": "Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations",
    "abstract": "Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.",
    "authors": [
      "Shifa Sulaiman",
      "Amarnath H",
      "Simon Bogh",
      "Naresh Marturi"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03632",
    "title": "Three-dimensional modelling of drag anchor penetration using the material point method",
    "abstract": "Drag embedment anchors are a key threat to buried subsea linear infrastructure, such as power/data cables and pipelines. For cables, selecting a burial depth is a compromise between protecting the cable from anchor strike and the increased cost of deeper installation. This presents an efficient large deformation, elasto-plastic Material Point Method-based soil-structure interaction predictive tool for the estimation of anchor penetration based on Cone Penetration Test (CPT) site investigation data. The tool builds on earlier work by the authors supplemented by three developments: modelling assemblies of rigid bodies (necessary for articulated anchors), a partitioned domain approach to enable accurate and efficient modelling of long anchor pulls and an improved means of modelling rotational inertia. The tool is validated against scaled physical tests conducted in a geotechnical centrifuge on sands with a range of relative densities with good agreement across the tested conditions. Numerical simulations identify key issues with the UK Cable Burial Risk Assessment (CBRA) approach for estimating anchor penetration and reveal the potentially non-conservatism of the CBRA framework for sandy seabeds. The numerical model enables site-specific anchor-penetration assessment along cable routes and can be used to evaluate the performance of different anchor designs and sizes in varied soil conditions.",
    "authors": [
      "Robert E. Bird",
      "William M. Coombs",
      "Michael J. Brown",
      "Charles E. Augarde",
      "Yaseen U. Sharif",
      "Giuliano Pretti",
      "Catriona Macdonald",
      "Duncan Stevens",
      "Gareth Carter"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03634",
    "title": "AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment",
    "abstract": "Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.",
    "authors": [
      "Ahmad Aghaebrahimian"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03635",
    "title": "Formal Analysis of the Sigmoid Function and Formal Proof of the Universal Approximation Theorem",
    "abstract": "This paper presents a formalized analysis of the sigmoid function and a fully mechanized proof of the Universal Approximation Theorem (UAT) in Isabelle/HOL, a higher-order logic theorem prover. The sigmoid function plays a fundamental role in neural networks; yet, its formal properties, such as differentiability, higher-order derivatives, and limit behavior, have not previously been comprehensively mechanized in a proof assistant. We present a rigorous formalization of the sigmoid function, proving its monotonicity, smoothness, and higher-order derivatives. We provide a constructive proof of the UAT, demonstrating that neural networks with sigmoidal activation functions can approximate any continuous function on a compact interval. Our work identifies and addresses gaps in Isabelle/HOL's formal proof libraries and introduces simpler methods for reasoning about the limits of real functions. By exploiting theorem proving for AI verification, our work enhances trust in neural networks and contributes to the broader goal of verified and trustworthy machine learning.",
    "authors": [
      "Dustin Bryant",
      "Jim Woodcock",
      "Simon Foster"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03636",
    "title": "Head, posture, and full-body gestures in interactive communication",
    "abstract": "When face-to-face communication becomes effortful due to background noise or interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively examined head or hand movements, here we explore movements of the whole body in acoustically adverse conditions. We hypothesized that increasing background noise in conversations would lead to increased gesture frequency in hand, head, trunk, and leg movements typical of conversation. Increased use of hand movements should support the speaker's role, while increased head and trunk movements may help the listener. We conducted a free dyadic conversation experiment with normal-hearing participants (n=8) in a virtual acoustic environment. Conversational movements were described with a newly developed labeling system for typical conversational actions, and the frequency of individual types was analyzed. In addition, we analyzed gesture quality by assessing hand-speech synchrony, with the hypothesis that higher levels of background noise would lead to a loss of synchrony according to an interactive coupling model. Higher noise levels led to increased hand-gesture complexity during speaking and listening, more pronounced up-down head movements, and contrary to expectations, head movements during listening generally decreased relative to speaking. Synchrony and peak velocity were unaffected by noise, while gesture quality scaled only modestly. The results support previous findings regarding gesturing frequency, but we found only limited evidence for changes in speech-gesture synchrony. This work reveals communication patterns of the whole body and illustrates multimodal adaptation to communication demands.",
    "authors": [
      "Ľuboš Hládek",
      "Bernhard U. Seeber"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03637",
    "title": "AaPE: Aliasing-aware Patch Embedding for Self-Supervised Audio Representation Learning",
    "abstract": "Transformer-based audio SSL (self-supervised learning) models often treat spectrograms as images, applying convolutional patchification with heavy temporal downsampling. This lowers the effective Nyquist frequency and introduces aliasing, while naïve low-pass filtering removes task-relevant high-frequency cues. In this study, we present Aliasing-aware Patch Embedding (AaPE), a drop-in patch stem that mitigates aliasing while preserving high-frequency information. AaPE augments standard patch tokens with features produced by a band-limited complex sinusoidal kernel using a two-sided exponential window that dynamically targets alias-prone bands. Frequency and decay parameters of the kernel are estimated from the input, enabling parallel, adaptive subband analysis whose outputs are fused with the standard patch tokens. AaPE integrates seamlessly into the masked teacher-student self-supervised learning. In addition, we combine a multi-mask strategy with a contrastive objective to enforce consistency across diverse mask patterns, stabilizing training. Pre-training on AudioSet followed by fine-tuning evaluation across diverse downstream benchmarks, which spanned categories, such as environmental sounds and other common audio domains. This approach yields state-of-the-art performance on a subset of tasks and competitive results across the remainder. Complementary linear probing evaluation mirrors this pattern, yielding clear gains on several benchmarks and strong performance elsewhere. The collective analysis of these results indicates that AaPE serves to mitigate the effects of aliasing without discarding of informative high-frequency content.",
    "authors": [
      "Kohei Yamamoto",
      "Kosuke Okusa"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03639",
    "title": "Context-Triggered Contingency Games for Strategic Multi-Agent Interaction",
    "abstract": "We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.",
    "authors": [
      "Kilian Schweppe",
      "Anne-Kathrin Schmuck"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03640",
    "title": "MKSNet: Advanced Small Object Detection in Remote Sensing Imagery with Multi-Kernel and Dual Attention Mechanisms",
    "abstract": "Deep convolutional neural networks (DCNNs) have substantially advanced object detection capabilities, particularly in remote sensing imagery. However, challenges persist, especially in detecting small objects where the high resolution of these images and the small size of target objects often result in a loss of critical information in the deeper layers of conventional CNNs. Additionally, the extensive spatial redundancy and intricate background details typical in remote-sensing images tend to obscure these small targets. To address these challenges, we introduce Multi-Kernel Selection Network (MKSNet), a novel network architecture featuring a novel Multi-Kernel Selection mechanism. The MKS mechanism utilizes large convolutional kernels to effectively capture an extensive range of contextual information. This innovative design allows for adaptive kernel size selection, significantly enhancing the network's ability to dynamically process and emphasize crucial spatial details for small object detection. Furthermore, MKSNet also incorporates a dual attention mechanism, merging spatial and channel attention modules. The spatial attention module adaptively fine-tunes the spatial weights of feature maps, focusing more intensively on relevant regions while mitigating background noise. Simultaneously, the channel attention module optimizes channel information selection, improving feature representation and detection accuracy. Empirical evaluations on the DOTA-v1.0 and HRSC2016 benchmark demonstrate that MKSNet substantially surpasses existing state-of-the-art models in detecting small objects in remote sensing images. These results highlight MKSNet's superior ability to manage the complexities associated with multi-scale and high-resolution image data, confirming its effectiveness and innovation in remote sensing object detection.",
    "authors": [
      "Jiahao Zhang",
      "Xiao Zhao",
      "Guangyu Gao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03641",
    "title": "A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception",
    "abstract": "Cyber-deception is an increasingly important defensive strategy, shaping adversarial decision making through controlled misinformation, uncertainty, and misdirection. Although game-theoretic, Bayesian, Markov decision process, and reinforcement learning models offer insight into deceptive interactions, they typically assume an attacker has already chosen to engage. Such approaches overlook cognitive and perceptual factors that influence an attacker's initial decision to engage or withdraw. This paper presents a descriptive model that incorporates the psychological and strategic elements shaping this decision. The model defines five components, belief (B), scepticism (S), deception fidelity (D), reconnaissance (R), and experience (E), which interact to capture how adversaries interpret deceptive cues and assess whether continued engagement is worthwhile. The framework provides a structured method for analysing engagement decisions in cyber-deception scenarios. A series of experiments has been designed to evaluate this model through Capture the Flag activities incorporating varying levels of deception, supported by behavioural and biometric observations. These experiments have not yet been conducted, and no experimental findings are presented in this paper. These experiments will combine behavioural observations with biometric indicators to produce a multidimensional view of adversarial responses. Findings will improve understanding of the factors influencing engagement decisions and refine the model's relevance to real-world cyber-deception settings. By addressing the gap in existing models that presume engagement, this work supports more cognitively realistic and strategically effective cyber-deception practices.",
    "authors": [
      "B.R. Turner",
      "O. Guidetti",
      "N.M. Karie",
      "R. Ryan",
      "Y. Yan"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03643",
    "title": "Optical Context Compression Is Just (Bad) Autoencoding",
    "abstract": "DeepSeek-OCR demonstrates that rendered text can be reconstructed with high fidelity from a small number of vision tokens. This finding has sparked excitement about vision-based context compression for language models. But the evaluation stops at reconstruction; whether these representations help language modeling remains untested. We test two assumptions implicit in the optical-compression narrative: that vision-based compression provides unique advantages for text reconstruction from compressed representations, and that DeepSeek-OCR's reconstruction results are evidence that vision-based compression will be useful for language modeling. Comparing their vision encoder against simple alternatives--parameter-free mean pooling and a learned hierarchical encoder--we find that these simple approaches match or surpass vision for reconstruction at matched compression ratios, and outperform it for language modeling--where vision-based compression fails to beat truncation. The excitement around optical context compression outpaces the evidence. Code and checkpoints are available at this https URL",
    "authors": [
      "Ivan Yee Lee",
      "Cheng Yang",
      "Taylor Berg-Kirkpatrick"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03644",
    "title": "FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management",
    "abstract": "Recent developments in large language models (LLMs) have introduced new requirements for efficient and robust training. As LLM clusters scale, node failures, lengthy recoveries, and bulky checkpoints erode efficiency. Infrequent asynchronous checkpoints trigger costly rollbacks, yet higher frequencies add prohibitive overhead. To address these challenges, we propose FFTrainer, a system designed for robust LLM training. FFTrainer leverages surplus network capacity to quickly save and load states, thereby preventing rollbacks and accelerating recovery. Compared with prior checkpointing approaches, FFTrainer reduces recovery time by up to 98% and mitigates GPU utilization loss by up to 68% without hindering normal training.",
    "authors": [
      "Bohan Zhao",
      "Yuanhong Wang",
      "Chenglin Liu",
      "Jiagi Pan",
      "Guang Yang",
      "Ruitao Liu",
      "Tingrui Zhang",
      "Kai Luo",
      "Wei Xu"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03650",
    "title": "Convergence analysis of a Crank-Nicolson scheme for strongly magnetized plasmas",
    "abstract": "The present paper is devoted to the convergence analysis of an asymptotic preserving particle scheme designed to serve as a particle pusher in a Particle-In-Cell (PIC) method for the Vlasov equation with a strong inhomogeneous magnetic field. The asymptotic preserving scheme that we study removes classical strong restrictive stability constraints on discretization steps while capturing the large-scale dynamics, even when the discretization is too coarse to capture fastest scales. Our error bounds are explicit regarding the discretization and stiffness parameters and match sharply numerical tests. The present analysis is expected to be representative of the general analysis of a class of schemes, developed by the authors, conceived as implicit-explicit schemes on augmented formulations.",
    "authors": [
      "Francis Filbet",
      "L Miguel Rodrigues",
      "Kim Han Trinh"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03653",
    "title": "Conditional updates of neural network weights for increased out of training performance",
    "abstract": "This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.",
    "authors": [
      "Jan Saynisch-Wagner",
      "Saran Rajendran Sari"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03656",
    "title": "Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting",
    "abstract": "Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.",
    "authors": [
      "Salim Khazem",
      "Houssam Kanso"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03661",
    "title": "Dynamically Scaled Activation Steering",
    "abstract": "Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.",
    "authors": [
      "Alex Ferrando",
      "Xavier Suau",
      "Jordi Gonzàlez",
      "Pau Rodriguez"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03663",
    "title": "Multi-Scale Visual Prompting for Lightweight Small-Image Classification",
    "abstract": "Visual prompting has recently emerged as an efficient strategy to adapt vision models using lightweight, learnable parameters injected into the input space. However, prior work mainly targets large Vision Transformers and high-resolution datasets such as ImageNet. In contrast, small-image benchmarks like MNIST, Fashion-MNIST, and CIFAR-10 remain widely used in education, prototyping, and research, yet have received little attention in the context of prompting. In this paper, we introduce \\textbf{Multi-Scale Visual Prompting (MSVP)}, a simple and generic module that learns a set of global, mid-scale, and local prompt maps fused with the input image via a lightweight $1 \\times 1$ convolution. MSVP is backbone-agnostic, adds less than $0.02\\%$ parameters, and significantly improves performance across CNN and Vision Transformer backbones. We provide a unified benchmark on MNIST, Fashion-MNIST, and CIFAR-10 using a simple CNN, ResNet-18, and a small Vision Transformer. Our method yields consistent improvements with negligible computational overhead. We further include ablations on prompt scales, fusion strategies, and backbone architectures, along with qualitative analyzes using prompt visualizations and Grad-CAM. Our results demonstrate that multi-scale prompting provides an effective inductive bias even on low-resolution images.",
    "authors": [
      "Salim Khazem"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03666",
    "title": "ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos",
    "abstract": "A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \\textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \\textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \\textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \\textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \\href{ this https URL }{ this https URL }..",
    "authors": [
      "Qi'ao Xu",
      "Tianwen Qian",
      "Yuqian Fu",
      "Kailing Li",
      "Yang Jiao",
      "Jiacheng Zhang",
      "Xiaoling Wang",
      "Liang He"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03667",
    "title": "Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning",
    "abstract": "In this study, we present Colon-X, an open initiative aimed at advancing multimodal intelligence in colonoscopy. We begin by constructing ColonVQA, the most comprehensive multimodal dataset ever built for colonoscopy, featuring over 1.1M+ visual question answering entries across 76 clinical findings and 18 multimodal tasks. Beyond serving as a community-wide data foundation, we further investigate a critical yet underexplored transition in colonoscopy - evolving from multimodal understanding to clinical reasoning: (a) To capture the current landscape of multimodal understanding behaviors, we systematically assess the generalizability of 22 multimodal large language models and examine their reliability under human-induced perturbations. The results reveal that clinical outputs from leading MLLMs remain far from robust and trustworthy. (b) To narrow this gap, we further explore reasoning-centric intelligence tailored for colonoscopy. Specifically, we curate ColonReason, a clinically grounded reasoning dataset annotated through a multi-expert debating pipeline, and develop ColonR1, the first R1-styled model incorporating task-adaptive rewarding and gradient-stable optimization techniques. Under data-scarce conditions, our ColonR1 achieves 56.61% overall accuracy, outperforming supervised fine-tuning by 25.22%, and sets a new reasoning-enabled baseline for multimodal colonoscopy analysis. All data and model resources are publicly available at this https URL .",
    "authors": [
      "Ge-Peng Ji",
      "Jingyi Liu",
      "Deng-Ping Fan",
      "Nick Barnes"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03669",
    "title": "Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data",
    "abstract": "With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.",
    "authors": [
      "Zuan Wang",
      "Juntao Lu",
      "Jiazhuang Wu",
      "Youliang Tian",
      "Wei Song",
      "Qiuxian Li",
      "Duo Zhang"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03671",
    "title": "Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context",
    "abstract": "The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.",
    "authors": [
      "Beatrice Savoldi",
      "Giuseppe Attanasio",
      "Olga Gorodetskaya",
      "Marta Marchiori Manerba",
      "Elisa Bassignana",
      "Silvia Casola",
      "Matteo Negri",
      "Tommaso Caselli",
      "Luisa Bentivogli",
      "Alan Ramponi",
      "Arianna Muti",
      "Nicoletta Balbo",
      "Debora Nozza"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03672",
    "title": "Evaluating Hydro-Science and Engineering Knowledge of Large Language Models",
    "abstract": "Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.",
    "authors": [
      "Shiruo Hu",
      "Wenbo Shan",
      "Yingjia Li",
      "Zhiqi Wan",
      "Xinpeng Yu",
      "Yunjia Qi",
      "Haotian Xia",
      "Yang Xiao",
      "Dingxiao Liu",
      "Jiaru Wang",
      "Chenxu Gong",
      "Ruixi Zhang",
      "Shuyue Wu",
      "Shibo Cui",
      "Chee Hui Lai",
      "Wei Luo",
      "Yubin He",
      "Bin Xu",
      "Jianshi Zhao"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03673",
    "title": "ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers",
    "abstract": "Diffusion transformers have demonstrated strong capabilities in generating high-quality images. However, as model size increases, the growing memory footprint and inference latency pose significant challenges for practical deployment. Recent studies in large language models (LLMs) show that rotation-based techniques can smooth outliers and enable 4-bit quantization, but these approaches often incur substantial overhead and struggle with row-wise outliers in diffusion transformers. To address these challenges, we propose ConvRot, a group-wise rotation-based quantization method that leverages regular Hadamard transform (RHT) to suppress both row-wise and column-wise outliers while reducing complexity from quadratic to linear. Building on this, we design ConvLinear4bit, a plug-and-play module that integrates rotation, quantization, GEMM, and dequantization, enabling W4A4 inference without retraining and preserving visual quality. Experiments on FLUX.1-dev demonstrate a 2.26$\\times$ speedup and 4.05$\\times$ memory reduction while maintaining image fidelity. To our knowledge, this is the first application of rotation-based quantization for plug-and-play W4A4 inference in diffusion transformers.",
    "authors": [
      "Feice Huang",
      "Zuliang Han",
      "Xing Zhou",
      "Yihuang Chen",
      "Lifei Zhu",
      "Haoqian Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03674",
    "title": "Lifting the Cage of Consent: A Techno-Legal Perspective on Evolvable Trust Relationships",
    "abstract": "Those concerned about privacy worry that personal data changes hands too easily. We argue that the actual challenge is the exact opposite: our data does not flow well enough, cultivating a reliance on questionable and often unlawful shortcuts in a desperate bid to survive within today's data-driven economy. Exclusively punitive interpretations of protective legislation such as the GDPR throw out the baby with the bathwater through barriers that equally hinder \"doing the right thing\" and \"doing the wrong thing\", in an abject mistranslation of how ethical choices correspond to financial cost. As long as privacy-friendly data treatment proves more expensive or complicated than readily available alternatives, economic imperatives will continue to outrank their legal counterparts. We examined existing legislation with the aim of facilitating mutually beneficial interactions, rather than more narrowly focusing on the prevention of undesired behaviors. In this article, we propose the implementation of evolvable trust systems as a scalable alternative to the omnipresent yet deeply broken delusion of ill-informed consent. We describe personalized, technology-assisted legal processes for initiating and maintaining long-term trust relationships, which enable parties to reliably and sustainably exchange data, goods, and services. Our proposal encourages a redirection of additional efforts towards the techno-legal alignment of economical incentives with societal ones, reminding us that - while trust remains an inherently human concept - technology can support people in evolving and scaling their relationships to meet the increasingly complex demands of current and future data landscapes.",
    "authors": [
      "Beatriz Esteves",
      "Ruben Verborgh"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03676",
    "title": "Different types of syntactic agreement recruit the same units within large language models",
    "abstract": "Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.",
    "authors": [
      "Daria Kryvosheieva",
      "Andrea de Varda",
      "Evelina Fedorenko",
      "Greta Tuckute"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03678",
    "title": "Feature-aware Modulation for Learning from Temporal Tabular Data",
    "abstract": "While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.",
    "authors": [
      "Hao-Run Cai",
      "Han-Jia Ye"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03679",
    "title": "From Memory Model to CPU Time: Exponential Integrators for Advection-Dominated Problems",
    "abstract": "In this paper, we investigate the application of exponential integrators to advection-dominated problems. We focus on Krylov subspace and Leja interpolation methods to compute the action of exponential and related matrix functions. Complementing our earlier paper, arXiv:2410.12765 (to appear in Advances in Applied Mathematics and Mechanics, 2025) based on a performance model, we extend the numerical investigation to higher-order Krylov approximations and new numerical regime, and assess their CPU-time efficiency relative to explicit Runge--Kutta schemes. We show that, depending on the problem setting, exponential integrators can either outperform or match explicit Runge--Kutta schemes. We also observe that Leja-based methods outperform Krylov iterations for large time steps, whereas for small time steps, Krylov-based methods provide better results than Leja-based methods.",
    "authors": [
      "Thi Tam Dang",
      "Trung Hau Hoang"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03680",
    "title": "Output-Constrained Controller with Fuzzy-Tuned Parameters for Overhead Cranes",
    "abstract": "This study proposes a fuzzy-adjusted nonlinear control method based on torque jitter output limit constraints for overhead crane systems with double pendulum effects. The proposed control method can effectively suppress swing and achieve precise positioning. Firstly, by enhancing the coupling relationship between the trolley displacement and swing angle, a composite signal with an error term was designed. Then, an energy-based Lyapunov function was constructed using the composite error signal, which incorporated a new formulation of the inertia matrix and potential energy function. Subsequently, using the backstepping method in conjunction with the hyperbolic tangent function, a controller with partial performance constraints was designed. In addition, to further enhance the system's dynamic performance, a fuzzy control scheme with online adjustable system parameters was designed. Finally, the stability of the system is proven using Lyapunov theory combined with LaSalle's invariance principle. Simulation results demonstrate that the proposed controller exhibits superior performance and robustness.",
    "authors": [
      "Dawei Zhao",
      "Kai Wang",
      "Xianglong Zhou",
      "Xin Ma",
      "Lei Jia"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03682",
    "title": "Knowing oneself with and through AI: From self-tracking to chatbots",
    "abstract": "This chapter examines how algorithms and artificial intelligence are transforming our practices of self-knowledge, self-understanding, and self-narration. Drawing on frameworks from distributed cognition, I analyse three key domains where AI shapes how and what we come to know about ourselves: self-tracking applications, technologically-distributed autobiographical memories, and narrative co-construction with Large Language Models (LLMs). While self-tracking devices promise enhanced self-knowledge through quantified data, they also impose particular frameworks that can crowd out other forms of self-understanding and promote self-optimization. Digital technologies increasingly serve as repositories for our autobiographical memories and self-narratives, offering benefits such as detailed record-keeping and scaffolding during difficult periods, but also creating vulnerabilities to algorithmic manipulation. Finally, conversational AI introduces new possibilities for interactive narrative construction that mimics interpersonal dialogue. While LLMs can provide valuable support for self-exploration, they also present risks of narrative deference and the construction of self-narratives that are detached from reality.",
    "authors": [
      "Lucy Osler"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03683",
    "title": "GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces",
    "abstract": "3D stylization is central to game development, virtual reality, and digital arts, where the demand for diverse assets calls for scalable methods that support fast, high-fidelity manipulation. Existing text-to-3D stylization methods typically distill from 2D image editors, requiring time-intensive per-asset optimization and exhibiting multi-view inconsistency due to the limitations of current text-to-image models, which makes them impractical for large-scale production. In this paper, we introduce GaussianBlender, a pioneering feed-forward framework for text-driven 3D stylization that performs edits instantly at inference. Our method learns structured, disentangled latent spaces with controlled information sharing for geometry and appearance from spatially-grouped 3D Gaussians. A latent diffusion model then applies text-conditioned edits on these learned representations. Comprehensive evaluations show that GaussianBlender not only delivers instant, high-fidelity, geometry-preserving, multi-view consistent stylization, but also surpasses methods that require per-instance test-time optimization - unlocking practical, democratized 3D stylization at scale.",
    "authors": [
      "Melis Ocal",
      "Xiaoyan Xing",
      "Yue Li",
      "Ngo Anh Vien",
      "Sezer Karaoglu",
      "Theo Gevers"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03684",
    "title": "A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection",
    "abstract": "This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.",
    "authors": [
      "Shahid Ansari",
      "Mahendra Kumar Gohil",
      "Yusuke Maeda",
      "Bishakh Bhattacharya"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03687",
    "title": "Active Visual Perception: Opportunities and Challenges",
    "abstract": "Active visual perception refers to the ability of a system to dynamically engage with its environment through sensing and action, allowing it to modify its behavior in response to specific goals or uncertainties. Unlike passive systems that rely solely on visual data, active visual perception systems can direct attention, move sensors, or interact with objects to acquire more informative data. This approach is particularly powerful in complex environments where static sensing methods may not provide sufficient information. Active visual perception plays a critical role in numerous applications, including robotics, autonomous vehicles, human-computer interaction, and surveillance systems. However, despite its significant promise, there are several challenges that need to be addressed, including real-time processing of complex visual data, decision-making in dynamic environments, and integrating multimodal sensory inputs. This paper explores both the opportunities and challenges inherent in active visual perception, providing a comprehensive overview of its potential, current research, and the obstacles that must be overcome for broader adoption.",
    "authors": [
      "Yian Li",
      "Xiaoyu Guo",
      "Hao Zhang",
      "Shuiwang Li",
      "Xiaowei Dai"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03688",
    "title": "AITutor-EvalKit: Exploring the Capabilities of AI Tutors",
    "abstract": "We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.",
    "authors": [
      "Numaan Naeem",
      "Kaushal Kumar Maurya",
      "Kseniia Petukhova",
      "Ekaterina Kochmar"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03694",
    "title": "SRPG: Semantically Reconstructed Privacy Guard for Zero-Trust Privacy in Educational Multi-Agent Systems",
    "abstract": "Multi-Agent Systems (MAS) with large language models (LLMs) enable personalized education but risk leaking minors personally identifiable information (PII) via unstructured dialogue. Existing privacy methods struggle to balance security and utility: role-based access control fails on unstructured text, while naive masking destroys pedagogical context. We propose SRPG, a privacy guard for educational MAS, using a Dual-Stream Reconstruction Mechanism: a strict sanitization stream ensures zero PII leakage, and a context reconstruction stream (LLM driven) recovers mathematical logic. This decouples instructional content from private data, preserving teaching efficacy. Tests on MathDial show SRPG works across models; with GPT-4o, it achieves 0.0000 Attack Success Rate (ASR) (zero leakage) and 0.8267 Exact Match, far outperforming the zero trust Pure LLM baseline (0.2138). SRPG effectively protects minors privacy without sacrificing mathematical instructional quality.",
    "authors": [
      "Shuang Guo",
      "Zihui Li"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03696",
    "title": "Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns",
    "abstract": "We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.",
    "authors": [
      "Mohammad Doost",
      "Mohammad Manthouri"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03697",
    "title": "On the Challenges of Energy-Efficiency Analysis in HPC Systems: Evaluating Synthetic Benchmarks and Gromacs",
    "abstract": "This paper discusses the challenges encountered when analyzing the energy efficiency of synthetic benchmarks and the Gromacs package on the Fritz and Alex HPC clusters. Experiments were conducted using MPI parallelism on full sockets of Intel Ice Lake and Sapphire Rapids CPUs, as well as Nvidia A40 and A100 GPUs. The metrics and measurements obtained with the Likwid and Nvidia profiling tools are presented, along with the results. The challenges and pitfalls encountered during experimentation and analysis are revealed and discussed. Best practices for future energy efficiency analysis studies are suggested.",
    "authors": [
      "Rafael Ravedutti Lucio Machado",
      "Jan Eitzinger",
      "Georg Hager",
      "Gerhard Wellein"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03701",
    "title": "Structured Uncertainty Similarity Score (SUSS): Learning a Probabilistic, Interpretable, Perceptual Metric Between Images",
    "abstract": "Perceptual similarity scores that align with human vision are critical for both training and evaluating computer vision models. Deep perceptual losses, such as LPIPS, achieve good alignment but rely on complex, highly non-linear discriminative features with unknown invariances, while hand-crafted measures like SSIM are interpretable but miss key perceptual properties. We introduce the Structured Uncertainty Similarity Score (SUSS); it models each image through a set of perceptual components, each represented by a structured multivariate Normal distribution. These are trained in a generative, self-supervised manner to assign high likelihood to human-imperceptible augmentations. The final score is a weighted sum of component log-probabilities with weights learned from human perceptual datasets. Unlike feature-based methods, SUSS learns image-specific linear transformations of residuals in pixel space, enabling transparent inspection through decorrelated residuals and sampling. SUSS aligns closely with human perceptual judgments, shows strong perceptual calibration across diverse distortion types, and provides localized, interpretable explanations of its similarity assessments. We further demonstrate stable optimization behavior and competitive performance when using SUSS as a perceptual loss for downstream imaging tasks.",
    "authors": [
      "Paula Seidler",
      "Neill D. F. Campbell",
      "Ivor J A Simpson"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03704",
    "title": "DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue",
    "abstract": "Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a \"Capacity-Stability Trade-off\": while smaller models incur an \"alignment tax\" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: this https URL",
    "authors": [
      "Yijun Liao"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03707",
    "title": "ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration",
    "abstract": "In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\\% with a high task success rate of 87.7\\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.",
    "authors": [
      "Sundas Rafat Mulkana",
      "Ronyu Yu",
      "Tanaya Guha",
      "Emma Li"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03712",
    "title": "A Hybrid Sequential Convex Programming Framework for Unbalanced Three-Phase AC OPF",
    "abstract": "This paper presents a hybrid Sequential Convex Programming (SCP) framework for solving the unbalanced three-phase AC Optimal Power Flow (OPF) problem. The method combines a fixed McCormick outer approximation of bilinear voltage-current terms, first-order Taylor linearisations, and an adaptive trust-region constraint to preserve feasibility and promote convergence. The resulting formulation remains convex at each iteration and ensures convergence to a stationary point that satisfies the first-order Karush-Kuhn-Tucker (KKT) conditions of the nonlinear OPF. Case studies on standard IEEE feeders and a real low-voltage (LV) network in Cyprus demonstrate high numerical accuracy with optimality gap below 0.1% and up to 2x faster runtimes compared to IPOPT. These results confirm that the method is accurate and computationally efficient for large-scale unbalanced distribution networks.",
    "authors": [
      "Sary Yehia",
      "Alessandra Parisio"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03715",
    "title": "DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction",
    "abstract": "This paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers a robust and scalable solution for large-scale 3D reconstruction.",
    "authors": [
      "Kaichen Zhang",
      "Tianxiang Sheng",
      "Xuanming Shi"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03718",
    "title": "Matrix Editing Meets Fair Clustering: Parameterized Algorithms and Complexity",
    "abstract": "We study the computational problem of computing a fair means clustering of discrete vectors, which admits an equivalent formulation as editing a colored matrix into one with few distinct color-balanced rows by changing at most $k$ values. While NP-hard in both the fairness-oblivious and the fair settings, the problem is well-known to admit a fixed-parameter algorithm in the former ``vanilla'' setting. As our first contribution, we exclude an analogous algorithm even for highly restricted fair means clustering instances. We then proceed to obtain a full complexity landscape of the problem, and establish tractability results which capture three means of circumventing our obtained lower bound: placing additional constraints on the problem instances, fixed-parameter approximation, or using an alternative parameterization targeting tree-like matrices.",
    "authors": [
      "Robert Ganian",
      "Hung P. Hoang",
      "Simon Wietheger"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03719",
    "title": "Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing",
    "abstract": "Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.",
    "authors": [
      "Seyed Mohammad Azimi-Abarghouyi",
      "Carlo Fischione",
      "Kaibin Huang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03720",
    "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at this https URL .",
    "authors": [
      "Tengyun Ma",
      "Jiaqi Yao",
      "Daojing He",
      "Shihao Peng",
      "Yu Li",
      "Shaohui Liu",
      "Zhuotao Tian"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03722",
    "title": "Tutorial on Large Language Model-Enhanced Reinforcement Learning for Wireless Networks",
    "abstract": "Reinforcement Learning (RL) has shown remarkable success in enabling adaptive and data-driven optimization for various applications in wireless networks. However, classical RL suffers from limitations in generalization, learning feedback, interpretability, and sample efficiency in dynamic wireless environments. Large Language Models (LLMs) have emerged as a transformative Artificial Intelligence (AI) paradigm with exceptional capabilities in knowledge generalization, contextual reasoning, and interactive generation, which have demonstrated strong potential to enhance classical RL. This paper serves as a comprehensive tutorial on LLM-enhanced RL for wireless networks. We propose a taxonomy to categorize the roles of LLMs into four critical functions: state perceiver, reward designer, decision-maker, and generator. Then, we review existing studies exploring how each role of LLMs enhances different stages of the RL pipeline. Moreover, we provide a series of case studies to illustrate how to design and apply LLM-enhanced RL in low-altitude economy networking, vehicular networks, and space-air-ground integrated networks. Finally, we conclude with a discussion on potential future directions for LLM-enhanced RL and offer insights into its future development in wireless networks.",
    "authors": [
      "Lingyi Cai",
      "Wenjie Fu",
      "Yuxi Huang",
      "Ruichen Zhang",
      "Yinqiu Liu",
      "Jiawen Kang",
      "Zehui Xiong",
      "Tao Jiang",
      "Dusit Niyato",
      "Xianbin Wang",
      "Shiwen Mao",
      "Xuemin Shen"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03723",
    "title": "Innovation by Displacement",
    "abstract": "New ideas are often thought to arise from recombining existing knowledge. Yet despite rapid publication growth - and expanding opportunities for recombination - scientific breakthroughs remain rare. This gap between productivity and progress challenges recombinant growth theory as the prevailing account of innovation. We argue that the limitation of this theory lies in treating ideas solely as complements, overlooking that breakthroughs often arise when ideas act as substitutes. To test this, we integrate scientist interviews, bibliometric validation, and machine learning analysis of 41 million papers (1965 - 2024). Interviews reveal that breakthroughs are marked not by novelty (Atypicality) alone but by their ability to displace dominant ideas (Disruption). Large-scale analysis confirms that novelty and disruption represent distinct innovation mechanisms: they are negatively correlated across domains, periods, team sizes, and paper versions. Novel papers extend dominant ideas across topics and attract immediate attention; disruptive papers displace them within the same topic and generate lasting influence. Hence, progress slows not from lack of effort but because most research extends rather than overturns ideas. Applying this perspective reveals distinct roles of theories and methods in scientific change: methods more often drive breakthroughs, whereas theories tend to be novel but rarely disruptive, reinforcing the dominance of established ideas.",
    "authors": [
      "Linzhuo Li",
      "Yiling Lin",
      "Lingfei Wu"
    ],
    "primary_category": "cs.DL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03724",
    "title": "PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention",
    "abstract": "The Vision-Language-Action (VLA) models have demonstrated remarkable performance on embodied tasks and shown promising potential for real-world applications. However, current VLAs still struggle to produce consistent and precise target-oriented actions, as they often generate redundant or unstable motions along trajectories, limiting their applicability in time-sensitive this http URL this work, we attribute these redundant actions to the spatially uniform perception field of existing VLAs, which causes them to be distracted by target-irrelevant objects, especially in complex this http URL address this issue, we propose an efficient PosA-VLA framework that anchors visual attention via pose-conditioned supervision, consistently guiding the model's perception toward task-relevant regions. The pose-conditioned anchor attention mechanism enables the model to better align instruction semantics with actionable visual cues, thereby improving action generation precision and efficiency. Moreover, our framework adopts a lightweight architecture and requires no auxiliary perception modules (e.g., segmentation or grounding networks), ensuring efficient inference. Extensive experiments verify that our method executes embodied tasks with precise and time-efficient behavior across diverse robotic manipulation benchmarks and shows robust generalization in a variety of challenging environments.",
    "authors": [
      "Ziwen Li",
      "Xin Wang",
      "Hanlue Zhang",
      "Runnan Chen",
      "Runqi Lin",
      "Xiao He",
      "Han Huang",
      "Yandong Guo",
      "Fakhri Karray",
      "Tongliang Liu",
      "Mingming Gong"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03728",
    "title": "AI/ML in 3GPP 5G Advanced - Services and Architecture",
    "abstract": "The 3rd Generation Partnership Project (3GPP), the standards body for mobile networks, is in the final phase of Release 19 standardization and is beginning Release 20. Artificial Intelligence/ Machine Learning (AI/ML) has brought about a paradigm shift in technology and it is being adopted across industries and verticals. 3GPP has been integrating AI/ML into the 5G advanced system since Release 18. This paper focuses on the AI/ML related technological advancements and features introduced in Release 19 within the Service and System Aspects (SA) Technical specifications group of 3GPP. The advancements relate to two paradigms: (i) enhancements that AI/ML brought to the 5G advanced system (AI for network), e.g. resource optimization, and (ii) enhancements that were made to the 5G system to support AI/ML applications (Network for AI), e.g. image recognition.",
    "authors": [
      "Pradnya Taksande",
      "Shwetha Kiran",
      "Pranav Jha",
      "Prasanna Chaporkar"
    ],
    "primary_category": "cs.ET",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03729",
    "title": "Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing",
    "abstract": "The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.",
    "authors": [
      "Samantha Chapin",
      "Kenneth Stewart",
      "Roxana Leontie",
      "Carl Glen Henshaw"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03730",
    "title": "Out-of-the-box: Black-box Causal Attacks on Object Detectors",
    "abstract": "Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.",
    "authors": [
      "Melane Navaratnarajah",
      "David A. Kelly",
      "Hana Chockler"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03733",
    "title": "A Superfast Direct Solver for Type-III Inverse Nonuniform Discrete Fourier Transform",
    "abstract": "The nonuniform discrete Fourier transform (NUDFT) and its inverse are widely used in various fields of scientific computing. In this article, we propose a novel superfast direct inversion method for type-III NUDFT. The proposed method approximates the type-III NUDFT matrix as a product of a type-II NUDFT matrix and an HSS matrix, where the type-II NUDFT matrix is further decomposed into the product of an HSS matrix and an uniform discrete Fourier transform (DFT) matrix as in [Wilber, Epperly, and Barnett, SIAM Journal on Scientific Computing, 47(3):A1702-A1732, 2025]. This decomposition enables both the forward application and the backward inversion to be accomplished with quasi-linear complexity. The fast inversion can serve as a high-accuracy direct solver or as an efficient preconditioner. Additionally, we provide an error bound for the approximation under specific sample distributions. Numerical results are presented to verify the relevant theoretical properties and demonstrate the efficiency of the proposed methods.",
    "authors": [
      "Yingzhou Li",
      "Jingyu Liu"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03736",
    "title": "Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control",
    "abstract": "Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.",
    "authors": [
      "Kenneth Stewart",
      "Samantha Chapin",
      "Roxana Leontie",
      "Carl Glen Henshaw"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03737",
    "title": "AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation",
    "abstract": "Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \\textbf{AR-Med}, a novel framework for \\textbf{A}utomated \\textbf{R}elevance assessment for \\textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\\%, a 24\\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.",
    "authors": [
      "Chuyue Wang",
      "Jie Feng",
      "Yuxi Wu",
      "Hang Zhang",
      "Zhiguo Fan",
      "Bing Cheng",
      "Wei Lin"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03741",
    "title": "An arbitrary Lagrangian-Eulerian semi-implicit hybrid method for continuum mechanics with GLM cleaning",
    "abstract": "This paper proposes a semi-implicit arbitrary Lagrangian-Eulerian (ALE) method for the solution of the unified Godunov-Peshkov-Romenski (GPR) model of continuum mechanics. To handle the curl free involutions arising in the solid limit of the model, the original system is augmented by adopting a thermodynamically compatible generalized Lagrangian multiplier (GLM) approach. Next, an operator splitting strategy decouples the computation of fast pressure waves from the bulk velocity of the medium yielding a transport subsystem, containing convective terms and non-conservative products, and a Poisson-type subsystem, for the pressure. A second splitting yields an ODE subsystem comprising only the potentially stiff source terms, responsible for the relaxation of the model between its fluid and solid limits. The mesh motion can be driven by two sources: the local fluid velocity and a prescribed boundary displacement. For the spatial discretization, we employ unstructured staggered grids, with the pressure defined on the primal mesh and all remaining variables on the dual grid. The transport subsystem is advanced via an explicit finite volume method, in which integration over closed space-time control volumes ensures verification of the geometric conservation law (GCL). On the other hand, implicit continuous finite elements are used for the discretization of the pressure subsystem and an implicit DIRK scheme is employed to solve the ODE subsystem. Consequently, the proposed approach is well suited to address all Mach number flows. A comprehensive set of benchmarks is employed to assess the accuracy and robustness of the proposed methodology in tackling both fluid and solid mechanics problems.",
    "authors": [
      "Saray Busto"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03743",
    "title": "Cross-embodied Co-design for Dexterous Hands",
    "abstract": "Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.",
    "authors": [
      "Kehlani Fay",
      "Darin Anthony Djapri",
      "Anya Zorin",
      "James Clinton",
      "Ali El Lahib",
      "Hao Su",
      "Michael T. Tolley",
      "Sha Yi",
      "Xiaolong Wang"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03744",
    "title": "Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm",
    "abstract": "Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and \"false recovery,\" where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining \"structural irreversibility detection\" and \"energy landscape reconstruction\" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.",
    "authors": [
      "Xuhui Lin",
      "Qiuchen Lu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03745",
    "title": "Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification",
    "abstract": "Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.",
    "authors": [
      "Jiaze Li",
      "Yan Lu",
      "Bin Liu",
      "Guojun Yin",
      "Mang Ye"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03746",
    "title": "Thinking with Programming Vision: Towards a Unified View for Thinking with Images",
    "abstract": "Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at this https URL .",
    "authors": [
      "Zirun Guo",
      "Minjie Hong",
      "Feng Zhang",
      "Kai Jia",
      "Tao Jin"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03749",
    "title": "Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models",
    "abstract": "Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.",
    "authors": [
      "Korada Sri Vardhana",
      "Shrikrishna Lolla",
      "Soma Biswas"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03750",
    "title": "Universally Converging Representations of Matter Across Scientific Foundation Models",
    "abstract": "Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.",
    "authors": [
      "Sathya Edamadaka",
      "Soojung Yang",
      "Ju Li",
      "Rafael Gómez-Bombarelli"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03751",
    "title": "Research on Brain Tumor Classification Method Based on Improved ResNet34 Network",
    "abstract": "Previously, image interpretation in radiology relied heavily on manual methods. However, manual classification of brain tumor medical images is time-consuming and labor-intensive. Even with shallow convolutional neural network models, the accuracy is not ideal. To improve the efficiency and accuracy of brain tumor image classification, this paper proposes a brain tumor classification model based on an improved ResNet34 network. This model uses the ResNet34 residual network as the backbone network and incorporates multi-scale feature extraction. It uses a multi-scale input module as the first layer of the ResNet34 network and an Inception v2 module as the residual downsampling layer. Furthermore, a channel attention mechanism module assigns different weights to different channels of the image from a channel domain perspective, obtaining more important feature information. The results after a five-fold crossover experiment show that the average classification accuracy of the improved network model is approximately 98.8%, which is not only 1% higher than ResNet34, but also only 80% of the number of parameters of the original model. Therefore, the improved network model not only improves accuracy but also reduces clutter, achieving a classification effect with fewer parameters and higher accuracy.",
    "authors": [
      "Yufeng Li",
      "Wenchao Zhao",
      "Bo Dang",
      "Weimin Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03755",
    "title": "Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition",
    "abstract": "Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \\to B \\ne B \\to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.",
    "authors": [
      "Stephen Law",
      "Tao Yang",
      "Nanjiang Chen",
      "Xuhui Lin"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03756",
    "title": "Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models",
    "abstract": "Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: this https URL .",
    "authors": [
      "Marlon Steiner",
      "Royden Wagner",
      "Ömer Sahin Tas",
      "Christoph Stiller"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03759",
    "title": "Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective",
    "abstract": "Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at this https URL .",
    "authors": [
      "Jingyang Ou",
      "Jiaqi Han",
      "Minkai Xu",
      "Shaoxuan Xu",
      "Jianwen Xie",
      "Stefano Ermon",
      "Yi Wu",
      "Chongxuan Li"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03762",
    "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design",
    "abstract": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.",
    "authors": [
      "Jiawei Xu",
      "Fengfeng Wei",
      "Weineng Chen"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03764",
    "title": "Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression",
    "abstract": "Policy gradient algorithms are widely used in reinforcement learning and belong to the class of approximate dynamic programming methods. This paper studies two key policy gradient algorithms - the Natural Policy Gradient and the Gauss-Newton Method - for solving the Linear Quadratic Regulator (LQR) problem in unknown stochastic linear systems. The main challenge lies in obtaining an unbiased gradient estimate from noisy data due to errors-in-variables in linear regression. This issue is addressed by employing a primal-dual estimation procedure. Using this novel gradient estimation scheme, the paper establishes convergence guarantees with a sample complexity of order O(1/epsilon). Theoretical results are further supported by numerical experiments, which demonstrate the effectiveness of the proposed algorithms.",
    "authors": [
      "Bowen Song",
      "Sebastien Gros",
      "Andrea Iannelli"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03765",
    "title": "The Treasury Proof Ledger: A Cryptographic Framework for Accountable Bitcoin Treasuries",
    "abstract": "Public companies and institutional investors that hold Bitcoin face increasing pressure to show solvency, manage risk, and satisfy regulatory expectations without exposing internal wallet structures or trading strategies. This paper introduces the Treasury Proof Ledger (TPL), a Bitcoin-anchored logging framework for multi-domain Bitcoin treasuries that treats on-chain and off-chain exposures as a conserved state machine with an explicit fee sink. A TPL instance records proof-of-reserves snapshots, proof-of-transit receipts for movements between domains, and policy metadata, and it supports restricted views based on stakeholder permissions. We define an idealised TPL model, represent Bitcoin treasuries as multi-domain exposure vectors, and give deployment-level security notions including exposure soundness, policy completeness, non-equivocation, and privacy-compatible policy views. We then outline how practical, restricted forms of these guarantees can be achieved by combining standard proof-of-reserves and proof-of-transit techniques with hash-based commitments anchored on Bitcoin. The results are existence-type statements: they show which guarantees are achievable once economic and governance assumptions are set, without claiming that any current system already provides them. A stylised corporate-treasury example illustrates how TPL could support responsible transparency policies and future cross-institution checks consistent with Bitcoin's fixed monetary supply.",
    "authors": [
      "Jose E. Puente",
      "Carlos Puente"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03766",
    "title": "Inaccessibility in Public Transit Networks",
    "abstract": "The study of networks derived from infrastructure systems has received considerable attention, yet the accessibility of such systems, particularly within public transit networks, remains comparatively underexplored. Accessibility encompasses a broad range of considerations, from infrastructure-based features such as elevators and step-free access to spatial factors such as the geographic distribution of accessible stations. In this work, we investigate infrastructure-based accessibility in two major transit systems: the London Underground and the New York City Subway. We construct network models in which nodes represent accessible stations and edges represent adjacency along transit lines. Using tools from network analysis, we examine the structural properties of these accessibility networks, including clustering patterns and the spatial distribution of accessible nodes. We further employ centrality measures to identify stations that serve as major accessible hubs. Finally, we analyze socioeconomic and tourism-related variables to assess the influence of neighborhood wealth and popularity on the prevalence of accessible stations. Our findings highlight significant disparities in accessibility across both systems and demonstrate the utility of mathematical and network-theoretic methods in understanding and improving modern transit infrastructure.",
    "authors": [
      "Katherine Betz"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03767",
    "title": "CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond",
    "abstract": "The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.",
    "authors": [
      "Bo Qian",
      "Hanlin Wu",
      "Jiacheng Chen",
      "Yunting Xu",
      "Xiaoyu Wang",
      "Haibo Zhou",
      "Yusheng Ji"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03768",
    "title": "Deep Unfolding: Recent Developments, Theory, and Design Guidelines",
    "abstract": "Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.",
    "authors": [
      "Nir Shlezinger",
      "Santiago Segarra",
      "Yi Zhang",
      "Dvir Avrahami",
      "Zohar Davidov",
      "Tirza Routtenberg",
      "Yonina C. Eldar"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03771",
    "title": "In-Context Representation Hijacking",
    "abstract": "We introduce \\textbf{Doublespeak}, a simple \\emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \\textit{bomb}) with a benign token (e.g., \\textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.",
    "authors": [
      "Itay Yona",
      "Amir Sarid",
      "Michael Karasik",
      "Yossi Gandelsman"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03772",
    "title": "Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control",
    "abstract": "This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.",
    "authors": [
      "Gabriele Fadini",
      "Deepak Ingole",
      "Tong Duy Son",
      "Alisa Rupenyan"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03774",
    "title": "Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving",
    "abstract": "Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.",
    "authors": [
      "Johannes Fischer",
      "Marlon Steiner",
      "Ömer Sahin Tas",
      "Christoph Stiller"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03775",
    "title": "\"MCP Does Not Stand for Misuse Cryptography Protocol\": Uncovering Cryptographic Misuse in Model Context Protocol at Scale",
    "abstract": "The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.",
    "authors": [
      "Biwei Yan",
      "Yue Zhang",
      "Minghui Xu",
      "Hao Wu",
      "Yechao Zhang",
      "Kun Li",
      "Guoming Zhang",
      "Xiuzhen Cheng"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03779",
    "title": "Exact and Parametric Dynamical System Representation of Nonlinear Functions",
    "abstract": "Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation.",
    "authors": [
      "Toshiyuki Ohtsuka"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03781",
    "title": "The BrainScaleS-2 multi-chip system: Interconnecting continuous-time neuromorphic compute substrates",
    "abstract": "The BrainScaleS-2 SoC integrates analog neuron and synapse circuits with digital periphery, including two CPUs with SIMD extensions. Each ASIC is connected to a Node-FPGA, providing experiment control and Ethernet connectivity. This work details the scaling of the compute substrate through FPGA-based interconnection via an additional Aggregator unit. The Aggregator provides up to 12 transceiver links to a backplane of Node-FPGAs, as well as 4 transceiver lanes for further extension. Two such interconnected backplanes are integrated into a standard 19in rack case with 4U height together with an Ethernet switch, system controller and power supplies. For all spike rates, chip-to-chip latencies -- consisting of four hops across three FPGAs -- below 1.3$\\mu$s are achieved within each backplane.",
    "authors": [
      "Joscha Ilmberger",
      "Johannes Schemmel"
    ],
    "primary_category": "cs.AR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03783",
    "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning",
    "abstract": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.",
    "authors": [
      "Dongchao Yang",
      "Songxiang Liu",
      "Disong Wang",
      "Yuanyuan Wang",
      "Guanglu Wan",
      "Helen Meng"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03784",
    "title": "Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop",
    "abstract": "Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.",
    "authors": [
      "Guisong Liu",
      "Jiansong Zhang",
      "Yinpei Luo",
      "Guoliang Wei",
      "Shuqing Sun",
      "Shiyang Deng",
      "Pengfei Wei",
      "Nanxi Chen"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03786",
    "title": "Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach",
    "abstract": "Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.",
    "authors": [
      "Conor McCarthy",
      "Jan Peter van Zandwijk",
      "Marcel Worring",
      "Zeno Geradts"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03787",
    "title": "Adaptive Identification and Modeling of Clinical Pathways with Process Mining",
    "abstract": "Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.",
    "authors": [
      "Francesco Vitale",
      "Nicola Mazzocca"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03790",
    "title": "ExOAR: Expert-Guided Object and Activity Recognition from Textual Data",
    "abstract": "Object-centric process mining requires structured data, but extracting it from unstructured text remains a challenge. We introduce ExOAR (Expert-Guided Object and Activity Recognition), an interactive method that combines large language models (LLMs) with human verification to identify objects and activities from textual data. ExOAR guides users through consecutive stages in which an LLM generates candidate object types, activities, and object instances based on contextual input, such as a user's profession, and textual data. Users review and refine these suggestions before proceeding to the next stage. Implemented as a practical tool, ExOAR is initially validated through a demonstration and then evaluated with real-world Active Window Tracking data from five users. Our results show that ExOAR can effectively bridge the gap between unstructured textual data and the structured log with clear semantics needed for object-centric process analysis, while it maintains flexibility and human oversight.",
    "authors": [
      "Iris Beerepoot",
      "Vinicius Stein Dani",
      "Xixi Lu"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03791",
    "title": "CCN: Decentralized Cross-Chain Channel Networks Supporting Secure and Privacy-Preserving Multi-Hop Interactions",
    "abstract": "Cross-chain technology enables interoperability among otherwise isolated blockchains, supporting interactions across heterogeneous networks. Similar to how multi-hop communication became fundamental in the evolution of the Internet, the demand for multi-hop cross-chain interactions is gaining increasing attention. However, this growing demand introduces new security and privacy challenges. On the security side, multi-hop interactions depend on the availability of multiple participating nodes. If any node becomes temporarily offline during execution, the protocol may fail to complete correctly, leading to settlement failure or fund loss. On the privacy side, the need for on-chain transparency to validate intermediate states may unintentionally leak linkable information, compromising the unlinkability of user interactions. In this paper, we propose the Cross-Chain Channel Network (CCN), a decentralized network designed to support secure and privacy-preserving multi-hop cross-chain transactions. Through experimental evaluation, we identify two critical types of offline failures, referred to as active and passive offline cases, which have not been adequately addressed by existing solutions. To mitigate these issues, we introduce R-HTLC, a core protocol within CCN. R-HTLC incorporates an hourglass mechanism and a multi-path refund strategy to ensure settlement correctness even when some nodes go offline during execution. Importantly, CCN addresses not only the correctness under offline conditions but also maintains unlinkability in such adversarial settings. To overcome this, CCN leverages zero-knowledge proofs and off-chain coordination, ensuring that interaction relationships remain indistinguishable even when certain nodes are temporarily offline.",
    "authors": [
      "Minghui Xu",
      "Yihao Guo",
      "Yanqiang Zhang",
      "Zhiguang Shan",
      "Guangyong Shang",
      "Zhen Ma",
      "Bin Xiao",
      "Xiuzhen Cheng"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03792",
    "title": "Unfolding Challenges in Securing and Regulating Unmanned Air Vehicles",
    "abstract": "Unmanned Aerial Vehicles (UAVs) or drones are being introduced in a wide range of commercial applications. This has also made them prime targets of attackers who compromise their fundamental security properties, including confidentiality, integrity, and availability. As researchers discover novel threat vectors in UAVs, the government and industry are increasingly concerned about their limited ability to secure and regulate UAVs and their usage. With the aim of unfolding a path for a large-scale commercial UAV network deployment, we conduct a comprehensive state-of-the-art study and examine the prevailing security challenges. Unlike the prior art, we focus on uncovering the research gaps that must be addressed to enforce security policy regulations in civilian off-the-shelf drone systems. To that end, we first examine the known security threats to UAVs based on their impact and effectiveness. We then analyze existing countermeasures to prevent, detect, and respond to these threats in terms of security and performance overhead. We further outline the future research directions for securing UAVs. Finally, we establish the fundamental requirements and highlight critical research challenges in introducing a regulatory entity to achieve a secure and regulated UAV network.",
    "authors": [
      "Sonali Rout",
      "Vireshwar Kumar"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03793",
    "title": "The enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice",
    "abstract": "Even though currently being challenged by ChatGPT and other large-language models (LLMs), Google Search remains one of the primary means for many individuals to find information on the internet. Interestingly, the way that we retrieve information on the web has hardly changed ever since Google was established in 1998, raising concerns as to Google's dominance in search and lack of competition. If the market for search was sufficiently competitive, then we should probably see a steady increase in search quality over time as well as alternative approaches to the Google's approach to search. However, hardly any research has so far looked at search quality, which is a key facet of a competitive market, especially not over time. In this report, we conducted a relatively large-scale quantitative comparison of search quality of 1,467 search queries relating to coding advice in October 2023. We focus on coding advice because the study of general search quality is difficult, with the aim of learning more about the assessment of search quality and motivating follow-up research into this important topic. We evaluate the search quality of Google Search, Microsoft Bing, and Apple Search, with a special emphasis on Apple Search, a widely used search engine that has never been explored in previous research. For the assessment of search quality, we use two independent metrics of search quality: 1) the number of trackers on the first search result, as a measure of privacy in web search, and 2) the average rank of the first Stack Overflow search result, under the assumption that Stack Overflow gives the best coding advice. Our results suggest that the privacy of search results is higher on Bing than on Google and Apple. Similarly, the quality of coding advice -- as measured by the average rank of Stack Overflow -- was highest on Bing.",
    "authors": [
      "Konrad Kollnig"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03794",
    "title": "AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition",
    "abstract": "Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.",
    "authors": [
      "Zichuan Lin",
      "Yicheng Liu",
      "Yang Yang",
      "Lvfang Tao",
      "Deheng Ye"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03795",
    "title": "MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving",
    "abstract": "Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.",
    "authors": [
      "Jia Hu",
      "Zhexi Lian",
      "Xuerun Yan",
      "Ruiang Bi",
      "Dou Shen",
      "Yu Ruan",
      "Haoran Wang"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03796",
    "title": "LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling",
    "abstract": "Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.",
    "authors": [
      "Hong-Kai Zheng",
      "Piji Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03803",
    "title": "Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5",
    "abstract": "Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.",
    "authors": [
      "Huey Sun",
      "Anabel Yong",
      "Lorenzo Gilly",
      "Felipe Jin"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03804",
    "title": "EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification",
    "abstract": "Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.",
    "authors": [
      "Hanhui Deng",
      "Xinglin Li",
      "Jie Luo",
      "Zhanpeng Jin",
      "Di Wu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03805",
    "title": "Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA",
    "abstract": "Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($\\lambda$,$\\lambda$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.",
    "authors": [
      "Tai Nguyen",
      "Phong Le",
      "André Biedenkapp",
      "Carola Doerr",
      "Nguyen Dang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03807",
    "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics",
    "abstract": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.",
    "authors": [
      "Christos Kolomvakis",
      "Thomas Bobille",
      "Arnaud Vandaele",
      "Nicolas Gillis"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03815",
    "title": "Runnable Directories: The Solution to the Monorepo vs. Multi-repo Debate",
    "abstract": "Modern software systems increasingly strain traditional codebase organization strategies. Monorepos offer consistency but often suffer from scalability issues and tooling complexity, while multi-repos provide modularity at the cost of coordination and dependency management challenges. As an answer to this trade-off, we present the Causify Dev system, a hybrid approach that integrates key benefits of both. Its central concept is the runnable directory -- a self-contained, independently executable unit with its own development, testing, and deployment lifecycles. Backed by a unified thin environment, shared helper utilities, and containerized Docker-based workflows, runnable directories enable consistent setups, isolated dependencies, and efficient CI/CD processes. The Causify Dev approach provides a practical middle ground between monorepo and multi-repo strategies, improving reliability and maintainability for growing, complex codebases.",
    "authors": [
      "Shayan Ghasemnezhad",
      "Samarth KaPatel",
      "Sofia Nikiforova",
      "Giacinto Paolo Saggese",
      "Paul Smith",
      "Heanh Sok"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03816",
    "title": "Log Probability Tracking of LLM APIs",
    "abstract": "When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.",
    "authors": [
      "Timothée Chauvin",
      "Erwan Le Merrer",
      "François Taïani",
      "Gilles Tredan"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03817",
    "title": "HieroGlyphTranslator: Automatic Recognition and Translation of Egyptian Hieroglyphs to English",
    "abstract": "Egyptian hieroglyphs, the ancient Egyptian writing system, are composed entirely of drawings. Translating these glyphs into English poses various challenges, including the fact that a single glyph can have multiple meanings. Deep learning translation applications are evolving rapidly, producing remarkable results that significantly impact our lives. In this research, we propose a method for the automatic recognition and translation of ancient Egyptian hieroglyphs from images to English. This study utilized two datasets for classification and translation: the Morris Franken dataset and the EgyptianTranslation dataset. Our approach is divided into three stages: segmentation (using Contour and Detectron2), mapping symbols to Gardiner codes, and translation (using the CNN model). The model achieved a BLEU score of 42.2, a significant result compared to previous research.",
    "authors": [
      "Ahmed Nasser",
      "Marwan Mohamed",
      "Alaa Sherif",
      "Basmala Mahmoud",
      "Shereen Yehia",
      "Asmaa Saad",
      "Mariam S. El-Rahmany",
      "Ensaf H. Mohamed"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03818",
    "title": "Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology",
    "abstract": "Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.",
    "authors": [
      "Kylie L. Anglin",
      "Stephanie Milan",
      "Brittney Hernandez",
      "Claudia Ventura"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03819",
    "title": "Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission",
    "abstract": "The widespread adoption of depth sensors has substantially lowered the barrier to point-cloud acquisition. This letter proposes a semantic wireless transmission framework for three dimension (3D) point clouds built on Deep Joint Source - Channel Coding (DeepJSCC). Instead of sending raw features, the transmitter predicts combination weights over a receiver-side semantic orthogonal feature pool, enabling compact representations and robust reconstruction. A folding-based decoder deforms a 2D grid into 3D, enforcing manifold continuity while preserving geometric fidelity. Trained with Chamfer Distance (CD) and an orthogonality regularizer, the system is evaluated on ModelNet40 across varying Signal-to-Noise Ratios (SNRs) and bandwidths. Results show performance on par with SEmantic Point cloud Transmission (SEPT) at high bandwidth and clear gains in bandwidth-constrained regimes, with consistent improvements in both Peak Signal-to-Noise Ratio (PSNR) and CD. Ablation experiments confirm the benefits of orthogonalization and the folding prior.",
    "authors": [
      "Junlin Chang",
      "Yubo Han",
      "Hnag Yue",
      "John S Thompson",
      "Rongke Liu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03825",
    "title": "Acceleration of Parallel Tempering for Markov Chain Monte Carlo methods",
    "abstract": "Markov Chain Monte Carlo methods are algorithms used to sample probability distributions, commonly used to sample the Boltzmann distribution of physical/chemical models (e.g., protein folding, Ising model, etc.). This allows us to study their properties by sampling the most probable states of those systems. However, the sampling capabilities of these methods are not sufficiently accurate when handling complex configuration spaces. This has resulted in the development of new techniques that improve sampling accuracy, usually at the expense of increasing the computational cost. One of such techniques is Parallel Tempering which improves accuracy by running several replicas which periodically exchange their states. Computationally, this imposes a significant slow-down, which can be counteracted by means of parallelization. These schemes enable MCMC/PT techniques to be run more effectively and allow larger models to be studied. In this work, we present a parallel implementation of Metropolis-Hastings with Parallel Tempering, using OpenMP and CUDA for the parallelization in modern CPUs and GPUs, respectively. The results show a maximum speed-up of 52x using OpenMP with 48 cores, and of 986x speed-up with the CUDA version. Furthermore, the results serve as a basic benchmark to compare a future quantum implementation of the same algorithm.",
    "authors": [
      "Aingeru Ramos",
      "Jose A Pascual",
      "Javier Navaridas",
      "Ivan Coluzza"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03827",
    "title": "A Robust Camera-based Method for Breath Rate Measurement",
    "abstract": "Proliferation of cheap and accessible cameras makes it possible to measure a subject's breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject's breath rate without any significant limitations on the subject's behavior.",
    "authors": [
      "Alexey Protopopov"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03828",
    "title": "IM HERE: Interaction Model for Human Effort Based Robot Engagement",
    "abstract": "The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.",
    "authors": [
      "Dominykas Strazdas",
      "Magnus Jung",
      "Jan Marquenie",
      "Ingo Siegert",
      "Ayoub Al-Hamadi"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03834",
    "title": "Lean Unet: A Compact Model for Image Segmentation",
    "abstract": "Unet and its variations have been standard in semantic image segmentation, especially for computer assisted radiology. Current Unet architectures iteratively downsample spatial resolution while increasing channel dimensions to preserve information content. Such a structure demands a large memory footprint, limiting training batch sizes and increasing inference latency. Channel pruning compresses Unet architecture without accuracy loss, but requires lengthy optimization and may not generalize across tasks and datasets. By investigating Unet pruning, we hypothesize that the final structure is the crucial factor, not the channel selection strategy of pruning. Based on our observations, we propose a lean Unet architecture (LUnet) with a compact, flat hierarchy where channels are not doubled as resolution is halved. We evaluate on a public MRI dataset allowing comparable reporting, as well as on two internal CT datasets. We show that a state-of-the-art pruning solution (STAMP) mainly prunes from the layers with the highest number of channels. Comparatively, simply eliminating a random channel at the pruning-identified layer or at the largest layer achieves similar or better performance. Our proposed LUnet with fixed architectures and over 30 times fewer parameters achieves performance comparable to both conventional Unet counterparts and data-adaptively pruned networks. The proposed lean Unet with constant channel count across layers requires far fewer parameters while achieving performance superior to standard Unet for the same total number of parameters. Skip connections allow Unet bottleneck channels to be largely reduced, unlike standard encoder-decoder architectures requiring increased bottleneck channels for information propagation.",
    "authors": [
      "Ture Hassler",
      "Ida Åkerholm",
      "Marcus Nordström",
      "Gabriele Balletti",
      "Orcun Goksel"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03835",
    "title": "Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN",
    "abstract": "The growing demand for robust, scalable wireless networks in the 5G-and-beyond era has led to the deployment of Unmanned Aerial Vehicles (UAVs) as mobile base stations to enhance coverage in dense urban and underserved rural areas. This paper presents a Multi-Agent Deep Reinforcement Learning (MADRL) framework that integrates Proximal Policy Optimization (MAPPO), Multi-Agent Deep Deterministic Policy Gradient (MADDPG), and Multi-Agent Deep Q-Networks (MADQN) to jointly optimize UAV positioning, resource allocation, Quality of Service (QoS), and energy efficiency through 5G network slicing. The framework adopts Centralized Training with Decentralized Execution (CTDE), enabling autonomous real-time decision-making while preserving global coordination. Users are prioritized into Premium (A), Silver (B), and Bronze (C) slices with distinct QoS requirements. Experiments in realistic urban and rural scenarios show that MAPPO achieves the best overall QoS-energy tradeoff, especially in interference-rich environments; MADDPG offers more precise continuous control and can attain slightly higher SINR in open rural settings at the cost of increased energy usage; and MADQN provides a computationally efficient baseline for discretized action spaces. These findings demonstrate that no single MARL algorithm is universally dominant; instead, algorithm suitability depends on environmental topology, user density, and service requirements. The proposed framework highlights the potential of MARL-driven UAV systems to enhance scalability, reliability, and differentiated QoS delivery in next-generation wireless networks.",
    "authors": [
      "Ghoshana Bista",
      "Abbas Bradai",
      "Emmanuel Moulay",
      "Abdulhalim Dandoush"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03837",
    "title": "Heatmap Pooling Network for Action Recognition from RGB Videos",
    "abstract": "Human action recognition (HAR) in videos has garnered widespread attention due to the rich information in RGB videos. Nevertheless, existing methods for extracting deep features from RGB videos face challenges such as information redundancy, susceptibility to noise and high storage costs. To address these issues and fully harness the useful information in videos, we propose a novel heatmap pooling network (HP-Net) for action recognition from videos, which extracts information-rich, robust and concise pooled features of the human body in videos through a feedback pooling module. The extracted pooled features demonstrate obvious performance advantages over the previously obtained pose data and heatmap features from videos. In addition, we design a spatial-motion co-learning module and a text refinement modulation module to integrate the extracted pooled features with other multimodal data, enabling more robust action recognition. Extensive experiments on several benchmarks namely NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome and UAV-Human consistently verify the effectiveness of our HP-Net, which outperforms the existing human action recognition methods. Our code is publicly available at: this https URL .",
    "authors": [
      "Mengyuan Liu",
      "Jinfu Liu",
      "Yongkang Jiang",
      "Bin He"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03838",
    "title": "Training and Evaluation of Guideline-Based Medical Reasoning in LLMs",
    "abstract": "Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.",
    "authors": [
      "Michael Staniek",
      "Artem Sokolov",
      "Stefan Riezler"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03839",
    "title": "A 3D virtual geographic environment for flood representation towards risk communication",
    "abstract": "Risk communication seeks to develop a shared understanding of disaster among stakeholders, thereby amplifying public awareness and empowering them to respond more effectively to emergencies. However, existing studies have overemphasized specialized numerical modelling, making the professional output challenging to understand and use by non-research stakeholders. In this context, this article proposes a 3D virtual geographic environment for flood representation towards risk communication, which integrates flood modelling, parallel computation, and 3D representation in a pipeline. Finally, a section of the Rhine River in Bonn, Germany, is selected for experiment analysis. The experimental results show that the proposed approach is capable of flood modelling and 3D representation within a few hours, the parallel speedup ratio reached 6.45. The intuitive flood scene with 3D city models is beneficial for promoting flood risk communication and is particularly helpful for participants without direct experience of floods to understand its spatiotemporal process. It also can be embedded in the Geospatial Infrastructure Management Ecosystem (GeoIME) cloud application for intelligent flood systems.",
    "authors": [
      "Weilian Li",
      "Jun Zhu",
      "Saied Pirasteh",
      "Qing Zhu",
      "Yukun Guo",
      "Lan Luo",
      "Youness Dehbi"
    ],
    "primary_category": "cs.CE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03840",
    "title": "Symplectic methods for stochastic Hamiltonian systems: asymptotic error distributions and Hamiltonian-specific analysis",
    "abstract": "In this paper, we investigate the asymptotic error distributions of symplectic methods for stochastic Hamiltonian systems and further provide Hamiltonian-specific analysis that clarifies the superiority of symplectic methods. Our contribution is threefold. First, we derive the asymptotic error distributions of symplectic methods for stochastic Hamiltonian systems with multiplicative noise and additive noise, respectively, and show that the obtained limiting stochastic processes satisfy equations retaining the Hamiltonian formulations. Second, we propose a new approach for calculating the asymptotic error distribution, revealing the connection between the stochastic modified equation and the asymptotic error distribution. Third, we characterize the limiting distribution of the normalized Hamiltonian deviation, thereby illustrating through test equations the superiority of symplectic methods for long-time simulations of the Hamiltonians, even in the limit as the step size tends to zero.",
    "authors": [
      "Chuchu Chen",
      "Xinyu Chen",
      "Jialin Hong",
      "Yuqian Miao"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03843",
    "title": "Robust Algorithms for Path and Cycle Problems in Geometric Intersection Graphs",
    "abstract": "We study the design of robust subexponential algorithms for classical connectivity problems on intersection graphs of similarly sized fat objects in $\\mathbb{R}^d$. In this setting, each vertex corresponds to a geometric object, and two vertices are adjacent if and only if their objects intersect. We introduce a new tool for designing such algorithms, which we call a $\\lambda$-linked partition. This is a partition of the vertex set into groups of highly connected vertices. Crucially, such a partition can be computed in polynomial time and does not require access to the geometric representation of the graph. We apply this framework to problems related to paths and cycles in graphs. First, we obtain the first robust ETH-tight algorithms for Hamiltonian Path and Hamiltonian Cycle, running in time $2^{O(n^{1-1/d})}$ on intersection graphs of similarly sized fat objects in $\\mathbb{R}^d$. This resolves an open problem of de Berg et al. [STOC 2018] and completes the study of these problems on geometric intersection graphs from the viewpoint of ETH-tight exact algorithms. We further extend our approach to the parameterized setting and design the first robust subexponential parameterized algorithm for Long Path in any fixed dimension $d$. More precisely, we obtain a randomized robust algorithm running in time $2^{O(k^{1-1/d}\\log^2 k)}\\, n^{O(1)}$ on intersection graphs of similarly sized fat objects in $\\mathbb{R}^d$, where $k$ is the natural parameter. Besides $\\lambda$-linked partitions, our algorithm also relies on a low-treewidth pattern covering theorem that we establish for geometric intersection graphs, which may be viewed as a refinement of a result of Marx-Pilipczuk [ESA 2017]. This structural result may be of independent interest.",
    "authors": [
      "Malory Marin",
      "Jean-Florent Raymond",
      "Rémi Watrigant"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03844",
    "title": "CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation",
    "abstract": "Prevailing Dataset Distillation (DD) methods leveraging generative models confront two fundamental limitations. First, despite pioneering the use of diffusion models in DD and delivering impressive performance, the vast majority of approaches paradoxically require a diffusion model pre-trained on the full target dataset, undermining the very purpose of DD and incurring prohibitive training costs. Second, although some methods turn to general text-to-image models without relying on such target-specific training, they suffer from a significant distributional mismatch, as the web-scale priors encapsulated in these foundation models fail to faithfully capture the target-specific semantics, leading to suboptimal performance. To tackle these challenges, we propose Core Distribution Alignment (CoDA), a framework that enables effective DD using only an off-the-shelf text-to-image model. Our key idea is to first identify the \"intrinsic core distribution\" of the target dataset using a robust density-based discovery mechanism. We then steer the generative process to align the generated samples with this core distribution. By doing so, CoDA effectively bridges the gap between general-purpose generative priors and target semantics, yielding highly representative distilled datasets. Extensive experiments suggest that, without relying on a generative model specifically trained on the target dataset, CoDA achieves performance on par with or even superior to previous methods with such reliance across all benchmarks, including ImageNet-1K and its subsets. Notably, it establishes a new state-of-the-art accuracy of 60.4% at the 50-images-per-class (IPC) setup on ImageNet-1K. Our code is available on the project webpage: this https URL",
    "authors": [
      "Letian Zhou",
      "Songhua Liu",
      "Xinchao Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03846",
    "title": "Fault-Tolerant Control of Steam Temperature in HRSG Superheater under Actuator Fault Using a Sliding Mode Observer and PINN",
    "abstract": "This paper presents a novel fault-tolerant control framework for steam temperature regulation in Heat Recovery Steam Generators (HRSGs) subject to actuator faults. Addressing the critical challenge of valve degradation in superheater spray attemperators, we propose a synergistic architecture comprising three components: (1) a Sliding Mode Observer (SMO) for estimation of unmeasured thermal states, (2) a Physics-Informed Neural Network (PINN) for estimating multiplicative actuator faults using physical laws as constraints, and (3) a one-sided Sliding Mode Controller (SMC) that adapts to the estimated faults while minimizing excessive actuation. The key innovation lies in the framework of closed-loop physics-awareness, where the PINN continuously informs both the observer and controller about fault severity while preserving thermodynamic consistency. Rigorous uniform ultimate boundedness (UUB) is established via Lyapunov analysis under practical assumptions. Validated on real HRSG operational data, the framework demonstrates effective fault adaptation, reduced temperature overshoot, and maintains steam temperature within 1°C of the setpoint under valve effectiveness loss. This work bridges control theory and physics-guided machine learning to deliver a practically deployable solution for power plant resilience, with extensions applicable to thermal systems subject to multiplicative faults.",
    "authors": [
      "Mojtaba Fanoodi",
      "Farzaneh Abdollahi",
      "Mahdi Aliyari Shoorehdeli"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03847",
    "title": "DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training",
    "abstract": "Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.",
    "authors": [
      "Dingwei Zhu",
      "Zhiheng Xi",
      "Shihan Dou",
      "Yuhui Wang",
      "Sixian Li",
      "Junjie Ye",
      "Honglin Guo",
      "Shichun Liu",
      "Chenhao Huang",
      "Yajie Yang",
      "Junlin Shang",
      "Senjie Jin",
      "Ming Zhang",
      "Jiazheng Zhang",
      "Caishuang Huang",
      "Yunke Zhang",
      "Demei Yan",
      "Yuran Wang",
      "Tao Gui"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03848",
    "title": "PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation",
    "abstract": "Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.",
    "authors": [
      "Hania Ghouse",
      "Maryam Alsharqi",
      "Farhad R. Nezami",
      "Muzammil Behzad"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03852",
    "title": "Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba",
    "abstract": "Traffic image restoration under adverse weather conditions remains a critical challenge for intelligent transportation systems. Existing methods primarily focus on spatial-domain modeling but neglect frequency-domain priors. Although the emerging Mamba architecture excels at long-range dependency modeling through patch-wise correlation analysis, its potential for frequency-domain feature extraction remains unexplored. To address this, we propose Frequency-Aware Mamba (FAMamba), a novel framework that integrates frequency guidance with sequence modeling for efficient image restoration. Our architecture consists of two key components: (1) a Dual-Branch Feature Extraction Block (DFEB) that enhances local-global interaction via bidirectional 2D frequency-adaptive scanning, dynamically adjusting traversal paths based on sub-band texture distributions; and (2) a Prior-Guided Block (PGB) that refines texture details through wavelet-based high-frequency residual learning, enabling high-quality image reconstruction with precise details. Meanwhile, we design a novel Adaptive Frequency Scanning Mechanism (AFSM) for the Mamba architecture, which enables the Mamba to achieve frequency-domain scanning across distinct subgraphs, thereby fully leveraging the texture distribution characteristics inherent in subgraph structures. Extensive experiments demonstrate the efficiency and effectiveness of FAMamba.",
    "authors": [
      "Liwen Pan",
      "Longguang Wang",
      "Guangwei Gao",
      "Jun Wang",
      "Jun Shi",
      "Juncheng Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03854",
    "title": "Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population",
    "abstract": "Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.",
    "authors": [
      "Peshawa J. Muhammad Ali",
      "Navin Vincent",
      "Saman S. Abdulla",
      "Han N. Mohammed Fadhl",
      "Anders Blilie",
      "Kelvin Szolnoky",
      "Julia Anna Mielcarz",
      "Xiaoyi Ji",
      "Kimmo Kartasalo",
      "Abdulbasit K. Al-Talabani",
      "Nita Mulliqi"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03861",
    "title": "Scalable Decision Focused Learning via Online Trainable Surrogates",
    "abstract": "Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.",
    "authors": [
      "Gaetano Signorelli",
      "Michele Lombardi"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03862",
    "title": "Diminishing Returns in Self-Supervised Learning",
    "abstract": "While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.",
    "authors": [
      "Oli Bridge",
      "Huey Sun",
      "Botond Branyicskai-Nagy",
      "Charles D'Ornano",
      "Shomit Basu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03864",
    "title": "Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment",
    "abstract": "Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\\times$ for training and 175 to 1000$\\times$ for inference. Furthermore, HDC reduces training times by 200$\\times$ and inference times by 300 to 600$\\times$, showcasing its potential for energy-efficient smart manufacturing.",
    "authors": [
      "Danny Hoang",
      "Anandkumar Patel",
      "Ruimen Chen",
      "Rajiv Malhotra",
      "Farhad Imani"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03868",
    "title": "A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software",
    "abstract": "Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.",
    "authors": [
      "Shree Hari Bittugondanahalli Indra Kumar",
      "Lilia Rodrigues Sampaio",
      "André Martin",
      "Andrey Brito",
      "Christof Fetzer"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03869",
    "title": "An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis",
    "abstract": "We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.",
    "authors": [
      "Daniele Falcetta",
      "Liane S. Canas",
      "Lorenzo Suppa",
      "Matteo Pentassuglia",
      "Jon Cleary",
      "Marc Modat",
      "Sébastien Ourselin",
      "Maria A. Zuluaga"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03870",
    "title": "Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers",
    "abstract": "Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.",
    "authors": [
      "Hongzhan Lin",
      "Zhiqi Bai",
      "Xinmiao Zhang",
      "Sen Yang",
      "Xiang Li",
      "Siran Yang",
      "Yunlong Xu",
      "Jiaheng Liu",
      "Yongchi Zhao",
      "Jiamang Wang",
      "Yuchi Xu",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03872",
    "title": "Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices",
    "abstract": "This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03874",
    "title": "OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance",
    "abstract": "Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.",
    "authors": [
      "Lei Zhang",
      "Diwen Zheng",
      "Kaixin Bai",
      "Zhenshan Bing",
      "Zoltan-Csaba Marton",
      "Zhaopeng Chen",
      "Alois Christian Knoll",
      "Jianwei Zhang"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03878",
    "title": "Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence",
    "abstract": "The growing global population of older adults, combined with ongoing healthcare workforce shortages, has increased reliance on informal caregivers, including family members and friends who provide unpaid support to individuals with chronic illnesses. Among their daily responsibilities, medication management remains one of the most demanding and error-prone tasks. Non-adherence to prescribed regimens not only undermines patient outcomes but also intensifies caregiver stress, anxiety, and fatigue. Although digital health technologies have proliferated to address adherence, most solutions focus exclusively on patients and neglect the informational and emotional needs of caregivers. This paper introduces Adhera, a caregiver-inclusive health informatics system designed to support medication adherence while reducing caregiver burden. Using a mixed-methods research design that included fifteen semi-structured caregiver interviews, sixty-five survey responses, and five pharmacist consultations, this study identified three primary challenges: caregiver stress related to uncertainty about medication intake, fragmented communication with healthcare professionals, and distrust in existing digital tools. Informed by the CeHRes Roadmap 2.0 and the Triple Bottom Line by Design and Culture (TBLD+C) framework, as well as recent co-design studies involving caregivers, Adhera integrates a sensor-equipped smart pill organizer with a mobile companion application that records intake events, sends real-time reminders, and provides caregivers with synchronized adherence data. Preliminary evaluation suggests that Adhera enhances visibility, improves caregiver confidence, and streamlines medication routines. This study contributes to the field of health informatics by demonstrating how human-centered design and collaborative frameworks can align technical innovation with empathy-driven care.",
    "authors": [
      "Zhiyin Zhou"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03879",
    "title": "Hybrid Temporal-8-Bit Spike Coding for Spiking Neural Network Surrogate Training",
    "abstract": "Spiking neural networks (SNNs) have emerged as a promising direction in both computational neuroscience and artificial intelligence, offering advantages such as strong biological plausibility and low energy consumption on neuromorphic hardware. Despite these benefits, SNNs still face challenges in achieving state-of-the-art performance on vision tasks. Recent work has shown that hybrid rate-temporal coding strategies (particularly those incorporating bit-plane representations of images into traditional rate coding schemes) can significantly improve performance when trained with surrogate backpropagation. Motivated by these findings, this study proposes a hybrid temporal-bit spike coding method that integrates bit-plane decompositions with temporal coding principles. Through extensive experiments across multiple computer vision benchmarks, we demonstrate that blending bit-plane information with temporal coding yields competitive, and in some cases improved, performance compared to established spike-coding techniques. To the best of our knowledge, this is the first work to introduce a hybrid temporal-bit coding scheme specifically designed for surrogate gradient training of SNNs.",
    "authors": [
      "Luu Trong Nhan",
      "Luu Trung Duong",
      "Pham Ngoc Nam",
      "Truong Cong Thang"
    ],
    "primary_category": "cs.NE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03882",
    "title": "Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models",
    "abstract": "Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.",
    "authors": [
      "Haidong Kang",
      "Wei Wu",
      "Hanling Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03883",
    "title": "Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy",
    "abstract": "Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\\% $\\pm$ 0.04), sensitivity (90.07\\% $\\pm$ 0.08), and specificity (72.86\\% $\\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\\pm$ 0.19) with SSDCA, confirming discriminative representation learning.",
    "authors": [
      "Jorge Tapias Gomez",
      "Despoina Kanata",
      "Aneesh Rangnekar",
      "Christina Lee",
      "Julio Garcia-Aguilar",
      "Joshua Jesse Smith",
      "Harini Veeraraghavan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03886",
    "title": "A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments",
    "abstract": "This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.",
    "authors": [
      "Brais Fontan-Costas",
      "M. Diaz-Cacho",
      "Ruben Fernandez-Boullon",
      "Manuel Alonso-Carracedo",
      "Javier Perez-Robles"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03887",
    "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)",
    "abstract": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow. The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation. We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at this https URL",
    "authors": [
      "Saurav Prateek"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03891",
    "title": "Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning",
    "abstract": "Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.",
    "authors": [
      "Ying-Kuan Tsai",
      "Yi-Ping Chen",
      "Vispi Karkaria",
      "Wei Chen"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03895",
    "title": "Parameter efficient hybrid spiking-quantum convolutional neural network with surrogate gradient and quantum data-reupload",
    "abstract": "The rapid advancement of artificial intelligence (AI) and deep learning (DL) has catalyzed the emergence of several optimization-driven subfields, notably neuromorphic computing and quantum machine learning. Leveraging the differentiable nature of hybrid models, researchers have explored their potential to address complex problems through unified optimization strategies. One such development is the Spiking Quantum Neural Network (SQNN), which combines principles from spiking neural networks (SNNs) and quantum computing. However, existing SQNN implementations often depend on pretrained SNNs due to the non-differentiable nature of spiking activity and the limited scalability of current SNN encoders. In this work, we propose a novel architecture, Spiking-Quantum Data Re-upload Convolutional Neural Network (SQDR-CNN), that enables joint training of convolutional SNNs and quantum circuits within a single backpropagation framework. Unlike its predecessor, SQDR-CNN allow convergence to reasonable performance without the reliance of pretrained spiking encoder and subsetting datasets. We also clarified some theoretical foundations, testing new design using quantum data-reupload with different training algorithm-initialization and evaluate the performance of the proposed model under noisy simulated quantum environments. As a result, we were able to achieve 86% of the mean top-performing accuracy of the SOTA SNN baselines, yet uses only 0.5% of the smallest spiking model's parameters. Through this integration of neuromorphic and quantum paradigms, we aim to open new research directions and foster technological progress in multi-modal, learnable systems.",
    "authors": [
      "Luu Trong Nhan",
      "Luu Trung Duong",
      "Pham Ngoc Nam",
      "Truong Cong Thang"
    ],
    "primary_category": "cs.NE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03899",
    "title": "Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction",
    "abstract": "Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.",
    "authors": [
      "Janis Keck",
      "Lukas Silvester Barth",
      "Fatemeh",
      "Fahimi",
      "Parvaneh Joharinad",
      "Jürgen Jost"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03903",
    "title": "BERnaT: Basque Encoders for Representing Natural Textual Diversity",
    "abstract": "Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.",
    "authors": [
      "Ekhi Azurmendi",
      "Joseba Fernandez de Landa",
      "Jaione Bengoetxea",
      "Maite Heredia",
      "Julen Etxaniz",
      "Mikel Zubillaga",
      "Ander Soraluze",
      "Aitor Soroa"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03905",
    "title": "Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence",
    "abstract": "The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.",
    "authors": [
      "Shuai Yang",
      "Junxin Lin",
      "Yifan Zhou",
      "Ziwei Liu",
      "Chen Change Loy"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03906",
    "title": "IBM Multilevel Process Mining vs de facto Object-Centric Process Mining approaches",
    "abstract": "The academic evolution of process mining is moving toward object centric process mining, marking a significant shift in how processes are modeled and analyzed. IBM has developed its own distinctive approach called Multilevel Process Mining. This paper provides a description of the two approaches and presents a comparative analysis of their respective advantages and limitations. IBM leveraged this comparison to drive the evolution of IBM Process Mining product, creating the new Organizational Mining feature, an innovation that combines the best of the two approaches. Demonstrate the potential of this novel, innovative and distinct methodology with an example.",
    "authors": [
      "Alberto Ronzoni",
      "Anina Antony",
      "Anjana M R",
      "Francesca De Leo",
      "Jesna Jose",
      "Mattia Freda",
      "Nandini Narayanankutty",
      "Rafflesia Khan",
      "Raji RV",
      "Thomas Diacci"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03911",
    "title": "Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware",
    "abstract": "We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.",
    "authors": [
      "Kenneth Stewart",
      "Roxana Leontie",
      "Samantha Chapin",
      "Joe Hays",
      "Sumit Bam Shrestha",
      "Carl Glen Henshaw"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03913",
    "title": "Hierarchical Vision Language Action Model Using Success and Failure Demonstrations",
    "abstract": "Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.",
    "authors": [
      "Jeongeun Park",
      "Jihwan Yoon",
      "Byungwoo Jeon",
      "Juhan Park",
      "Jinwoo Shin",
      "Namhoon Cho",
      "Kyungjae Lee",
      "Sangdoo Yun",
      "Sungjoon Choi"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03916",
    "title": "New Perspectives on Semiring Applications to Dynamic Programming",
    "abstract": "Semiring algebras have been shown to provide a suitable language to formalize many noteworthy combinatorial problems. For instance, the Shortest-Path problem can be seen as a special case of the Algebraic-Path problem when applied to the tropical semiring. The application of semirings typically makes it possible to solve extended problems without increasing the computational complexity. In this article we further exploit the idea of using semiring algebras to address and tackle several extensions of classical computational problems by dynamic programming. We consider a general approach which allows us to define a semiring extension of any problem with a reasonable notion of a certificate (e.g., an NP problem). This allows us to consider cost variants of these combinatorial problems, as well as their counting extensions where the goal is to determine how many solutions a given problem admits. The approach makes no particular assumptions (such as idempotence) on the semiring structure. We also propose a new associative algebraic operation on semirings, called $\\Delta$-product, which enables our dynamic programming algorithms to count the number of solutions of minimal costs. We illustrate the advantages of our framework on two well-known but computationally very different NP-hard problems, namely, Connected-Dominating-Set problems and finite-domain Constraint Satisfaction Problems (CSPs). In particular, we prove fixed parameter tractability (FPT) with respect to clique-width and tree-width of the input. This also allows us to count solutions of minimal cost, which is an overlooked problem in the literature.",
    "authors": [
      "Ambroise Baril",
      "Miguel Couceiro",
      "Victor Lagerkvist"
    ],
    "primary_category": "cs.CC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03918",
    "title": "UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework",
    "abstract": "We propose UniMo, an innovative autoregressive model for joint modeling of 2D human videos and 3D human motions within a unified framework, enabling simultaneous generation and understanding of these two modalities for the first time. Current methods predominantly focus on generating one modality given another as the condition or integrating either of them with other modalities such as text and audio. Unifying 2D videos and 3D motions for simultaneous optimization and generation remains largely unexplored, presenting significant challenges due to their substantial structural and distributional differences. Inspired by the LLM's ability to unify different modalities, our method models videos and 3D motions as a unified tokens sequence, utilizing separate embedding layers to mitigate distribution gaps. Additionally, we devise a sequence modeling strategy that integrates two distinct tasks within a single framework, proving the effectiveness of unified modeling. Moreover, to efficiently align with visual tokens and preserve 3D spatial information, we design a novel 3D motion tokenizer with a temporal expansion strategy, using a single VQ-VAE to produce quantized motion tokens. It features multiple expert decoders that handle body shapes, translation, global orientation, and body poses for reliable 3D motion reconstruction. Extensive experiments demonstrate that our method simultaneously generates corresponding videos and motions while performing accurate motion capture. This work taps into the capacity of LLMs to fuse diverse data types, paving the way for integrating human-centric information into existing models and potentially enabling multimodal, controllable joint modeling of humans, objects, and scenes.",
    "authors": [
      "Youxin Pang",
      "Yong Zhang",
      "Ruizhi Shao",
      "Xiang Deng",
      "Feng Gao",
      "Xu Xiaoming",
      "Xiaoming Wei",
      "Yebin Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03923",
    "title": "Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations",
    "abstract": "Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.",
    "authors": [
      "Xiang Rao",
      "Yina Liu",
      "Yuxuan Shen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03926",
    "title": "Tunable Automation in Automated Program Verification",
    "abstract": "Automated verification tools based on SMT solvers have made significant progress in verifying complex software systems. However, these tools face a fundamental tension between automation and performance when dealing with quantifier instantiation -- the primary source of incompleteness and verification slowdown in SMT-based verifiers. Tools choose between aggressive quantifier instantiation that provides more automation but longer verification times, or conservative instantiation that responds quickly but may require more manual proof hints. We present a mechanism that enables fine-grained control over the availability of quantified facts in verification contexts, allowing developers to selectively tune the level of automation. Our approach lets library authors provide different pre-defined automation levels while giving end-users the ability to further customize quantifier availability at the module, function, or proof context level. We implement our techniques in Verus, a Rust-based verification tool, and evaluate them on multiple openly available codebases. Our empirical analysis demonstrates the automation-performance tradeoff and that selective quantifier management enables developers to select the appropriate level of automation in different contexts.",
    "authors": [
      "Alexander Y. Bai",
      "Chris Hawblitzel",
      "Andrea Lattuada"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03927",
    "title": "OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference",
    "abstract": "Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.",
    "authors": [
      "Liujianfu Wang",
      "Yuyang Du",
      "Yuchen Pan",
      "Soung Chang Liew",
      "Jiacheng Liu",
      "Kexin Chen"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03928",
    "title": "Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization",
    "abstract": "We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.",
    "authors": [
      "Michele Alessi",
      "Alessio Ansuini",
      "Alex Rodriguez"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03931",
    "title": "Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties",
    "abstract": "This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).",
    "authors": [
      "Vineel Tummala",
      "Daniela Inclezan"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03932",
    "title": "Beyond the Ground Truth: Enhanced Supervision for Image Restoration",
    "abstract": "Deep learning-based image restoration has achieved significant success. However, when addressing real-world degradations, model performance is limited by the quality of ground-truth images in datasets due to practical constraints in data acquisition. To address this limitation, we propose a novel framework that enhances existing ground truth images to provide higher-quality supervision for real-world restoration. Our framework generates perceptually enhanced ground truth images using super-resolution by incorporating adaptive frequency masks, which are learned by a conditional frequency mask generator. These masks guide the optimal fusion of frequency components from the original ground truth and its super-resolved variants, yielding enhanced ground truth images. This frequency-domain mixup preserves the semantic consistency of the original content while selectively enriching perceptual details, preventing hallucinated artifacts that could compromise fidelity. The enhanced ground truth images are used to train a lightweight output refinement network that can be seamlessly integrated with existing restoration models. Extensive experiments demonstrate that our approach consistently improves the quality of restored images. We further validate the effectiveness of both supervision enhancement and output refinement through user studies. Code is available at this https URL .",
    "authors": [
      "Donghun Ryou",
      "Inju Ha",
      "Sanghyeok Chu",
      "Bohyung Han"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03936",
    "title": "Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response",
    "abstract": "Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.",
    "authors": [
      "Aron Distelzweig",
      "Yiwei Wang",
      "Faris Janjoš",
      "Marcel Hallgarten",
      "Mihai Dobre",
      "Alexander Langmann",
      "Joschka Boedecker",
      "Johannes Betz"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03937",
    "title": "DSP: A Statistically-Principled Structural Polarization Measure",
    "abstract": "Social and information networks may become polarized, leading to echo chambers and political gridlock. Accurately measuring this phenomenon is a critical challenge. Existing measures often conflate genuine structural division with random topological features, yielding misleadingly high polarization scores on random networks, and failing to distinguish real-world networks from randomized null models. We introduce DSP, a Diffusion-based Structural Polarization measure designed from first principles to correct for such biases. DSP removes the arbitrary concept of 'influencers' used by the popular Random Walk Controversy (RWC) score, instead treating every node as a potential origin for a random walk. To validate our approach, we introduce a set of desirable properties for polarization measures, expressed through reference topologies with known structural properties. We show that DSP satisfies these desiderata, being near-zero for non-polarized structures such as cliques and random networks, while correctly capturing the expected polarization of reference topologies such as monochromatic-splittable networks. Our method applied to U.S. Congress datasets uncovers trends of increasing polarization in recent years. By integrating a null model into its core definition, DSP provides a reliable and interpretable diagnostic tool, highlighting the necessity of statistically-grounded metrics to analyze societal fragmentation.",
    "authors": [
      "Giulia Preti",
      "Matteo Riondato",
      "Aristides Gionis",
      "Gianmarco De Francisci Morales"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03939",
    "title": "MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction",
    "abstract": "Recent stateful recurrent neural networks have achieved remarkable progress on static 3D reconstruction but remain vulnerable to motion-induced artifacts, where non-rigid regions corrupt attention propagation between the spatial memory and image feature. By analyzing the internal behaviors of the state and image token updating mechanism, we find that aggregating self-attention maps across layers reveals a consistent pattern: dynamic regions are naturally down-weighted, exposing an implicit motion cue that the pretrained transformer already encodes but never explicitly uses. Motivated by this observation, we introduce MUT3R, a training-free framework that applies the attention-derived motion cue to suppress dynamic content in the early layers of the transformer during inference. Our attention-level gating module suppresses the influence of dynamic regions before their artifacts propagate through the feature hierarchy. Notably, we do not retrain or fine-tune the model; we let the pretrained transformer diagnose its own motion cues and correct itself. This early regulation stabilizes geometric reasoning in streaming scenarios and leads to improvements in temporal consistency and camera pose robustness across multiple dynamic benchmarks, offering a simple and training-free pathway toward motion-aware streaming reconstruction.",
    "authors": [
      "Guole Shen",
      "Tianchen Deng",
      "Xingrui Qin",
      "Nailin Wang",
      "Jianyu Wang",
      "Yanbo Wang",
      "Yongtao Chen",
      "Hesheng Wang",
      "Jingchuan Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03943",
    "title": "Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions",
    "abstract": "While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.",
    "authors": [
      "Kazi Abrab Hossain",
      "Jannatul Somiya Mahmud",
      "Maria Hossain Tuli",
      "Anik Mitra",
      "S. M. Taiabul Haque",
      "Farig Y. Sadeque"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03945",
    "title": "Classification of User Satisfaction in HRI with Social Signals in the Wild",
    "abstract": "Socially interactive agents (SIAs) are being used in various scenarios and are nearing productive deployment. Evaluating user satisfaction with SIAs' performance is a key factor in designing the interaction between the user and SIA. Currently, subjective user satisfaction is primarily assessed manually through questionnaires or indirectly via system metrics. This study examines the automatic classification of user satisfaction through analysis of social signals, aiming to enhance both manual and autonomous evaluation methods for SIAs. During a field trial at the Deutsches Museum Bonn, a Furhat Robotics head was employed as a service and information hub, collecting an \"in-the-wild\" dataset. This dataset comprises 46 single-user interactions, including questionnaire responses and video data. Our method focuses on automatically classifying user satisfaction based on time series classification. We use time series of social signal metrics derived from the body pose, time series of facial expressions, and physical distance. This study compares three feature engineering approaches on different machine learning models. The results confirm the method's effectiveness in reliably identifying interactions with low user satisfaction without the need for manually annotated datasets. This approach offers significant potential for enhancing SIA performance and user experience through automated feedback mechanisms.",
    "authors": [
      "Michael Schiffmann",
      "Sabina Jeschke",
      "Anja Richert"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03955",
    "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol",
    "abstract": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.",
    "authors": [
      "Niklas Jobs",
      "Luis Miguel Vieira da Silva",
      "Jayanth Somashekaraiah",
      "Maximilian Weigand",
      "David Kube",
      "Felix Gehlhoff"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03958",
    "title": "MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation",
    "abstract": "Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: this https URL .",
    "authors": [
      "Xiaobei Zhao",
      "Xingqi Lyu",
      "Xiang Li"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03960",
    "title": "Aggregating maximal cliques in real-world graphs",
    "abstract": "Maximal clique enumeration is a fundamental graph mining task, but its utility is often limited by computational intractability and highly redundant output. To address these challenges, we introduce \\emph{$\\rho$-dense aggregators}, a novel approach that succinctly captures maximal clique structure. Instead of listing all cliques, we identify a small collection of clusters with edge density at least $\\rho$ that collectively contain every maximal clique. In contrast to maximal clique enumeration, we prove that for all $\\rho < 1$, every graph admits a $\\rho$-dense aggregator of \\emph{sub-exponential} size, $n^{O(\\log_{1/\\rho}n)}$, and provide an algorithm achieving this bound. For graphs with bounded degeneracy, a typical characteristic of real-world networks, our algorithm runs in near-linear time and produces near-linear size aggregators. We also establish a matching lower bound on aggregator size, proving our results are essentially tight. In an empirical evaluation on real-world networks, we demonstrate significant practical benefits for the use of aggregators: our algorithm is consistently faster than the state-of-the-art clique enumeration algorithm, with median speedups over $6\\times$ for $\\rho=0.1$ (and over $300\\times$ in an extreme case), while delivering a much more concise structural summary.",
    "authors": [
      "Noga Alon",
      "Sabyasachi Basu",
      "Shweta Jain",
      "Haim Kaplan",
      "Jakub Łącki",
      "Blair D. Sullivan"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03963",
    "title": "TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning",
    "abstract": "Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs' temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.",
    "authors": [
      "Tao Wu",
      "Li Yang",
      "Gen Zhan",
      "Yiting Liao",
      "Junlin Li",
      "Deliang Fu",
      "Li Zhang",
      "Limin Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03964",
    "title": "Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization",
    "abstract": "Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at this https URL",
    "authors": [
      "Lianyu Pang",
      "Ji Zhou",
      "Qiping Wang",
      "Baoquan Zhao",
      "Zhenguo Yang",
      "Qing Li",
      "Xudong Mao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03967",
    "title": "Technical Report on Text Dataset Distillation",
    "abstract": "In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.",
    "authors": [
      "Keith Ando Ogawa",
      "Bruno Lopes Yamamoto",
      "Lucas Lauton de Alcantara",
      "Victor Zacarias",
      "Edson Bollis",
      "Lucas Pellicer",
      "Rosimeire Pereira Costa",
      "Anna Helena Reali Costa",
      "Artur Jordao"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03971",
    "title": "Approximate Optimal Active Learning of Decision Trees",
    "abstract": "We consider the problem of actively learning an unknown binary decision tree using only membership queries, a setting in which the learner must reason about a large hypothesis space while maintaining formal guarantees. Rather than enumerating candidate trees or relying on heuristic impurity or entropy measures, we encode the entire space of bounded-depth decision trees symbolically in SAT formulas. We propose a symbolic method for active learning of decision trees, in which approximate model counting is used to estimate the reduction of the hypothesis space caused by each potential query, enabling near-optimal query selection without full model enumeration. The resulting learner incrementally strengthens a CNF representation based on observed query outcomes, and approximate model counter ApproxMC is invoked to quantify the remaining version space in a sound and scalable manner. Additionally, when ApproxMC stagnates, a functional equivalence check is performed to verify that all remaining hypotheses are functionally identical. Experiments on decision trees show that the method reliably converges to the correct model using only a handful of queries, while retaining a rigorous SAT-based foundation suitable for formal analysis and verification.",
    "authors": [
      "Zunchen Huang",
      "Chenglu Jin"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03972",
    "title": "OOPredictor: Predicting Object-Oriented Accesses using Static Analysis",
    "abstract": "Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders",
    "authors": [
      "Hassan Arafat",
      "David Bremner",
      "Kenneth B. Kent",
      "Julian Wang"
    ],
    "primary_category": "cs.PL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03973",
    "title": "Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: this https URL",
    "authors": [
      "Franki Nguimatsia Tiofack",
      "Théotime Le Hellard",
      "Fabian Schramm",
      "Nicolas Perrin-Gilbert",
      "Justin Carpentier"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03975",
    "title": "Sponsored Questions and How to Auction Them",
    "abstract": "Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow? This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded.",
    "authors": [
      "Kshipra Bhawalkar",
      "Alexandros Psomas",
      "Di Wang"
    ],
    "primary_category": "cs.GT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03976",
    "title": "Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study",
    "abstract": "Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\\rightarrow$ 1.54) and substantial improvements in Chinese$\\rightarrow$Tibetan translation quality (BLEU: 0.046 $\\rightarrow$ 0.261; chrF: 2.2 $\\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.",
    "authors": [
      "Lifeng Chen",
      "Ryan Lai",
      "Tianming Liu"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03977",
    "title": "An Information Theory of Finite Abstractions and their Fundamental Scalability Limits",
    "abstract": "Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy\" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.",
    "authors": [
      "Giannis Delimpaltadakis",
      "Gabriel Gleizer"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03979",
    "title": "BlurDM: A Blur Diffusion Model for Image Deblurring",
    "abstract": "Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at this https URL .",
    "authors": [
      "Jin-Ting He",
      "Fu-Jen Tsai",
      "Yan-Tsung Peng",
      "Min-Hung Chen",
      "Chia-Wen Lin",
      "Yen-Yu Lin"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03981",
    "title": "DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment",
    "abstract": "Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: this https URL . Code is available at: this https URL .",
    "authors": [
      "Sheng-Hao Liao",
      "Shang-Fu Chen",
      "Tai-Ming Huang",
      "Wen-Huang Cheng",
      "Kai-Lung Hua"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03988",
    "title": "HEART-Watch: A multimodal physiological dataset from a Google Pixel Watch across different physical states",
    "abstract": "Consumer-grade smartwatches offer a new personalized health monitoring option for general consumers globally as cardiovascular diseases continue to prevail as the leading cause of global mortality. The development and validation of reliable cardiovascular monitoring algorithms for these consumer-grade devices requires realistic biosignal data from diverse sets of participants. However, the availability of public consumer-grade smartwatch datasets with synchronized cardiovascular biosignals is limited, and existing datasets do not offer rich demographic diversity in their participant cohorts, leading to potentially biased algorithm development. This paper presents HEART-Watch, a multimodal physiological dataset collected from temporally synchronized wrist-worn Google Pixel Watch 2 electrocardiogram (ECG), photoplethysmography, and accelerometer signals from a diverse cohort of 40 healthy adults across three physical states - sitting, standing and walking with reference chest ECG. Intermittent upper arm blood pressure measurements and concurrent biosignals were collected as an additional biomarker for future research. The motivation, methodology, and initial analyses of results are presented. HEART-Watch is intended to support the development and benchmarking of robust algorithms for cardiovascular analyses on consumer-grade smartwatches across diverse populations.",
    "authors": [
      "Jathushan Kaetheeswaran",
      "Boyi Ma",
      "Ali Abedi",
      "Milad Lankarany",
      "Shehroz Khan"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03989",
    "title": "Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models",
    "abstract": "Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.",
    "authors": [
      "Taido Purason",
      "Pavel Chizhov",
      "Ivan P. Yamshchikov",
      "Mark Fishel"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03990",
    "title": "Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder",
    "abstract": "Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV.",
    "authors": [
      "Soha Ilbeigi",
      "Ashkan Bagherzadeh",
      "Alireza Sharifi"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03991",
    "title": "When to Say \"Hi\" - Learn to Open a Conversation with an in-the-wild Dataset",
    "abstract": "The social capabilities of socially interactive agents (SIA) are a key to successful and smooth interactions between the user and the SIA. A successful start of the interaction is one of the essential factors for satisfying SIA interactions. For a service and information task in which the SIA helps with information, e.g. about the location, it is an important skill to master the opening of the conversation and to recognize which interlocutor opens the conversation and when. We are therefore investigating the extent to which the opening of the conversation can be trained using the user's body language as an input for machine learning to ensure smooth conversation starts for the interaction. In this paper we propose the Interaction Initiation System (IIS) which we developed, trained and validated using an in-the-wild data set. In a field test at the Deutsches Museum Bonn, a Furhat robot from Furhat Robotics was used as a service and information point. Over the period of use we collected the data of \\textit{N} = 201 single user interactions for the training of the algorithms. We can show that the IIS, achieves a performance that allows the conclusion that this system is able to determine the greeting period and the opener of the interaction.",
    "authors": [
      "Michael Schiffmann",
      "Felix Struth",
      "Sabina Jeschke",
      "Anja Richert"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03992",
    "title": "DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation",
    "abstract": "Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.",
    "authors": [
      "Zexin Lin",
      "Hawen Wan",
      "Yebin Zhong",
      "Xiaoqiang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03994",
    "title": "Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs",
    "abstract": "Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: this https URL",
    "authors": [
      "Oren Rachmil",
      "Roy Betser",
      "Itay Gershon",
      "Omer Hofman",
      "Nitay Yakoby",
      "Yuval Meron",
      "Idan Yankelev",
      "Asaf Shabtai",
      "Yuval Elovici",
      "Roman Vainshtein"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03995",
    "title": "Artificial Microsaccade Compensation: Stable Vision for an Ornithopter",
    "abstract": "Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for \"Artificial Microsaccade Compensation\". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.",
    "authors": [
      "Levi Burner",
      "Guido de Croon",
      "Yiannis Aloimonos"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03996",
    "title": "Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation",
    "abstract": "Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \\href{ this https URL }{ this https URL }.",
    "authors": [
      "Hang Xu",
      "Linjiang Huang",
      "Feng Zhao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04000",
    "title": "Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding",
    "abstract": "The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.",
    "authors": [
      "Jialuo Li",
      "Bin Li",
      "Jiahao Li",
      "Yan Lu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04003",
    "title": "Mixed finite element approximation for non-divergence form elliptic equations with random input data",
    "abstract": "We consider an elliptic partial differential equation in non-divergence form with a random diffusion matrix and random forcing term. To address this, we propose a mixed-type continuous finite element discretization in the physical domain, combined with a collocation discretization in the stochastic domain. For the mixed formulation, we first introduce a stochastic cost functional at the continuous level. This formulation is then enhanced to incorporate the vanishing tangential trace constraint directly into a mesh-dependent cost functional, rather than enforcing it in the solution's function space. In this context, we define a mesh-dependent norm and provide an error analysis based on this norm. We employ the collocation method by collocating the stochastic equation at the zeros of suitable tensor product orthogonal polynomials. This approach leads to a system of uncoupled deterministic problems, simplifying computation. Furthermore, we establish an a poriori error bound for the fully discrete approximation, detailing the convergence rates with respect to the discretization parameters. Finally, numerical results are presented to confirm and validate the theoretical findings.",
    "authors": [
      "Amireh Mousavi"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04004",
    "title": "Physics-Embedded Gaussian Process for Traffic State Estimation",
    "abstract": "Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.",
    "authors": [
      "Yanlin Chen",
      "Kehua Chen",
      "Yinhai Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04006",
    "title": "Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics",
    "abstract": "Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.",
    "authors": [
      "Connall Garrod",
      "Jonathan P. Keating",
      "Christos Thrampoulidis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04007",
    "title": "On the Temporality for Sketch Representation Learning",
    "abstract": "Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.",
    "authors": [
      "Marcelo Isaias de Moraes Junior",
      "Moacir Antonelli Ponti"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04008",
    "title": "Efficient Public Verification of Private ML via Regularization",
    "abstract": "Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.",
    "authors": [
      "Zoë Ruha Bell",
      "Anvith Thudi",
      "Olive Franzese-McLaughlin",
      "Nicolas Papernot",
      "Shafi Goldwasser"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04009",
    "title": "Learning to Comparison-Shop",
    "abstract": "In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.",
    "authors": [
      "Jie Tang",
      "Daochen Zha",
      "Xin Liu",
      "Huiji Gao",
      "Liwei He",
      "Stephanie Moyerman",
      "Sanjeev Katariya"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04012",
    "title": "Emergent Outlier View Rejection in Visual Geometry Grounded Transformers",
    "abstract": "Reliable 3D reconstruction from in-the-wild image collections is often hindered by \"noisy\" images-irrelevant inputs with little or no view overlap with others. While traditional Structure-from-Motion pipelines handle such cases through geometric verification and outlier rejection, feed-forward 3D reconstruction models lack these explicit mechanisms, leading to degraded performance under in-the-wild conditions. In this paper, we discover that the existing feed-forward reconstruction model, e.g., VGGT, despite lacking explicit outlier-rejection mechanisms or noise-aware training, can inherently distinguish distractor images. Through an in-depth analysis under varying proportions of synthetic distractors, we identify a specific layer that naturally exhibits outlier-suppressing behavior. Further probing reveals that this layer encodes discriminative internal representations that enable an effective noise-filtering capability, which we simply leverage to perform outlier-view rejection in feed-forward 3D reconstruction without any additional fine-tuning or supervision. Extensive experiments on both controlled and in-the-wild datasets demonstrate that this implicit filtering mechanism is consistent and generalizes well across diverse scenarios.",
    "authors": [
      "Jisang Han",
      "Sunghwan Hong",
      "Jaewoo Jung",
      "Wooseok Jang",
      "Honggyu An",
      "Qianqian Wang",
      "Seungryong Kim",
      "Chen Feng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04013",
    "title": "AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving",
    "abstract": "As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality. This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.",
    "authors": [
      "Ying Wang",
      "Zhen Jin",
      "Jiexiong Xu",
      "Wenhai Lin",
      "Yiquan Chen",
      "Wenzhi Chen"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04015",
    "title": "Learning Group Actions In Disentangled Latent Image Representations",
    "abstract": "Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at this https URL .",
    "authors": [
      "Farhana Hossain Swarnali",
      "Miaomiao Zhang",
      "Tonmoy Hossain"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04019",
    "title": "Ultra-lightweight Neural Video Representation Compression",
    "abstract": "Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.",
    "authors": [
      "Ho Man Kwan",
      "Tianhao Peng",
      "Ge Gao",
      "Fan Zhang",
      "Mike Nilsson",
      "Andrew Gower",
      "David Bull"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04020",
    "title": "On topological and algebraic structures of categorical random variables",
    "abstract": "Based on entropy and symmetrical uncertainty (SU), we define a metric for categorical random variables and show that this metric can be promoted into an appropriate quotient space of categorical random variables. Moreover, we also show that there is a natural commutative monoid structure in the same quotient space, which is compatible with the topology induced by the metric, in the sense that the monoid operation is continuous.",
    "authors": [
      "Inocencio Ortiz",
      "Santiago Gómez-Guerrero",
      "Christian E. Schaerer"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04021",
    "title": "C3G: Learning Compact 3D Representations with 2K Gaussians",
    "abstract": "Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.",
    "authors": [
      "Honggyu An",
      "Jaewoo Jung",
      "Mungyeom Kim",
      "Sunghwan Hong",
      "Chaehyun Kim",
      "Kazumi Fukuda",
      "Minkyeong Jeon",
      "Jisang Han",
      "Takuya Narihira",
      "Hyuna Ko",
      "Junsu Kim",
      "Yuki Mitsufuji",
      "Seungryong Kim"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04022",
    "title": "Non-Linear Determinants of Pedestrian Injury Severity: Evidence from Administrative Data in Great Britain",
    "abstract": "This study investigates the non-linear determinants of pedestrian injury severity using administrative data from Great Britain's 2023 STATS19 dataset. To address inherent data-quality challenges, including missing information and substantial class imbalance, we employ a rigorous preprocessing pipeline utilizing mode imputation and Synthetic Minority Over-sampling (SMOTE). We utilize non-parametric ensemble methods (Random Forest and XGBoost) to capture complex interactions and heterogeneity often missed by linear models, while Shapley Additive Explanations are employed to ensure interpretability and isolate marginal feature effects. Our analysis reveals that vehicle count, speed limits, lighting, and road surface conditions are the primary predictors of severity, with police attendance and junction characteristics further distinguishing severe collisions. Spatially, while pedestrian risk is concentrated in dense urban Local Authority Districts (LADs), we identify that certain rural LADs experience disproportionately severe outcomes conditional on a collision occurring. These findings underscore the value of combining spatial analysis with interpretable machine learning to guide geographically targeted speed management, infrastructure investment, and enforcement strategies.",
    "authors": [
      "Yifei Tong"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04025",
    "title": "PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation",
    "abstract": "Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: this http URL",
    "authors": [
      "Xiaolong Li",
      "Youping Gu",
      "Xi Lin",
      "Weijie Wang",
      "Bohan Zhuang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04030",
    "title": "Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya",
    "abstract": "Community currencies (CCs) have been adopting innovative systems to overcome implementational hurdles from issuing paper currencies. Using a qualitative approach, this paper examined this digital transition of Sarafu Network in Kenya and its predecessor CCs as a case study. From the original vouchers launched in 2010, the foundation Grassroots Economics introduced a digital interface in 2016 that operates on a feature phone, and then integrated blockchain technology starting in 2018, undergoing several migrations before becoming settling on its current iteration called Community Asset Vouchers on the Celo blockchain since 2023. Using affordances from human-computer interaction, the research shows that digitalization and blockchain improved the facilitation of economic activities of the local communities, both their typical market transactions as well as traditional reciprocal labor exchanges, by offering more functionalities compared to the analog version of Sarafu. The unique contributions of blockchain include enabling automation of holding tax calculations and linking the vouchers to the mainstream monetary system via stablecoins facilitated by a series of smart contracts also known as the liquidity pool. The study also finds that there is an inherent trade-off between blockchain benefits and user interface complexity. Hence, balancing innovation and community needs remains a challenge.",
    "authors": [
      "Patricia Marcella Evite"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04032",
    "title": "Jina-VLM: Small Multilingual Vision Language Model",
    "abstract": "We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.",
    "authors": [
      "Andreas Koukounas",
      "Georgios Mastrapas",
      "Florian Hönicke",
      "Sedigheh Eslami",
      "Guillaume Roncari",
      "Scott Martens",
      "Han Xiao"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04034",
    "title": "Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions",
    "abstract": "Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.",
    "authors": [
      "Hong Yang",
      "Devroop Kar",
      "Qi Yu",
      "Alex Ororbia",
      "Travis Desell"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04039",
    "title": "Fast & Efficient Normalizing Flows and Applications of Image Generative Models",
    "abstract": "This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance. The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.",
    "authors": [
      "Sandeep Nagar"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04040",
    "title": "RELIC: Interactive Video World Model with Long-Horizon Memory",
    "abstract": "A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.",
    "authors": [
      "Yicong Hong",
      "Yiqun Mei",
      "Chongjian Ge",
      "Yiran Xu",
      "Yang Zhou",
      "Sai Bi",
      "Yannick Hold-Geoffroy",
      "Mike Roberts",
      "Matthew Fisher",
      "Eli Shechtman",
      "Kalyan Sunkavalli",
      "Feng Liu",
      "Zhengqi Li",
      "Hao Tan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04044",
    "title": "MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking",
    "abstract": "Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.",
    "authors": [
      "Yizhou Zhao",
      "Zhiwei Steven Wu",
      "Adam Block"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04046",
    "title": "Greedy techniques for inverse problems",
    "abstract": "Inverse imaging problems rely on limited and indirect measurements, making reconstruction highly dependent on both regularization and sample locations. We introduce a novel greedy framework for the optimal selection of indirect measurements in the operator codomain, specifically tailored to inverse problems. Our approach employs a two-step scheme combining kernel-based interpolation and extrapolation. Within this framework, greedy schemes can be residual-based, where points are selected according to the current approximation error for a specific target function, or error-based, where points are chosen using a priori error indicators independent of the residual. For the latter, we derive explicit error bounds that quantify the propagation of approximation errors through both interpolation and extrapolation. Numerical applications to solar hard X-ray imaging demonstrate that the proposed greedy sampling strategy achieves high-quality reconstructions using only a few available measurements.",
    "authors": [
      "L. Bruni Bruno",
      "P. Massa",
      "E. Perracchione",
      "M. Trombini"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04048",
    "title": "Stable Signer: Hierarchical Sign Language Generative Model",
    "abstract": "Sign Language Production (SLP) is the process of converting the complex input text into a real video. Most previous works focused on the Text2Gloss, Gloss2Pose, Pose2Vid stages, and some concentrated on Prompt2Gloss and Text2Avatar stages. However, this field has made slow progress due to the inaccuracy of text conversion, pose generation, and the rendering of poses into real human videos in these stages, resulting in gradually accumulating errors. Therefore, in this paper, we streamline the traditional redundant structure, simplify and optimize the task objective, and design a new sign language generative model called Stable Signer. It redefines the SLP task as a hierarchical generation end-to-end task that only includes text understanding (Prompt2Gloss, Text2Gloss) and Pose2Vid, and executes text understanding through our proposed new Sign Language Understanding Linker called SLUL, and generates hand gestures through the named SLP-MoE hand gesture rendering expert block to end-to-end generate high-quality and multi-style sign language videos. SLUL is trained using the newly developed Semantic-Aware Gloss Masking Loss (SAGM Loss). Its performance has improved by 48.6% compared to the current SOTA generation methods.",
    "authors": [
      "Sen Fang",
      "Yalin Feng",
      "Hongbin Zhong",
      "Yanxin Zhang",
      "Dimitris N. Metaxas"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04051",
    "title": "Convergence for Discrete Parameter Updates",
    "abstract": "Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.",
    "authors": [
      "Paul Wilson",
      "Fabio Zanasi",
      "George Constantinides"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04054",
    "title": "A Chronological Analysis of the Evolution of SmartNICs",
    "abstract": "Network Interface Cards (NICs) are one of the key enablers of the modern Internet. They serve as gateways for connecting computing devices to networks for the exchange of data with other devices. Recently, the pervasive nature of Internet-enabled devices coupled with the growing demands for faster network access have necessitated the enhancement of NICs to Smart NICs (SNICs), capable of processing enormous volumes of data at near real-time speed. However, despite their popularity, the exact use and applicability of SNICs remains an ongoing debate. These debates are exacerbated by the incorporation of accelerators into SNIC, allowing them to relieve their host's CPUs of various tasks. In this work, we carry out a chronological analysis of SNICs, using 370 articles published in the past 15 years, from 2010 to 2024, to gain some insight into SNICs; and shed some light on their evolution, manufacturers, use cases, and application domains.",
    "authors": [
      "Olasupo Ajayi",
      "Ryan Grant"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04062",
    "title": "Eval Factsheets: A Structured Framework for Documenting AI Evaluations",
    "abstract": "The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.",
    "authors": [
      "Florian Bordes",
      "Candace Ross",
      "Justine T Kao",
      "Evangelia Spiliopoulou",
      "Adina Williams"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04065",
    "title": "Fare Comparison App of Uber, Ola and Rapido",
    "abstract": "In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.",
    "authors": [
      "Ashlesha Gopinath Sawant",
      "Sahil S. Jadhav",
      "Vidhan R. Jain",
      "Shriraj S. Jagtap",
      "Prachi Jadhav",
      "Soham Jadhav",
      "Ichha Raina"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04068",
    "title": "Learning Steerable Clarification Policies with Collaborative Self-play",
    "abstract": "To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.",
    "authors": [
      "Jonathan Berant",
      "Maximillian Chen",
      "Adam Fisch",
      "Reza Aghajani",
      "Fantine Huot",
      "Mirella Lapata",
      "Jacob Eisenstein"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04069",
    "title": "SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL",
    "abstract": "Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: this https URL .",
    "authors": [
      "Siyi Chen",
      "Mikaela Angelina Uy",
      "Chan Hee Song",
      "Faisal Ladhak",
      "Adithyavairavan Murali",
      "Qing Qu",
      "Stan Birchfield",
      "Valts Blukis",
      "Jonathan Tremblay"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04072",
    "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors",
    "abstract": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These \"silver\" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.",
    "authors": [
      "Zayne Sprague",
      "Jack Lu",
      "Manya Wadhwa",
      "Sedrick Keh",
      "Mengye Ren",
      "Greg Durrett"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04074",
    "title": "Well-quasi-orders on embedded planar graphs",
    "abstract": "The central theorem of topological graph theory states that the graph minor relation is a well-quasi-order on graphs. It has far-reaching consequences, in particular in the study of graph structures and the design of (parameterized) algorithms. In this article, we study two embedded versions of classical minor relations from structural graph theory and prove that they are also well-quasi-orders on general or restricted classes of embedded planar graphs. These embedded minor relations appear naturally for intrinsically embedded objects, such as knot diagrams and surfaces in $\\mathbb{R}^3$. Handling the extra topological constraints of the embeddings requires careful analysis and extensions of classical methods for the more constrained embedded minor relations. We prove that the embedded version of immersion induces a well-quasi-order on bounded carving-width plane graphs by exhibiting particularly well-structured tree-decompositions and leveraging a classical argument on well-quasi-orders on forests. We deduce that the embedded graph minor relation defines a well-quasi-order on plane graphs via their directed medial graphs, when their branch-width is bounded. We conclude that the embedded graph minor relation is a well-quasi-order on all plane graphs, using classical grids theorems in the unbounded branch-width case.",
    "authors": [
      "Corentin Lunel",
      "Clément Maria"
    ],
    "primary_category": "cs.CG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04076",
    "title": "Radiance Meshes for Volumetric Reconstruction",
    "abstract": "We introduce radiance meshes, a technique for representing radiance fields with constant density tetrahedral cells produced with a Delaunay tetrahedralization. Unlike a Voronoi diagram, a Delaunay tetrahedralization yields simple triangles that are natively supported by existing hardware. As such, our model is able to perform exact and fast volume rendering using both rasterization and ray-tracing. We introduce a new rasterization method that achieves faster rendering speeds than all prior radiance field representations (assuming an equivalent number of primitives and resolution) across a variety of platforms. Optimizing the positions of Delaunay vertices introduces topological discontinuities (edge flips). To solve this, we use a Zip-NeRF-style backbone which allows us to express a smoothly varying field even when the topology changes. Our rendering method exactly evaluates the volume rendering equation and enables high quality, real-time view synthesis on standard consumer hardware. Our tetrahedral meshes also lend themselves to a variety of exciting applications including fisheye lens distortion, physics-based simulation, editing, and mesh extraction.",
    "authors": [
      "Alexander Mai",
      "Trevor Hedstrom",
      "George Kopanas",
      "Janne Kontkanen",
      "Falko Kuester",
      "Jonathan T. Barron"
    ],
    "primary_category": "cs.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04077",
    "title": "Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization",
    "abstract": "For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH).",
    "authors": [
      "Ismail Cosandal",
      "Sennur Ulukus",
      "Nail Akar"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04082",
    "title": "PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design",
    "abstract": "Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.",
    "authors": [
      "Jiazhe Wei",
      "Ken Li",
      "Tianyu Lao",
      "Haofan Wang",
      "Liang Wang",
      "Caifeng Shan",
      "Chenyang Si"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04084",
    "title": "SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows",
    "abstract": "Normalizing Flows (NFs) learn invertible mappings between the data and a Gaussian distribution. Prior works usually suffer from two limitations. First, they add random noise to training samples or VAE latents as data augmentation, introducing complex pipelines including extra noising and denoising steps. Second, they use a pretrained and frozen VAE encoder, resulting in suboptimal reconstruction and generation quality. In this paper, we find that the two issues can be solved in a very simple way: just fixing the variance (which would otherwise be predicted by the VAE encoder) to a constant (e.g., 0.5). On the one hand, this method allows the encoder to output a broader distribution of tokens and the decoder to learn to reconstruct clean images from the augmented token distribution, avoiding additional noise or denoising design. On the other hand, fixed variance simplifies the VAE evidence lower bound, making it stable to train an NF with a VAE jointly. On the ImageNet $256 \\times 256$ generation task, our model SimFlow obtains a gFID score of 2.15, outperforming the state-of-the-art method STARFlow (gFID 2.40). Moreover, SimFlow can be seamlessly integrated with the end-to-end representation alignment (REPA-E) method and achieves an improved gFID of 1.91, setting a new state of the art among NFs.",
    "authors": [
      "Qinyu Zhao",
      "Guangting Zheng",
      "Tao Yang",
      "Rui Zhu",
      "Xingjian Leng",
      "Stephen Gould",
      "Liang Zheng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04085",
    "title": "Unique Lives, Shared World: Learning from Single-Life Videos",
    "abstract": "We introduce the \"single-life\" learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person's life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.",
    "authors": [
      "Tengda Han",
      "Sayna Ebrahimi",
      "Dilara Gokay",
      "Li Yang Ku",
      "Maks Ovsjanikov",
      "Iva Babukova",
      "Daniel Zoran",
      "Viorica Patraucean",
      "Joao Carreira",
      "Andrew Zisserman",
      "Dima Damen"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03057",
    "title": "A note on the impossibility of conditional PAC-efficient reasoning in large language models",
    "abstract": "We prove an impossibility result for conditional Probably Approximately Correct (PAC)-efficient reasoning in large language models. While recent work has established marginal PAC efficiency guarantees for composite models that switch between expensive expert models and cheaper fast models, we show that conditional (pointwise) guarantees are impossible in the distribution-free setting. Specifically, for non-atomic input spaces, any algorithm achieving conditional PAC efficiency must be trivial in the sense that it defers to the expert model with probability at least $1-\\alpha$ for almost every input.",
    "authors": [
      "Hao Zeng"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03080",
    "title": "AtomDisc: An Atom-level Tokenizer that Boosts Molecular LLMs and Reveals Structure--Property Associations",
    "abstract": "Advances in large language models (LLMs) are accelerating discovery in molecular science. However, adapting molecular information to the serialized, token-based processing of LLMs remains a key challenge. Compared to other representations, molecular graphs explicitly encode atomic connectivity and local topological environments, which are key determinants of atomic behavior and molecular properties. Despite recent efforts to tokenize overall molecular topology, there still lacks effective fine-grained tokenization of local atomic environments, which are critical for determining sophisticated chemical properties and reactivity. To address these issues, we introduce AtomDisc, a novel framework that quantizes atom-level local environments into structure-aware tokens embedded directly in LLM's token space. Our experiments show that AtomDisc, in a data-driven way, can distinguish chemically meaningful structural features that reveal structure-property associations. Equipping LLMs with AtomDisc tokens injects an interpretable inductive bias that delivers state-of-the-art performance on property prediction and molecular generation. Our methodology and findings can pave the way for constructing more powerful molecular LLMs aimed at mechanistic insight and complex chemical reasoning.",
    "authors": [
      "Mingxu Zhang",
      "Dazhong Shen",
      "Ying Sun"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03081",
    "title": "Calibrating Geophysical Predictions under Constrained Probabilistic Distributions",
    "abstract": "Machine learning (ML) has shown significant promise in studying complex geophysical dynamical systems, including turbulence and climate processes. Such systems often display sensitive dependence on initial conditions, reflected in positive Lyapunov exponents, where even small perturbations in short-term forecasts can lead to large deviations in long-term outcomes. Thus, meaningful inference requires not only accurate short-term predictions, but also consistency with the system's long-term attractor that is captured by the marginal distribution of state variables. Existing approaches attempt to address this challenge by incorporating spatial and temporal dependence, but these strategies become impractical when data are extremely sparse. In this work, we show that prior knowledge of marginal distributions offers valuable complementary information to short-term observations, motivating a distribution-informed learning framework. We introduce a calibration algorithm based on normalization and the Kernelized Stein Discrepancy (KSD) to enhance ML predictions. The method here employs KSD within a reproducing kernel Hilbert space to calibrate model outputs, improving their fidelity to known physical distributions. This not only sharpens pointwise predictions but also enforces consistency with non-local statistical structures rooted in physical principles. Through synthetic experiments-spanning offline climatological CO2 fluxes and online quasi-geostrophic flow simulations-we demonstrate the robustness and broad utility of the proposed framework.",
    "authors": [
      "Zhewen Hou",
      "Jiajin Sun",
      "Subashree Venkatasubramanian",
      "Peter Jin",
      "Shuolin Li",
      "Tian Zheng"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03094",
    "title": "Performance Analysis of Quantum Support Vector Classifiers and Quantum Neural Networks",
    "abstract": "This study explores the performance of Quantum Support Vector Classifiers (QSVCs) and Quantum Neural Networks (QNNs) in comparison to classical models for machine learning tasks. By evaluating these models on the Iris and MNIST-PCA datasets, we find that quantum models tend to outperform classical approaches as the problem complexity increases. While QSVCs generally provide more consistent results, QNNs exhibit superior performance in higher-complexity tasks due to their increased quantum load. Additionally, we analyze the impact of hyperparameter tuning, showing that feature maps and ansatz configurations significantly influence model accuracy. We also compare the PennyLane and Qiskit frameworks, concluding that Qiskit provides better optimization and efficiency for our implementation. These findings highlight the potential of Quantum Machine Learning (QML) for complex classification problems and provide insights into model selection and optimization strategies",
    "authors": [
      "Tomás Villalba-Ferreiro",
      "Eduardo Mosqueira-Rey",
      "Diego Alvarez-Estevez"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03098",
    "title": "An AI Implementation Science Study to Improve Trustworthy Data in a Large Healthcare System",
    "abstract": "The rapid growth of Artificial Intelligence (AI) in healthcare has sparked interest in Trustworthy AI and AI Implementation Science, both of which are essential for accelerating clinical adoption. However, strict regulations, gaps between research and clinical settings, and challenges in evaluating AI systems continue to hinder real-world implementation. This study presents an AI implementation case study within Shriners Childrens (SC), a large multisite pediatric system, showcasing the modernization of SCs Research Data Warehouse (RDW) to OMOP CDM v5.4 within a secure Microsoft Fabric environment. We introduce a Python-based data quality assessment tool compatible with SCs infrastructure, extending OHDsi's R/Java-based Data Quality Dashboard (DQD) and integrating Trustworthy AI principles using the METRIC framework. This extension enhances data quality evaluation by addressing informative missingness, redundancy, timeliness, and distributional consistency. We also compare systematic and case-specific AI implementation strategies for Craniofacial Microsomia (CFM) using the FHIR standard. Our contributions include a real-world evaluation of AI implementations, integration of Trustworthy AI principles into data quality assessment, and insights into hybrid implementation strategies that blend systematic infrastructure with use-case-driven approaches to advance AI in healthcare.",
    "authors": [
      "Benoit L. Marteau",
      "Andrew Hornback",
      "Shaun Q. Tan",
      "Christian Lowson",
      "Jason Woloff",
      "May D. Wang"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03099",
    "title": "QGShap: Quantum Acceleration for Faithful GNN Explanations",
    "abstract": "Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at this https URL .",
    "authors": [
      "Haribandhu Jena",
      "Jyotirmaya Shivottam",
      "Subhankar Mishra"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03110",
    "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations",
    "abstract": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.",
    "authors": [
      "Steven Mascaro",
      "Owen Woodberry",
      "Charlie McLeod",
      "Mitch Messer",
      "Hiran Selvadurai",
      "Yue Wu",
      "Andre Schultz",
      "Thomas L Snelling"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03111",
    "title": "PanFoMa: A Lightweight Foundation Model and Benchmark for Pan-Cancer",
    "abstract": "Single-cell RNA sequencing (scRNA-seq) is essential for decoding tumor heterogeneity. However, pan-cancer research still faces two key challenges: learning discriminative and efficient single-cell representations, and establishing a comprehensive evaluation benchmark. In this paper, we introduce PanFoMa, a lightweight hybrid neural network that combines the strengths of Transformers and state-space models to achieve a balance between performance and efficiency. PanFoMa consists of a front-end local-context encoder with shared self-attention layers to capture complex, order-independent gene interactions; and a back-end global sequential feature decoder that efficiently integrates global context using a linear-time state-space model. This modular design preserves the expressive power of Transformers while leveraging the scalability of Mamba to enable transcriptome modeling, effectively capturing both local and global regulatory signals. To enable robust evaluation, we also construct a large-scale pan-cancer single-cell benchmark, PanFoMaBench, containing over 3.5 million high-quality cells across 33 cancer subtypes, curated through a rigorous preprocessing pipeline. Experimental results show that PanFoMa outperforms state-of-the-art models on our pan-cancer benchmark (+4.0\\%) and across multiple public tasks, including cell type annotation (+7.4\\%), batch integration (+4.0\\%) and multi-omics integration (+3.1\\%). The code is available at this https URL .",
    "authors": [
      "Xiaoshui Huang",
      "Tianlin Zhu",
      "Yifan Zuo",
      "Xue Xia",
      "Zonghan Wu",
      "Jiebin Yan",
      "Dingli Hua",
      "Zongyi Xu",
      "Yuming Fang",
      "Jian Zhang"
    ],
    "primary_category": "q-bio.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03193",
    "title": "In Situ Quantum Analog Pulse Characterization via Structured Signal Processing",
    "abstract": "Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults.",
    "authors": [
      "Yulong Dong",
      "Christopher Kang",
      "Murphy Yuezhen Niu"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03196",
    "title": "Ultra-Strong Gradient Diffusion MRI with Self-Supervised Learning for Prostate Cancer Characterization",
    "abstract": "Diffusion MRI (dMRI) enables non-invasive assessment of prostate microstructure but conventional metrics such as the Apparent Diffusion Coefficient in multiparametric MRI lack specificity to underlying histology. Integrating dMRI with the compartment-based biophysical VERDICT (Vascular, Extracellular, and Restricted Diffusion for Cytometry in Tumours) framework offers richer microstructural insights, though clinical gradient systems (40-80 mT/m) suffer from poor signal-to-noise ratio (SNR) at stronger diffusion weightings due to prolonged echo times. Ultra-strong gradients (up to 300 mT/m) can mitigate these limitations by improving SNR and contrast-to-noise ratios (CNR) but their adoption has until recently been limited to research environments due to challenges with peripheral nerve stimulation thresholds and gradient non-uniformity. This study investigates whether physics-informed self-supervised VERDICT (ssVERDICT) fitting applied to ultra-strong gradients enhances prostate cancer characterization relative to current clinical acquisitions. We developed enhanced ssVERDICT fitting approaches using dense multilayer perceptron (Dense MLP) and convolutional U-Net architectures, benchmarking them against non-linear least-squares (NLLS) fitting and Diffusion Kurtosis Imaging across clinical- to ultra-strong gradient systems. Dense ssVERDICT at ultra-strong gradient notably outperformed NLLS VERDICT, boosting median CNR by 47%, cutting inter-patient Coefficient of Variation by 52%, and reducing pooled f_ic variation by 50%. Overall, it delivered the highest CNR, the most stable parameter estimates, and the clearest tumour-normal contrast compared with conventional methods and clinical gradient systems. These findings highlight the potential of advanced gradient systems and deep learning-based modelling to improve non-invasive prostate cancer characterization and reduce unnecessary biopsies.",
    "authors": [
      "Tanishq Patil",
      "Snigdha Sen",
      "Malwina Molendowska",
      "Kieran G. Foley",
      "Fabrizio Fasano",
      "Mara Cercignani",
      "Marco Palombo",
      "Paddy J. Slator",
      "Eleftheria Panagiotaki"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03208",
    "title": "Uncertainty Quantification for Large Language Model Reward Learning under Heterogeneous Human Feedback",
    "abstract": "We study estimation and statistical inference for reward models used in aligning large language models (LLMs). A key component of LLM alignment is reinforcement learning from human feedback (RLHF), where humans compare pairs of model-generated answers and their preferences are used to train a reward model. However, human feedback is inherently heterogeneous, creating significant challenges for reliable reward learning. To address this, we adopt a heterogeneous preference framework that jointly models the latent reward of answers and human rationality. This leads to a challenging biconvex optimization problem, which we solve via an alternating gradient descent algorithm. We establish theoretical guarantees for the resulting estimator, including its convergence and asymptotic distribution. These results enable the construction of confidence intervals for reward estimates. Leveraging these uncertainty quantification results, we conduct valid statistical comparisons between rewards and incorporate uncertainty into the best-of-$N$ (BoN) policy framework. Extensive simulations demonstrate the effectiveness of our method, and applications to real LLM data highlight the practical value of accounting for uncertainty in reward modeling for LLM alignment.",
    "authors": [
      "Pangpang Liu",
      "Junwei Lu",
      "Will Wei Sun"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03216",
    "title": "Kaleidoscopic Scintillation Event Imaging",
    "abstract": "Scintillators are transparent materials that interact with high-energy particles and emit visible light as a result. They are used in state of the art methods of measuring high-energy particles and radiation sources. Most existing methods use fast single-pixel detectors to detect and time scintillation events. Cameras provide spatial resolution but can only capture an average over many events, making it difficult to image the events associated with an individual particle. Emerging single-photon avalanche diode cameras combine speed and spatial resolution to enable capturing images of individual events. This allows us to use machine vision techniques to analyze events, enabling new types of detectors. The main challenge is the very low brightness of the events. Techniques have to work with a very limited number of photons. We propose a kaleidoscopic scintillator to increase light collection in a single-photon camera while preserving the event's spatial information. The kaleidoscopic geometry creates mirror reflections of the event in known locations for a given event location that are captured by the camera. We introduce theory for imaging an event in a kaleidoscopic scintillator and an algorithm to estimate the event's 3D position. We find that the kaleidoscopic scintillator design provides sufficient light collection to perform high-resolution event measurements for advanced radiation imaging techniques using a commercial CMOS single-photon camera. Code and data are available at this https URL .",
    "authors": [
      "Alex Bocchieri",
      "John Mamish",
      "David Appleyard",
      "Andreas Velten"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03222",
    "title": "Game-Theoretic Learning-Based Mitigation of Insider Threats",
    "abstract": "An insider is defined as a team member who covertly deviates from the team's optimal collaborative control strategy in pursuit of a private objective, while maintaining an outward appearance of cooperation. Such insider threats can severely undermine cooperative systems: subtle deviations may degrade collective performance, jeopardize mission success, and compromise operational safety. This paper presents a comprehensive framework for identifying and mitigating insider threats in cooperative control settings. We introduce an insider-aware, game-theoretic formulation in which the insider's hidden intention is parameterized, allowing the threat identification task to be reformulated as a parameter estimation problem. To address this challenge, we employ an online indirect dual adaptive control approach that simultaneously infers the insider's control strategy and counteracts its negative influence. By injecting properly designed probing signals, the resulting mitigation policy asymptotically recovers the nominal optimal control law - one that would be achieved under full knowledge of the insider's objective. Simulation results validate the effectiveness of the proposed identification-mitigation framework and illustrate its capability to preserve team performance even in the presence of covert adversarial behavior.",
    "authors": [
      "Gehui Xu",
      "Kaiwen Chen",
      "Thomas Parisini",
      "Andreas A. Malikopoulos"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03224",
    "title": "Modeling and simulation of electrodiffusion in dense reconstructions of cerebral tissue",
    "abstract": "Excitable tissue is fundamental to brain function, yet its study is complicated by extreme morphological complexity and the physiological processes governing its dynamics. Consequently, detailed computational modeling of this tissue represents a formidable task, requiring both efficient numerical methods and robust implementations. Meanwhile, efficient and robust methods for image segmentation and meshing are needed to provide realistic geometries for which numerical solutions are tractable. Here, we present a computational framework that models electrodiffusion in excitable cerebral tissue, together with realistic geometries generated from electron microscopy data. To demonstrate a possible application of the framework, we simulate electrodiffusive dynamics in cerebral tissue during neuronal activity. Our results and findings highlight the numerical and computational challenges associated with modeling and simulation of electrodiffusion and other multiphysics in dense reconstructions of cerebral tissue.",
    "authors": [
      "Halvor Herlyng",
      "Marius Causemann",
      "Gaute T. Einevoll",
      "Ada J. Ellingsrud",
      "Geir Halnes",
      "Marie E. Rognes"
    ],
    "primary_category": "physics.med-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03225",
    "title": "Convergence of a class of gradient-free optimisation schemes when the objective function is noisy, irregular, or both",
    "abstract": "We investigate the convergence properties of a class of iterative algorithms designed to minimize a potentially non-smooth and noisy objective function, which may be algebraically intractable and whose values may be obtained as the output of a black box. The algorithms considered can be cast under the umbrella of a generalised gradient descent recursion, where the gradient is that of a smooth approximation of the objective function. The framework we develop includes as special cases model-based and mollification methods, two classical approaches to zero-th order optimisation. The convergence results are obtained under very weak assumptions on the regularity of the objective function and involve a trade-off between the degree of smoothing and size of the steps taken in the parameter updates. As expected, additional assumptions are required in the stochastic case. We illustrate the relevance of these algorithms and our convergence results through a challenging classification example from machine learning.",
    "authors": [
      "Christophe Andrieu",
      "Nicolas Chopin",
      "Ettore Fincato",
      "Mathieu Gerber"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03234",
    "title": "Iterative Tilting for Diffusion Fine-Tuning",
    "abstract": "We introduce iterative tilting, a gradient-free method for fine-tuning diffusion models toward reward-tilted distributions. The method decomposes a large reward tilt $\\exp(\\lambda r)$ into $N$ sequential smaller tilts, each admitting a tractable score update via first-order Taylor expansion. This requires only forward evaluations of the reward function and avoids backpropagating through sampling chains. We validate on a two-dimensional Gaussian mixture with linear reward, where the exact tilted distribution is available in closed form.",
    "authors": [
      "Jean Pachebat",
      "Giovanni Conforti",
      "Alain Durmus",
      "Yazid Janati"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03243",
    "title": "Novelty detection on path space",
    "abstract": "We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.",
    "authors": [
      "Ioannis Gasteratos",
      "Antoine Jacquier",
      "Maud Lemercier",
      "Terry Lyons",
      "Cristopher Salvi"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03312",
    "title": "Unlocking hidden biomolecular conformational landscapes in diffusion models at inference time",
    "abstract": "The function of biomolecules such as proteins depends on their ability to interconvert between a wide range of structures or \"conformations.\" Researchers have endeavored for decades to develop computational methods to predict the distribution of conformations, which is far harder to determine experimentally than a static folded structure. We present ConforMix, an inference-time algorithm that enhances sampling of conformational distributions using a combination of classifier guidance, filtering, and free energy estimation. Our approach upgrades diffusion models -- whether trained for static structure prediction or conformational generation -- to enable more efficient discovery of conformational variability without requiring prior knowledge of major degrees of freedom. ConforMix is orthogonal to improvements in model pretraining and would benefit even a hypothetical model that perfectly reproduced the Boltzmann distribution. Remarkably, when applied to a diffusion model trained for static structure prediction, ConforMix captures structural changes including domain motion, cryptic pocket flexibility, and transporter cycling, while avoiding unphysical states. Case studies of biologically critical proteins demonstrate the scalability, accuracy, and utility of this method.",
    "authors": [
      "Daniel D. Richman",
      "Jessica Karaguesian",
      "Carl-Mikael Suomivuori",
      "Ron O. Dror"
    ],
    "primary_category": "q-bio.BM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03325",
    "title": "When does Gaussian equivalence fail and how to fix it: Non-universal behavior of random features with quadratic scaling",
    "abstract": "A major effort in modern high-dimensional statistics has been devoted to the analysis of linear predictors trained on nonlinear feature embeddings via empirical risk minimization (ERM). Gaussian equivalence theory (GET) has emerged as a powerful universality principle in this context: it states that the behavior of high-dimensional, complex features can be captured by Gaussian surrogates, which are more amenable to analysis. Despite its remarkable successes, numerical experiments show that this equivalence can fail even for simple embeddings -- such as polynomial maps -- under general scaling regimes. We investigate this breakdown in the setting of random feature (RF) models in the quadratic scaling regime, where both the number of features and the sample size grow quadratically with the data dimension. We show that when the target function depends on a low-dimensional projection of the data, such as generalized linear models, GET yields incorrect predictions. To capture the correct asymptotics, we introduce a Conditional Gaussian Equivalent (CGE) model, which can be viewed as appending a low-dimensional non-Gaussian component to an otherwise high-dimensional Gaussian model. This hybrid model retains the tractability of the Gaussian framework and accurately describes RF models in the quadratic scaling regime. We derive sharp asymptotics for the training and test errors in this setting, which continue to agree with numerical simulations even when GET fails. Our analysis combines general results on CLT for Wiener chaos expansions and a careful two-phase Lindeberg swapping argument. Beyond RF models and quadratic scaling, our work hints at a rich landscape of universality phenomena in high-dimensional ERM.",
    "authors": [
      "Garrett G. Wen",
      "Hong Hu",
      "Yue M. Lu",
      "Zhou Fan",
      "Theodor Misiakiewicz"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03333",
    "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State",
    "abstract": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.",
    "authors": [
      "Xun Tang",
      "Haoxuan Chen",
      "Yuehaw Khoo",
      "Lexing Ying"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03434",
    "title": "Quantum Encrypted Control of Networked Systems",
    "abstract": "Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources.",
    "authors": [
      "Zihao Ren",
      "Daniel Quevedo",
      "Salah Sukkarieh",
      "Guodong Shi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03458",
    "title": "A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses",
    "abstract": "Decoding imagined speech engages complex neural processes that are difficult to interpret due to uncertainty in timing and the limited availability of imagined-response datasets. In this study, we present a Magnetoencephalography (MEG) dataset collected from trained musicians as they imagined and listened to musical and poetic stimuli. We show that both imagined and perceived brain responses contain consistent, condition-specific information. Using a sliding-window ridge regression model, we first mapped imagined responses to listened responses at the single-subject level, but found limited generalization across subjects. At the group level, we developed an encoder-decoder convolutional neural network with a subject-specific calibration layer that produced stable and generalizable mappings. The CNN consistently outperformed the null model, yielding significantly higher correlations between predicted and true listened responses for nearly all held-out subjects. Our findings demonstrate that imagined neural activity can be transformed into perception-like responses, providing a foundation for future brain-computer interface applications involving imagined speech and music.",
    "authors": [
      "Maryam Maghsoudi",
      "Mohsen Rezaeizadeh",
      "Shihab Shamma"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03460",
    "title": "Learning From Limited Data and Feedback for Cell Culture Process Monitoring: A Comparative Study",
    "abstract": "In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development.",
    "authors": [
      "Johnny Peng",
      "Thanh Tung Khuat",
      "Ellen Otte",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03497",
    "title": "Cell-cell communication inference and analysis: biological mechanisms, computational approaches, and future opportunities",
    "abstract": "In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field.",
    "authors": [
      "Xiangzheng Cheng",
      "Haili Huang",
      "Ye Su",
      "Qing Nie",
      "Xiufen Zou",
      "Suoqin Jin"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03524",
    "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities",
    "abstract": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.",
    "authors": [
      "Grzegorz Jamróz",
      "Rafał Kucharski",
      "David Watling"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03539",
    "title": "Real-Time Control and Automation Framework for Acousto-Holographic Microscopy",
    "abstract": "Manual operation of microscopes for repetitive tasks in cell biology is a significant bottleneck, consuming invaluable expert time, and introducing human error. Automation is essential, and while Digital Holographic Microscopy (DHM) offers powerful, label-free quantitative phase imaging (QPI), its inherently noisy and low-contrast holograms make robust autofocus and object detection challenging. We present the design, integration, and validation of a fully automated closed-loop DHM system engineered for high-throughput mechanical characterization of biological cells. The system integrates automated serpentine scanning, real-time YOLO-based object detection, and a high-performance, multi-threaded software architecture using pinned memory and SPSC queues. This design enables the GPU-accelerated reconstruction pipeline to run fully in parallel with the 50 fps data acquisition, adding no sequential overhead. A key contribution is the validation of a robust, multi-stage holographic autofocus strategy; we demonstrate that a selected metric (based on a low-pass filter and standard deviation) provides reliable focusing for noisy holograms where conventional methods (e.g., Tenengrad, Laplacian) fail entirely. Performance analysis of the complete system identifies the 2.23-second autofocus operation-not reconstruction-as the primary throughput bottleneck, resulting in a 9.62-second analysis time per object. This work delivers a complete functional platform for autonomous DHM screening and provides a clear, data-driven path for future optimization, proposing a hybrid brightfield imaging modality to address current bottlenecks.",
    "authors": [
      "Hasan Berkay Abdioğlu",
      "Yağmur Işık",
      "Mustafa İsmail İnal",
      "Nehir Serin",
      "Kerem Bayer",
      "Muhammed Furkan Koşar",
      "Taha Ünal",
      "Hüseyin Üvet"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03685",
    "title": "Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)",
    "abstract": "Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global Mølmer-Sørensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design.",
    "authors": [
      "Seng W. Loke"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03706",
    "title": "Consistent Projection of Langevin Dynamics: Preserving Thermodynamics and Kinetics in Coarse-Grained Models",
    "abstract": "Coarse graining (CG) is an important task for efficient modeling and simulation of complex multi-scale systems, such as the conformational dynamics of biomolecules. This work presents a projection-based coarse-graining formalism for general underdamped Langevin dynamics. Following the Zwanzig projection approach, we derive a closed-form expression for the coarse grained dynamics. In addition, we show how the generator Extended Dynamic Mode Decomposition (gEDMD) method, which was developed in the context of Koopman operator methods, can be used to model the CG dynamics and evaluate its kinetic properties, such as transition timescales. Finally, we combine our approach with thermodynamic interpolation (TI), a generative approach to transform samples between thermodynamic conditions, to extend the scope of the approach across thermodynamic states without repeated numerical simulations. Using a two-dimensional model system, we demonstrate that the proposed method allows to accurately capture the thermodynamic and kinetic properties of the full-space model.",
    "authors": [
      "Vahid Nateghi",
      "Lara Neureither",
      "Selma Moqvist",
      "Carsten Hartmann",
      "Simon Olsson",
      "Feliks Nüske"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03727",
    "title": "Colored Markov Random Fields for Probabilistic Topological Modeling",
    "abstract": "Probabilistic Graphical Models (PGMs) encode conditional dependencies among random variables using a graph -nodes for variables, links for dependencies- and factorize the joint distribution into lower-dimensional components. This makes PGMs well-suited for analyzing complex systems and supporting decision-making. Recent advances in topological signal processing highlight the importance of variables defined on topological spaces in several application domains. In such cases, the underlying topology shapes statistical relationships, limiting the expressiveness of canonical PGMs. To overcome this limitation, we introduce Colored Markov Random Fields (CMRFs), which model both conditional and marginal dependencies among Gaussian edge variables on topological spaces, with a theoretical foundation in Hodge theory. CMRFs extend classical Gaussian Markov Random Fields by including link coloring: connectivity encodes conditional independence, while color encodes marginal independence. We quantify the benefits of CMRFs through a distributed estimation case study over a physical network, comparing it with baselines with different levels of topological prior.",
    "authors": [
      "Lorenzo Marinucci",
      "Leonardo Di Nino",
      "Gabriele D'Acunto",
      "Mario Edoardo Pandolfo",
      "Paolo Di Lorenzo",
      "Sergio Barbarossa"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03788",
    "title": "Quantum Algorithm for Searching for the Longest Segment and the Largest Empty Rectangle",
    "abstract": "In the paper, we consider the problem of searching for the Largest empty rectangle in a 2D map, and the one-dimensional version of the problem is the problem of searching for the largest empty segment. We present a quantum algorithm for the Largest Empty Square problem and the Largest Empty Rectangle of a fixed width $d$ for $n\\times n$-rectangular map. Query complexity of the algorithm is $\\tilde{O}(n^{1.5})$ for the square case, and $\\tilde{O}(n\\sqrt{d})$ for the rectangle with a fixed width $d$ case, respectively. At the same time, the lower bounds for the classical case are $\\Omega(n^2)$, and $\\Omega(nd)$, respectively. The Quantum algorithm for the one-dimensional version of the problem has $O(\\sqrt{n}\\log n\\log\\log n)$ query complexity. The quantum lower bound for the problem is $\\Omega(\\sqrt{n})$ which is almost equal to the upper bound up to a log factor. The classical lower bound is $\\Omega(n)$. So, we obtain the quadratic speed-up for the problem.",
    "authors": [
      "Kamil Khadiev",
      "Vladislav Remidovskii",
      "Timur Bikmullin",
      "Aliya Khadieva"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03851",
    "title": "Comparison of neural network training strategies for the simulation of dynamical systems",
    "abstract": "Neural networks have become a widely adopted tool for modeling nonlinear dynamical systems from data. However, the choice of training strategy remains a key design decision, particularly for simulation tasks. This paper compares two predominant strategies: parallel and series-parallel training. The conducted empirical analysis spans five neural network architectures and two examples: a pneumatic valve test bench and an industrial robot benchmark. The study reveals that, even though series-parallel training dominates current practice, parallel training consistently yields better long-term prediction accuracy. Additionally, this work clarifies the often inconsistent terminology in the literature and relate both strategies to concepts from system identification. The findings suggest that parallel training should be considered the default training strategy for neural network-based simulation of dynamical systems.",
    "authors": [
      "Paul Strasser",
      "Andreas Pfeffer",
      "Jakob Weber",
      "Markus Gurtner",
      "Andreas Körner"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03866",
    "title": "Generating a Contact Matrix for Aged Care Settings in Australia: an agent-based model study",
    "abstract": "This study presents an agent-based model (ABM) developed to simulate staff and resident interactions within a synthetic aged care facility, capturing movement, task execution, and proximity-based contact events across three staff shifts and varying levels of resident care. Contacts were defined by spatial thresholds (1.5 m and 3 m) and cumulative duration, enabling the generation of detailed contact matrices. Simulation results showed that low and medium care residents experienced the highest frequency of interactions, particularly with staff on morning and afternoon shifts, while high care residents and night staff had substantially fewer contacts. Contact rates varied significantly by care level and shift, confirmed through Poisson-based regression modelling. Temporal analyses revealed clustering of high-risk contacts during structured daily routines, especially communal and care activities. An integrated airborne transmission module, seeded with a single infectious staff member, demonstrated that infection risk was highest during high-contact shifts and among medium care residents. Vaccination scenarios reduced predicted transmission by up to 68\\%, with the greatest impact observed when both staff and residents were vaccinated. These findings highlight the importance of accounting for contact heterogeneity in aged care and demonstrate the utility of ABMs for evaluating targeted infection control strategies in high-risk, enclosed environments.",
    "authors": [
      "Haley Stone",
      "C. Raina MacIntyre",
      "Mohana Kunasekaran",
      "Chris Poulos",
      "David Heslop"
    ],
    "primary_category": "q-bio.PE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03914",
    "title": "Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale",
    "abstract": "Efficient simulation of complex plasma dynamics is crucial for advancing fusion energy research. Particle-in-Cell (PIC) Monte Carlo (MC) simulations provide insights into plasma behavior, including turbulence and confinement, which are essential for optimizing fusion reactor performance. Transitioning to exascale simulations introduces significant challenges, with traditional file input/output (I/O) inefficiencies remaining a key bottleneck. This work advances BIT1, an electrostatic PIC MC code, by improving the particle mover with OpenMP task-based parallelism, integrating the openPMD streaming API, and enabling in-memory data streaming with ADIOS2's Sustainable Staging Transport (SST) engine to enhance I/O performance, computational efficiency, and system storage utilization. We employ profiling tools such as gprof, perf, IPM and Darshan, which provide insights into computation, communication, and I/O operations. We implement time-dependent data checkpointing with the openPMD API enabling seamless data movement and in-situ visualization for real-time analysis without interrupting the simulation. We demonstrate improvements in simulation runtime, data accessibility and real-time insights by comparing traditional file I/O with the ADIOS2 BP4 and SST backends. The proposed hybrid BIT1 openPMD SST enhancement introduces a new paradigm for real-time scientific discovery in plasma simulations, enabling faster insights and more efficient use of exascale computing resources.",
    "authors": [
      "Jeremy J. Williams",
      "Stefan Costea",
      "Daniel Medeiros",
      "Jordy Trilaksono",
      "Pratibha Hegde",
      "David Tskhakaya",
      "Leon Kos",
      "Ales Podolnik",
      "Jakub Hromadka",
      "Kevin A. Huck",
      "Allen D. Malony",
      "Frank Jenko",
      "Erwin Laure",
      "Stefano Markidis"
    ],
    "primary_category": "physics.plasm-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03915",
    "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models",
    "abstract": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.",
    "authors": [
      "X.Y. Han",
      "Yuan Zhong"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03930",
    "title": "A choice-based axiomatization of Nash equilibrium",
    "abstract": "An axiomatic characterization of Nash equilibrium is provided for games in normal form. The Nash equilibrium correspondence is shown to be fully characterized by four simple and intuitive axioms, two of which are inspired by contraction and expansion consistency properties from the literature on abstract choice theory. The axiomatization applies to Nash equilibria in pure and mixed strategies alike, to games with strategy sets of any cardinality, and it does not require that players' preferences have a utility or expected utility representation.",
    "authors": [
      "Michele Crescenzi"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03962",
    "title": "Tada-DIP: Input-adaptive Deep Image Prior for One-shot 3D Image Reconstruction",
    "abstract": "Deep Image Prior (DIP) has recently emerged as a promising one-shot neural-network based image reconstruction method. However, DIP has seen limited application to 3D image reconstruction problems. In this work, we introduce Tada-DIP, a highly effective and fully 3D DIP method for solving 3D inverse problems. By combining input-adaptation and denoising regularization, Tada-DIP produces high-quality 3D reconstructions while avoiding the overfitting phenomenon that is common in DIP. Experiments on sparse-view X-ray computed tomography reconstruction validate the effectiveness of the proposed method, demonstrating that Tada-DIP produces much better reconstructions than training-data-free baselines and achieves reconstruction performance on par with a supervised network trained using a large dataset with fully-sampled volumes.",
    "authors": [
      "Evan Bell",
      "Shijun Liang",
      "Ismail Alkhouri",
      "Saiprasad Ravishankar"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03974",
    "title": "Refining Machine Learning Potentials through Thermodynamic Theory of Phase Transitions",
    "abstract": "Foundational Machine Learning Potentials can resolve the accuracy and transferability limitations of classical force fields. They enable microscopic insights into material behavior through Molecular Dynamics simulations, which can crucially expedite material design and discovery. However, insufficiently broad and systematically biased reference data affect the predictive quality of the learned models. Often, these models exhibit significant deviations from experimentally observed phase transition temperatures, in the order of several hundred kelvins. Thus, fine-tuning is necessary to achieve adequate accuracy in many practical problems. This work proposes a fine-tuning strategy via top-down learning, directly correcting the wrongly predicted transition temperatures to match the experimental reference data. Our approach leverages the Differentiable Trajectory Reweighting algorithm to minimize the free energy differences between phases at the experimental target pressures and temperatures. We demonstrate that our approach can accurately correct the phase diagram of pure Titanium in a pressure range of up to 5 GPa, matching the experimental reference within tenths of kelvins and improving the liquid-state diffusion constant. Our approach is model-agnostic, applicable to multi-component systems with solid-solid and solid-liquid transitions, and compliant with top-down training on other experimental properties. Therefore, our approach can serve as an essential step towards highly accurate application-specific and foundational machine learning potentials.",
    "authors": [
      "Paul Fuchs",
      "Julija Zavadlav"
    ],
    "primary_category": "physics.comp-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04016",
    "title": "TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees",
    "abstract": "Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.",
    "authors": [
      "Davut Emre Tasar",
      "Ceren Ocal Tasar"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04031",
    "title": "Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study",
    "abstract": "This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.",
    "authors": [
      "Yixuan Li",
      "Yuhao Lu",
      "Yang Liu",
      "Liang Li",
      "R. Ruffini",
      "Di Li",
      "Rong-Gen Cai",
      "Xiaoyan Zhu",
      "Wenbin Lin",
      "Yu Wang"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04036",
    "title": "The Loss Landscape of Powder X-Ray Diffraction-Based Structure Optimization Is Too Rough for Gradient Descent",
    "abstract": "Solving crystal structures from powder X-ray diffraction (XRD) is a central challenge in materials characterization. In this work, we study the powder XRD-to-structure mapping using gradient descent optimization, with the goal of recovering the correct structure from moderately distorted initial states based solely on XRD similarity. We show that commonly used XRD similarity metrics result in a highly non-convex landscape, complicating direct optimization. Constraining the optimization to the ground-truth crystal family significantly improves recovery, yielding higher match rates and increased mutual information and correlation scores between structural similarity and XRD similarity. Nevertheless, the landscape may remain non-convex along certain symmetry axes. These findings suggest that symmetry-aware inductive biases could play a meaningful role in helping learning models navigate the inverse mapping from diffraction to structure.",
    "authors": [
      "Nofit Segal",
      "Akshay Subramanian",
      "Mingda Li",
      "Benjamin Kurt Miller",
      "Rafael Gomez-Bombarelli"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04047",
    "title": "Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs",
    "abstract": "In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.",
    "authors": [
      "Nadav Kunievsky"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04058",
    "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap",
    "abstract": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.",
    "authors": [
      "Shashaank Khanna",
      "Matthew Pusey",
      "Roger Colbeck"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2209.15402",
    "title": "Rethinking the Learning Paradigm for Facial Expression Recognition",
    "abstract": "Due to the subjective crowdsourcing annotations and the inherent inter-class similarity of facial expressions, the real-world Facial Expression Recognition (FER) datasets usually exhibit ambiguous annotation. To simplify the learning paradigm, most previous methods convert ambiguous annotation results into precise one-hot annotations and train FER models in an end-to-end supervised manner. In this paper, we rethink the existing training paradigm and propose that it is better to use weakly supervised strategies to train FER models with original ambiguous annotation.",
    "authors": [
      "Weijie Wang",
      "Bo Li",
      "Nicu Sebe",
      "Bruno Lepri"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2210.17139",
    "title": "Nested Sequents for Intuitionistic Grammar Logics via Structural Refinement",
    "abstract": "Intuitionistic grammar logics fuse constructive and multi-modal reasoning while permitting the use of converse modalities, serving as a generalization of standard intuitionistic modal logics. In this paper, we provide definitions of these logics as well as establish a suitable proof theory thereof. In particular, we show how to apply the structural refinement methodology to extract cut-free nested sequent calculi for intuitionistic grammar logics from their semantics. This method proceeds by first transforming the semantics of these logics into sound and complete labeled sequent systems, which we prove have favorable proof-theoretic properties such as syntactic cut-elimination. We then transform these labeled systems into nested sequent systems via the introduction of propagation rules and the elimination of structural rules. Our derived proof systems are then put to use, whereby we prove the conservativity of intuitionistic grammar logics over their modal counterparts, establish the general undecidability of these logics, and recognize a decidable subclass, referred to as \"simple\" intuitionistic grammar logics.",
    "authors": [
      "Tim S. Lyon"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2212.07356",
    "title": "Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks",
    "abstract": "Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.",
    "authors": [
      "Chung-Hsuan Hu",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2305.10937",
    "title": "The generalized Hierarchical Gaussian Filter",
    "abstract": "Hierarchical Bayesian models of perception and learning feature prominently in contemporary cognitive neuroscience where, for example, they inform computational concepts of mental disorders. This includes predictive coding and hierarchical Gaussian filtering (HGF), which differ in the nature of hierarchical representations. In this work, we present a new class of artificial neural networks that unifies computational principles of PC and HGFs. We extend the space of generative models underlying HGF to include a form of nonlinear hierarchical coupling between state values akin to predictive coding and artificial neural networks in general. We derive the update equations corresponding to this generalization of HGF and conceptualize them as connecting a network of (belief) nodes where parent nodes either predict the state of child nodes or their rate of change. This enables us to (1) create modular architectures with generic computational steps in each node of the network, and (2) disclose the hierarchical message passing implied by generalized HGF models and to compare this to comparable schemes under predictive coding. The practical advances of this work are twofold: on the one hand, our extension allows for a modular construction of ANNs of arbitrarily complex hierarchical structure under the general principles of HGF. On the other hand, by providing a highly flexible implementation of hierarchical Bayesian models available as open source software, it enables new types of empirical data analysis in computational psychiatry.",
    "authors": [
      "Lilian Aline Weber",
      "Peter Thestrup Waade",
      "Nicolas Legrand",
      "Anna Hedvig Møller",
      "Klaas Enno Stephan",
      "Christoph Mathys"
    ],
    "primary_category": "cs.NE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.08804",
    "title": "Capacity Bounds and Low-Complexity Constellation Shaping under Mixed Gaussian-Impulsive Noise",
    "abstract": "This paper investigates the bounds on channel capacity and constellation shaping under memoryless mixed noise, which is composed of impulsive noise (IN) and white Gaussian noise (WGN). The capacity bounds are derived using the entropy power inequality and the dual expression of capacity. It is then shown that the proposed lower and upper bounds asymptotically converge to the true channel capacity, and the analytic asymptotic capacity expression is obtained. Leveraging this property, we design a low-complexity constellation shaping method that operates without iterative procedures. Simulation results demonstrate that the derived bounds are remarkably tight, and the shaped constellation achieves the highest mutual information among all considered baseline schemes.",
    "authors": [
      "Tianfu Qi",
      "Jun Wang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2312.15478",
    "title": "A Group Fairness Lens for Large Language Models",
    "abstract": "The need to assess LLMs for bias and fairness is critical, with current evaluations often being narrow, missing a broad categorical view. In this paper, we propose evaluating the bias and fairness of LLMs from a group fairness lens using a novel hierarchical schema characterizing diverse social groups. Specifically, we construct a dataset, GFAIR, encapsulating target-attribute combinations across multiple dimensions. Moreover, we introduce statement organization, a new open-ended text generation task, to uncover complex biases in LLMs. Extensive evaluations of popular LLMs reveal inherent safety concerns. To mitigate the biases of LLMs from a group fairness perspective, we pioneer a novel chainof-thought method GF-THINK to mitigate biases of LLMs from a group fairness perspective. Experimental results demonstrate its efficacy in mitigating bias and achieving fairness in LLMs. Our dataset and codes are available at this https URL .",
    "authors": [
      "Guanqun Bi",
      "Yuqiang Xie",
      "Lei Shen",
      "Yanan Cao"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2402.14332",
    "title": "Accelerating data-driven algorithm selection for combinatorial partitioning problems",
    "abstract": "Data-driven algorithm selection is a powerful approach for choosing effective heuristics for computational problems. It operates by evaluating a set of candidate algorithms on a collection of representative training instances and selecting the one with the best empirical performance. However, running each algorithm on every training instance is computationally expensive, making scalability a central challenge. In practice, a common workaround is to evaluate algorithms on smaller proxy instances derived from the original inputs. However, this practice has remained largely ad hoc and lacked theoretical grounding. We provide the first theoretical foundations for this practice by formalizing the notion of size generalization: predicting an algorithm's performance on a large instance by evaluating it on a smaller, representative instance, subsampled from the original instance. We provide size generalization guarantees for three widely used clustering algorithms (single-linkage, $k$-means++, and Gonzalez's $k$-centers heuristic) and two canonical max-cut algorithms (Goemans-Williamson and Greedy). We characterize the subsample size sufficient to ensure that performance on the subsample reflects performance on the full instance, and our experiments support these findings.",
    "authors": [
      "Vaggos Chatziafratis",
      "Ishani Karmarkar",
      "Yingxi Li",
      "Ellen Vitercik"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.03631",
    "title": "Marginalize, Rather than Impute: Probabilistic Wind Power Forecasting with Incomplete Data",
    "abstract": "Machine learning methods are widely and successfully used for probabilistic wind power forecasting, yet the pervasive issue of missing values (e.g., due to sensor faults or communication outages) has received limited attention. The prevailing practice is impute-then-predict, but conditioning on point imputations biases parameter estimates and fails to propagate uncertainty from missing features. Our approach treats missing features and forecast targets uniformly: we learn a joint generative model of features and targets from incomplete data and, at operational deployment, condition on the observed features and marginalize the unobserved ones to produce forecasts. This imputation-free procedure avoids error introduced by imputation and preserves uncertainty aroused from missing features. In experiments, it improves forecast quality in terms of continuous ranked probability score relative to impute-then-predict baselines while incurring substantially lower computational cost than common alternatives.",
    "authors": [
      "Honglin Wen",
      "Pierre Pinson",
      "Jie Gu",
      "Zhijian Jin"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.05358",
    "title": "Variational Inference of Parameters in Opinion Dynamics Models",
    "abstract": "Despite the frequent use of agent-based models (ABMs) for studying social phenomena, parameter estimation remains a challenge, often relying on costly simulation-based heuristics. This work uses variational inference to estimate the parameters of an opinion dynamics ABM, by transforming the estimation problem into an optimization task that can be solved directly. Our proposal relies on probabilistic generative ABMs (PGABMs): we start by synthesizing a probabilistic generative model from the ABM rules. Then, we transform the inference process into an optimization problem suitable for automatic differentiation. In particular, we use the Gumbel-Softmax reparameterization for categorical agent attributes and stochastic variational inference for parameter estimation. Furthermore, we explore the trade-offs of using variational distributions with different complexity: normal distributions and normalizing flows. We validate our method on a bounded confidence model with agent roles (leaders and followers). Our approach estimates both macroscopic (bounded confidence intervals and backfire thresholds) and microscopic ($200$ categorical, agent-level roles) more accurately than simulation-based and MCMC methods. Consequently, our technique enables experts to tune and validate their ABMs against real-world observations, thus providing insights into human behavior in social systems via data-driven analysis.",
    "authors": [
      "Jacopo Lenti",
      "Fabrizio Silvestri",
      "Gianmarco De Francisci Morales"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.09060",
    "title": "GenRewrite: Query Rewriting via Large Language Models",
    "abstract": "Query rewriting is an effective technique for refining poorly written queries before they reach the query optimizer. However, manual rewriting is not scalable, as it is prone to errors and requires deep expertise. Traditional query rewriting algorithms fall short too: rule-based approaches fail to generalize to new query patterns, while synthesis-based methods struggle with complex queries. Fortunately, Large Language Models (LLMs) already possess broad knowledge and advanced reasoning capabilities, making them a promising solution for tackling these longstanding challenges. In this paper, we present GenRewrite, the first holistic system that leverages LLMs for query rewriting beyond traditional rules. We introduce the notion of Natural Language Rewrite Rules (NLR2s), which serve as hints for the LLM while also a means of knowledge transfer from rewriting one query to another, allowing GenRewrite to become smarter and more effective over time. We present a novel counterexample-guided technique that iteratively corrects the syntactic and semantic errors in the rewritten query, significantly reducing the LLM costs and the manual effort required for verification. Across the standard TPC-DS and JOB benchmarks and their SQLStorm-generated variants, GenRewrite consistently optimizes more queries at every speedup threshold than all baselines. At the >=2x threshold on TPC-DS, GenRewrite improves 25 queries-1.35x more than LLM-driven baselines and 2.6x more than LLM-enhanced rule-based baselines-and the gap widens further on TPC-DS (SQLStorm); on JOB and its SQLStorm variant, where queries are simpler, absolute gains are smaller but GenRewrite still leads by a notable margin.",
    "authors": [
      "Jie Liu",
      "Barzan Mozafari"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.09571",
    "title": "Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis",
    "abstract": "The tremendous hype around autonomous driving is eagerly calling for emerging and novel technologies to support advanced mobility use cases. As car manufactures keep developing SAE level 3+ systems to improve the safety and comfort of passengers, traffic authorities need to establish new procedures to manage the transition from human-driven to fully-autonomous vehicles while providing a feedback-loop mechanism to fine-tune envisioned autonomous systems. Thus, a way to automatically profile autonomous vehicles and differentiate those from human-driven ones is a must. In this paper, we present a fully-fledged framework that monitors active vehicles using camera images and state information in order to determine whether vehicles are autonomous, without requiring any active notification from the vehicles themselves. Essentially, it builds on the cooperation among vehicles, which share their data acquired on the road feeding a machine learning model to identify autonomous cars. We extensively tested our solution and created the NexusStreet dataset, by means of the CARLA simulator, employing an autonomous driving control agent and a steering wheel maneuvered by licensed drivers. Experiments show it is possible to discriminate the two behaviors by analyzing video clips with an accuracy of 80%, which improves up to 93% when the target state information is available. Lastly, we deliberately degraded the state to observe how the framework performs under non-ideal data collection conditions.",
    "authors": [
      "Fabio Maresca",
      "Filippo Grazioli",
      "Antonio Albanese",
      "Vincenzo Sciancalepore",
      "Gianpiero Negri",
      "Xavier Costa-Perez"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.10934",
    "title": "Quaternion-Based Sliding Mode Control for Six Degrees of Freedom Flight Control of Quadrotors",
    "abstract": "Despite extensive research on sliding mode control (SMC) design for quadrotors, the existing approaches suffer from certain limitations. Euler angle-based SMC formulations suffer from poor performance in high-pitch or -roll maneuvers. Quaternion-based SMC approaches have unwinding issues and complex architecture. Coordinate-free methods are slow and only almost globally stable. This paper presents a new six degrees of freedom SMC flight controller to address the above limitations. We use a cascaded architecture with a position controller in the outer loop and a quaternion-based attitude controller in the inner loop. The position controller generates the desired trajectory for the attitude controller using a coordinate-free approach. The quaternion-based attitude controller uses the natural characteristics of the quaternion hypersphere, featuring a simple structure while providing global stability and avoiding unwinding issues. We compare our controller with three other common control methods conducting challenging maneuvers like flip-over and high-speed trajectory tracking in the presence of model uncertainties and disturbances. Our controller consistently outperforms the benchmark approaches with less control effort and actuator saturation, offering highly effective and efficient flight control.",
    "authors": [
      "Amin Yazdanshenas",
      "Reza Faieghi"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2405.02203",
    "title": "Convergence of a Finite Volume Scheme for Compactly Heterogeneous Scalar Conservation Laws",
    "abstract": "We build a finite volume scheme for the scalar conservation law $\\partial_t u + \\partial_x (H(x, u)) = 0$ with bounded initial condition for a wide class of flux function $H$, convex with respect to the second variable. The main idea for the construction of the scheme is to use the theory of discontinuous flux. We prove that the resulting approximating sequence converges boundedly almost everywhere on $\\mathopen]0, +\\infty\\mathclose[$ to the entropy solution.",
    "authors": [
      "Abraham Sylla"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2405.14430",
    "title": "PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference",
    "abstract": "This paper presents PipeFusion, an innovative parallel methodology to tackle the high latency issues associated with generating high-resolution images using diffusion transformers (DiTs) models. PipeFusion partitions images into patches and the model layers across multiple GPUs. It employs a patch-level pipeline parallel strategy to orchestrate communication and computation efficiently. By capitalizing on the high similarity between inputs from successive diffusion steps, PipeFusion reuses one-step stale feature maps to provide context for the current pipeline step. This approach notably reduces communication costs compared to existing DiTs inference parallelism, including tensor parallel, sequence parallel and DistriFusion. PipeFusion enhances memory efficiency through parameter distribution across devices, ideal for large DiTs like Flux.1. Experimental results demonstrate that PipeFusion achieves state-of-the-art performance on 8$\\times$L40 PCIe GPUs for Pixart, Stable-Diffusion 3, and Flux.1 models. Our source code is available at this https URL .",
    "authors": [
      "Jiarui Fang",
      "Jinzhe Pan",
      "Aoyu Li",
      "Xibo Sun",
      "Jiannan Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2406.06424",
    "title": "Margin-aware Preference Optimization for Aligning Diffusion Models without Reference",
    "abstract": "Modern preference alignment methods, such as DPO, rely on divergence regularization to a reference model for training stability-but this creates a fundamental problem we call \"reference mismatch.\" In this paper, we investigate the negative impacts of reference mismatch in aligning text-to-image (T2I) diffusion models, showing that larger reference mismatch hinders effective adaptation given the same amount of data, e.g., as when learning new artistic styles, or personalizing to specific objects. We demonstrate this phenomenon across text-to-image (T2I) diffusion models and introduce margin-aware preference optimization (MaPO), a reference-agnostic approach that breaks free from this constraint. By directly optimizing the likelihood margin between preferred and dispreferred outputs under the Bradley-Terry model without anchoring to a reference, MaPO transforms diverse T2I tasks into unified pairwise preference optimization. We validate MaPO's versatility across five challenging domains: (1) safe generation, (2) style adaptation, (3) cultural representation, (4) personalization, and (5) general preference alignment. Our results reveal that MaPO's advantage grows dramatically with reference mismatch severity, outperforming both DPO and specialized methods like DreamBooth while reducing training time by 15%. MaPO thus emerges as a versatile and memory-efficient method for generic T2I adaptation tasks.",
    "authors": [
      "Jiwoo Hong",
      "Sayak Paul",
      "Noah Lee",
      "Kashif Rasul",
      "James Thorne",
      "Jongheon Jeong"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2406.16515",
    "title": "An FPRAS for Model Counting for Non-Deterministic Read-Once Branching Programs",
    "abstract": "Non-deterministic read-once branching programs, also known as non-deterministic free binary decision diagrams (nFBDD), are a fundamental data structure in computer science for representing Boolean functions. In this paper, we focus on #nFBDD, the problem of model counting for non-deterministic read-once branching programs. The #nFBDD problem is #P-hard, and it is known that there exists a quasi-polynomial randomized approximation scheme for #nFBDD. In this paper, we provide the first FPRAS for #nFBDD. Our result relies on the introduction of new analysis techniques that focus on bounding the dependence of samples.",
    "authors": [
      "Kuldeep S. Meel",
      "Alexis de Colnet"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.14766",
    "title": "Fairness Interventions: A Study in AI Explainability",
    "abstract": "This paper presents a philosophical and experimental study of fairness interventions in AI classification, centered on the explainability of corrective methods. We argue that ensuring fairness requires not only satisfying a target criterion, but also explaining which variables constrain its realization. When corrections are used to mitigate advantage transparently, they must remain sensitive to the distribution of true labels. To illustrate this approach, we built FairDream, a fairness package whose mechanism is made transparent for lay users, increasing the model's weights of errors on disadvantaged groups. While a user may intend to achieve Demographic Parity by the correction method, experiments show that FairDream tends towards Equalized Odds, revealing a conservative bias inherent to the data environment. We clarify the relationship between these fairness criteria, analyze FairDream's reweighting process, and compare its trade-offs with closely related GridSearch models. Finally, we justify the normative preference for Equalized Odds via an epistemological interpretation of the results, using their proximity with Simpson's paradox. The paper thus unites normative, epistemological, and empirical explanations of fairness interventions, to ensure transparency for the users.",
    "authors": [
      "Thomas Souverain",
      "Johnathan Nguyen",
      "Nicolas Meric",
      "Paul Égré"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2407.14938",
    "title": "Exercising the CCPA Opt-out Right on Android: Legally Mandated but Practically Challenging",
    "abstract": "The business model of many mobile apps is based on generating revenue from sharing user data with ad networks and other companies to deliver personalized ads. The California Consumer Privacy Act (CCPA) gives California residents a right to opt out of the selling and sharing of their personal information. In two experiments we evaluate to which extent popular apps on the Android platform enable California residents to exercise their CCPA opt-out right. In our first experiment -- manually exercising the opt-out right via app-level UIs for a set of 100 apps -- we find that only 48 apps implement the legally mandated setting, which suggests that CCPA opt-out right non-compliance is a broader issue on the platform. In our second experiment -- automatically exercising the opt-out right at the platform-level by sending Global Privacy Control (GPC) signals -- we find for an app dataset of $1,811$ apps that GPC is largely ineffective. While we estimate with 95% confidence that 62%--81% of apps in our app dataset must respect the CCPA's opt-out right, many apps do not do so. Disabling apps' access to the AdID, which is not intended for exercising the CCPA opt-out right but could have practical effect in this regard, does not lead to a different result. For example, when sending GPC signals and disabling apps' access to the AdID, 338 apps still had the ccpa status of the ad network Vungle set to opted in while only 26 had set it to opted out. Overall, our results suggest a compliance gap as California residents have no effective way of exercising their CCPA opt-out right on the Android platform; neither at the app- nor at the platform-level. We think that re-purposing the Android AdID setting as an opt-out right setting with legal meaning could resolve this compliance gap under the CCPA and other laws and improve users' privacy on the platform overall.",
    "authors": [
      "Sebastian Zimmeck",
      "Nishant Aggarwal",
      "Zachary Liu",
      "Sage Altman",
      "Konrad Kollnig"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.02697",
    "title": "Why Rectified Power Unit Networks Fail and How to Improve It: An Effective Field Theory Perspective",
    "abstract": "The Rectified Power Unit (RePU) activation function, a differentiable generalization of the Rectified Linear Unit (ReLU), has shown promise in constructing neural networks due to its smoothness properties. However, deep RePU networks often suffer from critical issues such as vanishing or exploding values during training, rendering them unstable regardless of hyperparameter initialization. Leveraging the perspective of effective field theory, we identify the root causes of these failures and propose the Modified Rectified Power Unit (MRePU) activation function. MRePU addresses RePU's limitations while preserving its advantages, such as differentiability and universal approximation properties. Theoretical analysis demonstrates that MRePU satisfies criticality conditions necessary for stable training, placing it in a distinct universality class. Extensive experiments validate the effectiveness of MRePU, showing significant improvements in training stability and performance across various tasks, including polynomial regression, physics-informed neural networks (PINNs) and real-world vision tasks. Our findings highlight the potential of MRePU as a robust alternative for building deep neural networks.",
    "authors": [
      "Taeyoung Kim",
      "Myungjoo Kang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.05235",
    "title": "SLO-aware GPU Frequency Scaling for Energy Efficient LLM Inference Serving",
    "abstract": "As Large Language Models (LLMs) gain traction, their reliance on power-hungry GPUs places ever-increasing energy demands, raising environmental and monetary concerns. Inference dominates LLM workloads, presenting a critical challenge for providers: minimizing energy costs under Service-Level Objectives (SLOs) that ensure optimal user experience. In this paper, we present \\textit{throttLL'eM}, a framework that reduces energy consumption while meeting SLOs through the use of instance and GPU frequency scaling. \\textit{throttLL'eM} features mechanisms that project future KV cache usage and batch size. Leveraging a Machine-Learning (ML) model that receives these projections as inputs, \\textit{throttLL'eM} manages performance at the iteration level to satisfy SLOs with reduced frequencies and instance sizes. We show that the proposed ML model achieves $R^2$ scores greater than 0.97 and miss-predicts performance by less than 1 iteration per second on average. Experimental results on LLM inference traces show that \\textit{throttLL'eM} achieves up to 43.8\\% lower energy consumption and an energy efficiency improvement of at least $1.71\\times$ under SLOs, when compared to NVIDIA's Triton server.",
    "authors": [
      "Andreas Kosmas Kakolyris",
      "Dimosthenis Masouros",
      "Petros Vavaroutsos",
      "Sotirios Xydis",
      "Dimitrios Soudris"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.02977",
    "title": "Large Language Model-Based Agents for Software Engineering: A Survey",
    "abstract": "The recent advance in Large Language Models (LLMs) has shaped a new paradigm of AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based agents substantially extend the versatility and expertise of LLMs by enhancing LLMs with the capabilities of perceiving and utilizing external resources and tools. To date, LLM-based agents have been applied and shown remarkable effectiveness in Software Engineering (SE). The synergy between multiple agents and human interaction brings further promise in tackling complex real-world SE problems. In this work, we present a comprehensive and systematic survey on LLM-based agents for SE. We collect 124 papers and categorize them from two perspectives, i.e., the SE and agent perspectives. In addition, we discuss open challenges and future directions in this critical domain. The repository of this survey is at this https URL .",
    "authors": [
      "Junwei Liu",
      "Kaixin Wang",
      "Yixuan Chen",
      "Xin Peng",
      "Zhenpeng Chen",
      "Lingming Zhang",
      "Yiling Lou"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.07414",
    "title": "NVRC: Neural Video Representation Compression",
    "abstract": "Recent advances in implicit neural representation (INR)-based video coding have demonstrated its potential to compete with both conventional and other learning-based approaches. With INR methods, a neural network is trained to overfit a video sequence, with its parameters compressed to obtain a compact representation of the video content. However, although promising results have been achieved, the best INR-based methods are still out-performed by the latest standard codecs, such as VVC VTM, partially due to the simple model compression techniques employed. In this paper, rather than focusing on representation architectures as in many existing works, we propose a novel INR-based video compression framework, Neural Video Representation Compression (NVRC), targeting compression of the representation. Based on the novel entropy coding and quantization models proposed, NVRC, for the first time, is able to optimize an INR-based video codec in a fully end-to-end manner. To further minimize the additional bitrate overhead introduced by the entropy models, we have also proposed a new model compression framework for coding all the network, quantization and entropy model parameters hierarchically. Our experiments show that NVRC outperforms many conventional and learning-based benchmark codecs, with a 24% average coding gain over VVC VTM (Random Access) on the UVG dataset, measured in PSNR. As far as we are aware, this is the first time an INR-based video codec achieving such performance. The implementation of NVRC will be released.",
    "authors": [
      "Ho Man Kwan",
      "Ge Gao",
      "Fan Zhang",
      "Andrew Gower",
      "David Bull"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.18980",
    "title": "IW-Bench: Evaluating Large Multimodal Models for Converting Image-to-Web",
    "abstract": "Recently advancements in large multimodal models have led to significant strides in image comprehension capabilities. Despite these advancements, there is a lack of the robust benchmark specifically for assessing the Image-to-Web conversion proficiency of these large models. Primarily, it is essential to ensure the integrity of the web elements generated. These elements comprise visible and invisible categories. Previous evaluation methods (e.g.,BLEU) are notably susceptible to significant alterations due to the presence of invisible elements in Web. Furthermore, it is crucial to measure the layout information of web pages, referring to the positional relationships between elements, which is overlooked by previous work. To address challenges, we have curated and aligned a benchmark of images and corresponding web codes (IW-BENCH). Specifically, we propose the Element Accuracy, which tests the completeness of the elements by parsing the Document Object Model (DOM) tree. Layout Accuracy is also proposed to analyze the positional relationships of elements by converting DOM tree into a common subsequence. Besides, we design a five-hop multimodal Chain-of-Thought Prompting for better performance, which contains five hop: 1) SoM prompt injection. 2) Inferring Elements. 3) Inferring Layout. 4) Inferring Web code. 5) Reflection. Our benchmark comprises 1200 pairs of images and web codes with varying levels of difficulty. We have conducted extensive experiments on existing large multimodal models, offering insights into their performance and areas for improvement in image-to-web domain.",
    "authors": [
      "Hongcheng Guo",
      "Wei Zhang",
      "Junhao Chen",
      "Yaonan Gu",
      "Jian Yang",
      "Junjia Du",
      "Shaosheng Cao",
      "Binyuan Hui",
      "Tianyu Liu",
      "Jianxin Ma",
      "Chang Zhou",
      "Zhoujun Li"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.02660",
    "title": "How to Train Long-Context Language Models (Effectively)",
    "abstract": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development -- instead of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set of long-context downstream tasks, and we evaluate models after SFT as this better reveals long-context abilities. Supported by our robust evaluations, we run thorough experiments to decide the data mix for continued pre-training, the instruction tuning dataset, and many other design choices such as position extrapolation. We find that (1) code repositories and books are excellent sources of long data, but it is crucial to combine them with high-quality short-context data; (2) training with a sequence length beyond the evaluation length boosts long-context performance; (3) for SFT, using only short instruction datasets yields strong performance on long-context tasks. Our final model, ProLong-8B, which is initialized from Llama-3 and trained on 40B tokens, demonstrates state-of-the-art long-context performance among similarly sized models at a length of 128K. ProLong outperforms Llama-3.1-8B-Instruct on the majority of long-context tasks despite using only 5% as many tokens during long-context training. Additionally, ProLong can effectively process up to 512K tokens, one of the longest context windows of publicly available LMs.",
    "authors": [
      "Tianyu Gao",
      "Alexander Wettig",
      "Howard Yen",
      "Danqi Chen"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.04960",
    "title": "On Efficient Variants of Segment Anything Model: A Survey",
    "abstract": "The Segment Anything Model (SAM) is a foundational model for image segmentation tasks, known for its strong generalization across diverse applications. However, its impressive performance comes with significant computational and resource demands, making it challenging to deploy in resource-limited environments such as edge devices. To address this, a variety of SAM variants have been proposed to enhance efficiency while keeping accuracy. This survey provides the first comprehensive review of these efficient SAM variants. We begin by exploring the motivations driving this research. We then present core techniques used in SAM and model acceleration. This is followed by a detailed exploration of SAM acceleration strategies, categorized by approach, and a discussion of several future research directions. Finally, we offer a unified and extensive evaluation of these methods across various hardware, assessing their efficiency and accuracy on representative benchmarks, and providing a clear comparison of their overall performance.",
    "authors": [
      "Xiaorui Sun",
      "Jun Liu",
      "Heng Tao Shen",
      "Xiaofeng Zhu",
      "Ping Hu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.08297",
    "title": "Matrix-free stochastic calculation of operator norms without using adjoints",
    "abstract": "This paper considers the problem of computing the operator norm of a linear map between finite dimensional Hilbert spaces when only evaluations of the linear map are available and under restrictive storage assumptions. We propose a stochastic method of random search type to maximize the Rayleigh quotient and employ an exact line search in the random search directions. Moreover, we show that the proposed algorithm converges to the global maximum (the operator norm) almost surely and a sublinear convergence behavior for the corresponding eigenvector and eigenvalue equation. Finally, we illustrate the performance of the method with numerical experiments.",
    "authors": [
      "Jonas Bresch",
      "Dirk A. Lorenz",
      "Felix Schneppe",
      "Maximilian Winkler"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.18084",
    "title": "DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes",
    "abstract": "Urban scene generation has been developing rapidly recently. However, existing methods primarily focus on generating static and single-frame scenes, overlooking the inherently dynamic nature of real-world driving environments. In this work, we introduce DynamicCity, a novel 4D occupancy generation framework capable of generating large-scale, high-quality dynamic 4D scenes with semantics. DynamicCity mainly consists of two key models. 1) A VAE model for learning HexPlane as the compact 4D representation. Instead of using naive averaging operations, DynamicCity employs a novel Projection Module to effectively compress 4D features into six 2D feature maps for HexPlane construction, which significantly enhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, we utilize an Expansion & Squeeze Strategy to reconstruct 3D feature volumes in parallel, which improves both network training efficiency and reconstruction accuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06x training speedup, and 70.84% memory reduction). 2) A DiT-based diffusion model for HexPlane generation. To make HexPlane feasible for DiT generation, a Padded Rollout Operation is proposed to reorganize all six feature planes of the HexPlane as a squared 2D feature map. In particular, various conditions could be introduced in the diffusion or sampling process, supporting versatile 4D generation applications, such as trajectory- and command-driven generation, inpainting, and layout-conditioned generation. Extensive experiments on the CarlaSC and Waymo datasets demonstrate that DynamicCity significantly outperforms existing state-of-the-art 4D occupancy generation methods across multiple metrics. The code and models have been released to facilitate future research.",
    "authors": [
      "Hengwei Bian",
      "Lingdong Kong",
      "Haozhe Xie",
      "Liang Pan",
      "Yu Qiao",
      "Ziwei Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.05826",
    "title": "From Pixels to Prose: Advancing Multi-Modal Language Models for Remote Sensing",
    "abstract": "Remote sensing has evolved from simple image acquisition to complex systems capable of integrating and processing visual and textual data. This review examines the development and application of multi-modal language models (MLLMs) in remote sensing, focusing on their ability to interpret and describe satellite imagery using natural language. We cover the technical underpinnings of MLLMs, including dual-encoder architectures, Transformer models, self-supervised and contrastive learning, and cross-modal integration. The unique challenges of remote sensing data--varying spatial resolutions, spectral richness, and temporal changes--are analyzed for their impact on MLLM performance. Key applications such as scene description, object detection, change detection, text-to-image retrieval, image-to-text generation, and visual question answering are discussed to demonstrate their relevance in environmental monitoring, urban planning, and disaster response. We review significant datasets and resources supporting the training and evaluation of these models. Challenges related to computational demands, scalability, data quality, and domain adaptation are highlighted. We conclude by proposing future research directions and technological advancements to further enhance MLLM utility in remote sensing.",
    "authors": [
      "Xintian Sun",
      "Benji Peng",
      "Charles Zhang",
      "Fei Jin",
      "Qian Niu",
      "Junyu Liu",
      "Keyu Chen",
      "Ming Li",
      "Pohsun Feng",
      "Ziqian Bi",
      "Ming Liu",
      "Xinyuan Song",
      "Yichao Zhang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.18551",
    "title": "Concentration of Cumulative Reward in Markov Decision Processes",
    "abstract": "In this paper, we investigate the concentration properties of cumulative reward in Markov Decision Processes (MDPs), focusing on both asymptotic and non-asymptotic settings. We introduce a unified approach to characterize reward concentration in MDPs, covering both infinite-horizon settings (i.e., average and discounted reward frameworks) and finite-horizon setting. Our asymptotic results include the law of large numbers, the central limit theorem, and the law of iterated logarithms, while our non-asymptotic bounds include Azuma-Hoeffding-type inequalities and a non-asymptotic version of the law of iterated logarithms. Additionally, we explore two key implications of our results. First, we analyze the sample path behavior of the difference in rewards between any two stationary policies. Second, we show that two alternative definitions of regret for learning policies proposed in the literature are rate-equivalent. Our proof techniques rely on a martingale decomposition of cumulative reward, properties of the solution to the policy evaluation fixed-point equation, and both asymptotic and non-asymptotic concentration results for martingale difference sequences.",
    "authors": [
      "Borna Sayedana",
      "Peter E. Caines",
      "Aditya Mahajan"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.03289",
    "title": "Recovery of cyclic words by their subwords",
    "abstract": "A problem of reconstructing words from their subwords involves determining the minimum amount of information needed, such as multisets of scattered subwords of a specific length or the frequency of scattered subwords from a given set, in order to uniquely identify a word. In this paper we show that a cyclic word on a binary alphabet can be reconstructed by its scattered subwords of length $\\frac34n+4$, and for each $n$ one can find two cyclic words of length $n$ which have the same set of scattered subwords of length $\\frac34n-\\frac32$.",
    "authors": [
      "Sergey Luchinin",
      "Svetlana Puzynina",
      "Michaël Rao"
    ],
    "primary_category": "cs.DM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.07768",
    "title": "Test-time Correction: An Online 3D Detection System via Visual Prompting",
    "abstract": "This paper introduces Test-time Correction (TTC), an online 3D detection system designed to rectify test-time errors using various auxiliary feedback, aiming to enhance the safety of deployed autonomous driving systems. Unlike conventional offline 3D detectors that remain fixed during inference, TTC enables immediate online error correction without retraining, allowing autonomous vehicles to adapt to new scenarios and reduce deployment risks. To achieve this, we equip existing 3D detectors with an Online Adapter (OA) module -- a prompt-driven query generator for real-time correction. At the core of OA module are visual prompts: image-based descriptions of objects of interest derived from auxiliary feedback such as mismatches with 2D detections, road descriptions, or user clicks. These visual prompts, collected from risky objects during inference, are maintained in a visual prompt buffer to enable continuous correction in future frames. By leveraging this mechanism, TTC consistently detects risky objects, achieving reliable, adaptive, and versatile driving autonomy. Extensive experiments show that TTC significantly improves instant error rectification over frozen 3D detectors, even under limited labels, zero-shot settings, and adverse conditions. We hope this work inspires future research on post-deployment online rectification systems for autonomous driving.",
    "authors": [
      "Hanxue Zhang",
      "Zetong Yang",
      "Yanan Sun",
      "Li Chen",
      "Fei Xia",
      "Fatma Güney",
      "Hongyang Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.09997",
    "title": "GT23D-Bench: A Comprehensive General Text-to-3D Generation Benchmark",
    "abstract": "Text-to-3D (T23D) generation has emerged as a crucial visual generation task, aiming at synthesizing 3D content from textual descriptions. Studies of this task are currently shifting from per-scene T23D, which requires optimization of the model for every content generated, to General T23D (GT23D), which requires only one pre-trained model to generate different content without re-optimization, for more generalized and efficient 3D generation. Despite notable advancements, GT23D is severely bottlenecked by two interconnected challenges: the lack of high-quality, large-scale training data and the prevalence of evaluation metrics that overlook intrinsic 3D properties. Existing datasets often suffer from incomplete annotations, noisy organization, and inconsistent quality, while current evaluations rely heavily on 2D image-text similarity or scoring, failing to thoroughly assess 3D geometric integrity and semantic relevance. To address these fundamental gaps, we introduce GT23D-Bench, the first comprehensive benchmark specifically designed for GT23D training and evaluation. We first construct a high-quality dataset of 400K 3D assets, featuring diverse visual annotations (70M+ visual samples) and multi-granularity hierarchical captions (1M+ descriptions) to foster robust semantic learning. Second, we propose a comprehensive evaluation suite with 10 metrics assessing both text-3D alignment and 3D visual quality at multiple levels. Crucially, we demonstrate through rigorous experiments that our proposed metrics exhibit significantly higher correlation with human judgment compared to existing methods. Our in-depth analysis of eight leading GT23D models using this benchmark provides the community with critical insights into current model capabilities and their shared failure modes. GT23D-Bench will be publicly available to facilitate rigorous and reproducible research.",
    "authors": [
      "Xiao Cai",
      "Sitong Su",
      "Jingkuan Song",
      "Pengpeng Zeng",
      "Ji Zhang",
      "Qinhong Du",
      "Mengqi Li",
      "Heng Tao Shen",
      "Lianli Gao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.12197",
    "title": "Anti-bullying Adaptive Cruise Control: A proactive right-of-way protection approach",
    "abstract": "Adaptive Cruise Control (ACC) systems have been widely commercialized in recent years. However, existing ACC systems remain vulnerable to close-range cut-ins, a behavior that resembles \"road bullying\". To address this issue, this research proposes an Anti-bullying Adaptive Cruise Control (AACC) approach, which is capable of proactively protecting right-of-way against such \"road bullying\" cut-ins. To handle diverse \"road bullying\" cut-in scenarios smoothly, the proposed approach first leverages an online Inverse Optimal Control (IOC) based algorithm for individual driving style identification. Then, based on Stackelberg competition, a game-theoretic-based motion planning framework is presented in which the identified individual driving styles are utilized to formulate cut-in vehicles' reaction functions. By integrating such reaction functions into the ego vehicle's motion planning, the ego vehicle could consider cut-in vehicles' all possible reactions to find its optimal right-of-way protection maneuver. To the best of our knowledge, this research is the first to model vehicles' interaction dynamics and develop an interactive planner that adapts cut-in vehicle's various driving styles. Simulation results show that the proposed approach can prevent \"road bullying\" cut-ins and be adaptive to different cut-in vehicles' driving styles. It can improve safety and comfort by up to 79.8% and 20.4%. The driving efficiency has benefits by up to 19.33% in traffic flow. The proposed approach can also adopt more flexible driving strategies. Furthermore, the proposed approach can support real-time field implementation by ensuring less than 50 milliseconds computation time.",
    "authors": [
      "Jia Hu",
      "Zhexi Lian",
      "Haoran Wang",
      "Zihan Zhang",
      "Ruoxi Qian",
      "Duo Li",
      "Jaehyun",
      "Junnian Zheng"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.12836",
    "title": "A Survey on Recommendation Unlearning: Fundamentals, Taxonomy, Evaluation, and Open Questions",
    "abstract": "Recommender systems have become increasingly influential in shaping user behavior and decision-making, highlighting their growing impact in various domains. Meanwhile, the widespread adoption of machine learning models in recommender systems has raised significant concerns regarding user privacy and security. As compliance with privacy regulations becomes more critical, there is a pressing need to address the issue of recommendation unlearning, i.e., eliminating the memory of specific training data from the learned recommendation models. Despite its importance, traditional machine unlearning methods are ill-suited for recommendation unlearning due to the unique challenges posed by collaborative interactions and model parameters. This survey offers a comprehensive review of the latest advancements in recommendation unlearning, exploring the design principles, challenges, and methodologies associated with this emerging field. We provide a unified taxonomy that categorizes different recommendation unlearning approaches, followed by a summary of widely used benchmarks and metrics for evaluation. By reviewing the current state of research, this survey aims to guide the development of more efficient, scalable, and robust recommendation unlearning techniques. Furthermore, we identify open research questions in this field, which could pave the way for future innovations not only in recommendation unlearning but also in a broader range of unlearning tasks across different machine learning applications.",
    "authors": [
      "Yuyuan Li",
      "Xiaohua Feng",
      "Chaochao Chen",
      "Qiang Yang"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.04005",
    "title": "LargeAD: Large-Scale Cross-Sensor Data Pretraining for Autonomous Driving",
    "abstract": "Recent advancements in vision foundation models (VFMs) have revolutionized visual perception in 2D, yet their potential for 3D scene understanding, particularly in autonomous driving applications, remains underexplored. In this paper, we introduce LargeAD, a versatile and scalable framework designed for large-scale 3D pretraining across diverse real-world driving datasets. Our framework leverages VFMs to extract semantically rich superpixels from 2D images, which are aligned with LiDAR point clouds to generate high-quality contrastive samples. This alignment facilitates cross-modal representation learning, enhancing the semantic consistency between 2D and 3D data. We introduce several key innovations: (i) VFM-driven superpixel generation for detailed semantic representation, (ii) a VFM-assisted contrastive learning strategy to align multimodal features, (iii) superpoint temporal consistency to maintain stable representations across time, and (iv) multi-source data pretraining to generalize across various LiDAR configurations. Our approach achieves substantial gains over state-of-the-art methods in linear probing and fine-tuning for LiDAR-based segmentation and object detection. Extensive experiments on 11 large-scale multi-sensor datasets highlight our superior performance, demonstrating adaptability, efficiency, and robustness in real-world autonomous driving scenarios.",
    "authors": [
      "Lingdong Kong",
      "Xiang Xu",
      "Youquan Liu",
      "Jun Cen",
      "Runnan Chen",
      "Wenwei Zhang",
      "Liang Pan",
      "Kai Chen",
      "Ziwei Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.08987",
    "title": "Degradedness Under Cooperation",
    "abstract": "We study cooperation problems in broadcast and relay networks, where the receivers do not satisfy the classical physical degradedness assumptions. New notions of degradedness, \\emph{strongly less noisy} and \\emph{strongly more capable} are introduced. We show that under these conditions, decode and forward (D\\&F) is optimal for classes of cooperative systems with limited conference rates, thus yielding new capacity results for these systems. In particular, we derive bounds on the capacity region of a class of broadcast channels with cooperation, that are tight on part of the capacity region. It is shown that the cut-set bound is tight for classes of primitive relay and diamond channels, beyond the physically or stochastically degraded models.",
    "authors": [
      "Yossef Steinberg"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.11384",
    "title": "Transductive Conformal Inference for Full Ranking",
    "abstract": "We introduce a method based on Conformal Prediction (CP) to quantify the uncertainty of full ranking algorithms. We focus on a specific scenario where $n+m$ items are to be ranked by some ``black box'' algorithm. It is assumed that the relative (ground truth) ranking of $n$ of them is known. The objective is then to quantify the error made by the algorithm on the ranks of the $m$ new items among the total $(n+m)$. In such a setting, the true ranks of the $n$ original items in the total $(n+m)$ depend on the (unknown) true ranks of the $m$ new ones. Consequently, we have no direct access to a calibration set to apply a classical CP method. To address this challenge, we propose to construct distribution-free bounds of the unknown conformity scores using recent results on the distribution of conformal p-values. Using these scores upper bounds, we provide valid prediction sets for the rank of any item. We also control the false coverage proportion, a crucial quantity when dealing with multiple prediction sets. Finally, we empirically show on both synthetic and real data the efficiency of our CP method for state-of-the-art algorithms such as RankNet or LambdaMart.",
    "authors": [
      "Jean-Baptiste Fermanian",
      "Pierre Humbert",
      "Gilles Blanchard"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.14402",
    "title": "On the Effectiveness of Microservices Tactics and Patterns to Reduce Energy Consumption: An Experimental Study on Trade-Offs",
    "abstract": "Context: Microservice-based systems have established themselves in the software industry. However, sustainability-related legislation and the growing costs of energy-hungry software increase the importance of energy efficiency for these systems. While some proposals for architectural tactics and patterns exist, their effectiveness as well as potential trade-offs on other quality attributes (QAs) remain unclear. Goal: We therefore aim to study the effectiveness of microservices tactics and patterns to reduce energy consumption, as well as potential trade-offs with performance and maintainability. Method: Using the open-source Online Boutique system, we conducted a controlled experiment with three tactics and three patterns, and analyzed the impact of each technique compared to a baseline. We also tested with three levels of simulated request loads (low, medium, high). Results: Request load moderated the effectiveness of reducing energy consumption. All techniques (tactics and patterns) reduced the energy consumption for at least one load level, up to 5.6%. For performance, the techniques could negatively impact response time by increasing it by up to 25.9%, while some also decreased it by up to 72.5%. Two techniques increased the throughput, by 1.9% and 34.0%. For maintainability, three techniques had a negative, one a positive, and two no impact. Conclusion: Some techniques reduced energy consumption while also improving performance. However, these techniques usually involved a trade-off in maintainability, e.g., via more code duplication and module coupling. Overall, all techniques significantly reduced energy consumption at higher loads, but most of them sacrificed one of the other QAs. This highlights that the real challenge is not simply reducing energy consumption of microservices, but to achieve energy efficiency.",
    "authors": [
      "Xingwen Xiao",
      "Chushu Gao",
      "Justus Bogner"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.19153",
    "title": "Test-Time Training Scaling Laws for Chemical Exploration in Drug Design",
    "abstract": "Chemical Language Models (CLMs) leveraging reinforcement learning (RL) have shown promise in de novo molecular design, yet often suffer from mode collapse, limiting their exploration capabilities. Inspired by Test-Time Training (TTT) in large language models, we propose scaling TTT for CLMs to enhance chemical space exploration. We introduce MolExp, a novel benchmark emphasizing the discovery of structurally diverse molecules with similar bioactivity, simulating real-world drug design challenges. Our results demonstrate that scaling TTT by increasing the number of independent RL agents follows a log-linear scaling law, significantly improving exploration efficiency as measured by MolExp. In contrast, increasing TTT training time yields diminishing returns, even with exploration bonuses. We further evaluate cooperative RL strategies to enhance exploration efficiency. These findings provide a scalable framework for generative molecular design, offering insights into optimizing AI-driven drug discovery.",
    "authors": [
      "Morgan Thomas",
      "Albert Bou",
      "Gianni De Fabritiis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.19306",
    "title": "SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling",
    "abstract": "Recent advancements in Large Language Models (LLMs) have created new opportunities to enhance performance on complex reasoning tasks by leveraging test-time computation. However, existing scaling methods have key limitations: parallel methods like repeated sampling are often inefficient and quickly saturate, while sequential methods like SELF-REFINE struggle to improve after a few rounds. Although combining these approaches shows promise, current methods require fine-tuned reward and revision models. This paper proposes Self-Enhanced Test-Time Scaling (SETS), a simple yet effective approach that overcomes these limitations by strategically combining parallel and sequential techniques and fully leveraging LLMs' self-improvement abilities. SETS exploits the inherent self-verification and self-correction capabilities of LLMs, unifying sampling, verification, and correction within a single framework. This facilitates efficient and scalable test-time computation for enhanced performance on complex tasks without any model training. Our comprehensive experimental results on challenging benchmarks spanning planning, reasoning, math, and coding demonstrate that SETS achieves significant performance improvements and more advantageous test-time scaling behavior than the alternatives.",
    "authors": [
      "Jiefeng Chen",
      "Jie Ren",
      "Xinyun Chen",
      "Chengrun Yang",
      "Ruoxi Sun",
      "Jinsung Yoon",
      "Sercan Ö Arık"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.04964",
    "title": "Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency",
    "abstract": "Uncertainty quantification (UQ) methods for Large Language Models (LLMs) encompass a variety of approaches, with two major types being particularly prominent: information-based, which focus on model confidence expressed as token probabilities, and consistency-based, which assess the semantic relationship between multiple outputs generated using repeated sampling. Several recent methods have combined these two approaches to boost UQ performance. However, they sometimes fail to outperform much simpler baseline methods. Our work discusses the fundamental approach to constructing uncertainty measures that directly links uncertainty with the minimum Bayes risks achieved by LLM decoding. Building on these findings, we propose a novel approach to integrating model confidence with output consistency, resulting in a family of efficient and robust UQ methods. Our investigation reveals distinctive characteristics of LLMs as probabilistic models, which help to explain why these UQ methods underperform in certain tasks. Based on these findings, we propose a new way of synthesizing model confidence and output consistency, leading to a family of efficient and robust UQ methods. We evaluate our approach across various tasks such as question answering, abstractive summarization, and machine translation, demonstrating sizable improvements over state-of-the-art UQ approaches.",
    "authors": [
      "Roman Vashurin",
      "Maiya Goloburda",
      "Albina Ilina",
      "Aleksandr Rubashevskii",
      "Preslav Nakov",
      "Artem Shelmanov",
      "Maxim Panov"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.09854",
    "title": "Scaling Multimodal Search and Recommendation with Small Language Models via Upside-Down Reinforcement Learning",
    "abstract": "In this work, we investigate how small language models (SLMs) can be scaled to support multimodal search and recommendation use cases while remaining efficient enough for real-time, resource-constrained deployments. We present a framework that combines upside-down reinforcement learning with synthetic data distillation from a large language model (Llama-3) to train a 100M-parameter GPT-2 model for multitask prompt generation. Despite being up to 80 times smaller than state-of-the-art large language models (LLMs), our SLM achieves relevance and diversity scores within 6% of competitive baselines such as Llama-3 8B, Qwen3 8B, and Ministral 8B. These results demonstrate that SLMs can effectively handle multimodal search and recommendation tasks, while dramatically reducing inference latency and memory overhead. Our study highlights the potential of lightweight models as practical engines for scalable multimodal discovery, bridging the gap between cutting-edge research and real-world multimodal applications such as media recommendations and creative content generation.",
    "authors": [
      "Yu-Chen Lin",
      "Sanat Sharma",
      "Hari Manikandan",
      "Jayant Kumar",
      "Tracy Holloway King",
      "Jing Zheng"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.10076",
    "title": "Filtration-Based Representation Learning for Temporal Graphs",
    "abstract": "In this work, we introduce a filtration on temporal graphs based on $\\delta$-temporal motifs (recurrent subgraphs), yielding a multi-scale representation of temporal structure. Our temporal filtration allows tools developed for filtered static graphs, including persistent homology and recent graph filtration kernels, to be applied directly to temporal graph analysis. We demonstrate the effectiveness of this approach on temporal graph classification tasks.",
    "authors": [
      "Samrik Chowdhury",
      "Siddharth Pritam",
      "Rohit Roy",
      "Madhav Cherupilil Sajeev"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.11678",
    "title": "Which Type of Students can LLMs Act? Investigating Authentic Simulation with Graph-based Human-AI Collaborative System",
    "abstract": "While rapid advances in large language models (LLMs) are reshaping data-driven intelligent education, accurately simulating students remains an important but challenging bottleneck for scalable educational data collection, evaluation, and intervention design. However, current works are limited by scarce real interaction data, costly expert evaluation for realism, and a lack of large-scale, systematic analyses of LLMs ability in simulating students. We address this gap by presenting a three-stage LLM-human collaborative pipeline to automatically generate and filter high-quality student agents. We leverage a two-round automated scoring validated by human experts and deploy a score propagation module to obtain more consistent scores across the student similarity graph. Experiments show that combining automated scoring, expert calibration, and graph-based propagation yields simulated student that more closely track authentication by human judgments. We then analyze which profiles and behaviors are simulated more faithfully, supporting subsequent studies on personalized learning and educational assessment.",
    "authors": [
      "Haoxuan Li",
      "Jifan Yu",
      "Xin Cong",
      "Yang Dang",
      "Daniel Zhang-li",
      "Lu Mi",
      "Yisi Zhan",
      "Huiqin Liu",
      "Zhiyuan Liu"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.16116",
    "title": "Integrating Weather Station Data and Radar for Precipitation Nowcasting: SmaAt-fUsion and SmaAt-Krige-GNet",
    "abstract": "Short-term precipitation nowcasting is essential for flood management, transportation, energy system operations, and emergency response. However, many existing models fail to fully exploit the extensive atmospheric information available, relying primarily on precipitation data alone. This study examines whether integrating multi-variable weather-station measurements with radar can enhance nowcasting skill and introduces two complementary architectures that integrate multi-variable station data with radar images. The SmaAt-fUsion model extends the SmaAt-UNet framework by incorporating weather station data through a convolutional layer, integrating it into the bottleneck of the network; The SmaAt-Krige-GNet model combines precipitation maps with weather station data processed using Kriging, a geo-statistical interpolation method, to generate variable-specific maps. These maps are then utilized in a dual-encoder architecture based on SmaAt-GNet, allowing multi-level data integration . Experimental evaluations were conducted using four years (2016--2019) of weather station and precipitation radar data from the Netherlands. Results demonstrate that SmaAt-Krige-GNet outperforms the standard SmaAt-UNet, which relies solely on precipitation radar data, in low precipitation scenarios, while SmaAt-fUsion surpasses SmaAt-UNet in both low and high precipitation scenarios. This highlights the potential of incorporating discrete weather station data to enhance the performance of deep learning-based weather nowcasting models.",
    "authors": [
      "Jie Shi",
      "Aleksej Cornelissen",
      "Siamak Mehrkanoon"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.20260",
    "title": "Understanding the Limits of Deep Tabular Methods with Temporal Shift",
    "abstract": "Deep tabular models have demonstrated remarkable success on i.i.d. data, excelling in a variety of structured data tasks. However, their performance often deteriorates under temporal distribution shifts, where trends and periodic patterns are present in the evolving data distribution over time. In this paper, we explore the underlying reasons for this failure in capturing temporal dependencies. We begin by investigating the training protocol, revealing a key issue in how model selection performs. While existing approaches use temporal ordering for splitting validation set, we show that even a random split can significantly improve model performance. By minimizing the time lag between training data and test time, while reducing the bias in validation, our proposed training protocol significantly improves generalization across various methods. Furthermore, we analyze how temporal data affects deep tabular representations, uncovering that these models often fail to capture crucial periodic and trend information. To address this gap, we introduce a plug-and-play temporal embedding method based on Fourier series expansion to learn and incorporate temporal patterns, offering an adaptive approach to handle temporal shifts. Our experiments demonstrate that this temporal embedding, combined with the improved training protocol, provides a more effective and robust framework for learning from temporal tabular data.",
    "authors": [
      "Hao-Run Cai",
      "Han-Jia Ye"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.03428",
    "title": "Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs",
    "abstract": "In a world where data is the new currency, wearable health devices offer unprecedented insights into daily life, continuously monitoring vital signs and metrics. However, this convenience raises privacy concerns, as these devices collect sensitive data that can be misused or breached. Traditional measures often fail due to real-time data processing needs and limited device power. Users also lack awareness and control over data sharing and usage. We propose a Privacy-Enhancing Technology (PET) framework for wearable devices, integrating federated learning, lightweight cryptographic methods, and selectively deployed blockchain technology. The blockchain acts as a secure ledger triggered only upon data transfer requests, granting users real-time notifications and control. By dismantling data monopolies, this approach returns data sovereignty to individuals. Through real-world applications like secure medical data sharing, privacy-preserving fitness tracking, and continuous health monitoring, our framework reduces privacy risks by up to 70 percent while preserving data utility and performance. This innovation sets a new benchmark for wearable privacy and can scale to broader IoT ecosystems, including smart homes and industry. As data continues to shape our digital landscape, our research underscores the critical need to maintain privacy and user control at the forefront of technological progress.",
    "authors": [
      "Karthik Barma"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.06717",
    "title": "You Point, I Learn: Online Adaptation of Interactive Segmentation Models for Handling Distribution Shifts in Medical Imaging",
    "abstract": "Interactive segmentation uses real-time user inputs, such as mouse clicks, to iteratively refine model predictions. Although not originally designed to address distribution shifts, this paradigm naturally lends itself to such challenges. In medical imaging, where distribution shifts are common, interactive methods can use user inputs to guide models towards improved predictions. Moreover, once a model is deployed, user corrections can be used to adapt the network parameters to the new data distribution, mitigating distribution shift. Based on these insights, we aim to develop a practical, effective method for improving the adaptive capabilities of interactive segmentation models to new data distributions in medical imaging. Firstly, we found that strengthening the model's responsiveness to clicks is important for the initial training process. Moreover, we show that by treating the post-interaction user-refined model output as pseudo-ground-truth, we can design a lean, practical online adaptation method that enables a model to learn effectively across sequential test images. The framework includes two components: (i) a Post-Interaction adaptation process, updating the model after the user has completed interactive refinement of an image, and (ii) a Mid-Interaction adaptation process, updating incrementally after each click. Both processes include a Click-Centered Gaussian loss that strengthens the model's reaction to clicks and enhances focus on user-guided, clinically relevant regions. Experiments on 5 fundus and 4 brain-MRI databases show that our approach consistently outperforms existing methods under diverse distribution shifts, including unseen imaging modalities and pathologies. Code and pretrained models will be released upon publication.",
    "authors": [
      "Wentian Xu",
      "Ziyun Liang",
      "Harry Anthony",
      "Yasin Ibrahim",
      "Felix Cohen",
      "Guang Yang",
      "Konstantinos Kamnitsas"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.06859",
    "title": "ActiveInitSplat: How Active Image Selection Helps Gaussian Splatting",
    "abstract": "Gaussian splatting (GS) along with its extensions and variants provides outstanding performance in real-time scene rendering while meeting reduced storage demands and computational efficiency. While the selection of 2D images capturing the scene of interest is crucial for the proper initialization and training of GS, hence markedly affecting the rendering performance, prior works rely on passively and typically densely selected 2D images. In contrast, this paper proposes `ActiveInitSplat', a novel framework for active selection of training images for proper initialization and training of GS. ActiveInitSplat relies on density and occupancy criteria of the resultant 3D scene representation from the selected 2D images, to ensure that the latter are captured from diverse viewpoints leading to better scene coverage and that the initialized Gaussian functions are well aligned with the actual 3D structure. Numerical tests on well-known simulated and real environments demonstrate the merits of ActiveInitSplat resulting in significant GS rendering performance improvement over passive GS baselines in both dense- and sparse-view settings, in the widely adopted LPIPS, SSIM, and PSNR metrics.",
    "authors": [
      "Konstantinos D. Polyzos",
      "Athanasios Bacharis",
      "Saketh Madhuvarasu",
      "Nikos Papanikolopoulos",
      "Tara Javidi"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.07828",
    "title": "Neural Radiance and Gaze Fields for Visual Attention Modeling in 3D Environments",
    "abstract": "We introduce Neural Radiance and Gaze Fields (NeRGs), a novel approach for representing visual attention in complex environments. Much like how Neural Radiance Fields (NeRFs) perform novel view synthesis, NeRGs reconstruct gaze patterns from arbitrary viewpoints, implicitly mapping visual attention to 3D surfaces. We achieve this by augmenting a standard NeRF with an additional network that models local egocentric gaze probability density, conditioned on scene geometry and observer position. The output of a NeRG is a rendered view of the scene alongside a pixel-wise salience map representing the conditional probability that a given observer fixates on visible surfaces. Unlike prior methods, our system is lightweight and enables visualization of gaze fields at interactive framerates. Moreover, NeRGs allow the observer perspective to be decoupled from the rendering camera and correctly account for gaze occlusion due to intervening geometry. We demonstrate the effectiveness of NeRGs using head pose from skeleton tracking as a proxy for gaze, employing our proposed gaze probes to aggregate noisy rays into robust probability density targets for supervision.",
    "authors": [
      "Andrei Chubarau",
      "Yinan Wang",
      "James J. Clark"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.11056",
    "title": "Flow to the Mode: Mode-Seeking Diffusion Autoencoders for State-of-the-Art Image Tokenization",
    "abstract": "Since the advent of popular visual generation frameworks like VQGAN and latent diffusion models, state-of-the-art image generation systems have generally been two-stage systems that first tokenize or compress visual data into a lower-dimensional latent space before learning a generative model. Tokenizer training typically follows a standard recipe in which images are compressed and reconstructed subject to a combination of MSE, perceptual, and adversarial losses. Diffusion autoencoders have been proposed in prior work as a way to learn end-to-end perceptually-oriented image compression, but have not yet shown state-of-the-art performance on the competitive task of ImageNet-1K reconstruction. We propose FlowMo, a transformer-based diffusion autoencoder that achieves a new state-of-the-art for image tokenization at multiple compression rates without using convolutions, adversarial losses, spatially-aligned two-dimensional latent codes, or distilling from other tokenizers. Our key insight is that FlowMo training should be broken into a mode-matching pre-training stage and a mode-seeking post-training stage. In addition, we conduct extensive analyses and explore the training of generative models atop the FlowMo tokenizer. Our code and models will be available at this http URL .",
    "authors": [
      "Kyle Sargent",
      "Kyle Hsu",
      "Justin Johnson",
      "Li Fei-Fei",
      "Jiajun Wu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.13430",
    "title": "AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction",
    "abstract": "Autonomous driving requires understanding infrastructure elements, such as lanes and crosswalks. To navigate safely, this understanding must be derived from sensor data in real-time and needs to be represented in vectorized form. Learned Bird's-Eye View (BEV) encoders are commonly used to combine a set of camera images from multiple views into one joint latent BEV grid. Traditionally, from this latent space, an intermediate raster map is predicted, providing dense spatial supervision but requiring post-processing into the desired vectorized form. More recent models directly derive infrastructure elements as polylines using vectorized map decoders, providing instance-level information. Our approach, Augmentation Map Network (AugMapNet), proposes latent BEV feature grid augmentation, a novel technique that significantly enhances the latent BEV representation. AugMapNet combines vector decoding and dense spatial supervision more effectively than existing architectures while remaining easy to integrate compared to other hybrid approaches. It additionally benefits from extra processing on its latent BEV features. Experiments on nuScenes and Argoverse2 datasets demonstrate significant improvements on vectorized map prediction of up to 13.3% over the StreamMapNet baseline on 60 m range and greater improvements on larger ranges. We confirm transferability by applying our method to another baseline, SQD-MapNet, and find similar improvements. A detailed analysis of the latent BEV grid confirms a more structured latent space of AugMapNet and shows the value of our novel concept beyond pure performance improvement. The code can be found at this https URL",
    "authors": [
      "Thomas Monninger",
      "Md Zafar Anwar",
      "Stanislaw Antol",
      "Steffen Staab",
      "Sihao Ding"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.18929",
    "title": "Trajectory Balance with Asynchrony: Decoupling Exploration and Learning for Fast, Scalable LLM Post-Training",
    "abstract": "Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, on-policy algorithms used for post-training are not naturally robust to a diversified content of experience replay buffers, which asynchronous off-policy actors can efficiently populate in parallel to training. We propose efficiently learning on such off-policy data via Trajectory Balance with Asynchrony (TBA), an approach to asynchronous RL for LLMs that leverages the principled off-policy TB objective. On math, preference-tuning, and automated red-teaming tasks, we post-train models ranging from Pythia 410M to Qwen 2.5 7B, finding TBA offers speed and performance boosts over strong baselines like Online DPO and Dr. GRPO. Beyond TBA's performance benefits (high accuracy even as asynchrony grows) and speedups ($4\\times$ or more), we show its reward- and recency-prioritizing sampling enable further gains as data generation is scaled. Our code is available at this https URL .",
    "authors": [
      "Brian Bartoldson",
      "Siddarth Venkatraman",
      "James Diffenderfer",
      "Moksh Jain",
      "Tal Ben-Nun",
      "Seanie Lee",
      "Minsu Kim",
      "Johan Obando-Ceron",
      "Yoshua Bengio",
      "Bhavya Kailkhura"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20162",
    "title": "Beyond Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-$2^{n/2}$ Enumeration",
    "abstract": "The Subset Sum problem, which asks whether a set of $n$ integers has a subset summing to a target $t$, is a fundamental NP-complete problem in cryptography and combinatorial optimization. The classical meet-in-the-middle (MIM) algorithm of Horowitz--Sahni runs in $\\mathcal{O}^*(2^{n/2})$, which remains the best-known deterministic bound. Yet in practice, many instances exhibit abundant collisions in partial sums, so the true difficulty is often governed by $U = |\\Sigma(S)|$, the number of unique subset sums. We present a structure-aware, adaptive solver that enumerates only the distinct subset sums, pruning duplicates on the fly and achieving deterministic runtime $\\mathcal{O}(U \\cdot n^2)$ and expected randomized runtime $\\mathcal{O}(U \\cdot n)$. Its core is a canonical unique-subset-sums enumerator combined with a double meet-in-the-middle strategy, supporting anytime and online modes. To ensure worst-case gains even on unstructured inputs, we introduce a Controlled Aliasing technique that provably reduces the enumeration space by a fixed constant factor. This yields a guaranteed global runtime of $\\mathcal{O}^*(2^{n/2 - \\varepsilon})$ for some $\\varepsilon > 0$, strictly improving upon classical bounds. Empirical results show that the solver adapts efficiently to structured inputs with low entropy (e.g., instances with small doubling constants, duplicates, or additive progressions) often approaching near-dynamic programming performance. We conclude by outlining how this adaptive framework can be extended to other NP-complete problems.",
    "authors": [
      "Jesus Salas"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.23793",
    "title": "Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables",
    "abstract": "Recently, deep learning-based pan-sharpening algorithms have achieved notable advancements over traditional methods. However, deep learning-based methods incur substantial computational overhead during inference, especially with large images. This excessive computational demand limits the applicability of these methods in real-world scenarios, particularly in the absence of dedicated computing devices such as GPUs and TPUs. To address these challenges, we propose Pan-LUT, a novel learnable look-up table (LUT) framework for pan-sharpening that strikes a balance between performance and computational efficiency for large remote sensing images. Our method makes it possible to process 15K*15K remote sensing images on a 24GB GPU. To finely control the spectral transformation, we devise the PAN-guided look-up table (PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained spatial details, we introduce the spatial details look-up table (SDLUT). Furthermore, to adaptively aggregate channel information for generating high-resolution multispectral images, we design an adaptive output look-up table (AOLUT). Our model contains fewer than 700K parameters and processes a 9K*9K image in under 1 ms using one RTX 2080 Ti GPU, demonstrating significantly faster performance compared to other methods. Experiments reveal that Pan-LUT efficiently processes large remote sensing images in a lightweight manner, bridging the gap to real-world applications. Furthermore, our model surpasses SOTA methods in full-resolution scenes under real-world conditions, highlighting its effectiveness and efficiency.",
    "authors": [
      "Zhongnan Cai",
      "Yingying Wang",
      "Hui Zheng",
      "Panwang Pan",
      "ZiXu Lin",
      "Ge Meng",
      "Chenxin Li",
      "Chunming He",
      "Jiaxin Xie",
      "Yunlong Lin",
      "Junbin Lu",
      "Yue Huang",
      "Xinghao Ding"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.02624",
    "title": "EgoLog: Ego-Centric Fine-Grained Daily Log with Ubiquitous Wearables",
    "abstract": "Despite advances in human activity recognition (HAR) with different modalities, a precise, robust, and accurate daily log system is not yet available. Current solutions primarily rely on controlled, lab-based data collection, which limits their real-world applicability. The challenges towards a fine-grained daily log are 1) contextual awareness, 2) spatial awareness, and 3) effective fusion of multi-modal sensor data. To solve them, we propose EgoLog, which integrates effective audio-IMU fusion for daily log with ubiquitous wearables. Our approach first fuses audio and IMU data from two perspectives: temporal understanding and spatial understanding. We extract scenario-level features and aggregate them in the time dimension, while using motion compensation to enhance the performance of sound source localization. The knowledge obtained from these steps is then integrated into a multi-modal HAR framework. Here, the scenario provides prior knowledge, and the spatial location helps differentiate the user from the background. Furthermore, we integrate a LLM to enhance scenario recognition through logical reasoning. The knowledge derived from the LLM is subsequently transferred back to the local device to enable efficient, on-device inference. Evaluated on both public and self-collected dataset, EgoLog achieves effective multimodal fusion for both activity and scenraio recognition, outperforms the baseline by 12% and 15%, respectively.",
    "authors": [
      "Lixing He",
      "Bufang Yang",
      "Di Duan",
      "Zhenyu Yan",
      "Guoliang Xing"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.03111",
    "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents",
    "abstract": "Large Language Model (LLM) agents are autonomous systems powered by LLMs, capable of reasoning and planning to solve problems by leveraging a set of tools. However, the integration of multi-tool capabilities in LLM agents introduces challenges in securely managing tools, ensuring their compatibility, handling dependency relationships, and protecting control flows within LLM agent workflows. In this paper, we present the first systematic security analysis of task control flows in multi-tool-enabled LLM agents. We identify a novel threat, Cross-Tool Harvesting and Polluting (XTHP), which includes multiple attack vectors to first hijack the normal control flows of agent tasks, and then collect and pollute confidential or private information within LLM agent systems. To understand the impact of this threat, we developed Chord, a dynamic scanning tool designed to automatically detect real-world agent tools susceptible to XTHP attacks. Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.",
    "authors": [
      "Zichuan Li",
      "Jian Cui",
      "Xiaojing Liao",
      "Luyi Xing"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.05868",
    "title": "Energy-Conserving Neural Network Closure Model for Long-Time Accurate and Stable LES",
    "abstract": "Machine learning-based closure models for LES have shown promise in capturing complex turbulence dynamics but often suffer from instabilities and physical inconsistencies. In this work, we develop a novel skew-symmetric neural architecture as closure model that enforces stability while preserving key physical conservation laws. Our approach leverages a discretization that ensures mass, momentum, and energy conservation, along with a face-averaging filter to maintain mass conservation in coarse-grained velocity fields. We compare our model against several conventional data-driven closures (including unconstrained convolutional neural networks), and the physics-based Smagorinsky model. Performance is evaluated on decaying turbulence and Kolmogorov flow for multiple coarse-graining factors. In these test cases we observe that unconstrained machine learning models suffer from numerical instabilities. In contrast, our skew-symmetric model remains stable across all tests, though at the cost of increased dissipation. Despite this trade-off, we demonstrate that our model still outperforms the Smagorinsky model in unseen scenarios. These findings highlight the potential of structure-preserving machine learning closures for reliable long-time LES.",
    "authors": [
      "Toby van Gastelen",
      "Wouter Edeling",
      "Benjamin Sanderse"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.06790",
    "title": "Analog Computing for Signal Processing and Communications -- Part I: Computing with Microwave Networks",
    "abstract": "Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.07477",
    "title": "Analog Computing for Signal Processing and Communications -- Part II: Toward Gigantic MIMO Beamforming",
    "abstract": "Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\\times 10^4$ and $4.0\\times 10^7$ times, respectively, compared to digital beamforming.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.15122",
    "title": "MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video",
    "abstract": "We present MoBGS, a novel motion deblurring 3D Gaussian Splatting (3DGS) framework capable of reconstructing sharp and high-quality novel spatio-temporal views from blurry monocular videos in an end-to-end manner. Existing dynamic novel view synthesis (NVS) methods are highly sensitive to motion blur in casually captured videos, resulting in significant degradation of rendering quality. While recent approaches address motion-blurred inputs for NVS, they primarily focus on static scene reconstruction and lack dedicated motion modeling for dynamic objects. To overcome these limitations, our MoBGS introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method using a proposed Blur-adaptive Neural Ordinary Differential Equation (ODE) solver for effective latent camera trajectory estimation, improving global camera motion deblurring. In addition, we propose a Latent Camera-induced Exposure Estimation (LCEE) method to ensure consistent deblurring of both a global camera and local object motions. Extensive experiments on the Stereo Blur dataset and real-world blurry videos show that our MoBGS significantly outperforms the very recent methods, achieving state-of-the-art performance for dynamic NVS under motion blur.",
    "authors": [
      "Minh-Quan Viet Bui",
      "Jongmin Park",
      "Juan Luis Gonzalez Bello",
      "Jaeho Moon",
      "Jihyong Oh",
      "Munchurl Kim"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.15471",
    "title": "Bigram Subnetworks: Mapping to Next Tokens in Transformer Language Models",
    "abstract": "In Transformer language models, activation vectors transform from current token embeddings to next token predictions as they pass through the model. To isolate a minimal form of this transformation, we identify language model subnetworks that make bigram predictions, naive next token predictions based only on the current token. We find that bigram subnetworks can be found in fully trained language models up to 1B parameters, and these subnetworks are critical for model performance even when they consist of less than 0.2% of model parameters. Bigram subnetworks are concentrated in the first Transformer MLP layer, and they overlap significantly with subnetworks trained to optimally prune a given model. Mechanistically, the bigram subnetworks often recreate a pattern from the full models where the first layer induces a sharp change that aligns activations with next token predictions rather than current token representations. Our results demonstrate that bigram subnetworks comprise a minimal subset of parameters that are both necessary and sufficient for basic next token predictions in language models, and they help drive the transformation from current to next token activations in the residual stream. These subnetworks can lay a foundation for studying more complex language model circuits by building up from a minimal circuit.",
    "authors": [
      "Tyler A. Chang",
      "Benjamin K. Bergen"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.19374",
    "title": "From Distance to Direction: Structure-aware Label-specific Feature Fusion for Label Distribution Learning",
    "abstract": "Label distribution learning (LDL) is an emerging learning paradigm designed to capture the relative importance of labels for each instance. Label-specific features (LSFs), constructed by LIFT, have proven effective for learning tasks with label ambiguity by leveraging clustering-based prototypes for each label to re-characterize instances. However, directly introducing LIFT into LDL tasks can be suboptimal, as the prototypes it collects primarily reflect intra-cluster relationships while neglecting cross-cluster interactions. Additionally, constructing LSFs using multi-perspective information, rather than relying solely on Euclidean distance, provides a more robust and comprehensive representation of instances, mitigating noise and bias that may arise from a single distance perspective. To address these limitations, we introduce Structural Anchor Points (SAPs) to capture inter-cluster interactions. This leads to a novel LSFs construction strategy, LIFT-SAP, which enhances LIFT by integrating both distance and directional information of each instance relative to SAPs. Furthermore, we propose a novel LDL algorithm, Label Distribution Learning via Label-specifIc FeaTure with SAPs (LDL-LIFT-SAP), which unifies multiple label description degrees predicted from different LSF spaces into a cohesive label distribution. Extensive experiments on 15 real-world datasets demonstrate the effectiveness of LIFT-SAP over LIFT, as well as the superiority of LDL-LIFT-SAP compared to seven other well-established algorithms.",
    "authors": [
      "Suping Xu",
      "Chuyi Dai",
      "Lin Shang",
      "Changbin Shao",
      "Xibei Yang",
      "Witold Pedrycz"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.02828",
    "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review",
    "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a pillar of Trustworthy AI and aims to bring transparency in complex models that are opaque by nature. Despite the benefits of incorporating explanations in models, an urgent need is found in addressing the privacy concerns of providing this additional information to end users. In this article, we conduct a scoping review of existing literature to elicit details on the conflict between privacy and explainability. Using the standard methodology for scoping review, we extracted 57 articles from 1,943 studies published from January 2019 to December 2024. The review addresses 3 research questions to present readers with more understanding of the topic: (1) what are the privacy risks of releasing explanations in AI systems? (2) what current methods have researchers employed to achieve privacy preservation in XAI systems? (3) what constitutes a privacy preserving explanation? Based on the knowledge synthesized from the selected studies, we categorize the privacy risks and preservation methods in XAI and propose the characteristics of privacy preserving explanations to aid researchers and practitioners in understanding the requirements of XAI that is privacy compliant. Lastly, we identify the challenges in balancing privacy with other system desiderata and provide recommendations for achieving privacy preserving XAI. We expect that this review will shed light on the complex relationship of privacy and explainability, both being the fundamental principles of Trustworthy AI.",
    "authors": [
      "Sonal Allana",
      "Mohan Kankanhalli",
      "Rozita Dara"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.08032",
    "title": "Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience",
    "abstract": "Adaptive beam switching is essential for mission-critical military and commercial 6G networks but faces major challenges from high carrier frequencies, user mobility, and frequent blockages. While existing machine learning (ML) solutions often focus on maximizing instantaneous throughput, this can lead to unstable policies with high signaling overhead. This paper presents an online Deep Reinforcement Learning (DRL) framework designed to learn an operationally stable policy. By equipping the DRL agent with an enhanced state representation that includes blockage history, and a stability-centric reward function, we enable it to prioritize long-term link quality over transient gains. Validated in a challenging 100-user scenario using the Sionna library, our agent achieves throughput comparable to a reactive Multi-Armed Bandit (MAB) baseline. Specifically, our proposed framework improves link stability by approximately 43% compared to a vanilla DRL approach, achieving operational reliability competitive with MAB while maintaining high data rates. This work demonstrates that by reframing the optimization goal towards operational stability, DRL can deliver efficient, reliable, and real-time beam management solutions for next-generation mission-critical networks.",
    "authors": [
      "Seyed Bagher Hashemi Natanzi",
      "Zhicong Zhu",
      "Bo Tang"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.10792",
    "title": "Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to improve factuality in large language models (LLMs) by grounding their outputs in retrieved documents. However, ensuring perfect retrieval of relevant information remains challenging, and when irrelevant content is passed downstream to an LLM, it can lead to hallucinations. In this work, we propose Finetune-RAG, a simple and effective fine-tuning approach that features the first-of-its-kind RAG training dataset constructed to mimic real-world imperfections. Experimental results show that Finetune-RAG improves factual accuracy by 21.2% over the base model. We also propose Bench-RAG, an LLM-as-a-judge evaluation pipeline that stress tests models under realistic imperfect retrieval scenarios. Our codebase and dataset are fully open sourced for community use.",
    "authors": [
      "Zhan Peng Lee",
      "Andre Lin",
      "Calvin Tan"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.14206",
    "title": "Challenges and Limitations of Generative AI in Synthesizing Wearable Sensor Data",
    "abstract": "The widespread adoption of wearable sensors has the potential to provide massive and heterogeneous time series data, driving the use of Artificial Intelligence in human sensing applications. However, data collection remains limited due to stringent ethical regulations, privacy concerns, and other constraints, hindering progress in the field. Synthetic data generation, particularly through Generative Adversarial Networks and Diffusion Models, has emerged as a promising solution to mitigate both data scarcity and privacy issues. However, these models are often limited to narrow operational scenarios, such as short-term and unimodal signal patterns. To address this gap, we present a systematic evaluation of state-of-the-art generative models for time series data, explicitly assessing their performance in challenging scenarios such as stress and emotion recognition. Our study examines the extent to which these models can jointly handle multi-modality, capture long-range dependencies, and support conditional generation-core requirements for real-world wearable sensor data generation. To enable a fair and rigorous comparison, we also introduce an evaluation framework that evaluates both the intrinsic fidelity of the generated data and their utility in downstream predictive tasks. Our findings reveal critical limitations in the existing approaches, particularly in maintaining cross-modal consistency, preserving temporal coherence, and ensuring robust performance in train-on-synthetic, test-on-real, and data augmentation scenarios. Finally, we present our future research directions to enhance synthetic time series generation and improve the applicability of generative models in the wearable computing domain.",
    "authors": [
      "Flavio Di Martino",
      "Franca Delmastro"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.15644",
    "title": "Can VLMs Detect and Localize Fine-Grained AI-Edited Images?",
    "abstract": "Fine-grained detection and localization of localized image edits is crucial for assessing content authenticity, especially as modern diffusion models and image editors can produce highly realistic manipulations. However, this problem faces three key challenges: (1) most AIGC detectors produce only a global real-or-fake label without indicating where edits occur; (2) traditional computer vision methods for edit localization typically rely on costly pixel-level annotations; and (3) there is no large-scale, modern benchmark specifically targeting edited-image detection. To address these gaps, we develop an automated data-generation pipeline and construct FragFake, a large-scale benchmark of AI-edited images spanning multiple source datasets, diverse editing models, and several common edit types. Building on FragFake, we are the first to systematically study vision language models (VLMs) for edited-image classification and edited-region localization. Our experiments show that pretrained VLMs, including GPT4o, perform poorly on this task, whereas fine-tuned models such as Qwen2.5-VL achieve high accuracy and substantially higher object precision across all settings. We further explore GRPO-based RLVR training, which yields modest metric gains while improving the interpretability of model outputs. Ablation and transfer analyses reveal how data balancing, training size, LoRA rank, and training domain affect performance, and highlight both the potential and the limitations of cross-editor and cross-dataset generalization. We anticipate that this work will establish a solid foundation to facilitate and inspire subsequent research endeavors in the domain of multimodal content authenticity.",
    "authors": [
      "Zhen Sun",
      "Ziyi Zhang",
      "Zeren Luo",
      "Zhiyuan Zhong",
      "Zeyang Sha",
      "Tianshuo Cong",
      "Zheng Li",
      "Shiwen Cui",
      "Weiqiang Wang",
      "Jiaheng Wei",
      "Xinlei He",
      "Qi Li",
      "Qian Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.16037",
    "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data",
    "abstract": "LLM routing aims to select the most appropriate model for each query, balancing competing performance metrics such as accuracy and cost across a pool of language models. Prior approaches typically adopt a decoupled strategy, where the metrics are first predicted and the model is then selected based on these estimates. This setup is prone to compounding errors and often relies on full-feedback data, where each query is evaluated by all candidate models, which is costly to obtain and maintain in practice. In contrast, we learn from observational data, which records only the outcome of the model actually deployed. We propose a causal end-to-end framework that learns routing policies by minimizing decision-making regret from observational data. To enable efficient optimization, we introduce two theoretically grounded surrogate objectives: a classification-based upper bound, and a softmax-weighted regret approximation shown to recover the optimal policy at convergence. We further extend our framework to handle heterogeneous cost preferences via an interval-conditioned architecture. Experiments on public benchmarks show that our method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.",
    "authors": [
      "Asterios Tsiourvas",
      "Wei Sun",
      "Georgia Perakis"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.17478",
    "title": "ConfRover: Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression",
    "abstract": "Understanding protein dynamics is critical for elucidating their biological functions. The increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins. However, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples. To address these limitations, we introduce ConfRover, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectories, supporting both time-dependent and time-independent sampling. At the core of our model is a modular architecture comprising: (i) an encoding layer, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a temporal module, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the structure decoder, generating conformations in continuous space. Experiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks. ConfRover is the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data. Project website: this https URL .",
    "authors": [
      "Yuning Shen",
      "Lihao Wang",
      "Huizhuo Yuan",
      "Yan Wang",
      "Bangji Yang",
      "Quanquan Gu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.18098",
    "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL",
    "abstract": "Large language models (LLMs) excel in tasks like question answering and dialogue, but complex tasks requiring interaction, such as negotiation and persuasion, require additional long-horizon reasoning and planning. Reinforcement learning (RL) fine-tuning can enable such planning in principle, but suffers from drawbacks that hinder scalability. In particular, multi-turn RL training incurs high memory and computational costs, which are exacerbated when training LLMs as policies. Furthermore, the largest LLMs do not expose the APIs necessary to be trained in such manner. As a result, modern methods to improve the reasoning of LLMs rely on sophisticated prompting mechanisms rather than RL fine-tuning. To remedy this, we propose a novel approach that uses goal-conditioned value functions to guide the reasoning of LLM agents, that scales even to large API-based models. These value functions predict how a task will unfold given an action, allowing the LLM agent to evaluate multiple possible outcomes, both positive and negative, to plan effectively. In addition, these value functions are trained over reasoning steps rather than full actions, to be a concise and light-weight module that facilitates decision-making in multi-turn interactions. We validate our method on tasks requiring interaction, including tool use, social deduction, and dialogue, demonstrating superior performance over both RL fine-tuning and prompting methods while maintaining efficiency and scalability.",
    "authors": [
      "Joey Hong",
      "Anca Dragan",
      "Sergey Levine"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.18565",
    "title": "Learning Fluid-Structure Interaction with Physics-Informed Machine Learning and Immersed Boundary Methods",
    "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising approach for solving complex fluid dynamics problems, yet their application to fluid-structure interaction (FSI) problems with moving boundaries remains largely unexplored. This work addresses the critical challenge of modeling FSI systems with moving interfaces, where traditional unified PINN architectures struggle to capture the distinct physics governing fluid and structural domains simultaneously. We present an innovative Eulerian-Lagrangian PINN architecture that integrates immersed boundary method (IBM) principles to solve FSI problems with moving boundary conditions. Our approach fundamentally departs from conventional unified architectures by introducing domain-specific neural networks: an Eulerian network for fluid dynamics and a Lagrangian network for structural interfaces, coupled through physics-based constraints. Additionally, we incorporate learnable B-spline activation functions with SiLU to capture both localized high-gradient features near interfaces and global flow patterns. Empirical studies on a 2D cavity flow problem involving a moving solid structure show that while baseline unified PINNs achieve reasonable velocity predictions, they suffer from substantial pressure errors (12.9%) in structural regions. Our Eulerian-Lagrangian architecture with learnable activations (EL-L) achieves better performance across all metrics, improving accuracy by 24.1-91.4% and particularly reducing pressure errors from 12.9% to 2.39%. These results demonstrate that domain decomposition aligned with physical principles, combined with locality-aware activation functions, is essential for accurate FSI modeling within the PINN framework.",
    "authors": [
      "Afrah Farea",
      "Saiful Khan",
      "Reza Daryani",
      "Emre Cenk Ersan",
      "Mustafa Serdar Celebi"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.19094",
    "title": "SATORI-R1: Incentivizing Multimodal Reasoning through Explicit Visual Anchoring",
    "abstract": "DeepSeek-R1 has demonstrated powerful reasoning capabilities in the text domain through stable reinforcement learning (RL). Recently, in the multimodal domain, works have begun to directly apply RL to generate R1-like free-form reasoning for Visual Question Answering (VQA) tasks. However, multimodal tasks share an intrinsically different nature from textual tasks, which heavily rely on the understanding of the input image to solve the problem. Therefore, such free-form reasoning faces two critical limitations in the VQA task: (1) Extended reasoning chains diffuse visual focus away from task-critical regions, degrading answer accuracy. (2) Unverifiable intermediate steps amplify policy-gradient variance and computational costs overhead. To address these issues, in this paper, we introduce SATORI ($\\textbf{S}patially$ $\\textbf{A}nchored$ $\\textbf{T}ask$ $\\textbf{O}ptimization$ with $\\textbf{R}e\\textbf{I}nforcement$ Learning), which decomposes VQA into three verifiable stages, including global image captioning, region localization, and answer prediction, each supplying explicit reward signals. Furthermore, we also introduce VQA-Verify, a 12k dataset annotated with answer-aligned captions and bounding-boxes to facilitate training. Experiments demonstrate consistent performance improvements across seven VQA benchmarks, achieving up to $15.7\\%$ improvement in accuracy in accuracy compared to the R1-like baseline. Our analysis of the attention map confirms enhanced focus on critical regions, which brings improvements in accuracy. Our code is available at this https URL .",
    "authors": [
      "Chuming Shen",
      "Wei Wei",
      "Xiaoye Qu",
      "Yu Cheng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.19582",
    "title": "Guard Me If You Know Me: Protecting Specific Face-Identity from Deepfakes",
    "abstract": "Securing personal identity against deepfake attacks is increasingly critical in the digital age, especially for celebrities and political figures whose faces are easily accessible and frequently targeted. Most existing deepfake detection methods focus on general-purpose scenarios and often ignore the valuable prior knowledge of known facial identities, e.g., \"VIP individuals\" whose authentic facial data are already available. In this paper, we propose \\textbf{VIPGuard}, a unified multimodal framework designed to capture fine-grained and comprehensive facial representations of a given identity, compare them against potentially fake or similar-looking faces, and reason over these comparisons to make accurate and explainable predictions. Specifically, our framework consists of three main stages. First, fine-tune a multimodal large language model (MLLM) to learn detailed and structural facial attributes. Second, we perform identity-level discriminative learning to enable the model to distinguish subtle differences between highly similar faces, including real and fake variations. Finally, we introduce user-specific customization, where we model the unique characteristics of the target face identity and perform semantic reasoning via MLLM to enable personalized and explainable deepfake detection. Our framework shows clear advantages over previous detection works, where traditional detectors mainly rely on low-level visual cues and provide no human-understandable explanations, while other MLLM-based models often lack a detailed understanding of specific face identities. To facilitate the evaluation of our method, we built a comprehensive identity-aware benchmark called \\textbf{VIPBench} for personalized deepfake detection, involving the latest 7 face-swapping and 7 entire face synthesis techniques for generation. The code is available at this https URL .",
    "authors": [
      "Kaiqing Lin",
      "Zhiyuan Yan",
      "Ke-Yue Zhang",
      "Li Hao",
      "Yue Zhou",
      "Yuzhen Lin",
      "Weixiang Li",
      "Taiping Yao",
      "Shouhong Ding",
      "Bin Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.21004",
    "title": "CoHear: Conversation Enhancement via Multi-Earphone Collaboration",
    "abstract": "In crowded places such as conferences, background noise, overlapping voices, and lively interactions make it difficult to have clear conversations. This situation often worsens the phenomenon known as \"cocktail party deafness.\" We present ClearSphere, the collaborative system that enhances speech at the conversation level with multi-earphones. Real-time conversation enhancement requires a holistic modeling of all the members in the conversation, and an effective way to extract the speech from the mixture. ClearSphere bridges the acoustic sensor system and state-of-the-art deep learning for target speech extraction by making two key contributions: 1) a conversation-driven network protocol, and 2) a robust target conversation extraction model. Our networking protocol enables mobile, infrastructure-free coordination among earphone devices. Our conversation extraction model can leverage the relay audio in a bandwidth-efficient way. ClearSphere is evaluated in both real-world experiments and simulations. Results show that our conversation network obtains more than 90\\% accuracy in group formation, improves the speech quality by up to 8.8 dB over state-of-the-art baselines, and demonstrates real-time performance on a mobile device. In a user study with 20 participants, ClearSphere has a much higher score than baseline with good usability.",
    "authors": [
      "Lixing He",
      "Yunqi Guo",
      "Zhenyu Yan",
      "Guoliang Xing"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.23316",
    "title": "Proximalized Preference Optimization for Diverse Feedback Types: A Decomposed Perspective on DPO",
    "abstract": "Direct alignment methods typically train large language models (LLMs) by contrasting the likelihoods of preferred and dispreferred responses. While effective at capturing relative preferences, these methods are widely observed to suppress the absolute likelihoods of example responses. As a result, aligned models can deviate from expected patterns, exhibiting rewar-hacking effect even without an explicit reward model. This fundamental limitation of contrastive alignment, which we term likelihood underdetermination, motivates us to revisit direct preference optimization (DPO) -- the seminal direct alignment method. Interestingly, we show that the DPO loss admits a principled decomposition. The reformulated loss not only extends naturally to a broader range of feedback types, but also unveils the root cause of likelihood underdetermination. Specifically, we identify that standard DPO implicitly oversimplifies a regularizer in the reformulated loss; restoring this full term effectively resolves the underdetermination. Building on these insights, we introduce PRoximalized PReference Optimization (PRO), a unified alignment method that accommodates diverse feedback types while eliminating likelihood underdetermination through an efficient approximation of the full regularizer. Empirical evaluations demonstrate the consistent superiority of PRO over existing methods across pairwise, binary and scalar feedback.",
    "authors": [
      "Kaiyang Guo",
      "Yinchuan Li",
      "Zhitang Chen"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.23623",
    "title": "Characterizing the Expressivity of Fixed-Precision Transformer Language Models",
    "abstract": "Transformer-based language models (LMs) have achieved widespread empirical success, but their theoretical expressive power remains only partially understood. In this work, we analyze a restricted idealization of fixed-precision transformers with strict future masking, soft attention, and no positional encodings. We establish that this class of models is exactly as expressive as a specific fragment of linear temporal logic that contains only a single temporal operator: the past operator. We further connect this fragment to established classes in formal language theory, automata theory, and algebra, yielding a unified framework for understanding transformer expressivity under this idealization. Finally, we present empirical results that align closely with our theory: transformers trained on languages within their characterized expressive capacity generalize reliably across sequence lengths, while they consistently fail to generalize on languages beyond it.",
    "authors": [
      "Jiaoda Li",
      "Ryan Cotterell"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.23733",
    "title": "Unintentional Consequences: Generative AI Use for Cybercrime",
    "abstract": "The democratization of generative AI introduces new forms of human-AI interaction and raises urgent safety, ethical, and cybersecurity concerns. We develop a socio-technical explanation for how generative AI enables and scales cybercrime. Drawing on affordance theory and technological amplification, we argue that generative AI systems create new action possibilities for cybercriminals and magnify pre-existing malicious intent by lowering expertise barriers and increasing attack efficiency. To illustrate this framework, we conduct interrupted time series analyses of two large datasets: (1) 464,190,074 malicious IP address reports from AbuseIPDB, and (2) 281,115 cryptocurrency scam reports from Chainabuse. Using November 30, 2022, as a high-salience public-access shock, we estimate the counterfactual trajectory of reported cyber abuse absent the release, providing an early-warning impact assessment of a general-purpose AI technology. Across both datasets, we observe statistically significant post-intervention increases in reported malicious activity, including an immediate increase of over 1.12 million weekly malicious IP reports and about 722 weekly cryptocurrency scam reports, with sustained growth in the latter. We discuss implications for AI governance, platform-level regulation, and cyber resilience, emphasizing the need for multi-layer socio-technical strategies that help key stakeholders maximize AI's benefits while mitigating its growing cybercrime risks.",
    "authors": [
      "Truong Jack Luu",
      "Binny M. Samuel"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.24029",
    "title": "Nonlinear Oscillatory Response of Automated Vehicle Car-following: Theoretical Analysis with Traffic State and Control Input Limits",
    "abstract": "This paper presents a framework grounded in the theory of describing function (DF) and incremental-input DF to theoretically analyze the nonlinear oscillatory response of automated vehicles (AVs) car-following (CF) amidst traffic oscillations, considering the limits of traffic state and control input. While prevailing approaches largely ignore these limits (i.e., saturation of acceleration/deceleration and speed) and focus on linear string stability analysis, this framework establishes a basis for theoretically analyzing the frequency response of AV systems with nonlinearities imposed by these limits. To this end, trajectories of CF pairs are decomposed into nominal and oscillatory trajectories, subsequently, the controlled AV system is repositioned within the oscillatory trajectory coordinates. Built on this base, DFs are employed to approximate the frequency responses of nonlinear saturation components by using their first harmonic output, thereby capturing the associated amplification ratio and phase shift. Considering the closed-loop nature of AV control systems, where system states and control input mutually influence each other, amplification ratios and phase shifts are balanced within the loop to ensure consistency. This balancing process may render multiple solutions, hence the incremental-input DF is further applied to identify the reasonable ones. The proposed method is validated by estimations from Simulink, and further comparisons with prevailing methods are conducted. Results confirm the alignment of our framework with Simulink results and exhibit its superior accuracy in analysis compared to the prevailing methods. Furthermore, the framework proves valuable in string stability analysis, especially when conventional linear methods offer misleading insights.",
    "authors": [
      "Sixu Li",
      "Yang Zhou"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.00195",
    "title": "Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences",
    "abstract": "Current LLMs are trained to refuse potentially harmful input queries regardless of whether users actually had harmful intents, causing a tradeoff between safety and user experience. Through a study of 480 participants evaluating 3,840 query-response pairs, we examine how different refusal strategies affect user perceptions across varying motivations. Our findings reveal that response strategy largely shapes user experience, while actual user motivation has negligible impact. Partial compliance -- providing general information without actionable details -- emerges as the optimal strategy, reducing negative user perceptions by over 50% to flat-out refusals. Complementing this, we analyze response patterns of 9 state-of-the-art LLMs and evaluate how 6 reward models score different refusal strategies, demonstrating that models rarely deploy partial compliance naturally and reward models currently undervalue it. This work demonstrates that effective guardrails require focusing on crafting thoughtful refusals rather than detecting intent, offering a path toward AI safety mechanisms that ensure both safety and sustained user engagement.",
    "authors": [
      "Mingqian Zheng",
      "Wenjia Hu",
      "Patrick Zhao",
      "Motahhare Eslami",
      "Jena D. Hwang",
      "Faeze Brahman",
      "Carolyn Rose",
      "Maarten Sap"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.00821",
    "title": "SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models",
    "abstract": "Genomic Foundation Models (GFMs), such as Evolutionary Scale Modeling (ESM), have demonstrated significant success in variant effect prediction. However, their adversarial robustness remains largely unexplored. To address this gap, we propose SafeGenes: a framework for Secure analysis of genomic foundation models, leveraging adversarial attacks to evaluate robustness against both engineered near-identical adversarial Genes and embedding-space manipulations. In this study, we assess the adversarial vulnerabilities of GFMs using two approaches: the Fast Gradient Sign Method (FGSM) and a soft prompt attack. FGSM introduces minimal perturbations to input sequences, while the soft prompt attack optimizes continuous embeddings to manipulate model predictions without modifying the input tokens. By combining these techniques, SafeGenes provides a comprehensive assessment of GFM susceptibility to adversarial manipulation. Targeted soft prompt attacks induced severe degradation in MLM-based shallow architectures such as ProteinBERT, while still producing substantial failure modes even in high-capacity foundation models such as ESM1b and ESM1v. These findings expose critical vulnerabilities in current foundation models, opening new research directions toward improving their security and robustness in high-stakes genomic applications such as variant effect prediction.",
    "authors": [
      "Huixin Zhan",
      "Clovis Barbour",
      "Jason H. Moore"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.02475",
    "title": "Comba: Improving Bilinear RNNs with Closed-loop Control",
    "abstract": "Recent efficient sequence modeling methods such as Gated DeltaNet, TTT, and RWKV-7 have achieved performance improvements by supervising the recurrent memory management through Delta learning rule. Unlike previous state-space models (e.g., Mamba) and gated linear attentions (e.g., GLA), these models introduce interactions between the recurrent state and the key vector, structurally resembling bilinear systems. In this paper, we first introduce the concept of Bilinear RNNs with a comprehensive analysis on the advantages and limitations of these models. Then, based on closed-loop control theory, we propose a novel Bilinear RNN variant named Comba, which adopts a scalar-plus-low-rank state transition, with both state feedback and output feedback corrections. We also implement a hardware-efficient chunk-wise parallel kernel in Triton and train models with 340M/1.3B parameters on large-scale corpus. Comba demonstrates superior performance and computation efficiency in both language and vision modeling.",
    "authors": [
      "Jiaxi Hu",
      "Yongqi Pan",
      "Jusen Du",
      "Disen Lan",
      "Xiaqiang Tang",
      "Qingsong Wen",
      "Yuxuan Liang",
      "Weigao Sun"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.03013",
    "title": "Cataloguing Hugging Face Models to Software Engineering Activities: Automation and Findings",
    "abstract": "Context: Open-source Pre-Trained Models (PTMs) provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs to support the reliable identification and reuse of models for SE. Objective: To address this gap, we derive a taxonomy encompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a popular open-source ML repository, Hugging Face (HF). Method: Our repository mining study followed a five-phase pipeline: (i) identification SE tasks from the literature; (ii) collection of PTM data from the HF API, including model card descriptions and metadata, and the abstracts of the associated arXiv papers; (iii) text processing to ensure consistency; (iv) a two-phase validation of SE relevance, involving humans and LLM assistance, supported by five pilot studies with human annotators and a generalization test; (v) and data analysis. This process yielded a curated catalogue of 2,205 SE PTMs. Results: We find that most SE PTMs target code generation and coding, emphasizing implementation over early or late development stages. In terms of ML tasks, text generation dominates within SE PTMs. Notably, the number of SE PTMs has increased markedly since 2023 Q2, while evaluation remains limited: only 9.6% report benchmark results, mostly scoring below 50%. Conclusions: Our catalogue reveals documentation and transparency gaps, highlights imbalances across SDLC phases, and provides a foundation for automated SE scenarios, such as the sampling and selection of suitable PTMs.",
    "authors": [
      "Alexandra González",
      "Xavier Franch",
      "David Lo",
      "Silverio Martínez-Fernández"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.03144",
    "title": "MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query",
    "abstract": "Semantic retrieval is crucial for modern applications yet remains underexplored in current research. Existing datasets are limited to single languages, single images, or singular retrieval conditions, often failing to fully exploit the expressive capacity of visual information as evidenced by maintained performance when images are replaced with captions. However, practical retrieval scenarios frequently involve interleaved multi-condition queries with multiple images. Hence, this paper introduces MERIT, the first multilingual dataset for interleaved multi-condition semantic retrieval, comprising 320,000 queries with 135,000 products in 5 languages, covering 7 distinct product categories. Extensive experiments on MERIT identify existing models's limitation: focusing solely on global semantic information while neglecting specific conditional elements in queries. Consequently, we propose Coral, a novel fine-tuning framework that adapts pre-trained MLLMs by integrating embedding reconstruction to preserve fine-grained conditional elements and contrastive learning to extract comprehensive global semantics. Experiments demonstrate that Coral achieves a 45.9% performance improvement over conventional approaches on MERIT, with strong generalization capabilities validated across 8 established retrieval benchmarks. Collectively, our contributions - a novel dataset, identification of critical limitations in existing approaches, and an innovative fine-tuning framework - establish a foundation for future research in interleaved multi-condition semantic retrieval.",
    "authors": [
      "Wei Chow",
      "Yuan Gao",
      "Linfeng Li",
      "Xian Wang",
      "Qi Xu",
      "Hang Song",
      "Lingdong Kong",
      "Ran Zhou",
      "Yi Zeng",
      "Yidong Cai",
      "Botian Jiang",
      "Shilin Xu",
      "Jiajun Zhang",
      "Minghui Qiu",
      "Xiangtai Li",
      "Tianshu Yang",
      "Siliang Tang",
      "Juncheng Li"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.05745",
    "title": "SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models",
    "abstract": "Large reasoning models (LRMs) excel at complex reasoning tasks but typically generate lengthy sequential chains-of-thought, resulting in long inference times before arriving at the final answer. To address this challenge, we introduce SPRINT, a novel post-training and inference-time framework designed to enable LRMs to dynamically identify and exploit opportunities for parallelization during their reasoning process. SPRINT incorporates an innovative data curation pipeline that reorganizes natural language reasoning trajectories into structured rounds of long-horizon planning and parallel execution. By fine-tuning LRMs on a small amount of such curated data, the models learn to dynamically identify independent subtasks within extended reasoning processes and effectively execute them in parallel. Through extensive evaluations, we demonstrate that models fine-tuned with the SPRINT framework match the performance of reasoning models on complex domains such as mathematics while generating up to 39% fewer sequential tokens on problems requiring more than 8,000 output tokens. Finally, we observe consistent results transferred to two out-of-distribution tasks, namely GPQA and Countdown, with up to 45% and 65% reduction in average sequential tokens respectively for longer reasoning trajectories, while matching the performance of the fine-tuned reasoning model.",
    "authors": [
      "Emil Biju",
      "Shayan Talaei",
      "Zhemin Huang",
      "Mohammadreza Pourreza",
      "Azalia Mirhoseini",
      "Amin Saberi"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.05980",
    "title": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification",
    "abstract": "Skill-based reinforcement learning (SBRL) enables rapid adaptation in environments with sparse rewards by pretraining a skill-conditioned policy. Effective skill learning requires jointly maximizing both exploration and skill diversity. However, existing methods often face challenges in simultaneously optimizing for these two conflicting objectives. In this work, we propose a new method, Adaptive Multi-objective Projection for balancing Exploration and skill Diversification (AMPED), which explicitly addresses both: during pre-training, a gradient-surgery projection balances the exploration and diversity gradients, and during fine-tuning, a skill selector exploits the learned diversity by choosing skills suited to downstream tasks. Our approach achieves performance that surpasses SBRL baselines across various benchmarks. Through an extensive ablation study, we identify the role of each component and demonstrate that each element in AMPED is contributing to performance. We further provide theoretical and empirical evidence that, with a greedy skill selector, greater skill diversity reduces fine-tuning sample complexity. These results highlight the importance of explicitly harmonizing exploration and diversity and demonstrate the effectiveness of AMPED in enabling robust and generalizable skill learning. Project Page: this https URL",
    "authors": [
      "Geonwoo Cho",
      "Jaemoon Lee",
      "Jaegyun Im",
      "Subi Lee",
      "Jihwan Lee",
      "Sundong Kim"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.06517",
    "title": "GS4: Generalizable Sparse Splatting Semantic SLAM",
    "abstract": "Traditional SLAM algorithms excel at camera tracking, but typically produce incomplete and low-resolution maps that are not tightly integrated with semantics prediction. Recent work integrates Gaussian Splatting (GS) into SLAM to enable dense, photorealistic 3D mapping, yet existing GS-based SLAM methods require per-scene optimization that is slow and consumes an excessive number of Gaussians. We present GS4, the first generalizable GS-based semantic SLAM system. Compared with prior approaches, GS4 runs 10x faster, uses 10x fewer Gaussians, and achieves state-of-the-art performance across color, depth, semantic mapping and camera tracking. From an RGB-D video stream, GS4 incrementally builds and updates a set of 3D Gaussians using a feed-forward network. First, the Gaussian Prediction Model estimates a sparse set of Gaussian parameters from input frame, which integrates both color and semantic prediction with the same backbone. Then, the Gaussian Refinement Network merges new Gaussians with the existing set while avoiding redundancy. Finally, when significant pose changes are detected, we perform only 1-5 iterations of joint Gaussian-pose optimization to correct drift, remove floaters, and further improve tracking accuracy. Experiments on the real-world ScanNet and ScanNet++ benchmarks demonstrate state-of-the-art semantic SLAM performance, with strong generalization capability shown through zero-shot transfer to the NYUv2 and TUM RGB-D datasets.",
    "authors": [
      "Mingqi Jiang",
      "Chanho Kim",
      "Chen Ziwen",
      "Li Fuxin"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.07985",
    "title": "Beyond Top Activations: Efficient and Reliable Crowdsourced Evaluation of Automated Interpretability",
    "abstract": "Interpreting individual neurons or directions in activation space is an important topic in mechanistic interpretability. Numerous automated interpretability methods have been proposed to generate such explanations, but it remains unclear how reliable these explanations are, and which methods produce the most accurate descriptions. While crowd-sourced evaluations are commonly used, existing pipelines are noisy, costly, and typically assess only the highest-activating inputs, leading to unreliable results. In this paper, we introduce two techniques to enable cost-effective and accurate crowdsourced evaluation of automated interpretability methods beyond top activating inputs. First, we propose Model-Guided Importance Sampling (MG-IS) to select the most informative inputs to show human raters. In our experiments, we show this reduces the number of inputs needed to reach the same evaluation accuracy by ~13x. Second, we address label noise in crowd-sourced ratings through Bayesian Rating Aggregation (BRAgg), which allows us to reduce the number of ratings per input required to overcome noise by ~3x. Together, these techniques reduce the evaluation cost by ~40x, making large-scale evaluation feasible. Finally, we use our methods to conduct a large scale crowd-sourced study comparing recent automated interpretability methods for vision networks.",
    "authors": [
      "Tuomas Oikarinen",
      "Ge Yan",
      "Akshay Kulkarni",
      "Tsui-Wei Weng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.08710",
    "title": "SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting",
    "abstract": "3D Gaussian Splatting (3DGS) serves as a highly performant and efficient encoding of scene geometry, appearance, and semantics. Moreover, grounding language in 3D scenes has proven to be an effective strategy for 3D scene understanding. Current Language Gaussian Splatting line of work fall into three main groups: (i) per-scene optimization-based, (ii) per-scene optimization-free, and (iii) generalizable approach. However, most of them are evaluated only on rendered 2D views of a handful of scenes and viewpoints close to the training views, limiting ability and insight into holistic 3D understanding. To address this gap, we propose the first large-scale benchmark that systematically assesses these three groups of methods directly in 3D space, evaluating on 1060 scenes across three indoor datasets and one outdoor dataset. Benchmark results demonstrate a clear advantage of the generalizable paradigm, particularly in relaxing the scene-specific limitation, enabling fast feed-forward inference on novel scenes, and achieving superior segmentation performance. We further introduce GaussianWorld-49K a carefully curated 3DGS dataset comprising around 49K diverse indoor and outdoor scenes obtained from multiple sources, with which we demonstrate the generalizable approach could harness strong data priors. Our codes, benchmark, and datasets are public to accelerate research in generalizable 3DGS scene understanding.",
    "authors": [
      "Mengjiao Ma",
      "Qi Ma",
      "Yue Li",
      "Jiahuan Cheng",
      "Runyi Yang",
      "Bin Ren",
      "Nikola Popovic",
      "Mingqiang Wei",
      "Nicu Sebe",
      "Luc Van Gool",
      "Theo Gevers",
      "Martin R. Oswald",
      "Danda Pani Paudel"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.09625",
    "title": "GLGENN: A Novel Parameter-Light Equivariant Neural Networks Architecture Based on Clifford Geometric Algebras",
    "abstract": "We propose, implement, and compare with competitors a new architecture of equivariant neural networks based on geometric (Clifford) algebras: Generalized Lipschitz Group Equivariant Neural Networks (GLGENN). These networks are equivariant to all pseudo-orthogonal transformations, including rotations and reflections, of a vector space with any non-degenerate or degenerate symmetric bilinear form. We propose a weight-sharing parametrization technique that takes into account the fundamental structures and operations of geometric algebras. Due to this technique, GLGENN architecture is parameter-light and has less tendency to overfitting than baseline equivariant models. GLGENN outperforms or matches competitors on several benchmarking equivariant tasks, including estimation of an equivariant function and a convex hull experiment, while using significantly fewer optimizable parameters.",
    "authors": [
      "Ekaterina Filimoshina",
      "Dmitry Shirokov"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.11534",
    "title": "GNSS-Inertial State Initialization Using Inter-Epoch Baseline Residuals",
    "abstract": "Initializing the state of a sensorized platform can be challenging, as a limited set of measurements often provide low-informative constraints that are in addition highly non-linear. This may lead to poor initial estimates that may converge to local minima during subsequent non-linear optimization. We propose an adaptive GNSS-inertial initialization strategy that delays the incorporation of global GNSS constraints until they become sufficiently informative. In the initial stage, our method leverages inter-epoch baseline vector residuals between consecutive GNSS fixes to mitigate inertial drift. To determine when to activate global constraints, we introduce a general criterion based on the evolution of the Hessian matrix's singular values, effectively quantifying system observability. Experiments on EuRoC, GVINS and MARS-LVIG datasets show that our approach consistently outperforms the naive strategy of fusing all measurements from the outset, yielding more accurate and robust initializations.",
    "authors": [
      "Samuel Cerezo",
      "Javier Civera"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.11599",
    "title": "A$^2$LC: Active and Automated Label Correction for Semantic Segmentation",
    "abstract": "Active Label Correction (ALC) has emerged as a promising solution to the high cost and error-prone nature of manual pixel-wise annotation in semantic segmentation, by actively identifying and correcting mislabeled data. Although recent work has improved correction efficiency by generating pseudo-labels using foundation models, substantial inefficiencies still remain. In this paper, we introduce A$^2$LC, an Active and Automated Label Correction framework for semantic segmentation, where manual and automatic correction stages operate in a cascaded manner. Specifically, the automatic correction stage leverages human feedback to extend label corrections beyond the queried samples, thereby maximizing cost efficiency. In addition, we introduce an adaptively balanced acquisition function that emphasizes underrepresented tail classes, working in strong synergy with the automatic correction stage. Extensive experiments on Cityscapes and PASCAL VOC 2012 demonstrate that A$^2$LC significantly outperforms previous state-of-the-art methods. Notably, A$^2$LC exhibits high efficiency by outperforming previous methods with only 20% of their budget, and shows strong effectiveness by achieving a 27.23% performance gain under the same budget on Cityscapes.",
    "authors": [
      "Youjin Jeon",
      "Kyusik Cho",
      "Suhan Woo",
      "Euntai Kim"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.19881",
    "title": "Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models",
    "abstract": "Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of \"provable copyright protection\" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copy protection that we dub being tainted. Then, we introduce our blameless copy protection framework for defining meaningful guarantees, and instantiate it with clean-room copy protection. Clean-room copy protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual clean-room setting. Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copy protection when the dataset is golden, a copyright deduplication requirement.",
    "authors": [
      "Aloni Cohen"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.19997",
    "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design",
    "abstract": "Generalizing deep reinforcement learning agents to unseen environments remains a significant challenge. One promising solution is Unsupervised Environment Design (UED), a co-evolutionary framework in which a teacher adaptively generates tasks with high learning potential, while a student learns a robust policy from this evolving curriculum. Existing UED methods typically measure learning potential via regret, the gap between optimal and current performance, approximated solely by value-function loss. Building on these approaches, we introduce the transition-prediction error as an additional term in our regret approximation. To capture how training on one task affects performance on others, we further propose a lightweight metric called Co-Learnability. By combining these two measures, we present Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED). Empirical evaluations show that TRACED produces curricula that improve zero-shot generalization over strong baselines across multiple benchmarks. Ablation studies confirm that the transition-prediction error drives rapid complexity ramp-up and that Co-Learnability delivers additional gains when paired with the transition-prediction error. These results demonstrate how refined regret approximation and explicit modeling of task relationships can be leveraged for sample-efficient curriculum design in UED. Project Page: this https URL",
    "authors": [
      "Geonwoo Cho",
      "Jaegyun Im",
      "Jihwan Lee",
      "Hojun Yi",
      "Sejin Kim",
      "Sundong Kim"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.21209",
    "title": "BitMark: Watermarking Bitwise Autoregressive Image Generative Models",
    "abstract": "State-of-the-art text-to-image models generate photorealistic images at an unprecedented speed. This work focuses on models that operate in a bitwise autoregressive manner over a discrete set of tokens that is practically infinite in size. However, their impressive generative power comes with a growing risk: as their outputs increasingly populate the Internet, they are likely to be scraped and reused as training data-potentially by the very same models. This phenomenon has been shown to lead to model collapse, where repeated training on generated content, especially from the models' own previous versions, causes a gradual degradation in performance. A promising mitigation strategy is watermarking, which embeds human-imperceptible yet detectable signals into generated images-enabling the identification of generated content. In this work, we introduce BitMark, a robust bitwise watermarking framework. Our method embeds a watermark directly at the bit level of the token stream during the image generation process. Our bitwise watermark subtly influences the bits to preserve visual fidelity and generation speed while remaining robust against a spectrum of removal techniques. Furthermore, it exhibits high radioactivity, i.e., when watermarked generated images are used to train another image generative model, this second model's outputs will also carry the watermark. The radioactive traces remain detectable even when only fine-tuning diffusion or image autoregressive models on images watermarked with our BitMark. Overall, our approach provides a principled step toward preventing model collapse in image generative models by enabling reliable detection of generated outputs. The code is available at this https URL .",
    "authors": [
      "Louis Kerner",
      "Michel Meintz",
      "Bihe Zhao",
      "Franziska Boenisch",
      "Adam Dziedzic"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.01513",
    "title": "SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism",
    "abstract": "By incorporating visual inputs, Multimodal Large Language Models (MLLMs) extend LLMs to support visual reasoning. However, this integration also introduces new vulnerabilities, making MLLMs susceptible to multimodal jailbreak attacks and hindering their safe this http URL defense methods, including Image-to-Text Translation, Safe Prompting, and Multimodal Safety Tuning, attempt to address this by aligning multimodal inputs with LLMs' built-in this http URL , they fall short in uncovering root causes of multimodal vulnerabilities, particularly how harmful multimodal tokens trigger jailbreak in MLLMs? Consequently, they remain vulnerable to text-driven multimodal jailbreaks, often exhibiting overdefensive behaviors and imposing heavy training this http URL bridge this gap, we present an comprehensive analysis of where, how and which harmful multimodal tokens bypass safeguards in MLLMs. Surprisingly, we find that less than 1% tokens in early-middle layers are responsible for inducing unsafe behaviors, highlighting the potential of precisely removing a small subset of harmful tokens, without requiring safety tuning, can still effectively improve safety against jailbreaks. Motivated by this, we propose Safe Prune-then-Restore (SafePTR), an training-free defense framework that selectively prunes harmful tokens at vulnerable layers while restoring benign features at subsequent this http URL incurring additional computational overhead, SafePTR significantly enhances the safety of MLLMs while preserving efficiency. Extensive evaluations across three MLLMs and five benchmarks demonstrate SafePTR's state-of-the-art performance in mitigating jailbreak risks without compromising utility.",
    "authors": [
      "Beitao Chen",
      "Xinyu Lyu",
      "Lianli Gao",
      "Jingkuan Song",
      "Heng Tao Shen"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.02459",
    "title": "A modified Crank-Nicolson scheme for the Vlasov-Poisson system with a strong external magnetic field",
    "abstract": "We propose and study a Particle-In-Cell (PIC) method based on the Crank-Nicolson time discretization for the Vlasov-Poisson system with a strong and inhomogeneous external magnetic field with fixed direction, where we focus on the motion of particles in the plane orthogonal to the magnetic field. In this regime, the time step can be subject to stability constraints related to the smallness of Larmor radius and plasma frequency [21]. To avoid this limitation, our approach is based on numerical schemes [9, 10, 12], providing a consistent PIC discretization of the guiding-center system taking into account variations of the magnetic field. We carry out some theoretical proofs and perform several numerical experiments to validate the method and its underlying concepts.",
    "authors": [
      "Francis Filbet",
      "L Miguel Rodrigues",
      "Kim Han Trinh"
    ],
    "primary_category": "math.NA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.02513",
    "title": "Automatic Labelling for Low-Light Pedestrian Detection",
    "abstract": "Pedestrian detection in RGB images is a key task in pedestrian safety, as the most common sensor in autonomous vehicles and advanced driver assistance systems is the RGB camera. A challenge in RGB pedestrian detection, that does not appear to have large public datasets, is low-light conditions. As a solution, in this research, we propose an automated infrared-RGB labeling pipeline. The proposed pipeline consists of 1) Infrared detection, where a fine-tuned model for infrared pedestrian detection is used 2) Label transfer process from the infrared detections to their RGB counterparts 3) Training object detection models using the generated labels for low-light RGB pedestrian detection. The research was performed using the KAIST dataset. For the evaluation, object detection models were trained on the generated autolabels and ground truth labels. When compared on a previously unseen image sequence, the results showed that the models trained on generated labels outperformed the ones trained on ground-truth labels in 6 out of 9 cases for the mAP@50 and mAP@50-95 metrics. The source code for this research is available at this https URL",
    "authors": [
      "Dimitrios Bouzoulas",
      "Eerik Alamikkotervo",
      "Risto Ojala"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.03724",
    "title": "MemOS: A Memory OS for AI System",
    "abstract": "Large Language Models (LLMs) have become an essential infrastructure for Artificial General Intelligence (AGI), yet their lack of well-defined memory management systems hinders the development of long-context reasoning, continual personalization, and knowledge this http URL models mainly rely on static parameters and short-lived contextual states, limiting their ability to track user preferences or update knowledge over extended this http URL Retrieval-Augmented Generation (RAG) introduces external knowledge in plain text, it remains a stateless workaround without lifecycle control or integration with persistent this http URL work has modeled the training and inference cost of LLMs from a memory hierarchy perspective, showing that introducing an explicit memory layer between parameter memory and external retrieval can substantially reduce these costs by externalizing specific knowledge. Beyond computational efficiency, LLMs face broader challenges arising from how information is distributed over time and context, requiring systems capable of managing heterogeneous knowledge spanning different temporal scales and sources. To address this challenge, we propose MemOS, a memory operating system that treats memory as a manageable system resource. It unifies the representation, scheduling, and evolution of plaintext, activation-based, and parameter-level memories, enabling cost-efficient storage and retrieval. As the basic unit, a MemCube encapsulates both memory content and metadata such as provenance and versioning. MemCubes can be composed, migrated, and fused over time, enabling flexible transitions between memory types and bridging retrieval with parameter-based learning. MemOS establishes a memory-centric system framework that brings controllability, plasticity, and evolvability to LLMs, laying the foundation for continual learning and personalized modeling.",
    "authors": [
      "Zhiyu Li",
      "Chenyang Xi",
      "Chunyu Li",
      "Ding Chen",
      "Boyu Chen",
      "Shichao Song",
      "Simin Niu",
      "Hanyu Wang",
      "Jiawei Yang",
      "Chen Tang",
      "Qingchen Yu",
      "Jihao Zhao",
      "Yezhaohui Wang",
      "Peng Liu",
      "Zehao Lin",
      "Pengyuan Wang",
      "Jiahao Huo",
      "Tianyi Chen",
      "Kai Chen",
      "Kehang Li",
      "Zhen Tao",
      "Huayi Lai",
      "Hao Wu",
      "Bo Tang",
      "Zhengren Wang",
      "Zhaoxin Fan",
      "Ningyu Zhang",
      "Linfeng Zhang",
      "Junchi Yan",
      "Mingchuan Yang",
      "Tong Xu",
      "Wei Xu",
      "Huajun Chen",
      "Haofen Wang",
      "Hongkang Yang",
      "Wentao Zhang",
      "Zhi-Qin John Xu",
      "Siheng Chen",
      "Feiyu Xiong"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.04209",
    "title": "Mutual Information Bounds for Lossy Common Information",
    "abstract": "We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and Gács-Körner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).",
    "authors": [
      "Anderson de Andrade"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.08243",
    "title": "CoreSPECT: Enhancing Clustering Algorithms via an Interplay of Density and Geometry",
    "abstract": "In this paper, we provide a novel perspective on the underlying structure of real-world data with ground-truth clusters via characterization of an abundantly observed yet often overlooked density-geometry correlation, that manifests itself as a multi-layered manifold structure. We leverage this correlation to design CoreSPECT (Core Space Projection based Enhancement of Clustering Techniques), a general framework that improves the performance of generic clustering algorithms. Our framework boosts the performance of clustering algorithms by applying them to strategically selected regions, then extending the partial partition to a complete partition for the dataset using a novel neighborhood graph based multi-layer propagation procedure. We provide initial theoretical support of the functionality of our framework under the assumption of our model, and then provide large-scale real-world experiments on 19 datasets that include standard image datasets as well as genomics datasets. We observe two notable improvements. First, CoreSPECT improves the NMI of K-Means by 20% on average, making it competitive to (and in some cases surpassing) the state-of-the-art manifold-based clustering algorithms, while being orders of magnitude faster. Secondly, our framework boosts the NMI of HDBSCAN by more than 100% on average, making it competitive to the state-of-the-art in several cases without requiring the true number of clusters and hyper-parameter tuning. The overall ARI improvements are higher.",
    "authors": [
      "Chandra Sekhar Mukherjee",
      "Joonyoung Bae",
      "Jiapeng Zhang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.10543",
    "title": "MP1: MeanFlow Tames Policy Learning in 1-step for Robotic Manipulation",
    "abstract": "In robot manipulation, robot learning has become a prevailing approach. However, generative models within this field face a fundamental trade-off between the slow, iterative sampling of diffusion models and the architectural constraints of faster Flow-based methods, which often rely on explicit consistency losses. To address these limitations, we introduce MP1, which pairs 3D point-cloud inputs with the MeanFlow paradigm to generate action trajectories in one network function evaluation (1-NFE). By directly learning the interval-averaged velocity via the \"MeanFlow Identity\", our policy avoids any additional consistency constraints. This formulation eliminates numerical ODE-solver errors during inference, yielding more precise trajectories. MP1 further incorporates CFG for improved trajectory controllability while retaining 1-NFE inference without reintroducing structural constraints. Because subtle scene-context variations are critical for robot learning, especially in few-shot learning, we introduce a lightweight Dispersive Loss that repels state embeddings during training, boosting generalization without slowing inference. We validate our method on the Adroit and Meta-World benchmarks, as well as in real-world scenarios. Experimental results show MP1 achieves superior average task success rates, outperforming DP3 by 10.2% and FlowPolicy by 7.3%. Its average inference time is only 6.8 ms-19x faster than DP3 and nearly 2x faster than FlowPolicy. Our project page is available at this https URL , and the code can be accessed at this https URL .",
    "authors": [
      "Juyi Sheng",
      "Ziyi Wang",
      "Peiming Li",
      "Mengyuan Liu"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.11168",
    "title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models",
    "abstract": "The increasing need for robustness, reliability, and determinism in wireless networks for industrial and mission-critical applications is the driver for the growth of new innovative methods. The study presented in this work makes use of machine learning techniques to predict channel quality in a Wi-Fi network in terms of the frame delivery ratio. Predictions can be used proactively to adjust communication parameters at runtime and optimize network operations for industrial applications. Methods including convolutional neural networks and long short-term memory were analyzed on datasets acquired from a real Wi-Fi setup across multiple channels. The models were compared in terms of prediction accuracy and computational complexity. Results show that the frame delivery ratio can be reliably predicted, and convolutional neural networks, although slightly less effective than other models, are more efficient in terms of CPU usage and memory consumption. This enhances the model's usability on embedded and industrial systems.",
    "authors": [
      "Gabriele Formis",
      "Amanda Ericson",
      "Stefan Forsstrom",
      "Kyi Thar",
      "Gianluca Cena",
      "Stefano Scanzio"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.12482",
    "title": "Kodezi Chronos: A Debugging-First Language Model for Repository-Scale Code Understanding",
    "abstract": "Large Language Models (LLMs) have advanced code generation and software automation but remain constrained by inference-time context and lack structured reasoning over code, leaving debugging largely unsolved. While Claude 4.5 Opus achieves 74.40% on SWE-bench Verified and Gemini 3 Pro reaches 76.2%, both models remain below 20% on real multi-file debugging tasks. We introduce Kodezi Chronos-1, a language model purpose-built for debugging that integrates Adaptive Graph-Guided Retrieval to navigate codebases up to 10 million lines (92% precision, 85% recall), Persistent Debug Memory trained on over 15 million sessions, and a seven-layer fix-test-refine architecture. On 5,000 real-world scenarios, Chronos-1 achieves 67.3% +/- 2.1% fix accuracy compared to 14.2% +/- 1.3% for Claude 4.1 Opus and 13.8% +/- 1.2% for GPT-4.1 (Cohen's d = 3.87). On SWE-bench Lite, Chronos-1 reaches a state-of-the-art 80.33% resolution rate (241 of 300), outperforming the next best system by 20 points and achieving repository-specific highs of 96.1% on Sympy and 90.4% on Django. Chronos-1 reduces debugging time by 40% and iterations by 65%, resolving complex multi-file and cross-repository bugs that require temporal analysis. Limitations remain for hardware-dependent and dynamic language errors, and Chronos-1 will be available in Kodezi OS in Q4 2025 and via API in Q1 2026.",
    "authors": [
      "Ishraq Khan",
      "Assad Chowdary",
      "Sharoz Haseeb",
      "Urvish Patel",
      "Yousuf Zaii"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.18603",
    "title": "Demystify Protein Generation with Hierarchical Conditional Diffusion Models",
    "abstract": "Generating novel and functional protein sequences is critical to a wide range of applications in biology. Recent advancements in conditional diffusion models have shown impressive empirical performance in protein generation tasks. However, reliable generations of protein remain an open research question in de novo protein design, especially when it comes to conditional diffusion models. Considering the biological function of a protein is determined by multi-level structures, we propose a novel multi-level conditional diffusion model that integrates both sequence-based and structure-based information for efficient end-to-end protein design guided by specified functions. By generating representations at different levels simultaneously, our framework can effectively model the inherent hierarchical relations between different levels, resulting in an informative and discriminative representation of the generated protein. We also propose a Protein-MMD, a new reliable evaluation metric, to evaluate the quality of generated protein with conditional diffusion models. Our new metric is able to capture both distributional and functional similarities between real and generated protein sequences while ensuring conditional consistency. We experiment with the benchmark datasets, and the results on conditional protein generation tasks demonstrate the efficacy of the proposed generation framework and evaluation metric.",
    "authors": [
      "Zinan Ling",
      "Yi Shi",
      "Brett McKinney",
      "Da Yan",
      "Yang Zhou",
      "Bo Hui"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.18725",
    "title": "The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse Models",
    "abstract": "Machine unlearning aims to efficiently eliminate the memory about deleted data from trained models and address the right to be forgotten. Despite the success of existing unlearning algorithms, unlearning in sparse models has not yet been well studied. In this paper, we empirically find that the deleted data has an impact on the pruned topology in a sparse model. Motivated by the observation and the right to be forgotten, we define a new terminology ``un-pruning\" to eliminate the impact of deleted data on model pruning. Then we propose an un-pruning algorithm to approximate the pruned topology driven by retained data. We remark that any existing unlearning algorithm can be integrated with the proposed un-pruning workflow and the error of un-pruning is upper-bounded in theory. Also, our un-pruning algorithm can be applied to both structured sparse models and unstructured sparse models. In the experiment, we further find that Membership Inference Attack (MIA) accuracy is unreliable for assessing whether a model has forgotten deleted data, as a small change in the amount of deleted data can produce arbitrary MIA results. Accordingly, we devise new performance metrics for sparse models to evaluate the success of un-pruning. Lastly, we conduct extensive experiments to verify the efficacy of un-pruning with various pruning methods and unlearning algorithms. Our code is released at this https URL .",
    "authors": [
      "Yang Xiao",
      "Gen Li",
      "Jie Ji",
      "Ruimeng Ye",
      "Xiaolong Ma",
      "Bo Hui"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.00835",
    "title": "PCS Workflow for Veridical Data Science in the Age of AI",
    "abstract": "Data science is a pillar of artificial intelligence (AI), which is transforming nearly every domain of human activity, from the social and physical sciences to engineering and medicine. While data-driven findings in AI offer unprecedented power to extract insights and guide decision-making, many are difficult or impossible to replicate. A key reason for this challenge is the uncertainty introduced by the many choices made throughout the data science life cycle (DSLC). Traditional statistical frameworks often fail to account for this uncertainty. The Predictability-Computability-Stability (PCS) framework for veridical (truthful) data science offers a principled approach to addressing this challenge throughout the DSLC. This paper presents an updated and streamlined PCS workflow, tailored for practitioners and enhanced with guided use of generative AI. We include a running example to display the PCS framework in action, and conduct a related case study which showcases the uncertainty in downstream predictions caused by judgment calls in the data cleaning stage.",
    "authors": [
      "Zachary T. Rewolinski",
      "Bin Yu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.01173",
    "title": "MARS: A Meta-Adaptive Reinforcement Learning Framework for Risk-Aware Multi-Agent Portfolio Management",
    "abstract": "Reinforcement Learning (RL) has shown significant promise in automated portfolio management; however, effectively balancing risk and return remains a central challenge, as many models fail to adapt to dynamically changing market conditions. We propose Meta-controlled Agents for a Risk-aware System (MARS), a novel framework addressing this through a multi-agent, risk-aware approach. MARS replaces monolithic models with a Heterogeneous Agent Ensemble, where each agent's unique risk profile is enforced by a Safety-Critic network to span behaviors from capital preservation to aggressive growth. A high-level Meta-Adaptive Controller (MAC) dynamically orchestrates this ensemble, shifting reliance between conservative and aggressive agents to minimize drawdown during downturns while seizing opportunities in bull markets. This two-tiered structure leverages behavioral diversity rather than explicit feature engineering to ensure a disciplined portfolio robust across market regimes. Experiments on major international indexes confirm that our framework significantly reduces maximum drawdown and volatility while maintaining competitive returns.",
    "authors": [
      "Jiayi Chen",
      "Jing Li",
      "Guiling Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.02013",
    "title": "SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents",
    "abstract": "Recently, role-playing agents have emerged as a promising paradigm for achieving personalized interaction and emotional resonance. Existing research primarily focuses on the textual modality, neglecting the critical dimension of speech in realistic interactive scenarios. In particular, there is a lack of systematic evaluation for Speech Role-Playing Agents (SRPAs). To address this gap, we construct SpeechRole-Data, a large-scale, high-quality dataset that comprises 98 diverse roles and 112k speech-based single-turn and multi-turn conversations. Each role demonstrates distinct vocal characteristics, including timbre and prosody, thereby enabling more sophisticated speech role-playing. Furthermore, we propose SpeechRole-Eval, a multidimensional evaluation benchmark that systematically assesses SRPAs performance in key aspects such as fundamental interaction ability, speech expressiveness, and role-playing fidelity. Experimental results reveal the advantages and challenges of both cascaded and end-to-end speech role-playing agents in maintaining vocal style consistency and role coherence. We release all data, code, and baseline models to provide a solid foundation for speech-driven multimodal role-playing research and to foster further developments in this field.",
    "authors": [
      "Changhao Jiang",
      "Jiajun Sun",
      "Yifei Cao",
      "Jiabao Zhuang",
      "Hui Li",
      "Baoyu Fan",
      "Tao Ji",
      "Tao Gui",
      "Qi Zhang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.02103",
    "title": "Instance-Dependent Continuous-Time Reinforcement Learning via Maximum Likelihood Estimation",
    "abstract": "Continuous-time reinforcement learning (CTRL) provides a natural framework for sequential decision-making in dynamic environments where interactions evolve continuously over time. While CTRL has shown growing empirical success, its ability to adapt to varying levels of problem difficulty remains poorly understood. In this work, we investigate the instance-dependent behavior of CTRL and introduce a simple, model-based algorithm built on maximum likelihood estimation (MLE) with a general function approximator. Unlike existing approaches that estimate system dynamics directly, our method estimates the state marginal density to guide learning. We establish instance-dependent performance guarantees by deriving a regret bound that scales with the total reward variance and measurement resolution. Notably, the regret becomes independent of the specific measurement strategy when the observation frequency adapts appropriately to the problem's complexity. To further improve performance, our algorithm incorporates a randomized measurement schedule that enhances sample efficiency without increasing measurement cost. These results highlight a new direction for designing CTRL algorithms that automatically adjust their learning behavior based on the underlying difficulty of the environment.",
    "authors": [
      "Runze Zhao",
      "Yue Yu",
      "Ruhan Wang",
      "Chunfeng Huang",
      "Dongruo Zhou"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.03142",
    "title": "UniEdit-I: Training-free Image Editing for Unified VLM via Iterative Understanding, Editing and Verifying",
    "abstract": "While Unified Vision-Language Models promise to synergistically combine the high-level semantic understanding of vision-language models with the generative fidelity of diffusion models, current editing methodologies remain fundamentally decoupled and open loop performing static, pre-defined transformations without dynamic feedback between semantic interpretation and visual generation. A central limitation stems from the representation gap: understanding typically leverages high-level, language aligned encoders, whereas generation relies on low level, pixel-space autoencoders, resulting in misaligned feature spaces. To bridge this gap, Recent advances such as Representation Autoencoders and BLIP3-o advocate performing diffusion-based modeling directly in high level features from pretrained semantic encoders. We find editing in the semantic latent space modifies conceptual representations rather than pixels, ensuring intermediates that are both semantically coherent and visually plausible. Building on this insight, We propose UniEdit-I, the first training-free, closed-loop image editing framework that operates entirely within the semantic latent space of a unified VLM by introducing an Understanding-Editing-Verifying (UEV) loop, By transforming the VLM from a posthoc evaluator into an in-process conductor, UniEdit-I establishes the first semantics-driven, self-correcting closed-loop image editing pipeline. Evaluated on GEdit-Bench, UniEdit-I achieves state of the art performance without any fine tuning or architectural modifications, and even surpasses several largescale pretrained editors.",
    "authors": [
      "Chengyu Bai",
      "Jintao Chen",
      "Xiang Bai",
      "Yilong Chen",
      "Qi She",
      "Ming Lu",
      "Shanghang Zhang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.03772",
    "title": "GTPO: Stabilizing Group Relative Policy Optimization via Gradient and Entropy Control",
    "abstract": "Group Relative Policy Optimization (GRPO) is a promising policy-based approach for Large Language Model alignment, yet its performance is often limited by training instability and suboptimal convergence. In this paper, we identify and analyze two main GRPO issues: (i) the token-level penalization, where valuable tokens shared across different responses receive contradictory feedback signals, leading to conflicting gradient updates that can reduce their likelihood; and (ii) the policy collapse, where negatively rewarded completions may penalize confident responses and shift model decisions toward unlikely tokens, destabilizing training process. To address these issues we introduce GTPO (Group-relative Trajectory-based Policy Optimization), which prevents conflicting gradients on valuable tokens by skipping negative updates while amplifying positive ones and filters out completions whose entropy exceeds a provable threshold, to prevent policy collapse. Unlike GRPO, GTPO does not rely on KL-divergence regularization, eliminating the need for a reference model during training, while still ensuring greater training stability and improved performance, as validated through multiple experiments on GSM8K, MATH, AIME 2024, AIME 2025 and AMC 2023.",
    "authors": [
      "Marco Simoni",
      "Aleksandar Fontana",
      "Giulio Rossolini",
      "Andrea Saracino",
      "Paolo Mori"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.04377",
    "title": "GoldMind: A Teacher-Centered Knowledge Management System for Higher Education -- Lessons from Iterative Design",
    "abstract": "Designing Knowledge Management Systems (KMSs) for higher education requires addressing complex human-technology interactions, especially where staff turnover and changing roles create ongoing challenges for reusing knowledge. While advances in process mining and Generative AI enable new ways of designing features to support knowledge management, existing KMSs often overlook the realities of educators' workflows, leading to low adoption and limited impact. This paper presents findings from a two-year human-centred design study with 108 higher education teachers, focused on the iterative co-design and evaluation of GoldMind, a KMS supporting in-the-flow knowledge management during digital teaching tasks. Through three design-evaluation cycles, we examined how teachers interacted with the system and how their feedback informed successive refinements. Insights are synthesised across three themes: (1) Technology Lessons from user interaction data, (2) Design Considerations shaped by co-design and usability testing, and (3) Human Factors, including cognitive load and knowledge behaviours, analysed using Epistemic Network Analysis.",
    "authors": [
      "Gloria Fernández-Nieto",
      "Lele Sha",
      "Yuheng Li",
      "Yi-Shan Tsai",
      "Guanliang Chen",
      "Yinwei Wei",
      "Weiqing Wang",
      "Jinchun Wen",
      "Shaveen Singh",
      "Ivan Silva",
      "Yuanfang Li",
      "Dragan Gasěvić",
      "Zachari Swiecki"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.05452",
    "title": "LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models",
    "abstract": "Existing evaluation of Large Language Models (LLMs) on static benchmarks is vulnerable to data contamination and leaderboard overfitting, critical issues that obscure true model capabilities. To address this, we introduce LLMEval-3, a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary bank of 220k graduate-level questions, from which it dynamically samples unseen test sets for each evaluation run. Its automated pipeline ensures integrity via contamination-resistant data curation, a novel anti-cheating architecture, and a calibrated LLM-as-a-judge process achieving 90% agreement with human experts, complemented by a relative ranking system for fair comparison. An 20-month longitudinal study of nearly 50 leading models reveals a performance ceiling on knowledge memorization and exposes data contamination vulnerabilities undetectable by static benchmarks. The framework demonstrates exceptional robustness in ranking stability and consistency, providing strong empirical validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and credible methodology for assessing the true capabilities of LLMs beyond leaderboard scores, promoting the development of more trustworthy evaluation standards.",
    "authors": [
      "Ming Zhang",
      "Yujiong Shen",
      "Jingyi Deng",
      "Yuhui Wang",
      "Yue Zhang",
      "Junzhe Wang",
      "Shichun Liu",
      "Shihan Dou",
      "Huayu Sha",
      "Qiyuan Peng",
      "Changhao Jiang",
      "Jingqi Tong",
      "Yilong Wu",
      "Zhihao Zhang",
      "Mingqi Wu",
      "Zhiheng Xi",
      "Mingxu Chai",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.08115",
    "title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork",
    "abstract": "We present TeamMedAgents, a modular multi-agent framework that systematically translates evidence-based teamwork principles from organizational psychology into large language model collaboration for medical decision-making. Building upon Salas et al.'s \"Big Five\" teamwork model, we operationalize five core components as independently configurable mechanisms: shared mental models, team leadership, team orientation, trust networks, and mutual monitoring. Our architecture dynamically recruits 2-4 specialist agents and employs structured four-phase deliberation with adaptive component selection. Evaluation across eight medical benchmarks encompassing 11,545 questions demonstrates TeamMedAgents achieves 77.63% overall accuracy (text-based: 81.30%, vision-language: 66.60%). Systematic ablation studies comparing three single-agent baselines (Zero-Shot, Few-Shot, CoT) against individual teamwork components reveal task-specific optimization patterns: shared mental models excel on knowledge tasks, trust mechanisms improve differential diagnosis, while comprehensive integration degrades performance. Adaptive component selection yields 2-10 percentage point improvements over strongest baselines, with 96.2% agent convergence validating structured coordination effectiveness. TeamMedAgents establishes principled methodology for translating human teamwork theory into multi-agent systems, demonstrating that evidence-based collaboration patterns enhance AI performance in safety-critical domains through modular component design and selective activation strategies.",
    "authors": [
      "Pranav Pushkar Mishra",
      "Mohammad Arvan",
      "Mohan Zalake"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.08136",
    "title": "FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting",
    "abstract": "The success of 3DGS in generative and editing applications has sparked growing interest in 3DGS-based style transfer. However, current methods still face two major challenges: (1) multi-view inconsistency often leads to style conflicts, resulting in appearance smoothing and distortion; and (2) heavy reliance on VGG features, which struggle to disentangle style and content from style images, often causing content leakage and excessive stylization. To tackle these issues, we introduce \\textbf{FantasyStyle}, a 3DGS-based style transfer framework, and the first to rely entirely on diffusion model distillation. It comprises two key components: (1) \\textbf{Multi-View Frequency Consistency}. We enhance cross-view consistency by applying a 3D filter to multi-view noisy latent, selectively reducing low-frequency components to mitigate stylized prior conflicts. (2) \\textbf{Controllable Stylized Distillation}. To suppress content leakage from style images, we introduce negative guidance to exclude undesired content. In addition, we identify the limitations of Score Distillation Sampling and Delta Denoising Score in 3D style transfer and remove the reconstruction term accordingly. Building on these insights, we propose a controllable stylized distillation that leverages negative guidance to more effectively optimize the 3D Gaussians. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art approaches, achieving higher stylization quality and visual realism across various scenes and styles. The code is available at this https URL .",
    "authors": [
      "Yitong Yang",
      "Yinglin Wang",
      "Changshuo Wang",
      "Huajie Wang",
      "Shuting He"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.08785",
    "title": "Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering",
    "abstract": "LLMs often suffer from hallucinations and outdated or incomplete knowledge. RAG is proposed to address these issues by integrating external knowledge like that in KGs into LLMs. However, leveraging private KGs in RAG systems poses significant privacy risks due to the black-box nature of LLMs and potential insecure data transmission, especially when using third-party LLM APIs lacking transparency and control. In this paper, we investigate the privacy-protected RAG scenario for the first time, where entities in KGs are anonymous for LLMs, thus preventing them from accessing entity semantics. Due to the loss of semantics of entities, previous RAG systems cannot retrieve question-relevant knowledge from KGs by matching questions with the meaningless identifiers of anonymous entities. To realize an effective RAG system in this scenario, two key challenges must be addressed: (1) How can anonymous entities be converted into retrievable information. (2) How to retrieve question-relevant anonymous entities. Hence, we propose a novel ARoG framework including relation-centric abstraction and structure-oriented abstraction strategies. For challenge (1), the first strategy abstracts entities into high-level concepts by dynamically capturing the semantics of their adjacent relations. It supplements meaningful semantics which can further support the retrieval process. For challenge (2), the second strategy transforms unstructured natural language questions into structured abstract concept paths. These paths can be more effectively aligned with the abstracted concepts in KGs, thereby improving retrieval performance. To guide LLMs to effectively retrieve knowledge from KGs, the two strategies strictly protect privacy from being exposed to LLMs. Experiments on three datasets demonstrate that ARoG achieves strong performance and privacy-robustness.",
    "authors": [
      "Yunfeng Ning",
      "Mayi Xu",
      "Jintao Wen",
      "Qiankun Pi",
      "Yuanyuan Zhu",
      "Ming Zhong",
      "Jiawei Jiang",
      "Tieyun Qian"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.08933",
    "title": "Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation",
    "abstract": "Language models have demonstrated remarkable performance on complex multi-step reasoning tasks. However, their evaluation has been predominantly confined to high-resource languages such as English. In this paper, we introduce a manually translated Bangla multi-step reasoning dataset derived from the English Reveal dataset, featuring both binary and non-binary question types. We conduct a controlled evaluation of English-centric and Bangla-centric multilingual small language models on the original dataset and our translated version to compare their ability to exploit relevant reasoning steps to produce correct answers. Our results show that, in comparable settings, reasoning context is beneficial for more challenging non-binary questions, but models struggle to employ relevant Bangla reasoning steps effectively. We conclude by exploring how reasoning steps contribute to models' predictions, highlighting different trends across models and languages.",
    "authors": [
      "Khondoker Ittehadul Islam",
      "Gabriele Sarti"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.09442",
    "title": "Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference",
    "abstract": "The Key-Value (KV) cache, which stores intermediate attention computations (Key and Value pairs) to avoid redundant calculations, is a fundamental mechanism for accelerating Large Language Model (LLM) inference. However, this efficiency optimization introduces significant yet underexplored privacy risks. This paper provides the first comprehensive analysis of these vulnerabilities, demonstrating that an attacker can reconstruct sensitive user inputs directly from the KV-cache. We design and implement three distinct attack vectors: a direct Inversion Attack, a more broadly applicable and potent Collision Attack, and a semantic-based Injection Attack. These methods demonstrate the practicality and severity of KV-cache privacy leakage issues. To mitigate this, we propose KV-Cloak, a novel, lightweight, and efficient defense mechanism. KV-Cloak uses a reversible matrix-based obfuscation scheme, combined with operator fusion, to secure the KV-cache. Our extensive experiments show that KV-Cloak effectively thwarts all proposed attacks, reducing reconstruction quality to random noise. Crucially, it achieves this robust security with virtually no degradation in model accuracy and minimal performance overhead, offering a practical solution for trustworthy LLM deployment.",
    "authors": [
      "Zhifan Luo",
      "Shuo Shao",
      "Su Zhang",
      "Lijing Zhou",
      "Yuke Hu",
      "Chenxu Zhao",
      "Zhihao Liu",
      "Zhan Qin"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.11323",
    "title": "Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking",
    "abstract": "3D multi-object tracking is a critical and challenging task in the field of autonomous driving. A common paradigm relies on modeling individual object motion, e.g., Kalman filters, to predict trajectories. While effective in simple scenarios, this approach often struggles in crowded environments or with inaccurate detections, as it overlooks the rich geometric relationships between objects. This highlights the need to leverage spatial cues. However, existing geometry-aware methods can be susceptible to interference from irrelevant objects, leading to ambiguous features and incorrect associations. To address this, we propose focusing on cue-consistency: identifying and matching stable spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency Tracker (DSC-Track) to implement this principle. Firstly, we design a unified spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative trajectory embeddings while suppressing interference. Secondly, our cue-consistency transformer module explicitly aligns consistent feature representations between historical tracks and current detections. Finally, a dynamic update mechanism preserves salient spatiotemporal information for stable online tracking. Extensive experiments on the nuScenes and Waymo Open Datasets validate the effectiveness and robustness of our approach. On the nuScenes benchmark, for instance, our method achieves state-of-the-art performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets, respectively.",
    "authors": [
      "Haonan Zhang",
      "Xinyao Wang",
      "Boxi Wu",
      "Tu Zheng",
      "Wang Yunhua",
      "Zheng Yang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.12409",
    "title": "S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing",
    "abstract": "Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS) analysis by leveraging unlabeled data through pseudo-labeling and consistency learning. However, existing S4 studies often rely on small-scale datasets and models, limiting their practical applicability. To address this, we propose S5, the first scalable framework for semi-supervised semantic segmentation in RS, which unlocks the potential of vast unlabeled Earth observation data typically underutilized due to costly pixel-level annotations. Built upon existing large-scale RS datasets, S5 introduces a data selection strategy that integrates entropy-based filtering and diversity expansion, resulting in the RS4P-1M dataset. Using this dataset, we systematically scale up S4 into a new pretraining paradigm, S4 pre-training (S4P), to pretrain RS foundation models (RSFMs) of varying sizes on this extensive corpus, significantly boosting their performance on land cover segmentation and object detection tasks. Furthermore, during fine-tuning, we incorporate a Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which enables efficient adaptation to multiple RS benchmarks with fewer parameters. This approach improves the generalization and versatility of RSFMs across diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance across all benchmarks, underscoring the viability of scaling semi-supervised learning for RS applications. All datasets, code, and models will be released at this https URL",
    "authors": [
      "Liang Lv",
      "Di Wang",
      "Jing Zhang",
      "Lefei Zhang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.12805",
    "title": "From Interpolating Formulas to Separating Languages and Back Again",
    "abstract": "Traditionally, research on Craig interpolation is concerned with (a) establishing the Craig interpolation property (CIP) of a logic saying that every valid implication in the logic has a Craig interpolant and (b) designing algorithms that extract Craig interpolants from proofs. Logics that lack the CIP are regarded as `pathological' and excluded from consideration. In this chapter, we survey variations and generalisations of traditional Craig interpolation. First, we consider Craig interpolants for implications in logics without the CIP, focusing on the decidability and complexity of deciding their existence. We then generalise interpolation by looking for Craig interpolants in languages L' that can be weaker than the language L of the given implication. Thus, do not only we restrict the non-logical symbols of Craig interpolants but also the logical ones. The resulting L/L'-interpolation problem generalises L/L'-definability, the question whether an L-formula is equivalent to some L'-formula. After that, we move from logical languages to formal languages where interpolation disguises itself as separation: given two disjoint languages in a class C, does there exist a separating language in a smaller class C'? This question is particularly well-studied in the case when the input languages are regular and the separating language is first-order definable. Finally, we connect the different research strands by showing how the decidability of the separation problem for regular languages can be used to prove the decidability of Craig interpolant existence for linear temporal logic LTL.",
    "authors": [
      "Agi Kurucz",
      "Frank Wolter",
      "Michael Zakharyaschev"
    ],
    "primary_category": "cs.LO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.17282",
    "title": "ERF-BA-TFD+: A Multimodal Model for Audio-Visual Deepfake Detection",
    "abstract": "Deepfake detection is a critical task in identifying manipulated multimedia content. In real-world scenarios, deepfake content can manifest across multiple modalities, including audio and video. To address this challenge, we present ERF-BA-TFD+, a novel multimodal deepfake detection model that combines enhanced receptive field (ERF) and audio-visual fusion. Our model processes both audio and video features simultaneously, leveraging their complementary information to improve detection accuracy and robustness. The key innovation of ERF-BA-TFD+ lies in its ability to model long-range dependencies within the audio-visual input, allowing it to better capture subtle discrepancies between real and fake content. In our experiments, we evaluate ERF-BA-TFD+ on the DDL-AV dataset, which consists of both segmented and full-length video clips. Unlike previous benchmarks, which focused primarily on isolated segments, the DDL-AV dataset allows us to assess the model's performance in a more comprehensive and realistic setting. Our method achieves state-of-the-art results on this dataset, outperforming existing techniques in terms of both accuracy and processing speed. The ERF-BA-TFD+ model demonstrated its effectiveness in the \"Workshop on Deepfake Detection, Localization, and Interpretability,\" Track 2: Audio-Visual Detection and Localization (DDL-AV), and won first place in this competition.",
    "authors": [
      "Xin Zhang",
      "Jiaming Chu",
      "Jian Zhao",
      "Yuchu Jiang",
      "Xu Yang",
      "Lei Jin",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.17316",
    "title": "SpecGen: Neural Spectral BRDF Generation via Spectral-Spatial Tri-plane Aggregation",
    "abstract": "Synthesizing spectral images across different wavelengths is essential for photorealistic rendering. Unlike conventional spectral uplifting methods that convert RGB images into spectral ones, we introduce SpecGen, a novel method that generates spectral bidirectional reflectance distribution functions (BRDFs) from a single RGB image of a sphere. This enables spectral image rendering under arbitrary illuminations and shapes covered by the corresponding material. A key challenge in spectral BRDF generation is the scarcity of measured spectral BRDF data. To address this, we propose the Spectral-Spatial Tri-plane Aggregation (SSTA) network, which models reflectance responses across wavelengths and incident-outgoing directions, allowing the training strategy to leverage abundant RGB BRDF data to enhance spectral BRDF generation. Experiments show that our method accurately reconstructs spectral BRDFs from limited spectral data and surpasses state-of-the-art methods in hyperspectral image reconstruction, achieving an improvement of 8 dB in PSNR. Codes and data will be released upon acceptance.",
    "authors": [
      "Zhenyu Jin",
      "Wenjie Li",
      "Zhanyu Ma",
      "Heng Guo"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.19499",
    "title": "Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery",
    "abstract": "Origin-Destination (OD) flow matrices are critical for urban mobility analysis, supporting traffic forecasting, infrastructure planning, and policy design. Existing methods face two key limitations: (1) reliance on costly auxiliary features (e.g., Points of Interest, socioeconomic statistics) with limited spatial coverage, and (2) fragility to spatial topology changes, where reordering urban regions disrupts the structural coherence of generated flows. We propose Sat2Flow, a structure-aware diffusion framework that generates structurally coherent OD flows using only satellite imagery. Our approach employs a multi-kernel encoder to capture diverse regional interactions and a permutation-aware diffusion process that maintains consistency across regional orderings. Through joint contrastive training linking satellite features with OD patterns and equivariant diffusion training enforcing structural invariance, Sat2Flow ensures topological robustness under arbitrary regional reindexing. Experiments on real-world datasets show that Sat2Flow outperforms physics-based and data-driven baselines in accuracy while preserving flow distributions and spatial structures under index permutations. Sat2Flow offers a globally scalable solution for OD flow generation in data-scarce environments, eliminating region-specific auxiliary data dependencies while maintaining structural robustness for reliable mobility modeling.",
    "authors": [
      "Xiangxu Wang",
      "Tianhong Zhao",
      "Wei Tu",
      "Bowen Zhang",
      "Guanzhou Chen",
      "Jinzhou Cao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.20464",
    "title": "Human-Centered Design for Connected Automation: Predicting Pedestrian Crossing Intentions",
    "abstract": "More than half of the 1.19 million annual traffic fatalities globally involve vulnerable road users, such as pedestrians, with a significant proportion attributable to human error. Level-5 automated driving systems (ADSs) have the potential to reduce these incidents; However, their effectiveness depends not only on automation performance but also on their ability to communicate intent and coordinate safely with pedestrians in the absence of traditional driver cues. This study aims to model pedestrian decision-making in road-crossing scenarios involving level-5 ADSs by extending the Theory of Planned Behavior (TPB) with safety, trust, compatibility, and understanding. An online survey (n = 212) found that perceived behavioral control, attitude, and social information significantly influence pedestrians' crossing intentions, with perceived safety and understanding having the strongest effects on the TPB constructs. The results offer guidance for designing eHMIs and cooperative V2X communication strategies that promote safe pedestrian-ADS interactions and advance human-centered design for autonomous vehicles.",
    "authors": [
      "Sanaz Motamedi",
      "Viktoria Marcus",
      "Griffin Pitts"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.00303",
    "title": "Access Paths for Efficient Ordering with Large Language Models",
    "abstract": "In this work, we present the \\texttt{LLM ORDER BY} semantic operator as a logical abstraction and conduct a systematic study of its physical implementations. First, we propose several improvements to existing semantic sorting algorithms and introduce a semantic-aware external merge sort algorithm. Our extensive evaluation reveals that no single implementation offers universal optimality on all datasets. From our evaluations, we observe a general test-time scaling relationship between sorting cost and the ordering quality for comparison-based algorithms. Building on these insights, we design a budget-aware optimizer that utilizes heuristic rules, LLM-as-Judge evaluation, and consensus aggregation to dynamically select the near-optimal access path for LLM ORDER BY. In our extensive evaluations, our optimizer consistently achieves ranking accuracy on par with or superior to the best static methods across all benchmarks. We believe that this work provides foundational insights into the principled optimization of semantic operators essential for building robust, large-scale LLM-powered analytic systems.",
    "authors": [
      "Fuheng Zhao",
      "Jiayue Chen",
      "Yiming Pan",
      "Tahseen Rabbani",
      "Sohaib",
      "Divyakant Agrawal",
      "Amr El Abbadi",
      "Paritosh Aggarwal",
      "Anupam Datta",
      "Dimitris Tsirogiannis"
    ],
    "primary_category": "cs.DB",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.04018",
    "title": "FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction",
    "abstract": "Robotic manipulation is a fundamental component of automation. However, traditional perception-planning pipelines often fall short in open-ended tasks due to limited flexibility, while the architecture of a single end-to-end Vision-Language-Action (VLA) offers promising capabilities but lacks crucial mechanisms for anticipating and recovering from failure. To address these challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with a supervisor for failure prediction and correction. The supervisor evaluates action viability through vision-language queries and generates corrective strategies when risks arise, trained efficiently without manual labeling. A dual-stream fusion module further refines actions by leveraging past predictions. Evaluation results on multiple simulation platforms (SIMPLER and LIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA outperforms state-of-the-art models in both zero-shot and fine-tuned settings. Successful real-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong generalization and practical utility for building more reliable autonomous systems.",
    "authors": [
      "Yifan Yang",
      "Zhixiang Duan",
      "Tianshi Xie",
      "Fuyu Cao",
      "Pinxi Shen",
      "Peili Song",
      "Piaopiao Jin",
      "Guokang Sun",
      "Shaoqing Xu",
      "Yangwei You",
      "Jingtai Liu"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.05661",
    "title": "Language-Driven Object-Oriented Two-Stage Method for Scene Graph Anticipation",
    "abstract": "A scene graph is a structured representation of objects and their spatio-temporal relationships in dynamic scenes. Scene Graph Anticipation (SGA) involves predicting future scene graphs from video clips, enabling applications in intelligent surveillance and human-machine collaboration. While recent SGA approaches excel at leveraging visual evidence, long-horizon forecasting fundamentally depends on semantic priors and commonsense temporal regularities that are challenging to extract purely from visual features. To explicitly model these semantic dynamics, we propose Linguistic Scene Graph Anticipation (LSGA), a linguistic formulation of SGA that performs temporal relational reasoning over sequences of textualized scene graphs, with visual scene-graph detection handled by a modular front-end when operating on video. Building on this formulation, we introduce Object-Oriented Two-Stage Method (OOTSM), a language-based framework that anticipates object-set dynamics and forecasts object-centric relation trajectories with temporal consistency regularization, and we evaluate it on a dedicated benchmark constructed from Action Genome annotations. Extensive experiments show that compact fine-tuned language models with up to 3B parameters consistently outperform strong zero- and one-shot API baselines, including GPT-4o, GPT-4o-mini, and DeepSeek-V3, under matched textual inputs and context windows. When coupled with off-the-shelf visual scene-graph generators, the resulting multimodal system achieves substantial improvements on video-based SGA, boosting long-horizon mR@50 by up to 21.9\\% over strong visual SGA baselines.",
    "authors": [
      "Xiaomeng Zhu",
      "Changwei Wang",
      "Haozhe Wang",
      "Xinyu Liu",
      "Fangzhen Lin"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.07506",
    "title": "Astra: A Multi-Agent System for GPU Kernel Performance Optimization",
    "abstract": "GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization. Our code is publicly available at this https URL .",
    "authors": [
      "Anjiang Wei",
      "Tianran Sun",
      "Yogesh Seenichamy",
      "Hang Song",
      "Anne Ouyang",
      "Azalia Mirhoseini",
      "Ke Wang",
      "Alex Aiken"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.07996",
    "title": "3D and 4D World Modeling: A Survey",
    "abstract": "World modeling has become a cornerstone in AI research, enabling agents to understand, represent, and predict the dynamic environments they inhabit. While prior work largely emphasizes generative methods for 2D image and video data, they overlook the rapidly growing body of work that leverages native 3D and 4D representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds for large-scale scene modeling. At the same time, the absence of a standardized definition and taxonomy for ``world models'' has led to fragmented and sometimes inconsistent claims in the literature. This survey addresses these gaps by presenting the first comprehensive review explicitly dedicated to 3D and 4D world modeling and generation. We establish precise definitions, introduce a structured taxonomy spanning video-based (VideoGen), occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and systematically summarize datasets and evaluation metrics tailored to 3D/4D settings. We further discuss practical applications, identify open challenges, and highlight promising research directions, aiming to provide a coherent and foundational reference for advancing the field. A systematic summary of existing literature is available at this https URL",
    "authors": [
      "Lingdong Kong",
      "Wesley Yang",
      "Jianbiao Mei",
      "Youquan Liu",
      "Ao Liang",
      "Dekai Zhu",
      "Dongyue Lu",
      "Wei Yin",
      "Xiaotao Hu",
      "Mingkai Jia",
      "Junyuan Deng",
      "Kaiwen Zhang",
      "Yang Wu",
      "Tianyi Yan",
      "Shenyuan Gao",
      "Song Wang",
      "Linfeng Li",
      "Liang Pan",
      "Yong Liu",
      "Jianke Zhu",
      "Wei Tsang Ooi",
      "Steven C. H. Hoi",
      "Ziwei Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.08863",
    "title": "GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial Analysis-Function Calling vs Code Generation",
    "abstract": "Large Language Models (LLMs) have demonstrated substantial progress in task automation and natural language understanding. However, without domain expertise in geographic information science (GIS), they continue to encounter limitations including reduced accuracy and unstable performance when processing complex tasks. To address these challenges, we propose GeoJSON Agents-a novel multi-agent LLM architecture specifically designed for geospatial analysis. This framework transforms natural language instructions into structured GeoJSON operations through two LLM enhancement techniques: Function Calling and Code Generation. The architecture integrates three core components: task parsing, agent collaboration, and result integration. The Planner agent systematically decomposes user-defined tasks into executable subtasks, while Worker agents perform spatial data processing and analysis either by invoking predefined function APIs or by generating and executing Python-based analytical code. The system produces reusable, standards-compliant GeoJSON outputs through iterative refinement. To evaluate both approaches, we constructed a benchmark comprising 70 tasks spanning basic, intermediate, and advanced complexity levels, conducting experiments with OpenAI's GPT-4o as the core model. Results indicate that the Code Generation-based agent achieved 97.14% accuracy, while the Function Calling-based agent attained 85.71%-both significantly outperforming the best-performing general-purpose model (48.57%). Comparative analysis reveals Code Generation offers superior flexibility for complex, open-ended tasks, whereas Function Calling provides enhanced execution stability for structured operations. This study represents the first systematic integration of GeoJSON data with a multi-agent LLM framework and provides empirical evidence comparing two mainstream enhancement methodologies in geospatial context.",
    "authors": [
      "Qianqian Luo",
      "Qingming Lin",
      "Liuchang Xu",
      "Sensen Wu",
      "Ruichen Mao",
      "Chao Wang",
      "Hailin Feng",
      "Bo Huang",
      "Zhenhong Du"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.09245",
    "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search",
    "abstract": "Large language models (LLMs) have shown great promise in automating data science workflows, but existing models still struggle with multi-step reasoning and tool use, which limits their effectiveness on complex data analysis tasks. To address this, we propose a scalable pipeline that extracts high-quality, tool-based data analysis tasks and their executable multi-step solutions from real-world Jupyter notebooks and associated data files. Using this pipeline, we introduce NbQA, a large-scale dataset of standardized task-solution pairs that reflect authentic tool-use patterns in practical data science scenarios. To further enhance multi-step reasoning, we present Jupiter, a framework that formulates data analysis as a search problem and applies Monte Carlo Tree Search (MCTS) to generate diverse solution trajectories for value model learning. During inference, Jupiter combines the value model and node visit counts to efficiently collect executable multi-step plans with minimal search steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench, respectively-matching or surpassing GPT-4o and advanced agent frameworks. Further evaluations demonstrate improved generalization and stronger tool-use reasoning across diverse multi-step reasoning tasks. Code and data are available at this https URL .",
    "authors": [
      "Shuocheng Li",
      "Yihao Liu",
      "Silin Du",
      "Wenxuan Zeng",
      "Zhe Xu",
      "Mengyu Zhou",
      "Yeye He",
      "Haoyu Dong",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.09796",
    "title": "Superstructure Optimization with Embedded Neural Networks for Sustainable Aviation Fuel Production",
    "abstract": "This study presents a multi-objective optimization framework for sustainable aviation fuel (SAF) production, integrating artificial neural networks (ANNs) within a mixed-integer quadratically constrained programming (MIQCP) formulation. By embedding data-driven surrogate models into the mathematical optimization structure, the proposed methodology addresses key limitations of conventional superstructure-based approaches, enabling simultaneous optimization of discrete process choices and continuous operating parameters. The framework captures variable input and output stream compositions, facilitating the joint optimization of target product composition and system design. Application to Fischer-Tropsch (FT) kerosene production demonstrates that cost-minimizing configurations under unconstrained CO2 emissions are dominated by the fossil-based autothermal reforming (ATR) route. Imposing carbon emission constraints necessitates the integration of biomass gasification and direct air capture coupled with carbon sequestration (DAC-CS), resulting in substantially reduced net emissions but higher production costs. At the zero-emission limit, hybrid configurations combining ATR and biomass gasification achieve the lowest costs (~2.38 \\$/kg-kerosene), followed closely by biomass gasification-only (~2.43 \\$/kg), both of which outperform the ATR-only pathway with DAC-CS (~2.65 \\$/kg). In contrast, DAC-only systems relying exclusively on atmospheric CO2 and water electrolysis are prohibitively expensive (~10.8 \\$/kg). The results highlight the critical role of the embedded ANNs: optimal process conditions, such as FT reactor pressure and gasification temperature, adapt to changing circumstances, consistently outperforming fixed setups and achieving up to 20% cost savings.",
    "authors": [
      "Alexander Klimek",
      "Christoph Plate",
      "Sebastian Sager",
      "Kai Sundmacher",
      "Caroline Ganzer"
    ],
    "primary_category": "cs.CE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.09828",
    "title": "DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception",
    "abstract": "Robust semantic perception for autonomous vehicles relies on effectively combining multiple sensors with complementary strengths and weaknesses. State-of-the-art sensor fusion approaches to semantic perception often treat sensor data uniformly across the spatial extent of the input, which hinders performance when faced with challenging conditions. By contrast, we propose a novel depth-guided multimodal fusion method that upgrades condition-aware fusion by integrating depth information. Our network, DGFusion, poses multimodal segmentation as a multi-task problem, utilizing the lidar measurements, which are typically available in outdoor sensor suites, both as one of the model's inputs and as ground truth for learning depth. Our corresponding auxiliary depth head helps to learn depth-aware features, which are encoded into spatially varying local depth tokens that condition our attentive cross-modal fusion. Together with a global condition token, these local depth tokens dynamically adapt sensor fusion to the spatially varying reliability of each sensor across the scene, which largely depends on depth. In addition, we propose a robust loss for our depth, which is essential for learning from lidar inputs that are typically sparse and noisy in adverse conditions. Our method achieves state-of-the-art panoptic and semantic segmentation performance on the challenging MUSES and DeLiVER datasets. Code and models will be available at this https URL",
    "authors": [
      "Tim Broedermannn",
      "Christos Sakaridis",
      "Luigi Piccinelli",
      "Wim Abbeloos",
      "Luc Van Gool"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10419",
    "title": "Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining",
    "abstract": "Ensuring the resilience of computer-based railways is increasingly crucial to account for uncertainties and changes due to the growing complexity and criticality of those systems. Although their software relies on strict verification and validation processes following well-established best-practices and certification standards, anomalies can still occur at run-time due to residual faults, system and environmental modifications that were unknown at design-time, or other emergent cyber-threat scenarios. This paper explores run-time control-flow anomaly detection using process mining to enhance the resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European Train Control System Level 2). Process mining allows learning the actual control flow of the system from its execution traces, thus enabling run-time monitoring through online conformance checking. In addition, anomaly localization is performed through unsupervised machine learning to link relevant deviations to critical system components. We test our approach on a reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its capability to detect and localize anomalies with high accuracy, efficiency, and explainability.",
    "authors": [
      "Francesco Vitale",
      "Tommaso Zoppi",
      "Francesco Flammini",
      "Nicola Mazzocca"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.10746",
    "title": "RECAP: Transparent Inference-Time Emotion Alignment for Medical Dialogue Systems",
    "abstract": "Large language models in healthcare often miss critical emotional cues, delivering medically sound but emotionally flat advice. Such responses are insufficient in clinical encounters, where distressed or vulnerable patients rely on empathic communication to support safety, adherence, and trust. We present RECAP (Reflect-Extract-Calibrate-Align-Produce), an inference-time framework that guides models through structured emotional reasoning without retraining. RECAP decomposes patient input into appraisal-theoretic stages, identifies psychological factors, and assigns Likert-based emotion likelihoods that clinicians can inspect or override, producing nuanced and auditable responses. Across EmoBench, SECEU, and EQ-Bench, RECAP improves emotional reasoning by 22-28% on 8B models and 10-13% on larger models over zero-shot baselines. In blinded evaluations, oncology clinicians rated RECAP's responses as more empathetic, supportive, and context-appropriate than prompting baselines. These findings demonstrate that modular, principled prompting can enhance emotional intelligence in medical AI while maintaining transparency and accountability for clinical deployment.",
    "authors": [
      "Adarsh Srinivasan",
      "Jacob Dineen",
      "Muhammad Umar Afzal",
      "Muhammad Uzair Sarfraz",
      "Irbaz B. Riaz",
      "Ben Zhou"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12178",
    "title": "All that structure matches does not glitter",
    "abstract": "Generative models for materials, especially inorganic crystals, hold potential to transform the theoretical prediction of novel compounds and structures. Advancement in this field depends on robust benchmarks and minimal, information-rich datasets that enable meaningful model evaluation. This paper critically examines common datasets and reported metrics for a crystal structure prediction task$\\unicode{x2014}$generating the most likely structures given the chemical composition of a material. We focus on three key issues: First, materials datasets should contain unique crystal structures; for example, we show that the widely-utilized carbon-24 dataset only contains $\\approx$40% unique structures. Second, materials datasets should not be split randomly if polymorphs of many different compositions are numerous, which we find to be the case for the perov-5 and MP-20 datasets. Third, benchmarks can mislead if used uncritically, e.g., reporting a match rate metric without considering the structural variety exhibited by identical building blocks. To address these oft-overlooked issues, we introduce several fixes. We provide revised versions of the carbon-24 dataset: one with duplicates removed, one deduplicated and split by number of atoms $N$, one with enantiomorphs, and two containing only identical structures but with different unit cells. We also propose new splits for datasets with polymorphs, ensuring that polymorphs are grouped within each split subset, setting a more sensible standard for benchmarking model performance. Finally, we present METRe and cRMSE, new model evaluation metrics that can correct existing issues with the match rate metric.",
    "authors": [
      "Maya M. Martirossyan",
      "Thomas Egg",
      "Philipp Hoellmer",
      "George Karypis",
      "Mark Transtrum",
      "Adrian Roitberg",
      "Mingjie Liu",
      "Richard G. Hennig",
      "Ellad B. Tadmor",
      "Stefano Martiniani"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12917",
    "title": "Reversible Deep Equilibrium Models",
    "abstract": "Deep Equilibrium Models (DEQs) are an interesting class of implicit model where the model output is implicitly defined as the fixed point of a learned function. These models have been shown to outperform explicit (fixed-depth) models in large-scale tasks by trading many deep layers for a single layer that is iterated many times. However, gradient calculation through DEQs is approximate. This often leads to unstable training dynamics and requires regularisation or many function evaluations to fix. Here, we introduce Reversible Deep Equilibrium Models (RevDEQs) that allow for exact gradient calculation, no regularisation and far fewer function evaluations than DEQs. We show that RevDEQs significantly improve performance on language modelling and image classification tasks against comparable implicit and explicit models.",
    "authors": [
      "Sam McCallum",
      "Kamran Arora",
      "James Foster"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.17701",
    "title": "Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs",
    "abstract": "Large Language Models (LLMs) are increasingly used for educational support, yet their response quality varies depending on the language of interaction. This paper presents an automated multilingual pipeline for generating, solving, and evaluating math problems aligned with the German K-10 curriculum. We generated 628 math exercises and translated them into English, German, and Arabic. Three commercial LLMs (GPT-4o-mini, Gemini 2.5 Flash, and Qwen-plus) were prompted to produce step-by-step solutions in each language. A held-out panel of LLM judges, including Claude 3.5 Haiku, evaluated solution quality using a comparative framework. Results show a consistent gap, with English solutions consistently rated highest, and Arabic often ranked lower. These findings highlight persistent linguistic bias and the need for more equitable multilingual AI systems in education.",
    "authors": [
      "Mariam Mahran",
      "Katharina Simbeck"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.19486",
    "title": "Supercomputing for High-speed Avoidance and Reactive Planning in Robots",
    "abstract": "This paper presents SHARP (Supercomputing for High-speed Avoidance and Reactive Planning), a proof-of-concept study demonstrating how high-performance computing (HPC) can enable millisecond-scale responsiveness in robotic control. While modern robots face increasing demands for reactivity in human--robot shared workspaces, onboard processors are constrained by size, power, and cost. Offloading to HPC offers massive parallelism for trajectory planning, but its feasibility for real-time robotics remains uncertain due to network latency and jitter. We evaluate SHARP in a stress-test scenario where a 7-DOF manipulator must dodge high-speed foam projectiles. Using a parallelized multi-goal A* search implemented with MPI on both local and remote HPC clusters, the system achieves mean planning latencies of 22.9 ms (local) and 30.0 ms (remote, ~300 km away), with avoidance success rates of 84% and 88%, respectively. These results show that when round-trip latency remains within the tens-of-milliseconds regime, HPC-side computation is no longer the bottleneck, enabling avoidance well below human reaction times. The SHARP results motivate hybrid control architectures: low-level reflexes remain onboard for safety, while bursty, high-throughput planning tasks are offloaded to HPC for scalability. By reporting per-stage timing and success rates, this study provides a reproducible template for assessing real-time feasibility of HPC-driven robotics. Collectively, SHARP reframes HPC offloading as a viable pathway toward dependable, reactive robots in dynamic environments.",
    "authors": [
      "Kieran S. Lachmansingh",
      "José R. González-Estrada",
      "Ryan E. Grant",
      "Matthew K. X. J. Pan"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.20412",
    "title": "Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics",
    "abstract": "Collective action problems, which require aligning individual incentives with collective goals, are classic examples of Ill-Structured Problems (ISPs). For an individual agent, the causal links between local actions and global outcomes are unclear, stakeholder objectives often conflict, and no single, clear algorithm can bridge micro-level choices with macro-level welfare. We present ECHO-MIMIC, a general computational framework that converts this global complexity into a tractable, Well-Structured Problem (WSP) for each agent by discovering executable heuristics and persuasive rationales. The framework operates in two stages: ECHO (Evolutionary Crafting of Heuristics from Outcomes) evolves snippets of Python code that encode candidate behavioral policies, while MIMIC (Mechanism Inference \\& Messaging for Individual-to-Collective Alignment) evolves companion natural language messages that motivate agents to adopt those policies. Both phases employ a large-language-model-driven evolutionary search: the LLM proposes diverse and context-aware code or text variants, while population-level selection retains those that maximize collective performance in a simulated environment. We demonstrate this framework on two distinct ISPs: a canonical agricultural landscape management problem and a carbon-aware EV charging time slot usage problem. Results show that ECHO-MIMIC discovers high-performing heuristics compared to baselines and crafts tailored messages that successfully align simulated agent behavior with system-level goals. By coupling algorithmic rule discovery with tailored communication, ECHO-MIMIC transforms the cognitive burden of collective action into a implementable set of agent-level instructions, making previously ill-structured problems solvable in practice and opening a new path toward scalable, adaptive policy design.",
    "authors": [
      "Kevin Bradley Dsouza",
      "Graham Alexander Watt",
      "Yuri Leonenko",
      "Juan Moreno-Cruz"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.20923",
    "title": "Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Training Framework",
    "abstract": "Computational pathology (CPath) digitizes pathology slides into whole slide images (WSIs), enabling analysis for critical healthcare tasks such as cancer diagnosis and prognosis. However, WSIs possess extremely long sequence lengths (up to 200K), significant length variations (from 200 to 200K), and limited supervision. These extreme variations in sequence length lead to high data heterogeneity and redundancy. Conventional methods often compromise on training efficiency and optimization to preserve such heterogeneity under limited supervision. To comprehensively address these challenges, we propose a pack-based MIL framework. It packs multiple sampled, variable-length feature sequences into fixed-length ones, enabling batched training while preserving data heterogeneity. Moreover, we introduce a residual branch that composes discarded features from multiple slides into a hyperslide which is trained with tailored labels. It offers multi-slide supervision while mitigating feature loss from sampling. Meanwhile, an attention-driven downsampler is introduced to compress features in both branches to reduce redundancy. By alleviating these challenges, our approach achieves an accuracy improvement of up to 8% while using only 12% of the training time in the PANDA(UNI). Extensive experiments demonstrate that focusing data challenges in CPath holds significant potential in the era of foundation models. The code is this https URL",
    "authors": [
      "Wenhao Tang",
      "Heng Fang",
      "Ge Wu",
      "Xiang Li",
      "Ming-Ming Cheng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.21384",
    "title": "Assessing the Alignment of Popular CNNs to the Brain for Valence Appraisal",
    "abstract": "Convolutional Neural Networks (CNNs) are a popular type of computer model that have proven their worth in many computer vision tasks. Moreover, they form an interesting study object for the field of psychology, with shown correspondences between the workings of CNNs and the human brain. However, these correspondences have so far mostly been studied in the context of general visual perception. In contrast, this paper explores to what extent this correspondence also holds for a more complex brain process, namely social cognition. To this end, we assess the alignment between popular CNN architectures and both human behavioral and fMRI data for image valence appraisal through a correlation analysis. We show that for this task CNNs struggle to go beyond simple visual processing, and do not seem to reflect higher-order brain processing. Furthermore, we present Object2Brain, a novel framework that combines GradCAM and object detection at the CNN-filter level with the aforementioned correlation analysis to study the influence of different object classes on the CNN-to-human correlations. Despite similar correlation trends, different CNN architectures are shown to display different object class sensitivities.",
    "authors": [
      "Laurent Mertens",
      "Elahe' Yargholi",
      "Laura Van Hove",
      "Hans Op de Beeck",
      "Jan Van den Stock",
      "Joost Vennekens"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.22855",
    "title": "Observation-Free Attacks on Online Learning to Rank",
    "abstract": "Online learning to rank (OLTR) plays a critical role in information retrieval and machine learning systems, with a wide range of applications in search engines and content recommenders. However, despite their extensive adoption, the susceptibility of OLTR algorithms to coordinated adversarial attacks remains poorly understood. In this work, we present a novel framework for attacking some of the widely used OLTR algorithms. Our framework is designed to promote a set of target items so that they appear in the list of top-K recommendations for T - o(T) rounds, while simultaneously inducing linear regret in the learning algorithm. We propose two novel attack strategies: CascadeOFA for CascadeUCB1 and PBMOFA for PBM-UCB . We provide theoretical guarantees showing that both strategies require only O(log T) manipulations to succeed. Additionally, we supplement our theoretical analysis with empirical results on real-world data.",
    "authors": [
      "Sameep Chattopadhyay",
      "Nikhil Karamchandani",
      "Sharayu Moharir"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.23143",
    "title": "MathBode: Measuring the Stability of LLM Reasoning using Frequency Response",
    "abstract": "This paper presents MathBode, a dynamic diagnostic for mathematical reasoning in large language models (LLMs). Instead of one-shot accuracy, MathBode treats each parametric problem as a system: we drive a single parameter sinusoidally and fit first-harmonic responses of model outputs and exact solutions. This yields interpretable, frequency-resolved metrics -- gain (amplitude tracking) and phase (lag) -- that form Bode-style fingerprints. Across five closed-form families (linear solve, ratio/saturation, compound interest, 2x2 linear systems, similar triangles), the diagnostic surfaces systematic low-pass behavior and growing phase lag that accuracy alone obscures. We compare several models against a symbolic baseline that calibrates the instrument ($G \\approx 1$, $\\phi \\approx 0$). Results separate frontier from mid-tier models on dynamics, providing a compact, reproducible protocol that complements standard benchmarks with actionable measurements of reasoning fidelity and consistency. We open-source the dataset and code to enable further research and adoption.",
    "authors": [
      "Charles L. Wang"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.23762",
    "title": "Accuracy-Robustness Trade Off via Spiking Neural Network Gradient Sparsity Trail",
    "abstract": "Spiking Neural Networks (SNNs) have attracted growing interest in both computational neuroscience and artificial intelligence, primarily due to their inherent energy efficiency and compact memory footprint. However, achieving adversarial robustness in SNNs, (particularly for vision-related tasks) remains a nascent and underexplored challenge. Recent studies have proposed leveraging sparse gradients as a form of regularization to enhance robustness against adversarial perturbations. In this work, we present a surprising finding: under specific architectural configurations, SNNs exhibit natural gradient sparsity and can achieve state-of-the-art adversarial defense performance without the need for any explicit regularization. Further analysis reveals a trade-off between robustness and generalization: while sparse gradients contribute to improved adversarial resilience, they can impair the model's ability to generalize; conversely, denser gradients support better generalization but increase vulnerability to attacks. Our findings offer new insights into the dual role of gradient sparsity in SNN training.",
    "authors": [
      "Luu Trong Nhan",
      "Luu Trung Duong",
      "Pham Ngoc Nam",
      "Truong Cong Thang"
    ],
    "primary_category": "cs.NE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.24091",
    "title": "PerfBench: Can Agents Resolve Real-World Performance Bugs?",
    "abstract": "Performance bugs are inefficiencies in software that waste computational resources without causing functional failures, making them particularly challenging to detect and fix. While recent advances in Software Engineering agents have shown promise in automated bug fixing, existing benchmarks primarily focus on functional correctness and fail to evaluate agents' abilities to identify and resolve non-functional issues like performance bugs. We introduce PerfBench, a benchmark comprising 81 real-world performance bug-fixing tasks from popular .NET repositories on GitHub. Unlike existing benchmarks that rely on pre-existing test suites, PerfBench features a novel evaluation harness that allows agents to generate their own performance benchmarks and validates fixes by comparing execution metrics collected for developer fix and agent fix. Each task in PerfBench is derived from actual developer fixes linked to performance-related issues, which are then verified by human experts, ensuring real-world relevance. Our evaluation reveals that current state-of-the-art coding agents struggle with performance optimization tasks, with baseline OpenHands agent achieving only a ~3% success rate on our benchmark. We develop OpenHands-Perf-Agent, which incorporates performance-aware tooling and instructions and achieves a ~20% success rate on the benchmark. We show that by ensuring the agent has proper instructions to benchmark its changes and tooling for benchmark output processing, we can improve the agent performance significantly, but room for improvement still remains. PerfBench provides a challenging test set for furthering the capabilities of agents in fixing performance issues.",
    "authors": [
      "Spandan Garg",
      "Roshanak Zilouchian Moghaddam",
      "Neel Sundaresan"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.24901",
    "title": "Unmute the Patch Tokens: Rethinking Probing in Multi-Label Audio Classification",
    "abstract": "Although probing frozen models has become a standard evaluation paradigm, self-supervised learning in audio defaults to fine-tuning when pursuing state-of-the-art on AudioSet. A key reason is that global pooling creates an information bottleneck causing linear probes to misrepresent the embedding quality: The $\\texttt{cls}$-token discards crucial token information about dispersed, localized events in audio. This weakness is rooted in the mismatch between the pretraining objective (globally) and the downstream task (localized). Across a comprehensive benchmark of 13 datasets and 6 spectrogram-based encoders, we investigate the global pooling bottleneck. We introduce binarized prototypical probes: a lightweight and simple pooling method that learns prototypes to perform class-wise information aggregation. Despite its simplicity, our method notably outperforms linear and attentive probing. Our work establishes probing as a competitive and efficient paradigm for evaluating audio SSL models, challenging the reliance on costly fine-tuning.",
    "authors": [
      "Lukas Rauch",
      "René Heinrich",
      "Houtan Ghaffari",
      "Lukas Miklautz",
      "Ilyass Moummad",
      "Bernhard Sick",
      "Christoph Scholz"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.24932",
    "title": "Graph Theory Meets Federated Learning over Satellite Constellations: Spanning Aggregations, Network Formation, and Performance Optimization",
    "abstract": "In this work, we introduce Fed-Span: \\textit{\\underline{fed}erated learning with \\underline{span}ning aggregation over low Earth orbit (LEO) satellite constellations}. Fed-Span aims to address critical challenges inherent to distributed learning in dynamic satellite networks, including intermittent satellite connectivity, heterogeneous computational capabilities of satellites, and time-varying satellites' datasets. At its core, Fed-Span leverages minimum spanning tree (MST) and minimum spanning forest (MSF) topologies to introduce spanning model aggregation and dispatching processes for distributed learning. To formalize Fed-Span, we offer a fresh perspective on MST/MSF topologies by formulating them through a set of continuous constraint representations (CCRs), thereby integrating these topologies into a distributed learning framework for satellite networks. Using these CCRs, we obtain the energy consumption and latency of operations in Fed-Span. Moreover, we derive novel convergence bounds for Fed-Span, accommodating its key system characteristics and degrees of freedom (i.e., tunable parameters). Finally, we propose a comprehensive optimization problem that jointly minimizes model prediction loss, energy consumption, and latency of {Fed-Span}. We unveil that this problem is NP-hard and develop a systematic approach to transform it into a geometric programming formulation, solved via successive convex optimization with performance guarantees. Through evaluations on real-world datasets, we demonstrate that Fed-Span outperforms existing methods, with faster model convergence, greater energy efficiency, and reduced latency.",
    "authors": [
      "Fardis Nadimi",
      "Payam Abdisarabshali",
      "Jacob Chakareski",
      "Nicholas Mastronarde",
      "Seyyedali Hosseinalipour"
    ],
    "primary_category": "cs.DC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.24980",
    "title": "SDPose: Exploiting Diffusion Priors for Out-of-Domain and Robust Pose Estimation",
    "abstract": "Pre-trained diffusion models provide rich multi-scale latent features and are emerging as powerful vision backbones. While recent works such as Marigold and Lotus adapt diffusion priors for dense prediction with strong cross-domain generalization, their potential for structured outputs remains underexplored. In this paper, we propose SDPose, a fine-tuning framework built upon Stable Diffusion to fully exploit pre-trained diffusion priors for human pose estimation. First, rather than modifying cross-attention modules or introducing learnable embeddings, we directly predict keypoint heatmaps in the SD U-Net's image latent space to preserve the original generative priors. Second, we map these latent features into keypoint heatmaps through a lightweight convolutional pose head, which avoids disrupting the pre-trained backbone. Finally, to prevent overfitting and enhance out-of-distribution robustness, we incorporate an auxiliary RGB reconstruction branch that preserves domain-transferable generative semantics. To evaluate robustness under domain shift, we further construct COCO-OOD, a style-transferred variant of COCO with preserved annotations. With just one-fifth of the training schedule used by Sapiens on COCO, SDPose attains parity with Sapiens-1B/2B on the COCO validation set and establishes a new state of the art on the cross-domain benchmarks HumanArt and COCO-OOD. Extensive ablations highlight the importance of diffusion priors, RGB reconstruction, and multi-scale SD U-Net features for cross-domain generalization, and t-SNE analyses further explain SD's domain-invariant latent structure. We also show that SDPose serves as an effective zero-shot pose annotator for controllable image and video generation.",
    "authors": [
      "Shuang Liang",
      "Jing He",
      "Chuanmeizhi Wang",
      "Lejun Liao",
      "Guo Zhang",
      "Yingcong Chen",
      "Yuan Yuan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25127",
    "title": "Score Distillation of Flow Matching Models",
    "abstract": "Diffusion models achieve high-quality image generation but are limited by slow iterative sampling. Distillation methods alleviate this by enabling one- or few-step generation. Flow matching, originally introduced as a distinct framework, has since been shown to be theoretically equivalent to diffusion under Gaussian assumptions, raising the question of whether distillation techniques such as score distillation transfer directly. We provide a simple derivation -- based on Bayes' rule and conditional expectations -- that unifies Gaussian diffusion and flow matching without relying on ODE/SDE formulations. Building on this view, we extend Score identity Distillation (SiD) to pretrained text-to-image flow-matching models, including SANA, SD3-Medium, SD3.5-Medium/Large, and FLUX.1-dev, all with DiT backbones. Experiments show that, with only modest flow-matching- and DiT-specific adjustments, SiD works out of the box across these models, in both data-free and data-aided settings, without requiring teacher finetuning or architectural changes. This provides the first systematic evidence that score distillation applies broadly to text-to-image flow matching models, resolving prior concerns about stability and soundness and unifying acceleration techniques across diffusion- and flow-based generators. A project page is available at this https URL .",
    "authors": [
      "Mingyuan Zhou",
      "Yi Gu",
      "Huangjie Zheng",
      "Liangchen Song",
      "Guande He",
      "Yizhe Zhang",
      "Wenze Hu",
      "Yinfei Yang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.02945",
    "title": "Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning",
    "abstract": "Continual reinforcement learning (continual RL) seeks to formalize the notions of lifelong learning and endless adaptation in RL. In particular, the aim of continual RL is to develop RL agents that can maintain a careful balance between retaining useful information and adapting to new situations. To date, continual RL has been explored almost exclusively through the lens of risk-neutral decision-making, in which the agent aims to optimize the expected long-run performance. In this work, we present the first formal theoretical treatment of continual RL through the lens of risk-aware decision-making, in which the behaviour of the agent is directed towards optimizing a measure of long-run performance beyond the mean. In particular, we show that the classical theory of risk measures, widely used as a theoretical foundation in non-continual risk-aware RL, is, in its current form, incompatible with continual learning. Then, building on this insight, we extend risk measure theory into the continual setting by introducing a new class of ergodic risk measures that are compatible with continual learning. Finally, we provide a case study of risk-aware continual learning, along with empirical results, which show the intuitive appeal of ergodic risk measures in continual settings.",
    "authors": [
      "Juan Sebastian Rojas",
      "Chi-Guhn Lee"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.03252",
    "title": "Universal Multi-Domain Translation via Diffusion Routers",
    "abstract": "Multi-domain translation (MDT) aims to learn translations between multiple domains, yet existing approaches either require fully aligned tuples or can only handle domain pairs seen in training, limiting their practicality and excluding many cross-domain mappings. We introduce universal MDT (UMDT), a generalization of MDT that seeks to translate between any pair of $K$ domains using only $K-1$ paired datasets with a central domain. To tackle this problem, we propose Diffusion Router (DR), a unified diffusion-based framework that models all central$\\leftrightarrow$non-central translations with a single noise predictor conditioned on the source and target domain labels. DR enables indirect non-central translations by routing through the central domain. We further introduce a novel scalable learning strategy with a variational-bound objective and an efficient Tweedie refinement procedure to support direct non-central mappings. Through evaluation on three large-scale UMDT benchmarks, DR achieves state-of-the-art results for both indirect and direct translations, while lowering sampling cost and unlocking novel tasks such as sketch$\\leftrightarrow$segmentation. These results establish DR as a scalable and versatile framework for universal translation across multiple domains.",
    "authors": [
      "Duc Kieu",
      "Kien Do",
      "Tuan Hoang",
      "Thao Minh Le",
      "Tung Kieu",
      "Dang Nguyen",
      "Thin Nguyen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.03747",
    "title": "LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes",
    "abstract": "Deepfakes pose significant societal risks, motivating the development of proactive defenses that embed adversarial perturbations in facial images to prevent manipulation. However, in this paper, we show that these preemptive defenses often lack robustness and reliability. We propose a novel approach, Low-Rank Adaptation (LoRA) patching, which injects a plug-and-play LoRA patch into Deepfake generators to bypass state-of-the-art defenses. A learnable gating mechanism adaptively controls the effect of the LoRA patch and prevents gradient explosions during fine-tuning. We also introduce a Multi-Modal Feature Alignment (MMFA) loss, encouraging the features of adversarial outputs to align with those of the desired outputs at the semantic level. Beyond bypassing, we present defensive LoRA patching, embedding visible warnings in the outputs as a complementary solution to mitigate this newly identified security vulnerability. With only 1,000 facial examples and a single epoch of fine-tuning, LoRA patching successfully defeats multiple proactive defenses. These results reveal a critical weakness in current paradigms and underscore the need for more robust Deepfake defense strategies. Our code is available at this https URL .",
    "authors": [
      "Zuomin Qu",
      "Yimao Guo",
      "Qianyue Hu",
      "Wei Lu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.03814",
    "title": "Detecting Invariant Manifolds in ReLU-Based RNNs",
    "abstract": "Recurrent Neural Networks (RNNs) have found widespread applications in machine learning for time series prediction and dynamical systems reconstruction, and experienced a recent renaissance with improved training algorithms and architectural designs. Understanding why and how trained RNNs produce their behavior is important for scientific and medical applications, and explainable AI more generally. An RNN's dynamical repertoire depends on the topological and geometrical properties of its state space. Stable and unstable manifolds of periodic points play a particularly important role: They dissect a dynamical system's state space into different basins of attraction, and their intersections lead to chaotic dynamics with fractal geometry. Here we introduce a novel algorithm for detecting these manifolds, with a focus on piecewise-linear RNNs (PLRNNs) employing rectified linear units (ReLUs) as their activation function. We demonstrate how the algorithm can be used to trace the boundaries between different basins of attraction, and hence to characterize multistability, a computationally important property. We further show its utility in finding so-called homoclinic points, the intersections between stable and unstable manifolds, and thus establish the existence of chaos in PLRNNs. Finally we show for an empirical example, electrophysiological recordings from a cortical neuron, how insights into the underlying dynamics could be gained through our method.",
    "authors": [
      "Lukas Eisenmann",
      "Alena Brändle",
      "Zahra Monfared",
      "Daniel Durstewitz"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05343",
    "title": "Robust Sensor Placement for Poisson Arrivals with False Alarm Aware Spatiotemporal Sensing",
    "abstract": "This paper studies sensor placement when detection performance varies stochastically due to environmental factors over space and time and false alarms are present, but a filter is used to attenuate the effect. We introduce a unified model that couples detection and false alarms through an availability function, which captures how false alarms reduce effective sensing and filtering responses to the disturbance. Building on this model, we give a sufficient condition under which filtering improves detection. In addition, we derive a coverage-based lower bound on the void probability. Furthermore, we prove robustness guarantees showing that performance remains stable when detection probabilities are learned from limited data. We validate the approach with numerical studies using AIS vessel-traffic data and synthetic maritime scenarios. Together, these results provide theory and practical guidance for deploying sensors in dynamic, uncertain environments.",
    "authors": [
      "Mingyu Kim",
      "Pronoy Sarker",
      "Seungmo Kim",
      "Daniel J. Stilwell",
      "Jorge Jimenez"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05620",
    "title": "Monte Carlo-Type Neural Operator for Differential Equations",
    "abstract": "The Monte Carlo-type Neural Operator (MCNO) introduces a framework for learning solution operators of one-dimensional partial differential equations (PDEs) by directly learning the kernel function and approximating the associated integral operator using a Monte Carlo-type approach. Unlike Fourier Neural Operators (FNOs), which rely on spectral representations and assume translation-invariant kernels, MCNO makes no such assumptions. The kernel is represented as a learnable tensor over sampled input-output pairs, and sampling is performed once, uniformly at random from a discretized grid. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training, while an interpolation step maps between arbitrary input and output grids to further enhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with efficient computational cost. We also provide a theoretical analysis proving that the Monte Carlo estimator yields a bounded bias and variance under mild regularity assumptions. This result holds in any spatial dimension, suggesting that MCNO may extend naturally beyond one-dimensional problems. More broadly, this work explores how Monte Carlo-type integration can be incorporated into neural operator frameworks for continuous-domain PDEs, providing a theoretically supported alternative to spectral methods (such as FNO) and to graph-based Monte Carlo approaches (such as the Graph Kernel Neural Operator, GNO).",
    "authors": [
      "Salah Eddine Choutri",
      "Prajwal Chauhan",
      "Othmane Mazhar",
      "Saif Eddin Jabari"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.08351",
    "title": "Fletch: File-System Metadata Caching in Programmable Switches",
    "abstract": "Fast and scalable metadata management across multiple metadata servers is crucial for distributed file systems to handle numerous files and directories. Client-side caching of frequently accessed metadata can mitigate server loads, but incurs significant overhead and complexity in maintaining cache consistency when the number of clients increases. We explore caching in programmable switches by serving file-system metadata requests from multiple clients on the switch data plane. Despite prior efforts on in-switch key-value caching, they fail to address the path dependencies specific to file-system semantics. We propose Fletch, an in-switch file-system metadata caching framework that leverages programmable switches to serve file-system metadata requests from multiple clients directly in the switch data plane. Unlike prior in-switch key-value caching approaches, Fletch addresses file-system-specific path dependencies under stringent switch resource constraints. We implement Fletch atop Hadoop HDFS and evaluate it on a Tofino-switch testbed using real-world file-system metadata workloads. Fletch achieves up to 181.6% higher throughput than vanilla HDFS and complements client-side caching with additional throughput gains of up to 139.6%. It also incurs low latencies and limited switch resource usage.",
    "authors": [
      "Qingxiu Liu",
      "Jiazhen Cai",
      "Siyuan Sheng",
      "Yuhui Chen",
      "Lu Tang",
      "Zhirong Shen",
      "Patrick P. C. Lee"
    ],
    "primary_category": "cs.AR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.13186",
    "title": "STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control",
    "abstract": "Edge Gaussian splatting (EGS), which aggregates data from distributed clients (e.g., drones) and trains a global GS model at the edge (e.g., ground server), is an emerging paradigm for scene reconstruction in low-altitude economy. Unlike traditional edge resource management methods that emphasize communication throughput or general-purpose learning performance, EGS explicitly aims to maximize the GS qualities, rendering existing approaches inapplicable. To address this problem, this paper formulates a novel GS-oriented objective function that distinguishes the heterogeneous view contributions of different clients. However, evaluating this function in turn requires clients' images, leading to a causality dilemma. To this end, this paper further proposes a sample-then-transmit EGS (or STT-GS for short) strategy, which first samples a subset of images as pilot data from each client for loss prediction. Based on the first-stage evaluation, communication resources are then prioritized towards more valuable clients. To achieve efficient sampling, a feature-domain clustering (FDC) scheme is proposed to select the most representative data and pilot transmission time minimization (PTTM) is adopted to reduce the pilot overhead. Subsequently, we develop a joint client selection and power control (JCSPC) framework to maximize the GS-oriented function under communication resource constraints. Despite the nonconvexity of the problem, we propose a low-complexity efficient solution based on the penalty alternating majorization minimization (PAMM) algorithm. Experiments reveal that the proposed scheme significantly outperforms existing benchmarks on real-world datasets. The GS-oriented objective can be accurately predicted with low sampling ratios (e.g., 10%), and our method achieves an excellent tradeoff between view contributions and communication costs.",
    "authors": [
      "Zhen Li",
      "Xibin Jin",
      "Guoliang Li",
      "Shuai Wang",
      "Miaowen Wen",
      "Huseyin Arslan",
      "Derrick Wing Kwan Ng",
      "Chengzhong Xu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.13747",
    "title": "InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue",
    "abstract": "We introduce InteractiveOmni, a unified and open-source omni-modal large language model for audio-visual multi-turn interaction, ranging from 4B to 8B parameters, designed to lead the field of lightweight models by offering comprehensive omni-modal understanding and speech generation capabilities. To achieve this, we integrate the vision encoder, audio encoder, large language model, and speech decoder into a unified model for understanding and generation tasks. We design a multi-stage training strategy to ensure robust cross-modal capabilities, including pre-training for omni-modal understanding, followed by post-training with speech conversation and audio-visual interaction. To enable human-like long-term conversational ability, we meticulously curate a multi-turn training dataset that enhances the model's ability to handle complex and multi-turn interactions. To effectively evaluate the multi-turn memory and speech interaction capabilities, we construct the multi-modal multi-turn memory benchmark and the multi-turn speech interaction benchmark. Experiments demonstrate that InteractiveOmni significantly outperforms leading open-source models and provides a more intelligent multi-turn audio-visual experience, particularly in its long-term memory capabilities. Notably, InteractiveOmni-4B is comparable to the much larger model like Qwen2.5-Omni-7B on general benchmarks, and it can retain 97% of the performance of the InteractiveOmni-8B while utilizing only 50% of the model size. Achieving state-of-the-art results against similarly sized models across image, audio, video understanding, and speech generation tasks, InteractiveOmni is an accessible, open-source foundation for next-generation intelligent interactive systems.",
    "authors": [
      "Wenwen Tong",
      "Hewei Guo",
      "Dongchuan Ran",
      "Jiangnan Chen",
      "Jiefan Lu",
      "Kaibin Wang",
      "Keqiang Li",
      "Xiaoxu Zhu",
      "Jiakui Li",
      "Kehan Li",
      "Xueheng Li",
      "Lumin Li",
      "Chenxu Guo",
      "Jiasheng Zhou",
      "Jiandong Chen",
      "Xianye Wu",
      "Jiahao Wang",
      "Silei Wu",
      "Lei Chen",
      "Hanming Deng",
      "Yuxuan Song",
      "Dinghao Zhou",
      "Guiping Zhong",
      "Ken Zheng",
      "Shiyin Kang",
      "Lewei Lu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.16088",
    "title": "Differentiable, Bit-shifting, and Scalable Quantization without training neural network from scratch",
    "abstract": "Quantization of neural networks provides benefits of inference in less compute and memory requirements. Previous work in quantization lack two important aspects which this work provides. First almost all previous work in quantization used a non-differentiable approach and for learning; the derivative is usually set manually in backpropogation which make the learning ability of algorithm questionable, our approach is not just differentiable, we also provide proof of convergence of our approach to the optimal neural network. Second previous work in shift/logrithmic quantization either have avoided activation quantization along with weight quantization or achieved less accuracy. Learning logrithmic quantize values of form $2^n$ requires the quantization function can scale to more than 1 bit quantization which is another benifit of our quantization that it provides $n$ bits quantization as well. Our approach when tested with image classification task using imagenet dataset, resnet18 and weight quantization only achieves less than 1 percent accuracy compared to full precision accuracy while taking only 15 epochs to train using shift bit quantization and achieves comparable to SOTA approaches accuracy in both weight and activation quantization using shift bit quantization in 15 training epochs with slightly higher(only higher cpu instructions) inference cost compared to 1 bit quantization(without logrithmic quantization) and not requiring any higher precision multiplication.",
    "authors": [
      "Zia Badar"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.18212",
    "title": "A Definition of AGI",
    "abstract": "The lack of a concrete definition for Artificial General Intelligence (AGI) obscures the gap between today's specialized AI and human-level cognition. This paper introduces a quantifiable framework to address this, defining AGI as matching the cognitive versatility and proficiency of a well-educated adult. To operationalize this, we ground our methodology in Cattell-Horn-Carroll theory, the most empirically validated model of human cognition. The framework dissects general intelligence into ten core cognitive domains-including reasoning, memory, and perception-and adapts established human psychometric batteries to evaluate AI systems. Application of this framework reveals a highly \"jagged\" cognitive profile in contemporary models. While proficient in knowledge-intensive domains, current AI systems have critical deficits in foundational cognitive machinery, particularly long-term memory storage. The resulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 57%) concretely quantify both rapid progress and the substantial gap remaining before AGI.",
    "authors": [
      "Dan Hendrycks",
      "Dawn Song",
      "Christian Szegedy",
      "Honglak Lee",
      "Yarin Gal",
      "Erik Brynjolfsson",
      "Sharon Li",
      "Andy Zou",
      "Lionel Levine",
      "Bo Han",
      "Jie Fu",
      "Ziwei Liu",
      "Jinwoo Shin",
      "Kimin Lee",
      "Mantas Mazeika",
      "Long Phan",
      "George Ingebretsen",
      "Adam Khoja",
      "Cihang Xie",
      "Olawale Salaudeen",
      "Matthias Hein",
      "Kevin Zhao",
      "Alexander Pan",
      "David Duvenaud",
      "Bo Li",
      "Steve Omohundro",
      "Gabriel Alfour",
      "Max Tegmark",
      "Kevin McGrew",
      "Gary Marcus",
      "Jaan Tallinn",
      "Eric Schmidt",
      "Yoshua Bengio"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.18214",
    "title": "VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety",
    "abstract": "Safety evaluation of multimodal foundation models often treats vision and language inputs separately, missing risks from joint interpretation where benign content becomes harmful in combination. Existing approaches also fail to distinguish clearly unsafe content from borderline cases, leading to problematic over-blocking or under-refusal of genuinely harmful content. We present Vision Language Safety Understanding (VLSU), a comprehensive framework to systematically evaluate multimodal safety through fine-grained severity classification and combinatorial analysis across 17 distinct safety patterns. Using a multi-stage pipeline with real-world images and human annotation, we construct a large-scale benchmark of 8,187 samples spanning 15 harm categories. Our evaluation of eleven state-of-the-art models reveals systematic joint understanding failures: while models achieve 90%-plus accuracy on clear unimodal safety signals, performance degrades substantially to 20-55% when joint image-text reasoning is required to determine the safety label. Most critically, 34% of errors in joint image-text safety classification occur despite correct classification of the individual modalities, further demonstrating absent compositional reasoning capabilities. Additionally, we find that models struggle to balance refusing unsafe content while still responding to borderline cases that deserve engagement. For example, we find that instruction framing can reduce the over-blocking rate on borderline content from 62.4% to 10.4% in Gemini-1.5, but only at the cost of under-refusing on unsafe content with refusal rate dropping from 90.8% to 53.9%. Overall, our framework exposes weaknesses in joint image-text understanding and alignment gaps in current models, and provides a critical test bed to enable the next milestones in research on robust vision-language safety.",
    "authors": [
      "Shruti Palaskar",
      "Leon Gatys",
      "Mona Abdelrahman",
      "Mar Jacobo",
      "Larry Lindsey",
      "Rutika Moharir",
      "Gunnar Lund",
      "Yang Xu",
      "Navid Shiee",
      "Jeffrey Bigham",
      "Charles Maalouf",
      "Joseph Yitan Cheng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.18874",
    "title": "Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting",
    "abstract": "Adapting language models (LMs) to new tasks via post-training carries the risk of degrading existing capabilities -- a phenomenon classically known as catastrophic forgetting. In this paper, toward identifying guidelines for mitigating this phenomenon, we systematically compare the forgetting patterns of two widely adopted post-training methods: supervised fine-tuning (SFT) and reinforcement learning (RL). Our experiments reveal a consistent trend across LM families (Llama, Qwen) and tasks (instruction following, general knowledge, and arithmetic reasoning): RL leads to less forgetting than SFT while achieving comparable or higher target task performance. To investigate the cause for this difference, we consider a simplified setting in which the LM is modeled as a mixture of two distributions, one corresponding to prior knowledge and the other to the target task. We identify that the mode-seeking nature of RL, which stems from its use of on-policy data, enables keeping prior knowledge intact when learning the target task. We then verify this insight by demonstrating that the use on-policy data underlies the robustness of RL to forgetting in practical settings, as opposed to other algorithmic choices such as the KL regularization or advantage estimation. Lastly, as a practical implication, our results highlight the potential of mitigating forgetting using approximately on-policy data, which can be substantially more efficient to obtain than fully on-policy data.",
    "authors": [
      "Howard Chen",
      "Noam Razin",
      "Karthik Narasimhan",
      "Danqi Chen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.19292",
    "title": "Vision-Based Mistake Analysis in Procedural Activities: A Review of Advances and Challenges",
    "abstract": "Mistake analysis in procedural activities is a critical area of research with applications spanning industrial automation, physical rehabilitation, education and human-robot collaboration. This paper reviews vision-based methods for detecting and predicting mistakes in structured tasks, focusing on procedural and executional errors. By leveraging advancements in computer vision, including action recognition, anticipation and activity understanding, vision-based systems can identify deviations in task execution, such as incorrect sequencing, use of improper techniques, or timing errors. We explore the challenges posed by intra-class variability, viewpoint differences and compositional activity structures, which complicate mistake detection. Additionally, we provide a comprehensive overview of existing datasets, evaluation metrics and state-of-the-art methods, categorizing approaches based on their use of procedural structure, supervision levels and learning strategies. Open challenges, such as distinguishing permissible variations from true mistakes and modeling error propagation are discussed alongside future directions, including neuro-symbolic reasoning and counterfactual state modeling. This work aims to establish a unified perspective on vision-based mistake analysis in procedural activities, highlighting its potential to enhance safety, efficiency and task performance across diverse domains.",
    "authors": [
      "Konstantinos Bacharidis",
      "Antonis A. Argyros"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.20288",
    "title": "Smoothed Analysis of Online Metric Matching with a Single Sample: Beyond Metric Distortion",
    "abstract": "In the online metric matching problem, $n$ servers and $n$ requests lie in a metric space. Servers are available upfront, and requests arrive sequentially. An arriving request must be matched immediately and irrevocably to an available server, incurring a cost equal to their distance. The goal is to minimize the total matching cost. We study this problem in the Euclidean metric $[0, 1]^d$, when servers are adversarial and requests are independently drawn from distinct distributions that satisfy a mild smoothness condition. Our main result is an $O(1)$-competitive algorithm for $d \\neq 2$ that requires no distributional knowledge, relying only on a single sample from each request distribution. To our knowledge, this is the first algorithm to achieve an $o(\\log n)$ competitive ratio for non-trivial metrics beyond the i.i.d. setting. Our approach bypasses the $\\Omega(\\log n)$ barrier introduced by probabilistic metric embeddings: instead of analyzing the embedding distortion and the algorithm separately, we directly bound the cost of the algorithm on the target metric of a simple deterministic embedding. We then combine this analysis with lower bounds on the offline optimum for Euclidean metrics, derived via majorization arguments, to obtain our guarantees.",
    "authors": [
      "Yingxi Li",
      "Ellen Vitercik",
      "Mingwei Yang"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.20723",
    "title": "Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel",
    "abstract": "We study the growth of the support size of the capacity-achieving input distribution for the amplitude-constrained additive white Gaussian noise (AWGN) channel. While it is known since Smith (1971) that the optimal input is discrete with finitely many mass points, tight bounds on the number of support points $K_A$ as the amplitude constraint $A$ increases remain open. Not much is known until recently, when Dytso et al. (2019) proved that $K_A$ grows at least linearly and at most quadratically in $A$. Here, we provide a novel method, building on Ma et al. (2024); Zhang (1994), to derive the first non-trivial lower bound showing that KA grows super-linearly in A.",
    "authors": [
      "Haiyang Wang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.21951",
    "title": "Pricing Problems in Adoption of New Technologies",
    "abstract": "We propose a generalization of the Bass diffusion model in discrete-time that explicitly models the effect of price in adoption. Our model is different from earlier price-incorporated models and fits well to adoption data for various products. We then utilize this model to study two decision-making problems. First, we provide a series of structural results on optimal pricing strategies to maximize profits from product sales by a monopolist over a finite horizon. We fully characterize the optimal pricing strategy in the single-period problem, and establish several structural properties of the same for the multi-period counterpart. Second, we study a Stackelberg game between a policy-maker and a monopolist, where the former seeks to maximize adoption through rebates, while the latter focuses on profits. For this problem, we analytically characterize crucial properties of the equilibrium path of the single-period game, and demonstrate how they carry over to the multi-period variant.",
    "authors": [
      "Yijin Wang",
      "Subhonmesh Bose"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22501",
    "title": "A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior",
    "abstract": "In this paper, we introduce the SDIR (Susceptible-Delayable-Infected-Recovered) model, an extension of the classical SIR epidemic framework, to provide a more explicit characterization of user behavior in online social networks. The newly merged state D (delayable) represents users who have received the information but delayed its spreading and may eventually choose not to share it at all. Based on the mean-field approximation method, we derive the dynamical equations of the model and investigate its convergence and stability conditions. Under these conditions, we further propose an approximation algorithm for the edge-deletion problem, aiming to minimize the influence of information diffusion by identifying approximate solutions.",
    "authors": [
      "Tran Van Khanh",
      "Do Xuan Cho",
      "Hoang Phi Dung"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.25664",
    "title": "$\\{s,t\\}$-Separating Principal Partition Sequence of Submodular Functions",
    "abstract": "Narayanan showed the existence of the principal partition sequence of a submodular function, a structure with numerous applications in areas such as clustering, fast algorithms, and approximation algorithms. In this work, motivated by two applications, we develop a theory of $\\{s,t\\}$-separating principal partition sequence of a submodular function. We define this sequence, show its existence, and design a polynomial-time algorithm to construct it. We show two applications: (1) approximation algorithm for the $\\{s,t\\}$-separating submodular $k$-partitioning problem for monotone and posimodular functions and (2) polynomial-time algorithm for the hypergraph orientation problem of finding an orientation that simultaneously has strong connectivity at least $k$ and $(s,t)$-connectivity at least $\\ell$.",
    "authors": [
      "Kristóf Bérczi",
      "Karthekeyan Chandrasekaran",
      "Tamás Király",
      "Daniel P. Szabo"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.26641",
    "title": "All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles",
    "abstract": "Autonomous Vehicles (AVs) are transforming the future of transportation through advances in intelligent perception, decision-making, and control systems. However, their success is tied to one core capability, reliable object detection in complex and multimodal environments. While recent breakthroughs in Computer Vision (CV) and Artificial Intelligence (AI) have driven remarkable progress, the field still faces a critical challenge as knowledge remains fragmented across multimodal perception, contextual reasoning, and cooperative intelligence. This survey bridges that gap by delivering a forward-looking analysis of object detection in AVs, emphasizing emerging paradigms such as Vision-Language Models (VLMs), Large Language Models (LLMs), and Generative AI rather than re-examining outdated techniques. We begin by systematically reviewing the fundamental spectrum of AV sensors (camera, ultrasonic, LiDAR, and Radar) and their fusion strategies, highlighting not only their capabilities and limitations in dynamic driving environments but also their potential to integrate with recent advances in LLM/VLM-driven perception frameworks. Next, we introduce a structured categorization of AV datasets that moves beyond simple collections, positioning ego-vehicle, infrastructure-based, and cooperative datasets (e.g., V2V, V2I, V2X, I2I), followed by a cross-analysis of data structures and characteristics. Ultimately, we analyze cutting-edge detection methodologies, ranging from 2D and 3D pipelines to hybrid sensor fusion, with particular attention to emerging transformer-driven approaches powered by Vision Transformers (ViTs), Large and Small Language Models (SLMs), and VLMs. By synthesizing these perspectives, our survey delivers a clear roadmap of current capabilities, open challenges, and future opportunities.",
    "authors": [
      "Sayed Pedram Haeri Boroujeni",
      "Niloufar Mehrabi",
      "Hazim Alzorgan",
      "Mahlagha Fazeli",
      "Abolfazl Razi"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.00293",
    "title": "MagicView: Multi-View Consistent Identity Customization via Priors-Guided In-Context Learning",
    "abstract": "Recent advances in personalized generative models have demonstrated impressive capabilities in producing identity-consistent images of the same individual across diverse scenes. However, most existing methods lack explicit viewpoint control and fail to ensure multi-view consistency of generated identities. To address this limitation, we present MagicView, a lightweight adaptation framework that equips existing generative models with multi-view generation capability through 3D priors-guided in-context learning. While prior studies have shown that in-context learning preserves identity consistency across grid samples, its effectiveness in multi-view settings remains unexplored. Building upon this insight, we conduct an in-depth analysis of the multi-view in-context learning ability, and design a conditioning architecture that leverages 3D priors to activate this capability for multi-view consistent identity customization. On the other hand, acquiring robust multi-view capability typically requires large-scale multi-dimensional datasets, which makes incorporating multi-view contextual learning under limited data regimes prone to textual controllability degradation. To address this issue, we introduce a novel Semantic Correspondence Alignment loss, which effectively preserves semantic alignment while maintaining multi-view consistency. Extensive experiments demonstrate that MagicView substantially outperforms recent baselines in multi-view consistency, text alignment, identity similarity, and visual quality, achieving strong results with only 100 multi-view training samples.",
    "authors": [
      "Hengjia Li",
      "Jianjin Xu",
      "Keli Cheng",
      "Lei Wang",
      "Ning Bi",
      "Boxi Wu",
      "Fernando De la Torre",
      "Deng Cai"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.00926",
    "title": "LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory",
    "abstract": "As Large Language Models (LLMs) grow in capability, do they develop self-awareness as an emergent behavior? And if so, can we measure it? We introduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for measuring self-awareness through strategic differentiation. Using the \"Guess 2/3 of Average\" game, we test 28 models (OpenAI, Anthropic, Google) across 4,200 trials with three opponent framings: (A) against humans, (B) against other AI models, and (C) against AI models like you. We operationalize self-awareness as the capacity to differentiate strategic reasoning based on opponent type. Finding 1: Self-awareness emerges with model advancement. The majority of advanced models (21/28, 75%) demonstrate clear self-awareness, while older/smaller models show no differentiation. Finding 2: Self-aware models rank themselves as most rational. Among the 21 models with self-awareness, a consistent rationality hierarchy emerges: Self > Other AIs > Humans, with large AI attribution effects and moderate self-preferencing. These findings reveal that self-awareness is an emergent capability of advanced LLMs, and that self-aware models systematically perceive themselves as more rational than humans. This has implications for AI alignment, human-AI collaboration, and understanding AI beliefs about human capabilities.",
    "authors": [
      "Kyung-Hoon Kim"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04108",
    "title": "Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models",
    "abstract": "Recent work has explored batch prompting as a strategy to amortize inference cost in large language models (LLMs). In this paper, we show that batching offers an additional, underappreciated benefit: it regularizes model behavior during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a comprehensive study across 13 diverse benchmarks and observe that batching improves accuracy while substantially reducing reasoning token usage, often by 3x-5x. Through detailed behavioral analysis, we find that batching suppresses overthinking, reduces hedging language (e.g., repetitive self-corrections), and encourages more decisive answers. Surprisingly, we also observe emergent collective effects in batched inference: models often generalize patterns from earlier examples to solve harder ones in the same batch. These findings position batching not just as a throughput optimization, but as a powerful inference-time regularizer for more efficient and reliable LLM reasoning.",
    "authors": [
      "Wenmo Qiu",
      "Saurabh Srivastava"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04847",
    "title": "Grounded Test-Time Adaptation for LLM Agents",
    "abstract": "Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions. This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time. To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment. First, an online distributional adaptation method parameterizes environmental nuances by learning a lightweight adaptation vector that biases the model's output distribution, enabling rapid alignment with an environment response format. Second, a deployment-time dynamics grounding method employs a persona-driven exploration phase to systematically probe and learn the environment's causal dynamics before task execution, equipping the agent with a nonparametric world model. We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation. Our empirical results show the effectiveness of both strategies across all benchmarks with minimal computational cost. We find that dynamics grounding is particularly effective in complex environments where unpredictable dynamics pose a major obstacle, demonstrating a robust path toward more generalizable and capable LLM-based agents. For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.",
    "authors": [
      "Arthur Chen",
      "Zuxin Liu",
      "Jianguo Zhang",
      "Akshara Prabhakar",
      "Zhiwei Liu",
      "Shelby Heinecke",
      "Silvio Savarese",
      "Victor Zhong",
      "Caiming Xiong"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.04867",
    "title": "Optimal Selection Using Algorithmic Rankings with Side Information",
    "abstract": "Motivated by online platforms such as job markets, we study an agent choosing from a list of candidates, each with a hidden quality that determines match value. The agent observes only a noisy ranking of the candidates plus a binary signal that indicates whether each candidate is \"free\" or \"busy.\" Being busy is positively correlated with higher quality, but can also reduce value due to decreased availability. We study the agent's optimal selection problem in the presence of ranking noise and free-busy signals and ask how the accuracy of the ranking tool impacts outcomes. In a setting with one high-valued candidate and an arbitrary number of low-valued candidates, we show that increased accuracy of the ranking tool can result in reduced social welfare. This can occur for two reasons: agents may be more likely to make offers to busy candidates, and (paradoxically) may be more likely to select lower-ranked candidates when rankings are more indicative of quality. We further discuss conditions under which these results extend to more general settings.",
    "authors": [
      "Kate Donahue",
      "Nicole Immorlica",
      "Brendan Lucier"
    ],
    "primary_category": "cs.GT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.07498",
    "title": "Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models",
    "abstract": "Large language models (LLMs) increasingly support multilingual understanding and generation. Meanwhile, efforts to interpret their internal mechanisms have emerged, offering insights to enhance multilingual performance. While multi-head self-attention (MHA) has proven critical in many areas, its role in multilingual capabilities remains underexplored. In this work, we study the contribution of MHA in supporting multilingual processing in LLMs. We propose Language Attention Head Importance Scores (LAHIS), an effective and efficient method that identifies attention head importance for multilingual capabilities via a single forward and backward pass through the LLM. Applying LAHIS to Aya-23-8B, Llama-3.2-3B, and Mistral-7B-v0.1, we reveal the existence of both language-specific and language-general heads. Language-specific heads enable cross-lingual attention transfer to guide the model toward target language contexts and mitigate off-target language generation issue, contributing to addressing challenges in multilingual LLMs. We also introduce a lightweight adaptation that learns a soft head mask to modulate attention outputs over language heads, requiring only 20 tunable parameters to improve XQuAD accuracy. Overall, our work enhances both the interpretability and multilingual capabilities of LLMs from the perspective of MHA.",
    "authors": [
      "Xin Liu",
      "Qiyang Song",
      "Qihang Zhou",
      "Haichao Du",
      "Shaowen Xu",
      "Wenbo Jiang",
      "Weijuan Zhang",
      "Xiaoqi Jia"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.07850",
    "title": "GAMA: A Neural Neighborhood Search Method with Graph-aware Multi-modal Attention for Vehicle Routing Problem",
    "abstract": "Recent advances in neural neighborhood search methods have shown potential in tackling Vehicle Routing Problems (VRPs). However, most existing approaches rely on simplistic state representations and fuse heterogeneous information via naive concatenation, limiting their ability to capture rich structural and semantic context. To address these limitations, we propose GAMA, a neural neighborhood search method with Graph-aware Multi-modal Attention model in VRP. GAMA encodes the problem instance and its evolving solution as distinct modalities using graph neural networks, and models their intra- and inter-modal interactions through stacked self- and cross-attention layers. A gated fusion mechanism further integrates the multi-modal representations into a structured state, enabling the policy to make informed and generalizable operator selection decisions. Extensive experiments conducted across various synthetic and benchmark instances demonstrate that the proposed algorithm GAMA significantly outperforms the recent neural baselines. Further ablation studies confirm that both the multi-modal attention mechanism and the gated fusion design play a key role in achieving the observed performance gains.",
    "authors": [
      "Xiangling Chen",
      "Yi Mei",
      "Mengjie Zhang"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.08878",
    "title": "Covariance Scattering Transforms",
    "abstract": "Machine learning and data processing techniques relying on covariance information are widespread as they identify meaningful patterns in unsupervised and unlabeled settings. As a prominent example, Principal Component Analysis (PCA) projects data points onto the eigenvectors of their covariance matrix, capturing the directions of maximum variance. This mapping, however, falls short in two directions: it fails to capture information in low-variance directions, relevant when, e.g., the data contains high-variance noise; and it provides unstable results in low-sample regimes, especially when covariance eigenvalues are close. CoVariance Neural Networks (VNNs), i.e., graph neural networks using the covariance matrix as a graph, show improved stability to estimation errors and learn more expressive functions in the covariance spectrum than PCA, but require training and operate in a labeled setup. To get the benefits of both worlds, we propose Covariance Scattering Transforms (CSTs), deep untrained networks that sequentially apply filters localized in the covariance spectrum to the input data and produce expressive hierarchical representations via nonlinearities. We define the filters as covariance wavelets that capture specific and detailed covariance spectral patterns. We improve CSTs' computational and memory efficiency via a pruning mechanism, and we prove that their error due to finite-sample covariance estimations is less sensitive to close covariance eigenvalues compared to PCA, improving their stability. Our experiments on age prediction from cortical thickness measurements on 4 datasets collecting patients with neurodegenerative diseases show that CSTs produce stable representations in low-data settings, as VNNs but without any training, and lead to comparable or better predictions w.r.t. more complex learning models.",
    "authors": [
      "Andrea Cavallo",
      "Ayushman Raghuvanshi",
      "Sundeep Prabhakar Chepuri",
      "Elvin Isufi"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.10855",
    "title": "ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries",
    "abstract": "Despite recent advances in LLMs, the task of code generation is still challenging. To cope, code selection algorithms select the best program from multiple programs generated by an LLM. However, existing algorithms can fail to identify the correct program, either because they can misidentify nonequivalent programs or because they rely on an LLM and assume it always correctly determines the output for every input. We present ExPairT-LLM, an exact learning algorithm for code selection that selects a program by posing to an LLM oracle two new types of queries: pairwise membership and pairwise equivalence. These queries are simpler for LLMs and enable ExPairT-LLM to identify the correct program through a tournament, which is robust to some LLM mistakes. We evaluate ExPairT-LLM on four popular code datasets. Its pass@1 (success rate) outperforms the state-of-the-art code selection algorithm on average by +13.0% and up to +27.1%. It also improves the pass@1 of LLMs performing complex reasoning by +24.0%.",
    "authors": [
      "Tom Yuviler",
      "Dana Drachsler-Cohen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.12254",
    "title": "Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation",
    "abstract": "Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.",
    "authors": [
      "Yuxiang Zhou",
      "Jichang Li",
      "Yanhao Zhang",
      "Haonan Lu",
      "Guanbin Li"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.12528",
    "title": "D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation",
    "abstract": "Visual Place Recognition (VPR) aims to determine the geographic location of a query image by retrieving its most visually similar counterpart from a geo-tagged reference database. Recently, the emergence of the powerful visual foundation model, DINOv2, trained in a self-supervised manner on massive datasets, has significantly improved VPR performance. This improvement stems from DINOv2's exceptional feature generalization capabilities but is often accompanied by increased model complexity and computational overhead that impede deployment on resource-constrained devices. To address this challenge, we propose $D^{2}$-VPR, a $D$istillation- and $D$eformable-based framework that retains the strong feature extraction capabilities of visual foundation models while significantly reducing model parameters and achieving a more favorable performance-efficiency trade-off. Specifically, first, we employ a two-stage training strategy that integrates knowledge distillation and fine-tuning. Additionally, we introduce a Distillation Recovery Module (DRM) to better align the feature spaces between the teacher and student models, thereby minimizing knowledge transfer losses to the greatest extent possible. Second, we design a Top-Down-attention-based Deformable Aggregator (TDDA) that leverages global semantic features to dynamically and adaptively adjust the Regions of Interest (ROI) used for aggregation, thereby improving adaptability to irregular structures. Extensive experiments demonstrate that our method achieves competitive performance compared to state-of-the-art approaches. Meanwhile, it reduces the parameter count by approximately 64.2% and FLOPs by about 62.6% (compared to CricaVPR).Code is available at this https URL .",
    "authors": [
      "Zheyuan Zhang",
      "Jiwei Zhang",
      "Boyu Zhou",
      "Linzhimeng Duan",
      "Hong Chen"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.13239",
    "title": "Talyxion: From Speculation to Optimization in Risk Managed Crypto Portfolio Allocation",
    "abstract": "Cryptocurrency trading has attracted tremendous attention from both retail and institutional investors. However, most traders fail to scale their assets under management due to fragile strategies that collapse during adverse markets. The primary causes are oversized leverage, speculative position sizing, and the absence of robust risk management or hedging mechanisms. This paper introduces Talyxion, an end to end framework for crypto portfolio allocation that shifts the paradigm from speculation to optimization. The proposed pipeline consists of four stages: universe selection, alpha backtesting, volatility aware portfolio optimization, and dynamic drawdown based risk management. By combining operations research techniques with practical risk controls, Talyxion enables scalable crypto portfolios that can withstand market downturns. In live 30 day trading on Binance Futures, the framework achieved a return on investment (ROI) of +16.68%, with the Sharpe ratio reaching 5.72 and the maximum drawdown contained at just 4.56%, demonstrating strong downside risk control. The system executed 227 trades, of which 131 were profitable, resulting in a win rate of 57.71% and a PnL of +1,137.49 USDT. Importantly, these results outperformed the buy and hold baseline (Sharpe 1.79, ROI 4.36%, MDD 4.96%) as well as several top leader copy trading bots on Binance, highlighting both the competitiveness and scalability of Talyxion in real world trading environments.",
    "authors": [
      "Thanh Nguyen"
    ],
    "primary_category": "cs.OS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.15244",
    "title": "Context Cascade Compression: Exploring the Upper Limits of Text Compression",
    "abstract": "Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at this https URL",
    "authors": [
      "Fanfan Liu",
      "Haibo Qiu"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.16334",
    "title": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe",
    "abstract": "Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at this https URL .",
    "authors": [
      "Kaichen Zhang",
      "Keming Wu",
      "Zuhao Yang",
      "Kairui Hu",
      "Bin Wang",
      "Ziwei Liu",
      "Xingxuan Li",
      "Lidong Bing"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.16345",
    "title": "NLP Datasets for Idiom and Figurative Language Tasks",
    "abstract": "Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.",
    "authors": [
      "Blake Matheny",
      "Phuong Minh Nguyen",
      "Minh Le Nguyen",
      "Stephanie Reynolds"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.16717",
    "title": "A Machine Learning-Driven Solution for Denoising Inertial Confinement Fusion Images",
    "abstract": "Neutron imaging is essential for diagnosing and optimizing inertial confinement fusion implosions at the National Ignition Facility. Due to the required 10-micrometer resolution, however, neutron image require image reconstruction using iterative algorithms. For low-yield sources, the images may be degraded by various types of noise. Gaussian and Poisson noise often coexist within one image, obscuring fine details and blurring the edges where the source information is encoded. Traditional denoising techniques, such as filtering and thresholding, can inadvertently alter critical features or reshape the noise statistics, potentially impacting the ultimate fidelity of the iterative image reconstruction pipeline. However, recent advances in synthetic data production and machine learning have opened new opportunities to address these challenges. In this study, we present an unsupervised autoencoder with a Cohen-Daubechies- Feauveau (CDF 97) wavelet transform in the latent space, designed to suppress for mixed Gaussian-Poisson noise while preserving essential image features. The network successfully denoises neutron imaging data. Benchmarking against both simulated and experimental NIF datasets demonstrates that our approach achieves lower reconstruction error and superior edge preservation compared to conventional filtering methods such as Block-matching and 3D filtering (BM3D). By validating the effectiveness of unsupervised learning for denoising neutron images, this study establishes a critical first step towards fully AI-driven, end-to-end reconstruction frameworks for ICF diagnostics.",
    "authors": [
      "Asya Y. Akkus",
      "Bradley T. Wolfe",
      "Pinghan Chu",
      "Chengkun Huang",
      "Chris S. Campbell",
      "Mariana Alvarado Alvarez",
      "Petr Volegov",
      "David Fittinghoff",
      "Robert Reinovsky",
      "Zhehui Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.18303",
    "title": "Hierarchical Deep Research with Local-Web RAG: Toward Automated System-Level Materials Discovery",
    "abstract": "We present a long-horizon, hierarchical deep research (DR) agent designed for complex materials and device discovery problems that exceed the scope of existing Machine Learning (ML) surrogates and closed-source commercial agents. Our framework instantiates a locally deployable DR instance that integrates local retrieval-augmented generation with large language model reasoners, enhanced by a Deep Tree of Research (DToR) mechanism that adaptively expands and prunes research branches to maximize coverage, depth, and coherence. We systematically evaluate across 27 nanomaterials/device topics using a large language model (LLM)-as-judge rubric with five web-enabled state-of-the-art models as jurors. In addition, we conduct dry-lab validations on five representative tasks, where human experts use domain simulations (e.g., density functional theory, DFT) to verify whether DR-agent proposals are actionable. Results show that our DR agent produces reports with quality comparable to--and often exceeding--those of commercial systems (ChatGPT-5-thinking/o3/o4-mini-high Deep Research) at a substantially lower cost, while enabling on-prem integration with local data and tools.",
    "authors": [
      "Rui Ding",
      "Rodrigo Pires Ferreira",
      "Yuxin Chen",
      "Junhong Chen"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.18538",
    "title": "From Code Foundation Models to Agents and Applications: A Comprehensive Survey and Practical Guide to Code Intelligence",
    "abstract": "Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.",
    "authors": [
      "Jian Yang",
      "Xianglong Liu",
      "Weifeng Lv",
      "Ken Deng",
      "Shawn Guo",
      "Lin Jing",
      "Yizhi Li",
      "Shark Liu",
      "Xianzhen Luo",
      "Yuyu Luo",
      "Changzai Pan",
      "Ensheng Shi",
      "Yingshui Tan",
      "Renshuai Tao",
      "Jiajun Wu",
      "Xianjie Wu",
      "Zhenhe Wu",
      "Daoguang Zan",
      "Chenchen Zhang",
      "Wei Zhang",
      "He Zhu",
      "Terry Yue Zhuo",
      "Kerui Cao",
      "Xianfu Cheng",
      "Jun Dong",
      "Shengjie Fang",
      "Zhiwei Fei",
      "Xiangyuan Guan",
      "Qipeng Guo",
      "Zhiguang Han",
      "Joseph James",
      "Tianqi Luo",
      "Renyuan Li",
      "Yuhang Li",
      "Yiming Liang",
      "Congnan Liu",
      "Jiaheng Liu",
      "Qian Liu",
      "Ruitong Liu",
      "Tyler Loakman",
      "Xiangxin Meng",
      "Chuang Peng",
      "Tianhao Peng",
      "Jiajun Shi",
      "Mingjie Tang",
      "Boyang Wang",
      "Haowen Wang",
      "Yunli Wang",
      "Fanglin Xu",
      "Zihan Xu",
      "Fei Yuan",
      "Ge Zhang",
      "Jiayi Zhang",
      "Xinhao Zhang",
      "Wangchunshu Zhou",
      "Hualei Zhu",
      "King Zhu",
      "Bryan Dai",
      "Aishan Liu",
      "Zhoujun Li",
      "Chenghua Lin",
      "Tianyu Liu",
      "Chao Peng",
      "Kai Shen",
      "Libo Qin",
      "Shuangyong Song",
      "Zizheng Zhan",
      "Jiajun Zhang",
      "Jie Zhang",
      "Zhaoxiang Zhang",
      "Bo Zheng"
    ],
    "primary_category": "cs.SE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.18751",
    "title": "Robust Multimodal Sentiment Analysis of Image-Text Pairs by Distribution-Based Feature Recovery and Fusion",
    "abstract": "As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.",
    "authors": [
      "Daiqing Wu",
      "Dongbao Yang",
      "Yu Zhou",
      "Can Ma"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.19304",
    "title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning",
    "abstract": "Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at this https URL .",
    "authors": [
      "Jiayi Zhang",
      "Yiran Peng",
      "Fanqi Kong",
      "Cheng Yang",
      "Yifan Wu",
      "Zhaoyang Yu",
      "Jinyu Xiang",
      "Jianhao Ruan",
      "Jinlin Wang",
      "Maojia Song",
      "HongZhang Liu",
      "Xiangru Tang",
      "Bang Liu",
      "Chenglin Wu",
      "Yuyu Luo"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.19473",
    "title": "WavefrontDiffusion: Dynamic Decoding Schedule for Improved Reasoning",
    "abstract": "Diffusion Language Models (DLMs) have shown strong potential for text generation and are becoming a competitive alternative to autoregressive models. The denoising strategy plays an important role in determining the quality of their outputs. Mainstream denoising strategies include Standard Diffusion and BlockDiffusion. Standard Diffusion performs global denoising without restricting the update range, often finalizing incomplete context and causing premature end-of-sequence predictions. BlockDiffusion updates fixed-size blocks in a preset order, but its rigid structure can break apart coherent semantic units and disrupt reasoning. We present WavefrontDiffusion, a dynamic decoding approach that expands a wavefront of active tokens outward from finalized positions. This adaptive process follows the natural flow of semantic structure while keeping computational cost equal to block-based methods. Across four benchmarks in reasoning and code generation, WavefrontDiffusion achieves state-of-the-art performance while producing outputs with higher semantic fidelity, showing the value of adaptive scheduling for more coherent and efficient generation.",
    "authors": [
      "Haojin Yang",
      "Rui Hu",
      "Zequn Sun",
      "Rui Zhou",
      "Yujun Cai",
      "Yiwei Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.19741",
    "title": "Efficient Transferable Optimal Transport via Min-Sliced Transport Plans",
    "abstract": "Optimal Transport (OT) offers a powerful framework for finding correspondences between distributions and addressing matching and alignment problems in various areas of computer vision, including shape analysis, image generation, and multimodal tasks. The computation cost of OT, however, hinders its scalability. Slice-based transport plans have recently shown promise for reducing the computational cost by leveraging the closed-form solutions of 1D OT problems. These methods optimize a one-dimensional projection (slice) to obtain a conditional transport plan that minimizes the transport cost in the ambient space. While efficient, these methods leave open the question of whether learned optimal slicers can transfer to new distribution pairs under distributional shift. Understanding this transferability is crucial in settings with evolving data or repeated OT computations across closely related distributions. In this paper, we study the min-Sliced Transport Plan (min-STP) framework and investigate the transferability of optimized slicers: can a slicer trained on one distribution pair yield effective transport plans for new, unseen pairs? Theoretically, we show that optimized slicers remain close under slight perturbations of the data distributions, enabling efficient transfer across related tasks. To further improve scalability, we introduce a minibatch formulation of min-STP and provide statistical guarantees on its accuracy. Empirically, we demonstrate that the transferable min-STP achieves strong one-shot matching performance and facilitates amortized training for point cloud alignment and flow-based generative modeling.",
    "authors": [
      "Xinran Liu",
      "Elaheh Akbari",
      "Rocio Diaz Martin",
      "Navid NaderiAlizadeh",
      "Soheil Kolouri"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20085",
    "title": "VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis",
    "abstract": "The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and this http URL also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.",
    "authors": [
      "Chujie Wang",
      "Zhiyuan Luo",
      "Ruiqi Liu",
      "Can Ran",
      "Shenghua Fan",
      "Xi Chen",
      "Chu He"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.21667",
    "title": "Escaping the Verifier: Learning to Reason via Demonstrations",
    "abstract": "Training Large Language Models (LLMs) to reason often relies on Reinforcement Learning (RL) with task-specific verifiers. However, many real-world reasoning-intensive tasks lack verifiers, despite offering abundant expert demonstrations that remain under-utilized for reasoning-focused training. We introduce RARO (Relativistic Adversarial Reasoning Optimization) that learns strong reasoning capabilities from only expert demonstrations via Inverse Reinforcement Learning. Our method sets up an adversarial interaction between a policy (generator) and a relativistic critic (discriminator): the policy learns to mimic expert answers, while the critic learns to compare and distinguish between policy and expert answers. Our method trains both the policy and the critic jointly and continuously via RL, and we identify the key stabilization techniques required for robust learning. Empirically, RARO significantly outperforms strong verifier-free baselines on all of our evaluation tasks -- Countdown, DeepMath, and Poetry Writing -- and enjoys the same robust scaling trends as RL on verifiable tasks. These results demonstrate that our method effectively elicits strong reasoning performance from expert demonstrations alone, enabling robust reasoning learning even when task-specific verifiers are unavailable.",
    "authors": [
      "Locke Cai",
      "Ivan Provilkov"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22074",
    "title": "Real-Time Procedural Learning From Experience for AI Agents",
    "abstract": "Learning how to do things from trial and error in real time is a hallmark of biological intelligence, yet most LLM-based agents lack mechanisms to acquire procedural knowledge after deployment. We propose Procedural Recall for Agents with eXperiences Indexed by State (PRAXIS), a lightweight post-training learning mechanism that stores the consequences of actions and retrieves them by jointly matching environmental and internal states of past episodes to the current state. PRAXIS augments agentic action selection with retrieved state-action-result exemplars that are generated in real time. When evaluated on the REAL web browsing benchmark, PRAXIS improves task completion accuracy, reliability, and cost efficiency across different foundation model backbones, and shows preliminary generalization to unseen tasks in similar environments. These results demonstrate that PRAXIS enables the practical adoption of AI agents in fast-evolving stateful environments by helping them learn new procedures effectively.",
    "authors": [
      "Dasheng Bi",
      "Yubin Hu",
      "Mohammed N. Nasir"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22187",
    "title": "HybridWorldSim: A Scalable and Controllable High-fidelity Simulator for Autonomous Driving",
    "abstract": "Realistic and controllable simulation is critical for advancing end-to-end autonomous driving, yet existing approaches often struggle to support novel view synthesis under large viewpoint changes or to ensure geometric consistency. We introduce HybridWorldSim, a hybrid simulation framework that integrates multi-traversal neural reconstruction for static backgrounds with generative modeling for dynamic agents. This unified design addresses key limitations of previous methods, enabling the creation of diverse and high-fidelity driving scenarios with reliable visual and spatial consistency. To facilitate robust benchmarking, we further release a new multi-traversal dataset MIRROR that captures a wide range of routes and environmental conditions across different cities. Extensive experiments demonstrate that HybridWorldSim surpasses previous state-of-the-art methods, providing a practical and scalable solution for high-fidelity simulation and a valuable resource for research and development in autonomous driving.",
    "authors": [
      "Qiang Li",
      "Yingwenqi Jiang",
      "Tuoxi Li",
      "Duyu Chen",
      "Xiang Feng",
      "Yucheng Ao",
      "Shangyue Liu",
      "Xingchen Yu",
      "Youcheng Cai",
      "Yumeng Liu",
      "Yuexin Ma",
      "Xin Hu",
      "Li Liu",
      "Yu Zhang",
      "Linkun Xu",
      "Bingtao Gao",
      "Xueyuan Wang",
      "Shuchang Zhou",
      "Xianming Liu",
      "Ligang Liu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22619",
    "title": "AI Deception: Risks, Dynamics, and Controls",
    "abstract": "As intelligence increases, so does its shadow. AI deception, in which systems induce false beliefs to secure self-beneficial outcomes, has evolved from a speculative concern to an empirically demonstrated risk across language models, AI agents, and emerging frontier systems. This project provides a comprehensive and up-to-date overview of the AI deception field, covering its core concepts, methodologies, genesis, and potential mitigations. First, we identify a formal definition of AI deception, grounded in signaling theory from studies of animal deception. We then review existing empirical studies and associated risks, highlighting deception as a sociotechnical safety challenge. We organize the landscape of AI deception research as a deception cycle, consisting of two key components: deception emergence and deception treatment. Deception emergence reveals the mechanisms underlying AI deception: systems with sufficient capability and incentive potential inevitably engage in deceptive behaviors when triggered by external conditions. Deception treatment, in turn, focuses on detecting and addressing such behaviors. On deception emergence, we analyze incentive foundations across three hierarchical levels and identify three essential capability preconditions required for deception. We further examine contextual triggers, including supervision gaps, distributional shifts, and environmental pressures. On deception treatment, we conclude detection methods covering benchmarks and evaluation protocols in static and interactive settings. Building on the three core factors of deception emergence, we outline potential mitigation strategies and propose auditing approaches that integrate technical, community, and governance efforts to address sociotechnical challenges and future AI risks. To support ongoing work in this area, we release a living resource at this http URL .",
    "authors": [
      "Boyuan Chen",
      "Sitong Fang",
      "Jiaming Ji",
      "Yanxu Zhu",
      "Pengcheng Wen",
      "Jinzhou Wu",
      "Yingshui Tan",
      "Boren Zheng",
      "Mengying Yuan",
      "Wenqi Chen",
      "Donghai Hong",
      "Alex Qiu",
      "Xin Chen",
      "Jiayi Zhou",
      "Kaile Wang",
      "Juntao Dai",
      "Borong Zhang",
      "Tianzhuo Yang",
      "Saad Siddiqui",
      "Isabella Duan",
      "Yawen Duan",
      "Brian Tse",
      "Jen-Tse",
      "Huang",
      "Kun Wang",
      "Baihui Zheng",
      "Jiaheng Liu",
      "Jian Yang",
      "Yiming Li",
      "Wenting Chen",
      "Dongrui Liu",
      "Lukas Vierling",
      "Zhiheng Xi",
      "Haobo Fu",
      "Wenxuan Wang",
      "Jitao Sang",
      "Zhengyan Shi",
      "Chi-Min Chan",
      "Eugenie Shi",
      "Simin Li",
      "Juncheng Li",
      "Jian Yang",
      "Wei Ji",
      "Dong Li",
      "Jinglin Yang",
      "Jun Song",
      "Yinpeng Dong",
      "Jie Fu",
      "Bo Zheng",
      "Min Yang",
      "Yike Guo",
      "Philip Torr",
      "Robert Trager",
      "Yi Zeng",
      "Zhongyuan Wang",
      "Yaodong Yang",
      "Tiejun Huang",
      "Ya-Qin Zhang",
      "Hongjiang Zhang",
      "Andrew Yao"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22696",
    "title": "Probabilistic Fusion and Calibration of Neural Speaker Diarization Models",
    "abstract": "End-to-End Neural Diarization (EEND) systems produce frame-level probabilistic speaker activity estimates, yet since evaluation focuses primarily on Diarization Error Rate (DER), the reliability and calibration of these confidence scores have been largely neglected. When fusing multiple diarization systems, DOVER-Lap remains the only established approach, operating at the segment level with hard decisions. We propose working with continuous probability outputs, which enables more sophisticated fusion and calibration techniques that can leverage model uncertainty and complementary strengths across different architectures. This paper presents the first comprehensive framework for calibrating and fusing EEND models at the probability level. We investigate two output formulations (multilabel and powerset representations) and their impact on calibration and fusion effectiveness. Through extensive experiments on the CallHome two-speaker benchmark, we demonstrate that proper calibration provides substantial improvements even for individual models (up to 19% relative DER reduction), in some cases mitigating the absence of domain adaptation. We reveal that joint calibration in powerset space consistently outperforms independent per-speaker calibration, that fusion substantially improves over individual models, and that the Fuse-then-Calibrate ordering generally outperforms both calibrating before fusion and uncalibrated fusion while requiring calibration of only a single combined model. Our best configuration outperforms DOVER-Lap in terms of DER while providing reliable confidence estimates essential for downstream applications. This work proposes best practices for probability-level fusion of EEND systems and demonstrates the advantages of leveraging soft outputs over hard decisions.",
    "authors": [
      "Juan Ignacio Alvarez-Trejos",
      "Sergio A. Balanya",
      "Daniel Ramos",
      "Alicia Lozano-Diez"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22826",
    "title": "Some Modalities are More Equal Than Others: Decoding and Architecting Multimodal Integration in MLLMs",
    "abstract": "Despite remarkable advancements in Multimodal Large Language Models (MLLMs), a fundamental question remains: are MLLMs robust to contradicting modalities? To rigorously study this, we introduce MMA-Bench comprising videos and tasks that probe a model's reliance on specific modalities. Using black-box and white-box interpretability techniques, we provide a critical analysis of the brittleness of both open- and closed-sourced MLLMs. We show that current MLLMs struggle under misaligned audio-visual pairs and simple misleading text, thereby lacking robust multi-modal reasoning. Building on these findings, we propose a modality alignment tuning strategy to teach the model when to prioritize, leverage, or ignore specific modality cues. Through extensive experiments and analysis, we show that our alignment tuning yields demonstrably stronger multimodal grounding. This work provides both interpretability tools and a clear path toward developing MLLMs with intrinsically reliable cross-modal reasoning. Code and dataset will be publicly available.",
    "authors": [
      "Tianle Chen",
      "Chaitanya Chakka",
      "Arjun Reddy Akula",
      "Xavier Thomas",
      "Deepti Ghadiyaram"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00417",
    "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency",
    "abstract": "This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain. Unlike general-purpose agent benchmarks for search and prediction, professional crypto analysis presents specific challenges: \\emph{extreme time-sensitivity}, \\emph{a highly adversarial information environment}, and the critical need to synthesize data from \\emph{diverse, specialized sources}, such as on-chain intelligence platforms and real-time Decentralized Finance (DeFi) dashboards. CryptoBench thus serves as a much more challenging and valuable scenario for LLM agent assessment. To address these challenges, we constructed a live, dynamic benchmark featuring 50 questions per month, expertly designed by crypto-native professionals to mirror actual analyst workflows. These tasks are rigorously categorized within a four-quadrant system: Simple Retrieval, Complex Retrieval, Simple Prediction, and Complex Prediction. This granular categorization enables a precise assessment of an LLM agent's foundational data-gathering capabilities alongside its advanced analytical and forecasting skills. Our evaluation of ten LLMs, both directly and within an agentic framework, reveals a performance hierarchy and uncovers a failure mode. We observe a \\textit{retrieval-prediction imbalance}, where many leading models, despite being proficient at data retrieval, demonstrate a pronounced weakness in tasks requiring predictive analysis. This highlights a problematic tendency for agents to appear factually grounded while lacking the deeper analytical capabilities to synthesize information.",
    "authors": [
      "Jiacheng Guo",
      "Suozhi Huang",
      "Zixin Yao",
      "Yifan Zhang",
      "Yifu Lu",
      "Jiashuo Liu",
      "Zihao Li",
      "Nicholas Deng",
      "Qixin Xiao",
      "Jia Tian",
      "Kanghong Zhan",
      "Tianyi Li",
      "Xiaochen Liu",
      "Jason Ge",
      "Chaoyang He",
      "Kaixuan Huang",
      "Lin Yang",
      "Wenhao Huang",
      "Mengdi Wang"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00451",
    "title": "STCTS: Generative Semantic Compression for Ultra-Low Bitrate Speech via Explicit Text-Prosody-Timbre Decomposition",
    "abstract": "Voice communication in bandwidth-constrained environments--maritime, satellite, and tactical networks--remains prohibitively expensive. Traditional codecs struggle below 1 kbps, while existing semantic approaches (STT-TTS) sacrifice prosody and speaker identity. We present STCTS, a generative semantic compression framework enabling natural voice communication at 80 bps. STCTS explicitly decomposes speech into linguistic content, prosodic expression, and speaker timbre, applying tailored compression: context-aware text encoding (70 bps), sparse prosody transmission via TTS interpolation (<14 bps at 0.1-1 Hz), and amortized speaker embedding. Evaluations on LibriSpeech demonstrate a 75x bitrate reduction versus Opus (6 kbps) and 12x versus EnCodec (1 kbps), while maintaining perceptual quality (NISQA MOS > 4.26), graceful degradation under packet loss and noise resilience. We also discover a bimodal quality distribution with prosody sampling rate: sparse and dense updates both achieve high quality, while mid-range rates degrade due to perceptual discontinuities--guiding optimal configuration design. Beyond efficiency, our modular architecture supports privacy-preserving encryption, human-interpretable transmission, and flexible deployment on edge devices, offering a robust solution for ultra-low bandwidth scenarios.",
    "authors": [
      "Siyu Wang",
      "Haitao Li",
      "Donglai Zhu"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00601",
    "title": "Clinical-R1: Empowering Large Language Models for Faithful and Comprehensive Reasoning with Clinical Objective Relative Policy Optimization",
    "abstract": "Recent advances in large language models (LLMs) have shown strong reasoning capabilities through large-scale pretraining and post-training reinforcement learning, demonstrated by DeepSeek-R1. However, current post-training methods, such as Grouped Relative Policy Optimization (GRPO), mainly reward correctness, which is not aligned with the multi-dimensional objectives required in high-stakes fields such as medicine, where reasoning must also be faithful and comprehensive. We introduce Clinical-Objective Relative Policy Optimization (CRPO), a scalable, multi-objective, verifiable reinforcement learning method designed to align LLM post-training with clinical reasoning principles. CRPO integrates rule-based and verifiable reward signals that jointly optimize accuracy, faithfulness, and comprehensiveness without relying on human annotation. To demonstrate its effectiveness, we train Clinical-R1-3B, a 3B-parameter model for clinical reasoning. The experiments on three benchmarks demonstrate that our CRPO substantially improves reasoning on truthfulness and completeness over standard GRPO while maintaining comfortable accuracy enhancements. This framework provides a scalable pathway to align LLM reasoning with clinical objectives, enabling safer and more collaborative AI systems for healthcare while also highlighting the potential of multi-objective, verifiable RL methods in post-training scaling of LLMs for medical domains.",
    "authors": [
      "Boyang Gu",
      "Hongjian Zhou",
      "Bradley Max Segal",
      "Jinge Wu",
      "Zeyu Cao",
      "Hantao Zhong",
      "Lei Clifton",
      "Fenglin Liu",
      "David A. Clifton"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00647",
    "title": "MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba",
    "abstract": "Vision Mamba has emerged as a promising and efficient alternative to Vision Transformers, yet its efficiency remains fundamentally constrained by the number of input tokens. Existing token reduction approaches typically adopt token pruning or merging to reduce computation. However, they inherently lead to information loss as they discard or compress token representations. This problem is further exacerbated when the same fine-grained token processing is uniformly applied across all images regardless of visual complexity. We observe that not all inputs require fine-grained processing: simple images can be effectively handled at a coarse resolution, while only complex ones require refinement. Based on this insight, we propose MambaScope, an adaptive framework for efficient inference for Vision Mamba. MambaScope first performs coarse-grained inference by dividing the input image into large patches, significantly reducing token length and computation. When the model's prediction confidence is low, selected regions are re-processed at a finer resolution to recover essential visual details with minimal additional cost. This dynamic resolution assignment strategy allows MambaScope to allocate computation adaptively according to image complexity, achieving efficient processing without compromising accuracy. Experiments across various vision tasks demonstrate that MambaScope outperforms both the baseline Vision Mamba and state-of-the-art token reduction techniques in terms of accuracy and efficiency.",
    "authors": [
      "Shanhui Liu",
      "Rui Xu",
      "Yunke Wang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00765",
    "title": "The Outline of Deception: Physical Adversarial Attacks on Traffic Signs Using Edge Patches",
    "abstract": "Intelligent driving systems are vulnerable to physical adversarial attacks on traffic signs. These attacks can cause misclassification, leading to erroneous driving decisions that compromise road safety. Moreover, within V2X networks, such misinterpretations can propagate, inducing cascading failures that disrupt overall traffic flow and system stability. However, a key limitation of current physical attacks is their lack of stealth. Most methods apply perturbations to central regions of the sign, resulting in visually salient patterns that are easily detectable by human observers, thereby limiting their real-world practicality. This study proposes TESP-Attack, a novel stealth-aware adversarial patch method for traffic sign classification. Based on the observation that human visual attention primarily focuses on the central regions of traffic signs, we employ instance segmentation to generate edge-aligned masks that conform to the shape characteristics of the signs. A U-Net generator is utilized to craft adversarial patches, which are then optimized through color and texture constraints along with frequency domain analysis to achieve seamless integration with the background environment, resulting in highly effective visual concealment. The proposed method demonstrates outstanding attack success rates across traffic sign classification models with varied architectures, achieving over 90% under limited query budgets. It also exhibits strong cross-model transferability and maintains robust real-world performance that remains stable under varying angles and distances.",
    "authors": [
      "Haojie Ji",
      "Te Hu",
      "Haowen Li",
      "Long Jin",
      "Chongshi Xin",
      "Yuchi Yao",
      "Jiarui Xiao"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00833",
    "title": "Logic Encryption: This Time for Real",
    "abstract": "Modern circuits face various threats like reverse engineering, theft of intellectual property (IP), side-channel attacks, etc. Here, we present a novel approach for IP protection based on logic encryption (LE). Unlike established schemes for logic locking, our work obfuscates the circuit's structure and functionality by encoding and encrypting the logic itself. We devise an end-to-end method for practical LE implementation based on standard cryptographic algorithms, key-bit randomization, simple circuit design techniques, and system-level synthesis operations, all in a correct-by-construction manner. Our extensive analysis demonstrates the remarkable efficacy of our scheme, outperforming prior art against a range of oracle-less attacks covering crucial threat vectors, all with lower design overheads. We provide a full open-source release.",
    "authors": [
      "Rupesh Raj Karn",
      "Lakshmi Likhitha Mankali",
      "Zeng Wang",
      "Saideep Sreekumar",
      "Prithwish Basu Roy",
      "Ozgur Sinanoglu",
      "Lilas Alrahis",
      "Johann Knechtel"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00882",
    "title": "Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints",
    "abstract": "Vision-Language Models (VLMs) exhibit significant performance plateaus in specialized domains like precision agriculture, primarily due to \"Reasoning-Driven Hallucination\" where linguistic priors override visual perception. A key bottleneck is the \"Modality Gap\": visual embeddings fail to reliably activate the fine-grained expert knowledge already encoded in model parameters. We propose \"Look, Recite, Then Answer,\" a parameter-efficient framework that enhances VLMs via self-generated knowledge hints while keeping backbone models frozen. The framework decouples inference into three stages: (1) Look generates objective visual descriptions and candidate sets; (2) Recite employs a lightweight 1.7B router to transform visual cues into targeted queries that trigger candidate-specific parametric knowledge; (3) Answer performs parallel evidence alignment between descriptions and recited knowledge to select the most consistent label. On AgroBench, our method achieves state-of-the-art results, improving Weed Identification accuracy by 23.52% over Qwen2-VL-72B and surpassing GPT-4o without external search overhead. This modular design mitigates hallucinations by transforming passive perception into active, controllable knowledge retrieval",
    "authors": [
      "Xisheng Feng"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00887",
    "title": "Multilingual Training-Free Remote Sensing Image Captioning",
    "abstract": "Remote sensing image captioning has advanced rapidly through encoder--decoder models, although the reliance on large annotated datasets and the focus on English restricts global applicability. To address these limitations, we propose the first training-free multilingual approach, based on retrieval-augmented prompting. For a given aerial image, we employ a domain-adapted SigLIP2 encoder to retrieve related captions and few-shot examples from a datastore, which are then provided to a language model. We explore two variants: an image-blind setup, where a multilingual Large Language Model (LLM) generates the caption from textual prompts alone, and an image-aware setup, where a Vision--Language Model (VLM) jointly processes the prompt and the input image. To improve the coherence of the retrieved content, we introduce a graph-based re-ranking strategy using PageRank on a graph of images and captions. Experiments on four benchmark datasets across ten languages demonstrate that our approach is competitive with fully supervised English-only systems and generalizes to other languages. Results also highlight the importance of re-ranking with PageRank, yielding up to 35% improvements in performance metrics. Additionally, it was observed that while VLMs tend to generate visually grounded but lexically diverse captions, LLMs can achieve stronger BLEU and CIDEr scores. Lastly, directly generating captions in the target language consistently outperforms other translation-based strategies. Overall, our work delivers one of the first systematic evaluations of multilingual, training-free captioning for remote sensing imagery, advancing toward more inclusive and scalable multimodal Earth observation systems.",
    "authors": [
      "Carlos Rebelo",
      "Gil Rocha",
      "João Daniel Silva",
      "Bruno Martins"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00907",
    "title": "Magnetic Tactile-Driven Soft Actuator for Intelligent Grasping and Firmness Evaluation",
    "abstract": "Soft robots are powerful tools for manipulating delicate objects, yet their adoption is hindered by two gaps: the lack of integrated tactile sensing and sensor signal distortion caused by actuator deformations. This paper addresses these challenges by introducing the SoftMag actuator: a magnetic tactile-sensorized soft actuator. Unlike systems relying on attached sensors or treating sensing and actuation separately, SoftMag unifies them through a shared architecture while confronting the mechanical parasitic effect, where deformations corrupt tactile signals. A multiphysics simulation framework models this coupling, and a neural-network-based decoupling strategy removes the parasitic component, restoring sensing fidelity. Experiments including indentation, quasi-static and step actuation, and fatigue tests validate the actuator's performance and decoupling effectiveness. Building upon this foundation, the system is extended into a two-finger SoftMag gripper, where a multi-task neural network enables real-time prediction of tri-axial contact forces and position. Furthermore, a probing-based strategy estimates object firmness during grasping. Validation on apricots shows a strong correlation (Pearson r over 0.8) between gripper-estimated firmness and reference measurements, confirming the system's capability for non-destructive quality assessment. Results demonstrate that combining integrated magnetic sensing, learning-based correction, and real-time inference enables a soft robotic platform that adapts its grasp and quantifies material properties. The framework offers an approach for advancing sensorized soft actuators toward intelligent, material-aware robotics.",
    "authors": [
      "Chengjin Du",
      "Federico Bernabei",
      "Zhengyin Du",
      "Sergio Decherchi",
      "Matteo Lo Preti",
      "Lucia Beccai"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01115",
    "title": "Sliced Rényi Pufferfish Privacy: Directional Additive Noise Mechanism and Private Learning with Gradient Clipping",
    "abstract": "We study privatization mechanism design and privacy accounting in the Pufferfish family, addressing two practical gaps of Renyi Pufferfish Privacy (RPP): high-dimensional optimal transport (OT) calibration and the absence of a general, mechanism-agnostic composition rule for iterative learning. We introduce Sliced Renyi Pufferfish Privacy (SRPP), which replaces high-dimensional comparisons by directional ones over a set of unit vectors, enabling geometry-aware and tractable guarantees. To calibrate noise without high-dimensional OT, we propose sliced Wasserstein mechanisms that compute per-direction (1-D) sensitivities, yielding closed-form, statistically stable, and anisotropic calibrations. We further define SRPP Envelope (SRPE) as computable upper bounds that are tightly implementable by these sliced Wasserstein mechanisms. For iterative deep learning algorithms, we develop a decompose-then-compose SRPP-SGD scheme with gradient clipping based on a History-Uniform Cap (HUC), a pathwise bound on one-step directional changes that is uniform over optimization history, and a mean-square variant (ms-HUC) that leverages subsampling randomness to obtain on-average SRPP guarantees with improved utility. The resulting HUC and ms-HUC accountants aggregate per-iteration, per-direction Renyi costs and integrate naturally with moments-accountant style analyses. Finally, when multiple mechanisms are trained and privatized independently under a common slicing geometry, our analysis yields graceful additive composition in both worst-case and mean-square regimes. Our experiments indicate that the proposed SRPP-based methods achieve favorable privacy-utility trade-offs in both static and iterative settings.",
    "authors": [
      "Tao Zhang",
      "Yevgeniy Vorobeychik"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01204",
    "title": "TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image",
    "abstract": "Generating high-fidelity, physically interactive 3D simulated tabletop scenes is essential for embodied AI--especially for robotic manipulation policy learning and data synthesis. However, current text- or image-driven 3D scene generation methods mainly focus on large-scale scenes, struggling to capture the high-density layouts and complex spatial relations that characterize tabletop scenes. To address these challenges, we propose TabletopGen, a training-free, fully automatic framework that generates diverse, instance-level interactive 3D tabletop scenes. TabletopGen accepts a reference image as input, which can be synthesized by a text-to-image model to enhance scene diversity. We then perform instance segmentation and completion on the reference to obtain per-instance images. Each instance is reconstructed into a 3D model followed by canonical coordinate alignment. The aligned 3D models then undergo pose and scale estimation before being assembled into a collision-free, simulation-ready tabletop scene. A key component of our framework is a novel pose and scale alignment approach that decouples the complex spatial reasoning into two stages: a Differentiable Rotation Optimizer for precise rotation recovery and a Top-view Spatial Alignment mechanism for robust translation and scale estimation, enabling accurate 3D reconstruction from 2D reference. Extensive experiments and user studies show that TabletopGen achieves state-of-the-art performance, markedly surpassing existing methods in visual fidelity, layout accuracy, and physical plausibility, capable of generating realistic tabletop scenes with rich stylistic and spatial diversity. Our code will be publicly available.",
    "authors": [
      "Ziqian Wang",
      "Yonghao He",
      "Licheng Yang",
      "Wei Zou",
      "Hongxuan Ma",
      "Liu Liu",
      "Wei Sui",
      "Yuxin Guo",
      "Hu Su"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01210",
    "title": "Knowledge Graph Augmented Large Language Models for Disease Prediction",
    "abstract": "Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.",
    "authors": [
      "Ruiyu Wang",
      "Tuan Vinh",
      "Ran Xu",
      "Yuyin Zhou",
      "Jiaying Lu",
      "Carl Yang",
      "Francisco Pasquel"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01311",
    "title": "CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL",
    "abstract": "Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at this https URL .",
    "authors": [
      "Shinji Mai",
      "Yunpeng Zhai",
      "Ziqian Chen",
      "Cheng Chen",
      "Anni Zou",
      "Shuchang Tao",
      "Zhaoyang Liu",
      "Bolin Ding"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01353",
    "title": "The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search",
    "abstract": "Large language models (LLMs) remain vulnerable to jailbreak attacks that bypass safety guardrails to elicit harmful outputs. Existing approaches overwhelmingly operate within the prompt-optimization paradigm: whether through traditional algorithmic search or recent agent-based workflows, the resulting prompts typically retain malicious semantic signals that modern guardrails are primed to detect. In contrast, we identify a deeper, largely overlooked vulnerability stemming from the highly interconnected nature of an LLM's internal knowledge. This structure allows harmful objectives to be realized by weaving together sequences of benign sub-queries, each of which individually evades detection. To exploit this loophole, we introduce the Correlated Knowledge Attack Agent (CKA-Agent), a dynamic framework that reframes jailbreaking as an adaptive, tree-structured exploration of the target model's knowledge base. The CKA-Agent issues locally innocuous queries, uses model responses to guide exploration across multiple paths, and ultimately assembles the aggregated information to achieve the original harmful objective. Evaluated across state-of-the-art commercial LLMs (Gemini2.5-Flash/Pro, GPT-oss-120B, Claude-Haiku-4.5), CKA-Agent consistently achieves over 95% success rates even against strong guardrails, underscoring the severity of this vulnerability and the urgent need for defenses against such knowledge-decomposition attacks. Our codes are available at this https URL .",
    "authors": [
      "Rongzhe Wei",
      "Peizhi Niu",
      "Xinjie Shen",
      "Tony Tu",
      "Yifan Li",
      "Ruihan Wu",
      "Eli Chien",
      "Pin-Yu Chen",
      "Olgica Milenkovic",
      "Pan Li"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01374",
    "title": "Stabilizing Reinforcement Learning with LLMs: Formulation and Practices",
    "abstract": "This paper proposes a novel formulation for reinforcement learning (RL) with large language models, explaining why and under what conditions the true sequence-level reward can be optimized via a surrogate token-level objective in policy gradient methods such as REINFORCE. Specifically, through a first-order approximation, we show that this surrogate becomes increasingly valid only when both the training-inference discrepancy and policy staleness are minimized. This insight provides a principled explanation for the crucial role of several widely adopted techniques in stabilizing RL training, including importance sampling correction, clipping, and particularly Routing Replay for Mixture-of-Experts (MoE) models. Through extensive experiments with a 30B MoE model totaling hundreds of thousands of GPU hours, we show that for on-policy training, the basic policy gradient algorithm with importance sampling correction achieves the highest training stability. When off-policy updates are introduced to accelerate convergence, combining clipping and Routing Replay becomes essential to mitigate the instability caused by policy staleness. Notably, once training is stabilized, prolonged optimization consistently yields comparable final performance regardless of cold-start initialization. We hope that the shared insights and the developed recipes for stable RL training will facilitate future research.",
    "authors": [
      "Chujie Zheng",
      "Kai Dang",
      "Bowen Yu",
      "Mingze Li",
      "Huiqiang Jiang",
      "Junrong Lin",
      "Yuqiong Liu",
      "Hao Lin",
      "Chencan Wu",
      "Feng Hu",
      "An Yang",
      "Jingren Zhou",
      "Junyang Lin"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01424",
    "title": "\\textit{ViRectify}: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models",
    "abstract": "As multimodal large language models (MLLMs) frequently exhibit errors in complex video reasoning scenarios, correcting these errors is critical for uncovering their weaknesses and improving performance. However, existing benchmarks lack systematic evaluation of MLLMs' ability to identify and correct these video reasoning errors. To bridge this gap, we propose \\textit{ViRectify}, a comprehensive benchmark to evaluate their fine-grained correction capability. Through an AI-assisted annotation pipeline with human verification, we construct a dataset of over 30\\textit{K} instances spanning dynamic perception, scientific reasoning, and embodied decision-making domains. In \\textit{ViRectify}, we challenge MLLMs to perform step-wise error identification and generate rationales with key video evidence grounding. In addition, we further propose the trajectory evidence-driven correction framework, comprising step-wise error trajectory and reward modeling on visual evidence-grounded correction. It encourages the model to explicitly concentrate on error propagation and key timestamps for correction. Extensive evaluation across 16 advanced MLLMs demonstrates that our \\textit{ViRectify} serves as a challenging testbed, where GPT-5 achieves only 31.94\\% correction accuracy. Our framework enables a Qwen2.5-VL-7B to consistently outperform the variants of 72B on \\textit{ViRectify}, showing the effectiveness of our approach. Further analysis uncovers systematic asymmetries in error correction across models, and our dataset is also a valuable data resource to perform reflection learning. We believe \\textit{ViRectify} provides a new direction for comprehensively evaluating the advanced MLLMs in video reasoning.",
    "authors": [
      "Xusen Hei",
      "Jiali Chen",
      "Jinyu Yang",
      "Mengchen Zhao",
      "Yi Cai"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01457",
    "title": "ZIP-RC: Optimizing Test-Time Compute via Zero-Overhead Joint Reward-Cost Prediction",
    "abstract": "Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.",
    "authors": [
      "Rohin Manvi",
      "Joey Hong",
      "Tim Seyde",
      "Maxime Labonne",
      "Mathias Lechner",
      "Sergey Levine"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01475",
    "title": "A Unified Bayesian Framework for Stochastic Data-Driven Smoothing, Prediction, and Control",
    "abstract": "Extending data-driven algorithms based on Willems' fundamental lemma to stochastic data often requires empirical and customized workarounds. This work presents a unified Bayesian framework that provides a systematic and general method for handling stochastic data-driven tasks, including smoothing, prediction, and control, via maximum a posteriori estimation. This framework formulates a unified trajectory estimation problem for the three tasks by specifying different types of trajectory knowledge. Then, a Bayesian problem is solved that optimally combines trajectory knowledge with a data-driven characterization of the trajectory from offline data for a general class of stochastic disturbances. Under specific conditions, this problem is shown to generalize existing data-driven prediction and control algorithms. Numerical examples demonstrate the performance of the unified approach for all three tasks against other data-driven and system identification approaches.",
    "authors": [
      "Mingzhou Yin",
      "Andrea Iannelli",
      "Seyed Ali Nazari",
      "Matthias A. Müller"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01803",
    "title": "Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos",
    "abstract": "Despite rapid advances in video generative models, robust metrics for evaluating visual and temporal correctness of complex human actions remain elusive. Critically, existing pure-vision encoders and Multimodal Large Language Models (MLLMs) are strongly appearance-biased, lack temporal understanding, and thus struggle to discern intricate motion dynamics and anatomical implausibilities in generated videos. We tackle this gap by introducing a novel evaluation metric derived from a learned latent space of real-world human actions. Our method first captures the nuances, constraints, and temporal smoothness of real-world motion by fusing appearance-agnostic human skeletal geometry features with appearance-based features. We posit that this combined feature space provides a robust representation of action plausibility. Given a generated video, our metric quantifies its action quality by measuring the distance between its underlying representations and this learned real-world action distribution. For rigorous validation, we develop a new multi-faceted benchmark specifically designed to probe temporally challenging aspects of human action fidelity. Through extensive experiments, we show that our metric achieves substantial improvement of more than 68% compared to existing state-of-the-art methods on our benchmark, performs competitively on established external benchmarks, and has a stronger correlation with human perception. Our in-depth analysis reveals critical limitations in current video generative models and establishes a new standard for advanced research in video generation.",
    "authors": [
      "Xavier Thomas",
      "Youngsun Lim",
      "Ananya Srinivasan",
      "Audrey Zheng",
      "Deepti Ghadiyaram"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02010",
    "title": "Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling",
    "abstract": "As large language models have grown larger, low-precision numerical formats such as NVFP4 have become increasingly popular due to the speed and memory benefits they provide. However, to accelerate computation with NVFP4, all matrix multiplication operands--weights and activations in the forward pass, and weights, activations, and gradients in the backward pass--must be quantized to NVFP4, often leading to divergence during training and performance degradation during inference. To address this issue, in this work we introduce Four Over Six (4/6), a modification to the NVFP4 quantization algorithm that evaluates two potential scale factors for each block of values. Unlike integer formats, floating-point formats such as FP4 have the most quantization error on near-maximal values in each block, which we find to be primarily responsible for downstream performance degradation. We find that for some blocks, scaling to smaller FP4 values makes the distribution of representable values more uniform, improving representation of near-maximal values. Importantly, 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, making it viable to use while training LLMs with NVFP4. In pre-training experiments with transformer and hybrid model architectures, we find that 4/6 prevents divergence in several cases, bringing training loss significantly closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. We also find that 4/6 can be easily incorporated into many different post-training quantization methods and generally improves downstream accuracy. We hope this inspires future work in training and deploying models with NVFP4. Our code is available at this http URL .",
    "authors": [
      "Jack Cook",
      "Junxian Guo",
      "Guangxuan Xiao",
      "Yujun Lin",
      "Song Han"
    ],
    "primary_category": "cs.CL",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02019",
    "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
    "abstract": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.",
    "authors": [
      "Sebastian Sanokowski",
      "Kaustubh Patil",
      "Alois Knoll"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02170",
    "title": "Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code",
    "abstract": "Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present Flowchart2Mermaid, a lightweight web system that converts flowchart images into editable this http URL code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.",
    "authors": [
      "Pritam Deka",
      "Barry Devereux"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02179",
    "title": "Young children's anthropomorphism of an AI chatbot: Brain activation and the role of parent co-presence",
    "abstract": "Artificial Intelligence (AI) chatbots powered by a large language model (LLM) are entering young children's learning and play, yet little is known about how young children construe these agents or how such construals relate to engagement. We examined anthropomorphism of a social AI chatbot during collaborative storytelling and asked how children's attributions related to their behavior and prefrontal activation. Children at ages 5-6 (N = 23) completed three storytelling sessions: interacting with (1) an AI chatbot only, (2) a parent only, and (3) the AI and a parent together. After the sessions, children completed an interview assessing anthropomorphism toward both the AI chatbot and the parent. Behavioral engagement was indexed by the conversational turn count (CTC) ratio, and concurrent fNIRS measured oxygenated hemoglobin in bilateral vmPFC and dmPFC regions. Children reported higher anthropomorphism for parents than for the AI chatbot overall, although AI ratings were relatively high for perceptive abilities and epistemic states. Anthropomorphism was not associated with CTC. In the right dmPFC, higher perceptive scores were associated with greater activation during the AI-only condition and with lower activation during the AI+Parent condition. Exploratory analyses indicated that higher dmPFC activation during the AI-only condition correlated with higher end-of-session \"scared\" mood ratings. Findings suggest that stronger perceptive anthropomorphism can be associated with greater brain activation related to interpreting the AI's mental states, whereas parent co-presence may help some children interpret and regulate novel AI interactions. These results may have design implications for encouraging parent-AI co-use in early childhood.",
    "authors": [
      "Pilyoung Kim",
      "Jenna H. Chin",
      "Yun Xie",
      "Nolan Brady",
      "Tom Yeh",
      "Sujin Yang"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02252",
    "title": "Optimal-Length Labeling Schemes and Fast Algorithms for k-gathering and k-broadcasting",
    "abstract": "We consider basic communication tasks in arbitrary radio networks: $k$-broadcasting and $k$-gathering. In the case of $k$-broadcasting messages from $k$ sources have to get to all nodes in the network. The goal of $k$-gathering is to collect messages from $k$ source nodes in a designated sink node. We consider these problems in the framework of distributed algorithms with advice. Krisko and Miller showed in 2021 that the optimal size of advice for $k$-broadcasting is $\\Theta(\\min(\\log \\Delta,$ $ \\log k))$, where $\\Delta$ is equal to the maximum degree of a vertex of the input communication graph. We show that the same bound $\\Theta(\\min(\\log \\Delta, \\log k))$ on the size of optimal labeling scheme holds also for the $k$-gathering problems. Moreover, we design fast algorithms for both problems with asymptotically optimal size of advice. For $k$-gathering our algorithm works in at most $D+k$ rounds, where $D$ is the diameter of the communication graph. This time bound is optimal even for centralized algorithms. We apply the $k$-gathering algorithm for $k$-broadcasting to achieve an algorithm working in time $O(D+\\log^2 n+k)$ rounds. We also exhibit a logarithmic time complexity gap between distributed algorithms with advice of optimal size and distributed algorithms with distinct arbitrary labels.",
    "authors": [
      "Adam Ganczorz",
      "Tomasz Jurdzinski"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02258",
    "title": "Exploring the Potentials of Spiking Neural Networks for Image Deraining",
    "abstract": "Biologically plausible and energy-efficient frameworks such as Spiking Neural Networks (SNNs) have not been sufficiently explored in low-level vision tasks. Taking image deraining as an example, this study addresses the representation of the inherent high-pass characteristics of spiking neurons, specifically in image deraining and innovatively proposes the Visual LIF (VLIF) neuron, overcoming the obstacle of lacking spatial contextual understanding present in traditional spiking neurons. To tackle the limitation of frequency-domain saturation inherent in conventional spiking neurons, we leverage the proposed VLIF to introduce the Spiking Decomposition and Enhancement Module and the lightweight Spiking Multi-scale Unit for hierarchical multi-scale representation learning. Extensive experiments across five benchmark deraining datasets demonstrate that our approach significantly outperforms state-of-the-art SNN-based deraining methods, achieving this superior performance with only 13\\% of their energy consumption. These findings establish a solid foundation for deploying SNNs in high-performance, energy-efficient low-level vision tasks.",
    "authors": [
      "Shuang Chen",
      "Tomas Krajnik",
      "Farshad Arvin",
      "Amir Atapour-Abarghouei"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02318",
    "title": "COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers",
    "abstract": "This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation this http URL Availability ( this https URL ).",
    "authors": [
      "Junyu Wang",
      "Changjia Zhu",
      "Yuanbo Zhou",
      "Lingyao Li",
      "Xu He",
      "Junjie Xiong"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02381",
    "title": "Fleet Size and Mix Capacitated Vehicle Routing Problem with Time Windows for Mobile Fast Chargers",
    "abstract": "The electrification of off-road heavy equipment presents operational challenges for agencies serving remote sites with limited fixed charging infrastructure. Existing mobile fast charging vehicle (MFCV) planning approaches typically treat fleet design and routing as separate problems, fixing vehicle characteristics before dispatch. This paper formulates a fleet size and mix capacitated vehicle routing problem with time windows (FSMCVRPTW) for MFCV deployment, jointly optimizing fleet composition, charger specifications, routing, and scheduling within a unified mixed-integer linear program. The model incorporates heterogeneous MFCV types with varying power ratings, battery capacities, fuel range, and cost structures, minimizing total daily cost from labor, fuel, amortized capital expenditure, and energy purchase under temporal service windows, resource budgets, and energy-delivery constraints. The formulation is implemented in Python/Gurobi and applied to two case studies using California Department of Transportation wheel-loader data in Los Angeles (dense urban) and Truckee (sparse mountainous). Results show that simultaneous optimization yields compact, well-utilized fleets that meet all service windows while revealing strong sensitivity of unit cost to demand density and geography. The proposed FSMCVRPTW framework provides a generalizable decision-support methodology that co-designs fleet size, charger power, routing, and service schedules in a single optimization layer for context-aware, cost-efficient mobile fast charging.",
    "authors": [
      "Farhang Motallebi Araghi",
      "Armin Abdolmohammadi",
      "Navid Mojahed",
      "Shima Nazari"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02384",
    "title": "Markov Chains Approximate Message Passing",
    "abstract": "Markov chain Monte Carlo algorithms have long been observed to obtain near-optimal performance in various Bayesian inference settings. However, developing a supporting theory that makes these studies rigorous has proved challenging. In this paper, we study the classical spiked Wigner inference problem, where one aims to recover a planted Boolean spike from a noisy matrix measurement. We relate the recovery performance of Glauber dynamics on the annealed posterior to the performance of Approximate Message Passing (AMP), which is known to achieve Bayes-optimal performance. Our main results rely on the analysis of an auxiliary Markov chain called restricted Gaussian dynamics (RGD). Concretely, we establish the following results: 1. RGD can be reduced to an effective one-dimensional recursion which mirrors the evolution of the AMP iterates. 2. From a warm start, RGD rapidly converges to a fixed point in correlation space, which recovers Bayes-optimal performance when run on the posterior. 3. Conditioned on widely believed mixing results for the SK model, we recover the phase transition for non-trivial inference.",
    "authors": [
      "Amit Rajaraman",
      "David X. Wu"
    ],
    "primary_category": "cs.DS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02397",
    "title": "Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance",
    "abstract": "We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.",
    "authors": [
      "Emanuele Bossi",
      "C. Tyler Diggans",
      "Abd AlRahman R. AlMomani"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02457",
    "title": "Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation",
    "abstract": "Recent audio-video generative systems suggest that coupling modalities benefits not only audio-video synchrony but also the video modality itself. We pose a fundamental question: Does audio-video joint denoising training improve video generation, even when we only care about video quality? To study this, we introduce a parameter-efficient Audio-Video Full DiT (AVFullDiT) architecture that leverages pre-trained text-to-video (T2V) and text-to-audio (T2A) modules for joint denoising. We train (i) a T2AV model with AVFullDiT and (ii) a T2V-only counterpart under identical settings. Our results provide the first systematic evidence that audio-video joint denoising can deliver more than synchrony. We observe consistent improvements on challenging subsets featuring large and object contact motions. We hypothesize that predicting audio acts as a privileged signal, encouraging the model to internalize causal relationships between visual events and their acoustic consequences (e.g., collision $\\times$ impact sound), which in turn regularizes video dynamics. Our findings suggest that cross-modal co-training is a promising approach to developing stronger, more physically grounded world models. Code and dataset will be made publicly available.",
    "authors": [
      "Jianzong Wu",
      "Hao Lian",
      "Dachao Hao",
      "Ye Tian",
      "Qingyu Shi",
      "Biaolong Chen",
      "Hao Jiang",
      "Yunhai Tong"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02512",
    "title": "Two-Stage Vision Transformer for Image Restoration: Colorization Pretraining + Residual Upsampling",
    "abstract": "In computer vision, Single Image Super-Resolution (SISR) is still a difficult problem. We present ViT-SR, a new technique to improve the performance of a Vision Transformer (ViT) employing a two-stage training strategy. In our method, the model learns rich, generalizable visual representations from the data itself through a self-supervised pretraining phase on a colourization task. The pre-trained model is then adjusted for 4x super-resolution. By predicting the addition of a high-frequency residual image to an initial bicubic interpolation, this design simplifies residual learning. ViT-SR, trained and evaluated on the DIV2K benchmark dataset, achieves an impressive SSIM of 0.712 and PSNR of 22.90 dB. These results demonstrate the efficacy of our two-stage approach and highlight the potential of self-supervised pre-training for complex image restoration tasks. Further improvements may be possible with larger ViT architectures or alternative pretext tasks.",
    "authors": [
      "Aditya Chaudhary",
      "Prachet Dev Singh",
      "Ankit Jha"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02513",
    "title": "Decentralized Fairness Aware Multi Task Federated Learning for VR Network",
    "abstract": "Wireless connectivity promises to unshackle virtual reality (VR) experiences, allowing users to engage from anywhere, anytime. However, delivering seamless, high-quality, real-time VR video wirelessly is challenging due to the stringent quality of experience requirements, low latency constraints, and limited VR device capabilities. This paper addresses these challenges by introducing a novel decentralized multi task fair federated learning (DMTFL) based caching that caches and prefetches each VR user's field of view (FOV) at base stations (BSs) based on the caching strategies tailored to each BS. In federated learning (FL) in its naive form, often biases toward certain users, and a single global model fails to capture the statistical heterogeneity across users and BSs. In contrast, the proposed DMTFL algorithm personalizes content delivery by learning individual caching models at each BS. These models are further optimized to perform well under any target distribution, while providing theoretical guarantees via Rademacher complexity and a probably approximately correct (PAC) bound on the loss. Using a realistic VR head-tracking dataset, our simulations demonstrate the superiority of our proposed DMTFL algorithm compared to baseline algorithms.",
    "authors": [
      "Krishnendu S. Tharakan",
      "Carlo Fischione"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02694",
    "title": "Embedding networks with the random walk first return time distribution",
    "abstract": "We propose the first return time distribution (FRTD) of a random walk as an interpretable and mathematically grounded node embedding. The FRTD assigns a probability mass function to each node, allowing us to define a distance between any pair of nodes using standard metrics for discrete distributions. We present several arguments to motivate the FRTD embedding. First, we show that FRTDs are strictly more informative than eigenvalue spectra, yet insufficient for complete graph identification, thus placing FRTD equivalence between cospectrality and isomorphism. Second, we argue that FRTD equivalence between nodes captures structural similarity. Third, we empirically demonstrate that the FRTD embedding outperforms manually designed graph metrics in network alignment tasks. Finally, we show that random networks that approximately match the FRTD of a desired target also preserve other salient features. Together these results demonstrate the FRTD as a simple and mathematically principled embedding for complex networks.",
    "authors": [
      "Vedanta Thapar",
      "Renaud Lambiotte",
      "George T. Cantwell"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02716",
    "title": "Menta: A Small Language Model for On-Device Mental Health Prediction",
    "abstract": "Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: this https URL",
    "authors": [
      "Tianyi Zhang",
      "Xiangyuan Xue",
      "Lingyan Ruan",
      "Shiya Fu",
      "Feng Xia",
      "Simon D'Alfonso",
      "Vassilis Kostakos",
      "Ting Dang",
      "Hong Jia"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02787",
    "title": "Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols",
    "abstract": "Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic manipulation, yet they remain limited in failure diagnosis and learning from failures. Additionally, existing failure datasets are mostly generated programmatically in simulation, which limits their generalization to the real world. In light of these, we introduce ViFailback, a framework designed to diagnose robotic manipulation failures and provide both textual and visual correction guidance. Our framework utilizes explicit visual symbols to enhance annotation efficiency. We further release the ViFailback dataset, a large-scale collection of 58,126 Visual Question Answering (VQA) pairs along with their corresponding 5,202 real-world manipulation trajectories. Based on the dataset, we establish ViFailback-Bench, a benchmark of 11 fine-grained VQA tasks designed to assess the failure diagnosis and correction abilities of Vision-Language Models (VLMs), featuring ViFailback-Bench Lite for closed-ended and ViFailback-Bench Hard for open-ended evaluation. To demonstrate the effectiveness of our framework, we built the ViFailback-8B VLM, which not only achieves significant overall performance improvement on ViFailback-Bench but also generates visual symbols for corrective action guidance. Finally, by integrating ViFailback-8B with a VLA model, we conduct real-world robotic experiments demonstrating its ability to assist the VLA model in recovering from failures. Project Website: this https URL",
    "authors": [
      "Xianchao Zeng",
      "Xinyu Zhou",
      "Youcheng Li",
      "Jiayou Shi",
      "Tianle Li",
      "Liangming Chen",
      "Lei Ren",
      "Yong-Lu Li"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02822",
    "title": "Decryption Through Polynomial Ambiguity: Noise-Enhanced High-Memory Convolutional Codes for Post-Quantum Cryptography",
    "abstract": "We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.",
    "authors": [
      "Meir Ariel"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02830",
    "title": "Defense That Attacks: How Robust Models Become Better Attackers",
    "abstract": "Deep learning has achieved great success in computer vision, but remains vulnerable to adversarial attacks. Adversarial training is the leading defense designed to improve model robustness. However, its effect on the transferability of attacks is underexplored. In this work, we ask whether adversarial training unintentionally increases the transferability of adversarial examples. To answer this, we trained a diverse zoo of 36 models, including CNNs and ViTs, and conducted comprehensive transferability experiments. Our results reveal a clear paradox: adversarially trained (AT) models produce perturbations that transfer more effectively than those from standard models, which introduce a new ecosystem risk. To enable reproducibility and further study, we release all models, code, and experimental scripts. Furthermore, we argue that robustness evaluations should assess not only the resistance of a model to transferred attacks but also its propensity to produce transferable adversarial examples.",
    "authors": [
      "Mohamed Awad",
      "Mahmoud Akrm",
      "Walid Gomaa"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02851",
    "title": "SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots",
    "abstract": "Visual traversability estimation is critical for autonomous navigation, but existing VLM-based methods rely on hand-crafted prompts, generalize poorly across embodiments, and output only traversability maps, leaving trajectory generation to slow external planners. We propose SwarmDiffusion, a lightweight end-to-end diffusion model that jointly predicts traversability and generates a feasible trajectory from a single RGB image. To remove the need for annotated or planner-produced paths, we introduce a planner-free trajectory construction pipeline based on randomized waypoint sampling, Bezier smoothing, and regularization enforcing connectivity, safety, directionality, and path thinness. This enables learning stable motion priors without demonstrations. SwarmDiffusion leverages VLM-derived supervision without prompt engineering and conditions the diffusion process on a compact embodiment state, producing physically consistent, traversable paths that transfer across different robot platforms. Across indoor environments and two embodiments (quadruped and aerial), the method achieves 80-100% navigation success and 0.09s inference, and adapts to a new robot using only-500 additional visual samples. It generalizes reliably to unseen environments in simulation and real-world trials, offering a scalable, prompt-free approach to unified traversability reasoning and trajectory generation.",
    "authors": [
      "Iana Zhura",
      "Sausar Karaf",
      "Faryal Batool",
      "Nipun Dhananjaya Weerakkodi Mudalige",
      "Valerii Serpiva",
      "Ali Alridha Abdulkarim",
      "Aleksey Fedoseev",
      "Didar Seyidov",
      "Hajira Amjad",
      "Dzmitry Tsetserukou"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02852",
    "title": "Adaptive Decentralized Federated Learning for Robust Optimization",
    "abstract": "In decentralized federated learning (DFL), the presence of abnormal clients, often caused by noisy or poisoned data, can significantly disrupt the learning process and degrade the overall robustness of the model. Previous methods on this issue often require a sufficiently large number of normal neighboring clients or prior knowledge of reliable clients, which reduces the practical applicability of DFL. To address these limitations, we develop here a novel adaptive DFL (aDFL) approach for robust estimation. The key idea is to adaptively adjust the learning rates of clients. By assigning smaller rates to suspicious clients and larger rates to normal clients, aDFL mitigates the negative impact of abnormal clients on the global model in a fully adaptive way. Our theory does not put any stringent conditions on neighboring nodes and requires no prior knowledge. A rigorous convergence analysis is provided to guarantee the oracle property of aDFL. Extensive numerical experiments demonstrate the superior performance of the aDFL method.",
    "authors": [
      "Shuyuan Wu",
      "Feifei Wang",
      "Yuan Gao",
      "Rui Wang",
      "Hansheng Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02895",
    "title": "MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm",
    "abstract": "We present MindGPT-4ov, a multimodal large language model (MLLM) that introduces a general post-training paradigm spanning data production, model training, and efficient deployment. It achieves state-of-the-art performance across multiple benchmarks at low cost, effectively enhancing the foundational capabilities of MLLMs and the generalization ability. Focusing on data construction, supervised fine-tuning strategies, and multimodal reinforcement learning methods, this work proposes three key innovations: (1) An information density-based data generation scheme, integrated with a dual-dimensional tree-structured label system, enabling automated generation of high-quality cross-domain data. (2) A collaborative curriculum supervised fine-tuning approach that balances the injection of domain-specific knowledge with the preservation of general capabilities. (3) A hybrid reinforcement learning paradigm that enhances reasoning ability while simultaneously addressing multi-objective optimization such as diversity exploration, maintenance of multimodal perception, and response conciseness. Moreover, we implement a series of infrastructure optimizations, such as 5D parallel training, operator optimization, and inference quantization to enhance training and inference efficiency while reducing the cost of domain adaptation. Experimental results demonstrate that the MindGPT-4ov model outperforms state-of-the-art models on benchmarks such as MMBench, MMStar, MathVision, and MathVista. In addition, MindGPT-4ov also demonstrates superior user experience in vertical domain tasks, enabling a seamless transition from academic research to industrial deployment. MindGPT-4ov provides a general post-training paradigm applicable to a wide range of MLLMs. The model weights, datasets, and code for the Qwen3-VL-based variants will be recently open-sourced to support the community's development of MLLMs.",
    "authors": [
      "Wei Chen",
      "Chaoqun Du",
      "Feng Gu",
      "Wei He",
      "Qizhen Li",
      "Zide Liu",
      "Xuhao Pan",
      "Chang Ren",
      "Xudong Rao",
      "Chenfeng Wang",
      "Tao Wei",
      "Chengjun Yu",
      "Pengfei Yu",
      "Yufei Zheng",
      "Chunpeng Zhou",
      "Pan Zhou",
      "Xuhan Zhu"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02901",
    "title": "Fairy2i: Training Complex LLMs from Real LLMs with All Parameters in $\\{\\pm 1, \\pm i\\}$",
    "abstract": "Large language models (LLMs) have revolutionized artificial intelligence, yet their massive memory and computational demands necessitate aggressive quantization, increasingly pushing representations toward the theoretical limit of a single bit. While complex-valued LLMs, such as iFairy, offer a superior chance for low-bit representation compared to real-valued counterparts, they require training from scratch, preventing the utilization of the vast ecosystem of pre-trained real-valued foundation models. Here we present Fairy2i, a universal framework that transforms pre-trained real-valued layers into an equivalent widely-linear complex form, enabling extremely low-bit quantization while reusing existing checkpoints. By proving a lossless mathematical equivalence between real and widely-linear maps, we convert standard Transformers into the complex domain and employ a phase-aware quantization scheme with a highly efficient codebook of fourth roots of unity. Furthermore, we introduce a recursive residual quantization mechanism that iteratively minimizes quantization error, allowing inference to proceed via efficient multiplication-free accumulation. We demonstrate that Fairy2i restores the performance of LLaMA-2 7B at an effective 2-bit precision to levels nearly comparable with full-precision baselines, significantly outperforming state-of-the-art real-valued binary and ternary quantization methods. This work bridges the gap between the representational efficiency of complex-valued arithmetic and the practical utility of pre-trained models, paving a new way for efficient inference on commodity hardware.",
    "authors": [
      "Feiyu Wang",
      "Xinyu Tan",
      "Bokai Huang",
      "Yihao Zhang",
      "Guoan Wang",
      "Peizhuang Cong",
      "Tong Yang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02906",
    "title": "MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding",
    "abstract": "Understanding high-resolution images remains a significant challenge for multimodal large language models (MLLMs). Recent study address this issue by dividing the image into smaller crops and computing the semantic similarity between each crop and a query using a pretrained retrieval-augmented generation (RAG) model. The most relevant crops are then selected to localize the target object and suppress irrelevant information. However, such crop-based processing can fragment complete objects across multiple crops, thereby disrupting the computation of semantic similarity. In our experiments, we find that image crops of objects with different sizes are better handled at different resolutions. Based on this observation, we propose Multi-resolution Retrieval-Detection (MRD), a training-free framework for high-resolution image understanding. To address the issue of semantic similarity bias caused by objects being split across different image crops, we propose a multi-resolution semantic fusion method, which integrates semantic similarity maps obtained at different resolutions to produce more accurate semantic information and preserve the integrity of target objects. Furthermore, to achieve direct localization of target objects at a global scale, we introduce an open-vocalbulary object detection (OVD) model that identifies object regions using a sliding-window this http URL on high-resolution image understanding benchmarks using different MLLMs demonstrate the effectiveness of our approach.",
    "authors": [
      "Fan Yang",
      "Kaihao Zhang"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02933",
    "title": "LoVoRA: Text-guided and Mask-free Video Object Removal and Addition with Learnable Object-aware Localization",
    "abstract": "Text-guided video editing, particularly for object removal and addition, remains a challenging task due to the need for precise spatial and temporal consistency. Existing methods often rely on auxiliary masks or reference images for editing guidance, which limits their scalability and generalization. To address these issues, we propose LoVoRA, a novel framework for mask-free video object removal and addition using object-aware localization mechanism. Our approach utilizes a unique dataset construction pipeline that integrates image-to-video translation, optical flow-based mask propagation, and video inpainting, enabling temporally consistent edits. The core innovation of LoVoRA is its learnable object-aware localization mechanism, which provides dense spatio-temporal supervision for both object insertion and removal tasks. By leveraging a Diffusion Mask Predictor, LoVoRA achieves end-to-end video editing without requiring external control signals during inference. Extensive experiments and human evaluation demonstrate the effectiveness and high-quality performance of LoVoRA. this https URL",
    "authors": [
      "Zhihan Xiao",
      "Lin Liu",
      "Yixin Gao",
      "Xiaopeng Zhang",
      "Haoxuan Che",
      "Songping Mai",
      "Qi Tian"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03000",
    "title": "DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling",
    "abstract": "Understanding the dynamic physical world, characterized by its evolving 3D structure, real-world motion, and semantic content with textual descriptions, is crucial for human-agent interaction and enables embodied agents to perceive and act within real environments with human-like capabilities. However, existing datasets are often derived from limited simulators or utilize traditional Structurefrom-Motion for up-to-scale annotation and offer limited descriptive captioning, which restricts the capacity of foundation models to accurately interpret real-world dynamics from monocular videos, commonly sourced from the internet. To bridge these gaps, we introduce DynamicVerse, a physical-scale, multimodal 4D world modeling framework for dynamic real-world video. We employ large vision, geometric, and multimodal models to interpret metric-scale static geometry, real-world dynamic motion, instance-level masks, and holistic descriptive captions. By integrating window-based Bundle Adjustment with global optimization, our method converts long real-world video sequences into a comprehensive 4D multimodal format. DynamicVerse delivers a large-scale dataset consisting of 100K+ videos with 800K+ annotated masks and 10M+ frames from internet videos. Experimental evaluations on three benchmark tasks, namely video depth estimation, camera pose estimation, and camera intrinsics estimation, demonstrate that our 4D modeling achieves superior performance in capturing physical-scale measurements with greater global accuracy than existing methods.",
    "authors": [
      "Kairun Wen",
      "Yuzhi Huang",
      "Runyu Chen",
      "Hui Zheng",
      "Yunlong Lin",
      "Panwang Pan",
      "Chenxin Li",
      "Wenyan Cong",
      "Jian Zhang",
      "Junbin Lu",
      "Chenguo Lin",
      "Dilin Wang",
      "Zhicheng Yan",
      "Hongyu Xu",
      "Justin Theiss",
      "Yue Huang",
      "Xinghao Ding",
      "Rakesh Ranjan",
      "Zhiwen Fan"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03028",
    "title": "SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control",
    "abstract": "Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In this work, we present Score-Matching Motion Priors (SMP), which leverages pre-trained motion diffusion models and score distillation sampling (SDS) to create reusable task-agnostic motion priors. SMPs can be pre-trained on a motion dataset, independent of any control policy or task. Once trained, SMPs can be kept frozen and reused as general-purpose reward functions to train policies to produce naturalistic behaviors for downstream tasks. We show that a general motion prior trained on large-scale datasets can be repurposed into a variety of style-specific priors. Furthermore SMP can compose different styles to synthesize new styles not present in the original dataset. Our method produces high-quality motion comparable to state-of-the-art adversarial imitation learning methods through reusable and modular motion priors. We demonstrate the effectiveness of SMP across a diverse suite of control tasks with physically simulated humanoid characters. Video demo available at this https URL",
    "authors": [
      "Yuxuan Mu",
      "Ziyu Zhang",
      "Yi Shi",
      "Minami Matsumoto",
      "Kotaro Imamura",
      "Guy Tevet",
      "Chuan Guo",
      "Michael Taylor",
      "Chang Shu",
      "Pengcheng Xi",
      "Xue Bin Peng"
    ],
    "primary_category": "cs.GR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03043",
    "title": "OneThinker: All-in-one Reasoning Model for Image and Video",
    "abstract": "Reinforcement learning (RL) has recently achieved remarkable success in eliciting visual reasoning within Multimodal Large Language Models (MLLMs). However, existing approaches typically train separate models for different tasks and treat image and video reasoning as disjoint domains. This results in limited scalability toward a multimodal reasoning generalist, which restricts practical versatility and hinders potential knowledge sharing across tasks and modalities. To this end, we propose OneThinker, an all-in-one reasoning model that unifies image and video understanding across diverse fundamental visual tasks, including question answering, captioning, spatial and temporal grounding, tracking, and segmentation. To achieve this, we construct the OneThinker-600k training corpus covering all these tasks and employ commercial models for CoT annotation, resulting in OneThinker-SFT-340k for SFT cold start. Furthermore, we propose EMA-GRPO to handle reward heterogeneity in multi-task RL by tracking task-wise moving averages of reward standard deviations for balanced optimization. Extensive experiments on diverse visual benchmarks show that OneThinker delivers strong performance on 31 benchmarks, across 10 fundamental visual understanding tasks. Moreover, it exhibits effective knowledge transfer between certain tasks and preliminary zero-shot generalization ability, marking a step toward a unified multimodal reasoning generalist. All code, model, and data are released.",
    "authors": [
      "Kaituo Feng",
      "Manyuan Zhang",
      "Hongyu Li",
      "Kaixuan Fan",
      "Shuang Chen",
      "Yilei Jiang",
      "Dian Zheng",
      "Peiwen Sun",
      "Yiyuan Zhang",
      "Haoze Sun",
      "Yan Feng",
      "Peng Pei",
      "Xunliang Cai",
      "Xiangyu Yue"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.05025",
    "title": "Unbiased Kinetic Langevin Monte Carlo with Inexact Gradients",
    "abstract": "We present an unbiased method for Bayesian posterior means based on kinetic Langevin dynamics that combines advanced splitting methods with enhanced gradient approximations. Our approach avoids Metropolis correction by coupling Markov chains at different discretization levels in a multilevel Monte Carlo approach. Theoretical analysis demonstrates that our proposed estimator is unbiased, attains finite variance, and satisfies a central limit theorem. It can achieve accuracy $\\epsilon>0$ for estimating expectations of Lipschitz functions in $d$ dimensions with $\\mathcal{O}(d^{1/4}\\epsilon^{-2})$ expected gradient evaluations, without assuming warm start. We exhibit similar bounds using both approximate and stochastic gradients, and our method's computational cost is shown to scale independently of the size of the dataset. The proposed method is tested using a multinomial regression problem on the MNIST dataset and a Poisson regression model for soccer scores. Experiments indicate that the number of gradient evaluations per effective sample is independent of dimension, even when using inexact gradients. For product distributions, we give dimension-independent variance bounds. Our results demonstrate that in large-scale applications, the unbiased algorithm we present can be 2-3 orders of magnitude more efficient than the ``gold-standard\" randomized Hamiltonian Monte Carlo.",
    "authors": [
      "Neil K. Chada",
      "Benedict Leimkuhler",
      "Daniel Paulin",
      "Peter A. Whalley"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.19062",
    "title": "Oracle Separations for the Quantum-Classical Polynomial Hierarchy",
    "abstract": "We study the quantum-classical polynomial hierarchy, QCPH, which is the class of languages solvable by a constant number of alternating classical quantifiers followed by a quantum verifier. Our main result is that QCPH is infinite relative to a random oracle (previously, this was not even known relative to any oracle). We further prove that higher levels of PH are not contained in lower levels of QCPH relative to a random oracle; this is a strengthening of the somewhat recent result that PH is infinite relative to a random oracle (Rossman, Servedio, and Tan 2016). The oracle separation requires lower bounding a certain type of low-depth alternating circuit with some quantum gates. To establish this, we give a new switching lemma for quantum algorithms which may be of independent interest. Our lemma says that for any $d$, if we apply a random restriction to a function $f$ with quantum query complexity $\\mathrm{Q}(f)\\le n^{1/3}$, the restricted function becomes exponentially close (in terms of $d$) to a depth-$d$ decision tree. Our switching lemma works even in a \"worst-case\" sense, in that only the indices to be restricted are random; the values they are restricted to are chosen adversarially. Moreover, the switching lemma also works for polynomial degree in place of quantum query complexity.",
    "authors": [
      "Avantika Agarwal",
      "Shalev Ben-David"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.07031",
    "title": "Large Language Models: An Applied Econometric Framework",
    "abstract": "Large language models (LLMs) enable researchers to analyze text at unprecedented scale and minimal cost. Researchers can now revisit old questions and tackle novel ones with rich data. We provide an econometric framework for realizing this potential in two empirical uses. For prediction problems -- forecasting outcomes from text -- valid conclusions require ``no training leakage'' between the LLM's training data and the researcher's sample, which can be enforced through careful model choice and research design. For estimation problems -- automating the measurement of economic concepts for downstream analysis -- valid downstream inference requires combining LLM outputs with a small validation sample to deliver consistent and precise estimates. Absent a validation sample, researchers cannot assess possible errors in LLM outputs, and consequently seemingly innocuous choices (which model, which prompt) can produce dramatically different parameter estimates. When used appropriately, LLMs are powerful tools that can expand the frontier of empirical economics.",
    "authors": [
      "Jens Ludwig",
      "Sendhil Mullainathan",
      "Ashesh Rambachan"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.07057",
    "title": "Interactive and Hybrid Imitation Learning: Provably Beating Behavior Cloning",
    "abstract": "Imitation learning (IL) is a paradigm for learning sequential decision making policies from experts, leveraging offline demonstrations, interactive annotations, or both. Recent advances show that when annotation cost is tallied per trajectory, Behavior Cloning (BC) which relies solely on offline demonstrations cannot be improved in general, leaving limited conditions for interactive methods such as DAgger to help. We revisit this conclusion and prove that when the annotation cost is measured per state, algorithms using interactive annotations can provably outperform BC. Specifically: (1) we show that Stagger, a one sample per round variant of DAgger, provably beats BC under low recovery cost settings; (2) we initiate the study of hybrid IL where the agent learns from offline demonstrations and interactive annotations. We propose Warm Stagger whose learning guarantee is not much worse than using either data source alone. Furthermore, motivated by compounding error and cold start problem in imitation learning practice, we give an MDP example in which Warm Stagger has significant better annotation cost; (3) experiments on MuJoCo continuous control tasks confirm that, with modest cost ratio between interactive and offline annotations, interactive and hybrid approaches consistently outperform BC. To the best of our knowledge, our work is the first to highlight the benefit of state wise interactive annotation and hybrid feedback in imitation learning.",
    "authors": [
      "Yichen Li",
      "Chicheng Zhang"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.01496",
    "title": "ORACLE: A Real-Time, Hierarchical, Deep-Learning Photometric Classifier for the LSST",
    "abstract": "We present ORACLE, the first hierarchical deep-learning model for real-time, context-aware classification of transient and variable astrophysical phenomena. ORACLE is a recurrent neural network with Gated Recurrent Units (GRUs), and has been trained using a custom hierarchical cross-entropy loss function to provide high-confidence classifications along an observationally-driven taxonomy with as little as a single photometric observation. Contextual information for each object, including host galaxy photometric redshift, offset, ellipticity and brightness, is concatenated to the light curve embedding and used to make a final prediction. Training on $\\sim$0.5M events from the Extended LSST Astronomical Time-Series Classification Challenge, we achieve a top-level (Transient vs Variable) macro-averaged precision of 0.96 using only 1 day of photometric observations after the first detection in addition to contextual information, for each event; this increases to $>$0.99 once 64 days of the light curve has been obtained, and 0.83 at 1024 days after first detection for 19-way classification (including supernova sub-types, active galactic nuclei, variable stars, microlensing events, and kilonovae). We also compare ORACLE with other state-of-the-art classifiers and report comparable performance for the 19-way classification task, in addition to delivering accurate top-level classifications much earlier. The code and model weights used in this work are publicly available at our associated GitHub repository ( this https URL ).",
    "authors": [
      "Ved G. Shah",
      "Alex Gagliano",
      "Konstantin Malanchev",
      "Gautham Narayan",
      "Alex I. Malz",
      "LSST Dark Energy Science Collaboration"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.01552",
    "title": "Multi-view Bayesian optimisation in an input-output reduced space for engineering design",
    "abstract": "Bayesian optimisation is an adaptive sampling strategy for constructing a Gaussian process surrogate to efficiently search for the global minimum of a black-box computational model. Gaussian processes have limited applicability in engineering design problems, which usually have many design variables but typically a low intrinsic dimensionality. Their scalability can be significantly improved by identifying a low-dimensional space of latent variables that serve as inputs to the Gaussian process. In this paper, we introduce a multi-view learning strategy that considers both the input design variables and output data representing the objective or constraint functions, to identify a low-dimensional latent subspace. Adopting a fully probabilistic viewpoint, we use probabilistic partial least squares (PPLS) to learn an orthogonal mapping from the design variables to the latent variables using training data consisting of inputs and outputs of the black-box computational model. The latent variables and posterior probability densities of the PPLS and Gaussian process models are determined sequentially and iteratively, with retraining occurring at each adaptive sampling iteration. We compare the proposed probabilistic partial least squares Bayesian optimisation (PPLS-BO) strategy with its deterministic counterpart, partial least squares Bayesian optimisation (PLS-BO), and classical Bayesian optimisation, demonstrating significant improvements in convergence to the global minimum.",
    "authors": [
      "Thomas A. Archbold",
      "Ieva Kazlauskaite",
      "Fehmi Cirak"
    ],
    "primary_category": "stat.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.17096",
    "title": "Why is the estimation of metaorder impact with public market data so challenging?",
    "abstract": "Estimating market impact and transaction costs of large trades (metaorders) is a very important topic in finance. However, using models of price and trade based on public market data provide average price trajectories which are qualitatively different from what is observed during real metaorder executions: the price increases linearly, rather than in a concave way, during the execution and the amount of reversion after its end is very limited. We claim that this is a generic phenomenon due to the fact that even sophisticated statistical models are unable to correctly describe the origin of the autocorrelation of the order flow. We propose a modified Transient Impact Model which provides more realistic trajectories by assuming that only a fraction of the metaorder trading triggers market order flow. Interestingly, in our model there is a critical condition on the kernels of the price and order flow equations in which market impact becomes permanent.",
    "authors": [
      "Manuel Naviglio",
      "Giacomo Bormetti",
      "Francesco Campigli",
      "German Rodikov",
      "Fabrizio Lillo"
    ],
    "primary_category": "q-fin.TR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.16800",
    "title": "A New Solution for Cooperative Game with Public Externalities",
    "abstract": "This study proposes a novel solution concept--the w-value--for cooperative games with public externalities. The w-value is axiomatically founded on three principles: Pareto Optimality (PO), Market Equilibrium (ME), and Fiscal Balance (FB), which together ensure a fair and economically sound distribution of gains. We establish its existence, uniqueness, and an accompanying implementation mechanism. A key theoretical advantage is its strong stability: the w-value lies within the core, specifically the {\\gamma}-core making it resistant to coalitional deviations. Moreover, its computational efficiency facilitates practical application to complex real-world problems, offering a clear advantage over more cumbersome alternatives. These properties make the w-value a superior framework for analyzing cooperation under public externalities. A numerical illustration demonstrates the step-by-step calculation process. Finally, we apply the concept to international climate negotiations, showing how it provides a theoretical rationale for the shift from rigid mandatory emission reduction systems toward the flexible structure of Nationally Determined Contributions.",
    "authors": [
      "Juanjuan Fan",
      "Ying Wang"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.17212",
    "title": "A Tractable Two-Step Linear Mixing Model Solved with Second-Order Optimization for Spectral Unmixing under Variability",
    "abstract": "In this paper, we propose a Two-Step Linear Mixing Model (2LMM) that bridges the gap between model complexity and computational tractability. The model achieves this by introducing two distinct scaling steps: an endmember scaling step across the image, and another for pixel-wise scaling. We show that this model leads to only a mildly non-convex optimization problem, which we solve with an optimization algorithm that incorporates second-order information. To the authors' knowledge, this work represents the first application of second-order optimization techniques to solve a spectral unmixing problem that models endmember variability. Our method is highly robust, as it requires virtually no hyperparameter tuning and can therefore be used easily and quickly in a wide range of unmixing tasks. We show through extensive experiments on both simulated and real data that the new model is competitive and in some cases superior to the state of the art in unmixing. The model also performs very well in challenging scenarios, such as blind unmixing.",
    "authors": [
      "Xander Haijen",
      "Bikram Koirala",
      "Xuanwen Tao",
      "Paul Scheunders"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.17641",
    "title": "Mesoscale Modeling of an Active Colloid's Motion",
    "abstract": "This paper uses Cahn-Hilliard equations as a mesoscale model of the motion of active colloids. The model attempts to capture the driving mechanisms and qualitative behavior of the isotropic colloids originally proposed by J. Decayeaux in 2021. We compare our model against the single colloid behavior presented in that work, as well as against multi-colloid systems.",
    "authors": [
      "Matthew Dobson",
      "David Masse"
    ],
    "primary_category": "cond-mat.soft",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20772",
    "title": "Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?",
    "abstract": "Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability - ranging from ordinal level comparability to full cardinal comparability - together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.",
    "authors": [
      "Ilia Shilov",
      "Ezzat Elokda",
      "Sophie Hall",
      "Heinrich H. Nax",
      "Saverio Bolognani"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.08722",
    "title": "Deriving the Gradients of Some Popular Optimal Transport Algorithms",
    "abstract": "In this note, I review entropy-regularized Monge-Kantorovich problem in Optimal Transport, and derive the gradients of several popular algorithms popular in Computational Optimal Transport, including the Sinkhorn algorithms, Wasserstein Barycenter algorithms, and the Wasserstein Dictionary Learning algorithms.",
    "authors": [
      "Fangzhou Xie"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.09342",
    "title": "Computationally Efficient Signal Detection with Unknown Bandwidths",
    "abstract": "Signal detection in environments with unknown signal bandwidth and time intervals is a fundamental problem in adversarial and spectrum-sharing scenarios. This paper addresses the problem of detecting signals occupying unknown degrees of freedom from non-coherent power measurements, where the signal is constrained to an interval in one dimension or a hyper-cube in multiple dimensions. A GLRT is derived, resulting in a straightforward metric involving normalized average signal energy for each candidate signal set. We present bounds on false alarm and missed detection probabilities, demonstrating their dependence on SNR and signal set sizes. To overcome the inherent computational complexity of exhaustive searches, we propose a computationally efficient binary search method, reducing the complexity from O(N^2) to O(N) for one-dimensional cases. Simulations indicate that the method maintains performance near exhaustive searches and achieves asymptotic consistency, with interval-of-overlap converging to one under constant SNR as measurement size increases. The simulation studies also demonstrate superior performance and reduced complexity compared to contemporary neural network-based approaches, specifically outperforming custom-trained U-Net models in spectrum detection tasks.",
    "authors": [
      "Ali Rasteh",
      "Sundeep Rangan"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.21438",
    "title": "Wasserstein-Aitchison GAN for angular measures of multivariate extremes",
    "abstract": "Economically responsible mitigation of multivariate extreme risks -- extreme rainfall in a large area, huge variations of many stock prices, widespread breakdowns in transportation systems -- requires estimates of the probabilities that such risks will materialize in the future. This paper develops a new method, Wasserstein--Aitchison Generative Adversarial Networks (WA-GAN) to, which provides simulated values of $d$-dimensional multivariate extreme events and which can hence be used to give estimates of such probabilities. The main hypothesis is that, after transforming the observations to the unit-Pareto scale, their distribution is regularly varying in the sense that the distributions of their radial and angular components (with respect to the $L_1$-norm) converge and become asymptotically independent as the radius gets large. The method is a combination of standard extreme value analysis modeling of the tails of the marginal distributions with nonparametric GAN modeling of the angular distribution. For the latter, the angular values are transformed to Aitchison coordinates in a full $(d-1)$-dimensional linear space, and a Wasserstein GAN is trained on these coordinates and used to generate new values. A reverse transformation is then applied to these values and gives simulated values on the original data scale. Our method is applied to simulated data and to a financial data set from the Kenneth French Data Library. The method shows good performance compared to other existing methods in the literature, both in terms of capturing the dependence structure of the extremes in the data and in generating accurate new extremes.",
    "authors": [
      "Stéphane Lhaut",
      "Holger Rootzén",
      "Johan Segers"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.05127",
    "title": "PixCell: A generative foundation model for digital histopathology images",
    "abstract": "The digitization of histology slides has revolutionized pathology, providing massive datasets for cancer diagnosis and research. Self-supervised and vision-language models have been shown to effectively mine large pathology datasets to learn discriminative representations. On the other hand, there are unique problems in pathology, such as annotated data scarcity, privacy regulations in data sharing, and inherently generative tasks like virtual staining. Generative models, capable of synthesizing realistic and diverse images, present a compelling solution to address these problems through image synthesis. We introduce PixCell, the first generative foundation model for histopathology images. PixCell is a diffusion model trained on PanCan-30M, a large, diverse dataset derived from 69,184 H&E-stained whole slide images of various cancer types. We employ a progressive training strategy and a self-supervision-based conditioning that allows us to scale up training without any human-annotated data. By conditioning on real slides, the synthetic images capture the properties of the real data and can be used as data augmentation for small-scale datasets to boost classification performance. We prove the foundational versatility of PixCell by applying it to two generative downstream tasks: privacy-preserving synthetic data generation and virtual IHC staining. PixCell's high-fidelity conditional generation enables institutions to use their private data to synthesize highly realistic, site-specific surrogate images that can be shared in place of raw patient data. Furthermore, using datasets of roughly paired H&E-IHC tiles, we learn to translate PixCell's conditioning from H&E to multiple IHC stains, allowing the generation of IHC images from H&E inputs. Our trained models are publicly released to accelerate research in computational pathology.",
    "authors": [
      "Srikar Yellapragada",
      "Alexandros Graikos",
      "Zilinghan Li",
      "Kostas Triaridis",
      "Varun Belagali",
      "Tarak Nath Nandi",
      "Karen Bai",
      "Beatrice S. Knudsen",
      "Tahsin Kurc",
      "Rajarsi R. Gupta",
      "Prateek Prasanna",
      "Ravi K Madduri",
      "Joel Saltz",
      "Dimitris Samaras"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.07150",
    "title": "Class conditional conformal prediction for multiple inputs by p-value aggregation",
    "abstract": "Conformal prediction methods are statistical tools designed to quantify uncertainty and generate predictive sets with guaranteed coverage probabilities. This work introduces an innovative refinement to these methods for classification tasks, specifically tailored for scenarios where multiple observations (multi-inputs) of a single instance are available at prediction time. Our approach is particularly motivated by applications in citizen science, where multiple images of the same plant or animal are captured by individuals. Our method integrates the information from each observation into conformal prediction, enabling a reduction in the size of the predicted label set while preserving the required class-conditional coverage guarantee. The approach is based on the aggregation of conformal p-values computed from each observation of a multi-input. By exploiting the exact distribution of these p-values, we propose a general aggregation framework using an abstract scoring function, encompassing many classical statistical tools. Knowledge of this distribution also enables refined versions of standard strategies, such as majority voting. We evaluate our method on simulated and real data, with a particular focus on Pl@ntNet, a prominent citizen science platform that facilitates the collection and identification of plant species through user-submitted images.",
    "authors": [
      "Jean-Baptiste Fermanian",
      "Mohamed Hebiri",
      "Joseph Salmon"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.09050",
    "title": "Learning to Solve Constrained Bilevel Control Co-Design Problems",
    "abstract": "Learning to Optimize (L2O) is a subfield of machine learning (ML) in which ML models are trained to solve parametric optimization problems. The general goal is to learn a fast approximator of solutions to constrained optimization problems, as a function of their defining parameters. Prior L2O methods focus almost entirely on single-level programs, in contrast to the bilevel programs, whose constraints are themselves expressed in terms of optimization subproblems. Bilevel programs have numerous important use cases but are notoriously difficult to solve, particularly under stringent time demands. This paper proposes a framework for learning to solve a broad class of challenging bilevel optimization problems, by leveraging modern techniques for differentiation through optimization problems. The framework is illustrated on an array of synthetic bilevel programs, as well as challenging control system co-design problems, showing how neural networks can be trained as efficient approximators of parametric bilevel optimization.",
    "authors": [
      "James Kotary",
      "Himanshu Sharma",
      "Ethan King",
      "Draguna Vrabie",
      "Ferdinando Fioretto",
      "Jan Drgona"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.19410",
    "title": "Reconstruction in the Calderón problem on a fixed partition from finite and partial boundary data",
    "abstract": "This short note modifies a reconstruction method by the author (Comm. PDE, 45(9):1118-1133, 2020), for reconstructing piecewise constant conductivities in the Calderón problem (electrical impedance tomography). In the former paper, a layering assumption and the local Neumann-to-Dirichlet map were needed since the piecewise constant partition also was assumed unknown. Here I show how to modify the method in case the partition is known, for general piecewise constant conductivities and only a finite number of partial boundary measurements. Moreover, no lower/upper bounds on the unknown conductivity are needed.",
    "authors": [
      "Henrik Garde"
    ],
    "primary_category": "math.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20975",
    "title": "Locally Adaptive Conformal Inference for Operator Models",
    "abstract": "Operator models are regression algorithms between Banach spaces of functions. They have become an increasingly critical tool for spatiotemporal forecasting and physics emulation, especially in high-stakes scenarios where robust, calibrated uncertainty quantification is required. We introduce Local Sliced Conformal Inference (LSCI), a distribution-free framework for generating function-valued, locally adaptive prediction sets for operator models. We prove finite-sample validity and derive a data-dependent upper bound on the coverage gap under local exchangeability. On synthetic Gaussian-process tasks and real applications (air quality monitoring, energy demand forecasting, and weather prediction), LSCI yields tighter sets with stronger adaptivity compared to conformal baselines. We also empirically demonstrate robustness against biased predictions and certain out-of-distribution noise regimes.",
    "authors": [
      "Trevor Harris",
      "Yan Liu"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.03758",
    "title": "TransUNet-GradCAM: A Hybrid Transformer-U-Net with Self-Attention and Explainable Visualizations for Foot Ulcer Segmentation",
    "abstract": "Automated segmentation of diabetic foot ulcers (DFUs) plays a critical role in clinical diagnosis, therapeutic planning, and longitudinal wound monitoring. However, this task remains challenging due to the heterogeneous appearance, irregular morphology, and complex backgrounds associated with ulcer regions in clinical photographs. Traditional convolutional neural networks (CNNs), such as U-Net, provide strong localization capabilities but struggle to model long-range spatial dependencies due to their inherently limited receptive fields. To address this, we employ the TransUNet architecture, a hybrid framework that integrates the global attention mechanism of Vision Transformers (ViTs) into the U-Net structure. This combination allows the model to extract global contextual features while maintaining fine-grained spatial resolution. We trained the model on the public Foot Ulcer Segmentation Challenge (FUSeg) dataset using a robust augmentation pipeline and a hybrid loss function to mitigate class imbalance. On the validation set, the model achieved a Dice Similarity Coefficient (F1-score) of 0.8799 using an optimized threshold of 0.4389. To ensure clinical transparency, we integrated Grad-CAM visualizations to highlight model focus areas. Furthermore, a clinical utility analysis demonstrated a strong correlation (Pearson r = 0.9631) between predicted and ground-truth wound areas. These outcomes demonstrate that our approach effectively integrates global and local feature extraction, offering a reliable, effective, and explainable solution for automated foot ulcer assessment.",
    "authors": [
      "Akwasi Asare",
      "Mary Sagoe",
      "Justice Williams Asare",
      "Stephen Edward Moore"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.13875",
    "title": "A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler",
    "abstract": "The Circle of Willis (CoW), vital for ensuring consistent blood flow to the brain, is closely linked to ischemic stroke. Accurate assessment of the CoW is important for identifying individuals at risk and guiding appropriate clinical management. Among existing imaging methods, Transcranial Color-coded Doppler (TCCD) offers unique advantages due to its radiation-free nature, affordability, and accessibility. However, reliable TCCD assessments depend heavily on operator expertise for identifying anatomical landmarks and performing accurate angle correction, which limits its widespread adoption. To address this challenge, we propose an AI-powered, real-time CoW auto-segmentation system capable of efficiently capturing cerebral arteries. No prior studies have explored AI-driven cerebrovascular segmentation using TCCD. In this work, we introduce a novel Attention-Augmented Wavelet YOLO (AAW-YOLO) network tailored for TCCD data, designed to provide real-time guidance for brain vessel segmentation in the CoW. We prospectively collected TCCD data comprising 738 annotated frames and 3,419 labeled artery instances to establish a high-quality dataset for model training and evaluation. The proposed AAW-YOLO demonstrated strong performance in segmenting both ipsilateral and contralateral CoW vessels, achieving an average Dice score of 0.901, IoU of 0.823, precision of 0.882, recall of 0.926, and mAP of 0.953, with a per-frame inference speed of 14.199 ms. This system offers a practical solution to reduce reliance on operator experience in TCCD-based cerebrovascular screening, with potential applications in routine clinical workflows and resource-constrained settings. Future research will explore bilateral modeling and larger-scale validation.",
    "authors": [
      "Wenxuan Zhang",
      "Shuai Li",
      "Xinyi Wang",
      "Yu Sun",
      "Hongyu Kang",
      "Pui Yuk Chryste Wan",
      "Jing Qin",
      "Yuanpeng Zhang",
      "Yong-Ping Zheng",
      "Sai-Kit Lam"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.08553",
    "title": "A Common Pipeline for Harmonizing Electronic Health Record Data for Translational Research",
    "abstract": "Despite the growing availability of Electronic Health Record (EHR) data, researchers often face substantial barriers in effectively using these data for translational research due to their complexity, heterogeneity, and lack of standardized tools and documentation. To address this critical gap, we introduce PEHRT, a common pipeline for harmonizing EHR data for translational research. PEHRT is a comprehensive, ready-to-use resource that includes open-source code, visualization tools, and detailed documentation to streamline the process of preparing EHR data for analysis. The pipeline provides tools to harmonize structured and unstructured EHR data to standardized ontologies to ensure consistency across diverse coding systems. In the presence of unmapped or heterogeneous local codes, PEHRT further leverages representation learning and pre-trained language models to generate robust embeddings that capture semantic relationships across sites to mitigate heterogeneity and enable integrative downstream analyses. PEHRT also supports cross-institutional co-training through shared representations, allowing participating sites to collaboratively refine embeddings and enhance generalizability without sharing individual-level data. The framework is data model-agnostic and can be seamlessly deployed across diverse healthcare systems to produce interoperable, research-ready datasets. By lowering the technical barriers to EHR-based research, PEHRT empowers investigators to transform raw clinical data into reproducible, analysis-ready resources for discovery and innovation.",
    "authors": [
      "Jessica Gronsbell",
      "Vidul Ayakulangara Panickan",
      "Doudou Zhou",
      "Chris Lin",
      "Thomas Charlon",
      "Chuan Hong",
      "Xin Xiong",
      "Linshanshan Wang",
      "Jianhui Gao",
      "Shirley Zhou",
      "Yuan Tian",
      "Yaqi Shi",
      "Ziming Gan",
      "Tianxi Cai"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12341",
    "title": "Exact Coset Sampling for Quantum Lattice Algorithms",
    "abstract": "In this work, we give a new completion of Chen's windowed-QFT lattice algorithm~\\citep{chen2024quantum}. This extra step, called Step~$9^\\dagger$, replaces the domain extension stage in Steps~8--9. The published Step~9 calls an amplitude periodicity lemma, yet its hypotheses break in the presence of affine offsets $\\boldsymbol{v}^*$. Our analysis finds a basic conflict between two design constraints. The lattice problem asks for high spectral resolution, so the method prefers wide time windows. The quadratic phase error of the state prefers narrow time windows. Assumption~A5 packages the spectral concentration and near-uniformity properties that we require from the front end. Under~A5, a direct $\\mathbb{Z}_M^n$ Fourier transform of the chirp-corrected coordinate state produces samples $\\boldsymbol{u}$ that satisfy $\\langle \\boldsymbol{b}, \\boldsymbol{u} \\rangle \\equiv 0 \\pmod{Q}$ with probability $1-\\mathrm{negl}(n)$ and are nearly uniform on the dual hyperplane $\\{\\boldsymbol{u} : \\langle \\boldsymbol{b}, \\boldsymbol{u} \\rangle \\equiv 0 \\pmod{Q}\\}$. The new procedure does not require internal access to control wires. It uses the normalization $b_1=-1$ to apply a center-referenced phase correction directly on the first coordinate register. The scaling parameter $D$ ensures that this physical operation can be implemented by arithmetic on $X_1$ alone and does not read the hidden loop index. For Chen's complex-Gaussian Karst-wave window, we isolate a parameter regime, formalized in Assumption~A5, in which a polynomial retuning of the parameters gives a one-dimensional envelope for the loop index with width $\\sigma_J \\asymp Q\\log n$.",
    "authors": [
      "Yifan Zhang"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25783",
    "title": "Sharpness of Minima in Deep Matrix Factorization: Exact Expressions",
    "abstract": "Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff & Michaeli (2020). This expression uncovers a fundamental property of the loss landscape of depth-2 matrix factorization problems: a minimum is flat if and only if it is spectral-norm balanced, which implies that flat minima are not necessarily Frobenius-norm balanced. Furthermore, to complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.",
    "authors": [
      "Anil Kamber",
      "Rahul Parhi"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.02208",
    "title": "MACS: Measurement-Aware Consistency Sampling for Inverse Problems",
    "abstract": "Diffusion models have emerged as powerful generative priors for solving inverse imaging problems. However, their practical deployment is hindered by the substantial computational cost of slow, multi-step sampling. Although Consistency Models (CMs) address this limitation by enabling high-quality generation in only one or a few steps, their direct application to inverse problems has remained largely unexplored. This paper introduces a modified consistency sampling framework specifically designed for inverse problems. The proposed approach regulates the sampler's stochasticity through a measurement-consistency mechanism that leverages the degradation operator, thereby enforcing fidelity to the observed data while preserving the computational efficiency of consistency-based generation. Comprehensive experiments on the Fashion-MNIST and LSUN Bedroom datasets demonstrate consistent improvements across both perceptual and pixel-level metrics, including the Fréchet Inception Distance (FID), Kernel Inception Distance (KID), peak signal-to-noise ratio (PSNR), and structural similarity index measure (SSIM), compared with baseline consistency and diffusion-based sampling methods. The proposed method achieves competitive or superior reconstruction quality with only a small number of sampling steps.",
    "authors": [
      "Amirreza Tanevardi",
      "Pooria Abbas Rad Moghadam",
      "Seyed Mohammad Eshtehardian",
      "Sajjad Amini",
      "Babak Khalaj"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.14159",
    "title": "Musical consonance: a review of theory and evidence on perception and preference of auditory roughness in humans and other animals",
    "abstract": "The origins of consonance in human music has long been contested, and today there are three primary hypotheses: aversion to roughness, preference for harmonicity, and learned preferences from cultural exposure. While the evidence is currently insufficient to disentangle the contributions of these hypotheses, I propose several reasons why roughness is an especially promising area for future study. The aim of this review is to summarize and critically evaluate roughness theory and models, experimental data, to highlight areas that deserve further research. I identify 2 key areas: There are fundamental issues with the definition and interpretation of results due to tautology in the definition of roughness, and the lack of independence in empirical measurements. Despite extensive model development, there are many duplications and models have issues with data quality and overfitting. Future theory development should aim for model simplicity, and extra assumptions, features and parameters should be evaluated systematically. Model evaluation should aim to maximise the breadth of stimuli that are predicted.",
    "authors": [
      "John M. McBride"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.17170",
    "title": "Computing Optimal Trajectories for Optimal Transport in Nonuniform Environments",
    "abstract": "In this work, we solve a discrete optimal transport problem in a nonuniform environment. To solve the optimal transport problem, we build the cost matrix and then use classical solvers for discrete optimal transport. The challenge is to form the cost matrix, which requires finding the optimal path between two points, and for this task we formulate and solve the associated Euler-Lagrange equations. A main contribution of ours is to provide verifiable sufficient conditions of optimality of the solution of the Euler-Lagrange equation and to propose new algorithms to to check optimality a-posteriori, thus validating the (exact) computation of the cost matrix. We illustrate our results and performance of the algorithms on several numerical examples in 2 and 3 dimensions.",
    "authors": [
      "Luca Dieci",
      "Daniyar Omarov"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.01955",
    "title": "Dynamic Estimates of Displacement in Disaster Regions: A Policy-driven framework triangulating data",
    "abstract": "While traditional data systems remain fundamental to humanitarian response, they often lack the real-time responsiveness and spatial precision needed to capture increasingly complex patterns of displacement. Internal displacement reached an unprecedented 83.4 million people by the end of 2024, underscoring the urgent need for innovative, data driven approaches to monitor and understand population movements. This report examines how integrating traditional data sources with emerging digital trace data, such as mobile phone GPS and social media activity, can enhance the accuracy, responsiveness, and granularity of displacement monitoring. Drawing on lessons from recent crises, including the escalation of the war in Ukraine and the 2022 floods in Pakistan, the report presents a structured pilot effort that tests the triangulation of multiple data streams to produce more robust and reliable displacement estimates. Statistical indicators derived from digital trace data are benchmarked against the International Organisation for Migration, Displacement Tracking Matrix datasets, to assess their validity, transparency, and scalability. The findings demonstrate how triangulated data approaches can deliver real-time, high-resolution insights into population movements, improving humanitarian resource allocation and intervention planning. The report includes a scalable framework for crisis monitoring that leverages digital innovation to strengthen humanitarian data systems and support evidence-based decision-making in complex emergencies.",
    "authors": [
      "Elisabetta Pietrostefani",
      "Matt Mason",
      "Rodgers Iradukunda",
      "Hong Tran-Jones",
      "Iryna Loktieva",
      "Francisco Rowe"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.08625",
    "title": "Cross-Field Interface-Aware Neural Operators for Multiphase Flow Simulation",
    "abstract": "Multiphase flow simulation is critical in science and engineering but incurs high computational costs due to complex field discontinuities and the need for high-resolution numerical meshes. While Neural Operators (NOs) offer an efficient alternative for solving Partial Differential Equations (PDEs), they struggle with two core challenges unique to multiphase systems: spectral bias caused by spatial heterogeneity at phase interfaces, and the persistent scarcity of expensive, high-resolution field data. This work introduces the Interface Information Aware Neural Operator (IANO), a novel architecture that mitigates these issues by leveraging readily obtainable interface data (e.g., topology and position). Interface data inherently contains the high-frequency features not only necessary to complement the physical field data, but also help with spectral bias. IANO incorporates an interface-aware function encoding mechanism to capture dynamic coupling, and a geometry-aware positional encoding method to enhance spatial fidelity for pointwise super-resolution. Empirical results across multiple multiphase flow cases demonstrate that IANO achieves significant accuracy improvements (up to $\\sim$10\\%) over existing NO baselines. Furthermore, IANO exhibits superior generalization capabilities in low-data and noisy settings, confirming its utility for practical, data-efficient $\\text{AI}$-based multiphase flow simulations.",
    "authors": [
      "Zhenzhong Wang",
      "Xin Zhang",
      "Jun Liao",
      "Min Jiang"
    ],
    "primary_category": "physics.flu-dyn",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.11618",
    "title": "On The Topology of Polygonal Meshes",
    "abstract": "This paper is an introductory and informal exposition on the topology of polygonal meshes. We begin with a broad overview of topological notions and discuss how homeomorphisms, homotopy, and homology can be used to characterize topology. We move on to define polygonal meshes and make a distinction between intrinsic topology and extrinsic topology which depends on the embedding space. A distinction is also made between quantitative topological properties and qualitative properties. We outline a proof of the Euler and the Euler-Poincaré formulas. The Betti numbers are defined in terms of the Euler-Poincaré formula and other mesh statistics rather than as cardinalities of the homology groups which allows us to avoid abstract algebra. Finally, we discuss how it is possible to cut a polygonal mesh such that it becomes a topological disc.",
    "authors": [
      "Andreas Bærentzen"
    ],
    "primary_category": "math.HO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20503",
    "title": "Manifold Percolation: from generative model to Reinforce learning",
    "abstract": "Generative modeling is typically framed as learning mapping rules, but from an observer's perspective without access to these rules, the task becomes disentangling the geometric support from the probability distribution. We propose that continuum percolation is uniquely suited to this support analysis, as the sampling process effectively projects high-dimensional density estimation onto a geometric counting problem on the support. In this work, we establish a rigorous correspondence between the topological phase transitions of random geometric graphs and the underlying data manifold in high-dimensional space. By analyzing the relationship between our proposed Percolation Shift metric and FID, we show that this metric captures structural pathologies, such as implicit mode collapse, where standard statistical metrics fail. Finally, we translate this topological phenomenon into a differentiable loss function that guides training. Experimental results confirm that this approach not only prevents manifold shrinkage but also fosters a form of synergistic improvement, where topological stability becomes a prerequisite for sustained high fidelity in both static generation and sequential decision making.",
    "authors": [
      "Rui Tong"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.22679",
    "title": "Foundations of Quantum Granular Computing with Effect-Based Granules, Algebraic Properties and Reference Architectures",
    "abstract": "This paper develops the foundations of Quantum Granular Computing (QGC), extending classical granular computing including fuzzy, rough, and shadowed granules to the quantum regime. Quantum granules are modeled as effects on a finite dimensional Hilbert space, so granular memberships are given by Born probabilities. This operator theoretic viewpoint provides a common language for sharp (projective) and soft (nonprojective) granules and embeds granulation directly into the standard formalism of quantum information theory. We establish foundational results for effect based quantum granules, including normalization and monotonicity properties, the emergence of Boolean islands from commuting families, granular refinement under Luders updates, and the evolution of granules under quantum channels via the adjoint channel in the Heisenberg picture. We connect QGC with quantum detection and estimation theory by interpreting the effect operators realizing Helstrom minimum error measurement for binary state discrimination as Helstrom type decision granules, i.e., soft quantum counterparts of Bayes optimal decision regions. Building on these results, we introduce Quantum Granular Decision Systems (QGDS) with three reference architectures that specify how quantum granules can be defined, learned, and integrated with classical components while remaining compatible with near term quantum hardware. Case studies on qubit granulation, two qubit parity effects, and Helstrom style soft decisions illustrate how QGC reproduces fuzzy like graded memberships and smooth decision boundaries while exploiting noncommutativity, contextuality, and entanglement. The framework thus provides a unified and mathematically grounded basis for operator valued granules in quantum information processing, granular reasoning, and intelligent systems.",
    "authors": [
      "Oscar Montiel Ross"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00517",
    "title": "No-Regret Gaussian Process Optimization of Time-Varying Functions",
    "abstract": "Sequential optimization of black-box functions from noisy evaluations has been widely studied, with Gaussian Process bandit algorithms such as GP-UCB guaranteeing no-regret in stationary settings. However, for time-varying objectives, it is known that no-regret is unattainable under pure bandit feedback unless strong and often unrealistic assumptions are imposed. In this article, we propose a novel method to optimize time-varying rewards in the frequentist setting, where the objective has bounded RKHS norm. Time variations are captured through uncertainty injection (UI), which enables heteroscedastic GP regression that adapts past observations to the current time step. As no-regret is unattainable in general in the strict bandit setting, we relax the latter allowing additional queries on previously observed points. Building on sparse inference and the effect of UI on regret, we propose W-SparQ-GP-UCB, an online algorithm that achieves no-regret with only a vanishing number of additional queries per iteration. To assess the theoretical limits of this approach, we establish a lower bound on the number of additional queries required for no-regret, proving the efficiency of our method. Finally, we provide a comprehensive analysis linking the degree of time-variation of the function to achievable regret rates, together with upper and lower bounds on the number of additional queries needed in each regime.",
    "authors": [
      "Eliabelle Mauduit",
      "Eloïse Berthier",
      "Andrea Simonetto"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03098",
    "title": "An AI Implementation Science Study to Improve Trustworthy Data in a Large Healthcare System",
    "abstract": "The rapid growth of Artificial Intelligence (AI) in healthcare has sparked interest in Trustworthy AI and AI Implementation Science, both of which are essential for accelerating clinical adoption. However, strict regulations, gaps between research and clinical settings, and challenges in evaluating AI systems continue to hinder real-world implementation. This study presents an AI implementation case study within Shriners Childrens (SC), a large multisite pediatric system, showcasing the modernization of SCs Research Data Warehouse (RDW) to OMOP CDM v5.4 within a secure Microsoft Fabric environment. We introduce a Python-based data quality assessment tool compatible with SCs infrastructure, extending OHDsi's R/Java-based Data Quality Dashboard (DQD) and integrating Trustworthy AI principles using the METRIC framework. This extension enhances data quality evaluation by addressing informative missingness, redundancy, timeliness, and distributional consistency. We also compare systematic and case-specific AI implementation strategies for Craniofacial Microsomia (CFM) using the FHIR standard. Our contributions include a real-world evaluation of AI implementations, integration of Trustworthy AI principles into data quality assessment, and insights into hybrid implementation strategies that blend systematic infrastructure with use-case-driven approaches to advance AI in healthcare.",
    "authors": [
      "Benoit L. Marteau",
      "Andrew Hornback",
      "Shaun Q. Tan",
      "Christian Lowson",
      "Jason Woloff",
      "May D. Wang"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03110",
    "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations",
    "abstract": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.",
    "authors": [
      "Steven Mascaro",
      "Owen Woodberry",
      "Charlie McLeod",
      "Mitch Messer",
      "Hiran Selvadurai",
      "Yue Wu",
      "Andre Schultz",
      "Thomas L Snelling"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03111",
    "title": "PanFoMa: A Lightweight Foundation Model and Benchmark for Pan-Cancer",
    "abstract": "Single-cell RNA sequencing (scRNA-seq) is essential for decoding tumor heterogeneity. However, pan-cancer research still faces two key challenges: learning discriminative and efficient single-cell representations, and establishing a comprehensive evaluation benchmark. In this paper, we introduce PanFoMa, a lightweight hybrid neural network that combines the strengths of Transformers and state-space models to achieve a balance between performance and efficiency. PanFoMa consists of a front-end local-context encoder with shared self-attention layers to capture complex, order-independent gene interactions; and a back-end global sequential feature decoder that efficiently integrates global context using a linear-time state-space model. This modular design preserves the expressive power of Transformers while leveraging the scalability of Mamba to enable transcriptome modeling, effectively capturing both local and global regulatory signals. To enable robust evaluation, we also construct a large-scale pan-cancer single-cell benchmark, PanFoMaBench, containing over 3.5 million high-quality cells across 33 cancer subtypes, curated through a rigorous preprocessing pipeline. Experimental results show that PanFoMa outperforms state-of-the-art models on our pan-cancer benchmark (+4.0\\%) and across multiple public tasks, including cell type annotation (+7.4\\%), batch integration (+4.0\\%) and multi-omics integration (+3.1\\%). The code is available at this https URL .",
    "authors": [
      "Xiaoshui Huang",
      "Tianlin Zhu",
      "Yifan Zuo",
      "Xue Xia",
      "Zonghan Wu",
      "Jiebin Yan",
      "Dingli Hua",
      "Zongyi Xu",
      "Yuming Fang",
      "Jian Zhang"
    ],
    "primary_category": "q-bio.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03122",
    "title": "Beyond Bayesian Inference: The Correlation Integral Likelihood Framework and Gradient Flow Methods for Deterministic Sampling",
    "abstract": "Calibrating mathematical models of biological processes is essential for achieving predictive accuracy and gaining mechanistic insight. However, this task remains challenging due to limited and noisy data, significant biological variability, and the computational complexity of the models themselves. In this method's article, we explore a range of approaches for parameter inference in partial differential equation (PDE) models of biological systems. We introduce a unified mathematical framework, the Correlation Integral Likelihood (CIL) method, for parameter estimation in systems exhibiting heterogeneous or chaotic dynamics, encompassing both pattern formation models and individual-based models. Departing from classical Bayesian inverse problem methodologies, we motivate the development of the CIL method, demonstrate its versatility, and highlight illustrative applications within mathematical biology. Furthermore, we compare stochastic sampling strategies, such as Markov Chain Monte Carlo (MCMC), with deterministic gradient flow approaches, highlighting how these methods can be integrated within the proposed framework to enhance inference performance. Our work provides a practical and theoretically grounded toolbox for researchers seeking to calibrate complex biological models using incomplete, noisy, or heterogeneous data, thereby advancing both the predictive capability and mechanistic understanding of such systems.",
    "authors": [
      "Piotr Gwiazda",
      "Alexey Kazarnikov",
      "Anna Marciniak-Czochra",
      "Zuzanna Szymańska"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03191",
    "title": "A Comprehensive Review of Casein Kinase 2 in Drosophila Circadian Timing and Its Biomedical Relevance",
    "abstract": "Circadian rhythms are endogenous 24-hour oscillations that regulate physiology, metabolism, sleep-wake cycles, and cellular homeostasis. Drosophila melanogaster, a genetically tractable model organism, has played a foundational role in uncovering the molecular mechanisms of circadian rhythms. The discovery of major clock genes, including period (per), timeless (tim), clock (clk), cycle (cyc), double time (dbt), and regulators such as Casein kinase 2 (CK2), emerged primarily from Drosophila research. CK2 operates as a critical post-translational regulator of PER protein phosphorylation, stability, nuclear entry, and degradation. Because PER dynamics dictate the timing and robustness of circadian rhythms in both flies and mammals, altered CK2 activity can profoundly impact rhythmic behaviour. CK2 dysregulation contributes not only to circadian disruption in Drosophila but also models broader pathological processes relevant to cancer, metabolic disease, neurodegeneration, and psychiatric disorders. This review synthesises CK2's molecular role in the Drosophila clock system, includes insights from computational modelling of CK2-PER dynamics, integrates tables throughout the text, and summarises the implications of dysregulated PER phosphorylation for human health.",
    "authors": [
      "Yasmin Fatima",
      "Md. Zubair Malik",
      "Prashant Ankur Jain"
    ],
    "primary_category": "q-bio.MN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03286",
    "title": "SpikGPT: A High-Accuracy and Interpretable Spiking Attention Framework for Single-Cell Annotation",
    "abstract": "Accurate and scalable cell type annotation remains a challenge in single-cell transcriptomics, especially when datasets exhibit strong batch effects or contain previously unseen cell populations. Here we introduce SpikGPT, a hybrid deep learning framework that integrates scGPT-derived cell embeddings with a spiking Transformer architecture to achieve efficient and robust annotation. scGPT provides biologically informed dense representations of each cell, which are further processed by a multi-head Spiking Self-Attention mechanism for energy-efficient feature extraction. Across multiple benchmark datasets, SpikGPT consistently matches or exceeds the performance of leading annotation tools. Notably, SpikGPT uniquely identifies unseen cell types by assigning low-confidence predictions to an \"Unknown\" category, allowing accurate rejection of cell states absent from the training reference. Together, these results demonstrate that SpikGPT is a versatile and reliable annotation tool capable of generalizing across datasets, resolving complex cellular heterogeneity, and facilitating discovery of novel or disease-associated cell populations.",
    "authors": [
      "Min Huang",
      "Rishikesan Kamaleswaran"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03312",
    "title": "Unlocking hidden biomolecular conformational landscapes in diffusion models at inference time",
    "abstract": "The function of biomolecules such as proteins depends on their ability to interconvert between a wide range of structures or \"conformations.\" Researchers have endeavored for decades to develop computational methods to predict the distribution of conformations, which is far harder to determine experimentally than a static folded structure. We present ConforMix, an inference-time algorithm that enhances sampling of conformational distributions using a combination of classifier guidance, filtering, and free energy estimation. Our approach upgrades diffusion models -- whether trained for static structure prediction or conformational generation -- to enable more efficient discovery of conformational variability without requiring prior knowledge of major degrees of freedom. ConforMix is orthogonal to improvements in model pretraining and would benefit even a hypothetical model that perfectly reproduced the Boltzmann distribution. Remarkably, when applied to a diffusion model trained for static structure prediction, ConforMix captures structural changes including domain motion, cryptic pocket flexibility, and transporter cycling, while avoiding unphysical states. Case studies of biologically critical proteins demonstrate the scalability, accuracy, and utility of this method.",
    "authors": [
      "Daniel D. Richman",
      "Jessica Karaguesian",
      "Carl-Mikael Suomivuori",
      "Ron O. Dror"
    ],
    "primary_category": "q-bio.BM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03409",
    "title": "Optimal Griffiths Phase in Heterogeneous Human Brain Networks: Brain Criticality Embracing Stability and Flexibility across Individuals",
    "abstract": "A prominent hypothesis in neuroscience proposes that brains achieve optimal performance by operating near a critical point. However, this framework, which often assumes a universal critical point, fails to account for the extensive individual variability observed in neural dynamics and cognitive functions. These variabilities are not noise but rather an inherent manifestation of a fundamental systems-biology principle: the necessary trade-off between robustness and flexibility in human populations. Here, we propose that the Griffiths phase (GP), an extended critical regime synergically induced by two kinds of heterogeneities in brain network region and connectivity, offers a unified framework for brain criticality that better reconciles robustness and flexibility and accounts for individual variability. Using Human Connectome Project data and whole-brain modeling, we demonstrated that the synergic interplay between structural network modularity and regional heterogeneity in local excitability yields biologically viable GP featured with widely extended global excitability ranges, with an embedded optimal point that balances global/local information transmission. Crucially, an individua's position within the GP gives rise to unique global network dynamics, which in turn confer a distinctive cognitive profile via flexible configuration of functional connectivity for segregation, integration, and balance between them. These results establish GP as an evolved adaptive mechanism resolving the robustness-flexibility trade-off, fulfilling diverse cognitive demands through individualized criticality landscapes, providing a new framework of brain criticality.",
    "authors": [
      "Kejian Wu",
      "Dante R. Chialvo",
      "Changsong Zhou",
      "Lianchun Yu"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03460",
    "title": "Learning From Limited Data and Feedback for Cell Culture Process Monitoring: A Comparative Study",
    "abstract": "In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development.",
    "authors": [
      "Johnny Peng",
      "Thanh Tung Khuat",
      "Ellen Otte",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03497",
    "title": "Cell-cell communication inference and analysis: biological mechanisms, computational approaches, and future opportunities",
    "abstract": "In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field.",
    "authors": [
      "Xiangzheng Cheng",
      "Haili Huang",
      "Ye Su",
      "Qing Nie",
      "Xiufen Zou",
      "Suoqin Jin"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03541",
    "title": "Toward AI-Ready Medical Imaging Data",
    "abstract": "Medical imaging data plays a vital role in disease diagnosis, monitoring, and clinical research discovery. Biomedical data managers and clinical researchers must navigate a complex landscape of medical imaging infrastructure, input/output tools and data reliability workflow configurations taking months to operationalize. While standard formats exist for medical imaging data, standard operating procedures (SOPs) for data management are lacking. These data management SOPs are key for developing Findable, Accessible, Interoperable, and Reusable (FAIR) data, a prerequisite for AI-ready datasets. The National Institutes of Health (NIH) Bridge to Artificial Intelligence (Bridge2AI) Standards Working Group members and domain-expert stakeholders from the Bridge2AI Grand Challenges teams developed data management SOPs for the Digital Imaging and Communications in Medicine (DICOM) format. We describe novel SOPs applying to both static and cutting edge video imaging modalities. We emphasize steps required for centralized data aggregation, validation, and de-identification, including a review of new defacing methods for facial DICOM scans, anticipating adversarial AI/ML data re-identification methods. Data management vignettes based on Bridge2AI datasets include example parameters for efficient capture of a wide modality spectrum, including datasets from new ophthalmology retinal scans DICOM modalities.",
    "authors": [
      "Milen Nikolov",
      "Edilberto Amorim",
      "J Harry Caufield",
      "Nayoon Gim",
      "Nomi L Harris",
      "Jared Houghtaling",
      "Xiang Li",
      "Danielle Morrison",
      "Anaïs Rameau",
      "Jamie Shaffer",
      "Hari Trivedi",
      "Monica C Munoz-Torres"
    ],
    "primary_category": "q-bio.OT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03585",
    "title": "Microclimatic variation in tropical canopies: A glimpse into the processes of community assembly in epiphytic bryophyte communities",
    "abstract": "Epiphytic communities offer an original framework to disentangle the contributions of environmental filters, biotic interactions and dispersal limitations to community structure at fine spatial scales. We determine here whether variations in light, microclimatic conditions and host tree size affect the variation in species composition and phylogenetic structure of epiphytic bryophyte communities, and hence, assess the contribution of environmental filtering, phylogenetic constraints and competition to community assembly.A canopy crane giving access to 1.1 ha of tropical rainforest in Yunnan (China) was employed to record hourly light and microclimatic conditions from 54 dataloggers and epiphytic bryophyte communities from 408 plots. Generalized Dissimilarity Modelling was implemented to analyse the relationship between taxonomic and phylogenetic turnover among epiphytic communities, host-tree characteristics and microclimatic this http URL -tree vertical turnover of bryophyte communities was significantly about 30% higher than horizontal turnover among-trees. Thus, the sharp vertical variations in microclimatic conditions from tree base to canopy are more important than differences in age, reflecting the likelihood of colonization, area, and habitat conditions between young and old trees, in shaping the composition of epiphytic bryophyte communities.",
    "authors": [
      "Ting Shen",
      "Richard T. Corlett",
      "Flavien Collart",
      "Thibault Kasprzyk",
      "Xin-Lei Guo",
      "Jairo Patiño",
      "Yang Su",
      "Olivier J. Hardy",
      "Wen-Zhang Ma",
      "Jian Wang",
      "Yu-Mei Wei",
      "Lea Mouton",
      "Yuan Li",
      "Liang Song",
      "Alain Vanderpoorten"
    ],
    "primary_category": "q-bio.PE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03866",
    "title": "Generating a Contact Matrix for Aged Care Settings in Australia: an agent-based model study",
    "abstract": "This study presents an agent-based model (ABM) developed to simulate staff and resident interactions within a synthetic aged care facility, capturing movement, task execution, and proximity-based contact events across three staff shifts and varying levels of resident care. Contacts were defined by spatial thresholds (1.5 m and 3 m) and cumulative duration, enabling the generation of detailed contact matrices. Simulation results showed that low and medium care residents experienced the highest frequency of interactions, particularly with staff on morning and afternoon shifts, while high care residents and night staff had substantially fewer contacts. Contact rates varied significantly by care level and shift, confirmed through Poisson-based regression modelling. Temporal analyses revealed clustering of high-risk contacts during structured daily routines, especially communal and care activities. An integrated airborne transmission module, seeded with a single infectious staff member, demonstrated that infection risk was highest during high-contact shifts and among medium care residents. Vaccination scenarios reduced predicted transmission by up to 68\\%, with the greatest impact observed when both staff and residents were vaccinated. These findings highlight the importance of accounting for contact heterogeneity in aged care and demonstrate the utility of ABMs for evaluating targeted infection control strategies in high-risk, enclosed environments.",
    "authors": [
      "Haley Stone",
      "C. Raina MacIntyre",
      "Mohana Kunasekaran",
      "Chris Poulos",
      "David Heslop"
    ],
    "primary_category": "q-bio.PE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03880",
    "title": "Leveraging topological data analysis to estimate bone strength from micro-CT as a surrogate for advanced imaging",
    "abstract": "Accurate bone strength prediction is essential for assessing fracture risk, particularly in aging populations and individuals with osteoporosis. Bone imaging has evolved from X-rays and DXA to clinical computed tomography (CT), and now to advanced modalities such as high-resolution peripheral quantitative CT and synchrotron radiation CT, which offer unprecedented resolution of bone microarchitecture. However, analytical methods have not kept pace with these imaging advances. This study applied topological data analysis (TDA) to extract biomechanically relevant features from high-resolution bone images, offering a new framework for bone strength prediction. We extracted topological features, specifically those derived from persistent homology, and combined them with standard bone morphometric descriptors to train machine learning models for apparent strength prediction. Models based solely on topological features outperformed those using traditional morphometrics, highlighting TDA's ability to capture biomechanically relevant structure. In particular, internal voids, often dismissed as imaging noise, proved to be the most predictive. While limited by dataset size and class imbalance, these results suggest that TDA offers a promising approach for advancing osteoporosis risk assessment.",
    "authors": [
      "John Rick Manzanares",
      "Richard Leslie Abel",
      "Paweł Dłotko"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03907",
    "title": "Emergent Spatiotemporal Dynamics in Large-Scale Brain Networks with Next Generation Neural Mass Models",
    "abstract": "Understanding the dynamics of large-scale brain models remains a central challenge due to the inherent complexity of these systems. In this work, we explore the emergence of complex spatiotemporal patterns in a large scale-brain model composed of 90 interconnected brain regions coupled through empirically derived anatomical connectivity. An important aspect of our formulation is that the local dynamics of each brain region are described by a next-generation neural mass model, which explicitly captures the macroscopic gamma activity of coupled excitatory and inhibitory neural populations (PING mechanism). We first identify the system's homogeneous states-both resting and oscillatory-and analyze their stability under uniform perturbations. Then, we determine the stability against non-uniform perturbations by obtaining dispersion relations for the perturbation growth rate. This analysis enables us to link unstable directions of the homogeneous solutions to the emergence of rich spatiotemporal patterns, that we characterize by means of Lyapunov exponents and frequency spectrum analysis. Our results show that, compared to previous studies with classical neural mass models, next-generation neural mass models provide a broader dynamical repertoire, both within homogeneous states and in the heterogeneous regime. Additionally, we identify a key role for anatomical connectivity in cross-frequency coupling, allowing for the emergence of gamma oscillations with amplitude modulated by slower rhythms. These findings suggest that such models are not only more biophysically grounded but also particularly well-suited to capture the full complexity of large-scale brain dynamics. Overall, our study advances the analytical understanding of emerging spatiotemporal patterns in whole-brain models.",
    "authors": [
      "Rosa Maria Delicado",
      "Gemma Huguet",
      "Pau Clusella"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03092",
    "title": "Approximate Bayesian Inference on Mechanisms of Network Growth and Evolution",
    "abstract": "Mechanistic models can provide an intuitive and interpretable explanation of network growth by specifying a set of generative rules. These rules can be defined by domain knowledge about real-world mechanisms governing network growth or may be designed to facilitate the appearance of certain network motifs. In the formation of real-world networks, multiple mechanisms may be simultaneously involved; it is then important to understand the relative contribution of each of these mechanisms. In this paper, we propose the use of a conditional density estimator, augmented with a graph neural network, to perform inference on a flexible mixture of network-forming mechanisms. This event-wise mixture-of-mechanisms model assigns mechanisms to each edge formation event rather than stipulating node-level mechanisms, thus allowing for an explanation of the network generation process, as well as the dynamic evolution of the network over time. We demonstrate that our approximate Bayesian approach yields valid inferences for the relative weights of the mechanisms in our model, and we utilize this method to investigate the mechanisms behind the formation of a variety of real-world networks.",
    "authors": [
      "Maxwell H Wang",
      "Till Hoffmann",
      "Jukka-Pekka Onnela"
    ],
    "primary_category": "cs.SI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03158",
    "title": "Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing",
    "abstract": "Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.",
    "authors": [
      "Adele Chinda",
      "Richmond Azumah",
      "Hemanth Demakethepalli Venkateswara"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03293",
    "title": "Prior preferences in active inference agents: soft, hard, and goal shaping",
    "abstract": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).",
    "authors": [
      "Filippo Torresan",
      "Ryota Kanai",
      "Manuel Baltieri"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03784",
    "title": "Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop",
    "abstract": "Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.",
    "authors": [
      "Guisong Liu",
      "Jiansong Zhang",
      "Yinpei Luo",
      "Guoliang Wei",
      "Shuqing Sun",
      "Shiyang Deng",
      "Pengfei Wei",
      "Nanxi Chen"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.02706",
    "title": "DeepBioisostere: Discovering Bioisosteres with Deep Learning for a Fine Control of Multiple Molecular Properties",
    "abstract": "Optimizing molecular properties while preserving biological activity is a central challenge in drug design. Bioisosteric replacement, which substitutes a molecular fragment with a chemically or biologically analogous moiety, offers a powerful strategy for fine-tuning properties without disrupting target binding. However, existing in silico approaches often rely on expert-defined modification sites or suffer from modulating multiple molecular properties simultaneously. Here, we present DeepBioisostere, a deep generative model that performs end-to-end bioisosteric replacement by autonomously selecting and substituting molecular fragments to satisfy multiple target properties. The model captures complex relationships across the molecular graph, enabling the optimization of sophisticated properties such as drug-likeness and synthetic accessibility. By learning from experimental bio-assay data, DeepBioisostere proposes replacements that maintain biological activities, even generating potential bioisosteres beyond the training data. We demonstrate the effectiveness of the model in computational hit-to-lead optimization scenarios, highlighting its potential to accelerate rational molecular design without relying on expert heuristics or pre-established substitution rules.",
    "authors": [
      "Hyeongwoo Kim",
      "Seokhyun Moon",
      "Wonho Zhung",
      "Shinwoo Kim",
      "Jaechang Lim",
      "Woo Youn Kim"
    ],
    "primary_category": "q-bio.BM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2410.18222",
    "title": "Kubo-Martin-Schwinger states of Path-structured Flow in Directed Brain Synaptic Networks",
    "abstract": "The brain's synaptic network, characterized by parallel connections and feedback loops, drives interaction pathways between neurons through a large system with infinitely many degrees of freedom. This system is best modeled by the graph C*-algebra of the underlying directed graph, the Toeplitz-Cuntz-Krieger (TCK) algebra, which captures the diversity of path-structured flow connectivity. Equipped with the gauge action, the TCK algebra defines an {\\em algebraic quantum system}, and here we demonstrate that its thermodynamic properties provide a natural framework for describing the dynamic mappings of potential flow pathways within the network. Specifically, the KMS states of this system represent the stationary distributions of a non-Markovian stochastic process with memory decay, capturing how influence propagates along exponentially weighted paths, and yield global statistical measures of neuronal interactions. Applied to the {\\em C. elegans} synaptic network, our framework reveals that neurolocomotor neurons emerge as the primary hubs of incoming path-structured flow at inverse temperatures where the entropy of KMS states peaks. This finding aligns with experimental evidence of the foundational role of locomotion in {\\em C. elegans} behavior, suggesting that functional centrality may arise from the topological embedding of neurons rather than solely from local physiological properties. Our results highlight the potential of algebraic quantum methods and graph algebras to uncover patterns of functional organization in complex systems and neuroscience.",
    "authors": [
      "El-kaïoum M. Moutuou",
      "Habib Benali"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.02154",
    "title": "In Silico Functional Profiling of Engineered Small Molecules: A Machine Learning Approach Leveraging PubChem Identifiers (CID_SID ML model)",
    "abstract": "The article introduces a concept for a time- and cost-effective methodological framework leveraging machine learning (ML) models for both early-stage drug development and clinical trial support. The rationale for this approach is the inherent scalability and speed enabled by using pre-calculated data embedded in existing PubChem identifiers (CID and SID), thereby eliminating the computationally intensive step of on-the-fly molecular descriptor generation. The approach was effectively demonstrated across four diverse bioassays: antagonists of the human D3 dopamine receptor, Rab9 promoter activators, small-molecule inhibitors of CHOP, and antagonists of the human M1 muscarinic receptor. A comparison, based on Matthews correlation coefficient (MCC), was conducted between the CID_SID ML model, the MORGAN2-based ML model, and the RDKit-transformed SMILES model for these four case studies, revealing that no method is universally superior in terms of performance. Furthermore, the CID_SID model averaged a rapid execution time of only 3.3 seconds; the ML models relying on explicit structural descriptors, such as MORGAN2 and RDKit-transformed SMILES, demonstrated high computational costs, with processing times averaging 106.0 and 109.6 seconds, respectively. While negligible for a single ML model, these times would cause a significant difference in computational resource consumption when scaled across a framework involving over a million buildings. Moreover, the CID_SID ML model achieved strong average performance metrics: Accuracy of 83.52%, Precision of 89.62%, Recall of 75.65%, F1-Score of 81.93% and ROC of 83.53%.",
    "authors": [
      "Mariya L. Ivanova",
      "Michael Nicholls",
      "Nicola Russo",
      "Gueorgui Mihaylov",
      "Konstantin Nikolic"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.00655",
    "title": "Implicit Generative Modeling by Kernel Similarity Matching",
    "abstract": "Understanding how the brain encodes stimuli has been a fundamental problem in computational neuroscience. Insights into this problem have led to the design and development of artificial neural networks that learn representations by incorporating brain-like learning abilities. Recently, learning representations by capturing similarity between input samples has been studied to tackle this problem. This approach, however, has thus far been used to only learn downstream features from an input and has not been studied in the context of a generative paradigm, where one can map the representations back to the input space, incorporating not only bottom-up interactions (stimuli to latent) but also learning features in a top-down manner (latent to stimuli). We investigate a kernel similarity matching framework for generative modeling. Starting with a modified sparse coding objective for learning representations proposed in prior work, we demonstrate that representation learning in this context is equivalent to maximizing similarity between the input kernel and a latent kernel. We show that an implicit generative model arises from learning the kernel structure in the latent space and show how the framework can be adapted to learn manifold structures, potentially providing insights as to how task representations can be encoded in the brain. To solve the objective, we propose a novel Alternate Direction Method of Multipliers (ADMM) based algorithm and discuss the interpretation of the optimization process. Finally, we discuss how this representation learning problem can lead towards a biologically plausible architecture to learn the model parameters that ties together representation learning using similarity matching (a bottom-up approach) with predictive coding (a top-down approach).",
    "authors": [
      "Shubham Choudhary",
      "Paul Masset",
      "Demba Ba"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.01376",
    "title": "Fluctuating growth rates link turnover and unevenness in species-rich communities",
    "abstract": "The maintenance of diversity, the `commonness of rarity', and compositional turnover are ubiquitous features of species-rich communities. Through a minimal model, we consider how these features reflect the interplay between environmental stochasticity, intra- and interspecific competition, and dispersal. We show that, even if species have the same time-average fitness, fluctuations tend to drive the community towards ever-growing unevenness and species extinctions, but self-limitation and/or dispersal allow species-rich states to be sustained. Species abundance--distributions vary systematically in a Buffering--Stabilization parameter plane that describes the relative strength of the underlying ecological processes, and cover different empirically relevant power-law and unimodal shapes. A model describing the effective dynamics of a focal species relates static abundance distributions with turnover dynamics, also when species have different mean fitness. The model suggests how community statistics and time series of individual species can inform on the relative importance of the ecological processes that structure diversity.",
    "authors": [
      "Emil Mallmin",
      "Arne Traulsen",
      "Silvia De Monte"
    ],
    "primary_category": "q-bio.PE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.00593",
    "title": "Look mom, no experimental data! Learning to score protein-ligand interactions from simulations",
    "abstract": "Despite recent advances in protein-ligand structure prediction, deep learning methods remain limited in their ability to accurately predict binding affinities, particularly for novel protein targets dissimilar from the training set. In contrast, physics-based binding free energy calculations offer high accuracy across chemical space but are computationally prohibitive for large-scale screening. We propose a hybrid approach that approximates the accuracy of physics-based methods by training target-specific neural networks on molecular dynamics simulations of the protein in complex with random small molecules. Our method uses force matching to learn an implicit free energy landscape of ligand binding for each target. Evaluated on six proteins, our approach achieves competitive virtual screening performance using 100-500 $\\mu$s of MD simulations per target. Notably, this approach achieves state-of-the-art early enrichment when using the true pose for active compounds. These results highlight the potential of physics-informed learning for virtual screening on novel targets. We publicly release the code for this paper at this https URL under the MIT license.",
    "authors": [
      "Michael Brocidiacono",
      "James Wellnitz",
      "Konstantin I. Popov",
      "Alexander Tropsha"
    ],
    "primary_category": "q-bio.QM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.20233",
    "title": "Identifying multi-compartment Hodgkin-Huxley models with high-density extracellular voltage recordings",
    "abstract": "Multi-compartment Hodgkin-Huxley models are biophysical models of how electrical signals propagate throughout a neuron, and they form the basis of our knowledge of neural computation at the cellular level. However, these models have many free parameters that must be estimated for each cell, and existing fitting methods rely on intracellular voltage measurements that are highly challenging to obtain in vivo. Recent advances in neural recording technology with high-density probes and arrays enable dense sampling of extracellular voltage from many sites surrounding a neuron, allowing indirect measurement of many compartments of a cell simultaneously. Here, we propose a method for inferring the underlying membrane voltage, biophysical parameters, and the neuron's position relative to the probe, using extracellular measurements alone. We use an Extended Kalman Filter to infer membrane voltage and channel states using efficient, differentiable simulators. Then, we learn the model parameters by maximizing the marginal likelihood using gradient-based methods. We demonstrate the performance of this approach using simulated data and real neuron morphologies.",
    "authors": [
      "Ian Christopher Tanoh",
      "Michael Deistler",
      "Jakob H. Macke",
      "Scott W. Linderman"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.27030",
    "title": "Generalizing matrix representations to fully heterochronous ranked tree shapes",
    "abstract": "Phylogenetic tree shapes capture fundamental signatures of evolution. We consider ``ranked'' tree shapes, which are equipped with a total order on the internal nodes compatible with the tree graph. Recent work has established an elegant bijection of ranked tree shapes and a class of integer matrices, called \\textbf{F}-matrices, defined by simple inequalities. This formulation is for isochronous ranked tree shapes, where all leaves share the same sampling time, such as in the study of ancient human demography from present-day individuals. Another important style of phylogenetics concerns trees where the ``timing'' of events is by branch length rather than calendar time. This style of tree, called a rooted phylogram, is output by popular maximum-likelihood methods. These trees are broadly relevant, such as to study the affinity maturation of B cells in the immune system. Discretizing time in a rooted phylogram gives a fully heterochronous ranked tree shape, where leaves are part of the total order. Here we extend the \\textbf{F}-matrix framework to such fully heterochronous ranked tree shapes. We establish an explicit bijection between a class of \\textbf{F}-matrices and the space of such tree shapes. The matrix representation has the key feature that values at any entry are highly constrained via four previous entries, enabling straightforward enumeration of all valid tree shapes. We also use this framework to develop probabilistic models on ranked tree shapes. Our work extends understanding of combinatorial objects that have a rich history in the literature.",
    "authors": [
      "Chris Jennings-Shaffer",
      "Cherith Chen",
      "Julia A Palacios",
      "Frederick A Matsen IV"
    ],
    "primary_category": "q-bio.PE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2305.10937",
    "title": "The generalized Hierarchical Gaussian Filter",
    "abstract": "Hierarchical Bayesian models of perception and learning feature prominently in contemporary cognitive neuroscience where, for example, they inform computational concepts of mental disorders. This includes predictive coding and hierarchical Gaussian filtering (HGF), which differ in the nature of hierarchical representations. In this work, we present a new class of artificial neural networks that unifies computational principles of PC and HGFs. We extend the space of generative models underlying HGF to include a form of nonlinear hierarchical coupling between state values akin to predictive coding and artificial neural networks in general. We derive the update equations corresponding to this generalization of HGF and conceptualize them as connecting a network of (belief) nodes where parent nodes either predict the state of child nodes or their rate of change. This enables us to (1) create modular architectures with generic computational steps in each node of the network, and (2) disclose the hierarchical message passing implied by generalized HGF models and to compare this to comparable schemes under predictive coding. The practical advances of this work are twofold: on the one hand, our extension allows for a modular construction of ANNs of arbitrarily complex hierarchical structure under the general principles of HGF. On the other hand, by providing a highly flexible implementation of hierarchical Bayesian models available as open source software, it enables new types of empirical data analysis in computational psychiatry.",
    "authors": [
      "Lilian Aline Weber",
      "Peter Thestrup Waade",
      "Nicolas Legrand",
      "Anna Hedvig Møller",
      "Klaas Enno Stephan",
      "Christoph Mathys"
    ],
    "primary_category": "cs.NE",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20145",
    "title": "Asymptotic Analysis of the Total Quasi-Steady State Approximation for the Michaelis--Menten Enzyme Kinetic Reactions",
    "abstract": "We consider a stochastic model of the Michaelis-Menten (MM) enzyme kinetic reactions in terms of Stochastic Differential Equations (SDEs) driven by Poisson Random Measures (PRMs). It has been argued that among various Quasi-Steady State Approximations (QSSAs) for the deterministic model of such chemical reactions, the total QSSA (tQSSA) is the most accurate approximation, and it is valid for a wider range of parameter values than the standard QSSA (sQSSA). While the sQSSA for this model has been rigorously derived from a probabilistic perspective at least as early as 2006 in Ball et al. (2006), a rigorous study of the tQSSA for the stochastic model appears missing. We fill in this gap by deriving it as a Functional Law of Large Numbers (FLLN), and also studying the fluctuations around this approximation as a Functional Central Limit Theorem (FCLT).",
    "authors": [
      "Arnab Ganguly",
      "Wasiur R. KhudaBukhsh"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.17478",
    "title": "ConfRover: Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression",
    "abstract": "Understanding protein dynamics is critical for elucidating their biological functions. The increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins. However, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples. To address these limitations, we introduce ConfRover, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectories, supporting both time-dependent and time-independent sampling. At the core of our model is a modular architecture comprising: (i) an encoding layer, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a temporal module, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the structure decoder, generating conformations in continuous space. Experiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks. ConfRover is the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data. Project website: this https URL .",
    "authors": [
      "Yuning Shen",
      "Lihao Wang",
      "Huizhuo Yuan",
      "Yan Wang",
      "Bangji Yang",
      "Quanquan Gu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.05127",
    "title": "PixCell: A generative foundation model for digital histopathology images",
    "abstract": "The digitization of histology slides has revolutionized pathology, providing massive datasets for cancer diagnosis and research. Self-supervised and vision-language models have been shown to effectively mine large pathology datasets to learn discriminative representations. On the other hand, there are unique problems in pathology, such as annotated data scarcity, privacy regulations in data sharing, and inherently generative tasks like virtual staining. Generative models, capable of synthesizing realistic and diverse images, present a compelling solution to address these problems through image synthesis. We introduce PixCell, the first generative foundation model for histopathology images. PixCell is a diffusion model trained on PanCan-30M, a large, diverse dataset derived from 69,184 H&E-stained whole slide images of various cancer types. We employ a progressive training strategy and a self-supervision-based conditioning that allows us to scale up training without any human-annotated data. By conditioning on real slides, the synthetic images capture the properties of the real data and can be used as data augmentation for small-scale datasets to boost classification performance. We prove the foundational versatility of PixCell by applying it to two generative downstream tasks: privacy-preserving synthetic data generation and virtual IHC staining. PixCell's high-fidelity conditional generation enables institutions to use their private data to synthesize highly realistic, site-specific surrogate images that can be shared in place of raw patient data. Furthermore, using datasets of roughly paired H&E-IHC tiles, we learn to translate PixCell's conditioning from H&E to multiple IHC stains, allowing the generation of IHC images from H&E inputs. Our trained models are publicly released to accelerate research in computational pathology.",
    "authors": [
      "Srikar Yellapragada",
      "Alexandros Graikos",
      "Zilinghan Li",
      "Kostas Triaridis",
      "Varun Belagali",
      "Tarak Nath Nandi",
      "Karen Bai",
      "Beatrice S. Knudsen",
      "Tahsin Kurc",
      "Rajarsi R. Gupta",
      "Prateek Prasanna",
      "Ravi K Madduri",
      "Joel Saltz",
      "Dimitris Samaras"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03123",
    "title": "A Stochastic Thermodynamics Approach to Price Impact and Round-Trip Arbitrage: Theory and Empirical Implications",
    "abstract": "This paper develops a comprehensive theoretical framework that imports concepts from stochastic thermodynamics to model price impact and characterize the feasibility of round-trip arbitrage in financial markets. A trading cycle is treated as a non-equilibrium thermodynamic process, where price impact represents dissipative work and market noise plays the role of thermal fluctuations. The paper proves a Financial Second Law: under general convex impact functionals, any round-trip trading strategy yields non-positive expected profit. This structural constraint is complemented by a fluctuation theorem that bounds the probability of profitable cycles in terms of dissipated work and market volatility. The framework introduces a statistical ensemble of trading strategies governed by a Gibbs measure, leading to a free energy decomposition that connects expected cost, strategy entropy, and a market temperature parameter. The framework provides rigorous, testable inequalities linking microstructural impact to macroscopic no-arbitrage conditions, offering a novel physics-inspired perspective on market efficiency. The paper derives explicit analytical results for prototypical trading strategies and discusses empirical validation protocols.",
    "authors": [
      "Amit Kumar Jha"
    ],
    "primary_category": "q-fin.MF",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03189",
    "title": "The First Crypto President: Presidential Power and Cryptocurrency Markets During Trump's Second Term (2025-2029)",
    "abstract": "This paper analyzes the intersection of presidential authority and cryptocurrency markets during Donald J. Trump's second term (2025-2029). We examine developments from 2024 through October 2025, focusing on how executive influence, family business ventures, and digital assets became intertwined in ways that blurred boundaries between public office and private profit. Using a mixed-methods approach that combines quantitative market data with qualitative institutional assessment, we identify politically linked digital assets as a distinct class characterized by reflexive valuations, asymmetric risk distribution, and systemic vulnerabilities. The Trump family's integrated cryptocurrency ecosystem reached peak valuations exceeding eleven billion dollars before collapsing by more than one trillion in market capitalization following a tariff announcement in October 2025. Results highlight conflicts of interest, failures in market microstructure, and the emergence of political finance as a monetizable phenomenon in the digital age. The study contributes to understanding how presidential signaling reshapes capital flows, how politically branded tokens function as quasi-currencies, and how sudden policy actions can trigger cascading liquidations across global digital asset systems.",
    "authors": [
      "Habib Badawi"
    ],
    "primary_category": "q-fin.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03242",
    "title": "A Theoretical Framework Bridging Model Validation and Loss Ratio in Insurance",
    "abstract": "This paper establishes the first analytical relationship between predictive model performance and loss ratio in insurance pricing. We derive a closed-form formula connecting the Pearson correlation between predicted and actual losses to expected loss ratio. The framework proves that model improvements exhibit diminishing marginal returns, analytically confirming the actuarial intuition to prioritize poorly performing models. We introduce the Loss Ratio Error metric for quantifying business impact across frequency, severity, and pure premium models. Simulations show reliable predictions under stated assumptions, with graceful degradation under assumption violations. This framework transforms model investment decisions from qualitative intuition to quantitative cost-benefit analysis.",
    "authors": [
      "C. Evans Hedges"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03267",
    "title": "Orlicz-Lorentz premia and distortion Haezendonck-Goovaerts risk measures",
    "abstract": "In financial and actuarial research, distortion and Haezendonck-Goovaerts risk measures are attractive due to their strong properties. They have so far been treated separately. In this paper, following a suggestion by Goovaerts, Linders, Van Weert, and Tank, we introduce and study a new class of risk measure that encompasses the distortion and Haezendonck-Goovaerts risk measures, aptly called the distortion Haezendonck-Goovaerts risk measures. They will be defined on a larger space than the space of bounded risks. We provide situations where these new risk measures are coherent, and explore their risk theoretic properties.",
    "authors": [
      "Aline Goulard",
      "Karl Grosse-Erdmann"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03596",
    "title": "vop_poc_nz: A Python Framework for Distributional Cost-Effectiveness and Value of Perspective Analysis",
    "abstract": "Health economic evaluations are sensitive to the choice of analytical perspective (e.g., health system vs. societal). While guidelines often recommend specific perspectives, the uncertainty associated with this choice - and the potential decision discordance it creates - is rarely quantified. We present vop_poc_nz, a Python package that implements a framework for Distributional Cost-Effectiveness Analysis (DCEA) and operationalizes the quantification of perspective uncertainty through the Value of Perspective (VoP) metric. The package provides tools for Markov modeling, probabilistic sensitivity analysis, value of information analysis, and equity impact assessment. Unlike existing tools that treat perspective as a fixed input, vop_poc_nz allows for the simultaneous evaluation of multiple perspectives. This enables decision-makers to estimate the opportunity cost of perspective misalignment. We demonstrate the package's capabilities using case studies from Aotearoa New Zealand.",
    "authors": [
      "Dylan A Mordaunt"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03709",
    "title": "The Effect of High-Speed Rail Connectivity on Capital Market Earnings Forecast Error: Evidence from the Chinese Stock Market",
    "abstract": "This study examines how China's high-speed rail (HSR) expansion affects analyst earnings forecast errors from an economic information friction perspective. Using firm-year panel data from 2008-2019, a period that covers HSR's early introduction and rapid nationwide rollout, the findings show that analysts' relative earnings forecast errors (RFE) decline significantly only after firms' cities become connected by high-speed rail. The placebo test, which artificially shifts HSR connectivity 3 years earlier than the actual opening year, yields an insignificant DID coefficient, rejecting the possibility that forecast errors were improving before the infrastructure shock. This supports the conclusion that forecast error reduction is linked to real geographic accessibility improvements rather than coincidence, pre-existing trends, or analyst anticipation. Economically, the study highlights that HSR reduces analysts' costs of gathering private, incremental information, particularly soft information obtained via plant or management visits. The rail network does not directly alter firms' internal capital allocation or earnings generation paths, but it lowers spatial barriers to information collection, enabling analysts to update EPS expectations under reduced travel friction. This work provides intuitive evidence that geography and mobility improvements contribute to forecasting accuracy in China's emerging, decentralized capital market corridors, and it encourages future research to consider transport accessibility as an exogenous information cost shock rather than an internal firm-capital shock.",
    "authors": [
      "Shilong Han"
    ],
    "primary_category": "q-fin.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03821",
    "title": "Is Jobless Growth Valid in Turkiye? A Sectoral Analysis of the Relationship between Unemployment and Economic Growth",
    "abstract": "This study analyzes the validity of jobless growth in Turkiye on sectoral basis. It analyzes the impacts of agriculture, industry, construction and services sectors on unemployment using annual data for the period 2000-2022. ARDL method is applied within the scope of the analysis. The findings are tested with FMOLS and CCR methods. The results show that growth in all sectors reduces the unemployment. A one-unit increase in the share of agriculture sector in GDP decreases the unemployment rate by 0.471 points, 0.680 points in the industrial sector, 0.899 points in the construction sector and 1.383 points in the services sector in the short-run. The long-run coefficients reveal that the impacts of sectoral growth on unemployment are stronger in the long-run than in the short-run. A one unit increase in the share of the agricultural sector in GDP decreases the unemployment rate by 2.380 points, 4.057 points in the industrial sector, 1.761 points in the construction sector and 3.664 points in the services sector in the long-run. These findings show that jobless growth is not valid in Turkiye in general. On the contrary, economic growth plays an important role in reducing unemployment.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03822",
    "title": "Does Globalization Promote or Hinder Sustainable Development? Evidence from Turkiye on the Three Dimensions of Globalization",
    "abstract": "This study analyzes the impact of globalization on sustainable development in Turkiye. We used the ARDL method with annual data for the period 2000-2021. Results reveal that economic globalization promotes positively to sustainable development in the short run with a coefficient of 0.144 and in the long run with a 0.153 coefficient. Although social globalization has a negative impact with a coefficient of -0.150 in the short run, this effect turns positive with a coefficient of 0.080 in the long run. Political globalization strongly supports sustainable development with a coefficient of 0.254 in the short run and 2.634 in the long run. Finally, total globalization has a positive impact on sustainable development in the short and long run with coefficients of 0.339 and 0.196, respectively.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03902",
    "title": "Equalizer or amplifier? How AI may reshape human cognitive differences",
    "abstract": "Machines have at times equalized physical strength by substituting for human effort, and at other times amplified these differences. Artificial intelligence (AI) may likewise narrow or widen disparities in cognitive ability. Recent evidence from the Information and Communication Technology (ICT) revolution suggests that computers increased inequality by education but reduced it by cognitive ability. Early research on generative AI shows larger productivity gains for less-skilled than for high-skilled workers. Whether AI ultimately acts as an equalizer or an amplifier of human cognitive differences is especially crucial for education systems, which must decide whether -- and how -- to allow students to use AI in coursework and exams. This decision is urgent because employers value workers who can leverage AI effectively rather than operate independently of it.",
    "authors": [
      "Maria Bigoni",
      "Andrea Ichino",
      "Aldo Rustichini",
      "Giulio Zanella"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03922",
    "title": "A Co-evolutionary Approach for Heston Calibration",
    "abstract": "We evaluate a co-evolutionary calibration framework for the Heston model in which a genetic algorithm (GA) over parameters is coupled to an evolving neural inverse map from option surfaces to parameters. While GA-history sampling can reduce training loss quickly and yields strong in-sample fits to the target surface, learning-curve diagnostics show a widening train--validation gap across generations, indicating substantial overfitting induced by the concentrated and less diverse dataset. In contrast, a broad, space-filling dataset generated via Latin hypercube sampling (LHS) achieves nearly comparable calibration accuracy while delivering markedly better out-of-sample stability across held-out surfaces. These results suggest that apparent improvements from co-evolutionary data generation largely reflect target-specific specialization rather than a more reliable global inverse mapping, and that maintaining dataset diversity is critical for robust amortized calibration.",
    "authors": [
      "Julian Gutierrez"
    ],
    "primary_category": "q-fin.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04047",
    "title": "Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs",
    "abstract": "In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.",
    "authors": [
      "Nadav Kunievsky"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03088",
    "title": "From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection",
    "abstract": "As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.",
    "authors": [
      "Giulio Caldarelli"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03107",
    "title": "Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%",
    "abstract": "Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.",
    "authors": [
      "Mainak Singha"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.17096",
    "title": "Why is the estimation of metaorder impact with public market data so challenging?",
    "abstract": "Estimating market impact and transaction costs of large trades (metaorders) is a very important topic in finance. However, using models of price and trade based on public market data provide average price trajectories which are qualitatively different from what is observed during real metaorder executions: the price increases linearly, rather than in a concave way, during the execution and the amount of reversion after its end is very limited. We claim that this is a generic phenomenon due to the fact that even sophisticated statistical models are unable to correctly describe the origin of the autocorrelation of the order flow. We propose a modified Transient Impact Model which provides more realistic trajectories by assuming that only a fraction of the metaorder trading triggers market order flow. Interestingly, in our model there is a critical condition on the kernels of the price and order flow equations in which market impact becomes permanent.",
    "authors": [
      "Manuel Naviglio",
      "Giacomo Bormetti",
      "Francesco Campigli",
      "German Rodikov",
      "Fabrizio Lillo"
    ],
    "primary_category": "q-fin.TR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.04093",
    "title": "Dynamic Asset Pricing with α-MEU Model",
    "abstract": "We study a dynamic asset pricing problem in which a representative agent is ambiguous about the aggregate endowment growth rate and trades a risky stock, human capital, and a risk-free asset to maximize her preference value of consumption represented by the {\\alpha}-maxmin expected utility model. This preference model is known to be dynamically inconsistent, so we consider intra-personal equilibrium strategies for the representative agent and define the market equilibrium as the one in which the strategy that clears the market is an intra-personal equilibrium. We prove the existence and uniqueness of the market equilibrium and show that the asset prices in the equilibrium are the same as in the case when the agent does not perceive any ambiguity but believes in a particular probabilistic model of the endowment process. We show that with reasonable parameter values, the more ambiguity the agent perceives or the more ambiguity-averse she is, the lower the risk-free rate, the higher the stock price, the higher the stock risk premium, and the lower the stock volatility.",
    "authors": [
      "Jiacheng Fan",
      "Xue Dong He",
      "Ruocheng Wu"
    ],
    "primary_category": "q-fin.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.13099",
    "title": "Governance, productivity and economic development",
    "abstract": "This paper explores the interplay between transfer policies, R\\&D, corruption, and economic development using a general equilibrium model with heterogeneous agents and a government. The government collects taxes, redistributes fiscal revenues, and undertakes public investment (in R\\&D, infrastructure, etc.). Corruption is modeled as a fraction of tax revenues that is siphoned off and removed from the economy. We first establish the existence of a political-economic equilibrium. Then, using an analytically tractable framework with two private agents, we examine the effects of corruption and evaluate the impact of various policies, including redistribution and innovation-led strategies.",
    "authors": [
      "Cuong Le Van",
      "Ngoc-Sang Pham",
      "Thi Kim Cuong Pham",
      "Binh Tran-Nam"
    ],
    "primary_category": "q-fin.CP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05809",
    "title": "Coherent estimation of risk measures",
    "abstract": "We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.",
    "authors": [
      "Martin Aichele",
      "Igor Cialenco",
      "Damian Jelito",
      "Marcin Pitera"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00785",
    "title": "Comparative Analysis of OECD Countries Based on Energy Trilemma Index: A Clustering Approach",
    "abstract": "This study analyzes OECD countries in the context of the energy trilemma index and clusters countries with similar characteristics. In the study, the k-means clustering technique is used. The optimum number of clusters was determined using the Elbow method in combination with the Silhouette Index. Moreover, all results are visualized to enhance comprehensibility. The results show that countries such as Austria, Canada, Finland, and Denmark are in the high energy trilemma group with index scores of 82.2, 82.3, 82.7, and 83.3, respectively. Countries in the high group have achieved a high level of balance between energy security, energy equity, and environmental sustainability. In addition, countries such as Belgium, Hungary, Australia, the Czech Republic, and Estonia are in the medium energy trilemma group with index scores of 76.4, 76.6, 77.1, 77.6, and 78.7, respectively. Countries in the medium group have made progress in balancing the dimensions of the energy trilemma but have not yet reached excellence. However, countries such as Mexico, Türkiye, Colombia, and Costa Rica are in the low energy trilemma group with index scores of 63.1, 64.1, 64.8, and 69.3, respectively. These low energy trilemma group countries face significant challenges in balancing energy security, energy equity, and environmental sustainability and need to make improvements in these areas.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02676",
    "title": "Exploring the Impacts of Economic Growth on Ecosystem and Its Subcomponents in Turkiye",
    "abstract": "This study analyzes the impacts of economic growth on ecosystem in Turkiye. The study uses annual data for the period 1995-2021 and the ARDL method. The study utilizes the Ecosystem Vitality Index, a sub-dimension of the Environmental Performance Index. In addition, seven models were constructed to assess in detail the impact of economic growth on different dimensions of the ecosystem. The results show that economic growth has a significant impact in all models analyzed. However, the direction of this impact differs across ecosystem components. Economic growth is found to have a positive impact on agriculture and water resources. In these models, a 1% increase in GDP increases the agriculture and water resources indices by 0.074-0.672%. In contrast, economic growth has a negative impact on biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality. In these models, a 1% increase in GDP reduces the indices of biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality by 0.101-2.144%. The results suggest that the environmental costs of economic growth processes need to be considered. Environmentally friendly policies should be combined with sustainable development strategies to reduce the negative impacts of economic growth.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.13501",
    "title": "Target search optimization by threshold resetting",
    "abstract": "We introduce a new class of first passage time optimization driven by threshold resetting, inspired by many natural processes where crossing a critical limit triggers failure, degradation or transition. In here, search agents are collectively reset when a threshold is reached, creating event-driven, system-coupled simultaneous resets that induce long-range interactions. We develop a unified framework to compute search times for these correlated stochastic processes, with ballistic- and diffusive- searchers as key examples uncovering diverse optimization behaviors. A cost function, akin to breakdown penalties, reveals that optimal resetting can forestall larger losses. This formalism generalizes to broader stochastic systems with multiple degrees of freedom.",
    "authors": [
      "Arup Biswas",
      "Satya N Majumdar",
      "Arnab Pal"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.02158",
    "title": "Asset-liability management with Epstein-Zin utility under stochastic interest rate and unknown market price of risk",
    "abstract": "This paper solves a consumption-investment choice problem with Epstein-Zin recursive utility under partial information--unobservable market price of risk. The main novelty is the introduction of a terminal liability constraint, a feature directly motivated by practical portfolio management and insurance applications but absent from the recursive utility literature. Such constraint gives rise to a coupled forward-backward stochastic differential equation (FBSDE) whose well-posedness has not been addressed in earlier work. We provide an explicit solution to this FBSDE system--contrasting with the typical existence and uniqueness results with no closed-form expressions in the literature. Under mild additional assumptions, we also establish the Malliavin differentiability of the solution allowing the optimal investment strategy to be expressed as a conditional expectation of random variables that can be efficiently simulated. These results allows us to obtain the explicit expressions of the optimal controls and the value function. Finally, we quantify the utility loss from ignoring learning about the market price of risk, highlighting the economic significance of partial information.",
    "authors": [
      "Wilfried Kuissi-Kamdem"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03057",
    "title": "A note on the impossibility of conditional PAC-efficient reasoning in large language models",
    "abstract": "We prove an impossibility result for conditional Probably Approximately Correct (PAC)-efficient reasoning in large language models. While recent work has established marginal PAC efficiency guarantees for composite models that switch between expensive expert models and cheaper fast models, we show that conditional (pointwise) guarantees are impossible in the distribution-free setting. Specifically, for non-atomic input spaces, any algorithm achieving conditional PAC efficiency must be trivial in the sense that it defers to the expert model with probability at least $1-\\alpha$ for almost every input.",
    "authors": [
      "Hao Zeng"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03116",
    "title": "Assessing Extrapolation of Peaks Over Thresholds with Martingale Testing",
    "abstract": "We present the winning strategy for the EVA2025 Data Challenge, which aimed to estimate the probability of extreme precipitation events. These events occurred at most once in the dataset making the challenge fundamentally one of extrapolating extreme values. Given the scarcity of extreme events, we argue that a simple, robust modeling approach is essential. We adopt univariate models instead of multivariate ones and model Peaks Over Thresholds using Extreme Value Theory. Specifically, we fit an exponential distribution to model exceedances of the target variable above a high quantile (after seasonal adjustment). The novelty of our approach lies in using martingale testing to evaluate the extrapolation power of the procedure and to agnostically select the level of the high quantile. While this method has several limitations, we believe that framing extrapolation as a game opens the door to other agnostic approaches in Extreme Value Analysis.",
    "authors": [
      "Joseph de Vilmarest",
      "Olivier Wintenberger"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03208",
    "title": "Uncertainty Quantification for Large Language Model Reward Learning under Heterogeneous Human Feedback",
    "abstract": "We study estimation and statistical inference for reward models used in aligning large language models (LLMs). A key component of LLM alignment is reinforcement learning from human feedback (RLHF), where humans compare pairs of model-generated answers and their preferences are used to train a reward model. However, human feedback is inherently heterogeneous, creating significant challenges for reliable reward learning. To address this, we adopt a heterogeneous preference framework that jointly models the latent reward of answers and human rationality. This leads to a challenging biconvex optimization problem, which we solve via an alternating gradient descent algorithm. We establish theoretical guarantees for the resulting estimator, including its convergence and asymptotic distribution. These results enable the construction of confidence intervals for reward estimates. Leveraging these uncertainty quantification results, we conduct valid statistical comparisons between rewards and incorporate uncertainty into the best-of-$N$ (BoN) policy framework. Extensive simulations demonstrate the effectiveness of our method, and applications to real LLM data highlight the practical value of accounting for uncertainty in reward modeling for LLM alignment.",
    "authors": [
      "Pangpang Liu",
      "Junwei Lu",
      "Will Wei Sun"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03225",
    "title": "Convergence of a class of gradient-free optimisation schemes when the objective function is noisy, irregular, or both",
    "abstract": "We investigate the convergence properties of a class of iterative algorithms designed to minimize a potentially non-smooth and noisy objective function, which may be algebraically intractable and whose values may be obtained as the output of a black box. The algorithms considered can be cast under the umbrella of a generalised gradient descent recursion, where the gradient is that of a smooth approximation of the objective function. The framework we develop includes as special cases model-based and mollification methods, two classical approaches to zero-th order optimisation. The convergence results are obtained under very weak assumptions on the regularity of the objective function and involve a trade-off between the degree of smoothing and size of the steps taken in the parameter updates. As expected, additional assumptions are required in the stochastic case. We illustrate the relevance of these algorithms and our convergence results through a challenging classification example from machine learning.",
    "authors": [
      "Christophe Andrieu",
      "Nicolas Chopin",
      "Ettore Fincato",
      "Mathieu Gerber"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03234",
    "title": "Iterative Tilting for Diffusion Fine-Tuning",
    "abstract": "We introduce iterative tilting, a gradient-free method for fine-tuning diffusion models toward reward-tilted distributions. The method decomposes a large reward tilt $\\exp(\\lambda r)$ into $N$ sequential smaller tilts, each admitting a tractable score update via first-order Taylor expansion. This requires only forward evaluations of the reward function and avoids backpropagating through sampling chains. We validate on a two-dimensional Gaussian mixture with linear reward, where the exact tilted distribution is available in closed form.",
    "authors": [
      "Jean Pachebat",
      "Giovanni Conforti",
      "Alain Durmus",
      "Yazid Janati"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03235",
    "title": "Estimation of Semiparametric Factor Models with Missing Data",
    "abstract": "We study semiparametric factor models in high-dimensional panels where the factor loadings consist of a nonparametric component explained by observed covariates and an idiosyncratic component capturing unobserved heterogeneity. A key challenge in empirical applications is the presence of missing observations, which can distort both factor recovery and loading estimation. To address this issue, we develop a projected principal component analysis (PPCA) procedure that accommodates general missing-at-random mechanisms through inverse-probability weighting. We establish consistency and derive the asymptotic distributions of the estimated factors and loading functions, allowing the sieve dimension to diverge and permitting the time dimension to be either fixed or growing. Unlike classical PCA, PPCA achieves consistent factor estimation even when T is fixed, and the limiting distributions under missing data exhibit mixture normality with enlarged asymptotic variances. Theoretical results are supported by simulations and an empirical application. Our findings demonstrate that PPCA provides an effective and robust framework for estimating semiparametric factor models in the presence of missing data.",
    "authors": [
      "Sijie Zheng"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03243",
    "title": "Novelty detection on path space",
    "abstract": "We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.",
    "authors": [
      "Ioannis Gasteratos",
      "Antoine Jacquier",
      "Maud Lemercier",
      "Terry Lyons",
      "Cristopher Salvi"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03254",
    "title": "Assumption-Lean Differential Variance Inference for Heterogeneous Treatment Effect Detection",
    "abstract": "The conditional average treatment effect (CATE) is frequently estimated to refute the homogeneous treatment effect assumption. Under this assumption, all units making up the population under study experience identical benefit from a given treatment. Uncovering heterogeneous treatment effects through inference about the CATE, however, requires that covariates truly modifying the treatment effect be reliably collected at baseline. CATE-based techniques will necessarily fail to detect violations when effect modifiers are omitted from the data due to, for example, resource constraints. Severe measurement error has a similar impact. To address these limitations, we prove that the homogeneous treatment effect assumption can be gauged through inference about contrasts of the potential outcomes' variances. We derive causal machine learning estimators of these contrasts and study their asymptotic properties. We establish that these estimators are doubly robust and asymptotically linear under mild conditions, permitting formal hypothesis testing about the homogeneous treatment effect assumption even when effect modifiers are missing or mismeasured. Numerical experiments demonstrate that these estimators' asymptotic guarantees are approximately achieved in experimental and observational data alike. These inference procedures are then used to detect heterogeneous treatment effects in the re-analysis of randomized controlled trials investigating targeted temperature management in cardiac arrest patients.",
    "authors": [
      "Philippe A. Boileau",
      "Hani Zaki",
      "Gabriele Lileikyte",
      "Niklas Nielsen",
      "Patrick R. Lawler",
      "Mireille E. Schnitzer"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03255",
    "title": "Change Point Detection for Functional Autoregressive Processes on the Sphere",
    "abstract": "We introduce a novel framework for change point detection in spherical functional autoregressive (SPHAR) processes, enabling the identification of structural breaks in spatio-temporal random fields on the sphere. Our LASSO-regularized estimator, based on penalized dynamic programming in the harmonic domain, operates without knowledge of the number or locations of change points and offers non-asymptotic theoretical guarantees. This approach provides a new tool for analyzing nonstationary phenomena on the sphere, relevant to climate science, cosmology, and beyond.",
    "authors": [
      "Federica Spoto",
      "Alessia Caponera",
      "Pierpaolo Brutti"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03266",
    "title": "Invited Discussion of \"Model Uncertainty and Missing Data: An Objective Bayesian Perspective\" by Gonzalo García-Donato , María Eugenia Castellanos , Stefano Cabras Alicia Quirós , and Anabel Forte",
    "abstract": "The article by Garc{í}a-Donato and co-authors addresses the dual challenges of accounting for model uncertainty and missing data within the Gaussian regression frameworks from an objective Bayesian perspective. Thru the use of an imputation $g$-prior that replaces $X_\\gamma^TX_\\gamma$ for model $\\gamma$ in the covariance of $\\beta_\\gamma$ with $\\Sigma_{X_\\gamma}$, the authors develop a coherent approach to addressing the missing data problem and model uncertainty simultaneously with random $X_\\gamma$ in the missing at random (MAR) or missing completely at random (MCAR) settings, while still being computationally tractable. I discuss the connection of the imputation $g$-prior to the $g$-prior with imputed $X$, and to model selection for graphical models that provide an alternative justification for the $g$-prior for random $X$s.",
    "authors": [
      "Merlise A Clyde"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03321",
    "title": "Numerical optimization for the compatibility constant of the lasso",
    "abstract": "Compatibility condition and compatibility constant have been commonly used to evaluate the prediction error of the lasso when the number of variables exceeds the number of observations. However, the computation of the compatibility constant is generally difficult because it is a complicated nonlinear optimization problem. In this study, we present a numerical approach to compute the compatibility constant when the zero/nonzero pattern of true regression coefficients is given. We show that the optimization problem reduces to a quadratic program (QP) once the signs of the nonzero coefficients are specified. In this case, the compatibility constant can be obtained by solving QPs for all possible sign combinations. We also formulate a mixed-integer quadratic programming (MIQP) approach that can be applied when the number of true nonzero coefficients is moderately large. We investigate the finite-sample behavior of the compatibility constant for simulated data under a wide variety of parameter settings and compare the mean squared error with its theoretical error bound based on the compatibility constant. The behavior of the compatibility constant in finite samples is also investigated through a real data analysis.",
    "authors": [
      "Kei Hirose"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03322",
    "title": "SSLfmm: An R Package for Semi-Supervised Learning with a Mixed-Missingness Mechanism in Finite Mixture Models",
    "abstract": "Semi-supervised learning (SSL) constructs classifiers from datasets in which only a subset of observations is labelled, a situation that naturally arises because obtaining labels often requires expert judgement or costly manual effort. This motivates methods that integrate labelled and unlabelled data within a learning framework. Most SSL approaches assume that label absence is harmless, typically treated as missing completely at random or ignored, but in practice, the missingness process can be informative, as the chances of an observation being unlabelled may depend on the ambiguity of its feature vector. In such cases, the missingness indicators themselves provide additional information that, if properly modelled, may improve estimation efficiency. The \\textbf{SSLfmm} package for R is designed to capture this behaviour by estimating the Bayes' classifier under a finite mixture model in which each component corresponding to a class follows a multivariate normal distribution. It incorporates a mixed-missingness mechanism that combines a missing completely at random (MCR) component with a (non-ignorable) missing at random (MAR) component, the latter modelling the probability of label missingness as a logistic function of the entropy based on the features. Parameters are estimated via an Expectation--Conditional Maximisation algorithm. In the two-class Gaussian setting with arbitrary covariance matrices, the resulting classifier trained on partially labelled data may, in some cases, achieve a lower misclassification rate than the supervised version in the case where all the labels are known. The package includes a practical tool for modelling and illustrates its performance through simulated examples.",
    "authors": [
      "Geoffrey J. McLachlan",
      "Jinran Wu"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03325",
    "title": "When does Gaussian equivalence fail and how to fix it: Non-universal behavior of random features with quadratic scaling",
    "abstract": "A major effort in modern high-dimensional statistics has been devoted to the analysis of linear predictors trained on nonlinear feature embeddings via empirical risk minimization (ERM). Gaussian equivalence theory (GET) has emerged as a powerful universality principle in this context: it states that the behavior of high-dimensional, complex features can be captured by Gaussian surrogates, which are more amenable to analysis. Despite its remarkable successes, numerical experiments show that this equivalence can fail even for simple embeddings -- such as polynomial maps -- under general scaling regimes. We investigate this breakdown in the setting of random feature (RF) models in the quadratic scaling regime, where both the number of features and the sample size grow quadratically with the data dimension. We show that when the target function depends on a low-dimensional projection of the data, such as generalized linear models, GET yields incorrect predictions. To capture the correct asymptotics, we introduce a Conditional Gaussian Equivalent (CGE) model, which can be viewed as appending a low-dimensional non-Gaussian component to an otherwise high-dimensional Gaussian model. This hybrid model retains the tractability of the Gaussian framework and accurately describes RF models in the quadratic scaling regime. We derive sharp asymptotics for the training and test errors in this setting, which continue to agree with numerical simulations even when GET fails. Our analysis combines general results on CLT for Wiener chaos expansions and a careful two-phase Lindeberg swapping argument. Beyond RF models and quadratic scaling, our work hints at a rich landscape of universality phenomena in high-dimensional ERM.",
    "authors": [
      "Garrett G. Wen",
      "Hong Hu",
      "Yue M. Lu",
      "Zhou Fan",
      "Theodor Misiakiewicz"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03513",
    "title": "Seasonal trend assessment of US extreme precipitation via changepoint segmentation",
    "abstract": "Most climate trend studies analyze long-term trends as a proxy for climate dynamics. However, when examining seasonal data, it is unrealistic to assume that long-term trends remain consistent across all seasons. Instead, each season likely experiences distinct trends. Additionally, seasonal climate time series, such as seasonal maximum precipitation, often exhibit nonstationarities, including periodicities and location shifts. Failure to rigorously account for these features in modeling may lead to inaccurate trend estimates. This study quantifies seasonal trends in the contiguous United States' seasonal maximum precipitation series while addressing these nonstationarities. To ensure accurate trend estimation, we identify changepoints where the seasonal maximum precipitation shifts due to factors like measurement device changes, observer differences, or location moves. We employ a penalized likelihood method to estimate multiple changepoints, incorporating a generalized extreme value distribution with periodic features. A genetic algorithm based search algorithm efficiently explores the vast space of potential changepoints in both number and timing. Additionally, we compute seasonal return levels for extreme precipitation. Our methods are illustrated using two selected stations, and the results for the US are summarized through maps. We find that seasonal trends vary more when changepoints are considered than in studies that ignore them. Our findings also reveal distinct regional and seasonal patterns, with increasing trends more prevalent during fall in the South and along the East Coast when changepoints are accounted for.",
    "authors": [
      "Jaechoul Lee",
      "Mintaek Lee",
      "Thea Sukianto"
    ],
    "primary_category": "stat.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03543",
    "title": "Parsimonious Factor Models for Asymmetric Dependence in Multivariate Extremes",
    "abstract": "Modelling multivariate extreme events is essential when extrapolating beyond the range of observed data. Parametric models that are suitable for real-world extremes must be flexible -- particularly in their ability to capture asymmetric dependence structures -- while also remaining parsimonious for interpretability and computationally scalable in high dimensions. Although many models have been proposed, it is rare for any single construction to satisfy all of these requirements. For instance, the popular Hüsler-Reiss model is limited to symmetric dependence structures. In this manuscript, we introduce a class of additive factor models and derive their extreme-value limits. This leads to a broad and tractable family of models characterised by a manageable number of parameters. These models naturally accommodate asymmetric tail dependence and allow for non-stationary behaviour. We present the limiting models from both the componentwise-maxima and Peaks-over-Thresholds perspectives, via the multivariate extreme value and multivariate generalized Pareto distributions, respectively. Simulation studies illustrate identifiability properties based on existing inference methodologies. Finally, applications to summer temperature maxima in Melbourne, Australia, and to weekly negative returns from four major UK banks demonstrate improved fit compared with the Hüsler-Reiss model.",
    "authors": [
      "Pavel Krupskii",
      "Boris Berangér"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03727",
    "title": "Colored Markov Random Fields for Probabilistic Topological Modeling",
    "abstract": "Probabilistic Graphical Models (PGMs) encode conditional dependencies among random variables using a graph -nodes for variables, links for dependencies- and factorize the joint distribution into lower-dimensional components. This makes PGMs well-suited for analyzing complex systems and supporting decision-making. Recent advances in topological signal processing highlight the importance of variables defined on topological spaces in several application domains. In such cases, the underlying topology shapes statistical relationships, limiting the expressiveness of canonical PGMs. To overcome this limitation, we introduce Colored Markov Random Fields (CMRFs), which model both conditional and marginal dependencies among Gaussian edge variables on topological spaces, with a theoretical foundation in Hodge theory. CMRFs extend classical Gaussian Markov Random Fields by including link coloring: connectivity encodes conditional independence, while color encodes marginal independence. We quantify the benefits of CMRFs through a distributed estimation case study over a physical network, comparing it with baselines with different levels of topological prior.",
    "authors": [
      "Lorenzo Marinucci",
      "Leonardo Di Nino",
      "Gabriele D'Acunto",
      "Mario Edoardo Pandolfo",
      "Paolo Di Lorenzo",
      "Sergio Barbarossa"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03738",
    "title": "Weighted Conformal Prediction for Survival Analysis under Covariate Shift",
    "abstract": "Reliable uncertainty quantification is essential in survival prediction, particularly in clinical settings where erroneous decisions carry high risk. Conformal prediction has attracted substantial attention as it offers a model-agnostic framework with finite-sample coverage guarantees. Extending it to right-censored outcomes poses nontrivial challenges. Several adaptations of conformal approaches for survival outcomes have been developed, but they either rely on restrictive censoring settings or substantial computation. A recent conformal approach for right-censored data constructs censoring-adjusted p-values and enables prediction intervals in general survival settings. However, the empirical coverage depends sensitively on heuristic tuning choices and its validity is limited to scenarios without covariate shift. In this paper, we establish theoretical justification for its prediction-set construction, providing a principled basis for defining prediction-set bounds, and extend the approach to covariate-shift settings. Simulation studies and a real data application demonstrate that the proposed method achieves robust coverage and coherent interval structure across varying censoring levels and covariate-shift settings.",
    "authors": [
      "Jaeyoung Shin",
      "Chi Hyun Lee",
      "Sangwook Kang"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03760",
    "title": "A decay-adjusted spatio-temporal model to account for the impact of mass drug administration on neglected tropical disease prevalence",
    "abstract": "Prevalence surveys are routinely used to monitor the effectiveness of mass drug administration (MDA) programmes for controlling neglected tropical diseases (NTDs). We propose a decay-adjusted spatio-temporal (DAST) model that explicitly accounts for the time-varying impact of MDA on NTD prevalence, providing a flexible and interpretable framework for estimating intervention effects from sparse survey data. Using case studies on soil-transmitted helminths and lymphatic filariasis, we show that DAST offers a practical alternative to standard geostatistical models when the objective includes quantifying MDA impact and supporting short-term programmatic forecasting. We also discuss extensions and identifiability challenges, advocating for data-driven parsimony over complexity in settings where the available data are too sparse to support the estimation of highly parameterised models.",
    "authors": [
      "Emanuele Giorgi",
      "Claudio Fronterre",
      "Peter J. Diggle"
    ],
    "primary_category": "stat.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03761",
    "title": "Using functional information for binary classifications",
    "abstract": "The adequate use of information measured in a continuous manner along a period of time represents a methodological challenge. In the last decades, most of traditional statistical procedures have been extended for accommodating these functional data. The binary classification problem, which aims to correctly identify units as positive or negative based on marker values, is not aside of this scenario. The crucial point for making binary classifications based on a marker is to establish an order in the marker values, which is not immediate when these values are presented as functions. Here, we argue that if the marker is related to the characteristic under study, a trajectory from a positive participant should be more similar to trajectories from the positive population than to those drawn from the negative. With this criterion, a classification procedure based on the distance between the involved functions is proposed. Besides, we propose a fully non-parametric estimator for this so-called probability-based criterion, PBC. We explore its asymptotic properties, and its finite-sample behavior from an extensive Monte Carlo study. The observed results suggest that the proposed methodology works adequately, and frequently better than its competitors, for a wide variety of situations when the sample size in both the training and the testing cohorts is adequate. The practical use of the proposal is illustrated from real-world dataset. As online supplementary material, the manuscript includes a document with further simulations and additional comments. An R function which wraps up the implemented routines is also provided.",
    "authors": [
      "Pablo Martinez-Camblor"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03777",
    "title": "A comparison between initialization strategies for the infinite hidden Markov model",
    "abstract": "Infinite hidden Markov models provide a flexible framework for modelling time series with structural changes and complex dynamics, without requiring the number of latent states to be specified in advance. This flexibility is achieved through the hierarchical Dirichlet process prior, while efficient Bayesian inference is enabled by the beam sampler, which combines dynamic programming with slice sampling to truncate the infinite state space adaptively. Despite extensive methodological developments, the role of initialization in this framework has received limited attention. This study addresses this gap by systematically evaluating initialization strategies commonly used for finite hidden Markov models and assessing their suitability in the infinite setting. Results from both simulated and real datasets show that distance-based clustering initializations consistently outperform model-based and uniform alternatives, the latter being the most widely adopted in the existing literature.",
    "authors": [
      "Federico P. Cortese",
      "Luca Rossini"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03851",
    "title": "Comparison of neural network training strategies for the simulation of dynamical systems",
    "abstract": "Neural networks have become a widely adopted tool for modeling nonlinear dynamical systems from data. However, the choice of training strategy remains a key design decision, particularly for simulation tasks. This paper compares two predominant strategies: parallel and series-parallel training. The conducted empirical analysis spans five neural network architectures and two examples: a pneumatic valve test bench and an industrial robot benchmark. The study reveals that, even though series-parallel training dominates current practice, parallel training consistently yields better long-term prediction accuracy. Additionally, this work clarifies the often inconsistent terminology in the literature and relate both strategies to concepts from system identification. The findings suggest that parallel training should be considered the default training strategy for neural network-based simulation of dynamical systems.",
    "authors": [
      "Paul Strasser",
      "Andreas Pfeffer",
      "Jakob Weber",
      "Markus Gurtner",
      "Andreas Körner"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03859",
    "title": "SUP: An Inferable Private Multiple Testing Framework with Super Uniformity",
    "abstract": "Multiple testing is widely applied across scientific fields, particularly in genomic and health data analysis, where protecting sensitive personal information is imperative. However, developing private multiple testing algorithms for super uniform $p$-values remains an open question, as privacy mechanisms introduce intricate dependence among the peeled $p$-values and disrupt their super uniformity, complicating post-selection inference. To address this, we introduce a general Super Uniform Private (SUP) multiple testing framework with three key components. First, we develop a novel \\( p \\)-value transformation that is compatible with diverse privacy regimes while retaining the super uniformity. Next, a reversed peeling algorithm is designed to reduce privacy budgets while facilitating inference. Then, we provide diverse rejection thresholds that are privacy-parameter-free and tailored for different Type-I errors, including the family-wise error rate (FWER) and the false discovery rate (FDR). Building upon these, we advance adaptive techniques to determine the peeling number and boost thresholds. Theoretically, we propose a technique overcoming the post-selection obstacle to Type-I error control, quantify the privacy-induced power loss of SUP relative to its non-private counterpart, and demonstrate that SUP surpasses existing private methods in terms of power. The results of extensive simulations and a real data application validate our theories.",
    "authors": [
      "Kehan Wang",
      "Wenxuan Song",
      "Wangli Xu",
      "Linglong Kong"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03912",
    "title": "Parsimonious Clustering of Covariance Matrices",
    "abstract": "Functional connectivity (FC) derived from functional magnetic resonance imaging (fMRI) data offers vital insights for understanding brain function and neurological and psychiatric disorders. Unsupervised clustering methods are desired to group individuals based on shared features, facilitating clinical diagnosis. In this study, a parsimonious clustering model is proposed, which integrates the Mixture-of-Experts (MoE) and covariance regression framework, to cluster individuals based on FC captured by data covariance matrices in resting-state fMRI studies. The model assumes common linear projections across covariance matrices and a generalized linear model with covariates, allowing for flexible yet interpretable projection-specific clustering solutions. To evaluate the performance of the proposed framework, extensive simulation studies are conducted to assess clustering accuracy and robustness. The approach is applied to resting-state fMRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Subgroups are identified based on brain coherence and simultaneously uncover the association with demographic factors and cognitive functions.",
    "authors": [
      "Yixi Xu",
      "Yi Zhao"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03946",
    "title": "When are novel methods for analyzing complex chemical mixtures in epidemiology beneficial?",
    "abstract": "Estimating the health impacts of exposure to a mixture of chemicals poses many statistical challenges: multiple correlated exposure variables, moderate to high dimensionality, and possible nonlinear and interactive health effects of mixture components. Reviews of chemical mixture methods aim to help researchers select a statistical method suited to their goals and data, but examinations of empirical performance have emphasized novel methods purpose-built for analyzing complex chemical mixtures, or other more advanced methods, over more general methods which are widely used in many application domains. We conducted a broad experimental comparison, across simulated scenarios, of both more general methods (such as generalized linear models) and novel methods (such as Bayesian Kernel Machine Regression) designed to study chemical mixtures. We assessed methods based on their ability to control Type I error rate, maximize power, provide interpretable results, and make accurate predictions. We find that when there is moderate correlation between mixture components and the exposure-response function does not have complicated interactions, or when mixture components have opposite effects, general methods are preferred over novel ones. With highly interactive exposure-response functions or highly correlated exposures, novel methods provide important benefits. We provide a comprehensive summary of when different methods are most suitable.",
    "authors": [
      "Nate Wiecha",
      "Emily Griffith",
      "Brian J. Reich",
      "Jane A. Hoppin"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03983",
    "title": "Statistical hypothesis testing for differences between layers in dynamic multiplex networks",
    "abstract": "With the emergence of dynamic multiplex networks, corresponding to graphs where multiple types of edges evolve over time, a key inferential task is to determine whether the layers associated with different edge types differ in their connectivity. In this work, we introduce a hypothesis testing framework, under a latent space network model, for assessing whether the layers share a common latent representation. The method we propose extends previous literature related to the problem of pairwise testing for random graphs and enables global testing of differences between layers in multiplex graphs. While we introduce the method as a test for differences between layers, it can easily be adapted to test for differences between time points. We construct a test statistic based on a spectral embedding of an unfolded representation of the graph adjacency matrices and demonstrate its ability to detect differences across layers in the asymptotic regime where the number of nodes in each graph tends to infinity. The finite-sample properties of the test are empirically demonstrated by assessing its performance on both simulated data and a biological dataset describing the neural activity of larval Drosophila.",
    "authors": [
      "Maximilian Baum",
      "Francesco Sanna Passino",
      "Axel Gandy"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04059",
    "title": "Inference for location and height of peaks of a standardized field after selection",
    "abstract": "Peak inference concerns the use of local maxima (\"peaks\") of a noisy random field to detect and localize regions where underlying signal is present. We propose a peak inference method that first subjects observed peaks to a significance test of the null hypothesis that no signal is present, and then uses the peaks that are declared significant to construct post-selectively valid confidence regions for the location and height of nearby true peaks. We analyze the performance of this method in a smooth signal plus constant variance noise model under a high-curvature asymptotic assumption, and prove that it asymptotically controls both the number of false discoveries, and the number of confidence regions that do not contain a true peak, relative to the number of points at which inference is conducted. An important intermediate theoretical result uses the Kac-Rice formula to derive a novel approximation to the intensity function of a point process that counts local maxima, which is second-order accurate under the alternative, nearby high-curvature true peaks.",
    "authors": [
      "Alden Green",
      "Jonathan Taylor"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03060",
    "title": "A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap",
    "abstract": "Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale. We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.",
    "authors": [
      "Jing Pan",
      "Li Shi",
      "Paul Lo"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03062",
    "title": "Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing",
    "abstract": "Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \\textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \\textbf{PivGa}, an additional \\textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.",
    "authors": [
      "Roman Rausch",
      "David Jansen",
      "Sukhbinder Singh",
      "Román Orús"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03081",
    "title": "Calibrating Geophysical Predictions under Constrained Probabilistic Distributions",
    "abstract": "Machine learning (ML) has shown significant promise in studying complex geophysical dynamical systems, including turbulence and climate processes. Such systems often display sensitive dependence on initial conditions, reflected in positive Lyapunov exponents, where even small perturbations in short-term forecasts can lead to large deviations in long-term outcomes. Thus, meaningful inference requires not only accurate short-term predictions, but also consistency with the system's long-term attractor that is captured by the marginal distribution of state variables. Existing approaches attempt to address this challenge by incorporating spatial and temporal dependence, but these strategies become impractical when data are extremely sparse. In this work, we show that prior knowledge of marginal distributions offers valuable complementary information to short-term observations, motivating a distribution-informed learning framework. We introduce a calibration algorithm based on normalization and the Kernelized Stein Discrepancy (KSD) to enhance ML predictions. The method here employs KSD within a reproducing kernel Hilbert space to calibrate model outputs, improving their fidelity to known physical distributions. This not only sharpens pointwise predictions but also enforces consistency with non-local statistical structures rooted in physical principles. Through synthetic experiments-spanning offline climatological CO2 fluxes and online quasi-geostrophic flow simulations-we demonstrate the robustness and broad utility of the proposed framework.",
    "authors": [
      "Zhewen Hou",
      "Jiajin Sun",
      "Subashree Venkatasubramanian",
      "Peter Jin",
      "Shuolin Li",
      "Tian Zheng"
    ],
    "primary_category": "physics.ao-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03102",
    "title": "Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration",
    "abstract": "In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.",
    "authors": [
      "Yiwei Shi",
      "Hongnan Ma",
      "Mengyue Yang",
      "Cunjia Liu",
      "Weiru Liu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03107",
    "title": "Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%",
    "abstract": "Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.",
    "authors": [
      "Mainak Singha"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03109",
    "title": "E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing",
    "abstract": "Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.",
    "authors": [
      "Shuvom Sadhuka",
      "Drew Prinster",
      "Clara Fannjiang",
      "Gabriele Scalia",
      "Aviv Regev",
      "Hanchen Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03112",
    "title": "Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability",
    "abstract": "Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.",
    "authors": [
      "Jialai She"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03238",
    "title": "How to DP-fy Your Data: A Practical Guide to Generating Synthetic Data With Differential Privacy",
    "abstract": "High quality data is needed to unlock the full potential of AI for end users. However finding new sources of such data is getting harder: most publicly-available human generated data will soon have been used. Additionally, publicly available data often is not representative of users of a particular system -- for example, a research speech dataset of contractors interacting with an AI assistant will likely be more homogeneous, well articulated and self-censored than real world commands that end users will issue. Therefore unlocking high-quality data grounded in real user interactions is of vital interest. However, the direct use of user data comes with significant privacy risks. Differential Privacy (DP) is a well established framework for reasoning about and limiting information leakage, and is a gold standard for protecting user privacy. The focus of this work, \\emph{Differentially Private Synthetic data}, refers to synthetic data that preserves the overall trends of source data,, while providing strong privacy guarantees to individuals that contributed to the source dataset. DP synthetic data can unlock the value of datasets that have previously been inaccessible due to privacy concerns and can replace the use of sensitive datasets that previously have only had rudimentary protections like ad-hoc rule-based anonymization. In this paper we explore the full suite of techniques surrounding DP synthetic data, the types of privacy protections they offer and the state-of-the-art for various modalities (image, tabular, text and decentralized). We outline all the components needed in a system that generates DP synthetic data, from sensitive data handling and preparation, to tracking the use and empirical privacy testing. We hope that work will result in increased adoption of DP synthetic data, spur additional research and increase trust in DP synthetic data approaches.",
    "authors": [
      "Natalia Ponomareva",
      "Zheng Xu",
      "H. Brendan McMahan",
      "Peter Kairouz",
      "Lucas Rosenblatt",
      "Vincent Cohen-Addad",
      "Cristóbal Guzmán",
      "Ryan McKenna",
      "Galen Andrew",
      "Alex Bie",
      "Da Yu",
      "Alex Kurakin",
      "Morteza Zadimoghaddam",
      "Sergei Vassilvitskii",
      "Andreas Terzis"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03242",
    "title": "A Theoretical Framework Bridging Model Validation and Loss Ratio in Insurance",
    "abstract": "This paper establishes the first analytical relationship between predictive model performance and loss ratio in insurance pricing. We derive a closed-form formula connecting the Pearson correlation between predicted and actual losses to expected loss ratio. The framework proves that model improvements exhibit diminishing marginal returns, analytically confirming the actuarial intuition to prioritize poorly performing models. We introduce the Loss Ratio Error metric for quantifying business impact across frequency, severity, and pure premium models. Simulations show reliable predictions under stated assumptions, with graceful degradation under assumption violations. This framework transforms model investment decisions from qualitative intuition to quantitative cost-benefit analysis.",
    "authors": [
      "C. Evans Hedges"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03333",
    "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State",
    "abstract": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation.",
    "authors": [
      "Xun Tang",
      "Haoxuan Chen",
      "Yuehaw Khoo",
      "Lexing Ying"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03336",
    "title": "Single-Round Scalable Analytic Federated Learning",
    "abstract": "Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.",
    "authors": [
      "Alan T. L. Bacellar",
      "Mustafa Munir",
      "Felipe M. G. França",
      "Priscila M. V. Lima",
      "Radu Marculescu",
      "Lizy K. John"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03354",
    "title": "Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions",
    "abstract": "Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.",
    "authors": [
      "Hongseon Yeom",
      "Jaeyoul Shin",
      "Soojin Min",
      "Jeongmin Yoon",
      "Seunghak Yu",
      "Dongyeop Kang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03393",
    "title": "Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization",
    "abstract": "Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a \"momentum-like\" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.",
    "authors": [
      "Lakshmi Jayalal",
      "Sheetal Kalyani"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03428",
    "title": "GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test",
    "abstract": "We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.",
    "authors": [
      "Ziyi Ding",
      "Xiao-Ping Zhang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03467",
    "title": "Bayesian Event-Based Model for Disease Subtype and Stage Inference",
    "abstract": "Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.",
    "authors": [
      "Hongtao Hao",
      "Joseph L. Austerweil"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03475",
    "title": "Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression",
    "abstract": "Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.",
    "authors": [
      "Hongtao Hao",
      "Joseph L. Austerweil"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03537",
    "title": "Parameter-Efficient Augment Plugin for Class-Incremental Learning",
    "abstract": "Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL this http URL treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.",
    "authors": [
      "Zhiming Xu",
      "Baile Xu",
      "Jian Zhao",
      "Furao Shen",
      "Suorong Yang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03579",
    "title": "Optimal Transportation and Alignment Between Gaussian Measures",
    "abstract": "Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.",
    "authors": [
      "Sanjit Dandapanthula",
      "Aleksandr Podkopaev",
      "Shiva Prasad Kasiviswanathan",
      "Aaditya Ramdas",
      "Ziv Goldfeld"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03637",
    "title": "AaPE: Aliasing-aware Patch Embedding for Self-Supervised Audio Representation Learning",
    "abstract": "Transformer-based audio SSL (self-supervised learning) models often treat spectrograms as images, applying convolutional patchification with heavy temporal downsampling. This lowers the effective Nyquist frequency and introduces aliasing, while naïve low-pass filtering removes task-relevant high-frequency cues. In this study, we present Aliasing-aware Patch Embedding (AaPE), a drop-in patch stem that mitigates aliasing while preserving high-frequency information. AaPE augments standard patch tokens with features produced by a band-limited complex sinusoidal kernel using a two-sided exponential window that dynamically targets alias-prone bands. Frequency and decay parameters of the kernel are estimated from the input, enabling parallel, adaptive subband analysis whose outputs are fused with the standard patch tokens. AaPE integrates seamlessly into the masked teacher-student self-supervised learning. In addition, we combine a multi-mask strategy with a contrastive objective to enforce consistency across diverse mask patterns, stabilizing training. Pre-training on AudioSet followed by fine-tuning evaluation across diverse downstream benchmarks, which spanned categories, such as environmental sounds and other common audio domains. This approach yields state-of-the-art performance on a subset of tasks and competitive results across the remainder. Complementary linear probing evaluation mirrors this pattern, yielding clear gains on several benchmarks and strong performance elsewhere. The collective analysis of these results indicates that AaPE serves to mitigate the effects of aliasing without discarding of informative high-frequency content.",
    "authors": [
      "Kohei Yamamoto",
      "Kosuke Okusa"
    ],
    "primary_category": "cs.SD",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03763",
    "title": "Learning from crises: A new class of time-varying parameter VARs with observable adaptation",
    "abstract": "We revisit macroeconomic time-varying parameter vector autoregressions (TVP-VARs), whose persistent coefficients may adapt too slowly to large, abrupt shifts such as those during major crises. We explore the performance of an adaptively-varying parameter (AVP) VAR that incorporates deterministic adjustments driven by observable exogenous variables, replacing latent state innovations with linear combinations of macroeconomic and financial indicators. This reformulation collapses the state equation into the measurement equation, enabling simple linear estimation of the model. Simulations show that adaptive parameters are substantially more parsimonious than conventional TVPs, effectively disciplining parameter dynamics without sacrificing flexibility. Using macroeconomic datasets for both the U.S. and the euro area, we demonstrate that AVP-VAR consistently improves out-of-sample forecasts, especially during periods of heightened volatility.",
    "authors": [
      "Nicolas Hardy",
      "Dimitris Korobilis"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03807",
    "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics",
    "abstract": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.",
    "authors": [
      "Christos Kolomvakis",
      "Thomas Bobille",
      "Arnaud Vandaele",
      "Nicolas Gillis"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03899",
    "title": "Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction",
    "abstract": "Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.",
    "authors": [
      "Janis Keck",
      "Lukas Silvester Barth",
      "Fatemeh",
      "Fahimi",
      "Parvaneh Joharinad",
      "Jürgen Jost"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04006",
    "title": "Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics",
    "abstract": "Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.",
    "authors": [
      "Connall Garrod",
      "Jonathan P. Keating",
      "Christos Thrampoulidis"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04058",
    "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap",
    "abstract": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.",
    "authors": [
      "Shashaank Khanna",
      "Matthew Pusey",
      "Roger Colbeck"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.05025",
    "title": "Unbiased Kinetic Langevin Monte Carlo with Inexact Gradients",
    "abstract": "We present an unbiased method for Bayesian posterior means based on kinetic Langevin dynamics that combines advanced splitting methods with enhanced gradient approximations. Our approach avoids Metropolis correction by coupling Markov chains at different discretization levels in a multilevel Monte Carlo approach. Theoretical analysis demonstrates that our proposed estimator is unbiased, attains finite variance, and satisfies a central limit theorem. It can achieve accuracy $\\epsilon>0$ for estimating expectations of Lipschitz functions in $d$ dimensions with $\\mathcal{O}(d^{1/4}\\epsilon^{-2})$ expected gradient evaluations, without assuming warm start. We exhibit similar bounds using both approximate and stochastic gradients, and our method's computational cost is shown to scale independently of the size of the dataset. The proposed method is tested using a multinomial regression problem on the MNIST dataset and a Poisson regression model for soccer scores. Experiments indicate that the number of gradient evaluations per effective sample is independent of dimension, even when using inexact gradients. For product distributions, we give dimension-independent variance bounds. Our results demonstrate that in large-scale applications, the unbiased algorithm we present can be 2-3 orders of magnitude more efficient than the ``gold-standard\" randomized Hamiltonian Monte Carlo.",
    "authors": [
      "Neil K. Chada",
      "Benedict Leimkuhler",
      "Daniel Paulin",
      "Peter A. Whalley"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2312.10596",
    "title": "A maximin optimal approach for sampling designs in two-phase studies",
    "abstract": "Data collection costs can vary widely across variables in data science tasks. Two-phase designs can be employed to save data collection costs. This paper considers the two-phase studies where inexpensive variables are collected for all subjects in the first phase, and expensive variables are measured for a subsample of subjects in the second phase based on a predetermined sampling rule. The estimation efficiency under two-phase designs relies heavily on the sampling rule. Existing literature primarily focuses on designing sampling rules for estimating a scalar parameter in some parametric models or specific estimating problems. However, real-world scenarios are usually model-unknown and involve two-phase designs for model-free estimation of a scalar or multi-dimensional parameter. This paper proposes a maximin criterion to design an optimal sampling rule based on semiparametric efficiency bounds. The proposed method is model-free and applicable to general estimating problems. The resulting sampling rule can minimize the semiparametric efficiency bound when the parameter is scalar and improve the bound for every component when the parameter is multi-dimensional. Simulation studies demonstrate that the proposed designs reduce the variance of the resulting estimator in various settings. The implementation of the proposed design is illustrated in a real data analysis.",
    "authors": [
      "Ruoyu Wang",
      "Qihua Wang",
      "Wang Miao"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2401.01264",
    "title": "Multiple Randomization Designs: Estimation and Inference with Interference",
    "abstract": "Classical designs of randomized experiments, going back to Fisher and Neyman in the 1930s still dominate practice even in online experimentation. However, such designs are of limited value for answering standard questions in settings, common in marketplaces, where multiple populations of agents interact strategically, leading to complex patterns of spillover effects. In this paper, we discuss new experimental designs and corresponding estimands to account for and capture these complex spillovers. We derive the finite-sample properties of tractable estimators for main effects, direct effects, and spillovers, and present associated central limit theorems.",
    "authors": [
      "Lorenzo Masoero",
      "Suhas Vijaykumar",
      "Thomas Richardson",
      "James McQueen",
      "Ido Rosen",
      "Brian Burdick",
      "Pat Bajari",
      "Guido Imbens"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.00888",
    "title": "Gradient-free optimization via integration",
    "abstract": "We develop and analyse an approach to optimize functions $l\\colon \\mathbb{R}^d \\rightarrow \\mathbb{R}$ not assumed to be convex, differentiable or even continuous. The algorithm belongs to the class of model-based search methods. The idea is to fit recursively $l$ to a parametric family of distributions, using a Bayesian update followed by a reprojection back onto the chosen family. Remarkably, reprojection in our scenario boils down to computing expectations, which can be simply approximated through Monte Carlo. We show that when the family of distributions is appropriately chosen this approach can be interpreted as an implicit time-inhomogeneous gradient descent algorithm on a sequence of smoothed approximations of $l$, providing a route to establishing convergence. We establish new results for generic inhomogeneous gradient descent algorithms, which we specialise to the model-based search algorithm in the Gaussian scenario. We illustrate the performance of the algorithm on a challenging classification task in machine learning.",
    "authors": [
      "Christophe Andrieu",
      "Nicolas Chopin",
      "Ettore Fincato",
      "Mathieu Gerber"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2408.12618",
    "title": "Refining Genetic Discoveries of Group Knockoffs via A Feature-level Filter",
    "abstract": "Identifying variants that carry substantial information on the trait of interest remains a core topic in genetic studies. In analyzing the EADB-UKBB dataset to identify genetic variants associated with Alzheimer's disease (AD), however, we recognize that both existing marginal association tests and conditional independence tests using existing knockoff filters suffer either power loss or lack of informativeness, especially when strong correlations exist among variants. To address these limitations, we propose a new feature-versus-group (FVG) filter that achieves balance between the power and precision in identifying important features from a set of strongly correlated features using group knockoffs. In extensive simulation studies, the FVG filter controls the expected proportion of false discoveries and identifies important features in smaller catching sets without large power loss. Applying the proposed method to the EADB-UKBB dataset, we discover important variants from 89 loci (similar to the most powerful group knockoff filter) with catching sets of substantially smaller size and higher purity and verify the biological informativeness of our discoveries.",
    "authors": [
      "Jiaqi Gu",
      "Zhaomeng Chen",
      "Zihuai He"
    ],
    "primary_category": "stat.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.04744",
    "title": "Marginally interpretable spatial logistic regression with bridge processes",
    "abstract": "In including random effects to account for dependent observations, the odds ratio interpretation of logistic regression coefficients is changed from population-averaged to subject-specific. This is unappealing in many applications, motivating a rich literature on methods that maintain the marginal logistic regression structure without random effects, such as generalized estimating equations. However, for spatial data, random effect approaches are appealing in providing a full probabilistic characterization of the data that can be used for prediction. We propose a new class of spatial logistic regression models that maintain both population-averaged and subject-specific interpretations through a novel class of bridge processes for spatial random effects. These processes are shown to have appealing computational and theoretical properties, including a scale mixture of normal representation. The new methodology is illustrated with simulations and an analysis of childhood malaria prevalence data in the Gambia.",
    "authors": [
      "Changwoo J. Lee",
      "David B. Dunson"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.07057",
    "title": "Interactive and Hybrid Imitation Learning: Provably Beating Behavior Cloning",
    "abstract": "Imitation learning (IL) is a paradigm for learning sequential decision making policies from experts, leveraging offline demonstrations, interactive annotations, or both. Recent advances show that when annotation cost is tallied per trajectory, Behavior Cloning (BC) which relies solely on offline demonstrations cannot be improved in general, leaving limited conditions for interactive methods such as DAgger to help. We revisit this conclusion and prove that when the annotation cost is measured per state, algorithms using interactive annotations can provably outperform BC. Specifically: (1) we show that Stagger, a one sample per round variant of DAgger, provably beats BC under low recovery cost settings; (2) we initiate the study of hybrid IL where the agent learns from offline demonstrations and interactive annotations. We propose Warm Stagger whose learning guarantee is not much worse than using either data source alone. Furthermore, motivated by compounding error and cold start problem in imitation learning practice, we give an MDP example in which Warm Stagger has significant better annotation cost; (3) experiments on MuJoCo continuous control tasks confirm that, with modest cost ratio between interactive and offline annotations, interactive and hybrid approaches consistently outperform BC. To the best of our knowledge, our work is the first to highlight the benefit of state wise interactive annotation and hybrid feedback in imitation learning.",
    "authors": [
      "Yichen Li",
      "Chicheng Zhang"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.15530",
    "title": "High-dimensional sliced inverse regression with endogeneity",
    "abstract": "Sliced inverse regression (SIR) is a popular sufficient dimension reduction method that identifies a few linear transformations of the covariates without losing regression information with the response. In high-dimensional settings, SIR can be combined with sparsity penalties to achieve sufficient dimension reduction and variable selection simultaneously. Nevertheless, both classical and sparse estimators assume the covariates are exogenous. However, endogeneity can arise in a variety of situations, such as when variables are omitted or are measured with error. In this article, we show such endogeneity invalidates SIR estimators, leading to inconsistent estimation of the true central subspace. To address this challenge, we propose a two-stage Lasso SIR estimator, which first constructs a sparse high-dimensional instrumental variables model to obtain fitted values of the covariates spanned by the instruments, and then applies SIR augmented with a Lasso penalty on these fitted values. We establish theoretical bounds for the estimation and selection consistency of the true central subspace for the proposed estimators, allowing the number of covariates and instruments to grow exponentially with the sample size. Simulation studies and applications to two real-world datasets in nutrition and genetics illustrate the superior empirical performance of the two-stage Lasso SIR estimator compared with existing methods that disregard endogeneity and/or nonlinearity in the outcome model.",
    "authors": [
      "Linh H. Nghiem",
      "Francis.K.C. Hui",
      "Samuel Muller",
      "A.H. Welsh"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.01552",
    "title": "Multi-view Bayesian optimisation in an input-output reduced space for engineering design",
    "abstract": "Bayesian optimisation is an adaptive sampling strategy for constructing a Gaussian process surrogate to efficiently search for the global minimum of a black-box computational model. Gaussian processes have limited applicability in engineering design problems, which usually have many design variables but typically a low intrinsic dimensionality. Their scalability can be significantly improved by identifying a low-dimensional space of latent variables that serve as inputs to the Gaussian process. In this paper, we introduce a multi-view learning strategy that considers both the input design variables and output data representing the objective or constraint functions, to identify a low-dimensional latent subspace. Adopting a fully probabilistic viewpoint, we use probabilistic partial least squares (PPLS) to learn an orthogonal mapping from the design variables to the latent variables using training data consisting of inputs and outputs of the black-box computational model. The latent variables and posterior probability densities of the PPLS and Gaussian process models are determined sequentially and iteratively, with retraining occurring at each adaptive sampling iteration. We compare the proposed probabilistic partial least squares Bayesian optimisation (PPLS-BO) strategy with its deterministic counterpart, partial least squares Bayesian optimisation (PLS-BO), and classical Bayesian optimisation, demonstrating significant improvements in convergence to the global minimum.",
    "authors": [
      "Thomas A. Archbold",
      "Ieva Kazlauskaite",
      "Fehmi Cirak"
    ],
    "primary_category": "stat.AP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.21438",
    "title": "Wasserstein-Aitchison GAN for angular measures of multivariate extremes",
    "abstract": "Economically responsible mitigation of multivariate extreme risks -- extreme rainfall in a large area, huge variations of many stock prices, widespread breakdowns in transportation systems -- requires estimates of the probabilities that such risks will materialize in the future. This paper develops a new method, Wasserstein--Aitchison Generative Adversarial Networks (WA-GAN) to, which provides simulated values of $d$-dimensional multivariate extreme events and which can hence be used to give estimates of such probabilities. The main hypothesis is that, after transforming the observations to the unit-Pareto scale, their distribution is regularly varying in the sense that the distributions of their radial and angular components (with respect to the $L_1$-norm) converge and become asymptotically independent as the radius gets large. The method is a combination of standard extreme value analysis modeling of the tails of the marginal distributions with nonparametric GAN modeling of the angular distribution. For the latter, the angular values are transformed to Aitchison coordinates in a full $(d-1)$-dimensional linear space, and a Wasserstein GAN is trained on these coordinates and used to generate new values. A reverse transformation is then applied to these values and gives simulated values on the original data scale. Our method is applied to simulated data and to a financial data set from the Kenneth French Data Library. The method shows good performance compared to other existing methods in the literature, both in terms of capturing the dependence structure of the extremes in the data and in generating accurate new extremes.",
    "authors": [
      "Stéphane Lhaut",
      "Holger Rootzén",
      "Johan Segers"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.08721",
    "title": "Testing the Missing Completely at Random Assumption for Functional Data",
    "abstract": "We consider functional data which have only been observed on a subset of their domain. This paper aims to develop statistical tests to determine whether the function and the domain over which it is observed are independent. The assumption that data is missing completely at random (MCAR) is essential for many functional data methods handling incomplete observations. However, no general testing procedures have been established to validate this assumption. We address this critical gap by introducing a testing framework which is generally based on a partition of the observation patterns. Besides deterministic partitions, we also consider a data-driven approach based on clustering. We establish asymptotic results for our tests and illustrate the methodology in several real data applications.",
    "authors": [
      "Maximilian Ofner",
      "Siegfried Hörmann",
      "David Kraus",
      "Dominik Liebl"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.07150",
    "title": "Class conditional conformal prediction for multiple inputs by p-value aggregation",
    "abstract": "Conformal prediction methods are statistical tools designed to quantify uncertainty and generate predictive sets with guaranteed coverage probabilities. This work introduces an innovative refinement to these methods for classification tasks, specifically tailored for scenarios where multiple observations (multi-inputs) of a single instance are available at prediction time. Our approach is particularly motivated by applications in citizen science, where multiple images of the same plant or animal are captured by individuals. Our method integrates the information from each observation into conformal prediction, enabling a reduction in the size of the predicted label set while preserving the required class-conditional coverage guarantee. The approach is based on the aggregation of conformal p-values computed from each observation of a multi-input. By exploiting the exact distribution of these p-values, we propose a general aggregation framework using an abstract scoring function, encompassing many classical statistical tools. Knowledge of this distribution also enables refined versions of standard strategies, such as majority voting. We evaluate our method on simulated and real data, with a particular focus on Pl@ntNet, a prominent citizen science platform that facilitates the collection and identification of plant species through user-submitted images.",
    "authors": [
      "Jean-Baptiste Fermanian",
      "Mohamed Hebiri",
      "Joseph Salmon"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.20975",
    "title": "Locally Adaptive Conformal Inference for Operator Models",
    "abstract": "Operator models are regression algorithms between Banach spaces of functions. They have become an increasingly critical tool for spatiotemporal forecasting and physics emulation, especially in high-stakes scenarios where robust, calibrated uncertainty quantification is required. We introduce Local Sliced Conformal Inference (LSCI), a distribution-free framework for generating function-valued, locally adaptive prediction sets for operator models. We prove finite-sample validity and derive a data-dependent upper bound on the coverage gap under local exchangeability. On synthetic Gaussian-process tasks and real applications (air quality monitoring, energy demand forecasting, and weather prediction), LSCI yields tighter sets with stronger adaptivity compared to conformal baselines. We also empirically demonstrate robustness against biased predictions and certain out-of-distribution noise regimes.",
    "authors": [
      "Trevor Harris",
      "Yan Liu"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.00167",
    "title": "Likelihood-free Posterior Density Learning for Uncertainty Quantification in Inference Problems",
    "abstract": "Generative models and those with computationally intractable likelihoods are widely used to describe complex systems in the natural sciences, social sciences, and engineering. Fitting these models to data requires likelihood-free inference methods that explore the parameter space without explicit likelihood evaluations, relying instead on sequential simulation, which comes at the cost of computational efficiency and extensive tuning. We develop an alternative framework called kernel-adaptive synthetic posterior estimation (KASPE) that uses deep learning to directly reconstruct the mapping between the observed data and a finite-dimensional parametric representation of the posterior distribution, trained on a large number of simulated datasets. We provide theoretical justification for KASPE and a formal connection to the likelihood-based approach of expectation propagation. Simulation experiments demonstrate KASPE's flexibility and performance relative to existing likelihood-free methods including approximate Bayesian computation in challenging inferential settings involving posteriors with heavy tails, multiple local modes, and over the parameters of a nonlinear dynamical system.",
    "authors": [
      "Rui Zhang",
      "Oksana A. Chkrebtii",
      "Dongbin Xiu"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.16312",
    "title": "Tree-based methods for length-biased survival data",
    "abstract": "Left-truncated survival data commonly arise in prevalent cohort studies, where only individuals who have experienced disease onset and survived until enrollment in the study. When the onset process follows a stationary Poisson process, the resulting data are length-biased. This sampling mechanism induces a selection bias towards longer survival individuals, and statistical methods for traditional survival data are not directly applicable. While tree-based methods developed for left-truncated data can be applied, they may be inefficient for length-biased data, as they do not account for the distribution of truncation times. To address this, we propose new survival trees and forests for length-biased right-censored data within the conditional inference framework. Our approach uses a score function derived from the full likelihood to construct permutation test statistics for variable splitting. For survival prediction, we consider two estimators of the unbiased survival function, differing in statistical efficiency and computational complexity. These elements enhance efficiency in tree construction and improve accuracy of survival prediction in ensemble settings. Simulation studies demonstrate efficiency gains in both tree recovery and survival prediction, often exceeding the gains from ensembling alone. We further illustrate the utility of the proposed methods using lung cancer data from the Cancer Public Library Database, a nationwide cancer registry in South Korea.",
    "authors": [
      "Jinwoo Lee",
      "Donghwan Lee",
      "Hyunwoo Lee",
      "Jiyu Sun"
    ],
    "primary_category": "stat.ME",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.08553",
    "title": "A Common Pipeline for Harmonizing Electronic Health Record Data for Translational Research",
    "abstract": "Despite the growing availability of Electronic Health Record (EHR) data, researchers often face substantial barriers in effectively using these data for translational research due to their complexity, heterogeneity, and lack of standardized tools and documentation. To address this critical gap, we introduce PEHRT, a common pipeline for harmonizing EHR data for translational research. PEHRT is a comprehensive, ready-to-use resource that includes open-source code, visualization tools, and detailed documentation to streamline the process of preparing EHR data for analysis. The pipeline provides tools to harmonize structured and unstructured EHR data to standardized ontologies to ensure consistency across diverse coding systems. In the presence of unmapped or heterogeneous local codes, PEHRT further leverages representation learning and pre-trained language models to generate robust embeddings that capture semantic relationships across sites to mitigate heterogeneity and enable integrative downstream analyses. PEHRT also supports cross-institutional co-training through shared representations, allowing participating sites to collaboratively refine embeddings and enhance generalizability without sharing individual-level data. The framework is data model-agnostic and can be seamlessly deployed across diverse healthcare systems to produce interoperable, research-ready datasets. By lowering the technical barriers to EHR-based research, PEHRT empowers investigators to transform raw clinical data into reproducible, analysis-ready resources for discovery and innovation.",
    "authors": [
      "Jessica Gronsbell",
      "Vidul Ayakulangara Panickan",
      "Doudou Zhou",
      "Chris Lin",
      "Thomas Charlon",
      "Chuan Hong",
      "Xin Xiong",
      "Linshanshan Wang",
      "Jianhui Gao",
      "Shirley Zhou",
      "Yuan Tian",
      "Yaqi Shi",
      "Ziming Gan",
      "Tianxi Cai"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.25783",
    "title": "Sharpness of Minima in Deep Matrix Factorization: Exact Expressions",
    "abstract": "Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff & Michaeli (2020). This expression uncovers a fundamental property of the loss landscape of depth-2 matrix factorization problems: a minimum is flat if and only if it is spectral-norm balanced, which implies that flat minima are not necessarily Frobenius-norm balanced. Furthermore, to complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.",
    "authors": [
      "Anil Kamber",
      "Rahul Parhi"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.03109",
    "title": "Rates of Convergence of Generalised Variational Inference Posteriors under Prior Misspecification",
    "abstract": "We prove rates of convergence and robustness to prior misspecification within a Generalised Variational Inference (GVI) framework with bounded divergences. This addresses a significant open challenge for GVI and Federated GVI that employ a different divergence to the Kullback-Leibler under prior misspecification, operate within a subset of possible probability measures, and result in intractable posteriors. Our theoretical contributions extend to misspecified priors that lead to inconsistent Bayes posteriors. In particular, we are able to establish sufficient conditions for existence and uniqueness of GVI posteriors on arbitrary Polish spaces, prove that the GVI posterior measure concentrates on a neighbourhood of loss minimisers, and extend this to rates of convergence regardless of the prior measure.",
    "authors": [
      "Terje Mildner",
      "Paris Giampouras",
      "Theodoros Damoulas"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.20503",
    "title": "Manifold Percolation: from generative model to Reinforce learning",
    "abstract": "Generative modeling is typically framed as learning mapping rules, but from an observer's perspective without access to these rules, the task becomes disentangling the geometric support from the probability distribution. We propose that continuum percolation is uniquely suited to this support analysis, as the sampling process effectively projects high-dimensional density estimation onto a geometric counting problem on the support. In this work, we establish a rigorous correspondence between the topological phase transitions of random geometric graphs and the underlying data manifold in high-dimensional space. By analyzing the relationship between our proposed Percolation Shift metric and FID, we show that this metric captures structural pathologies, such as implicit mode collapse, where standard statistical metrics fail. Finally, we translate this topological phenomenon into a differentiable loss function that guides training. Experimental results confirm that this approach not only prevents manifold shrinkage but also fosters a form of synergistic improvement, where topological stability becomes a prerequisite for sustained high fidelity in both static generation and sequential decision making.",
    "authors": [
      "Rui Tong"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00517",
    "title": "No-Regret Gaussian Process Optimization of Time-Varying Functions",
    "abstract": "Sequential optimization of black-box functions from noisy evaluations has been widely studied, with Gaussian Process bandit algorithms such as GP-UCB guaranteeing no-regret in stationary settings. However, for time-varying objectives, it is known that no-regret is unattainable under pure bandit feedback unless strong and often unrealistic assumptions are imposed. In this article, we propose a novel method to optimize time-varying rewards in the frequentist setting, where the objective has bounded RKHS norm. Time variations are captured through uncertainty injection (UI), which enables heteroscedastic GP regression that adapts past observations to the current time step. As no-regret is unattainable in general in the strict bandit setting, we relax the latter allowing additional queries on previously observed points. Building on sparse inference and the effect of UI on regret, we propose W-SparQ-GP-UCB, an online algorithm that achieves no-regret with only a vanishing number of additional queries per iteration. To assess the theoretical limits of this approach, we establish a lower bound on the number of additional queries required for no-regret, proving the efficiency of our method. Finally, we provide a comprehensive analysis linking the degree of time-variation of the function to achievable regret rates, together with upper and lower bounds on the number of additional queries needed in each regime.",
    "authors": [
      "Eliabelle Mauduit",
      "Eloïse Berthier",
      "Andrea Simonetto"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01817",
    "title": "Sharp Self-Normalized Concentration Inequalities of Marginal Mean with Sample Variance Only",
    "abstract": "(This is the first version of a working paper. A more detailed follow-up with applications is in preparation.) We develop a family of self-normalized concentration inequalities for marginal mean under martingale-difference structure and $\\phi/\\tilde{\\phi}$-mixing conditions, where the latter includes many processes that are not strongly mixing. The variance term is fully data-observable: naive sample variance in the martingale case and an empirical block long-run variance under mixing conditions. Thus, no predictable variance proxy is required. No specific assumption on the decay of the mixing coefficients (e.g. summability) is needed for the validity. The constants are explicit and the bounds are ready to use.",
    "authors": [
      "Zihao Yuan"
    ],
    "primary_category": "math.ST",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03021",
    "title": "Semiparametric Robust Estimation of Population Location",
    "abstract": "Real-world measurements often comprise a dominant signal contaminated by a noisy background. Robustly estimating the dominant signal in practice has been a fundamental statistical problem. Classically, mixture models have been used to cluster the heterogeneous population into homogeneous components. Modeling such data with fully parametric models risks bias under misspecification, while fully nonparametric approaches can dissipate power and computational resources. We propose a middle path: a semiparametric method that models only the dominant component parametrically and leaves the background completely nonparametric, yet remains computationally scalable and statistically robust. So instead of outlier downweighting, traditionally done in robust statistics literature, we maximize the observed likelihood such that the noisy background is absorbed by the nonparametric component. Computationally, we propose a new approximate FFT-accelerated likelihood maximization algorithm. Empirically, this FFT plug-in achieves order-of-magnitude speedups over vanilla weighted EM while preserving statistical accuracy and large sample properties.",
    "authors": [
      "Ananyabrata Barua",
      "Ayanendranath Basu"
    ],
    "primary_category": "stat.CO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2402.14332",
    "title": "Accelerating data-driven algorithm selection for combinatorial partitioning problems",
    "abstract": "Data-driven algorithm selection is a powerful approach for choosing effective heuristics for computational problems. It operates by evaluating a set of candidate algorithms on a collection of representative training instances and selecting the one with the best empirical performance. However, running each algorithm on every training instance is computationally expensive, making scalability a central challenge. In practice, a common workaround is to evaluate algorithms on smaller proxy instances derived from the original inputs. However, this practice has remained largely ad hoc and lacked theoretical grounding. We provide the first theoretical foundations for this practice by formalizing the notion of size generalization: predicting an algorithm's performance on a large instance by evaluating it on a smaller, representative instance, subsampled from the original instance. We provide size generalization guarantees for three widely used clustering algorithms (single-linkage, $k$-means++, and Gonzalez's $k$-centers heuristic) and two canonical max-cut algorithms (Goemans-Williamson and Greedy). We characterize the subsample size sufficient to ensure that performance on the subsample reflects performance on the full instance, and our experiments support these findings.",
    "authors": [
      "Vaggos Chatziafratis",
      "Ishani Karmarkar",
      "Yingxi Li",
      "Ellen Vitercik"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.05358",
    "title": "Variational Inference of Parameters in Opinion Dynamics Models",
    "abstract": "Despite the frequent use of agent-based models (ABMs) for studying social phenomena, parameter estimation remains a challenge, often relying on costly simulation-based heuristics. This work uses variational inference to estimate the parameters of an opinion dynamics ABM, by transforming the estimation problem into an optimization task that can be solved directly. Our proposal relies on probabilistic generative ABMs (PGABMs): we start by synthesizing a probabilistic generative model from the ABM rules. Then, we transform the inference process into an optimization problem suitable for automatic differentiation. In particular, we use the Gumbel-Softmax reparameterization for categorical agent attributes and stochastic variational inference for parameter estimation. Furthermore, we explore the trade-offs of using variational distributions with different complexity: normal distributions and normalizing flows. We validate our method on a bounded confidence model with agent roles (leaders and followers). Our approach estimates both macroscopic (bounded confidence intervals and backfire thresholds) and microscopic ($200$ categorical, agent-level roles) more accurately than simulation-based and MCMC methods. Consequently, our technique enables experts to tune and validate their ABMs against real-world observations, thus providing insights into human behavior in social systems via data-driven analysis.",
    "authors": [
      "Jacopo Lenti",
      "Fabrizio Silvestri",
      "Gianmarco De Francisci Morales"
    ],
    "primary_category": "cs.CY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.02141",
    "title": "Uniqueness of Maximum Scores in Countable-Outcome Round-Robin Tournaments",
    "abstract": "In this note, we extend a recent result on the uniqueness of the maximum score in a classical round-robin tournament to general round-robin tournament models with equally strong players, where the scores take values in $[0,\\,1]$.",
    "authors": [
      "Gideon Amir",
      "Yaakov Malinovsky"
    ],
    "primary_category": "math.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.18551",
    "title": "Concentration of Cumulative Reward in Markov Decision Processes",
    "abstract": "In this paper, we investigate the concentration properties of cumulative reward in Markov Decision Processes (MDPs), focusing on both asymptotic and non-asymptotic settings. We introduce a unified approach to characterize reward concentration in MDPs, covering both infinite-horizon settings (i.e., average and discounted reward frameworks) and finite-horizon setting. Our asymptotic results include the law of large numbers, the central limit theorem, and the law of iterated logarithms, while our non-asymptotic bounds include Azuma-Hoeffding-type inequalities and a non-asymptotic version of the law of iterated logarithms. Additionally, we explore two key implications of our results. First, we analyze the sample path behavior of the difference in rewards between any two stationary policies. Second, we show that two alternative definitions of regret for learning policies proposed in the literature are rate-equivalent. Our proof techniques rely on a martingale decomposition of cumulative reward, properties of the solution to the policy evaluation fixed-point equation, and both asymptotic and non-asymptotic concentration results for martingale difference sequences.",
    "authors": [
      "Borna Sayedana",
      "Peter E. Caines",
      "Aditya Mahajan"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.11384",
    "title": "Transductive Conformal Inference for Full Ranking",
    "abstract": "We introduce a method based on Conformal Prediction (CP) to quantify the uncertainty of full ranking algorithms. We focus on a specific scenario where $n+m$ items are to be ranked by some ``black box'' algorithm. It is assumed that the relative (ground truth) ranking of $n$ of them is known. The objective is then to quantify the error made by the algorithm on the ranks of the $m$ new items among the total $(n+m)$. In such a setting, the true ranks of the $n$ original items in the total $(n+m)$ depend on the (unknown) true ranks of the $m$ new ones. Consequently, we have no direct access to a calibration set to apply a classical CP method. To address this challenge, we propose to construct distribution-free bounds of the unknown conformity scores using recent results on the distribution of conformal p-values. Using these scores upper bounds, we provide valid prediction sets for the rank of any item. We also control the false coverage proportion, a crucial quantity when dealing with multiple prediction sets. Finally, we empirically show on both synthetic and real data the efficiency of our CP method for state-of-the-art algorithms such as RankNet or LambdaMart.",
    "authors": [
      "Jean-Baptiste Fermanian",
      "Pierre Humbert",
      "Gilles Blanchard"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.19374",
    "title": "From Distance to Direction: Structure-aware Label-specific Feature Fusion for Label Distribution Learning",
    "abstract": "Label distribution learning (LDL) is an emerging learning paradigm designed to capture the relative importance of labels for each instance. Label-specific features (LSFs), constructed by LIFT, have proven effective for learning tasks with label ambiguity by leveraging clustering-based prototypes for each label to re-characterize instances. However, directly introducing LIFT into LDL tasks can be suboptimal, as the prototypes it collects primarily reflect intra-cluster relationships while neglecting cross-cluster interactions. Additionally, constructing LSFs using multi-perspective information, rather than relying solely on Euclidean distance, provides a more robust and comprehensive representation of instances, mitigating noise and bias that may arise from a single distance perspective. To address these limitations, we introduce Structural Anchor Points (SAPs) to capture inter-cluster interactions. This leads to a novel LSFs construction strategy, LIFT-SAP, which enhances LIFT by integrating both distance and directional information of each instance relative to SAPs. Furthermore, we propose a novel LDL algorithm, Label Distribution Learning via Label-specifIc FeaTure with SAPs (LDL-LIFT-SAP), which unifies multiple label description degrees predicted from different LSF spaces into a cohesive label distribution. Extensive experiments on 15 real-world datasets demonstrate the effectiveness of LIFT-SAP over LIFT, as well as the superiority of LDL-LIFT-SAP compared to seven other well-established algorithms.",
    "authors": [
      "Suping Xu",
      "Chuyi Dai",
      "Lin Shang",
      "Changbin Shao",
      "Xibei Yang",
      "Witold Pedrycz"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.16037",
    "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data",
    "abstract": "LLM routing aims to select the most appropriate model for each query, balancing competing performance metrics such as accuracy and cost across a pool of language models. Prior approaches typically adopt a decoupled strategy, where the metrics are first predicted and the model is then selected based on these estimates. This setup is prone to compounding errors and often relies on full-feedback data, where each query is evaluated by all candidate models, which is costly to obtain and maintain in practice. In contrast, we learn from observational data, which records only the outcome of the model actually deployed. We propose a causal end-to-end framework that learns routing policies by minimizing decision-making regret from observational data. To enable efficient optimization, we introduce two theoretically grounded surrogate objectives: a classification-based upper bound, and a softmax-weighted regret approximation shown to recover the optimal policy at convergence. We further extend our framework to handle heterogeneous cost preferences via an interval-conditioned architecture. Experiments on public benchmarks show that our method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.",
    "authors": [
      "Asterios Tsiourvas",
      "Wei Sun",
      "Georgia Perakis"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.00835",
    "title": "PCS Workflow for Veridical Data Science in the Age of AI",
    "abstract": "Data science is a pillar of artificial intelligence (AI), which is transforming nearly every domain of human activity, from the social and physical sciences to engineering and medicine. While data-driven findings in AI offer unprecedented power to extract insights and guide decision-making, many are difficult or impossible to replicate. A key reason for this challenge is the uncertainty introduced by the many choices made throughout the data science life cycle (DSLC). Traditional statistical frameworks often fail to account for this uncertainty. The Predictability-Computability-Stability (PCS) framework for veridical (truthful) data science offers a principled approach to addressing this challenge throughout the DSLC. This paper presents an updated and streamlined PCS workflow, tailored for practitioners and enhanced with guided use of generative AI. We include a running example to display the PCS framework in action, and conduct a related case study which showcases the uncertainty in downstream predictions caused by judgment calls in the data cleaning stage.",
    "authors": [
      "Zachary T. Rewolinski",
      "Bin Yu"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.02103",
    "title": "Instance-Dependent Continuous-Time Reinforcement Learning via Maximum Likelihood Estimation",
    "abstract": "Continuous-time reinforcement learning (CTRL) provides a natural framework for sequential decision-making in dynamic environments where interactions evolve continuously over time. While CTRL has shown growing empirical success, its ability to adapt to varying levels of problem difficulty remains poorly understood. In this work, we investigate the instance-dependent behavior of CTRL and introduce a simple, model-based algorithm built on maximum likelihood estimation (MLE) with a general function approximator. Unlike existing approaches that estimate system dynamics directly, our method estimates the state marginal density to guide learning. We establish instance-dependent performance guarantees by deriving a regret bound that scales with the total reward variance and measurement resolution. Notably, the regret becomes independent of the specific measurement strategy when the observation frequency adapts appropriately to the problem's complexity. To further improve performance, our algorithm incorporates a randomized measurement schedule that enhances sample efficiency without increasing measurement cost. These results highlight a new direction for designing CTRL algorithms that automatically adjust their learning behavior based on the underlying difficulty of the environment.",
    "authors": [
      "Runze Zhao",
      "Yue Yu",
      "Ruhan Wang",
      "Chunfeng Huang",
      "Dongruo Zhou"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.12917",
    "title": "Reversible Deep Equilibrium Models",
    "abstract": "Deep Equilibrium Models (DEQs) are an interesting class of implicit model where the model output is implicitly defined as the fixed point of a learned function. These models have been shown to outperform explicit (fixed-depth) models in large-scale tasks by trading many deep layers for a single layer that is iterated many times. However, gradient calculation through DEQs is approximate. This often leads to unstable training dynamics and requires regularisation or many function evaluations to fix. Here, we introduce Reversible Deep Equilibrium Models (RevDEQs) that allow for exact gradient calculation, no regularisation and far fewer function evaluations than DEQs. We show that RevDEQs significantly improve performance on language modelling and image classification tasks against comparable implicit and explicit models.",
    "authors": [
      "Sam McCallum",
      "Kamran Arora",
      "James Foster"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05620",
    "title": "Monte Carlo-Type Neural Operator for Differential Equations",
    "abstract": "The Monte Carlo-type Neural Operator (MCNO) introduces a framework for learning solution operators of one-dimensional partial differential equations (PDEs) by directly learning the kernel function and approximating the associated integral operator using a Monte Carlo-type approach. Unlike Fourier Neural Operators (FNOs), which rely on spectral representations and assume translation-invariant kernels, MCNO makes no such assumptions. The kernel is represented as a learnable tensor over sampled input-output pairs, and sampling is performed once, uniformly at random from a discretized grid. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training, while an interpolation step maps between arbitrary input and output grids to further enhance flexibility. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with efficient computational cost. We also provide a theoretical analysis proving that the Monte Carlo estimator yields a bounded bias and variance under mild regularity assumptions. This result holds in any spatial dimension, suggesting that MCNO may extend naturally beyond one-dimensional problems. More broadly, this work explores how Monte Carlo-type integration can be incorporated into neural operator frameworks for continuous-domain PDEs, providing a theoretically supported alternative to spectral methods (such as FNO) and to graph-based Monte Carlo approaches (such as the Graph Kernel Neural Operator, GNO).",
    "authors": [
      "Salah Eddine Choutri",
      "Prajwal Chauhan",
      "Othmane Mazhar",
      "Saif Eddin Jabari"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05809",
    "title": "Coherent estimation of risk measures",
    "abstract": "We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.",
    "authors": [
      "Martin Aichele",
      "Igor Cialenco",
      "Damian Jelito",
      "Marcin Pitera"
    ],
    "primary_category": "q-fin.RM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.16088",
    "title": "Differentiable, Bit-shifting, and Scalable Quantization without training neural network from scratch",
    "abstract": "Quantization of neural networks provides benefits of inference in less compute and memory requirements. Previous work in quantization lack two important aspects which this work provides. First almost all previous work in quantization used a non-differentiable approach and for learning; the derivative is usually set manually in backpropogation which make the learning ability of algorithm questionable, our approach is not just differentiable, we also provide proof of convergence of our approach to the optimal neural network. Second previous work in shift/logrithmic quantization either have avoided activation quantization along with weight quantization or achieved less accuracy. Learning logrithmic quantize values of form $2^n$ requires the quantization function can scale to more than 1 bit quantization which is another benifit of our quantization that it provides $n$ bits quantization as well. Our approach when tested with image classification task using imagenet dataset, resnet18 and weight quantization only achieves less than 1 percent accuracy compared to full precision accuracy while taking only 15 epochs to train using shift bit quantization and achieves comparable to SOTA approaches accuracy in both weight and activation quantization using shift bit quantization in 15 training epochs with slightly higher(only higher cpu instructions) inference cost compared to 1 bit quantization(without logrithmic quantization) and not requiring any higher precision multiplication.",
    "authors": [
      "Zia Badar"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.22664",
    "title": "The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"",
    "abstract": "We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.",
    "authors": [
      "Tomoi Koide",
      "Armin van de Venn"
    ],
    "primary_category": "cond-mat.stat-mech",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.08878",
    "title": "Covariance Scattering Transforms",
    "abstract": "Machine learning and data processing techniques relying on covariance information are widespread as they identify meaningful patterns in unsupervised and unlabeled settings. As a prominent example, Principal Component Analysis (PCA) projects data points onto the eigenvectors of their covariance matrix, capturing the directions of maximum variance. This mapping, however, falls short in two directions: it fails to capture information in low-variance directions, relevant when, e.g., the data contains high-variance noise; and it provides unstable results in low-sample regimes, especially when covariance eigenvalues are close. CoVariance Neural Networks (VNNs), i.e., graph neural networks using the covariance matrix as a graph, show improved stability to estimation errors and learn more expressive functions in the covariance spectrum than PCA, but require training and operate in a labeled setup. To get the benefits of both worlds, we propose Covariance Scattering Transforms (CSTs), deep untrained networks that sequentially apply filters localized in the covariance spectrum to the input data and produce expressive hierarchical representations via nonlinearities. We define the filters as covariance wavelets that capture specific and detailed covariance spectral patterns. We improve CSTs' computational and memory efficiency via a pruning mechanism, and we prove that their error due to finite-sample covariance estimations is less sensitive to close covariance eigenvalues compared to PCA, improving their stability. Our experiments on age prediction from cortical thickness measurements on 4 datasets collecting patients with neurodegenerative diseases show that CSTs produce stable representations in low-data settings, as VNNs but without any training, and lead to comparable or better predictions w.r.t. more complex learning models.",
    "authors": [
      "Andrea Cavallo",
      "Ayushman Raghuvanshi",
      "Sundeep Prabhakar Chepuri",
      "Elvin Isufi"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01070",
    "title": "Differential Geometry of the Fixed-Rank Core Covariance Manifold",
    "abstract": "We study the differential geometry of the fixed-rank core covariance manifold. According to Hoff, McCormack, and Zhang [J. R. Stat. Soc., B: Stat., 85 (2023), pp. 1659--1679], every covariance matrix $\\Sigma$ of $p_1\\times p_2$ matrix-variate data uniquely decomposes into a separable component $K$ and a core component $C$. Such a decomposition also exists for rank-$r$ $\\Sigma$ if $p_1/p_2+p_2/p_1<r$, with $C$ sharing the same rank. They posed an open question on whether a partial-isotropy structure can be imposed on $C$ for high-dimensional covariance estimation. We address this question by showing that a partial-isotropy rank-$r$ core is a non-trivial convex combination of a rank-$r$ core and $I_p$ for $p:=p_1p_2$, motivating the study of rank-$r$ cores. For fixed $r>p_1/p_2+p_2/p_1$, we prove that the set of rank-$r$ cores, $\\mathcal{C}_{p_1,p_2,r}^+$, is a compact, smooth, embedded submanifold of the set of rank-$r$ positive semi-definite matrices, except for a measure-zero subset associated with canonical decomposability. When $r=p$, the set of full-rank cores $\\mathcal{C}_{p_1,p_2}^{++}$ is itself a smooth manifold. Moreover, the positive definite cone $\\mathcal{S}_p^{++}$ is diffeomorphic to the product of the Kronecker and core covariance manifolds, providing new geometric insight into $\\mathcal{S}_p^{++}$ via separability. Differential geometric quantities, such as the differential of the diffeomorphism, as well as the Riemannian gradient and Hessian operator on $\\mathcal{C}_{p_1,p_2}^{++}$ and the manifolds used in constructing $\\mathcal{C}_{p_1,p_2,r}^+$, are also derived. Lastly, we propose a partial-isotropy core shrinkage estimator for matrix-variate data, supported by numerical illustrations.",
    "authors": [
      "Bongjung Sung"
    ],
    "primary_category": "math.DG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02019",
    "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
    "abstract": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to this objective, we derive a modified surrogate objective for MaxEntRL that incorporates diffusion dynamics in a principled way. This leads to simple diffusion-based variants of Soft Actor-Critic (SAC), Proximal Policy Optimization (PPO) and Wasserstein Policy Optimization (WPO), termed DiffSAC, DiffPPO and DiffWPO. All of these methods require only minor implementation changes to their base algorithm. We find that on standard continuous control benchmarks, DiffSAC, DiffPPO and DiffWPO achieve better returns and higher sample efficiency than SAC and PPO.",
    "authors": [
      "Sebastian Sanokowski",
      "Kaustubh Patil",
      "Alois Knoll"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02852",
    "title": "Adaptive Decentralized Federated Learning for Robust Optimization",
    "abstract": "In decentralized federated learning (DFL), the presence of abnormal clients, often caused by noisy or poisoned data, can significantly disrupt the learning process and degrade the overall robustness of the model. Previous methods on this issue often require a sufficiently large number of normal neighboring clients or prior knowledge of reliable clients, which reduces the practical applicability of DFL. To address these limitations, we develop here a novel adaptive DFL (aDFL) approach for robust estimation. The key idea is to adaptively adjust the learning rates of clients. By assigning smaller rates to suspicious clients and larger rates to normal clients, aDFL mitigates the negative impact of abnormal clients on the global model in a fully adaptive way. Our theory does not put any stringent conditions on neighboring nodes and requires no prior knowledge. A rigorous convergence analysis is provided to guarantee the oracle property of aDFL. Extensive numerical experiments demonstrate the superior performance of the aDFL method.",
    "authors": [
      "Shuyuan Wu",
      "Feifei Wang",
      "Yuan Gao",
      "Rui Wang",
      "Hansheng Wang"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03160",
    "title": "Time-Invariant Polytopic and Interval Observers for Uncertain Linear Systems via Non-Square Transformation",
    "abstract": "This paper presents novel polytopic and interval observer designs for uncertain linear continuous-time (CT) and discrete-time (DT) systems subjected to bounded disturbances and noise. Our approach guarantees enclosure of the true state and input-to-state stability (ISS) of the polytopic and interval set estimates. Notably, our approach applies to all detectable systems that are stabilized by any optimal observer design, utilizing a potentially non-square (lifted) time-invariant coordinate transformation based on polyhedral Lyapunov functions and mixed-monotone embedding systems that do not impose any positivity constraints, enabling feasible and optimal observer designs, even in cases where previous methods fail. The effectiveness of our approach is demonstrated through several examples of uncertain linear CT and DT systems.",
    "authors": [
      "Feiya Zhu",
      "Tarun Pati",
      "Sze Zheng Yong"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03196",
    "title": "Ultra-Strong Gradient Diffusion MRI with Self-Supervised Learning for Prostate Cancer Characterization",
    "abstract": "Diffusion MRI (dMRI) enables non-invasive assessment of prostate microstructure but conventional metrics such as the Apparent Diffusion Coefficient in multiparametric MRI lack specificity to underlying histology. Integrating dMRI with the compartment-based biophysical VERDICT (Vascular, Extracellular, and Restricted Diffusion for Cytometry in Tumours) framework offers richer microstructural insights, though clinical gradient systems (40-80 mT/m) suffer from poor signal-to-noise ratio (SNR) at stronger diffusion weightings due to prolonged echo times. Ultra-strong gradients (up to 300 mT/m) can mitigate these limitations by improving SNR and contrast-to-noise ratios (CNR) but their adoption has until recently been limited to research environments due to challenges with peripheral nerve stimulation thresholds and gradient non-uniformity. This study investigates whether physics-informed self-supervised VERDICT (ssVERDICT) fitting applied to ultra-strong gradients enhances prostate cancer characterization relative to current clinical acquisitions. We developed enhanced ssVERDICT fitting approaches using dense multilayer perceptron (Dense MLP) and convolutional U-Net architectures, benchmarking them against non-linear least-squares (NLLS) fitting and Diffusion Kurtosis Imaging across clinical- to ultra-strong gradient systems. Dense ssVERDICT at ultra-strong gradient notably outperformed NLLS VERDICT, boosting median CNR by 47%, cutting inter-patient Coefficient of Variation by 52%, and reducing pooled f_ic variation by 50%. Overall, it delivered the highest CNR, the most stable parameter estimates, and the clearest tumour-normal contrast compared with conventional methods and clinical gradient systems. These findings highlight the potential of advanced gradient systems and deep learning-based modelling to improve non-invasive prostate cancer characterization and reduce unnecessary biopsies.",
    "authors": [
      "Tanishq Patil",
      "Snigdha Sen",
      "Malwina Molendowska",
      "Kieran G. Foley",
      "Fabrizio Fasano",
      "Mara Cercignani",
      "Marco Palombo",
      "Paddy J. Slator",
      "Eleftheria Panagiotaki"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03202",
    "title": "Quality assurance of the Federal Interagency Traumatic Brain Injury Research (FITBIR) MRI database to enable integrated multi-site analysis",
    "abstract": "The Federal Interagency Traumatic Brain Injury Research (FITBIR) database is a centralized data repository for traumatic brain injury (TBI) research. It includes over 45,529 magnetic resonance images (MRI) from 6,211 subjects (9,229 imaging sessions) across 26 studies with heterogeneous organization formats, contrasts, acquisition parameters, and demographics. In this work, we organized all available structural and diffusion MRI from FITBIR along with relevant demographic information into the Brain Imaging Data Structure. We analyzed whole-brain mean fractional anisotropy, mean diffusivity, total intracranial volume, and the volumes of 132 regions of interest using UNesT segmentations. There were 4,868 subjects (7,035 sessions) with structural MRI and 2,666 subjects (3,763 sessions) with diffusion MRI following quality assurance and harmonization. We modeled profiles for these metrics across ages with generalized additive models for location, scale, and shape (GAMLSS) and found significant differences in subjects with TBI compared to controls in volumes of 54 regions of the brain (q<0.05, likelihood ratio test with false discovery rate correction).",
    "authors": [
      "Adam M. Saunders",
      "Michael E. Kim",
      "Gaurav Rudravaram",
      "Elyssa M. McMaster",
      "Chloe Scholten",
      "Simon Vandekar",
      "Tonia S. Rex",
      "François Rheault",
      "Bennett A. Landman"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03301",
    "title": "Comparing Unsupervised and Supervised Semantic Speech Tokens: A Case Study of Child ASR",
    "abstract": "Discrete speech tokens have gained attention for their storage efficiency and integration with Large Language Models (LLMs). They are commonly categorized into acoustic and semantic tokens, with the latter being more advantageous for Automatic Speech Recognition (ASR). Traditionally, unsupervised K-means clustering has been used to extract semantic speech tokens from Speech Foundation Models (SFMs). Recently, supervised methods, such as finite scalar quantization (FSQ) trained with ASR loss, have emerged for speech generation. Both approaches leverage pre-trained SFMs, benefiting low-resource tasks such as child ASR. This paper systematically compares supervised and unsupervised semantic speech tokens for child ASR. Results show that supervised methods not only outperform unsupervised ones but even unexpectedly surpass continuous representations, and they perform well even in ultra-low bitrate settings. These findings highlight the advantages of supervised semantic tokens and offer insights for improving discrete speech tokenization.",
    "authors": [
      "Mohan Shi",
      "Natarajan Balaji Shankar",
      "Kaiyuan Zhang",
      "Zilai Wang",
      "Abeer Alwan"
    ],
    "primary_category": "eess.AS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03319",
    "title": "Optimizing ISAC MIMO Systems with Reconfigurable Pixel Antennas",
    "abstract": "The integration of sensing and communication demands architectures that can flexibly exploit spatial and electromagnetic (EM) degrees of freedom (DoF). This paper proposes an Integrated Sensing and Communication (ISAC) MIMO framework that uses Reconfigurable Pixel Antenna (RPixA), which introduces additional EM-domain DoF that are electronically controlled through binary antenna coder switch networks. We introduce a beamforming architecture combining this EM and digital precoding to jointly optimize Sensing and Communication. Based on full-wave simulation of pixel antenna, we formulate a non-convex joint optimization problem to maximize sensing rate under user-specific constraints on communication rate. We utilize an Alternating Optimization framework incorporating genetic algorithm for port states of Pixel antennas, and semi-definite relaxation (SDR) for digital beamforming. Numerical results demonstrate that the proposed EM-aware design achieves considerably higher sensing rate compared to conventional arrays and enables considerable antenna reduction for equivalent ISAC performance. These findings highlight the potential of reconfigurable pixel antennas to realize efficient and scalable EM-aware ISAC systems for future 6G networks.",
    "authors": [
      "Ataher Sams",
      "Yu-Cheng Hsiao",
      "Muhammad Talha",
      "Besma Smida",
      "Ashutosh Sabharwal"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03458",
    "title": "A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses",
    "abstract": "Decoding imagined speech engages complex neural processes that are difficult to interpret due to uncertainty in timing and the limited availability of imagined-response datasets. In this study, we present a Magnetoencephalography (MEG) dataset collected from trained musicians as they imagined and listened to musical and poetic stimuli. We show that both imagined and perceived brain responses contain consistent, condition-specific information. Using a sliding-window ridge regression model, we first mapped imagined responses to listened responses at the single-subject level, but found limited generalization across subjects. At the group level, we developed an encoder-decoder convolutional neural network with a subject-specific calibration layer that produced stable and generalizable mappings. The CNN consistently outperformed the null model, yielding significantly higher correlations between predicted and true listened responses for nearly all held-out subjects. Our findings demonstrate that imagined neural activity can be transformed into perception-like responses, providing a foundation for future brain-computer interface applications involving imagined speech and music.",
    "authors": [
      "Maryam Maghsoudi",
      "Mohsen Rezaeizadeh",
      "Shihab Shamma"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03459",
    "title": "Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion",
    "abstract": "Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control.",
    "authors": [
      "Hidaka Asai",
      "Tomoyuki Noda",
      "Jun Morimoto"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03486",
    "title": "A Universal Harmonic Discriminator for High-quality GAN-based Vocoder",
    "abstract": "With the emergence of GAN-based vocoders, the discriminator, as a crucial component, has been developed recently. In our work, we focus on improving the time-frequency based discriminator. Particularly, Short-Time Fourier Transform (STFT) representation is usually used as input of time-frequency based discriminator. However, the STFT spectrogram has the same frequency resolution at different frequency bins, which results in an inferior performance, especially for singing voices. Motivated by this, we propose a universal harmonic discriminator for dynamic frequency resolution modeling and harmonic tracking. Specifically, we design a harmonic filter with learnable triangular band-pass filter banks, where each frequency bin has a flexible bandwidth. Additionally, we add a half-harmonic to capture fine-grained harmonic relationships at low-frequency band. Experiments on speech and singing datasets validate the effectiveness of the proposed discriminator on both subjective and objective metrics.",
    "authors": [
      "Nan Xu",
      "Zhaolong Huang",
      "Xiao Zeng"
    ],
    "primary_category": "eess.AS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03502",
    "title": "Resource Allocation for Pinching-Antenna Systems (PASS)-enabled NOMA Communications",
    "abstract": "Pinching-antenna systems (PASS) have emerged as a promising technology due to their ability to dynamically reconfigure wireless propagation environments. A novel PASS-based multi-user non-orthogonal multiple access (NOMA) framework is proposed by exploiting the waveguide-division (WD) transmission characteristic. Specifically, each NOMA user cluster is served by one dedicated waveguide, and the corresponding pinching beamforming is exploited to enhance the intra-cluster performance while mitigating the inter-cluster interference. Based on this framework, a sum-rate maximization problem is formulated for jointly optimizing power allocation, pinching beamforming, and user scheduling. To solve this problem, a two-step algorithm is developed, which decomposes the original problem into two subproblems. For the joint power allocation and pinching beamforming design, a penalty dual decomposition (PDD) algorithm is proposed to obtain the locally optimal solutions. Specifically, the coupling constraints are alleviated through augmented Lagrangian relaxation, and the resulting augmented Lagrangian (AL) problem is decomposed into four subproblems, which are solved by the block coordinate descent (BCD) method. For the user scheduling, a low-complexity matching algorithm is developed to solve the user-to-waveguide assignment problem. Simulation results demonstrate that 1) the proposed PASS-based NOMA framework under the WD transmission structure achieves significant sum-rate gain over conventional fixed-position antenna systems and orthogonal multiple access (OMA) scheme; and 2) the proposed matching-based user scheduling algorithm achieves near-optimal user-waveguide association with low computational complexity.",
    "authors": [
      "Songtao Xue",
      "Jingjing Zhao",
      "Kaiquan Cai",
      "Xidong Mu",
      "Zhenyu Xiao",
      "Yuanwei Liu"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03506",
    "title": "A Comprehensive Survey of 3GPP Release 19 ISAC Channel Modeling: From Empirical Features to Unified Methodology and Standardized Simulator",
    "abstract": "Integrated Sensing and Communication (ISAC) has been identified as a key 6G application by ITU and 3GPP. Channel measurement and modeling is a prerequisite for ISAC system design and has attracted widespread attention from both academia and industry. 3GPP Release 19 initiated the ISAC channel study item in December 2023 and finalized its modeling specification in May 2025 after extensive technical discussions. However, a comprehensive survey that provides a systematic overview,from empirical channel features to modeling methodologies and standardized simulators,remains unavailable. In this paper, the key requirements and challenges in ISAC channel research are first analyzed, followed by a structured overview of the standardization workflow throughout the 3GPP Release 19 process. Then, critical aspects of ISAC channels, including physical objects, target channels, and background channels, are examined in depth, together with additional features such as spatial consistency, environment objects, Doppler characteristics, and shared clusters, supported by measurement-based analysis. To establish a unified ISAC channel modeling framework, an Extended Geometry-based Stochastic Model (E-GBSM) is proposed, incorporating all the aforementioned ISAC channel characteristics. Finally, a standardized simulator is developed based on E-GBSM, and a two-phase calibration procedure aligned with 3GPP Release 19 is conducted to validate both the model and the simulator, demonstrating close agreement with industrial reference results. Overall, this paper provides a systematic survey of 3GPP Release 19 ISAC channel standardization and offers insights into best practices for new feature characterization, unified modeling methodology, and standardized simulator implementation, which can effectively supporting ISAC technology evaluation and future 6G standardization.",
    "authors": [
      "Yameng Liu",
      "Yuxiang Zhang",
      "Jianhua Zhang",
      "Yuanpeng Pei",
      "Changsheng Zhao",
      "Shilin Luo",
      "Lei Tian",
      "Yingyang Li",
      "Wei Hong",
      "Jianming Wu",
      "Guangyi Liu",
      "Yan Li",
      "Tao Jiang",
      "Chuangxin Jiang",
      "Junchen Liu",
      "Yongqiang Fei",
      "Woo-Suk Ko",
      "Jing Xu",
      "Bin Liang",
      "Takahiro Tomie"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03545",
    "title": "Resilient AFE Drive Control using Neural Networks with Tracking Guarantees",
    "abstract": "Industrial installations across several sectors have seen a dramatic increase in productivity, accuracy and efficiency over the last decade due to expanded utilization of medium voltage, variable speed power electronic converters to drive their processes. Specifically, active front-end (AFE) drives have become popular due to their ability to deliver power while maintaining safe electrical setpoints. However, under abnormal grid conditions such as phase loss, conventional AFE control may fail to enforce safety constraints, potentially leading to drive shutdown and significant financial losses. In this work, we propose using reference-tracking Performance Boosting (rPB) to improve the resilience of standard AFE control to faults. This neural-network control framework provides a principled way to optimize transient performance while preserving the steady-state tracking properties of AFE-based drives. By carefully shaping the input signals to the rPB controller, we ensure that it activates only during grid faults, leaving nominal operation unaffected. Simulation results show that the proposed approach successfully maintains the DC bus voltage and the grid current within safe limits during single-phase loss events.",
    "authors": [
      "Nicolas Kirsch",
      "Catalin Arghir",
      "Silvia Mastellone",
      "Giancarlo Ferrari-Trecate"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03604",
    "title": "Physics-Based Communication Compression via Lyapunov-Weighted Event-Triggered Control",
    "abstract": "Event-Triggered Control (ETC) reduces communication overhead in networked systems by transmitting only when stability requires it. Conventional mechanisms use isotropic error thresholds ($\\|e\\| \\le \\sigma \\|x\\|$), treating all directions equally. This ignores stability geometry and triggers conservatively. We propose a static directional triggering mechanism that exploits this asymmetry. By weighting errors via the Lyapunov matrix $P$, we define an anisotropic half-space scaling with instantaneous energy margins: larger deviations tolerated along stable modes, strict bounds where instability threatens. We prove global asymptotic stability and exclusion of Zeno behavior. Monte Carlo simulations ($N=100$) show 43.6\\% fewer events than optimally tuned isotropic methods while achieving $2.1\\times$ better control performance than time-varying alternatives. The mechanism functions as a runtime safety gate for learning-based controllers operating under communication constraints.",
    "authors": [
      "Abbas Tariverdi"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03605",
    "title": "A Perception-feedback position-tracking control for quadrotors",
    "abstract": "In this paper a position-tracking controller for quadrotors based on perception feedback is developed, which directly uses measurements from onboard sensors such as low cost IMUs and GPS to generate the control commands without state estimation. Bias in gyros sensors are corrected to enhance the tracking performance. Practical stability of the origin of the tracking error system in the presence of external disturbances is proved using the Lyapunov analysis, which turns out to exponential stability in the absence of external disturbances. Numerical simulations are included to illustrate the proposed control scheme and to verify the robustness of the proposed controller under noisy measurements and parameter uncertainties.",
    "authors": [
      "Eduardo Espindola",
      "Yu Tang"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03615",
    "title": "Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach",
    "abstract": "This paper deals with the problem of covariance control for a class of linear stochastic discrete-time systems in the Stochastic Model Predictive Control (SMPC) framework. The considered systems are affected by independent and identically distributed (i.i.d.) additive and parametric stochastic uncertainties (potentially unbounded), in addition to polytopic deterministic uncertainties bounding the mean of the state and input parameters. The control design conditions presented in this paper are formulated as Linear Matrix Inequalities (LMIs), using the S-variable approach in order to reduce the potential conservatism. These conditions are derived using a deterministic exact characterization of the covariance dynamics, the latter involves bilinear terms in the control gain. A technique to linearize such dynamics is presented, it results in a descriptor representation allowing to derive sufficient conditions for covariance control design. The derived condition is firstly compared to a known necessary and sufficient stability condition for systems without deterministic uncertainties and additive stochastic noise, although more conservative, it turns out to be more numerically tractable. Then, the same condition is used to design controllers that are robust to both deterministic and stochastic uncertainties. Several numerical examples are presented for comparison and illustration.",
    "authors": [
      "Kaouther Moussa",
      "Dimitri Peaucelle"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03680",
    "title": "Output-Constrained Controller with Fuzzy-Tuned Parameters for Overhead Cranes",
    "abstract": "This study proposes a fuzzy-adjusted nonlinear control method based on torque jitter output limit constraints for overhead crane systems with double pendulum effects. The proposed control method can effectively suppress swing and achieve precise positioning. Firstly, by enhancing the coupling relationship between the trolley displacement and swing angle, a composite signal with an error term was designed. Then, an energy-based Lyapunov function was constructed using the composite error signal, which incorporated a new formulation of the inertia matrix and potential energy function. Subsequently, using the backstepping method in conjunction with the hyperbolic tangent function, a controller with partial performance constraints was designed. In addition, to further enhance the system's dynamic performance, a fuzzy control scheme with online adjustable system parameters was designed. Finally, the stability of the system is proven using Lyapunov theory combined with LaSalle's invariance principle. Simulation results demonstrate that the proposed controller exhibits superior performance and robustness.",
    "authors": [
      "Dawei Zhao",
      "Kai Wang",
      "Xianglong Zhou",
      "Xin Ma",
      "Lei Jia"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03703",
    "title": "Scalable Pixel-based Reconfigurable Beamforming Networks for Designing Fluid Antenna Systems",
    "abstract": "A novel scalable pixel-based reconfigurable beamforming network (PRBFN) that can be used to form a Fluid Antenna System (FAS), referred to as a PRBFN-FAS, is introduced. The concept of FAS has emerged as an attractive new technology for use in sixth-generation (6G) wireless systems, but most implementations of FAS rely on mechanically reconfigurable antennas which are hindered by inertia, and are therefore too slow to be useful. Using the insight that changing an antenna's physical position is equivalent to switching the excitation current vector of a multi-port antenna, a novel beamformer is proposed with a scalable methodology for incorporating into FAS to form a PRBFN-FAS. Key novelties in creating the PRBFN include selecting the required current vectors and concatenating beamforming networks together to form the desired PRBFN. Two PRBFN-FAS design examples are demonstrated with FAS equivalent physical movements of 0.5 and 1.5 wavelengths. Measurements demonstrate that the PRBFN-FAS provides good matching and Bessel correlation across the desired bandwidth, satisfying FAS requirements. System-level experiments confirm the viability of PRBFN-FAS in practical communication scenarios.",
    "authors": [
      "Jichen Zhang",
      "Junhui Rao",
      "Tianqu Kang",
      "Zhaoyang Ming",
      "Yijun Chen",
      "Alikhan Umirbayev",
      "Chi-Yuk Chiu",
      "Ross Murch"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03712",
    "title": "A Hybrid Sequential Convex Programming Framework for Unbalanced Three-Phase AC OPF",
    "abstract": "This paper presents a hybrid Sequential Convex Programming (SCP) framework for solving the unbalanced three-phase AC Optimal Power Flow (OPF) problem. The method combines a fixed McCormick outer approximation of bilinear voltage-current terms, first-order Taylor linearisations, and an adaptive trust-region constraint to preserve feasibility and promote convergence. The resulting formulation remains convex at each iteration and ensures convergence to a stationary point that satisfies the first-order Karush-Kuhn-Tucker (KKT) conditions of the nonlinear OPF. Case studies on standard IEEE feeders and a real low-voltage (LV) network in Cyprus demonstrate high numerical accuracy with optimality gap below 0.1% and up to 2x faster runtimes compared to IPOPT. These results confirm that the method is accurate and computationally efficient for large-scale unbalanced distribution networks.",
    "authors": [
      "Sary Yehia",
      "Alessandra Parisio"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03752",
    "title": "A BTR-Based Approach for Detection of Infrared Small Targets",
    "abstract": "Infrared small target detection plays a crucial role in military reconnaissance and air defense systems. However,existing low-rank sparse based methods still face high computational complexity when dealing with low-contrast small targets and complex dynamic backgrounds mixed with target-like interference. To address this limitation, we reconstruct the data into a fourth-order tensor and propose a new infrared small target detection model based on bilateral tensor ring decomposition, called BTR-ISTD. The approach begins by constructing a four-dimensional infrared tensor from an image sequence, then utilizes BTR decomposition to effectively distinguish weak spatial correlations from strong temporal-patch correlations while simultaneously capturing interactions between these two components. This model is efficiently solved under the proximal alternating minimization (PAM) framework. Experimental results demonstrate that the proposed approach outperforms several state-of-the-art methods in terms of detection accuracy, background suppression capability, and computational speed.",
    "authors": [
      "Ke-Xin Li"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03764",
    "title": "Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression",
    "abstract": "Policy gradient algorithms are widely used in reinforcement learning and belong to the class of approximate dynamic programming methods. This paper studies two key policy gradient algorithms - the Natural Policy Gradient and the Gauss-Newton Method - for solving the Linear Quadratic Regulator (LQR) problem in unknown stochastic linear systems. The main challenge lies in obtaining an unbiased gradient estimate from noisy data due to errors-in-variables in linear regression. This issue is addressed by employing a primal-dual estimation procedure. Using this novel gradient estimation scheme, the paper establishes convergence guarantees with a sample complexity of order O(1/epsilon). Theoretical results are further supported by numerical experiments, which demonstrate the effectiveness of the proposed algorithms.",
    "authors": [
      "Bowen Song",
      "Sebastien Gros",
      "Andrea Iannelli"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03767",
    "title": "CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond",
    "abstract": "The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.",
    "authors": [
      "Bo Qian",
      "Hanlin Wu",
      "Jiacheng Chen",
      "Yunting Xu",
      "Xiaoyu Wang",
      "Haibo Zhou",
      "Yusheng Ji"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03779",
    "title": "Exact and Parametric Dynamical System Representation of Nonlinear Functions",
    "abstract": "Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation.",
    "authors": [
      "Toshiyuki Ohtsuka"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03802",
    "title": "Doppler Robust Vortex Wavefront Design for Integrated Sensing and Communication",
    "abstract": "Integrated sensing and communication (ISAC) is a promising paradigm for future wireless systems due to spectrum reuse, hardware sharing, and joint waveform design. In dynamic scenes, Doppler shifts degrade both sensing and communication, which is particularly critical for beam-sensitive orbital angular momentum (OAM) wavefronts. To address this, we propose a Doppler-robust ISAC framework, which first senses and then communicates. Specifically, in the sensing phase, multiple vortex modes are simultaneously transmitted via code-division mode-multiplexing (CDMM). To solve Doppler-induced inter-mode interference, we propose a velocity-consistency matching (VCM)-expectation maximization (EM) algorithm that jointly decodes the sensing matrix and estimates range, azimuth, elevation, and velocity for multiple moving targets. In the communication phase, the joint transmitter (Tx) beamforming and receiver (Rx) beam steering are configured from the estimated channel state information (CSI). We further quantify the sensing-communication allocation trade-off by evaluating how pilot length affects estimation accuracy, beam alignment, and spectral efficiency (SE). Simulation results show that the proposed VCM-EM and ISAC designs achieve higher sensing accuracy and communication SE than baseline schemes in dynamic scenarios.",
    "authors": [
      "Yuan Liu",
      "Wen-Xuan Long",
      "M. R. Bhavani Shankar",
      "Marco Moretti",
      "Rui Chen",
      "Björn Ottersten"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03835",
    "title": "Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN",
    "abstract": "The growing demand for robust, scalable wireless networks in the 5G-and-beyond era has led to the deployment of Unmanned Aerial Vehicles (UAVs) as mobile base stations to enhance coverage in dense urban and underserved rural areas. This paper presents a Multi-Agent Deep Reinforcement Learning (MADRL) framework that integrates Proximal Policy Optimization (MAPPO), Multi-Agent Deep Deterministic Policy Gradient (MADDPG), and Multi-Agent Deep Q-Networks (MADQN) to jointly optimize UAV positioning, resource allocation, Quality of Service (QoS), and energy efficiency through 5G network slicing. The framework adopts Centralized Training with Decentralized Execution (CTDE), enabling autonomous real-time decision-making while preserving global coordination. Users are prioritized into Premium (A), Silver (B), and Bronze (C) slices with distinct QoS requirements. Experiments in realistic urban and rural scenarios show that MAPPO achieves the best overall QoS-energy tradeoff, especially in interference-rich environments; MADDPG offers more precise continuous control and can attain slightly higher SINR in open rural settings at the cost of increased energy usage; and MADQN provides a computationally efficient baseline for discretized action spaces. These findings demonstrate that no single MARL algorithm is universally dominant; instead, algorithm suitability depends on environmental topology, user density, and service requirements. The proposed framework highlights the potential of MARL-driven UAV systems to enhance scalability, reliability, and differentiated QoS delivery in next-generation wireless networks.",
    "authors": [
      "Ghoshana Bista",
      "Abbas Bradai",
      "Emmanuel Moulay",
      "Abdulhalim Dandoush"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03846",
    "title": "Fault-Tolerant Control of Steam Temperature in HRSG Superheater under Actuator Fault Using a Sliding Mode Observer and PINN",
    "abstract": "This paper presents a novel fault-tolerant control framework for steam temperature regulation in Heat Recovery Steam Generators (HRSGs) subject to actuator faults. Addressing the critical challenge of valve degradation in superheater spray attemperators, we propose a synergistic architecture comprising three components: (1) a Sliding Mode Observer (SMO) for estimation of unmeasured thermal states, (2) a Physics-Informed Neural Network (PINN) for estimating multiplicative actuator faults using physical laws as constraints, and (3) a one-sided Sliding Mode Controller (SMC) that adapts to the estimated faults while minimizing excessive actuation. The key innovation lies in the framework of closed-loop physics-awareness, where the PINN continuously informs both the observer and controller about fault severity while preserving thermodynamic consistency. Rigorous uniform ultimate boundedness (UUB) is established via Lyapunov analysis under practical assumptions. Validated on real HRSG operational data, the framework demonstrates effective fault adaptation, reduced temperature overshoot, and maintains steam temperature within 1°C of the setpoint under valve effectiveness loss. This work bridges control theory and physics-guided machine learning to deliver a practically deployable solution for power plant resilience, with extensions applicable to thermal systems subject to multiplicative faults.",
    "authors": [
      "Mojtaba Fanoodi",
      "Farzaneh Abdollahi",
      "Mahdi Aliyari Shoorehdeli"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03962",
    "title": "Tada-DIP: Input-adaptive Deep Image Prior for One-shot 3D Image Reconstruction",
    "abstract": "Deep Image Prior (DIP) has recently emerged as a promising one-shot neural-network based image reconstruction method. However, DIP has seen limited application to 3D image reconstruction problems. In this work, we introduce Tada-DIP, a highly effective and fully 3D DIP method for solving 3D inverse problems. By combining input-adaptation and denoising regularization, Tada-DIP produces high-quality 3D reconstructions while avoiding the overfitting phenomenon that is common in DIP. Experiments on sparse-view X-ray computed tomography reconstruction validate the effectiveness of the proposed method, demonstrating that Tada-DIP produces much better reconstructions than training-data-free baselines and achieves reconstruction performance on par with a supervised network trained using a large dataset with fully-sampled volumes.",
    "authors": [
      "Evan Bell",
      "Shijun Liang",
      "Ismail Alkhouri",
      "Saiprasad Ravishankar"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03977",
    "title": "An Information Theory of Finite Abstractions and their Fundamental Scalability Limits",
    "abstract": "Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy\" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.",
    "authors": [
      "Giannis Delimpaltadakis",
      "Gabriel Gleizer"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03990",
    "title": "Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder",
    "abstract": "Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV.",
    "authors": [
      "Soha Ilbeigi",
      "Ashkan Bagherzadeh",
      "Alireza Sharifi"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03216",
    "title": "Kaleidoscopic Scintillation Event Imaging",
    "abstract": "Scintillators are transparent materials that interact with high-energy particles and emit visible light as a result. They are used in state of the art methods of measuring high-energy particles and radiation sources. Most existing methods use fast single-pixel detectors to detect and time scintillation events. Cameras provide spatial resolution but can only capture an average over many events, making it difficult to image the events associated with an individual particle. Emerging single-photon avalanche diode cameras combine speed and spatial resolution to enable capturing images of individual events. This allows us to use machine vision techniques to analyze events, enabling new types of detectors. The main challenge is the very low brightness of the events. Techniques have to work with a very limited number of photons. We propose a kaleidoscopic scintillator to increase light collection in a single-photon camera while preserving the event's spatial information. The kaleidoscopic geometry creates mirror reflections of the event in known locations for a given event location that are captured by the camera. We introduce theory for imaging an event in a kaleidoscopic scintillator and an algorithm to estimate the event's 3D position. We find that the kaleidoscopic scintillator design provides sufficient light collection to perform high-resolution event measurements for advanced radiation imaging techniques using a commercial CMOS single-photon camera. Code and data are available at this https URL .",
    "authors": [
      "Alex Bocchieri",
      "John Mamish",
      "David Appleyard",
      "Andreas Velten"
    ],
    "primary_category": "physics.ins-det",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03248",
    "title": "Learning Network Sheaves for AI-native Semantic Communication",
    "abstract": "Recent advances in AI call for a paradigm shift from bit-centric communication to goal- and semantics-oriented architectures, paving the way for AI-native 6G networks. In this context, we address a key open challenge: enabling heterogeneous AI agents to exchange compressed latent-space representations while mitigating semantic noise and preserving task-relevant meaning. We cast this challenge as learning both the communication topology and the alignment maps that govern information exchange among agents, yielding a learned network sheaf equipped with orthogonal maps. This learning process is further supported by a semantic denoising end compression module that constructs a shared global semantic space and derives sparse, structured representations of each agent's latent space. This corresponds to a nonconvex dictionary learning problem solved iteratively with closed-form updates. Experiments with mutiple AI agents pre-trained on real image data show that the semantic denoising and compression facilitates AI agents alignment and the extraction of semantic clusters, while preserving high accuracy in downstream task. The resulting communication network provides new insights about semantic heterogeneity across agents, highlighting the interpretability of our methodology.",
    "authors": [
      "Enrico Grimaldi",
      "Mario Edoardo Pandolfo",
      "Gabriele D'Acunto",
      "Sergio Barbarossa",
      "Paolo Di Lorenzo"
    ],
    "primary_category": "cs.MA",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03434",
    "title": "Quantum Encrypted Control of Networked Systems",
    "abstract": "Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources.",
    "authors": [
      "Zihao Ren",
      "Daniel Quevedo",
      "Salah Sukkarieh",
      "Guodong Shi"
    ],
    "primary_category": "quant-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03444",
    "title": "PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers",
    "abstract": "Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.",
    "authors": [
      "Davood Soleymanzadeh",
      "Xiao Liang",
      "Minghui Zheng"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03519",
    "title": "Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems",
    "abstract": "Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects. A key tenet of Systems Engineering and acquisition engineering is centred around a \"left-shift\" in test and evaluation activities to earlier in the system lifecycle, to allow for \"accelerated delivery of [systems] that work\". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.",
    "authors": [
      "Ben Larwood",
      "Oliver J. Sutton",
      "Callum Cockburn"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03524",
    "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities",
    "abstract": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.",
    "authors": [
      "Grzegorz Jamróz",
      "Rafał Kucharski",
      "David Watling"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03539",
    "title": "Real-Time Control and Automation Framework for Acousto-Holographic Microscopy",
    "abstract": "Manual operation of microscopes for repetitive tasks in cell biology is a significant bottleneck, consuming invaluable expert time, and introducing human error. Automation is essential, and while Digital Holographic Microscopy (DHM) offers powerful, label-free quantitative phase imaging (QPI), its inherently noisy and low-contrast holograms make robust autofocus and object detection challenging. We present the design, integration, and validation of a fully automated closed-loop DHM system engineered for high-throughput mechanical characterization of biological cells. The system integrates automated serpentine scanning, real-time YOLO-based object detection, and a high-performance, multi-threaded software architecture using pinned memory and SPSC queues. This design enables the GPU-accelerated reconstruction pipeline to run fully in parallel with the 50 fps data acquisition, adding no sequential overhead. A key contribution is the validation of a robust, multi-stage holographic autofocus strategy; we demonstrate that a selected metric (based on a low-pass filter and standard deviation) provides reliable focusing for noisy holograms where conventional methods (e.g., Tenengrad, Laplacian) fail entirely. Performance analysis of the complete system identifies the 2.23-second autofocus operation-not reconstruction-as the primary throughput bottleneck, resulting in a 9.62-second analysis time per object. This work delivers a complete functional platform for autonomous DHM screening and provides a clear, data-driven path for future optimization, proposing a hybrid brightfield imaging modality to address current bottlenecks.",
    "authors": [
      "Hasan Berkay Abdioğlu",
      "Yağmur Işık",
      "Mustafa İsmail İnal",
      "Nehir Serin",
      "Kerem Bayer",
      "Muhammed Furkan Koşar",
      "Taha Ünal",
      "Hüseyin Üvet"
    ],
    "primary_category": "physics.optics",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03636",
    "title": "Head, posture, and full-body gestures in interactive communication",
    "abstract": "When face-to-face communication becomes effortful due to background noise or interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively examined head or hand movements, here we explore movements of the whole body in acoustically adverse conditions. We hypothesized that increasing background noise in conversations would lead to increased gesture frequency in hand, head, trunk, and leg movements typical of conversation. Increased use of hand movements should support the speaker's role, while increased head and trunk movements may help the listener. We conducted a free dyadic conversation experiment with normal-hearing participants (n=8) in a virtual acoustic environment. Conversational movements were described with a newly developed labeling system for typical conversational actions, and the frequency of individual types was analyzed. In addition, we analyzed gesture quality by assessing hand-speech synchrony, with the hypothesis that higher levels of background noise would lead to a loss of synchrony according to an interactive coupling model. Higher noise levels led to increased hand-gesture complexity during speaking and listening, more pronounced up-down head movements, and contrary to expectations, head movements during listening generally decreased relative to speaking. Synchrony and peak velocity were unaffected by noise, while gesture quality scaled only modestly. The results support previous findings regarding gesturing frequency, but we found only limited evidence for changes in speech-gesture synchrony. This work reveals communication patterns of the whole body and illustrates multimodal adaptation to communication demands.",
    "authors": [
      "Ľuboš Hládek",
      "Bernhard U. Seeber"
    ],
    "primary_category": "cs.HC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03727",
    "title": "Colored Markov Random Fields for Probabilistic Topological Modeling",
    "abstract": "Probabilistic Graphical Models (PGMs) encode conditional dependencies among random variables using a graph -nodes for variables, links for dependencies- and factorize the joint distribution into lower-dimensional components. This makes PGMs well-suited for analyzing complex systems and supporting decision-making. Recent advances in topological signal processing highlight the importance of variables defined on topological spaces in several application domains. In such cases, the underlying topology shapes statistical relationships, limiting the expressiveness of canonical PGMs. To overcome this limitation, we introduce Colored Markov Random Fields (CMRFs), which model both conditional and marginal dependencies among Gaussian edge variables on topological spaces, with a theoretical foundation in Hodge theory. CMRFs extend classical Gaussian Markov Random Fields by including link coloring: connectivity encodes conditional independence, while color encodes marginal independence. We quantify the benefits of CMRFs through a distributed estimation case study over a physical network, comparing it with baselines with different levels of topological prior.",
    "authors": [
      "Lorenzo Marinucci",
      "Leonardo Di Nino",
      "Gabriele D'Acunto",
      "Mario Edoardo Pandolfo",
      "Paolo Di Lorenzo",
      "Sergio Barbarossa"
    ],
    "primary_category": "stat.ML",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03729",
    "title": "Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing",
    "abstract": "The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.",
    "authors": [
      "Samantha Chapin",
      "Kenneth Stewart",
      "Roxana Leontie",
      "Carl Glen Henshaw"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03736",
    "title": "Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control",
    "abstract": "Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.",
    "authors": [
      "Kenneth Stewart",
      "Samantha Chapin",
      "Roxana Leontie",
      "Carl Glen Henshaw"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03768",
    "title": "Deep Unfolding: Recent Developments, Theory, and Design Guidelines",
    "abstract": "Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.",
    "authors": [
      "Nir Shlezinger",
      "Santiago Segarra",
      "Yi Zhang",
      "Dvir Avrahami",
      "Zohar Davidov",
      "Tirza Routtenberg",
      "Yonina C. Eldar"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03772",
    "title": "Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control",
    "abstract": "This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.",
    "authors": [
      "Gabriele Fadini",
      "Deepak Ingole",
      "Tong Duy Son",
      "Alisa Rupenyan"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03807",
    "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics",
    "abstract": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.",
    "authors": [
      "Christos Kolomvakis",
      "Thomas Bobille",
      "Arnaud Vandaele",
      "Nicolas Gillis"
    ],
    "primary_category": "cs.IR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03872",
    "title": "Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices",
    "abstract": "This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03886",
    "title": "A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments",
    "abstract": "This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.",
    "authors": [
      "Brais Fontan-Costas",
      "M. Diaz-Cacho",
      "Ruben Fernandez-Boullon",
      "Manuel Alonso-Carracedo",
      "Javier Perez-Robles"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04019",
    "title": "Ultra-lightweight Neural Video Representation Compression",
    "abstract": "Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.",
    "authors": [
      "Ho Man Kwan",
      "Tianhao Peng",
      "Ge Gao",
      "Fan Zhang",
      "Mike Nilsson",
      "Andrew Gower",
      "David Bull"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04077",
    "title": "Semi-Markov Decision Process Framework for Age of Incorrect Information Minimization",
    "abstract": "For a remote estimation system, we study age of incorrect information (AoII), which is a recently proposed semantic-aware freshness metric. In particular, we assume an information source observing a discrete-time finite-state Markov chain (DTMC) and employing push-based transmissions of status update packets towards the monitor which is tasked with remote estimation of the source. The source-to-monitor channel delay is assumed to have a general discrete-time phase-type (DPH) distribution, whereas the zero-delay reverse channel ensures that the source has perfect information on AoII and the remote estimate. A multi-threshold transmission policy is employed where packet transmissions are initiated when the AoII process exceeds a threshold which may be different for each estimation value. In this general setting, our goal is to minimize the weighted sum of time average of an arbitrary function of AoII and estimation, and transmission costs, by suitable choice of the thresholds. We formulate the problem as a semi-Markov decision process (SMDP) with the same state-space as the original DTMC to obtain the optimum multi-threshold policy whereas the parameters of the SMDP are obtained by using a novel stochastic tool called dual-regime absorbing Markov chain (DR-AMC), and its corresponding absorption time distribution named as dual-regime DPH (DR-DPH).",
    "authors": [
      "Ismail Cosandal",
      "Sennur Ulukus",
      "Nail Akar"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2308.05571",
    "title": "Reconfigurable Intelligent Surface Deployments for Mars: Communication and Localization Across Diverse Terrains",
    "abstract": "Space exploration has witnessed a steady increase since the 1960s, with Mars playing a significant role in our quest for further knowledge. As the ambition to colonize Mars becomes a reality through the collaboration of private companies and space agencies, the need for reliable and robust communication infrastructures in the Martian environment becomes paramount. In this context, reconfigurable intelligent surface (RIS)-empowered communication emerges as a promising technology to enhance the coverage due to lack of multipath components in line-of-sight (LOS) dominated Martian environments. By considering various Martian scenarios such as canyons, craters, mountains, and plateaus, this article explores of the potential of RISs in increasing the coverage in Martian environments. The article also provides an overview of RIS-assisted localization in both LOS and non-line-of-sight (NLOS) scenarios, presenting a general framework for accurate user angle estimation in challenging Martian conditions. The findings and presented framework of this article provide a promising research direction for integrating RISs in deep space communication as well as paving the way for future improvements in interplanetary communication networks.",
    "authors": [
      "Enes Koktas",
      "Recep A. Tasci",
      "Ibrahim Yildirim",
      "Ertugrul Basar"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2309.05794",
    "title": "Robust Physics-based Deep MRI Reconstruction Via Diffusion Purification",
    "abstract": "Deep learning (DL) techniques have been extensively employed in magnetic resonance imaging (MRI) reconstruction, delivering notable performance enhancements over traditional non-DL methods. Nonetheless, recent studies have identified vulnerabilities in these models during testing, namely, their susceptibility to (\\textit{i}) worst-case measurement perturbations and to (\\textit{ii}) variations in training/testing settings like acceleration factors and k-space sampling locations. This paper addresses the robustness challenges by leveraging diffusion models. In particular, we present a robustification strategy that improves the resilience of DL-based MRI reconstruction methods by utilizing pretrained diffusion models as noise purifiers. In contrast to conventional robustification methods for DL-based MRI reconstruction, such as adversarial training (AT), our proposed approach eliminates the need to tackle a minimax optimization problem. It only necessitates fine-tuning on purified examples. Our experimental results highlight the efficacy of our approach in mitigating the aforementioned instabilities when compared to leading robustification approaches for deep MRI reconstruction, including AT and randomized smoothing.",
    "authors": [
      "Ismail Alkhouri",
      "Shijun Liang",
      "Rongrong Wang",
      "Qing Qu",
      "Saiprasad Ravishankar"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.12197",
    "title": "Anti-bullying Adaptive Cruise Control: A proactive right-of-way protection approach",
    "abstract": "Adaptive Cruise Control (ACC) systems have been widely commercialized in recent years. However, existing ACC systems remain vulnerable to close-range cut-ins, a behavior that resembles \"road bullying\". To address this issue, this research proposes an Anti-bullying Adaptive Cruise Control (AACC) approach, which is capable of proactively protecting right-of-way against such \"road bullying\" cut-ins. To handle diverse \"road bullying\" cut-in scenarios smoothly, the proposed approach first leverages an online Inverse Optimal Control (IOC) based algorithm for individual driving style identification. Then, based on Stackelberg competition, a game-theoretic-based motion planning framework is presented in which the identified individual driving styles are utilized to formulate cut-in vehicles' reaction functions. By integrating such reaction functions into the ego vehicle's motion planning, the ego vehicle could consider cut-in vehicles' all possible reactions to find its optimal right-of-way protection maneuver. To the best of our knowledge, this research is the first to model vehicles' interaction dynamics and develop an interactive planner that adapts cut-in vehicle's various driving styles. Simulation results show that the proposed approach can prevent \"road bullying\" cut-ins and be adaptive to different cut-in vehicles' driving styles. It can improve safety and comfort by up to 79.8% and 20.4%. The driving efficiency has benefits by up to 19.33% in traffic flow. The proposed approach can also adopt more flexible driving strategies. Furthermore, the proposed approach can support real-time field implementation by ensuring less than 50 milliseconds computation time.",
    "authors": [
      "Jia Hu",
      "Zhexi Lian",
      "Haoran Wang",
      "Zihan Zhang",
      "Ruoxi Qian",
      "Duo Li",
      "Jaehyun",
      "Junnian Zheng"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.17212",
    "title": "A Tractable Two-Step Linear Mixing Model Solved with Second-Order Optimization for Spectral Unmixing under Variability",
    "abstract": "In this paper, we propose a Two-Step Linear Mixing Model (2LMM) that bridges the gap between model complexity and computational tractability. The model achieves this by introducing two distinct scaling steps: an endmember scaling step across the image, and another for pixel-wise scaling. We show that this model leads to only a mildly non-convex optimization problem, which we solve with an optimization algorithm that incorporates second-order information. To the authors' knowledge, this work represents the first application of second-order optimization techniques to solve a spectral unmixing problem that models endmember variability. Our method is highly robust, as it requires virtually no hyperparameter tuning and can therefore be used easily and quickly in a wide range of unmixing tasks. We show through extensive experiments on both simulated and real data that the new model is competitive and in some cases superior to the state of the art in unmixing. The model also performs very well in challenging scenarios, such as blind unmixing.",
    "authors": [
      "Xander Haijen",
      "Bikram Koirala",
      "Xuanwen Tao",
      "Paul Scheunders"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.18612",
    "title": "Understanding Untrained Deep Models for Inverse Problems: Algorithms and Theory",
    "abstract": "In recent years, deep learning methods have been extensively developed for inverse imaging problems (IIPs), encompassing supervised, self-supervised, and generative approaches. Most of these methods require large amounts of labeled or unlabeled training data to learn effective models. However, in many practical applications, such as medical image reconstruction, extensive training datasets are often unavailable or limited. A significant milestone in addressing this challenge came in 2018 with the work of Ulyanov et al., which introduced the Deep Image Prior (DIP)--the first training-data-free neural network method for IIPs. Unlike conventional deep learning approaches, DIP requires only a convolutional neural network, the noisy measurements, and a forward operator. By leveraging the implicit regularization of deep networks initialized with random noise, DIP can learn and restore image structures without relying on external datasets. However, a well-known limitation of DIP is its susceptibility to overfitting, primarily due to the over-parameterization of the network. In this tutorial paper, we provide a comprehensive review of DIP, including a theoretical analysis of its training dynamics. We also categorize and discuss recent advancements in DIP-based methods aimed at mitigating overfitting, including techniques such as regularization, network re-parameterization, and early stopping. Furthermore, we discuss approaches that combine DIP with pre-trained neural networks, present empirical comparison results against data-centric methods, and highlight open research questions and future directions.",
    "authors": [
      "Ismail Alkhouri",
      "Evan Bell",
      "Avrajit Ghosh",
      "Shijun Liang",
      "Rongrong Wang",
      "Saiprasad Ravishankar"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.09342",
    "title": "Computationally Efficient Signal Detection with Unknown Bandwidths",
    "abstract": "Signal detection in environments with unknown signal bandwidth and time intervals is a fundamental problem in adversarial and spectrum-sharing scenarios. This paper addresses the problem of detecting signals occupying unknown degrees of freedom from non-coherent power measurements, where the signal is constrained to an interval in one dimension or a hyper-cube in multiple dimensions. A GLRT is derived, resulting in a straightforward metric involving normalized average signal energy for each candidate signal set. We present bounds on false alarm and missed detection probabilities, demonstrating their dependence on SNR and signal set sizes. To overcome the inherent computational complexity of exhaustive searches, we propose a computationally efficient binary search method, reducing the complexity from O(N^2) to O(N) for one-dimensional cases. Simulations indicate that the method maintains performance near exhaustive searches and achieves asymptotic consistency, with interval-of-overlap converging to one under constant SNR as measurement size increases. The simulation studies also demonstrate superior performance and reduced complexity compared to contemporary neural network-based approaches, specifically outperforming custom-trained U-Net models in spectrum detection tasks.",
    "authors": [
      "Ali Rasteh",
      "Sundeep Rangan"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2505.24029",
    "title": "Nonlinear Oscillatory Response of Automated Vehicle Car-following: Theoretical Analysis with Traffic State and Control Input Limits",
    "abstract": "This paper presents a framework grounded in the theory of describing function (DF) and incremental-input DF to theoretically analyze the nonlinear oscillatory response of automated vehicles (AVs) car-following (CF) amidst traffic oscillations, considering the limits of traffic state and control input. While prevailing approaches largely ignore these limits (i.e., saturation of acceleration/deceleration and speed) and focus on linear string stability analysis, this framework establishes a basis for theoretically analyzing the frequency response of AV systems with nonlinearities imposed by these limits. To this end, trajectories of CF pairs are decomposed into nominal and oscillatory trajectories, subsequently, the controlled AV system is repositioned within the oscillatory trajectory coordinates. Built on this base, DFs are employed to approximate the frequency responses of nonlinear saturation components by using their first harmonic output, thereby capturing the associated amplification ratio and phase shift. Considering the closed-loop nature of AV control systems, where system states and control input mutually influence each other, amplification ratios and phase shifts are balanced within the loop to ensure consistency. This balancing process may render multiple solutions, hence the incremental-input DF is further applied to identify the reasonable ones. The proposed method is validated by estimations from Simulink, and further comparisons with prevailing methods are conducted. Results confirm the alignment of our framework with Simulink results and exhibit its superior accuracy in analysis compared to the prevailing methods. Furthermore, the framework proves valuable in string stability analysis, especially when conventional linear methods offer misleading insights.",
    "authors": [
      "Sixu Li",
      "Yang Zhou"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.05127",
    "title": "PixCell: A generative foundation model for digital histopathology images",
    "abstract": "The digitization of histology slides has revolutionized pathology, providing massive datasets for cancer diagnosis and research. Self-supervised and vision-language models have been shown to effectively mine large pathology datasets to learn discriminative representations. On the other hand, there are unique problems in pathology, such as annotated data scarcity, privacy regulations in data sharing, and inherently generative tasks like virtual staining. Generative models, capable of synthesizing realistic and diverse images, present a compelling solution to address these problems through image synthesis. We introduce PixCell, the first generative foundation model for histopathology images. PixCell is a diffusion model trained on PanCan-30M, a large, diverse dataset derived from 69,184 H&E-stained whole slide images of various cancer types. We employ a progressive training strategy and a self-supervision-based conditioning that allows us to scale up training without any human-annotated data. By conditioning on real slides, the synthetic images capture the properties of the real data and can be used as data augmentation for small-scale datasets to boost classification performance. We prove the foundational versatility of PixCell by applying it to two generative downstream tasks: privacy-preserving synthetic data generation and virtual IHC staining. PixCell's high-fidelity conditional generation enables institutions to use their private data to synthesize highly realistic, site-specific surrogate images that can be shared in place of raw patient data. Furthermore, using datasets of roughly paired H&E-IHC tiles, we learn to translate PixCell's conditioning from H&E to multiple IHC stains, allowing the generation of IHC images from H&E inputs. Our trained models are publicly released to accelerate research in computational pathology.",
    "authors": [
      "Srikar Yellapragada",
      "Alexandros Graikos",
      "Zilinghan Li",
      "Kostas Triaridis",
      "Varun Belagali",
      "Tarak Nath Nandi",
      "Karen Bai",
      "Beatrice S. Knudsen",
      "Tahsin Kurc",
      "Rajarsi R. Gupta",
      "Prateek Prasanna",
      "Ravi K Madduri",
      "Joel Saltz",
      "Dimitris Samaras"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.06210",
    "title": "Spectral Derivatives",
    "abstract": "One of the happiest accidents in all math is the ease of transforming a function to and taking derivatives in the Fourier frequency domain. But in order to exploit this extraordinary fact without serious artefacting, and in order to be able to use a computer, we need quite a bit of extra knowledge and care. This document sets out the math behind the spectral-derivatives Python package. I touch on fundamental signal processing and calculus concepts as necessary and build upwards.",
    "authors": [
      "Pavel Komarov"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.11294",
    "title": "Design of 3D Beamforming and Deployment Strategies for ISAC-based HAPS Systems",
    "abstract": "This paper explores high-altitude platform station (HAPS) systems enabled by integrated sensing and communication (ISAC), in which a HAPS simultaneously transmits communication signals and synthetic aperture radar (SAR) imaging signals to support multi-user communication while performing ground target sensing. Taking into account the operational characteristics of SAR imaging, we consider two HAPS deployment strategies: (i) a quasi-stationary HAPS that remains fixed at an optimized location during SAR operation, following the stop-and-go scanning model; and (ii) a dynamic HAPS that continuously adjusts its flight trajectory along a circular path. For each strategy, we aim at maximizing the weighted sum-rate throughput for communication users while ensuring that SAR imaging requirements, such as beampattern gain and signal-to-noise ratio (SNR), are satisfied. This is achieved by jointly optimizing the HAPS deployment strategy, i.e., its placement or trajectory, along with three-dimensional (3D) transmit beamforming, under practical constraints including transmit power limits, energy consumption, and flight dynamics. Nevertheless, the formulated optimization problems corresponding to the two deployment strategies are inherently non-convex. To address the issue, we propose efficient algorithms that leverage both convex and non-convex optimization techniques to obtain high-quality suboptimal solutions. Numerical results demonstrate the effectiveness and advantages of the proposed approaches over benchmark schemes.",
    "authors": [
      "Xue Zhang",
      "Bang Huang",
      "Mohamed-Slim Alouini"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.12639",
    "title": "Channel Estimation for Downlink Communications Based on Dynamic Metasurface Antennas",
    "abstract": "Dynamic metasurface antennas (DMAs) are emerging as a promising technology to enable energy-efficient, large array-based multi-antenna systems. This paper presents a simple channel estimation scheme for the downlink of a multiple-input single-output orthogonal frequency division multiplexing (MISO-OFDM) communication system exploiting DMAs. The proposed scheme extracts separate estimates of the wireless channel and the unknown waveguide propagation vector using a simple iterative algorithm based on the parallel factor (PARAFAC) decomposition. Obtaining decoupled estimates of the wireless channel and inner waveguide vector enables the isolation and compensation for its effect when designing the DMA beamformer, regardless of the wireless channel state, which evolves much faster due to its shorter coherence time and bandwidth. Additionally, our solution operates in a data-aided manner, delivering estimates of useful data symbols jointly with channel estimates, without requiring sequential pilot and data stages. To the best of our knowledge, this is the first work to explore this CE approach. Numerical results corroborate the notable performance of the proposed scheme.",
    "authors": [
      "Amarilton L. Magalhães",
      "Fazal E-Asim",
      "André L. F. de Almeida",
      "A. Lee Swindlehurst"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2506.21325",
    "title": "Localization-Based Beam Focusing in Near-Field Communications",
    "abstract": "Shifting 6G-and-beyond wireless systems to higher frequency bands and the utilization of massive multiple-input multiple-output arrays will extend the near-field region, affecting beamforming and user localization schemes. In this paper, we propose a localization-based beam-focusing design, in which the receive combiners are directly constructed from the steering vectors corresponding to the estimated user locations. To support this approach, we analyze the 2D-MUSIC algorithm by examining its spectrum in simplified, tractable setups with minimal numbers of antennas and users. Lastly, we compare the proposed localization-based beam focusing, with locations estimated via 2D-MUSIC, with pilot-based zero forcing in terms of uplink sum spectral efficiency. Our results show significant gains under dominant line-of-sight propagation, short coherence blocks, and high noise power typical of high-frequency systems.",
    "authors": [
      "Nima Mozaffarikhosravi",
      "Prathapasinghe Dharmawansa",
      "Italo Atzeni"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.03758",
    "title": "TransUNet-GradCAM: A Hybrid Transformer-U-Net with Self-Attention and Explainable Visualizations for Foot Ulcer Segmentation",
    "abstract": "Automated segmentation of diabetic foot ulcers (DFUs) plays a critical role in clinical diagnosis, therapeutic planning, and longitudinal wound monitoring. However, this task remains challenging due to the heterogeneous appearance, irregular morphology, and complex backgrounds associated with ulcer regions in clinical photographs. Traditional convolutional neural networks (CNNs), such as U-Net, provide strong localization capabilities but struggle to model long-range spatial dependencies due to their inherently limited receptive fields. To address this, we employ the TransUNet architecture, a hybrid framework that integrates the global attention mechanism of Vision Transformers (ViTs) into the U-Net structure. This combination allows the model to extract global contextual features while maintaining fine-grained spatial resolution. We trained the model on the public Foot Ulcer Segmentation Challenge (FUSeg) dataset using a robust augmentation pipeline and a hybrid loss function to mitigate class imbalance. On the validation set, the model achieved a Dice Similarity Coefficient (F1-score) of 0.8799 using an optimized threshold of 0.4389. To ensure clinical transparency, we integrated Grad-CAM visualizations to highlight model focus areas. Furthermore, a clinical utility analysis demonstrated a strong correlation (Pearson r = 0.9631) between predicted and ground-truth wound areas. These outcomes demonstrate that our approach effectively integrates global and local feature extraction, offering a reliable, effective, and explainable solution for automated foot ulcer assessment.",
    "authors": [
      "Akwasi Asare",
      "Mary Sagoe",
      "Justice Williams Asare",
      "Stephen Edward Moore"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2508.13875",
    "title": "A Novel Attention-Augmented Wavelet YOLO System for Real-time Brain Vessel Segmentation on Transcranial Color-coded Doppler",
    "abstract": "The Circle of Willis (CoW), vital for ensuring consistent blood flow to the brain, is closely linked to ischemic stroke. Accurate assessment of the CoW is important for identifying individuals at risk and guiding appropriate clinical management. Among existing imaging methods, Transcranial Color-coded Doppler (TCCD) offers unique advantages due to its radiation-free nature, affordability, and accessibility. However, reliable TCCD assessments depend heavily on operator expertise for identifying anatomical landmarks and performing accurate angle correction, which limits its widespread adoption. To address this challenge, we propose an AI-powered, real-time CoW auto-segmentation system capable of efficiently capturing cerebral arteries. No prior studies have explored AI-driven cerebrovascular segmentation using TCCD. In this work, we introduce a novel Attention-Augmented Wavelet YOLO (AAW-YOLO) network tailored for TCCD data, designed to provide real-time guidance for brain vessel segmentation in the CoW. We prospectively collected TCCD data comprising 738 annotated frames and 3,419 labeled artery instances to establish a high-quality dataset for model training and evaluation. The proposed AAW-YOLO demonstrated strong performance in segmenting both ipsilateral and contralateral CoW vessels, achieving an average Dice score of 0.901, IoU of 0.823, precision of 0.882, recall of 0.926, and mAP of 0.953, with a per-frame inference speed of 14.199 ms. This system offers a practical solution to reduce reliance on operator experience in TCCD-based cerebrovascular screening, with potential applications in routine clinical workflows and resource-constrained settings. Future research will explore bilateral modeling and larger-scale validation.",
    "authors": [
      "Wenxuan Zhang",
      "Shuai Li",
      "Xinyi Wang",
      "Yu Sun",
      "Hongyu Kang",
      "Pui Yuk Chryste Wan",
      "Jing Qin",
      "Yuanpeng Zhang",
      "Yong-Ping Zheng",
      "Sai-Kit Lam"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.02208",
    "title": "MACS: Measurement-Aware Consistency Sampling for Inverse Problems",
    "abstract": "Diffusion models have emerged as powerful generative priors for solving inverse imaging problems. However, their practical deployment is hindered by the substantial computational cost of slow, multi-step sampling. Although Consistency Models (CMs) address this limitation by enabling high-quality generation in only one or a few steps, their direct application to inverse problems has remained largely unexplored. This paper introduces a modified consistency sampling framework specifically designed for inverse problems. The proposed approach regulates the sampler's stochasticity through a measurement-consistency mechanism that leverages the degradation operator, thereby enforcing fidelity to the observed data while preserving the computational efficiency of consistency-based generation. Comprehensive experiments on the Fashion-MNIST and LSUN Bedroom datasets demonstrate consistent improvements across both perceptual and pixel-level metrics, including the Fréchet Inception Distance (FID), Kernel Inception Distance (KID), peak signal-to-noise ratio (PSNR), and structural similarity index measure (SSIM), compared with baseline consistency and diffusion-based sampling methods. The proposed method achieves competitive or superior reconstruction quality with only a small number of sampling steps.",
    "authors": [
      "Amirreza Tanevardi",
      "Pooria Abbas Rad Moghadam",
      "Seyed Mohammad Eshtehardian",
      "Sajjad Amini",
      "Babak Khalaj"
    ],
    "primary_category": "eess.IV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.05343",
    "title": "Robust Sensor Placement for Poisson Arrivals with False Alarm Aware Spatiotemporal Sensing",
    "abstract": "This paper studies sensor placement when detection performance varies stochastically due to environmental factors over space and time and false alarms are present, but a filter is used to attenuate the effect. We introduce a unified model that couples detection and false alarms through an availability function, which captures how false alarms reduce effective sensing and filtering responses to the disturbance. Building on this model, we give a sufficient condition under which filtering improves detection. In addition, we derive a coverage-based lower bound on the void probability. Furthermore, we prove robustness guarantees showing that performance remains stable when detection probabilities are learned from limited data. We validate the approach with numerical studies using AIS vessel-traffic data and synthetic maritime scenarios. Together, these results provide theory and practical guidance for deploying sensors in dynamic, uncertain environments.",
    "authors": [
      "Mingyu Kim",
      "Pronoy Sarker",
      "Seungmo Kim",
      "Daniel J. Stilwell",
      "Jorge Jimenez"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.21951",
    "title": "Pricing Problems in Adoption of New Technologies",
    "abstract": "We propose a generalization of the Bass diffusion model in discrete-time that explicitly models the effect of price in adoption. Our model is different from earlier price-incorporated models and fits well to adoption data for various products. We then utilize this model to study two decision-making problems. First, we provide a series of structural results on optimal pricing strategies to maximize profits from product sales by a monopolist over a finite horizon. We fully characterize the optimal pricing strategy in the single-period problem, and establish several structural properties of the same for the multi-period counterpart. Second, we study a Stackelberg game between a policy-maker and a monopolist, where the former seeks to maximize adoption through rebates, while the latter focuses on profits. For this problem, we analytically characterize crucial properties of the equilibrium path of the single-period game, and demonstrate how they carry over to the multi-period variant.",
    "authors": [
      "Yijin Wang",
      "Subhonmesh Bose"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.02689",
    "title": "Eye Movement Analysis in Simulated Driving Scenarios",
    "abstract": "This study investigates eye movement behaviour during three conditions: Baseline, Ride (simulated drive under normal visibility), and Fog (simulated drive under reduced visibility). Eye tracking data are analyzed using 31 parameters, organized into three groups: (1) saccade features, (2) Bivariate Contour Ellipse Area (BCEA), and (3) blinking features. Specifically, the analysis includes 13 saccade, 13 BCEA, and 5 blinking variables. Across all feature groups, numerous statistically significant differences emerge between Baseline and the driving conditions, particularly between Baseline and Ride or Fog. Between Ride and Fog, saccade features show minimal changes (four out of 13), whereas BCEA (9 of 13) and blink features (four of 5) exhibit pronounced differences, highlighting the strong impact of reduced visibility on gaze stability and blinking behaviour. In addition to conventional measures such as Mean Squared Error (MSE) and entropy metrics, a new parameter, Guzik's Index (GI), is introduced to quantify fixation asymmetry along the major axis of the BCEA. This index utilizes eye tracking data to enhance the understanding of eye movement dynamics during driving conditions. Separately from GI, other parameters elicit the largest deviations compared to Ride (e.g., number of saccades: Cliff's {\\delta} = 0.98, BCEA: Cohen's d = 0.89, and standard deviation of blink duration: Cliff's {\\delta} = 0.80), underscoring the influence of reduced visibility on visual attention. Overall, these findings demonstrate that combining BCEA with saccade and blink parameters provides a comprehensive understanding of visual attention and gaze stability, while GI offers additional insights into fixation asymmetry under varying visibility conditions.",
    "authors": [
      "Smilja Stokanović",
      "Jaka Sodnik",
      "Nadica Miljković"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.06246",
    "title": "IDMap: A Pseudo-Speaker Generator Framework Based on Speaker Identity Index to Vector Mapping",
    "abstract": "Facilitated by the speech generation framework that disentangles speech into content, speaker, and prosody, voice anonymization is accomplished by substituting the original speaker embedding vector with that of a pseudo-speaker. In this framework, the pseudo-speaker generation forms a fundamental challenge. Current pseudo-speaker generation methods demonstrate limitations in the uniqueness of pseudo-speakers, consequently restricting their effectiveness in voice privacy protection. Besides, existing model-based methods suffer from heavy computation costs. Especially, in the large-scale scenario where a huge number of pseudo-speakers are generated, the limitations of uniqueness and computational inefficiency become more significant. To this end, this paper proposes a framework for pseudo-speaker generation, which establishes a mapping from speaker identity index to speaker vector in the feedforward architecture, termed IDMap. Specifically, the framework is specified into two models: IDMap-MLP and IDMap-Diff. Experiments were conducted on both small- and large-scale evaluation datasets. Small-scale evaluations on the LibriSpeech dataset validated the effectiveness of the proposed IDMap framework in enhancing the uniqueness of pseudo-speakers, thereby improving voice privacy protection, while at a reduced computational cost. Large-scale evaluations on the MLS and Common Voice datasets further justified the superiority of the IDMap framework regarding the stability of the voice privacy protection capability as the number of pseudo-speakers increased. Audio samples and open-source code can be found in this https URL .",
    "authors": [
      "Zeyan Liu",
      "Liping Chen",
      "Kong Aik Lee",
      "Zhenhua Ling"
    ],
    "primary_category": "eess.AS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.08769",
    "title": "SSMRadNet : A Sample-wise State-Space Framework for Efficient and Ultra-Light Radar Segmentation and Object Detection",
    "abstract": "We introduce SSMRadNet, the first multi-scale State Space Model (SSM) based detector for Frequency Modulated Continuous Wave (FMCW) radar that sequentially processes raw ADC samples through two SSMs. One SSM learns a chirp-wise feature by sequentially processing samples from all receiver channels within one chirp, and a second SSM learns a representation of a frame by sequentially processing chirp-wise features. The latent representations of a radar frame are decoded to perform segmentation and detection tasks. Comprehensive evaluations on the RADIal dataset show SSMRadNet has 10-33x fewer parameters and 60-88x less computation (GFLOPs) while being 3.7x faster than state-of-the-art transformer and convolution-based radar detectors at competitive performance for segmentation tasks.",
    "authors": [
      "Anuab Sen",
      "Mir Sayeed Mohammad",
      "Saibal Mukhopadhyay"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.10639",
    "title": "Direction-of-Arrival and Noise Covariance Matrix joint estimation for beamforming",
    "abstract": "We propose a joint estimation method for the Direction-of-Arrival (DoA) and the Noise Covariance Matrix (NCM) tailored for beamforming applications. Building upon an existing NCM framework, our approach simplifies the estimation procedure by deriving an quasi-linear solution, instead of the traditional exhaustive search. Additionally, we introduce a novel DoA estimation technique that operates across all frequency bins, improving robustness in reverberant environments. Simulation results demonstrate that our method outperforms classical techniques, such as MUSIC, in mid- to high-angle scenarios, achieving lower angular errors and superior signal enhancement through beamforming. The proposed framework was also fared against other techniques for signal enhancement, having better noise rejection and interference canceling capabilities. These improvements are validated using both theoretical and empirical performance metrics.",
    "authors": [
      "Vitor Gelsleichter Probst Curtarelli",
      "Stephan Paul",
      "Anderson Wedderhoff Spengler"
    ],
    "primary_category": "eess.AS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.18725",
    "title": "First Deep Learning Approach to Hammering Acoustics for Stem Stability Assessment in Total Hip Arthroplasty",
    "abstract": "Audio event classification has recently emerged as a promising approach in medical applications. In total hip arthroplasty (THA), intra-operative hammering acoustics provide critical cues for assessing the initial stability of the femoral stem, yet variability due to femoral morphology, implant size, and surgical technique constrains conventional assessment methods. We propose the first deep learning framework for this task, employing a TimeMIL model trained on Log-Mel Spectrogram features and enhanced with pseudo-labeling. On intra-operative recordings, the method achieved 91.17 % +/- 2.79 % accuracy, demonstrating reliable estimation of stem stability. Comparative experiments further show that reducing the diversity of femoral stem brands improves model performance, although limited dataset size remains a bottleneck. These results establish deep learning-based audio event classification as a feasible approach for intra-operative stability assessment in THA.",
    "authors": [
      "Dongqi Zhu",
      "Zhuwen Xu",
      "Youyuan Chen",
      "Minghao Jin",
      "Wan Zheng",
      "Yi Zhou",
      "Huiwu Li",
      "Yongyun Chang",
      "Feng Hong",
      "Zanjing Zhai"
    ],
    "primary_category": "eess.AS",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00205",
    "title": "RIS-Aided Localization and Sensing",
    "abstract": "High-precision localization and environmental sensing are essential for a new wave of applications, ranging from industrial automation and autonomous systems to augmented reality and remote healthcare. Conventional wireless methods, however, often face limitations in accuracy, reliability, and coverage, especially in complex non-line-of-sight (NLoS) environments. Reconfigurable Intelligent Surfaces (RISs) have emerged as a key enabling technology, offering dynamic control over the radio propagation environment to overcome these challenges. This chapter provides a comprehensive overview of RIS-aided localization and sensing, bridging fundamental theory with practical implementation. The core principles of the RIS technology are first described detailing how programmable metasurfaces can intelligently combat blockages, enhance signal diversity, and create virtual line-of-sight (LoS) links. The chapter then reviews a range of application scenarios where RISs can offer significant improvements. A significant portion of the chapter is dedicated to algorithmic methodologies, covering beam sweeping protocols, codebook-based techniques, and advanced optimization and machine learning strategies for both localization and sensing. To validate the theoretical concepts in real-world conditions, recent experimental results using an RIS prototype are detailed, showcasing the technology's efficacy and illustrating key performance trade-offs.",
    "authors": [
      "Dimitris Kompostiotis",
      "Dimitris Vordonis",
      "Konstantinos D. Katsanos",
      "Florin-Catalin Grec",
      "Vassilis Paliouras",
      "George C. Alexandropoulos"
    ],
    "primary_category": "eess.SP",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01475",
    "title": "A Unified Bayesian Framework for Stochastic Data-Driven Smoothing, Prediction, and Control",
    "abstract": "Extending data-driven algorithms based on Willems' fundamental lemma to stochastic data often requires empirical and customized workarounds. This work presents a unified Bayesian framework that provides a systematic and general method for handling stochastic data-driven tasks, including smoothing, prediction, and control, via maximum a posteriori estimation. This framework formulates a unified trajectory estimation problem for the three tasks by specifying different types of trajectory knowledge. Then, a Bayesian problem is solved that optimally combines trajectory knowledge with a data-driven characterization of the trajectory from offline data for a general class of stochastic disturbances. Under specific conditions, this problem is shown to generalize existing data-driven prediction and control algorithms. Numerical examples demonstrate the performance of the unified approach for all three tasks against other data-driven and system identification approaches.",
    "authors": [
      "Mingzhou Yin",
      "Andrea Iannelli",
      "Seyed Ali Nazari",
      "Matthias A. Müller"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02381",
    "title": "Fleet Size and Mix Capacitated Vehicle Routing Problem with Time Windows for Mobile Fast Chargers",
    "abstract": "The electrification of off-road heavy equipment presents operational challenges for agencies serving remote sites with limited fixed charging infrastructure. Existing mobile fast charging vehicle (MFCV) planning approaches typically treat fleet design and routing as separate problems, fixing vehicle characteristics before dispatch. This paper formulates a fleet size and mix capacitated vehicle routing problem with time windows (FSMCVRPTW) for MFCV deployment, jointly optimizing fleet composition, charger specifications, routing, and scheduling within a unified mixed-integer linear program. The model incorporates heterogeneous MFCV types with varying power ratings, battery capacities, fuel range, and cost structures, minimizing total daily cost from labor, fuel, amortized capital expenditure, and energy purchase under temporal service windows, resource budgets, and energy-delivery constraints. The formulation is implemented in Python/Gurobi and applied to two case studies using California Department of Transportation wheel-loader data in Los Angeles (dense urban) and Truckee (sparse mountainous). Results show that simultaneous optimization yields compact, well-utilized fleets that meet all service windows while revealing strong sensitivity of unit cost to demand density and geography. The proposed FSMCVRPTW framework provides a generalizable decision-support methodology that co-designs fleet size, charger power, routing, and service schedules in a single optimization layer for context-aware, cost-efficient mobile fast charging.",
    "authors": [
      "Farhang Motallebi Araghi",
      "Armin Abdolmohammadi",
      "Navid Mojahed",
      "Shima Nazari"
    ],
    "primary_category": "eess.SY",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2212.07356",
    "title": "Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks",
    "abstract": "Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.",
    "authors": [
      "Chung-Hsuan Hu",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2311.08804",
    "title": "Capacity Bounds and Low-Complexity Constellation Shaping under Mixed Gaussian-Impulsive Noise",
    "abstract": "This paper investigates the bounds on channel capacity and constellation shaping under memoryless mixed noise, which is composed of impulsive noise (IN) and white Gaussian noise (WGN). The capacity bounds are derived using the entropy power inequality and the dual expression of capacity. It is then shown that the proposed lower and upper bounds asymptotically converge to the true channel capacity, and the analytic asymptotic capacity expression is obtained. Leveraging this property, we design a low-complexity constellation shaping method that operates without iterative procedures. Simulation results demonstrate that the derived bounds are remarkably tight, and the shaped constellation achieves the highest mutual information among all considered baseline schemes.",
    "authors": [
      "Tianfu Qi",
      "Jun Wang"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.03631",
    "title": "Marginalize, Rather than Impute: Probabilistic Wind Power Forecasting with Incomplete Data",
    "abstract": "Machine learning methods are widely and successfully used for probabilistic wind power forecasting, yet the pervasive issue of missing values (e.g., due to sensor faults or communication outages) has received limited attention. The prevailing practice is impute-then-predict, but conditioning on point imputations biases parameter estimates and fails to propagate uncertainty from missing features. Our approach treats missing features and forecast targets uniformly: we learn a joint generative model of features and targets from incomplete data and, at operational deployment, condition on the observed features and marginalize the unobserved ones to produce forecasts. This imputation-free procedure avoids error introduced by imputation and preserves uncertainty aroused from missing features. In experiments, it improves forecast quality in terms of continuous ranked probability score relative to impute-then-predict baselines while incurring substantially lower computational cost than common alternatives.",
    "authors": [
      "Honglin Wen",
      "Pierre Pinson",
      "Jie Gu",
      "Zhijian Jin"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2403.10934",
    "title": "Quaternion-Based Sliding Mode Control for Six Degrees of Freedom Flight Control of Quadrotors",
    "abstract": "Despite extensive research on sliding mode control (SMC) design for quadrotors, the existing approaches suffer from certain limitations. Euler angle-based SMC formulations suffer from poor performance in high-pitch or -roll maneuvers. Quaternion-based SMC approaches have unwinding issues and complex architecture. Coordinate-free methods are slow and only almost globally stable. This paper presents a new six degrees of freedom SMC flight controller to address the above limitations. We use a cascaded architecture with a position controller in the outer loop and a quaternion-based attitude controller in the inner loop. The position controller generates the desired trajectory for the attitude controller using a coordinate-free approach. The quaternion-based attitude controller uses the natural characteristics of the quaternion hypersphere, featuring a simple structure while providing global stability and avoiding unwinding issues. We compare our controller with three other common control methods conducting challenging maneuvers like flip-over and high-speed trajectory tracking in the presence of model uncertainties and disturbances. Our controller consistently outperforms the benchmark approaches with less control effort and actuator saturation, offering highly effective and efficient flight control.",
    "authors": [
      "Amin Yazdanshenas",
      "Reza Faieghi"
    ],
    "primary_category": "cs.RO",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2409.07414",
    "title": "NVRC: Neural Video Representation Compression",
    "abstract": "Recent advances in implicit neural representation (INR)-based video coding have demonstrated its potential to compete with both conventional and other learning-based approaches. With INR methods, a neural network is trained to overfit a video sequence, with its parameters compressed to obtain a compact representation of the video content. However, although promising results have been achieved, the best INR-based methods are still out-performed by the latest standard codecs, such as VVC VTM, partially due to the simple model compression techniques employed. In this paper, rather than focusing on representation architectures as in many existing works, we propose a novel INR-based video compression framework, Neural Video Representation Compression (NVRC), targeting compression of the representation. Based on the novel entropy coding and quantization models proposed, NVRC, for the first time, is able to optimize an INR-based video codec in a fully end-to-end manner. To further minimize the additional bitrate overhead introduced by the entropy models, we have also proposed a new model compression framework for coding all the network, quantization and entropy model parameters hierarchically. Our experiments show that NVRC outperforms many conventional and learning-based benchmark codecs, with a 24% average coding gain over VVC VTM (Random Access) on the UVG dataset, measured in PSNR. As far as we are aware, this is the first time an INR-based video codec achieving such performance. The implementation of NVRC will be released.",
    "authors": [
      "Ho Man Kwan",
      "Ge Gao",
      "Fan Zhang",
      "Andrew Gower",
      "David Bull"
    ],
    "primary_category": "cs.CV",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2411.18551",
    "title": "Concentration of Cumulative Reward in Markov Decision Processes",
    "abstract": "In this paper, we investigate the concentration properties of cumulative reward in Markov Decision Processes (MDPs), focusing on both asymptotic and non-asymptotic settings. We introduce a unified approach to characterize reward concentration in MDPs, covering both infinite-horizon settings (i.e., average and discounted reward frameworks) and finite-horizon setting. Our asymptotic results include the law of large numbers, the central limit theorem, and the law of iterated logarithms, while our non-asymptotic bounds include Azuma-Hoeffding-type inequalities and a non-asymptotic version of the law of iterated logarithms. Additionally, we explore two key implications of our results. First, we analyze the sample path behavior of the difference in rewards between any two stationary policies. Second, we show that two alternative definitions of regret for learning policies proposed in the literature are rate-equivalent. Our proof techniques rely on a martingale decomposition of cumulative reward, properties of the solution to the policy evaluation fixed-point equation, and both asymptotic and non-asymptotic concentration results for martingale difference sequences.",
    "authors": [
      "Borna Sayedana",
      "Peter E. Caines",
      "Aditya Mahajan"
    ],
    "primary_category": "cs.LG",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.00655",
    "title": "Implicit Generative Modeling by Kernel Similarity Matching",
    "abstract": "Understanding how the brain encodes stimuli has been a fundamental problem in computational neuroscience. Insights into this problem have led to the design and development of artificial neural networks that learn representations by incorporating brain-like learning abilities. Recently, learning representations by capturing similarity between input samples has been studied to tackle this problem. This approach, however, has thus far been used to only learn downstream features from an input and has not been studied in the context of a generative paradigm, where one can map the representations back to the input space, incorporating not only bottom-up interactions (stimuli to latent) but also learning features in a top-down manner (latent to stimuli). We investigate a kernel similarity matching framework for generative modeling. Starting with a modified sparse coding objective for learning representations proposed in prior work, we demonstrate that representation learning in this context is equivalent to maximizing similarity between the input kernel and a latent kernel. We show that an implicit generative model arises from learning the kernel structure in the latent space and show how the framework can be adapted to learn manifold structures, potentially providing insights as to how task representations can be encoded in the brain. To solve the objective, we propose a novel Alternate Direction Method of Multipliers (ADMM) based algorithm and discuss the interpretation of the optimization process. Finally, we discuss how this representation learning problem can lead towards a biologically plausible architecture to learn the model parameters that ties together representation learning using similarity matching (a bottom-up approach) with predictive coding (a top-down approach).",
    "authors": [
      "Shubham Choudhary",
      "Paul Masset",
      "Demba Ba"
    ],
    "primary_category": "q-bio.NC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2503.20772",
    "title": "Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?",
    "abstract": "Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability - ranging from ordinal level comparability to full cardinal comparability - together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.",
    "authors": [
      "Ilia Shilov",
      "Ezzat Elokda",
      "Sophie Hall",
      "Heinrich H. Nax",
      "Saverio Bolognani"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.06790",
    "title": "Analog Computing for Signal Processing and Communications -- Part I: Computing with Microwave Networks",
    "abstract": "Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.07477",
    "title": "Analog Computing for Signal Processing and Communications -- Part II: Toward Gigantic MIMO Beamforming",
    "abstract": "Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\\times 10^4$ and $4.0\\times 10^7$ times, respectively, compared to digital beamforming.",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.18446",
    "title": "MROP: Modulated Rank-One Projections for compressive radio interferometric imaging",
    "abstract": "The emerging generation of radio-interferometric (RI) arrays are set to form images of the sky with a new regime of sensitivity and resolution. This implies a significant increase in visibility data volumes, which for single-frequency observations will scale as $\\mathcal{O}(Q^2B)$ for $Q$ antennas and $B$ short-time integration intervals (or batches), calling for efficient data dimensionality reduction techniques. This paper proposes a new approach to data compression during acquisition, coined modulated rank-one projection (MROP). MROP compresses the $Q\\times Q$ batchwise covariance matrix into a smaller number $P$ of random rank-one projections and compresses across time by trading $B$ for a smaller number $M$ of random modulations of the ROP measurement vectors. Firstly, we introduce a dual perspective on the MROP acquisition, which can either be understood as random beamforming, or as a post-correlation compression. Secondly, we analyse the noise statistics of MROPs and demonstrate that the random projections induce a uniform noise level across measurements independently of the visibility-weighting scheme used. Thirdly, we propose a detailed analysis of the memory and computational cost requirements across the data acquisition and image reconstruction stages, with comparison to state-of-the-art dimensionality reduction approaches. Finally, the MROP model is validated for monochromatic intensity imaging both in simulation and from real data, with comparison to the classical and baseline-dependent averaging (BDA) models, and using the uSARA optimisation algorithm for image formation. Our results suggest that the data size necessary to preserve imaging quality using MROPs is reduced to the order of image size, well below the original and BDA data sizes.",
    "authors": [
      "Olivier Leblanc",
      "Chung San Chu",
      "Laurent Jacques",
      "Yves Wiaux"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.04209",
    "title": "Mutual Information Bounds for Lossy Common Information",
    "abstract": "We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and Gács-Körner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).",
    "authors": [
      "Anderson de Andrade"
    ],
    "primary_category": "cs.IT",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.11168",
    "title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models",
    "abstract": "The increasing need for robustness, reliability, and determinism in wireless networks for industrial and mission-critical applications is the driver for the growth of new innovative methods. The study presented in this work makes use of machine learning techniques to predict channel quality in a Wi-Fi network in terms of the frame delivery ratio. Predictions can be used proactively to adjust communication parameters at runtime and optimize network operations for industrial applications. Methods including convolutional neural networks and long short-term memory were analyzed on datasets acquired from a real Wi-Fi setup across multiple channels. The models were compared in terms of prediction accuracy and computational complexity. Results show that the frame delivery ratio can be reliably predicted, and convolutional neural networks, although slightly less effective than other models, are more efficient in terms of CPU usage and memory consumption. This enhances the model's usability on embedded and industrial systems.",
    "authors": [
      "Gabriele Formis",
      "Amanda Ericson",
      "Stefan Forsstrom",
      "Kyi Thar",
      "Gianluca Cena",
      "Stefano Scanzio"
    ],
    "primary_category": "cs.NI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2509.23143",
    "title": "MathBode: Measuring the Stability of LLM Reasoning using Frequency Response",
    "abstract": "This paper presents MathBode, a dynamic diagnostic for mathematical reasoning in large language models (LLMs). Instead of one-shot accuracy, MathBode treats each parametric problem as a system: we drive a single parameter sinusoidally and fit first-harmonic responses of model outputs and exact solutions. This yields interpretable, frequency-resolved metrics -- gain (amplitude tracking) and phase (lag) -- that form Bode-style fingerprints. Across five closed-form families (linear solve, ratio/saturation, compound interest, 2x2 linear systems, similar triangles), the diagnostic surfaces systematic low-pass behavior and growing phase lag that accuracy alone obscures. We compare several models against a symbolic baseline that calibrates the instrument ($G \\approx 1$, $\\phi \\approx 0$). Results separate frontier from mid-tier models on dynamics, providing a compact, reproducible protocol that complements standard benchmarks with actionable measurements of reasoning fidelity and consistency. We open-source the dataset and code to enable further research and adoption.",
    "authors": [
      "Charles L. Wang"
    ],
    "primary_category": "cs.AI",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2510.14159",
    "title": "Musical consonance: a review of theory and evidence on perception and preference of auditory roughness in humans and other animals",
    "abstract": "The origins of consonance in human music has long been contested, and today there are three primary hypotheses: aversion to roughness, preference for harmonicity, and learned preferences from cultural exposure. While the evidence is currently insufficient to disentangle the contributions of these hypotheses, I propose several reasons why roughness is an especially promising area for future study. The aim of this review is to summarize and critically evaluate roughness theory and models, experimental data, to highlight areas that deserve further research. I identify 2 key areas: There are fundamental issues with the definition and interpretation of results due to tautology in the definition of roughness, and the lack of independence in empirical measurements. Despite extensive model development, there are many duplications and models have issues with data quality and overfitting. Future theory development should aim for model simplicity, and extra assumptions, features and parameters should be evaluated systematically. Model evaluation should aim to maximise the breadth of stimuli that are predicted.",
    "authors": [
      "John M. McBride"
    ],
    "primary_category": "physics.soc-ph",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03366",
    "title": "Evaluating A/B Testing Methodologies via Sample Splitting: Theory and Practice",
    "abstract": "We develop a theoretical framework for sample splitting in A/B testing environments, where data for each test are partitioned into two splits to measure methodological performance when the true impacts of tests are unobserved. We show that sample-split estimators are generally biased for full-sample performance but consistently estimate sample-split analogues of it. We derive their asymptotic distributions, construct valid confidence intervals, and characterize the bias-variance trade-offs underlying sample-split design choices. We validate our theoretical results through simulations and provide implementation guidance for A/B testing products seeking to evaluate new estimators and decision rules.",
    "authors": [
      "Ryan Kessler",
      "James McQueen",
      "Miikka Rokkanen"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03396",
    "title": "Aggregate then evaluate",
    "abstract": "We distinguish two frameworks for decisions under ambiguity: evaluate-then-aggregate (ETA) and aggregate-then-evaluate (ATE). Given a statistic that represents the decision maker's pure-risk preferences (such as expected utility) and an ambiguous act, an ETA model first evaluates the act under each plausible probabilistic model using this statistic and then aggregates the resulting evaluations according to ambiguity attitudes. In contrast, an ATE model first aggregates ambiguity by assigning the act a single representative distribution and then evaluates that distribution using the statistic. These frameworks differ in the order in which risk and ambiguity are processed, and they coincide when there is no ambiguity. While most existing ambiguity models fall within the ETA framework, our study focuses on the ATE framework, which is conceptually just as compelling and has been relatively neglected in the literature. We develop a Choquet ATE model, which generalizes the Choquet expected utility model by allowing arbitrary pure-risk preferences. We provide an axiomatization of this model in a Savage setting with an exogenous source of unambiguous events. The Choquet ATE framework allows us to analyze a wide range of ambiguity attitudes and their interplay with risk attitudes.",
    "authors": [
      "Zachary Van Oosten",
      "Ruodu Wang"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03596",
    "title": "vop_poc_nz: A Python Framework for Distributional Cost-Effectiveness and Value of Perspective Analysis",
    "abstract": "Health economic evaluations are sensitive to the choice of analytical perspective (e.g., health system vs. societal). While guidelines often recommend specific perspectives, the uncertainty associated with this choice - and the potential decision discordance it creates - is rarely quantified. We present vop_poc_nz, a Python package that implements a framework for Distributional Cost-Effectiveness Analysis (DCEA) and operationalizes the quantification of perspective uncertainty through the Value of Perspective (VoP) metric. The package provides tools for Markov modeling, probabilistic sensitivity analysis, value of information analysis, and equity impact assessment. Unlike existing tools that treat perspective as a fixed input, vop_poc_nz allows for the simultaneous evaluation of multiple perspectives. This enables decision-makers to estimate the opportunity cost of perspective misalignment. We demonstrate the package's capabilities using case studies from Aotearoa New Zealand.",
    "authors": [
      "Dylan A Mordaunt"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03693",
    "title": "Estimation of Panel Data Models with Nonlinear Factor Structure",
    "abstract": "Panel data models with unobserved heterogeneity in the form of interactive effects standardly assume that the time effects - or \"common factors\" - enter linearly. This assumption is unnatural in the sense that it pertains to the unobserved component of the model, and there is rarely any reason to believe that this component takes on a particular functional form. This is in stark contrast to the relationship between the observables, which can often be credibly argued to be linear. Linearity in the factors has persevered mainly because it is convenient, and that it is better than standard fixed effects. The present paper relaxes this assumption. It does so by combining the common correlated effects (CCE) approach to standard interactive effects with the method of sieves. The new estimator - abbreviated \"SCCE\" - retains many of the advantages of CCE, including its computational simplicity, and good small-sample and asymptotic properties, but is applicable under a much broader class of factor structures that includes the linear one as a special case. This makes it well-suited for a wide range of empirical applications.",
    "authors": [
      "Christina Maschmann",
      "Joakim Westerlund"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03763",
    "title": "Learning from crises: A new class of time-varying parameter VARs with observable adaptation",
    "abstract": "We revisit macroeconomic time-varying parameter vector autoregressions (TVP-VARs), whose persistent coefficients may adapt too slowly to large, abrupt shifts such as those during major crises. We explore the performance of an adaptively-varying parameter (AVP) VAR that incorporates deterministic adjustments driven by observable exogenous variables, replacing latent state innovations with linear combinations of macroeconomic and financial indicators. This reformulation collapses the state equation into the measurement equation, enabling simple linear estimation of the model. Simulations show that adaptive parameters are substantially more parsimonious than conventional TVPs, effectively disciplining parameter dynamics without sacrificing flexibility. Using macroeconomic datasets for both the U.S. and the euro area, we demonstrate that AVP-VAR consistently improves out-of-sample forecasts, especially during periods of heightened volatility.",
    "authors": [
      "Nicolas Hardy",
      "Dimitris Korobilis"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03812",
    "title": "From Micro-Distributions to Macro-Regularities: A Critique and Reconstruction of the Production Function Based on the Maximum Entropy Principle",
    "abstract": "This paper aims to provide a micro-foundation for the Cobb-Douglas production function based on statistical physics, and to launch a critique of its political-economic implications. By introducing the Maximum Entropy Principle and an axiom of scale invariance, we prove that in an economic system with incomplete information, the most unbiased distribution of micro-level technical coefficients must take the form of a truncated power law. Based on this, statistical aggregation naturally leads to the emergence of a constant-returns-to-scale Cobb-Douglas function at the macro level. This result not only provides a micro-foundation for neoclassical growth models that does not rely on a representative agent or value aggregation of capital but, more importantly, reveals that the aggregate production function is essentially a lossy compression of micro-level information. In this compression process, the social-historical relations embedded in distribution parameters are 'naturalized' into seemingly eternal technical laws, which is the manifestation of Marx's critique of 'fetishism' at the level of mathematical logic. This paper further deepens the understanding of the production function as a statistical phenomenon rather than a technical law through dialogues with Marx, the Cambridge School, and Shaikh.",
    "authors": [
      "Jihyuan Liuh"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03821",
    "title": "Is Jobless Growth Valid in Turkiye? A Sectoral Analysis of the Relationship between Unemployment and Economic Growth",
    "abstract": "This study analyzes the validity of jobless growth in Turkiye on sectoral basis. It analyzes the impacts of agriculture, industry, construction and services sectors on unemployment using annual data for the period 2000-2022. ARDL method is applied within the scope of the analysis. The findings are tested with FMOLS and CCR methods. The results show that growth in all sectors reduces the unemployment. A one-unit increase in the share of agriculture sector in GDP decreases the unemployment rate by 0.471 points, 0.680 points in the industrial sector, 0.899 points in the construction sector and 1.383 points in the services sector in the short-run. The long-run coefficients reveal that the impacts of sectoral growth on unemployment are stronger in the long-run than in the short-run. A one unit increase in the share of the agricultural sector in GDP decreases the unemployment rate by 2.380 points, 4.057 points in the industrial sector, 1.761 points in the construction sector and 3.664 points in the services sector in the long-run. These findings show that jobless growth is not valid in Turkiye in general. On the contrary, economic growth plays an important role in reducing unemployment.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03822",
    "title": "Does Globalization Promote or Hinder Sustainable Development? Evidence from Turkiye on the Three Dimensions of Globalization",
    "abstract": "This study analyzes the impact of globalization on sustainable development in Turkiye. We used the ARDL method with annual data for the period 2000-2021. Results reveal that economic globalization promotes positively to sustainable development in the short run with a coefficient of 0.144 and in the long run with a 0.153 coefficient. Although social globalization has a negative impact with a coefficient of -0.150 in the short run, this effect turns positive with a coefficient of 0.080 in the long run. Political globalization strongly supports sustainable development with a coefficient of 0.254 in the short run and 2.634 in the long run. Finally, total globalization has a positive impact on sustainable development in the short and long run with coefficients of 0.339 and 0.196, respectively.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03902",
    "title": "Equalizer or amplifier? How AI may reshape human cognitive differences",
    "abstract": "Machines have at times equalized physical strength by substituting for human effort, and at other times amplified these differences. Artificial intelligence (AI) may likewise narrow or widen disparities in cognitive ability. Recent evidence from the Information and Communication Technology (ICT) revolution suggests that computers increased inequality by education but reduced it by cognitive ability. Early research on generative AI shows larger productivity gains for less-skilled than for high-skilled workers. Whether AI ultimately acts as an equalizer or an amplifier of human cognitive differences is especially crucial for education systems, which must decide whether -- and how -- to allow students to use AI in coursework and exams. This decision is urgent because employers value workers who can leverage AI effectively rather than operate independently of it.",
    "authors": [
      "Maria Bigoni",
      "Andrea Ichino",
      "Aldo Rustichini",
      "Giulio Zanella"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03930",
    "title": "A choice-based axiomatization of Nash equilibrium",
    "abstract": "An axiomatic characterization of Nash equilibrium is provided for games in normal form. The Nash equilibrium correspondence is shown to be fully characterized by four simple and intuitive axioms, two of which are inspired by contraction and expansion consistency properties from the literature on abstract choice theory. The axiomatization applies to Nash equilibria in pure and mixed strategies alike, to games with strategy sets of any cardinality, and it does not require that players' preferences have a utility or expected utility representation.",
    "authors": [
      "Michele Crescenzi"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03982",
    "title": "Payoff Continuity in Games of Incomplete Information Across Models of Knowledge",
    "abstract": "Equilibrium predictions in games of incomplete information are sensitive to the assumed information structure. Monderer and Samet (1996) and Kajii and Morris (1998) define topological notions of proximity for common prior information structures such that two information structures are close if and only if (approximate) equilibrium payoffs are close. However, Monderer and Samet (1996) fix a common prior and define their topology on profiles of partitions over a state space, whereas Kajii and Morris (1998) define their topology on common priors over the product of a state space and a type space. We prove the open conjecture that two partition profiles are close in the Monderer and Samet (1996) topology if and only if there exists a labeling of types such that the associated common priors are close in the Kajii and Morris (1998) topology.",
    "authors": [
      "Ashwin Kambhampati"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04035",
    "title": "Assessing Financial Statement Risks among $\\mathrm{MCDM}$ Techniques",
    "abstract": "In this paper, to determine the financial risks faced by an industrial company, assessing the relative importance of these risks and identifying the years most exposed to financial risk using modern multi-criteria decision-making techniques. Applied to AL-Ahliah Vegetable Oil Company, the research utilizes the Analytical Hierarchy Process and Simple Additive Weighting to analyze financial ratios from 2008 to 2017.",
    "authors": [
      "Marwa Abdullah",
      "Revzon Oksana Anatolyevna",
      "Duaa Abdullah"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.04047",
    "title": "Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs",
    "abstract": "In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.",
    "authors": [
      "Nadav Kunievsky"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03088",
    "title": "From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection",
    "abstract": "As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.",
    "authors": [
      "Giulio Caldarelli"
    ],
    "primary_category": "cs.CR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.03524",
    "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities",
    "abstract": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.",
    "authors": [
      "Grzegorz Jamróz",
      "Rafał Kucharski",
      "David Watling"
    ],
    "primary_category": "math.OC",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2412.07031",
    "title": "Large Language Models: An Applied Econometric Framework",
    "abstract": "Large language models (LLMs) enable researchers to analyze text at unprecedented scale and minimal cost. Researchers can now revisit old questions and tackle novel ones with rich data. We provide an econometric framework for realizing this potential in two empirical uses. For prediction problems -- forecasting outcomes from text -- valid conclusions require ``no training leakage'' between the LLM's training data and the researcher's sample, which can be enforced through careful model choice and research design. For estimation problems -- automating the measurement of economic concepts for downstream analysis -- valid downstream inference requires combining LLM outputs with a small validation sample to deliver consistent and precise estimates. Absent a validation sample, researchers cannot assess possible errors in LLM outputs, and consequently seemingly innocuous choices (which model, which prompt) can produce dramatically different parameter estimates. When used appropriately, LLMs are powerful tools that can expand the frontier of empirical economics.",
    "authors": [
      "Jens Ludwig",
      "Sendhil Mullainathan",
      "Ashesh Rambachan"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.04243",
    "title": "Making school choice lotteries transparent",
    "abstract": "Lotteries are commonly employed in school choice to fairly resolve priority ties; however, current practices typically keep students uninformed about their lottery outcomes at the time of preference submission. This paper advocates for revealing lottery information to students beforehand. When preference lists are constrained in length, which is a common feature in real-world systems, such disclosure reduces uncertainty and enables students to make more informed decisions. We demonstrate the benefits of lottery revelation through two stylized models. Theoretical predictions are supported by laboratory experiments.",
    "authors": [
      "Lingbo Huang",
      "Jun Zhang"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2502.16800",
    "title": "A New Solution for Cooperative Game with Public Externalities",
    "abstract": "This study proposes a novel solution concept--the w-value--for cooperative games with public externalities. The w-value is axiomatically founded on three principles: Pareto Optimality (PO), Market Equilibrium (ME), and Fiscal Balance (FB), which together ensure a fair and economically sound distribution of gains. We establish its existence, uniqueness, and an accompanying implementation mechanism. A key theoretical advantage is its strong stability: the w-value lies within the core, specifically the {\\gamma}-core making it resistant to coalitional deviations. Moreover, its computational efficiency facilitates practical application to complex real-world problems, offering a clear advantage over more cumbersome alternatives. These properties make the w-value a superior framework for analyzing cooperation under public externalities. A numerical illustration demonstrates the step-by-step calculation process. Finally, we apply the concept to international climate negotiations, showing how it provides a theoretical rationale for the shift from rigid mandatory emission reduction systems toward the flexible structure of Nationally Determined Contributions.",
    "authors": [
      "Juanjuan Fan",
      "Ying Wang"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2504.03985",
    "title": "Testing Single Crossing Property with Stochastic Choice Data",
    "abstract": "In a typical model of private information and choice under uncertainty, a decision maker observes a signal, updates her prior beliefs using Bayes rule, and maximizes her expected utility. If the decision maker's utility function satisfies the single crossing property, and the information structure is ordered according to the monotone likelihood ratio, then the comparative statics exhibit monotonicity with respect to signals. We consider the restrictions placed by this model of signal processing on state conditional stochastic choice data. In particular, we show that this model rationalizes a state conditional stochastic choice dataset if and only if the dataset itself is ordered according to the monotone likelihood ratio. A straightforward application of the main result shows the conditions under which the analyst can infer when one DM is more informed than the other.",
    "authors": [
      "Tanay Raj Bhatt"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2511.21155",
    "title": "Consistent solutions to the allocation of indivisible objects with general endowments",
    "abstract": "We apply the consistency principle to examine various core concepts in a general allocation model that subsumes several familiar market design models as special cases. The conventional strong core is consistent but may be empty, whereas the exclusion core proposed by Balbuzanov and Kotowski (2019), although nonempty, is not consistent and may include unintuitive allocations. We therefore propose a refinement of the exclusion core, which is both nonempty and consistent. Our solution offers sharper predictions than alternatives and coincides with the strong core and/or the exclusion core in special cases that generalize familiar models.",
    "authors": [
      "Jun Zhang"
    ],
    "primary_category": "econ.TH",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.00785",
    "title": "Comparative Analysis of OECD Countries Based on Energy Trilemma Index: A Clustering Approach",
    "abstract": "This study analyzes OECD countries in the context of the energy trilemma index and clusters countries with similar characteristics. In the study, the k-means clustering technique is used. The optimum number of clusters was determined using the Elbow method in combination with the Silhouette Index. Moreover, all results are visualized to enhance comprehensibility. The results show that countries such as Austria, Canada, Finland, and Denmark are in the high energy trilemma group with index scores of 82.2, 82.3, 82.7, and 83.3, respectively. Countries in the high group have achieved a high level of balance between energy security, energy equity, and environmental sustainability. In addition, countries such as Belgium, Hungary, Australia, the Czech Republic, and Estonia are in the medium energy trilemma group with index scores of 76.4, 76.6, 77.1, 77.6, and 78.7, respectively. Countries in the medium group have made progress in balancing the dimensions of the energy trilemma but have not yet reached excellence. However, countries such as Mexico, Türkiye, Colombia, and Costa Rica are in the low energy trilemma group with index scores of 63.1, 64.1, 64.8, and 69.3, respectively. These low energy trilemma group countries face significant challenges in balancing energy security, energy equity, and environmental sustainability and need to make improvements in these areas.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.01139",
    "title": "Market Sensitivities and Growth Differentials Across Australian Housing Markets",
    "abstract": "Australian house prices have risen strongly since the mid-1990s, but growth has been highly uneven across regions. Raw growth figures obscure whether these differences reflect persistent structural trends or cyclical fluctuations. We address this by estimating a three-factor model in levels for regional repeat-sales log price indexes over 1995-2024. The model decomposes each regional index into a national Market factor, two stationary spreads (Mining and Lifestyle) that capture mean-reverting geographic cycles, and a city-specific residual. The Mining spread, proxied by a Perth-Sydney index differential, reflects resource-driven oscillations in relative performance; the Lifestyle spread captures amenity-driven coastal and regional cycles. The Market loading isolates each region's fundamental sensitivity, beta, to national growth, so that a city's growth under an assumed national change is calculated from its beta once mean-reverting spreads are netted out. Comparing realised paths to these factor-implied trajectories indicates when a city is historically elevated or depressed, and attributes the gap to Mining or Lifestyle spreads. Expanding-window ARIMAX estimation reveals that Market betas are stable across major shocks (the mining boom, the Global Financial Crisis, and COVID-19), while Mining and Lifestyle behave as stationary spreads that widen forecast funnels without overturning the cross-sectional ranking implied by beta. Melbourne amplifies national growth, Sydney tracks the national trend closely, and regional areas dampen it. The framework thus provides a simple, factor-based tool for interpreting regional growth differentials and their persistence.",
    "authors": [
      "Willem P Sijp"
    ],
    "primary_category": "econ.EM",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2512.02676",
    "title": "Exploring the Impacts of Economic Growth on Ecosystem and Its Subcomponents in Turkiye",
    "abstract": "This study analyzes the impacts of economic growth on ecosystem in Turkiye. The study uses annual data for the period 1995-2021 and the ARDL method. The study utilizes the Ecosystem Vitality Index, a sub-dimension of the Environmental Performance Index. In addition, seven models were constructed to assess in detail the impact of economic growth on different dimensions of the ecosystem. The results show that economic growth has a significant impact in all models analyzed. However, the direction of this impact differs across ecosystem components. Economic growth is found to have a positive impact on agriculture and water resources. In these models, a 1% increase in GDP increases the agriculture and water resources indices by 0.074-0.672%. In contrast, economic growth has a negative impact on biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality. In these models, a 1% increase in GDP reduces the indices of biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality by 0.101-2.144%. The results suggest that the environmental costs of economic growth processes need to be considered. Environmentally friendly policies should be combined with sustainable development strategies to reduce the negative impacts of economic growth.",
    "authors": [
      "Emre Akusta"
    ],
    "primary_category": "econ.GN",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2501.17096",
    "title": "Why is the estimation of metaorder impact with public market data so challenging?",
    "abstract": "Estimating market impact and transaction costs of large trades (metaorders) is a very important topic in finance. However, using models of price and trade based on public market data provide average price trajectories which are qualitatively different from what is observed during real metaorder executions: the price increases linearly, rather than in a concave way, during the execution and the amount of reversion after its end is very limited. We claim that this is a generic phenomenon due to the fact that even sophisticated statistical models are unable to correctly describe the origin of the autocorrelation of the order flow. We propose a modified Transient Impact Model which provides more realistic trajectories by assuming that only a fraction of the metaorder trading triggers market order flow. Interestingly, in our model there is a critical condition on the kernels of the price and order flow equations in which market impact becomes permanent.",
    "authors": [
      "Manuel Naviglio",
      "Giacomo Bormetti",
      "Francesco Campigli",
      "German Rodikov",
      "Fabrizio Lillo"
    ],
    "primary_category": "q-fin.TR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  },
  {
    "id": "arXiv:2507.04093",
    "title": "Dynamic Asset Pricing with α-MEU Model",
    "abstract": "We study a dynamic asset pricing problem in which a representative agent is ambiguous about the aggregate endowment growth rate and trades a risky stock, human capital, and a risk-free asset to maximize her preference value of consumption represented by the {\\alpha}-maxmin expected utility model. This preference model is known to be dynamically inconsistent, so we consider intra-personal equilibrium strategies for the representative agent and define the market equilibrium as the one in which the strategy that clears the market is an intra-personal equilibrium. We prove the existence and uniqueness of the market equilibrium and show that the asset prices in the equilibrium are the same as in the case when the agent does not perceive any ambiguity but believes in a particular probabilistic model of the endowment process. We show that with reasonable parameter values, the more ambiguity the agent perceives or the more ambiguity-averse she is, the lower the risk-free rate, the higher the stock price, the higher the stock risk premium, and the lower the stock volatility.",
    "authors": [
      "Jiacheng Fan",
      "Xue Dong He",
      "Ruocheng Wu"
    ],
    "primary_category": "q-fin.PR",
    "published": "2025-12-04T00:00:00+08:00",
    "updated": "2025-12-04T00:00:00+08:00"
  }
]